{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamarasessink/Master_Thesis/blob/master/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWlSGYfHk5iS",
        "outputId": "b5c7de4e-02aa-4d9d-e639-adbed2cda5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Master_Thesis'...\n",
            "remote: Enumerating objects: 256, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 256 (delta 26), reused 39 (delta 18), pack-reused 205\u001b[K\n",
            "Receiving objects: 100% (256/256), 507.08 KiB | 1.88 MiB/s, done.\n",
            "Resolving deltas: 100% (135/135), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tamarasessink/Master_Thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "DLz5nh4Hfirc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGbg0wTIPEXy",
        "outputId": "e7a25bf9-bbda-4465-f5f7-7b6e3b72fe39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 1, 'arch': 'resnet50', 'state_dict': OrderedDict([('module.queue', tensor([[-0.1885, -0.1864, -0.1856,  ..., -0.1898, -0.1623, -0.1729],\n",
            "        [ 0.0964,  0.0155,  0.0286,  ...,  0.0033, -0.0655,  0.0750],\n",
            "        [ 0.0656,  0.0905,  0.0953,  ...,  0.1015,  0.1236,  0.0729],\n",
            "        ...,\n",
            "        [-0.1036, -0.1060, -0.1139,  ..., -0.1028, -0.0904, -0.1115],\n",
            "        [ 0.1567,  0.1320,  0.1406,  ...,  0.1008,  0.0820,  0.1578],\n",
            "        [ 0.1212,  0.1433,  0.1267,  ...,  0.1375,  0.1906,  0.1015]])), ('module.queue_ptr', tensor([3072])), ('module.encoder_q.conv1.weight', tensor([[[[ 2.5702e-02,  5.6902e-02,  8.2494e-02,  ...,  5.8239e-02,\n",
            "            5.0325e-02,  8.9318e-02],\n",
            "          [ 1.0900e-01,  5.2887e-02,  5.4955e-02,  ...,  8.9962e-02,\n",
            "            6.3472e-02,  1.0593e-01],\n",
            "          [ 7.7601e-02,  6.3080e-02,  6.8413e-02,  ...,  6.6245e-02,\n",
            "            8.9524e-02,  3.9641e-02],\n",
            "          ...,\n",
            "          [ 4.7562e-02,  5.6000e-02,  2.8433e-02,  ...,  7.1702e-02,\n",
            "            3.2047e-03,  6.0118e-02],\n",
            "          [ 1.8893e-02,  8.3977e-02,  8.2059e-02,  ...,  2.2265e-02,\n",
            "            6.3014e-02,  7.3029e-02],\n",
            "          [ 4.5768e-02,  5.5659e-02,  3.5576e-02,  ...,  3.0767e-02,\n",
            "            2.2247e-02,  2.4496e-02]],\n",
            "\n",
            "         [[ 1.3407e-01,  5.1201e-02,  1.0528e-01,  ...,  9.9557e-02,\n",
            "            4.7681e-02,  8.1713e-02],\n",
            "          [ 1.3241e-01,  7.0912e-02,  1.1354e-01,  ...,  1.3964e-01,\n",
            "            1.2585e-01,  9.2404e-02],\n",
            "          [ 9.4969e-02,  1.4591e-01,  1.2224e-01,  ...,  5.3314e-02,\n",
            "            8.9308e-02,  1.1760e-01],\n",
            "          ...,\n",
            "          [ 8.9003e-02,  1.1488e-01,  7.1986e-02,  ...,  8.2938e-02,\n",
            "            7.9241e-02, -6.2373e-03],\n",
            "          [ 1.3995e-01,  1.2289e-01,  9.9014e-02,  ...,  6.3070e-02,\n",
            "            5.9389e-02,  4.1449e-02],\n",
            "          [ 1.2387e-01,  1.1003e-01,  1.1871e-01,  ...,  1.0704e-01,\n",
            "            2.3128e-02,  9.3015e-02]],\n",
            "\n",
            "         [[ 1.3738e-01,  9.3758e-02,  5.2757e-02,  ...,  7.7979e-02,\n",
            "            1.4230e-01,  1.3778e-01],\n",
            "          [ 1.1362e-01,  8.3497e-02,  8.9190e-02,  ...,  9.3233e-02,\n",
            "            1.3992e-01,  1.1132e-01],\n",
            "          [ 1.8219e-01,  1.2437e-01,  6.9000e-02,  ...,  1.0863e-01,\n",
            "            1.0967e-01,  1.3154e-01],\n",
            "          ...,\n",
            "          [ 1.0913e-01,  1.5121e-01,  9.4324e-02,  ...,  1.2796e-01,\n",
            "            1.1978e-01,  1.6598e-01],\n",
            "          [ 1.1576e-01,  1.3610e-01,  1.3259e-01,  ...,  9.5632e-02,\n",
            "            1.1555e-01,  1.5097e-01],\n",
            "          [ 1.4418e-01,  1.4892e-01,  1.0438e-01,  ...,  6.2813e-02,\n",
            "            1.3759e-01,  1.4279e-01]]],\n",
            "\n",
            "\n",
            "        [[[-3.3311e-02, -2.2036e-02, -2.8969e-02,  ...,  2.2580e-02,\n",
            "           -3.9315e-02, -2.4463e-02],\n",
            "          [ 3.1089e-02, -2.5233e-02,  3.2699e-02,  ..., -1.8271e-02,\n",
            "           -5.2747e-02, -5.9758e-02],\n",
            "          [ 6.5905e-03, -1.5109e-02, -1.3379e-03,  ..., -2.2794e-02,\n",
            "           -4.7554e-03, -1.3766e-02],\n",
            "          ...,\n",
            "          [-7.8607e-02,  1.5040e-04, -1.2137e-02,  ..., -4.6179e-02,\n",
            "           -3.9679e-03,  6.9121e-03],\n",
            "          [-2.0482e-02, -3.0183e-02, -4.6927e-02,  ..., -5.0617e-02,\n",
            "           -2.2318e-02, -5.1894e-02],\n",
            "          [-1.8191e-02, -5.1222e-02, -1.8545e-02,  ...,  4.3474e-03,\n",
            "           -2.7472e-02, -2.6405e-02]],\n",
            "\n",
            "         [[ 9.5812e-03,  3.0205e-02,  2.7230e-02,  ...,  2.9303e-02,\n",
            "            2.5369e-02,  9.1222e-02],\n",
            "          [-2.2219e-02, -6.3457e-03,  1.0082e-02,  ...,  1.8469e-02,\n",
            "            8.5437e-02,  7.0718e-02],\n",
            "          [ 6.5949e-02,  2.5784e-02,  7.3300e-03,  ...,  4.3226e-02,\n",
            "            1.6170e-02,  6.8874e-02],\n",
            "          ...,\n",
            "          [ 2.5993e-03,  6.7734e-02, -3.5804e-02,  ...,  5.5091e-02,\n",
            "            4.8749e-02,  2.9639e-02],\n",
            "          [-6.5275e-03,  4.9694e-02,  1.8071e-02,  ...,  2.1452e-02,\n",
            "            4.8998e-02,  9.8858e-02],\n",
            "          [-3.0469e-02,  1.8971e-02,  1.7999e-02,  ...,  1.2316e-02,\n",
            "            2.2707e-02,  4.8229e-02]],\n",
            "\n",
            "         [[ 2.3210e-04,  3.0502e-02,  7.4343e-02,  ...,  7.8734e-02,\n",
            "            1.7029e-02,  6.1355e-02],\n",
            "          [ 2.9219e-02,  6.9947e-02,  9.5999e-02,  ...,  3.0092e-02,\n",
            "            3.5528e-02,  7.4064e-02],\n",
            "          [ 3.8405e-02,  5.0321e-02,  1.2431e-01,  ...,  1.0116e-01,\n",
            "            3.2935e-02,  3.4181e-02],\n",
            "          ...,\n",
            "          [ 1.5459e-02,  6.6932e-02,  3.7236e-02,  ...,  8.4999e-02,\n",
            "            2.1389e-02,  9.1212e-02],\n",
            "          [ 5.3228e-02,  4.7371e-02,  6.1589e-02,  ...,  1.5362e-02,\n",
            "            6.8028e-02,  2.3580e-02],\n",
            "          [ 4.4681e-02,  2.2285e-02,  7.5484e-02,  ...,  7.0354e-02,\n",
            "            2.6550e-02,  3.9868e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2215e-02,  7.0574e-02,  4.7707e-02,  ...,  1.6042e-02,\n",
            "            2.4826e-02,  5.7341e-02],\n",
            "          [ 3.1868e-02,  4.8464e-02,  5.6540e-02,  ...,  3.2754e-02,\n",
            "            3.5862e-02,  9.5031e-02],\n",
            "          [ 5.6404e-02,  1.7876e-02,  2.8177e-02,  ...,  4.0632e-02,\n",
            "            7.6729e-02,  4.3845e-02],\n",
            "          ...,\n",
            "          [ 5.6580e-02,  3.1692e-02, -1.1104e-02,  ...,  1.3203e-02,\n",
            "            6.2570e-02,  9.1866e-02],\n",
            "          [ 3.7866e-02,  1.7016e-02,  1.9545e-02,  ...,  6.6297e-02,\n",
            "            3.4289e-02,  1.6116e-02],\n",
            "          [ 6.2343e-02,  2.1254e-02,  5.1376e-02,  ...,  7.3453e-02,\n",
            "            4.4937e-02,  1.8808e-02]],\n",
            "\n",
            "         [[ 1.3561e-02, -9.0821e-03,  3.7942e-02,  ...,  2.0401e-02,\n",
            "           -1.4384e-02,  9.2479e-02],\n",
            "          [ 6.6645e-02,  3.9029e-02,  2.8060e-02,  ...,  3.9865e-02,\n",
            "            9.9805e-02,  4.5666e-02],\n",
            "          [ 3.3563e-02,  2.2831e-02,  3.8882e-02,  ...,  4.8162e-02,\n",
            "            5.5950e-02,  1.0449e-01],\n",
            "          ...,\n",
            "          [ 3.3542e-02,  5.8230e-02,  5.7212e-03,  ...,  6.1595e-02,\n",
            "            3.8358e-02,  6.3809e-02],\n",
            "          [ 7.3743e-02,  4.8668e-02, -1.7078e-02,  ...,  5.7893e-02,\n",
            "            2.8046e-02,  8.2666e-02],\n",
            "          [ 3.9371e-02,  2.4505e-02,  5.4788e-02,  ...,  1.2043e-03,\n",
            "            1.5206e-02,  6.0956e-02]],\n",
            "\n",
            "         [[ 5.3664e-02, -7.9372e-03,  3.2137e-02,  ...,  2.7981e-02,\n",
            "            2.8339e-02,  3.2552e-02],\n",
            "          [-3.8825e-02,  2.7984e-02, -3.0751e-04,  ...,  3.9426e-02,\n",
            "            1.3382e-02,  2.3998e-02],\n",
            "          [ 2.4253e-02,  8.2708e-02,  3.3304e-02,  ..., -5.2858e-03,\n",
            "            6.9510e-02,  6.0728e-02],\n",
            "          ...,\n",
            "          [ 3.1667e-02,  6.3684e-02,  2.2083e-03,  ...,  3.4823e-02,\n",
            "            2.4045e-02,  6.3341e-02],\n",
            "          [ 4.6753e-02, -2.2883e-02, -3.2370e-03,  ...,  5.9798e-03,\n",
            "            4.8475e-02,  1.1139e-02],\n",
            "          [-3.0429e-02,  1.3219e-03,  4.0086e-02,  ...,  3.4024e-02,\n",
            "            2.4558e-02,  4.6836e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.7067e-03,  5.4167e-02,  4.4530e-02,  ...,  3.6657e-02,\n",
            "           -2.1310e-02,  6.2893e-02],\n",
            "          [-3.2768e-03, -1.6673e-02,  9.6405e-03,  ...,  2.3155e-02,\n",
            "            5.8483e-02,  1.7640e-02],\n",
            "          [ 3.8112e-02,  2.8344e-02, -2.9415e-02,  ...,  2.4720e-02,\n",
            "            1.8149e-02,  4.3968e-02],\n",
            "          ...,\n",
            "          [-3.0103e-03,  1.8682e-02,  1.6875e-02,  ...,  4.9864e-02,\n",
            "            2.2403e-02,  7.9310e-02],\n",
            "          [ 2.3965e-02,  6.6313e-02,  9.5695e-03,  ...,  1.7974e-02,\n",
            "            2.2576e-02,  4.1197e-02],\n",
            "          [ 5.7647e-02,  1.5347e-02,  2.6717e-02,  ...,  2.2946e-02,\n",
            "            1.8760e-02,  2.2766e-02]],\n",
            "\n",
            "         [[-2.4445e-02, -8.5923e-04, -2.3031e-02,  ..., -2.4244e-02,\n",
            "           -5.5321e-03, -3.3928e-02],\n",
            "          [-3.8052e-02, -8.1288e-03, -9.6647e-03,  ..., -5.5747e-02,\n",
            "           -2.3307e-02, -6.5059e-02],\n",
            "          [ 2.2697e-02, -4.8425e-02, -1.7724e-02,  ..., -9.4817e-03,\n",
            "           -2.4175e-02, -4.1602e-02],\n",
            "          ...,\n",
            "          [-4.3960e-02, -2.4908e-02, -2.3254e-02,  ..., -1.3959e-02,\n",
            "           -7.4723e-02, -3.7683e-02],\n",
            "          [-4.1083e-02,  2.0001e-02, -6.9569e-02,  ..., -1.4911e-02,\n",
            "            4.6021e-03, -1.7924e-02],\n",
            "          [ 1.6079e-02, -5.5279e-02, -3.1789e-02,  ...,  3.5283e-03,\n",
            "           -9.1934e-02, -1.5998e-04]],\n",
            "\n",
            "         [[-9.0515e-02, -6.3998e-02, -5.9795e-03,  ..., -3.3986e-02,\n",
            "           -5.7690e-02, -1.7267e-02],\n",
            "          [-3.7832e-02, -2.1715e-02, -4.2363e-02,  ...,  1.5366e-03,\n",
            "           -1.4866e-01, -3.9187e-02],\n",
            "          [-6.0340e-02, -2.4059e-02, -4.2359e-02,  ..., -5.8483e-02,\n",
            "           -2.3855e-02, -1.0178e-01],\n",
            "          ...,\n",
            "          [-5.7057e-02, -2.0288e-02, -8.0843e-02,  ..., -4.3032e-02,\n",
            "           -4.0993e-02, -5.4296e-02],\n",
            "          [-4.6349e-02, -2.0435e-02, -4.1019e-02,  ..., -6.1990e-02,\n",
            "           -7.8704e-02, -8.3297e-02],\n",
            "          [-5.1316e-03, -1.8433e-02, -2.8397e-02,  ..., -9.6487e-02,\n",
            "           -3.8907e-02, -8.0492e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5481e-02, -1.9484e-02,  3.1617e-02,  ...,  2.1170e-02,\n",
            "            9.8877e-03,  3.9698e-02],\n",
            "          [-1.3949e-02, -2.8032e-02, -1.8913e-02,  ...,  3.6870e-02,\n",
            "           -3.0065e-02,  1.9517e-02],\n",
            "          [-2.3613e-02, -4.5828e-02,  8.2031e-03,  ..., -9.4770e-03,\n",
            "            4.7022e-03, -5.4773e-02],\n",
            "          ...,\n",
            "          [-3.5342e-02, -4.1267e-02, -7.4289e-03,  ..., -2.5470e-03,\n",
            "           -9.3570e-03, -1.6074e-02],\n",
            "          [-2.2999e-02, -6.0062e-02, -3.4534e-02,  ..., -2.6499e-03,\n",
            "           -1.7571e-02,  5.8223e-03],\n",
            "          [-6.5405e-02, -5.2744e-02, -8.4768e-03,  ..., -1.7967e-02,\n",
            "           -3.5395e-02, -1.1628e-02]],\n",
            "\n",
            "         [[ 7.1073e-03, -3.5767e-02, -1.7352e-02,  ...,  2.4905e-02,\n",
            "           -2.9245e-02, -2.8369e-02],\n",
            "          [-2.7993e-02, -6.1123e-02, -9.2739e-03,  ..., -3.7911e-02,\n",
            "           -1.7424e-02, -1.2381e-02],\n",
            "          [-4.5520e-02, -2.0060e-02, -1.3771e-02,  ..., -3.0543e-02,\n",
            "           -2.1616e-02, -4.2397e-02],\n",
            "          ...,\n",
            "          [-3.4529e-02, -3.4726e-02, -2.3167e-02,  ..., -6.8711e-02,\n",
            "           -7.2844e-02, -2.6662e-02],\n",
            "          [-3.3388e-02, -4.2207e-02, -6.0816e-02,  ..., -3.3641e-02,\n",
            "           -3.8705e-02, -3.9428e-02],\n",
            "          [-7.1147e-02, -6.7016e-02, -5.4238e-02,  ..., -7.0156e-03,\n",
            "           -6.7340e-02, -8.4017e-02]],\n",
            "\n",
            "         [[ 1.1544e-01,  6.1375e-02,  5.4399e-02,  ...,  2.3124e-03,\n",
            "            5.1508e-02,  6.1262e-02],\n",
            "          [ 3.5250e-02,  6.0014e-02, -5.7582e-04,  ...,  4.6294e-02,\n",
            "            4.6112e-02,  1.0752e-03],\n",
            "          [ 4.0654e-02,  1.3541e-02,  1.5932e-02,  ...,  4.4674e-02,\n",
            "            6.5308e-02,  4.4646e-02],\n",
            "          ...,\n",
            "          [ 1.0575e-02,  1.2503e-02, -1.4129e-03,  ..., -2.7229e-04,\n",
            "           -2.2864e-02,  2.4003e-03],\n",
            "          [ 3.7119e-02,  1.2475e-02, -1.8712e-02,  ..., -2.1206e-02,\n",
            "           -3.5810e-02, -5.4280e-03],\n",
            "          [-5.0694e-02, -5.9919e-03,  3.6371e-02,  ...,  1.1897e-02,\n",
            "           -2.6690e-02,  3.1324e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5534e-02, -1.5261e-02, -7.7541e-02,  ..., -3.7525e-02,\n",
            "           -2.1173e-02, -5.0034e-02],\n",
            "          [-6.0051e-02,  1.8632e-02, -5.3693e-03,  ..., -2.8734e-02,\n",
            "            6.1524e-02, -1.1294e-02],\n",
            "          [-2.6958e-02,  7.7522e-03, -2.0294e-02,  ..., -1.8771e-02,\n",
            "            1.1957e-02, -4.9590e-03],\n",
            "          ...,\n",
            "          [-5.4041e-02, -1.8614e-02,  6.0147e-02,  ..., -2.1952e-02,\n",
            "            2.5475e-02, -1.1775e-02],\n",
            "          [ 4.6229e-03, -9.0748e-03,  6.2192e-03,  ..., -2.2056e-02,\n",
            "           -1.9617e-02,  1.2759e-02],\n",
            "          [-3.8262e-02,  1.9151e-02, -2.9767e-02,  ..., -3.6328e-02,\n",
            "           -4.8860e-02, -2.3257e-02]],\n",
            "\n",
            "         [[ 2.6808e-02,  1.4539e-03,  6.2393e-03,  ...,  4.4113e-02,\n",
            "            1.4434e-02, -1.5506e-02],\n",
            "          [ 2.5953e-02,  3.6530e-03,  3.4104e-02,  ...,  4.7725e-02,\n",
            "            1.9215e-02,  1.8953e-02],\n",
            "          [ 2.6403e-02,  1.7728e-02,  5.4963e-02,  ...,  5.9852e-02,\n",
            "            7.2918e-02,  2.2224e-02],\n",
            "          ...,\n",
            "          [ 4.1406e-02,  3.5586e-02,  3.1289e-02,  ..., -1.7519e-02,\n",
            "            3.6865e-02,  3.5710e-02],\n",
            "          [ 2.5621e-02,  2.3284e-02,  3.5975e-02,  ...,  4.6706e-02,\n",
            "            4.4120e-02,  5.7992e-02],\n",
            "          [ 3.8365e-02,  3.2375e-02,  4.6292e-02,  ...,  3.1296e-02,\n",
            "            3.8189e-02,  4.9845e-02]],\n",
            "\n",
            "         [[-1.1680e-01, -1.0068e-01,  4.0831e-03,  ..., -1.0139e-01,\n",
            "           -6.5252e-02, -6.7271e-02],\n",
            "          [-8.8338e-02, -5.4145e-02, -8.8650e-03,  ..., -5.9845e-02,\n",
            "           -1.7305e-02, -4.1730e-02],\n",
            "          [-1.0143e-01, -3.6698e-02, -2.3550e-02,  ..., -2.2367e-02,\n",
            "           -2.3519e-02, -4.4814e-02],\n",
            "          ...,\n",
            "          [-1.0696e-01, -1.0231e-01, -2.6072e-02,  ..., -4.4492e-02,\n",
            "           -2.3938e-02, -7.1720e-02],\n",
            "          [-3.4772e-02, -2.4035e-02, -8.6496e-03,  ..., -7.6543e-02,\n",
            "           -9.1108e-02, -4.3442e-02],\n",
            "          [-5.9284e-02, -6.5907e-02, -5.4311e-02,  ..., -5.0407e-02,\n",
            "           -3.8820e-02,  1.3862e-02]]]])), ('module.encoder_q.bn1.weight', tensor([0.9745, 0.9692, 1.0140, 0.9912, 0.9725, 0.9927, 0.9526, 1.0166, 0.9847,\n",
            "        0.9910, 0.9956, 0.9865, 0.9946, 0.9976, 1.0030, 1.0108, 0.9981, 0.9959,\n",
            "        0.9890, 0.9647, 0.9708, 0.9996, 1.0232, 1.0187, 0.9825, 0.9835, 0.9803,\n",
            "        0.9978, 0.9779, 0.9782, 0.9971, 0.9965, 0.9918, 0.9964, 0.9796, 1.0143,\n",
            "        0.9969, 0.9905, 0.9868, 1.0177, 1.0061, 0.9919, 1.0084, 0.9796, 1.0155,\n",
            "        0.9713, 0.9847, 1.0132, 0.9931, 0.9808, 0.9736, 0.9839, 0.9782, 1.0059,\n",
            "        1.0070, 1.0170, 0.9907, 1.0301, 0.9733, 1.0181, 0.9468, 0.9694, 0.9953,\n",
            "        0.9971])), ('module.encoder_q.bn1.bias', tensor([-0.0145,  0.0332,  0.0177,  0.0113, -0.0185,  0.0118, -0.0354,  0.0425,\n",
            "        -0.0178,  0.0209, -0.0097, -0.0045, -0.0073,  0.0083,  0.0342, -0.0048,\n",
            "         0.0070,  0.0337, -0.0173, -0.0331, -0.0350,  0.0129, -0.0177,  0.0147,\n",
            "         0.0035,  0.0044,  0.0045,  0.0119,  0.0043, -0.0003,  0.0010, -0.0165,\n",
            "        -0.0146,  0.0061, -0.0052, -0.0078,  0.0054,  0.0087, -0.0080,  0.0016,\n",
            "        -0.0006, -0.0262, -0.0219,  0.0188, -0.0163, -0.0067, -0.0068, -0.0116,\n",
            "        -0.0299, -0.0118,  0.0129, -0.0260,  0.0301,  0.0253, -0.0200,  0.0407,\n",
            "         0.0123,  0.0301, -0.0019,  0.0360, -0.0387, -0.0516,  0.0459,  0.0028])), ('module.encoder_q.bn1.running_mean', tensor([ 3.1647,  0.8246,  1.1937, -1.1195, -1.1415, -0.8937, -0.5366, -0.5186,\n",
            "        -0.3887,  0.5270,  0.9490,  0.8431, -0.4408, -0.6788,  1.5006,  0.8409,\n",
            "         0.9341,  0.6050, -0.9874, -1.3780,  1.3956,  0.3099,  0.3179, -0.3663,\n",
            "        -1.0830,  0.6268, -0.4513, -0.2538,  0.9054, -1.0199, -0.6766, -0.6475,\n",
            "        -0.0616,  1.3925,  1.7925, -1.3561, -0.4498, -1.0103, -0.7713, -0.4140,\n",
            "         0.6037,  0.0644,  1.6550, -0.0226, -2.7681,  0.6597,  0.6598, -0.1864,\n",
            "        -0.9561,  1.4092,  1.4034,  0.8235, -0.7740,  2.0518, -1.2974,  1.7900,\n",
            "        -0.3220, -0.6581, -0.2166, -0.7077,  0.8414, -0.6950, -0.0558, -0.7408])), ('module.encoder_q.bn1.running_var', tensor([1.7941, 0.2037, 0.2420, 0.2657, 0.2044, 0.2269, 0.2341, 0.0403, 0.2574,\n",
            "        0.1711, 0.1609, 0.2437, 0.0368, 0.2683, 0.5125, 0.4924, 0.1373, 0.0988,\n",
            "        0.1526, 0.3204, 0.4346, 0.0647, 0.1047, 0.0465, 0.3261, 0.0702, 0.0474,\n",
            "        0.1768, 0.2444, 0.2354, 0.0734, 0.1307, 0.0368, 0.4122, 0.5001, 0.3110,\n",
            "        0.0417, 0.2365, 0.1244, 0.1324, 0.1769, 0.0972, 0.5719, 0.2384, 1.2534,\n",
            "        0.1219, 0.0904, 0.0408, 0.1875, 0.3054, 0.4656, 0.1482, 0.1378, 0.6369,\n",
            "        0.2722, 0.5330, 0.0820, 0.2002, 0.0540, 0.0855, 0.1050, 0.1750, 0.0397,\n",
            "        0.1358])), ('module.encoder_q.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.0.conv1.weight', tensor([[[[-0.0914]],\n",
            "\n",
            "         [[ 0.2044]],\n",
            "\n",
            "         [[ 0.0394]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0784]],\n",
            "\n",
            "         [[ 0.0953]],\n",
            "\n",
            "         [[-0.1223]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0511]],\n",
            "\n",
            "         [[-0.2314]],\n",
            "\n",
            "         [[ 0.1599]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1130]],\n",
            "\n",
            "         [[-0.1030]],\n",
            "\n",
            "         [[-0.0942]]],\n",
            "\n",
            "\n",
            "        [[[-0.0741]],\n",
            "\n",
            "         [[-0.0205]],\n",
            "\n",
            "         [[ 0.0576]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0686]],\n",
            "\n",
            "         [[-0.3220]],\n",
            "\n",
            "         [[-0.0498]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0608]],\n",
            "\n",
            "         [[ 0.0302]],\n",
            "\n",
            "         [[ 0.1777]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3433]],\n",
            "\n",
            "         [[ 0.2224]],\n",
            "\n",
            "         [[-0.1819]]],\n",
            "\n",
            "\n",
            "        [[[-0.0010]],\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.0941]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2434]],\n",
            "\n",
            "         [[ 0.0125]],\n",
            "\n",
            "         [[-0.1189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0066]],\n",
            "\n",
            "         [[-0.2216]],\n",
            "\n",
            "         [[-0.1217]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1188]],\n",
            "\n",
            "         [[ 0.2031]],\n",
            "\n",
            "         [[-0.1579]]]])), ('module.encoder_q.layer1.0.bn1.weight', tensor([0.9934, 0.9962, 0.9914, 0.9849, 0.9860, 0.9943, 0.9765, 0.9866, 0.9928,\n",
            "        0.9782, 1.0049, 0.9971, 0.9731, 1.0059, 0.9945, 0.9821, 1.0045, 0.9992,\n",
            "        1.0010, 0.9927, 1.0007, 0.9996, 1.0063, 1.0090, 0.9933, 0.9997, 0.9912,\n",
            "        0.9861, 0.9860, 0.9812, 0.9937, 0.9840, 0.9823, 0.9963, 1.0035, 0.9911,\n",
            "        0.9871, 0.9896, 0.9917, 0.9870, 0.9877, 0.9886, 0.9772, 0.9865, 0.9922,\n",
            "        0.9853, 0.9939, 0.9872, 0.9798, 0.9828, 0.9871, 0.9924, 0.9949, 1.0025,\n",
            "        1.0041, 1.0116, 1.0021, 0.9901, 1.0045, 0.9829, 1.0115, 0.9633, 1.0213,\n",
            "        0.9814])), ('module.encoder_q.layer1.0.bn1.bias', tensor([ 1.4657e-02,  1.2244e-02, -2.4451e-03, -1.1207e-02, -1.3364e-02,\n",
            "        -3.7309e-03,  4.0450e-03, -2.8230e-02, -1.3478e-02,  2.1503e-04,\n",
            "         2.6448e-02, -4.1154e-03, -3.4391e-02,  4.1506e-03,  8.5610e-03,\n",
            "         1.4167e-02,  1.1045e-02, -6.9096e-03,  8.7778e-03,  4.0279e-03,\n",
            "         1.1467e-02, -1.0129e-02,  1.3861e-02,  9.1119e-03,  9.2436e-03,\n",
            "         7.4864e-03,  1.4015e-02, -1.1298e-02,  6.0749e-03, -8.9109e-03,\n",
            "         4.4174e-03,  1.1000e-02, -1.1130e-02, -4.3631e-03, -1.5659e-03,\n",
            "        -1.1786e-02, -4.4488e-04,  7.8337e-03,  2.1891e-02, -4.0990e-03,\n",
            "        -8.4560e-03, -1.4088e-02, -8.7751e-03,  5.8306e-03,  9.8187e-03,\n",
            "        -1.2481e-03,  5.6539e-03,  2.9354e-03, -1.3768e-02,  2.5552e-03,\n",
            "        -6.9172e-03,  1.5677e-02,  2.2190e-02,  8.5960e-03,  1.1174e-02,\n",
            "         6.6690e-03,  6.1520e-03, -1.1681e-02, -2.8447e-05, -1.9968e-04,\n",
            "         1.6090e-02, -1.8913e-02,  9.1261e-03, -1.2387e-02])), ('module.encoder_q.layer1.0.bn1.running_mean', tensor([-0.3820,  0.1860,  0.6841,  0.2209,  0.1801, -0.5430, -0.0044,  1.2806,\n",
            "        -0.0596, -0.1698, -0.0847, -0.1360, -0.0889,  0.3782,  0.2436,  0.3515,\n",
            "        -0.5503, -0.7790,  0.0551, -0.0033, -0.2235, -0.1204,  0.0380,  1.5020,\n",
            "         0.1006,  0.3211, -0.1186,  0.5497, -1.7935,  0.5700,  0.0671, -0.1476,\n",
            "         0.1877, -0.4556, -0.0281,  0.9543, -0.5874,  0.5455, -0.7910, -0.0599,\n",
            "         0.3619,  0.0500,  0.3314, -0.1694, -1.0293, -1.3178,  0.2195, -0.4081,\n",
            "         0.4476,  0.1872,  0.1426, -1.2689, -1.0453,  0.0163, -0.3959,  0.0694,\n",
            "        -0.1335,  0.9782,  0.1190,  0.6086, -0.2986,  0.1166, -0.5120, -0.0791])), ('module.encoder_q.layer1.0.bn1.running_var', tensor([0.8546, 0.3549, 0.6255, 1.3106, 0.3858, 1.0303, 0.3448, 0.4617, 1.3481,\n",
            "        1.1144, 1.6074, 0.3575, 2.5002, 0.1497, 0.3895, 0.4055, 1.0757, 0.4986,\n",
            "        1.8460, 1.1602, 1.6911, 3.0490, 1.7561, 0.7087, 0.4329, 0.7142, 0.1877,\n",
            "        1.5593, 1.7893, 0.3383, 1.0241, 0.1897, 0.7743, 0.5874, 0.4275, 0.9016,\n",
            "        1.8303, 1.6138, 2.2091, 0.6005, 0.1703, 3.0934, 0.5556, 2.0175, 3.3989,\n",
            "        3.4800, 0.9362, 0.7048, 0.2819, 0.1732, 0.4542, 1.2042, 1.1093, 0.7806,\n",
            "        1.0356, 0.3374, 1.0825, 0.4724, 0.3569, 2.8580, 0.6099, 0.3632, 2.2469,\n",
            "        0.2919])), ('module.encoder_q.layer1.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.0.conv2.weight', tensor([[[[-0.0594, -0.0470, -0.0548],\n",
            "          [ 0.0557,  0.1136,  0.0788],\n",
            "          [-0.0897, -0.1933, -0.0500]],\n",
            "\n",
            "         [[ 0.0092, -0.0366,  0.0860],\n",
            "          [-0.0744, -0.0331,  0.0183],\n",
            "          [-0.0282, -0.0008, -0.0168]],\n",
            "\n",
            "         [[ 0.0239,  0.0186,  0.0970],\n",
            "          [ 0.0066,  0.0147,  0.1193],\n",
            "          [-0.0099,  0.0408, -0.0664]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0555,  0.0285,  0.0233],\n",
            "          [-0.1067,  0.0024,  0.0450],\n",
            "          [-0.0868, -0.0213,  0.0525]],\n",
            "\n",
            "         [[ 0.0133, -0.0568, -0.0164],\n",
            "          [-0.0220, -0.0569,  0.0449],\n",
            "          [ 0.0531,  0.0032, -0.0977]],\n",
            "\n",
            "         [[ 0.1388,  0.0783,  0.0848],\n",
            "          [ 0.0690,  0.0023, -0.0493],\n",
            "          [-0.0729,  0.0913,  0.0138]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0737,  0.0158,  0.0983],\n",
            "          [-0.0051, -0.0690, -0.0670],\n",
            "          [ 0.0497,  0.0455, -0.0034]],\n",
            "\n",
            "         [[-0.0164,  0.0226,  0.0612],\n",
            "          [ 0.0207,  0.0033, -0.0865],\n",
            "          [-0.0860,  0.0133,  0.0772]],\n",
            "\n",
            "         [[ 0.0236, -0.0289,  0.0427],\n",
            "          [ 0.0122, -0.0445,  0.0099],\n",
            "          [ 0.0606, -0.0442, -0.0363]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0132, -0.0722, -0.0521],\n",
            "          [ 0.0378,  0.0199,  0.0348],\n",
            "          [ 0.0004,  0.0598,  0.0019]],\n",
            "\n",
            "         [[ 0.0097,  0.0074,  0.0585],\n",
            "          [ 0.0034,  0.0619, -0.0182],\n",
            "          [-0.0650, -0.0081,  0.0714]],\n",
            "\n",
            "         [[-0.0136, -0.0035, -0.0094],\n",
            "          [ 0.0625, -0.0520, -0.0116],\n",
            "          [ 0.1065,  0.0526, -0.0428]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0353, -0.1440,  0.0437],\n",
            "          [-0.0497, -0.1624, -0.0542],\n",
            "          [ 0.0975, -0.0297,  0.0182]],\n",
            "\n",
            "         [[-0.0394, -0.0119, -0.0161],\n",
            "          [ 0.0819, -0.0012,  0.0802],\n",
            "          [ 0.0386,  0.1316,  0.0984]],\n",
            "\n",
            "         [[-0.0157, -0.0355, -0.0224],\n",
            "          [ 0.0342,  0.0134,  0.0174],\n",
            "          [-0.0724, -0.0983,  0.0552]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0163,  0.1310,  0.0197],\n",
            "          [ 0.0806,  0.0251,  0.0714],\n",
            "          [-0.0676,  0.0487,  0.0188]],\n",
            "\n",
            "         [[ 0.0427, -0.0135, -0.0189],\n",
            "          [-0.1022, -0.0824, -0.0083],\n",
            "          [ 0.0362, -0.0414, -0.0184]],\n",
            "\n",
            "         [[ 0.0732, -0.0789,  0.0802],\n",
            "          [ 0.0932, -0.0408, -0.0045],\n",
            "          [-0.0441, -0.0366,  0.0301]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0365,  0.0030, -0.0949],\n",
            "          [-0.0285, -0.0230,  0.0172],\n",
            "          [ 0.0207,  0.0436,  0.0590]],\n",
            "\n",
            "         [[ 0.0568, -0.0909,  0.0241],\n",
            "          [-0.0163, -0.0132,  0.0723],\n",
            "          [-0.0085,  0.0928, -0.0554]],\n",
            "\n",
            "         [[-0.0177,  0.0357,  0.0664],\n",
            "          [-0.0250, -0.0553, -0.0111],\n",
            "          [-0.0854,  0.0044,  0.0340]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0358,  0.0603,  0.0541],\n",
            "          [-0.1087,  0.0780, -0.0086],\n",
            "          [ 0.1534, -0.0563, -0.0414]],\n",
            "\n",
            "         [[ 0.0238, -0.0101,  0.1556],\n",
            "          [-0.0112, -0.0284, -0.1035],\n",
            "          [ 0.0748,  0.0317,  0.0258]],\n",
            "\n",
            "         [[-0.0412, -0.0042, -0.0415],\n",
            "          [ 0.0939, -0.0035, -0.0545],\n",
            "          [ 0.0538, -0.0678,  0.0013]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0931,  0.0082, -0.0295],\n",
            "          [-0.0273, -0.0486, -0.0268],\n",
            "          [ 0.0276, -0.0644, -0.0696]],\n",
            "\n",
            "         [[-0.0998, -0.0185, -0.0529],\n",
            "          [ 0.0035, -0.0329, -0.0198],\n",
            "          [ 0.0734, -0.0420, -0.0245]],\n",
            "\n",
            "         [[-0.0036, -0.0468, -0.0215],\n",
            "          [ 0.0070, -0.1150, -0.0297],\n",
            "          [ 0.0958, -0.0868, -0.0500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0499, -0.0443,  0.0330],\n",
            "          [-0.0471, -0.0355, -0.0083],\n",
            "          [ 0.0978,  0.0294,  0.0247]],\n",
            "\n",
            "         [[ 0.1801,  0.0741,  0.0400],\n",
            "          [-0.0658, -0.0125, -0.0096],\n",
            "          [-0.0264,  0.1640,  0.0517]],\n",
            "\n",
            "         [[ 0.0308,  0.0568, -0.0521],\n",
            "          [-0.0261,  0.0659,  0.1471],\n",
            "          [ 0.0308, -0.0462,  0.0510]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0676, -0.0746, -0.0267],\n",
            "          [-0.1132,  0.0624,  0.0988],\n",
            "          [-0.0090,  0.0692,  0.0621]],\n",
            "\n",
            "         [[ 0.0023,  0.0682, -0.0887],\n",
            "          [ 0.0179,  0.1075, -0.0432],\n",
            "          [-0.0438,  0.0373,  0.0172]],\n",
            "\n",
            "         [[ 0.0414,  0.1095, -0.1197],\n",
            "          [ 0.0007, -0.0177,  0.0614],\n",
            "          [ 0.0177,  0.0194,  0.0526]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0396, -0.0291,  0.0461],\n",
            "          [ 0.0970, -0.0023, -0.0286],\n",
            "          [-0.0066,  0.0349, -0.0203]],\n",
            "\n",
            "         [[-0.0384, -0.0361,  0.0162],\n",
            "          [ 0.0321, -0.0830, -0.0027],\n",
            "          [ 0.0976,  0.0074, -0.0022]],\n",
            "\n",
            "         [[-0.0687,  0.0450,  0.0241],\n",
            "          [ 0.0714,  0.0559, -0.0493],\n",
            "          [-0.0748,  0.0013, -0.0958]]]])), ('module.encoder_q.layer1.0.bn2.weight', tensor([1.0030, 0.9599, 0.9984, 0.9853, 0.9822, 0.9779, 0.9844, 1.0055, 0.9930,\n",
            "        0.9989, 0.9920, 1.0072, 1.0019, 0.9970, 0.9831, 0.9913, 1.0048, 0.9831,\n",
            "        1.0242, 0.9624, 0.9888, 0.9917, 0.9944, 1.0001, 0.9958, 0.9973, 1.0140,\n",
            "        1.0061, 0.9688, 0.9976, 0.9997, 0.9854, 1.0136, 1.0085, 0.9620, 0.9852,\n",
            "        0.9839, 0.9914, 0.9915, 0.9871, 0.9843, 0.9825, 0.9912, 0.9956, 0.9836,\n",
            "        1.0162, 0.9695, 0.9879, 0.9971, 0.9974, 1.0121, 1.0007, 0.9936, 0.9893,\n",
            "        0.9864, 0.9871, 0.9883, 0.9762, 0.9926, 0.9897, 1.0191, 0.9705, 1.0039,\n",
            "        0.9900])), ('module.encoder_q.layer1.0.bn2.bias', tensor([ 0.0147, -0.0272, -0.0004, -0.0001, -0.0054, -0.0013, -0.0025,  0.0077,\n",
            "        -0.0018, -0.0087, -0.0119,  0.0068,  0.0003,  0.0004, -0.0086, -0.0081,\n",
            "         0.0241, -0.0044,  0.0200, -0.0172,  0.0028,  0.0038,  0.0104,  0.0126,\n",
            "         0.0011,  0.0149,  0.0273,  0.0247, -0.0173,  0.0064, -0.0123, -0.0116,\n",
            "         0.0087, -0.0018, -0.0042, -0.0078,  0.0097,  0.0154,  0.0024, -0.0108,\n",
            "        -0.0117,  0.0019,  0.0099, -0.0118, -0.0036,  0.0052, -0.0089,  0.0031,\n",
            "        -0.0052,  0.0024,  0.0041,  0.0031,  0.0171,  0.0045, -0.0136, -0.0119,\n",
            "         0.0037, -0.0150,  0.0068,  0.0008,  0.0129, -0.0147,  0.0041, -0.0025])), ('module.encoder_q.layer1.0.bn2.running_mean', tensor([-1.1630,  0.6896,  0.3341,  0.3235,  0.7313, -0.6111,  0.1244,  0.3324,\n",
            "         0.2764, -0.3167, -0.1985, -0.6911, -0.2902,  1.3357,  1.0260,  0.2066,\n",
            "        -0.5523,  0.3937, -0.5466,  0.1312, -0.7807, -0.6429, -1.0527, -0.9573,\n",
            "        -1.2090,  0.6132, -0.4432, -0.7332, -1.2501,  0.0564, -0.2204, -0.0709,\n",
            "         1.2587,  0.9454, -0.6218,  0.9101,  0.1958, -0.4238, -0.2836, -0.3999,\n",
            "         0.5710,  0.7640, -0.9585,  0.4890, -1.1139,  0.1175, -0.7581, -0.2348,\n",
            "         0.0106, -1.1107,  1.0552,  0.0657, -0.4632,  0.1832, -0.0937, -0.6142,\n",
            "        -0.4477, -0.9649, -1.0503, -0.6398,  1.1081, -0.4858,  0.8937, -0.2675])), ('module.encoder_q.layer1.0.bn2.running_var', tensor([1.5815, 3.7665, 1.8059, 1.8544, 1.0319, 1.4035, 2.6276, 1.5568, 0.8578,\n",
            "        2.4729, 0.9787, 1.3945, 1.6202, 2.6772, 2.1840, 1.8526, 3.1352, 1.7340,\n",
            "        0.6024, 2.9369, 2.4030, 1.8182, 2.4338, 1.3203, 1.3568, 1.0137, 2.0060,\n",
            "        2.0475, 2.6339, 1.4206, 0.7527, 1.8266, 1.9151, 1.1361, 3.1319, 2.3844,\n",
            "        1.1384, 1.3475, 2.9214, 0.9568, 1.0589, 1.7969, 1.5132, 3.0159, 3.6709,\n",
            "        2.4374, 1.9292, 1.6386, 2.3823, 1.8301, 3.8107, 1.6739, 3.1897, 1.8696,\n",
            "        1.4286, 3.2151, 2.6342, 1.7595, 0.8579, 3.1478, 1.9501, 1.8528, 2.1586,\n",
            "        1.2402])), ('module.encoder_q.layer1.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.0.conv3.weight', tensor([[[[-0.0484]],\n",
            "\n",
            "         [[-0.1040]],\n",
            "\n",
            "         [[ 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0217]],\n",
            "\n",
            "         [[-0.0406]],\n",
            "\n",
            "         [[ 0.1314]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0079]],\n",
            "\n",
            "         [[ 0.0238]],\n",
            "\n",
            "         [[ 0.0531]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0555]],\n",
            "\n",
            "         [[ 0.0277]],\n",
            "\n",
            "         [[ 0.1721]]],\n",
            "\n",
            "\n",
            "        [[[-0.0997]],\n",
            "\n",
            "         [[ 0.0677]],\n",
            "\n",
            "         [[-0.0734]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1977]],\n",
            "\n",
            "         [[ 0.0330]],\n",
            "\n",
            "         [[-0.1586]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1391]],\n",
            "\n",
            "         [[-0.0322]],\n",
            "\n",
            "         [[ 0.2278]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0467]],\n",
            "\n",
            "         [[ 0.0665]],\n",
            "\n",
            "         [[-0.0644]]],\n",
            "\n",
            "\n",
            "        [[[-0.0413]],\n",
            "\n",
            "         [[ 0.0289]],\n",
            "\n",
            "         [[-0.0332]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0300]],\n",
            "\n",
            "         [[ 0.0808]],\n",
            "\n",
            "         [[-0.0322]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0377]],\n",
            "\n",
            "         [[-0.0134]],\n",
            "\n",
            "         [[ 0.0764]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0377]],\n",
            "\n",
            "         [[ 0.1338]],\n",
            "\n",
            "         [[-0.0084]]]])), ('module.encoder_q.layer1.0.bn3.weight', tensor([0.9990, 0.9931, 0.9877, 0.9931, 0.9948, 0.9928, 0.9817, 0.9874, 0.9925,\n",
            "        0.9831, 0.9890, 0.9981, 0.9902, 0.9920, 0.9914, 0.9831, 0.9976, 0.9891,\n",
            "        0.9952, 0.9810, 0.9953, 0.9895, 0.9872, 0.9825, 0.9902, 0.9925, 0.9823,\n",
            "        0.9931, 0.9923, 0.9897, 0.9821, 0.9925, 0.9941, 0.9990, 0.9869, 0.9871,\n",
            "        0.9855, 0.9857, 0.9939, 1.0093, 0.9964, 0.9841, 1.0003, 0.9900, 0.9842,\n",
            "        0.9954, 0.9930, 1.0036, 0.9856, 0.9885, 0.9872, 0.9934, 0.9890, 0.9946,\n",
            "        0.9926, 0.9971, 0.9940, 0.9991, 0.9926, 0.9847, 0.9968, 0.9880, 0.9887,\n",
            "        0.9909, 0.9865, 0.9952, 0.9955, 0.9944, 0.9971, 0.9970, 0.9840, 0.9968,\n",
            "        1.0004, 0.9861, 0.9935, 0.9927, 0.9799, 0.9956, 0.9977, 0.9928, 0.9936,\n",
            "        0.9828, 0.9956, 0.9757, 0.9858, 0.9935, 0.9914, 0.9965, 0.9954, 1.0046,\n",
            "        0.9878, 0.9960, 0.9984, 0.9989, 0.9953, 0.9923, 1.0009, 0.9962, 0.9892,\n",
            "        0.9877, 0.9879, 0.9888, 1.0020, 0.9935, 0.9981, 0.9906, 0.9974, 0.9907,\n",
            "        0.9922, 0.9893, 0.9902, 0.9870, 0.9840, 0.9878, 0.9906, 0.9924, 0.9924,\n",
            "        0.9926, 0.9942, 0.9893, 0.9970, 0.9888, 0.9859, 0.9885, 1.0036, 0.9879,\n",
            "        0.9916, 0.9931, 1.0036, 0.9924, 0.9916, 0.9991, 0.9858, 0.9971, 0.9840,\n",
            "        0.9919, 0.9800, 0.9865, 0.9899, 1.0033, 0.9999, 0.9955, 0.9966, 0.9984,\n",
            "        0.9993, 0.9908, 0.9909, 0.9894, 0.9894, 0.9924, 0.9911, 0.9996, 0.9942,\n",
            "        0.9895, 1.0024, 0.9983, 0.9873, 0.9913, 0.9978, 0.9867, 0.9957, 0.9865,\n",
            "        0.9907, 0.9876, 0.9868, 0.9854, 0.9935, 0.9830, 0.9870, 0.9925, 0.9949,\n",
            "        0.9896, 1.0073, 0.9962, 0.9852, 0.9894, 0.9959, 0.9841, 0.9917, 0.9924,\n",
            "        0.9900, 0.9921, 0.9963, 0.9952, 0.9874, 0.9870, 0.9934, 0.9918, 1.0001,\n",
            "        0.9873, 0.9904, 0.9918, 0.9866, 0.9942, 0.9846, 0.9973, 0.9919, 0.9928,\n",
            "        0.9922, 0.9930, 0.9886, 0.9979, 0.9993, 0.9908, 0.9877, 0.9806, 0.9928,\n",
            "        1.0001, 0.9897, 0.9953, 0.9904, 0.9908, 0.9870, 0.9888, 1.0007, 0.9859,\n",
            "        0.9949, 0.9968, 0.9932, 0.9857, 0.9801, 0.9872, 0.9837, 1.0007, 0.9904,\n",
            "        0.9900, 0.9943, 0.9943, 0.9926, 0.9992, 1.0041, 0.9879, 0.9889, 0.9922,\n",
            "        1.0008, 0.9988, 0.9999, 0.9906, 0.9901, 0.9810, 0.9848, 0.9833, 0.9877,\n",
            "        0.9989, 0.9947, 0.9855, 0.9875, 1.0027, 0.9949, 1.0046, 0.9847, 1.0043,\n",
            "        0.9913, 0.9891, 0.9892, 0.9960])), ('module.encoder_q.layer1.0.bn3.bias', tensor([ 8.6227e-03, -2.7140e-03,  2.5384e-03,  1.3338e-03, -3.2818e-04,\n",
            "         8.7486e-03, -3.7308e-03, -1.8414e-03, -1.8862e-03,  2.4124e-03,\n",
            "         5.7503e-03,  2.4880e-03, -7.3603e-04, -5.2277e-04, -6.7760e-03,\n",
            "        -2.7416e-03, -4.6006e-03, -1.1027e-02, -7.0389e-04, -4.1154e-03,\n",
            "        -4.4478e-03, -2.2306e-03, -3.2751e-03, -3.2983e-03, -1.4058e-03,\n",
            "        -1.6680e-03, -1.3341e-02,  1.1347e-03, -8.0313e-04, -2.9976e-03,\n",
            "        -3.7490e-03,  8.2885e-04,  7.7305e-04,  8.8088e-03, -7.0116e-03,\n",
            "        -3.0290e-03, -6.6308e-03,  1.2718e-03, -5.4755e-03,  9.3504e-03,\n",
            "        -4.3225e-03, -1.3734e-03,  1.7951e-03,  8.3190e-03,  2.1764e-03,\n",
            "        -5.6097e-03, -3.2597e-03,  7.2696e-03, -3.3622e-03, -7.5213e-03,\n",
            "        -6.1929e-03,  1.5029e-03,  3.5327e-03,  4.3142e-04,  7.3079e-03,\n",
            "         1.2144e-02,  2.0947e-03,  6.6673e-03, -3.2398e-04,  2.9148e-03,\n",
            "         1.2393e-03, -4.2061e-03,  8.5738e-04,  6.4526e-03, -8.8709e-04,\n",
            "         2.2648e-03, -4.5407e-03,  1.0078e-02,  1.9039e-03,  7.0735e-03,\n",
            "         1.9351e-03,  3.3120e-03, -1.6995e-03, -7.0153e-04,  8.7874e-03,\n",
            "         4.3645e-03, -6.5407e-03,  3.3273e-03,  8.2972e-03, -6.9670e-04,\n",
            "        -2.8651e-03, -5.6481e-03, -2.8334e-03, -4.9741e-03,  3.4810e-03,\n",
            "        -3.6003e-04,  3.0687e-04,  6.9920e-03, -5.9209e-03,  1.8539e-04,\n",
            "         4.3579e-03, -3.9734e-03, -5.2089e-03,  1.3670e-03, -2.6285e-03,\n",
            "         2.0609e-03,  2.2902e-03,  6.7735e-03, -4.7727e-03, -5.1855e-03,\n",
            "        -6.8455e-03,  1.1313e-03,  9.3697e-04,  3.1423e-03,  5.6140e-04,\n",
            "        -1.5957e-03, -8.6626e-04,  4.9673e-03,  2.3169e-03,  2.9324e-03,\n",
            "         2.1766e-04, -2.8062e-03, -7.7549e-03, -3.3911e-03,  1.1523e-02,\n",
            "         1.1624e-03, -2.3217e-03,  1.3158e-03,  4.3208e-03, -2.5040e-03,\n",
            "         4.4480e-03,  2.4644e-03, -3.5903e-03, -8.3735e-03, -1.8039e-03,\n",
            "        -2.1212e-03, -2.0788e-03,  1.1467e-02,  1.0365e-02, -5.0445e-03,\n",
            "        -6.9013e-03,  6.4914e-04, -5.8611e-03, -8.2549e-04, -2.4636e-03,\n",
            "         3.7357e-03, -1.0685e-02, -8.2340e-03, -5.5282e-04, -2.5002e-03,\n",
            "         2.9851e-03,  6.5800e-04, -2.3626e-04, -7.7786e-04,  1.0048e-02,\n",
            "         3.0663e-03, -2.1490e-03, -1.6667e-04, -6.3873e-03,  6.7017e-03,\n",
            "         6.7384e-03,  1.4942e-03, -1.7288e-03,  3.6313e-03,  1.9695e-03,\n",
            "        -2.1451e-03,  7.2730e-04, -6.6308e-04,  5.7725e-04, -3.1895e-03,\n",
            "        -4.1509e-04, -6.9110e-03, -8.7862e-03, -8.2827e-05,  4.6393e-03,\n",
            "         3.0917e-04,  8.6955e-04, -5.4358e-03,  2.0139e-03, -7.0118e-03,\n",
            "        -1.7102e-04,  2.3450e-03,  2.5933e-03, -7.0286e-04,  5.7788e-03,\n",
            "        -7.4792e-04,  3.6825e-03, -8.7056e-03,  4.6655e-03,  7.3054e-03,\n",
            "         2.9249e-03, -4.5421e-03,  1.0747e-02,  1.2664e-03,  1.3647e-03,\n",
            "         4.4815e-04,  6.9548e-04,  1.4464e-03,  5.0155e-03, -3.7713e-03,\n",
            "         1.4679e-04,  1.2160e-03, -9.5748e-04, -1.4346e-03,  3.0690e-03,\n",
            "         2.7680e-03, -5.0127e-03, -5.0190e-03,  1.8941e-04, -2.1062e-03,\n",
            "         3.1199e-03,  2.4000e-03,  3.7947e-03,  5.5063e-03,  2.0151e-04,\n",
            "         1.1935e-03, -4.6695e-03,  1.0615e-02,  9.5935e-03, -1.5149e-03,\n",
            "        -4.4948e-04,  4.6976e-03, -1.0782e-03, -2.4493e-03,  1.1219e-02,\n",
            "        -5.0145e-03, -8.5780e-03,  5.7367e-04,  3.3366e-03, -1.9210e-03,\n",
            "        -3.6628e-03, -1.9299e-03, -7.9222e-03,  4.8404e-03, -3.2186e-04,\n",
            "        -1.8664e-03,  6.9964e-03,  1.5416e-03, -2.4428e-03,  1.8777e-03,\n",
            "        -1.2778e-03,  3.2406e-03,  3.7909e-03,  2.4271e-03,  1.8056e-03,\n",
            "        -1.1706e-03,  5.0942e-03, -9.7473e-03,  5.2624e-03, -1.5650e-02,\n",
            "         3.2425e-03, -1.9666e-03, -8.4850e-03,  3.6614e-03, -7.7051e-03,\n",
            "        -6.9409e-03, -1.3486e-02,  5.8248e-03,  3.4140e-03,  1.4317e-02,\n",
            "        -1.0761e-02,  5.8738e-03,  5.4324e-03,  5.9221e-03,  5.6921e-03,\n",
            "        -4.9188e-03])), ('module.encoder_q.layer1.0.bn3.running_mean', tensor([-5.1874e-01,  8.1943e-01, -3.0183e-01, -6.2855e-01,  1.2575e-01,\n",
            "         4.9535e-02,  2.7487e-01,  5.3453e-01,  3.2997e-01, -1.6565e-01,\n",
            "        -4.0133e-02, -8.1017e-01,  4.4725e-01, -2.4146e-01,  4.1533e-01,\n",
            "        -2.7643e-01, -5.2562e-02,  3.5264e-02,  5.4433e-02,  3.0159e-01,\n",
            "        -4.0737e-01, -7.2828e-03,  2.5330e-01,  5.1609e-01,  1.6973e-01,\n",
            "         1.9116e-01, -1.0159e-01, -8.2253e-03,  1.5787e-01, -6.7988e-02,\n",
            "        -7.5527e-02, -1.1829e-02,  9.6355e-02, -4.8787e-01, -4.4089e-01,\n",
            "         2.3920e-01,  6.3685e-02,  2.4066e-01,  5.3445e-02, -1.4501e-01,\n",
            "        -1.1063e-01,  2.0692e-01, -1.3625e-01,  3.1523e-01,  5.5345e-02,\n",
            "        -2.6010e-01,  2.3351e-01, -1.3478e-01,  3.2302e-01,  2.4078e-02,\n",
            "         3.2182e-01,  8.2615e-02, -3.4674e-01, -5.9316e-01, -3.4709e-01,\n",
            "         2.5544e-01,  2.7713e-01,  1.2750e-01,  2.8664e-02,  4.3991e-01,\n",
            "         1.6061e-01,  7.2021e-01, -2.0044e-01, -3.7486e-01,  1.6426e-01,\n",
            "        -3.4677e-02, -7.4895e-02,  5.8106e-02,  1.7749e-02,  8.6182e-02,\n",
            "        -8.8294e-02,  1.8284e-01, -3.3453e-01,  2.1494e-02,  1.3847e-01,\n",
            "        -4.9598e-01,  1.8929e-02, -2.4556e-01,  2.7157e-01, -3.3334e-01,\n",
            "        -3.1760e-01,  1.5882e-01,  6.1537e-01,  8.5678e-02,  1.2286e-01,\n",
            "         7.2626e-02,  5.1478e-02,  3.6611e-01,  8.0257e-02, -3.7652e-01,\n",
            "         2.1632e-01,  4.1713e-02,  5.5332e-01, -5.5461e-01,  2.2217e-01,\n",
            "        -5.3946e-01, -4.4441e-01,  1.6476e-01, -2.8946e-01, -6.6906e-02,\n",
            "         8.8166e-02,  4.1940e-01,  2.9218e-01, -6.9097e-02,  1.4941e-01,\n",
            "         3.3014e-01, -1.6693e-01,  1.5284e-01, -2.7271e-01,  3.2403e-01,\n",
            "         9.9248e-02, -4.9229e-02, -3.8574e-01,  2.6707e-02, -5.1088e-01,\n",
            "         3.5820e-01, -3.7628e-01,  1.4314e-01,  2.6913e-01,  5.0258e-01,\n",
            "        -2.9907e-01,  2.6303e-01,  9.8401e-02,  5.1556e-01,  8.2506e-02,\n",
            "        -1.7741e-01,  3.7338e-01,  2.6943e-02, -1.6206e-01,  1.5773e-01,\n",
            "         3.1276e-01, -1.6169e-01,  9.5298e-02, -2.8821e-02,  2.1273e-01,\n",
            "        -1.2359e-01,  2.1732e-01,  3.1738e-03, -2.7230e-02,  1.2510e-01,\n",
            "         1.6401e-02, -4.3032e-01, -6.3540e-02,  1.9408e-01, -2.9678e-01,\n",
            "         8.7550e-02,  1.7922e-01, -2.6886e-01, -1.6918e-01, -1.2813e-02,\n",
            "         2.7115e-01, -5.5918e-01,  2.6726e-01, -1.3985e-01,  5.5989e-02,\n",
            "         5.8364e-01, -2.0509e-02,  4.8668e-01, -3.1195e-01, -1.7416e-01,\n",
            "        -3.6254e-01,  3.7941e-02,  4.1041e-01,  1.4472e-01,  4.9978e-01,\n",
            "        -1.0943e-01,  3.8328e-01, -1.0146e-01,  4.1274e-01,  1.5369e-01,\n",
            "        -5.7966e-02,  2.3161e-01, -3.8155e-01, -1.2713e-01, -5.1330e-01,\n",
            "        -2.3918e-01, -4.6569e-01, -2.1809e-01,  5.2089e-01, -1.3545e-01,\n",
            "        -4.0172e-01,  3.0609e-01, -9.0102e-02, -2.9085e-02, -2.2478e-01,\n",
            "         4.1486e-02,  3.3047e-01,  5.2454e-02, -3.0784e-02,  2.3218e-01,\n",
            "         1.7553e-01,  3.0669e-01,  2.9450e-04, -2.9670e-01,  9.8140e-02,\n",
            "        -2.2125e-01, -1.0477e-01,  8.8229e-02,  2.4406e-01,  1.0066e-01,\n",
            "         3.6547e-01, -1.9880e-01,  1.2136e-01, -5.1244e-01, -9.5901e-02,\n",
            "         5.2848e-01,  7.6300e-02,  2.8843e-01, -9.7553e-02, -1.5244e-01,\n",
            "        -2.8614e-03,  3.1809e-01,  5.6726e-02, -2.5488e-02, -3.6382e-01,\n",
            "        -1.7997e-01, -8.0845e-02,  5.9017e-02,  1.3411e-01, -2.4036e-01,\n",
            "         6.2869e-02, -1.3048e-01, -4.8988e-01,  8.4908e-02,  1.1049e-02,\n",
            "         3.7775e-02, -2.9241e-01, -5.7092e-02,  2.1508e-01,  3.5190e-01,\n",
            "         1.8594e-01,  9.7209e-02,  3.6272e-01, -8.6706e-02, -4.7394e-01,\n",
            "        -1.9231e-01, -4.5150e-01, -2.5573e-02, -1.3529e-01,  2.8796e-01,\n",
            "         1.7890e-01,  1.7676e-01, -2.5001e-01, -2.7757e-01,  7.5682e-03,\n",
            "        -1.2796e-01,  1.0054e-01,  2.9158e-02, -8.4018e-03, -2.8039e-01,\n",
            "         4.4682e-01, -3.3726e-01, -3.6740e-01,  6.7324e-01, -2.7185e-01,\n",
            "        -1.9491e-02])), ('module.encoder_q.layer1.0.bn3.running_var', tensor([0.1709, 0.3275, 0.1861, 0.1761, 0.3406, 0.1728, 0.4636, 0.1683, 0.2428,\n",
            "        0.1975, 0.2175, 0.0838, 0.2655, 0.1545, 0.1710, 0.2923, 0.1021, 0.1638,\n",
            "        0.1532, 0.2053, 0.2159, 0.3630, 0.3955, 0.2127, 0.1038, 0.1483, 0.1168,\n",
            "        0.0986, 0.1589, 0.2543, 0.2486, 0.0513, 0.1649, 0.2137, 0.4300, 0.1583,\n",
            "        0.1399, 0.2332, 0.2535, 0.2869, 0.0729, 0.1527, 0.1075, 0.1640, 0.3702,\n",
            "        0.0997, 0.1242, 0.2577, 0.2623, 0.1706, 0.1676, 0.1089, 0.2114, 0.2298,\n",
            "        0.1187, 0.2176, 0.1707, 0.2342, 0.1712, 0.2200, 0.1668, 0.1138, 0.3616,\n",
            "        0.2219, 0.0983, 0.0768, 0.5280, 0.1020, 0.1290, 0.3666, 0.1306, 0.1639,\n",
            "        0.1719, 0.1879, 0.1418, 0.3404, 0.1300, 0.1126, 0.0960, 0.5374, 0.1472,\n",
            "        0.1633, 0.2904, 0.1314, 0.2715, 0.0828, 0.1417, 0.4652, 0.2093, 0.4141,\n",
            "        0.2604, 0.1437, 0.1336, 0.1628, 0.0672, 0.3716, 0.1247, 0.2373, 0.1098,\n",
            "        0.2279, 0.3316, 0.1592, 0.2040, 0.1795, 0.1581, 0.1463, 0.1885, 0.3741,\n",
            "        0.4857, 0.2746, 0.1785, 0.2758, 0.0972, 0.0671, 0.4827, 0.1750, 0.1885,\n",
            "        0.6965, 0.2077, 0.2843, 0.2106, 0.1641, 0.2806, 0.1312, 0.2801, 0.2637,\n",
            "        0.1845, 0.1302, 0.2221, 0.3172, 0.2428, 0.1260, 0.1533, 0.1801, 0.3417,\n",
            "        0.2003, 0.3110, 0.1091, 0.0805, 0.1364, 0.3868, 0.1575, 0.1530, 0.2928,\n",
            "        0.1259, 0.1424, 0.2687, 0.1328, 0.2368, 0.1836, 0.2003, 0.1557, 0.2130,\n",
            "        0.2912, 0.1074, 0.4022, 0.0660, 0.1821, 0.3666, 0.0515, 0.1645, 0.1082,\n",
            "        0.3263, 0.0772, 0.1020, 0.0963, 0.2418, 0.0781, 0.0993, 0.0540, 0.0832,\n",
            "        0.2483, 0.1528, 0.2948, 0.1913, 0.1550, 0.2411, 0.2208, 0.1725, 0.1442,\n",
            "        0.1991, 0.8456, 0.3893, 0.0900, 0.1505, 0.2409, 0.2339, 0.1083, 0.2452,\n",
            "        0.1921, 0.1127, 0.1693, 0.2245, 0.2784, 0.1100, 0.1203, 0.1547, 0.1259,\n",
            "        0.4521, 0.3052, 0.1335, 0.1748, 0.0770, 0.1762, 0.1789, 0.1802, 0.2397,\n",
            "        0.1843, 0.2745, 0.2304, 0.1136, 0.2233, 0.1243, 0.1110, 0.1265, 0.1839,\n",
            "        0.2098, 0.1315, 0.1128, 0.3298, 0.4349, 0.1219, 0.2148, 0.1651, 0.1496,\n",
            "        0.1866, 0.0947, 0.1643, 0.1109, 0.1609, 0.1665, 0.5081, 0.3835, 0.1712,\n",
            "        0.2628, 0.1124, 0.1617, 0.3174, 0.2566, 0.1199, 0.1131, 0.2189, 0.1693,\n",
            "        0.1610, 0.1474, 0.1731, 0.1683, 0.5031, 0.1864, 0.2254, 0.1614, 0.2447,\n",
            "        0.5691, 0.6162, 0.2341, 0.1455])), ('module.encoder_q.layer1.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.0.downsample.0.weight', tensor([[[[-0.0025]],\n",
            "\n",
            "         [[-0.0413]],\n",
            "\n",
            "         [[ 0.0738]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1411]],\n",
            "\n",
            "         [[ 0.0162]],\n",
            "\n",
            "         [[-0.0549]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0469]],\n",
            "\n",
            "         [[-0.1543]],\n",
            "\n",
            "         [[ 0.0446]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0911]],\n",
            "\n",
            "         [[-0.0374]],\n",
            "\n",
            "         [[ 0.0059]]],\n",
            "\n",
            "\n",
            "        [[[-0.0768]],\n",
            "\n",
            "         [[ 0.0681]],\n",
            "\n",
            "         [[-0.0339]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0375]],\n",
            "\n",
            "         [[ 0.1456]],\n",
            "\n",
            "         [[ 0.0842]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0250]],\n",
            "\n",
            "         [[ 0.1035]],\n",
            "\n",
            "         [[ 0.0388]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0886]],\n",
            "\n",
            "         [[ 0.0058]],\n",
            "\n",
            "         [[-0.0758]]],\n",
            "\n",
            "\n",
            "        [[[-0.0147]],\n",
            "\n",
            "         [[-0.0110]],\n",
            "\n",
            "         [[-0.1190]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0222]],\n",
            "\n",
            "         [[-0.0776]],\n",
            "\n",
            "         [[-0.0342]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0631]],\n",
            "\n",
            "         [[ 0.0631]],\n",
            "\n",
            "         [[-0.1262]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0908]],\n",
            "\n",
            "         [[ 0.0722]],\n",
            "\n",
            "         [[ 0.2299]]]])), ('module.encoder_q.layer1.0.downsample.1.weight', tensor([0.9876, 0.9986, 0.9966, 0.9941, 0.9908, 1.0046, 0.9975, 0.9924, 0.9897,\n",
            "        0.9920, 0.9910, 0.9993, 0.9991, 0.9961, 0.9918, 0.9911, 0.9891, 0.9892,\n",
            "        0.9967, 0.9999, 0.9889, 0.9884, 0.9919, 0.9931, 0.9983, 0.9872, 0.9792,\n",
            "        0.9962, 0.9914, 0.9871, 0.9885, 0.9844, 0.9895, 0.9911, 0.9897, 0.9942,\n",
            "        0.9883, 0.9922, 0.9867, 0.9956, 0.9923, 1.0071, 0.9930, 0.9967, 0.9937,\n",
            "        0.9839, 0.9858, 1.0003, 0.9953, 0.9807, 0.9876, 0.9915, 1.0010, 0.9936,\n",
            "        0.9938, 0.9966, 0.9920, 0.9912, 0.9969, 1.0043, 0.9800, 0.9933, 0.9946,\n",
            "        0.9917, 0.9976, 0.9833, 0.9912, 0.9966, 0.9923, 0.9893, 1.0007, 0.9962,\n",
            "        1.0039, 0.9827, 0.9961, 0.9896, 0.9952, 0.9985, 0.9908, 0.9829, 0.9846,\n",
            "        0.9909, 0.9838, 0.9916, 0.9985, 0.9952, 0.9857, 0.9943, 0.9854, 0.9843,\n",
            "        0.9957, 0.9879, 0.9845, 0.9967, 0.9897, 0.9940, 0.9962, 0.9908, 0.9953,\n",
            "        0.9882, 0.9891, 0.9960, 0.9920, 0.9948, 0.9927, 0.9890, 0.9910, 0.9942,\n",
            "        0.9909, 1.0005, 0.9940, 0.9946, 0.9857, 0.9950, 1.0031, 0.9962, 0.9853,\n",
            "        1.0025, 0.9935, 0.9887, 0.9930, 0.9895, 0.9952, 0.9867, 0.9903, 0.9961,\n",
            "        0.9899, 0.9988, 0.9950, 0.9916, 0.9910, 0.9891, 0.9931, 0.9870, 0.9939,\n",
            "        0.9960, 0.9844, 0.9902, 0.9893, 0.9853, 0.9785, 0.9999, 0.9937, 0.9960,\n",
            "        1.0001, 0.9868, 0.9916, 0.9894, 0.9911, 0.9920, 0.9938, 0.9906, 0.9930,\n",
            "        1.0007, 0.9875, 0.9825, 0.9915, 0.9930, 0.9894, 0.9940, 1.0003, 0.9879,\n",
            "        0.9844, 0.9906, 1.0011, 0.9941, 0.9898, 0.9997, 0.9948, 0.9825, 0.9963,\n",
            "        0.9922, 0.9844, 0.9845, 1.0019, 0.9919, 0.9897, 0.9954, 1.0001, 0.9994,\n",
            "        1.0042, 0.9969, 0.9943, 0.9954, 0.9970, 0.9896, 0.9885, 0.9990, 0.9860,\n",
            "        0.9962, 0.9792, 0.9911, 0.9928, 0.9928, 0.9976, 0.9900, 0.9862, 0.9870,\n",
            "        0.9886, 0.9859, 0.9928, 1.0016, 0.9984, 1.0014, 0.9972, 0.9946, 0.9819,\n",
            "        1.0068, 0.9914, 0.9933, 0.9980, 1.0032, 0.9964, 0.9877, 0.9957, 0.9906,\n",
            "        0.9804, 0.9995, 0.9920, 0.9909, 0.9935, 0.9834, 0.9907, 0.9921, 0.9913,\n",
            "        0.9920, 0.9992, 0.9935, 0.9885, 0.9944, 0.9990, 0.9932, 0.9978, 0.9998,\n",
            "        0.9910, 0.9894, 1.0009, 0.9808, 0.9938, 0.9839, 0.9983, 0.9978, 0.9888,\n",
            "        0.9917, 0.9891, 0.9940, 0.9872, 0.9882, 0.9947, 0.9989, 0.9828, 1.0037,\n",
            "        1.0050, 0.9945, 0.9904, 0.9900])), ('module.encoder_q.layer1.0.downsample.1.bias', tensor([ 8.6227e-03, -2.7140e-03,  2.5384e-03,  1.3338e-03, -3.2818e-04,\n",
            "         8.7486e-03, -3.7308e-03, -1.8414e-03, -1.8862e-03,  2.4124e-03,\n",
            "         5.7503e-03,  2.4880e-03, -7.3603e-04, -5.2277e-04, -6.7760e-03,\n",
            "        -2.7416e-03, -4.6006e-03, -1.1027e-02, -7.0389e-04, -4.1154e-03,\n",
            "        -4.4478e-03, -2.2306e-03, -3.2751e-03, -3.2983e-03, -1.4058e-03,\n",
            "        -1.6680e-03, -1.3341e-02,  1.1347e-03, -8.0313e-04, -2.9976e-03,\n",
            "        -3.7490e-03,  8.2885e-04,  7.7305e-04,  8.8088e-03, -7.0116e-03,\n",
            "        -3.0290e-03, -6.6308e-03,  1.2718e-03, -5.4755e-03,  9.3504e-03,\n",
            "        -4.3225e-03, -1.3734e-03,  1.7951e-03,  8.3190e-03,  2.1764e-03,\n",
            "        -5.6097e-03, -3.2597e-03,  7.2696e-03, -3.3622e-03, -7.5213e-03,\n",
            "        -6.1929e-03,  1.5029e-03,  3.5327e-03,  4.3142e-04,  7.3079e-03,\n",
            "         1.2144e-02,  2.0947e-03,  6.6673e-03, -3.2398e-04,  2.9148e-03,\n",
            "         1.2393e-03, -4.2061e-03,  8.5738e-04,  6.4526e-03, -8.8709e-04,\n",
            "         2.2648e-03, -4.5407e-03,  1.0078e-02,  1.9039e-03,  7.0735e-03,\n",
            "         1.9351e-03,  3.3120e-03, -1.6995e-03, -7.0153e-04,  8.7874e-03,\n",
            "         4.3645e-03, -6.5407e-03,  3.3273e-03,  8.2972e-03, -6.9670e-04,\n",
            "        -2.8651e-03, -5.6481e-03, -2.8334e-03, -4.9741e-03,  3.4810e-03,\n",
            "        -3.6003e-04,  3.0687e-04,  6.9920e-03, -5.9209e-03,  1.8539e-04,\n",
            "         4.3579e-03, -3.9734e-03, -5.2089e-03,  1.3670e-03, -2.6285e-03,\n",
            "         2.0609e-03,  2.2902e-03,  6.7735e-03, -4.7727e-03, -5.1855e-03,\n",
            "        -6.8455e-03,  1.1313e-03,  9.3697e-04,  3.1423e-03,  5.6140e-04,\n",
            "        -1.5957e-03, -8.6626e-04,  4.9673e-03,  2.3169e-03,  2.9324e-03,\n",
            "         2.1766e-04, -2.8062e-03, -7.7549e-03, -3.3911e-03,  1.1523e-02,\n",
            "         1.1624e-03, -2.3217e-03,  1.3158e-03,  4.3208e-03, -2.5040e-03,\n",
            "         4.4480e-03,  2.4644e-03, -3.5903e-03, -8.3735e-03, -1.8039e-03,\n",
            "        -2.1212e-03, -2.0788e-03,  1.1467e-02,  1.0365e-02, -5.0445e-03,\n",
            "        -6.9013e-03,  6.4914e-04, -5.8611e-03, -8.2549e-04, -2.4636e-03,\n",
            "         3.7357e-03, -1.0685e-02, -8.2340e-03, -5.5282e-04, -2.5002e-03,\n",
            "         2.9851e-03,  6.5800e-04, -2.3626e-04, -7.7786e-04,  1.0048e-02,\n",
            "         3.0663e-03, -2.1490e-03, -1.6667e-04, -6.3873e-03,  6.7017e-03,\n",
            "         6.7384e-03,  1.4942e-03, -1.7288e-03,  3.6313e-03,  1.9695e-03,\n",
            "        -2.1451e-03,  7.2730e-04, -6.6308e-04,  5.7725e-04, -3.1895e-03,\n",
            "        -4.1509e-04, -6.9110e-03, -8.7862e-03, -8.2827e-05,  4.6393e-03,\n",
            "         3.0917e-04,  8.6955e-04, -5.4358e-03,  2.0139e-03, -7.0118e-03,\n",
            "        -1.7102e-04,  2.3450e-03,  2.5933e-03, -7.0286e-04,  5.7788e-03,\n",
            "        -7.4792e-04,  3.6825e-03, -8.7056e-03,  4.6655e-03,  7.3054e-03,\n",
            "         2.9249e-03, -4.5421e-03,  1.0747e-02,  1.2664e-03,  1.3647e-03,\n",
            "         4.4815e-04,  6.9548e-04,  1.4464e-03,  5.0155e-03, -3.7713e-03,\n",
            "         1.4679e-04,  1.2160e-03, -9.5748e-04, -1.4346e-03,  3.0690e-03,\n",
            "         2.7680e-03, -5.0127e-03, -5.0190e-03,  1.8941e-04, -2.1062e-03,\n",
            "         3.1199e-03,  2.4000e-03,  3.7947e-03,  5.5063e-03,  2.0151e-04,\n",
            "         1.1935e-03, -4.6695e-03,  1.0615e-02,  9.5935e-03, -1.5149e-03,\n",
            "        -4.4948e-04,  4.6976e-03, -1.0782e-03, -2.4493e-03,  1.1219e-02,\n",
            "        -5.0145e-03, -8.5780e-03,  5.7367e-04,  3.3366e-03, -1.9210e-03,\n",
            "        -3.6628e-03, -1.9299e-03, -7.9222e-03,  4.8404e-03, -3.2186e-04,\n",
            "        -1.8664e-03,  6.9964e-03,  1.5416e-03, -2.4428e-03,  1.8777e-03,\n",
            "        -1.2778e-03,  3.2406e-03,  3.7909e-03,  2.4271e-03,  1.8056e-03,\n",
            "        -1.1706e-03,  5.0942e-03, -9.7473e-03,  5.2624e-03, -1.5650e-02,\n",
            "         3.2425e-03, -1.9666e-03, -8.4850e-03,  3.6614e-03, -7.7051e-03,\n",
            "        -6.9409e-03, -1.3486e-02,  5.8248e-03,  3.4140e-03,  1.4317e-02,\n",
            "        -1.0761e-02,  5.8738e-03,  5.4324e-03,  5.9221e-03,  5.6921e-03,\n",
            "        -4.9188e-03])), ('module.encoder_q.layer1.0.downsample.1.running_mean', tensor([ 0.3363,  0.1276,  0.1894,  0.1049,  0.4372,  0.1908, -0.4285, -0.1303,\n",
            "         0.3528,  0.4721, -0.5995, -0.5257,  0.3469,  0.1588,  0.2097, -0.6547,\n",
            "         0.1425,  0.1417,  0.1898, -0.5917, -0.0394,  0.2119,  0.0735,  0.2252,\n",
            "         0.5775, -0.2008,  0.0608,  0.3352, -0.1993,  0.0068, -0.0430,  0.5193,\n",
            "         0.4265, -0.3810,  0.6560, -0.2584, -0.3047, -0.3256,  0.2253, -0.1405,\n",
            "         0.6603, -0.1212,  0.0112,  0.2585, -0.2485, -0.2700,  0.2792, -0.0446,\n",
            "         0.1271, -0.1674, -0.6785, -0.3670,  0.9447, -0.6381,  0.2334,  0.0696,\n",
            "         0.4093,  0.2255,  0.3903, -0.0403, -0.1004, -0.0247,  0.2150, -0.1271,\n",
            "        -0.2364,  1.1612,  0.1862, -0.1555,  0.2728, -0.0415, -0.0895, -0.5842,\n",
            "        -0.1472, -0.1609,  0.2780,  0.1250,  0.2662,  0.1948, -0.0464,  0.1202,\n",
            "        -0.1962,  0.0125, -0.4490, -0.5330, -0.2731, -0.2177, -0.1686,  0.0433,\n",
            "        -0.3242, -0.1276, -0.1051,  0.5431, -0.5298, -0.3845, -0.2917,  0.1471,\n",
            "        -0.1871, -0.0960,  0.8228,  0.4025, -0.0397, -0.4028, -0.4709,  0.0466,\n",
            "        -0.3256, -0.5684,  0.0741, -0.1220,  0.0321, -0.1899,  0.1893,  0.0572,\n",
            "        -0.2410, -0.1137,  0.3849,  0.1456, -0.0972, -0.3738,  0.8264,  0.1820,\n",
            "         0.0078, -0.2396, -0.3916, -0.0351,  0.3662,  0.3234,  0.5548, -0.1912,\n",
            "        -0.0216, -0.0287, -0.2246,  0.2897,  0.1749,  0.0156, -0.2617, -0.1337,\n",
            "         0.0489, -0.5239, -0.3307, -0.1099,  0.1180,  0.0784, -0.3486,  0.0064,\n",
            "         0.0329,  0.5807,  0.1391, -0.1877, -0.5235, -0.5281, -0.4758, -0.0658,\n",
            "         0.4109, -0.6052,  0.5648, -0.6764, -0.3525, -0.0247, -0.1392,  0.4956,\n",
            "        -0.2115,  0.2094, -0.2779, -0.5671,  0.2364,  0.2315,  0.2598,  0.2700,\n",
            "        -0.2561, -0.0750, -0.0252, -0.8105,  0.5210,  0.1236, -0.1385,  0.1247,\n",
            "        -0.2172,  0.7152,  0.1308,  0.1517, -0.5624,  0.3844, -0.3542,  0.2654,\n",
            "         0.1949, -0.2893, -0.3397,  0.1596, -0.0800,  0.2171,  0.4427, -0.1763,\n",
            "         0.2511,  0.4967, -0.0315,  0.1521,  0.2857, -0.2445, -0.2907, -0.2761,\n",
            "        -0.1304,  0.1216, -0.2819,  0.1907, -0.0958,  0.0044, -0.1740, -0.2053,\n",
            "        -0.6718, -0.1198, -0.3901,  0.4439, -0.1843, -0.6304, -0.4541, -0.1296,\n",
            "        -0.2952,  0.0792, -0.0753,  0.2253, -0.0784,  0.0716, -0.0251,  0.1886,\n",
            "         0.3042,  0.5245, -0.4015, -0.3667, -0.0230, -0.2369,  0.7593,  0.4082,\n",
            "         0.2099,  0.1249,  0.3191,  0.0224,  0.0761,  0.0205, -0.5194,  0.5810,\n",
            "        -0.3385, -0.1796,  0.2838,  0.3932, -0.4279, -0.1881, -0.2153,  0.5316,\n",
            "        -0.4120, -0.3842, -0.7291,  0.2845, -0.0395, -0.3962, -0.4015,  0.7448])), ('module.encoder_q.layer1.0.downsample.1.running_var', tensor([0.2504, 0.2216, 0.1808, 0.1382, 0.3129, 0.1977, 0.0859, 0.0682, 0.3360,\n",
            "        0.0958, 0.2220, 0.1226, 0.2362, 0.1683, 0.1883, 0.2479, 0.0776, 0.1005,\n",
            "        0.1002, 0.1063, 0.1852, 0.1159, 0.1193, 0.0900, 0.0962, 0.3029, 0.1401,\n",
            "        0.7571, 0.3693, 0.8339, 0.1430, 0.1917, 0.1576, 0.2928, 0.5823, 0.1299,\n",
            "        0.3279, 0.0789, 0.1543, 0.1255, 0.3310, 0.0985, 0.1074, 0.4793, 0.0927,\n",
            "        0.0955, 0.1288, 0.1359, 0.3871, 0.4103, 0.1458, 0.4070, 0.4237, 0.2508,\n",
            "        0.4327, 0.0679, 0.1603, 0.1464, 0.3414, 0.0806, 0.2621, 0.4190, 0.7314,\n",
            "        0.1322, 0.1623, 0.4294, 0.2822, 0.1785, 0.0457, 0.0520, 0.3342, 0.2430,\n",
            "        0.1561, 0.2125, 0.1833, 0.1575, 0.1364, 0.2851, 0.3841, 0.0963, 0.1993,\n",
            "        0.1147, 0.2252, 0.2161, 0.1005, 0.0845, 0.1167, 0.4076, 0.1962, 0.4106,\n",
            "        0.0731, 0.2223, 0.3113, 0.0891, 0.3471, 0.0822, 0.2059, 0.0821, 0.2157,\n",
            "        0.1723, 0.2691, 0.5670, 0.3936, 0.0453, 0.2419, 0.2470, 0.1542, 0.0955,\n",
            "        0.2869, 0.2301, 0.1574, 0.2886, 0.0939, 0.1419, 0.1343, 0.4260, 0.1494,\n",
            "        0.2614, 0.1622, 0.2390, 0.2840, 0.1759, 0.1903, 0.0300, 0.0447, 0.5043,\n",
            "        0.1536, 0.2245, 0.0502, 0.1910, 0.0746, 0.5052, 0.1512, 0.4005, 0.1323,\n",
            "        0.3679, 0.2470, 0.4227, 0.1595, 0.6179, 0.1747, 0.2548, 0.2344, 0.0678,\n",
            "        0.3801, 0.2688, 0.1344, 0.2137, 0.1718, 0.2096, 0.1908, 0.0512, 0.4977,\n",
            "        0.1515, 0.1973, 0.2277, 0.2635, 0.1399, 0.0454, 0.1462, 0.0775, 0.8256,\n",
            "        0.1878, 0.1760, 0.2927, 0.1270, 0.8101, 0.1507, 0.1466, 0.1723, 0.1393,\n",
            "        0.5846, 0.1557, 0.0684, 0.1069, 0.4934, 0.0745, 0.2448, 0.0882, 0.1299,\n",
            "        0.1472, 0.3792, 0.3643, 0.0420, 0.0951, 0.2643, 0.5649, 0.1043, 0.2568,\n",
            "        0.3119, 0.0858, 0.1659, 0.2408, 0.2730, 0.3058, 0.2457, 0.1075, 0.1977,\n",
            "        0.1386, 0.0758, 0.2319, 0.0556, 0.2582, 0.0794, 0.1553, 0.2665, 0.0965,\n",
            "        0.0833, 0.1573, 0.2255, 0.2578, 0.2205, 0.2946, 0.1350, 0.1512, 0.1650,\n",
            "        0.1795, 0.1519, 0.1910, 0.1516, 0.1895, 0.0891, 0.2168, 0.0736, 0.0489,\n",
            "        0.5509, 0.1815, 0.2030, 0.1389, 0.2273, 0.2986, 0.1930, 0.5465, 0.1541,\n",
            "        0.1451, 0.0814, 0.0789, 0.2797, 0.1237, 0.0929, 0.1645, 0.4837, 0.1865,\n",
            "        0.2702, 0.1155, 0.3415, 0.2457, 0.2606, 0.3445, 0.0909, 0.3070, 0.8551,\n",
            "        0.0576, 0.1305, 0.0852, 0.1376])), ('module.encoder_q.layer1.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.1.conv1.weight', tensor([[[[ 0.0892]],\n",
            "\n",
            "         [[ 0.0927]],\n",
            "\n",
            "         [[ 0.1448]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0110]],\n",
            "\n",
            "         [[ 0.1206]],\n",
            "\n",
            "         [[ 0.0382]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0797]],\n",
            "\n",
            "         [[-0.0839]],\n",
            "\n",
            "         [[ 0.1625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0974]],\n",
            "\n",
            "         [[-0.0933]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1500]],\n",
            "\n",
            "         [[ 0.0418]],\n",
            "\n",
            "         [[ 0.3206]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0799]],\n",
            "\n",
            "         [[ 0.1226]],\n",
            "\n",
            "         [[-0.0689]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0024]],\n",
            "\n",
            "         [[-0.0387]],\n",
            "\n",
            "         [[ 0.0733]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0016]],\n",
            "\n",
            "         [[-0.0555]],\n",
            "\n",
            "         [[-0.0707]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1315]],\n",
            "\n",
            "         [[-0.2056]],\n",
            "\n",
            "         [[-0.0408]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1446]],\n",
            "\n",
            "         [[ 0.2296]],\n",
            "\n",
            "         [[-0.0963]]],\n",
            "\n",
            "\n",
            "        [[[-0.0520]],\n",
            "\n",
            "         [[-0.0609]],\n",
            "\n",
            "         [[ 0.0591]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0519]],\n",
            "\n",
            "         [[-0.3131]],\n",
            "\n",
            "         [[ 0.0052]]]])), ('module.encoder_q.layer1.1.bn1.weight', tensor([0.9995, 0.9772, 0.9894, 0.9884, 0.9888, 0.9845, 1.0052, 1.0099, 0.9887,\n",
            "        0.9859, 0.9892, 0.9940, 0.9992, 0.9826, 1.0033, 0.9891, 0.9976, 0.9945,\n",
            "        1.0050, 0.9800, 1.0078, 0.9934, 1.0070, 1.0060, 0.9792, 1.0222, 0.9890,\n",
            "        1.0004, 0.9835, 0.9877, 0.9844, 0.9957, 1.0030, 1.0054, 0.9859, 0.9806,\n",
            "        1.0018, 0.9913, 0.9909, 0.9835, 0.9951, 0.9912, 0.9873, 0.9914, 0.9689,\n",
            "        0.9906, 0.9998, 0.9925, 1.0006, 0.9790, 1.0016, 0.9835, 1.0023, 1.0065,\n",
            "        0.9894, 0.9754, 0.9826, 0.9819, 0.9908, 0.9882, 0.9830, 0.9931, 0.9840,\n",
            "        0.9947])), ('module.encoder_q.layer1.1.bn1.bias', tensor([ 0.0030, -0.0032, -0.0038,  0.0018, -0.0028, -0.0039,  0.0098,  0.0185,\n",
            "         0.0097,  0.0148, -0.0042, -0.0040, -0.0093, -0.0144,  0.0057,  0.0020,\n",
            "         0.0091,  0.0018,  0.0038, -0.0254,  0.0078,  0.0080, -0.0037, -0.0005,\n",
            "        -0.0185,  0.0186, -0.0042,  0.0115, -0.0067, -0.0101, -0.0006,  0.0166,\n",
            "         0.0225,  0.0168, -0.0026, -0.0143,  0.0101, -0.0167, -0.0007, -0.0079,\n",
            "         0.0034,  0.0002, -0.0014,  0.0038, -0.0177,  0.0026, -0.0051, -0.0024,\n",
            "         0.0072, -0.0132, -0.0144, -0.0027,  0.0197, -0.0006, -0.0056, -0.0236,\n",
            "        -0.0172, -0.0079, -0.0017, -0.0076, -0.0142,  0.0161, -0.0029,  0.0027])), ('module.encoder_q.layer1.1.bn1.running_mean', tensor([-0.4120, -0.8106,  0.8998, -1.4839, -2.8605,  0.1488,  3.1069, -2.0420,\n",
            "         0.8973,  0.3887,  1.1119,  0.8663, -2.1984,  1.3194,  1.2807, -5.3040,\n",
            "        -0.7828,  0.9743, -0.5916,  1.1318, -0.1218,  2.3750,  1.4338,  2.0554,\n",
            "         0.0420, -1.2085,  0.3697, -0.5549,  1.5494, -2.6352,  0.0182,  2.0130,\n",
            "        -0.2601, -0.7385, -1.4697,  1.5586,  0.6610,  1.6186,  1.4471,  3.5277,\n",
            "        -0.9601, -1.0826,  0.4890, -3.2944,  0.4572, -2.6413,  1.3673, -2.1067,\n",
            "         0.5430,  0.7635,  1.2511,  1.3735,  1.1006, -1.5878, -1.5274, -1.6237,\n",
            "         1.2634,  0.6576, -1.2821,  1.2006, -3.6835,  0.2324, -0.5165, -0.4938])), ('module.encoder_q.layer1.1.bn1.running_var', tensor([ 5.0402,  8.1185,  5.9836,  3.1950, 12.7436, 10.3025, 10.4694,  6.7949,\n",
            "         5.7194,  6.2204,  7.0313,  5.2316,  7.7605, 10.9805, 13.3498, 10.9586,\n",
            "         5.9753,  8.8588, 10.1324,  5.6183,  7.3785,  6.7949,  7.5593,  9.4330,\n",
            "         4.3952,  6.8893,  7.3764, 10.3749, 13.9503,  7.7139,  5.1369, 35.1928,\n",
            "         4.7504,  2.3938, 10.4433,  7.0474,  8.4720, 10.1380,  6.0003, 12.7064,\n",
            "         5.3063,  8.2514, 14.4364,  4.8824, 15.4228, 12.6884, 10.3767, 10.3932,\n",
            "         6.3824, 14.5747,  7.3153,  5.7980,  5.5755,  4.1919, 16.4596,  4.5844,\n",
            "         6.9774,  9.6352,  7.7208, 14.8024,  7.4557,  6.9943,  6.3771,  6.1489])), ('module.encoder_q.layer1.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.1.conv2.weight', tensor([[[[-2.6045e-02,  4.7371e-02,  1.0869e-01],\n",
            "          [ 3.3632e-02,  2.4677e-02,  6.7420e-02],\n",
            "          [ 7.0165e-02,  1.2637e-01, -6.6878e-02]],\n",
            "\n",
            "         [[ 1.6028e-02,  1.0311e-02, -2.9927e-02],\n",
            "          [ 4.4083e-02, -5.6032e-02, -8.3434e-02],\n",
            "          [ 7.8620e-02,  2.9901e-02, -5.5911e-03]],\n",
            "\n",
            "         [[ 5.2950e-02, -2.7597e-02, -7.2805e-04],\n",
            "          [ 1.0171e-01,  5.6700e-02,  9.7442e-02],\n",
            "          [ 8.8243e-03, -2.9511e-02, -3.0021e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1356e-01, -5.6262e-02,  2.9263e-02],\n",
            "          [ 1.4616e-01, -1.6772e-02,  3.1619e-02],\n",
            "          [-1.4898e-01, -6.0535e-02,  8.7943e-02]],\n",
            "\n",
            "         [[ 2.6704e-02, -7.9963e-02, -7.4240e-02],\n",
            "          [ 5.6894e-02, -7.6417e-02, -9.0481e-02],\n",
            "          [ 7.4575e-02,  9.0360e-02,  6.3790e-02]],\n",
            "\n",
            "         [[ 5.3898e-02, -5.7007e-02,  4.6772e-02],\n",
            "          [ 5.1313e-02,  3.5791e-02,  1.0882e-02],\n",
            "          [-3.3595e-02, -3.3311e-02, -1.1471e-01]]],\n",
            "\n",
            "\n",
            "        [[[-4.8466e-02, -1.9003e-01, -2.3697e-02],\n",
            "          [-7.9155e-03, -4.5399e-02, -1.2856e-02],\n",
            "          [-6.8574e-02,  8.6020e-02, -7.7535e-02]],\n",
            "\n",
            "         [[ 2.5532e-02,  2.8817e-02,  5.5569e-02],\n",
            "          [-6.8768e-03,  4.3626e-02, -4.8916e-02],\n",
            "          [ 3.7441e-02, -7.6529e-02,  1.9327e-02]],\n",
            "\n",
            "         [[-4.7509e-02,  6.5040e-03,  8.9110e-02],\n",
            "          [-1.5590e-02,  2.9762e-02, -1.2261e-02],\n",
            "          [-5.9732e-02,  3.5470e-03, -1.6253e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9007e-02, -4.8816e-03,  9.4897e-03],\n",
            "          [-2.8052e-02, -4.9495e-02, -3.6310e-03],\n",
            "          [-1.8174e-02,  9.8523e-02,  8.1029e-02]],\n",
            "\n",
            "         [[ 5.9052e-02,  3.6186e-02,  1.0507e-01],\n",
            "          [-8.8992e-02,  1.0662e-01,  2.2332e-02],\n",
            "          [ 3.5521e-03, -6.5814e-02,  1.6785e-02]],\n",
            "\n",
            "         [[ 1.8386e-02, -5.6522e-02, -2.1344e-02],\n",
            "          [ 2.7961e-02, -2.3822e-02, -1.5845e-02],\n",
            "          [ 8.4787e-02,  1.2442e-02, -7.1619e-03]]],\n",
            "\n",
            "\n",
            "        [[[-6.2605e-02, -2.3877e-02,  1.2449e-01],\n",
            "          [ 7.5729e-02, -3.6422e-02, -6.2728e-04],\n",
            "          [ 5.2951e-02,  6.5860e-02,  1.9663e-02]],\n",
            "\n",
            "         [[-6.7575e-03,  2.8087e-02,  1.4534e-02],\n",
            "          [ 1.4390e-01,  3.8676e-02,  2.4518e-02],\n",
            "          [ 4.4716e-03,  2.7180e-02, -5.5985e-03]],\n",
            "\n",
            "         [[ 3.7087e-02,  3.9889e-02,  1.7284e-02],\n",
            "          [ 9.0031e-02,  3.4917e-02,  1.5435e-04],\n",
            "          [-2.2141e-02, -1.1606e-01,  1.6637e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.6441e-02, -9.4590e-02,  9.9656e-03],\n",
            "          [ 1.4342e-02, -6.5462e-02, -2.1664e-02],\n",
            "          [ 5.1762e-02,  2.4618e-02,  8.8638e-03]],\n",
            "\n",
            "         [[-3.4087e-02,  7.5143e-02,  3.9479e-02],\n",
            "          [-2.1159e-02,  5.0950e-02, -6.5378e-02],\n",
            "          [ 3.0104e-03, -9.0811e-02,  8.0652e-02]],\n",
            "\n",
            "         [[-2.5481e-02, -7.6875e-02,  1.7737e-02],\n",
            "          [-5.4493e-02,  6.0795e-02,  7.8932e-02],\n",
            "          [-2.0030e-02,  5.0482e-02,  2.5308e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0621e-01,  8.6007e-02, -5.1123e-02],\n",
            "          [ 1.7281e-02,  3.2519e-02, -2.5168e-02],\n",
            "          [ 4.6213e-02,  2.7943e-02, -7.8185e-03]],\n",
            "\n",
            "         [[ 7.5378e-02, -2.3801e-02,  5.5582e-03],\n",
            "          [-1.5585e-02, -3.0981e-02,  1.2979e-01],\n",
            "          [-1.4966e-01,  1.6170e-02, -7.4646e-03]],\n",
            "\n",
            "         [[-9.3639e-02,  9.7896e-03,  2.6164e-03],\n",
            "          [ 2.6467e-02, -3.4609e-02,  8.3186e-02],\n",
            "          [-7.5848e-02, -8.2831e-02,  5.4486e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.5801e-02, -4.4159e-02, -9.6799e-02],\n",
            "          [-4.5700e-02,  3.9214e-02,  8.2536e-02],\n",
            "          [-4.4149e-02, -4.8391e-02, -4.0452e-02]],\n",
            "\n",
            "         [[-2.4722e-02, -5.6487e-02, -2.8691e-02],\n",
            "          [ 1.6662e-02,  1.0785e-01, -1.9378e-02],\n",
            "          [ 9.1200e-02, -8.0775e-02,  2.6046e-02]],\n",
            "\n",
            "         [[-2.6936e-02,  2.5395e-02,  1.8731e-02],\n",
            "          [-2.3239e-03, -3.8313e-02,  4.8490e-02],\n",
            "          [-1.0834e-03,  3.1948e-02, -1.7353e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.3074e-02, -3.1641e-02,  2.6945e-02],\n",
            "          [-7.8241e-02, -4.1820e-02,  1.9611e-02],\n",
            "          [-7.4672e-02,  1.0604e-01,  4.2477e-02]],\n",
            "\n",
            "         [[ 6.6209e-02,  3.5791e-02, -2.5097e-02],\n",
            "          [ 7.8464e-02, -6.9799e-02,  7.3727e-02],\n",
            "          [ 3.9659e-02, -7.0566e-02,  1.1901e-01]],\n",
            "\n",
            "         [[-2.7328e-02, -5.5622e-02,  1.9210e-02],\n",
            "          [ 1.3199e-02, -1.1085e-01,  7.0317e-02],\n",
            "          [-8.9519e-02, -5.7128e-02,  4.2311e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4816e-02, -6.8282e-02, -4.3047e-02],\n",
            "          [-1.3059e-02,  4.3617e-02,  7.0337e-02],\n",
            "          [-1.2476e-02,  9.0791e-03,  1.3076e-01]],\n",
            "\n",
            "         [[ 1.4162e-02, -9.0996e-02,  5.2012e-02],\n",
            "          [-8.6110e-02, -3.7259e-02,  4.9971e-02],\n",
            "          [-3.4817e-02, -1.7036e-01, -9.0041e-02]],\n",
            "\n",
            "         [[-3.5262e-02, -1.2021e-01, -6.7217e-02],\n",
            "          [ 3.1886e-02, -1.0015e-01,  8.3956e-02],\n",
            "          [ 1.2596e-01,  5.1776e-02,  6.7314e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.6960e-02,  2.9111e-02,  4.1966e-02],\n",
            "          [ 1.7233e-02,  2.4225e-02,  6.7947e-02],\n",
            "          [-8.3179e-02, -6.4733e-02, -3.5356e-02]],\n",
            "\n",
            "         [[-1.0817e-02, -7.5093e-02, -4.1723e-02],\n",
            "          [ 1.1847e-03, -1.3667e-02,  1.3380e-02],\n",
            "          [-7.0352e-02,  3.3560e-02, -5.5688e-02]],\n",
            "\n",
            "         [[-5.4335e-02,  3.1074e-02, -2.5371e-02],\n",
            "          [-1.2119e-01,  2.6725e-02,  9.2640e-02],\n",
            "          [ 1.0189e-02,  1.0033e-01,  2.8346e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3419e-02,  1.9091e-02,  6.7208e-02],\n",
            "          [-1.5831e-03, -3.1765e-03,  2.5589e-02],\n",
            "          [ 2.1353e-02,  3.3986e-02, -3.0711e-02]],\n",
            "\n",
            "         [[ 1.0471e-01, -5.7913e-02,  1.3742e-01],\n",
            "          [ 1.9058e-02, -9.6670e-02,  8.2756e-02],\n",
            "          [-4.7192e-02,  8.6137e-02, -3.8368e-02]],\n",
            "\n",
            "         [[-1.3527e-02,  3.6282e-02, -4.2549e-02],\n",
            "          [ 1.6993e-01, -1.4635e-01, -1.0928e-01],\n",
            "          [-5.6468e-02, -6.5043e-02, -3.5345e-02]]]])), ('module.encoder_q.layer1.1.bn2.weight', tensor([0.9885, 0.9778, 0.9815, 0.9864, 0.9744, 0.9972, 0.9858, 0.9805, 0.9999,\n",
            "        1.0157, 0.9862, 0.9944, 0.9852, 0.9879, 0.9934, 0.9992, 1.0044, 0.9740,\n",
            "        1.0053, 1.0163, 0.9848, 0.9824, 1.0004, 0.9945, 0.9919, 1.0032, 0.9976,\n",
            "        0.9953, 0.9778, 0.9855, 0.9919, 0.9934, 0.9895, 0.9863, 0.9877, 0.9830,\n",
            "        0.9930, 1.0023, 0.9959, 1.0110, 0.9988, 1.0147, 1.0011, 0.9983, 1.0014,\n",
            "        1.0099, 0.9982, 0.9741, 0.9829, 0.9789, 0.9947, 0.9824, 0.9969, 0.9983,\n",
            "        1.0017, 0.9994, 0.9900, 0.9874, 0.9939, 0.9888, 0.9822, 0.9824, 0.9834,\n",
            "        0.9822])), ('module.encoder_q.layer1.1.bn2.bias', tensor([-2.0333e-03, -1.8949e-02, -2.8464e-03, -7.6684e-03, -7.7820e-03,\n",
            "         2.5489e-03, -2.6842e-03,  2.3304e-03,  9.4362e-03,  1.0960e-02,\n",
            "        -1.5585e-02, -4.4639e-03, -3.3881e-03, -1.3280e-03,  1.0930e-03,\n",
            "         4.4468e-03,  2.1787e-03, -1.0501e-02, -1.8253e-03,  2.6529e-02,\n",
            "        -1.2716e-02,  2.4152e-03, -6.1204e-03,  9.5802e-03,  2.3010e-03,\n",
            "         2.7054e-02,  1.7925e-03,  1.2041e-02, -1.2202e-02, -1.0187e-03,\n",
            "         7.1677e-04,  9.3285e-04,  8.5803e-03, -3.2891e-03, -1.2351e-02,\n",
            "        -2.6625e-03,  4.2354e-05,  8.4773e-03,  9.3001e-04,  2.0431e-03,\n",
            "         1.6545e-03,  1.0161e-02,  6.5994e-03, -3.5802e-03,  1.2954e-02,\n",
            "         1.1033e-02,  2.4386e-03, -7.2093e-03, -1.0199e-02, -1.0649e-03,\n",
            "        -9.5910e-03, -4.6489e-04, -1.6870e-02,  1.1846e-02,  1.0201e-02,\n",
            "         5.4664e-04, -6.8477e-03, -1.2408e-02,  6.7844e-03, -4.7800e-03,\n",
            "        -1.1170e-02, -8.3393e-03, -7.1773e-03, -3.6980e-03])), ('module.encoder_q.layer1.1.bn2.running_mean', tensor([-0.6941,  0.1240, -0.5525,  0.3705, -0.0586,  0.8259,  0.0844, -0.6953,\n",
            "         0.1980,  0.7955,  0.3316,  0.0574,  0.1640,  0.5864, -0.3178,  0.2457,\n",
            "        -0.1366, -0.2884, -0.3044, -0.6357,  0.8601, -0.5853, -0.0232,  0.1533,\n",
            "         0.2311,  0.0036,  0.3776, -0.1715,  1.2894,  0.7776, -0.5252,  0.0335,\n",
            "         0.5209, -0.0154, -0.1940, -1.0395, -0.4184,  0.9420,  0.8802, -0.3190,\n",
            "         0.0675,  0.1431,  0.6895,  0.9682, -0.4916,  0.3512,  0.2939, -0.0542,\n",
            "         0.7224,  0.8277,  0.3715, -0.6096,  0.9684,  0.1946,  0.3931,  0.1273,\n",
            "         1.1168,  0.6024, -0.5906,  0.4670, -0.2668, -0.5622, -0.0632,  0.1813])), ('module.encoder_q.layer1.1.bn2.running_var', tensor([1.4395, 1.1515, 3.2095, 1.0960, 0.5356, 1.4698, 0.6768, 1.1953, 0.9775,\n",
            "        0.7940, 1.0458, 1.7438, 1.1099, 1.1337, 1.6264, 0.8396, 1.3475, 0.9578,\n",
            "        1.3480, 1.4192, 4.2364, 0.8145, 1.3115, 1.0528, 0.9568, 1.6387, 1.0563,\n",
            "        0.9488, 2.2496, 2.1224, 1.3732, 0.6208, 0.6230, 1.3365, 0.9652, 1.3522,\n",
            "        0.6850, 1.6391, 0.6251, 0.9437, 1.3600, 1.0147, 3.3621, 2.6653, 0.8402,\n",
            "        1.5325, 1.3741, 0.8229, 1.1558, 2.0442, 0.6889, 1.3801, 2.3278, 0.4778,\n",
            "        1.1955, 0.7515, 1.0667, 1.2815, 1.3800, 1.2463, 1.7694, 1.2004, 1.5356,\n",
            "        0.6920])), ('module.encoder_q.layer1.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.1.conv3.weight', tensor([[[[-0.1380]],\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[-0.0166]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0400]],\n",
            "\n",
            "         [[-0.0032]],\n",
            "\n",
            "         [[-0.1291]]],\n",
            "\n",
            "\n",
            "        [[[-0.0164]],\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         [[-0.2042]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0929]],\n",
            "\n",
            "         [[-0.0196]],\n",
            "\n",
            "         [[-0.0424]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0426]],\n",
            "\n",
            "         [[-0.1238]],\n",
            "\n",
            "         [[-0.0551]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1369]],\n",
            "\n",
            "         [[-0.0040]],\n",
            "\n",
            "         [[-0.0857]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0264]],\n",
            "\n",
            "         [[ 0.0824]],\n",
            "\n",
            "         [[-0.1724]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1570]],\n",
            "\n",
            "         [[-0.0955]],\n",
            "\n",
            "         [[ 0.0999]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0542]],\n",
            "\n",
            "         [[ 0.0014]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0391]],\n",
            "\n",
            "         [[-0.0586]],\n",
            "\n",
            "         [[-0.0778]]],\n",
            "\n",
            "\n",
            "        [[[-0.0585]],\n",
            "\n",
            "         [[ 0.0817]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1206]],\n",
            "\n",
            "         [[-0.1205]],\n",
            "\n",
            "         [[-0.1286]]]])), ('module.encoder_q.layer1.1.bn3.weight', tensor([0.9940, 0.9892, 1.0010, 0.9999, 0.9918, 0.9936, 0.9858, 0.9873, 0.9976,\n",
            "        0.9920, 0.9939, 0.9969, 0.9958, 0.9937, 0.9893, 0.9977, 0.9926, 0.9871,\n",
            "        0.9974, 0.9880, 0.9923, 0.9961, 0.9921, 0.9903, 0.9987, 0.9880, 0.9952,\n",
            "        0.9928, 0.9930, 0.9970, 0.9968, 0.9816, 0.9959, 0.9933, 0.9902, 0.9884,\n",
            "        0.9839, 0.9930, 0.9865, 0.9893, 0.9868, 0.9899, 0.9893, 0.9907, 0.9903,\n",
            "        0.9964, 0.9896, 0.9948, 0.9920, 0.9896, 0.9929, 0.9896, 0.9916, 0.9950,\n",
            "        0.9921, 0.9905, 0.9979, 0.9931, 0.9854, 0.9973, 0.9991, 0.9936, 0.9935,\n",
            "        0.9911, 0.9922, 0.9891, 0.9929, 0.9882, 0.9877, 0.9902, 0.9844, 0.9871,\n",
            "        0.9973, 0.9931, 0.9988, 0.9905, 1.0074, 0.9871, 0.9971, 0.9942, 0.9987,\n",
            "        0.9926, 0.9894, 0.9861, 0.9911, 0.9910, 0.9900, 0.9847, 0.9892, 0.9961,\n",
            "        0.9958, 0.9942, 0.9870, 0.9972, 0.9940, 0.9882, 0.9949, 0.9875, 0.9888,\n",
            "        0.9926, 0.9936, 0.9967, 0.9971, 0.9852, 0.9984, 0.9937, 0.9866, 0.9840,\n",
            "        0.9948, 0.9959, 0.9947, 0.9921, 0.9911, 0.9939, 0.9906, 0.9940, 0.9957,\n",
            "        0.9888, 0.9979, 0.9880, 0.9946, 0.9936, 0.9842, 0.9916, 0.9901, 0.9862,\n",
            "        0.9903, 0.9967, 0.9902, 0.9859, 0.9898, 0.9991, 0.9894, 0.9892, 0.9982,\n",
            "        0.9851, 0.9948, 0.9937, 0.9880, 0.9939, 1.0010, 0.9887, 0.9919, 0.9899,\n",
            "        0.9850, 0.9916, 0.9922, 0.9925, 0.9917, 0.9898, 0.9912, 0.9881, 0.9913,\n",
            "        0.9897, 0.9953, 0.9947, 0.9908, 0.9929, 0.9918, 0.9932, 0.9912, 0.9906,\n",
            "        0.9907, 0.9912, 0.9911, 0.9921, 0.9897, 0.9912, 0.9955, 0.9941, 0.9884,\n",
            "        0.9900, 0.9975, 0.9830, 0.9899, 0.9908, 0.9916, 0.9864, 0.9936, 0.9926,\n",
            "        0.9926, 0.9850, 0.9913, 0.9922, 0.9950, 0.9941, 0.9853, 0.9923, 0.9903,\n",
            "        0.9978, 1.0001, 0.9941, 0.9965, 0.9950, 0.9959, 0.9847, 0.9896, 0.9968,\n",
            "        0.9937, 0.9901, 0.9880, 0.9924, 0.9945, 0.9948, 0.9921, 0.9911, 0.9948,\n",
            "        0.9924, 0.9951, 0.9892, 0.9891, 0.9891, 0.9963, 0.9919, 0.9868, 0.9847,\n",
            "        0.9921, 0.9894, 0.9957, 0.9874, 0.9927, 0.9920, 0.9940, 0.9935, 0.9875,\n",
            "        0.9952, 0.9898, 0.9925, 0.9877, 0.9868, 0.9952, 0.9893, 0.9961, 0.9892,\n",
            "        0.9881, 0.9955, 0.9950, 0.9929, 0.9948, 0.9910, 0.9878, 0.9919, 0.9919,\n",
            "        0.9948, 0.9970, 0.9905, 0.9923, 0.9891, 0.9901, 0.9974, 0.9960, 1.0007,\n",
            "        0.9890, 0.9949, 0.9962, 0.9931])), ('module.encoder_q.layer1.1.bn3.bias', tensor([ 2.6893e-03, -3.4471e-03,  2.6914e-03,  3.9536e-03, -2.3077e-04,\n",
            "         4.4970e-03, -2.1654e-04,  7.3115e-04,  4.9731e-03, -3.2101e-03,\n",
            "         2.8891e-03,  1.5296e-04,  2.3781e-03, -3.3738e-03, -1.2491e-03,\n",
            "         4.2865e-03, -1.7143e-03, -4.8759e-03,  3.6079e-03, -8.9073e-03,\n",
            "        -1.7658e-03,  4.8978e-03, -2.8085e-03,  2.3427e-03, -3.1792e-04,\n",
            "        -2.1003e-03, -7.1955e-03,  5.7720e-04,  5.3716e-03, -2.3549e-03,\n",
            "        -7.5073e-05, -2.0950e-03,  3.3026e-03, -2.9422e-03, -4.0048e-03,\n",
            "        -2.8794e-03, -6.0502e-03,  8.8627e-04,  4.8498e-04,  4.4472e-03,\n",
            "         3.1452e-03, -5.7754e-03, -2.1618e-03, -6.9589e-03, -1.2283e-03,\n",
            "        -4.0017e-04, -6.1247e-04,  1.7168e-03, -4.0386e-03, -2.2922e-03,\n",
            "        -8.0620e-03,  2.1396e-03, -6.7849e-04,  2.4301e-03,  4.7864e-03,\n",
            "         2.7853e-03,  4.1397e-03,  4.7301e-03, -1.4178e-03,  2.5051e-03,\n",
            "         6.0554e-03, -1.2870e-03,  5.4149e-03, -2.8314e-04,  8.2614e-04,\n",
            "         2.4226e-03, -1.8380e-03,  3.2084e-03,  1.0163e-03,  4.0155e-03,\n",
            "         1.3551e-03, -2.5392e-04, -2.6212e-03,  6.7137e-03,  5.4643e-03,\n",
            "         4.0100e-03,  3.5638e-03, -2.5346e-03,  6.2435e-03,  1.6605e-03,\n",
            "         1.2425e-03, -1.5340e-03, -1.6560e-03, -3.3446e-03, -4.0739e-04,\n",
            "        -2.0014e-03,  3.6514e-03,  4.1268e-03, -5.8678e-03,  4.1015e-03,\n",
            "         2.5496e-03,  2.0898e-04, -9.0389e-03,  3.3782e-03,  4.7250e-04,\n",
            "        -4.9610e-03,  7.0147e-03, -1.0030e-03, -3.3798e-03,  1.6304e-05,\n",
            "        -3.9387e-03, -1.4346e-03, -3.0844e-03, -2.7757e-03,  1.1133e-03,\n",
            "        -2.1322e-03, -2.4259e-03, -2.8906e-03, -7.8222e-04, -2.4006e-03,\n",
            "        -2.5634e-03, -4.0053e-03, -1.7171e-03,  1.8137e-03, -4.7319e-03,\n",
            "        -1.4862e-04, -2.1282e-03,  3.1953e-03,  3.7447e-03, -1.6802e-03,\n",
            "         7.2234e-04, -4.4393e-04, -3.7619e-03, -2.4092e-03, -5.9838e-03,\n",
            "        -8.1559e-04, -3.1117e-03,  7.0555e-03,  6.7343e-03, -6.1585e-03,\n",
            "        -4.8662e-03,  2.0260e-03, -3.1955e-03, -2.6241e-03,  4.7083e-03,\n",
            "        -2.9190e-03, -2.1616e-03, -1.6019e-03, -6.3933e-04,  3.9169e-03,\n",
            "         6.1289e-03, -2.8420e-03, -1.7922e-04, -1.3045e-03,  5.5404e-04,\n",
            "         4.7577e-03,  6.4620e-04,  3.0596e-03, -7.2492e-05,  6.5977e-03,\n",
            "         3.8665e-03,  1.3157e-03,  2.7896e-03, -3.1396e-03,  2.5068e-03,\n",
            "        -3.7295e-03, -1.3793e-03,  1.5113e-03, -3.9734e-03, -2.5805e-03,\n",
            "        -4.8829e-04, -2.0964e-03, -2.9450e-03, -1.5274e-03, -2.0393e-03,\n",
            "         6.4604e-03, -1.9600e-03, -4.8719e-03,  2.6103e-03, -4.0928e-03,\n",
            "         4.0579e-03, -3.1015e-03, -1.1773e-04, -2.8781e-03, -2.3675e-04,\n",
            "        -3.0260e-03,  5.4909e-04, -6.6721e-03,  2.2464e-04, -7.9005e-04,\n",
            "        -2.2946e-03, -4.6283e-03, -1.4147e-03,  3.8612e-04,  1.0129e-03,\n",
            "        -7.2543e-04, -3.0704e-03,  5.8109e-03, -4.2867e-03, -1.8785e-03,\n",
            "         6.7130e-03,  1.2113e-03, -2.2461e-03, -1.9430e-03, -4.6935e-04,\n",
            "        -5.0791e-03, -2.9236e-03,  2.3739e-03, -3.3724e-04, -1.2409e-03,\n",
            "        -4.0383e-03,  3.4106e-04,  3.9529e-03,  9.0442e-03,  6.5399e-04,\n",
            "         7.0249e-04,  1.1638e-03,  4.3989e-03,  1.8938e-03, -1.2176e-03,\n",
            "        -4.2661e-03, -5.6457e-04, -7.0515e-04,  1.7938e-03, -2.6137e-03,\n",
            "        -2.1531e-03, -4.0851e-03, -5.2509e-03,  5.8684e-04, -2.5054e-03,\n",
            "        -3.2753e-03, -3.2388e-03,  1.2073e-03, -5.1647e-04, -4.0566e-03,\n",
            "         3.1495e-03, -2.3990e-03, -4.5240e-04,  3.3023e-03,  4.7450e-03,\n",
            "         1.1427e-04, -2.1816e-03,  2.7282e-03,  5.3926e-03, -6.5299e-04,\n",
            "         1.0219e-03,  6.2728e-03, -2.6889e-03,  3.9364e-03, -8.4180e-03,\n",
            "         2.3586e-03,  1.0629e-03, -4.7529e-03,  4.4172e-03,  4.9196e-03,\n",
            "        -9.5496e-03, -9.6266e-03,  2.1754e-03,  2.6822e-03,  5.3156e-03,\n",
            "        -1.4432e-03,  3.1102e-03,  4.7557e-03,  4.9381e-03,  8.4862e-03,\n",
            "        -5.6912e-03])), ('module.encoder_q.layer1.1.bn3.running_mean', tensor([-3.4082e-01, -4.5733e-01, -2.7812e-01,  5.6612e-02, -7.8608e-02,\n",
            "        -1.0998e-01, -4.9145e-01,  4.9950e-02,  4.4387e-02, -1.8341e-01,\n",
            "        -1.0235e-01, -2.0559e-01, -4.2779e-01,  2.1791e-01,  2.0547e-01,\n",
            "         1.6989e-01, -2.9691e-01, -1.2594e-02,  5.2835e-02,  5.8391e-02,\n",
            "        -1.5514e-01, -3.2119e-01, -1.2140e-01, -2.4762e-01,  2.4268e-01,\n",
            "        -3.1056e-01,  2.6880e-01, -9.2265e-02, -9.6165e-02,  1.7378e-01,\n",
            "        -2.4810e-01,  1.8819e-01,  7.4887e-02,  8.0606e-02, -4.1501e-02,\n",
            "        -5.4646e-02, -1.3053e-01, -9.8325e-02,  1.2891e-02,  2.4390e-01,\n",
            "         2.9303e-01, -5.6679e-01,  5.2046e-02,  1.5084e-01, -4.0682e-01,\n",
            "         3.9191e-01,  1.4382e-01,  1.2121e-01, -3.3998e-01, -1.9841e-01,\n",
            "         2.5148e-02, -1.3900e-01, -7.9694e-02,  6.1967e-01,  3.6531e-01,\n",
            "        -3.1468e-01,  2.8308e-01, -5.7380e-02, -1.4124e-01,  3.1083e-01,\n",
            "        -5.8325e-01, -2.6298e-01,  3.4313e-01,  1.4278e-01, -6.5163e-02,\n",
            "         2.1212e-01, -3.5343e-01,  2.1851e-01,  6.8545e-02,  1.2811e-02,\n",
            "         8.8939e-02,  8.2947e-02, -1.2421e-01,  2.9588e-01, -1.2413e-01,\n",
            "        -8.1384e-03, -4.7482e-04,  6.3956e-02, -1.2911e-01, -4.8571e-01,\n",
            "         8.0045e-02,  7.7035e-02,  3.5268e-01, -2.6860e-01, -3.6010e-02,\n",
            "         5.3979e-01, -4.1672e-01, -1.5949e-02, -2.6206e-03, -1.4589e-01,\n",
            "        -9.0691e-03, -2.3366e-02, -3.6760e-01, -6.9160e-03,  1.8106e-01,\n",
            "        -1.0009e-01,  3.5503e-01,  2.1628e-02,  1.3315e-01, -2.2537e-01,\n",
            "        -5.3920e-02, -4.0179e-01, -1.3915e-01, -2.5114e-01, -3.8681e-02,\n",
            "        -1.1320e-01, -1.7158e-01,  1.3367e-01,  9.0866e-02, -1.5821e-01,\n",
            "        -7.3855e-02,  3.2442e-01,  4.5767e-01,  9.2165e-02, -2.7781e-02,\n",
            "        -7.7316e-02,  2.1200e-01,  9.3347e-03,  7.1854e-02,  7.7065e-02,\n",
            "         3.2176e-02,  4.9813e-02,  1.9576e-02, -1.7510e-01, -8.8707e-02,\n",
            "        -2.2585e-01,  3.4495e-01,  2.6901e-01,  1.1983e-01, -9.1498e-02,\n",
            "        -3.3261e-01, -2.0646e-01,  1.2654e-01, -6.4494e-02,  4.7451e-01,\n",
            "         3.2293e-01, -3.5446e-01,  3.0487e-01, -2.7855e-01,  2.0068e-02,\n",
            "         4.1811e-01, -1.0334e-01,  3.5540e-01,  3.9716e-01, -6.3963e-01,\n",
            "        -1.5780e-01,  3.4749e-01,  1.7564e-01, -3.4314e-02,  1.8132e-01,\n",
            "         1.2361e-01, -3.8099e-02,  4.2856e-01, -6.5040e-02, -2.3173e-01,\n",
            "        -3.3534e-01,  1.4536e-02,  2.8770e-01,  6.1086e-01, -1.8376e-01,\n",
            "         1.4375e-01, -1.7710e-01,  3.4780e-01,  9.6872e-02, -2.4530e-01,\n",
            "        -2.4753e-01,  4.6591e-02,  4.5788e-01,  2.7727e-01, -1.7015e-01,\n",
            "        -2.5690e-01, -1.3571e-01,  2.2197e-01,  8.9335e-02, -7.3179e-02,\n",
            "        -1.3780e-02, -1.6026e-01,  9.6020e-02,  3.5117e-01,  8.5296e-02,\n",
            "        -1.2011e-01,  1.1016e-01, -7.2460e-02, -2.3144e-01, -4.0262e-01,\n",
            "        -1.3114e-01,  5.5027e-02,  2.2662e-01, -4.5040e-02,  4.2396e-01,\n",
            "         2.1659e-02, -1.6603e-01, -1.0624e-01,  2.1361e-02,  8.2749e-02,\n",
            "         9.4685e-02,  5.3752e-01, -2.5790e-01, -2.3522e-01, -1.5085e-01,\n",
            "         8.5122e-02,  3.1562e-01,  1.1290e-02, -1.8501e-01,  4.8170e-02,\n",
            "        -2.1662e-01, -9.5282e-02,  3.8383e-01, -4.7167e-01, -5.6660e-02,\n",
            "        -2.7950e-02, -5.7891e-02, -4.6163e-02,  3.9722e-02,  1.3383e-01,\n",
            "         2.5309e-01,  1.7633e-01, -1.2485e-01,  1.9103e-01,  5.2947e-01,\n",
            "        -4.6536e-01, -2.0642e-01,  7.3503e-02, -1.3783e-01, -4.8181e-01,\n",
            "         2.0451e-01, -3.3163e-01,  1.2838e-01,  2.0699e-01,  2.8547e-01,\n",
            "         1.4446e-01, -3.7678e-01,  2.1098e-02,  3.9487e-01, -3.5401e-01,\n",
            "         1.5420e-01, -2.9971e-01,  1.4448e-02,  2.2833e-01,  5.3844e-02,\n",
            "         1.3266e-01,  5.9712e-02, -1.0784e-01,  8.7294e-02, -1.6035e-01,\n",
            "         2.2339e-02,  2.0928e-01, -3.5151e-02, -1.7057e-01,  7.5060e-02,\n",
            "         1.8388e-03,  3.4489e-01,  1.2873e-02,  1.2993e-01,  1.0534e-01,\n",
            "        -3.7798e-01])), ('module.encoder_q.layer1.1.bn3.running_var', tensor([0.1637, 0.1361, 0.2012, 0.3796, 0.1401, 0.1584, 0.2144, 0.2282, 0.2326,\n",
            "        0.1123, 0.2045, 0.4080, 0.0710, 0.1452, 0.0971, 0.1021, 0.3731, 0.2290,\n",
            "        0.3488, 0.2380, 0.0839, 0.1780, 0.8733, 0.2647, 0.0432, 0.4419, 0.1916,\n",
            "        0.1331, 0.4107, 0.0580, 0.3149, 0.4886, 0.2306, 0.1270, 0.2395, 0.2101,\n",
            "        0.1205, 0.2710, 0.1349, 0.1826, 0.4794, 0.3178, 0.1649, 0.2363, 0.1928,\n",
            "        0.4103, 0.1192, 0.1199, 0.1321, 0.2509, 0.1637, 0.1427, 0.1391, 0.4293,\n",
            "        0.4481, 0.2652, 0.1973, 0.1609, 0.1425, 0.2161, 0.2376, 0.2839, 0.1269,\n",
            "        0.1112, 0.0921, 0.3393, 0.1740, 0.3293, 0.1081, 0.1748, 0.2841, 0.2726,\n",
            "        0.2313, 0.5724, 0.3913, 0.1672, 0.1277, 0.1887, 0.1574, 0.1585, 0.1344,\n",
            "        0.1658, 0.3511, 0.2106, 0.1051, 0.2313, 0.2913, 0.1713, 0.4132, 0.1335,\n",
            "        0.1327, 0.0872, 0.6457, 0.1571, 0.2245, 0.0942, 0.1147, 0.0862, 0.4488,\n",
            "        0.4542, 0.1737, 0.1398, 0.2142, 0.1588, 0.0712, 0.1200, 0.2569, 0.1454,\n",
            "        0.3302, 0.2667, 0.1022, 0.3261, 0.4824, 0.1777, 0.0930, 0.4399, 0.0875,\n",
            "        0.0990, 0.1998, 0.0743, 0.3465, 0.1654, 0.2645, 0.6249, 0.2477, 0.1706,\n",
            "        0.4653, 0.2713, 0.1596, 0.1248, 0.3054, 0.2208, 0.0545, 0.0726, 0.3647,\n",
            "        0.5138, 0.2509, 0.5801, 0.1249, 0.5037, 0.1245, 0.1990, 0.1792, 0.2826,\n",
            "        0.6360, 0.1325, 0.1625, 0.0872, 0.2097, 0.1746, 0.2372, 0.0594, 0.5307,\n",
            "        0.1474, 0.1130, 0.0956, 0.0786, 0.1663, 0.2129, 0.0593, 0.1803, 0.1342,\n",
            "        0.4034, 0.1443, 0.2619, 0.0528, 0.2295, 0.4577, 0.2548, 0.1707, 0.3468,\n",
            "        0.2164, 0.1285, 0.1024, 0.1380, 0.2599, 0.2544, 0.2471, 0.1336, 0.1225,\n",
            "        0.1409, 0.1116, 0.0770, 0.2217, 0.2460, 0.0576, 0.1355, 0.1506, 0.1901,\n",
            "        0.3712, 0.1221, 0.3131, 0.1176, 0.1625, 0.2646, 0.1702, 0.8961, 0.3930,\n",
            "        0.1932, 0.2049, 0.1722, 0.2394, 0.3472, 0.0920, 0.1221, 0.2958, 0.5830,\n",
            "        0.1068, 0.3429, 0.1660, 0.1192, 0.1625, 0.2511, 0.1503, 0.1745, 0.3629,\n",
            "        0.1575, 0.1172, 0.1278, 0.5221, 0.2223, 0.3564, 0.2495, 0.1413, 0.3200,\n",
            "        0.1528, 0.1038, 0.1613, 0.3090, 0.2181, 0.1886, 0.1131, 0.1813, 0.1984,\n",
            "        0.1442, 0.2150, 0.2022, 0.0985, 0.4135, 0.3225, 0.2210, 0.2409, 0.2693,\n",
            "        0.2553, 0.1926, 0.3502, 0.2242, 0.1282, 0.2091, 0.1763, 0.0923, 0.4012,\n",
            "        0.2153, 0.3977, 0.0875, 0.1597])), ('module.encoder_q.layer1.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.2.conv1.weight', tensor([[[[-0.1249]],\n",
            "\n",
            "         [[-0.1337]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0397]],\n",
            "\n",
            "         [[ 0.1365]],\n",
            "\n",
            "         [[-0.1110]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4102]],\n",
            "\n",
            "         [[ 0.0481]],\n",
            "\n",
            "         [[ 0.0144]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1692]],\n",
            "\n",
            "         [[ 0.3463]],\n",
            "\n",
            "         [[-0.1371]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1041]],\n",
            "\n",
            "         [[-0.2098]],\n",
            "\n",
            "         [[-0.1894]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1144]],\n",
            "\n",
            "         [[-0.3007]],\n",
            "\n",
            "         [[ 0.1774]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0878]],\n",
            "\n",
            "         [[-0.0279]],\n",
            "\n",
            "         [[-0.2034]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1352]],\n",
            "\n",
            "         [[-0.1683]],\n",
            "\n",
            "         [[ 0.1345]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0541]],\n",
            "\n",
            "         [[-0.0051]],\n",
            "\n",
            "         [[ 0.0230]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1441]],\n",
            "\n",
            "         [[-0.0696]],\n",
            "\n",
            "         [[-0.0642]]],\n",
            "\n",
            "\n",
            "        [[[-0.1540]],\n",
            "\n",
            "         [[ 0.0765]],\n",
            "\n",
            "         [[ 0.0883]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2354]],\n",
            "\n",
            "         [[-0.3238]],\n",
            "\n",
            "         [[ 0.2754]]]])), ('module.encoder_q.layer1.2.bn1.weight', tensor([0.9924, 0.9971, 0.9900, 0.9831, 0.9887, 1.0027, 0.9908, 0.9963, 0.9867,\n",
            "        0.9844, 0.9912, 0.9922, 0.9896, 0.9925, 0.9936, 1.0079, 0.9796, 0.9886,\n",
            "        0.9814, 0.9988, 0.9816, 0.9920, 0.9922, 0.9816, 0.9874, 0.9939, 1.0073,\n",
            "        0.9874, 0.9997, 0.9882, 1.0039, 0.9931, 0.9805, 0.9845, 0.9926, 0.9937,\n",
            "        0.9942, 0.9901, 0.9762, 0.9978, 0.9907, 0.9992, 0.9985, 0.9856, 1.0085,\n",
            "        0.9978, 0.9999, 0.9887, 0.9938, 0.9889, 0.9897, 0.9861, 0.9862, 0.9941,\n",
            "        0.9919, 0.9960, 0.9966, 0.9988, 0.9952, 1.0027, 0.9983, 0.9930, 0.9847,\n",
            "        0.9943])), ('module.encoder_q.layer1.2.bn1.bias', tensor([-0.0056,  0.0065,  0.0005, -0.0050, -0.0094,  0.0065, -0.0014,  0.0092,\n",
            "        -0.0055, -0.0071,  0.0063,  0.0061, -0.0079,  0.0033, -0.0022,  0.0115,\n",
            "        -0.0024, -0.0008, -0.0025,  0.0020, -0.0079,  0.0032, -0.0009, -0.0105,\n",
            "        -0.0037,  0.0031,  0.0059,  0.0044,  0.0043, -0.0055, -0.0065,  0.0035,\n",
            "        -0.0069, -0.0104, -0.0068,  0.0131,  0.0067,  0.0077, -0.0121,  0.0064,\n",
            "        -0.0010, -0.0075,  0.0014,  0.0067, -0.0036,  0.0062,  0.0062, -0.0052,\n",
            "        -0.0031, -0.0108, -0.0071,  0.0022, -0.0011,  0.0036,  0.0027,  0.0049,\n",
            "         0.0023,  0.0137, -0.0010,  0.0148,  0.0092,  0.0048, -0.0077, -0.0031])), ('module.encoder_q.layer1.2.bn1.running_mean', tensor([ 0.7184, -2.1166,  0.3027,  1.8864,  0.4301, -0.7970,  1.5665,  1.0273,\n",
            "         0.7581, -1.1282, -0.5339, -1.3248, -0.2578,  0.3448, -2.4157, -5.7721,\n",
            "        -1.2672, -2.6596, -1.9848,  0.8298,  0.6797, -3.4224, -1.0958,  1.9085,\n",
            "         2.0217, -1.9090,  0.5856, -0.3502, -3.4774,  1.4698,  1.4442,  0.3475,\n",
            "         1.7936,  1.2857,  0.6735,  1.5441, -0.0760, -3.9717,  2.5485, -2.9011,\n",
            "        -2.8451,  0.5077,  1.6162,  2.5181, -2.1248,  1.4333,  2.0546,  0.8961,\n",
            "        -0.3182,  0.2744, -2.8007, -2.0332, -0.0714,  0.4074, -0.5103,  2.0354,\n",
            "        -2.5927, -0.4811, -0.2582, -2.9694, -2.1330,  3.2039, -0.0295,  0.4135])), ('module.encoder_q.layer1.2.bn1.running_var', tensor([14.5437,  5.7034,  4.3270, 16.8015, 20.7746, 10.1925, 14.5190, 12.1012,\n",
            "        17.3417, 12.1443, 10.3106, 10.5061, 13.1727, 13.7445,  7.4645, 10.0458,\n",
            "         7.9707, 10.1154,  8.6941,  5.4259, 13.0505, 12.5289, 12.0248, 12.5789,\n",
            "         7.4587, 12.0782,  7.5054,  9.5633, 10.1585,  5.5811, 10.3294,  9.9067,\n",
            "         8.1200,  8.7605,  9.5068,  6.1109, 10.5716, 12.0459, 15.4029, 13.9796,\n",
            "        17.1077, 15.5883, 21.2827,  9.6955,  6.0770,  8.9791,  9.8358, 11.9484,\n",
            "        10.6412, 26.3680, 34.4808, 20.0579, 13.6728,  5.3730,  9.8179,  9.8776,\n",
            "         9.0578,  9.2227, 15.4406, 10.5002, 18.6786, 11.6744,  9.5549, 14.3753])), ('module.encoder_q.layer1.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.2.conv2.weight', tensor([[[[ 1.1014e-01, -9.5409e-02,  7.2945e-02],\n",
            "          [ 3.6719e-02, -2.3697e-03,  1.4893e-01],\n",
            "          [ 1.0894e-01,  8.0434e-02, -3.1506e-02]],\n",
            "\n",
            "         [[-6.7970e-02, -8.5815e-02, -1.1626e-01],\n",
            "          [ 2.6721e-02, -1.1228e-01, -3.5158e-02],\n",
            "          [ 6.0903e-02,  6.1428e-02, -6.0116e-02]],\n",
            "\n",
            "         [[ 5.8973e-02, -4.1029e-02,  2.1750e-02],\n",
            "          [ 8.2609e-02, -6.5780e-02,  7.2882e-03],\n",
            "          [-3.7796e-02, -4.5483e-02, -3.3626e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.6142e-03, -2.5434e-02, -8.2041e-02],\n",
            "          [-1.0078e-01,  4.2367e-02,  1.3639e-01],\n",
            "          [ 8.4537e-02,  2.3547e-02, -3.8332e-03]],\n",
            "\n",
            "         [[-9.1159e-02,  6.7467e-02,  1.2088e-02],\n",
            "          [-3.8363e-02,  1.1205e-02,  1.4570e-03],\n",
            "          [ 5.7582e-02, -4.1910e-02, -4.6240e-04]],\n",
            "\n",
            "         [[-1.0729e-02, -6.0313e-02,  1.1932e-01],\n",
            "          [ 2.1465e-02,  2.6147e-02,  5.3400e-02],\n",
            "          [ 5.6835e-02, -5.7278e-02, -8.8348e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9151e-02,  3.2963e-02, -3.0105e-02],\n",
            "          [-2.8026e-02,  8.8211e-02,  2.8484e-02],\n",
            "          [-4.8345e-02, -9.2968e-02, -2.4577e-02]],\n",
            "\n",
            "         [[-2.0917e-02, -1.1540e-02, -5.2769e-02],\n",
            "          [-3.7475e-02, -1.1598e-02,  2.8624e-02],\n",
            "          [-6.7921e-03, -1.1238e-02,  1.8546e-02]],\n",
            "\n",
            "         [[ 8.5538e-03,  1.8159e-02, -5.1543e-03],\n",
            "          [-6.8873e-02, -7.9127e-02,  6.2209e-02],\n",
            "          [ 1.6648e-02, -2.0454e-02, -4.1559e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.2734e-02, -2.4896e-02, -6.6755e-02],\n",
            "          [ 1.2086e-02, -2.0373e-03, -1.4769e-03],\n",
            "          [-7.4382e-02, -8.4110e-03, -4.1738e-02]],\n",
            "\n",
            "         [[-4.1475e-02, -9.2622e-02,  5.0133e-02],\n",
            "          [-7.3703e-02,  1.0025e-01, -9.5920e-02],\n",
            "          [-7.8291e-02, -4.4505e-02,  8.9066e-02]],\n",
            "\n",
            "         [[ 2.0771e-02,  5.2271e-02,  1.2420e-02],\n",
            "          [ 9.1024e-03, -1.1269e-03,  9.3280e-02],\n",
            "          [-7.1505e-02,  3.5786e-02, -1.4106e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3284e-01,  1.0134e-02, -1.2707e-02],\n",
            "          [ 2.3974e-02, -1.4788e-02, -8.6677e-02],\n",
            "          [-5.4549e-02, -3.0016e-02, -6.6424e-02]],\n",
            "\n",
            "         [[ 5.9504e-02,  1.1139e-01,  4.7237e-02],\n",
            "          [ 3.1492e-02, -7.2887e-02,  5.8555e-03],\n",
            "          [ 4.0355e-02,  8.8329e-02,  4.2255e-02]],\n",
            "\n",
            "         [[ 1.3402e-03,  2.9476e-02,  6.7104e-02],\n",
            "          [-1.0530e-01, -4.0368e-02, -2.3888e-02],\n",
            "          [ 2.4478e-02,  4.4269e-02, -1.6526e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2808e-02, -1.7586e-02, -3.0680e-02],\n",
            "          [ 2.8396e-02, -1.6566e-02, -3.6526e-02],\n",
            "          [-5.3241e-02, -1.2050e-01,  3.6865e-03]],\n",
            "\n",
            "         [[ 1.1800e-01, -4.2597e-02,  3.9591e-02],\n",
            "          [ 4.5643e-02, -1.9498e-02, -6.2708e-02],\n",
            "          [-6.1140e-02, -7.6607e-02,  4.2256e-02]],\n",
            "\n",
            "         [[-3.7581e-02,  3.4813e-02,  6.6821e-02],\n",
            "          [-3.0161e-02, -2.1017e-02, -8.3116e-02],\n",
            "          [ 6.2236e-03,  3.3885e-02, -5.9886e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4078e-02, -7.2955e-02, -3.5611e-02],\n",
            "          [-1.1133e-01,  2.9282e-02, -1.8708e-02],\n",
            "          [-2.2006e-02, -3.6206e-02, -2.4577e-03]],\n",
            "\n",
            "         [[-5.9051e-02,  2.3473e-02, -3.4586e-02],\n",
            "          [ 4.2092e-02, -9.2149e-02, -3.4001e-02],\n",
            "          [-8.3648e-02,  1.3015e-04,  5.5244e-02]],\n",
            "\n",
            "         [[-2.9446e-02, -1.1664e-02,  5.3792e-02],\n",
            "          [ 3.6504e-02, -7.1822e-02, -1.6344e-03],\n",
            "          [ 4.0551e-02, -8.0614e-02,  1.1854e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0633e-02, -3.0712e-02, -2.4689e-02],\n",
            "          [-1.0339e-02,  1.6663e-02,  1.2634e-01],\n",
            "          [ 1.3079e-01, -3.6424e-02,  7.1854e-02]],\n",
            "\n",
            "         [[-5.2983e-02, -9.0673e-02,  1.3582e-02],\n",
            "          [-1.0208e-01,  1.5258e-02, -6.6563e-02],\n",
            "          [ 8.5525e-02, -7.3256e-02, -1.0166e-02]],\n",
            "\n",
            "         [[-3.9245e-02, -1.9106e-03, -4.2991e-03],\n",
            "          [-2.1826e-04, -1.1315e-01,  1.4509e-02],\n",
            "          [-7.1994e-02, -6.1991e-02, -1.0207e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8427e-03, -6.6287e-02,  9.3110e-03],\n",
            "          [ 4.6175e-04, -4.1171e-02, -4.5850e-02],\n",
            "          [-8.7151e-02, -5.7214e-02,  2.0061e-02]],\n",
            "\n",
            "         [[-4.6643e-02,  1.1363e-01,  1.6007e-01],\n",
            "          [ 1.4174e-02,  1.2564e-02, -8.8086e-02],\n",
            "          [ 1.5236e-02,  6.0700e-02,  4.5121e-02]],\n",
            "\n",
            "         [[-6.2852e-02, -5.4283e-03,  4.5606e-02],\n",
            "          [-4.6362e-02,  5.4269e-02,  1.0834e-01],\n",
            "          [-2.0153e-03,  2.2986e-02,  2.1355e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0790e-02,  6.4808e-04, -3.7538e-02],\n",
            "          [-5.1132e-02, -4.4656e-02,  8.2750e-02],\n",
            "          [-2.3082e-02,  1.3215e-01,  4.4551e-02]],\n",
            "\n",
            "         [[ 1.4856e-01, -1.1890e-02, -3.4458e-02],\n",
            "          [-2.0305e-02,  5.6133e-02,  7.2399e-02],\n",
            "          [ 5.0951e-02, -2.9323e-02,  2.8906e-02]],\n",
            "\n",
            "         [[-8.6876e-02,  4.3737e-02,  1.1185e-01],\n",
            "          [ 5.4255e-02,  4.7951e-02,  1.2960e-02],\n",
            "          [-4.7161e-02,  2.1928e-02, -2.9716e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6781e-02, -7.1662e-02, -1.4761e-02],\n",
            "          [ 2.3443e-03, -1.6659e-02, -4.7203e-02],\n",
            "          [-2.7689e-02,  2.5721e-02, -1.2479e-01]],\n",
            "\n",
            "         [[-3.6070e-02,  4.0546e-02, -1.4398e-01],\n",
            "          [ 5.0707e-02,  5.6187e-02,  7.7086e-02],\n",
            "          [-2.9644e-02, -3.9668e-02, -5.6189e-02]],\n",
            "\n",
            "         [[-2.5140e-03, -3.2596e-02,  3.9613e-02],\n",
            "          [ 9.1527e-02, -3.9410e-02, -6.6836e-02],\n",
            "          [ 1.6994e-01,  1.3950e-02,  1.0400e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5453e-02,  4.5234e-02,  3.2903e-02],\n",
            "          [ 1.1065e-02, -4.0081e-02, -4.2015e-02],\n",
            "          [-6.0891e-02, -9.1080e-02,  7.1706e-02]],\n",
            "\n",
            "         [[ 2.6767e-02, -1.2573e-01,  1.5258e-03],\n",
            "          [-2.3769e-02, -2.1228e-02,  9.0780e-02],\n",
            "          [ 8.8609e-02, -3.8528e-02, -7.5209e-02]],\n",
            "\n",
            "         [[-1.3412e-01,  5.1084e-02, -6.4322e-02],\n",
            "          [-1.0583e-01, -4.4670e-02, -3.3942e-02],\n",
            "          [ 5.4535e-02,  1.4357e-02, -8.9590e-03]]]])), ('module.encoder_q.layer1.2.bn2.weight', tensor([0.9968, 0.9882, 0.9904, 0.9951, 0.9756, 0.9854, 0.9912, 0.9945, 0.9881,\n",
            "        1.0045, 0.9986, 0.9920, 0.9846, 0.9913, 1.0145, 0.9923, 0.9842, 0.9852,\n",
            "        0.9947, 0.9845, 0.9811, 0.9888, 0.9839, 0.9978, 0.9893, 1.0032, 0.9863,\n",
            "        0.9911, 0.9948, 0.9969, 0.9941, 0.9902, 0.9810, 0.9984, 0.9820, 0.9918,\n",
            "        0.9971, 0.9912, 0.9960, 0.9890, 0.9986, 0.9982, 0.9935, 0.9942, 0.9885,\n",
            "        0.9947, 0.9834, 0.9894, 0.9974, 0.9931, 0.9944, 0.9935, 1.0016, 0.9872,\n",
            "        0.9960, 0.9836, 0.9993, 0.9919, 0.9943, 0.9988, 0.9947, 0.9879, 0.9903,\n",
            "        1.0042])), ('module.encoder_q.layer1.2.bn2.bias', tensor([ 0.0045, -0.0072, -0.0009,  0.0048, -0.0158, -0.0038,  0.0076,  0.0119,\n",
            "        -0.0074,  0.0021,  0.0042,  0.0035, -0.0105, -0.0012,  0.0199,  0.0003,\n",
            "        -0.0007, -0.0012,  0.0023, -0.0023, -0.0092, -0.0065,  0.0023,  0.0066,\n",
            "        -0.0066,  0.0063, -0.0021, -0.0016,  0.0094,  0.0036, -0.0040, -0.0007,\n",
            "        -0.0032,  0.0007, -0.0044,  0.0012, -0.0029,  0.0060, -0.0025,  0.0030,\n",
            "         0.0022,  0.0085,  0.0103,  0.0046, -0.0025, -0.0040, -0.0092, -0.0017,\n",
            "        -0.0021, -0.0022,  0.0045, -0.0018,  0.0099, -0.0025, -0.0049, -0.0029,\n",
            "         0.0024,  0.0067, -0.0043,  0.0050, -0.0027,  0.0006,  0.0006,  0.0124])), ('module.encoder_q.layer1.2.bn2.running_mean', tensor([-0.1503,  0.1310, -0.0763, -0.4417, -0.8804, -0.2353, -0.4378, -0.4060,\n",
            "         0.1718, -0.2491,  0.0671, -0.9201,  0.1859,  0.7485,  0.1986,  0.7278,\n",
            "         0.2876, -0.7802, -0.9106,  0.2621,  0.8639,  1.4112, -0.5567, -0.0409,\n",
            "        -0.1553,  0.6879, -0.4020,  0.3504, -0.0332,  0.0997, -0.8649, -0.3499,\n",
            "         1.2371, -0.9153, -0.5531, -0.6464,  0.4559, -0.1645,  0.1354, -0.1415,\n",
            "        -0.5422,  0.0104,  0.1126,  0.0023, -0.0601,  0.2944, -0.0496,  0.4545,\n",
            "         0.5203,  1.0032,  0.5793,  1.1915,  0.7537,  0.6081, -0.1124, -0.3337,\n",
            "         0.5754, -0.0429,  0.1489,  0.3466, -0.1937,  0.0676, -0.2570, -0.2223])), ('module.encoder_q.layer1.2.bn2.running_var', tensor([1.4329, 0.8368, 0.9690, 0.8139, 1.8349, 0.5071, 0.5759, 0.4607, 0.7899,\n",
            "        0.9116, 0.9688, 0.9029, 1.0729, 1.9329, 0.9023, 0.8232, 1.2529, 0.7989,\n",
            "        1.7800, 0.9616, 1.2348, 0.8912, 0.9829, 0.7331, 1.0268, 0.7958, 1.0542,\n",
            "        0.9670, 0.9558, 0.9940, 0.8143, 0.9284, 2.1451, 0.7842, 1.3255, 1.1155,\n",
            "        1.5873, 0.7695, 0.7291, 0.8655, 1.2608, 0.8295, 1.4916, 0.6734, 0.8602,\n",
            "        1.5704, 0.5007, 0.9714, 0.7969, 0.9716, 0.8849, 1.2494, 0.9518, 0.7397,\n",
            "        1.4398, 1.1153, 1.0666, 1.5427, 0.5228, 1.4626, 0.7557, 0.4702, 1.3632,\n",
            "        0.9057])), ('module.encoder_q.layer1.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer1.2.conv3.weight', tensor([[[[-0.1585]],\n",
            "\n",
            "         [[ 0.0076]],\n",
            "\n",
            "         [[ 0.0511]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0644]],\n",
            "\n",
            "         [[ 0.0502]],\n",
            "\n",
            "         [[ 0.0385]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0208]],\n",
            "\n",
            "         [[-0.0223]],\n",
            "\n",
            "         [[ 0.0212]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0227]],\n",
            "\n",
            "         [[-0.1197]],\n",
            "\n",
            "         [[-0.1679]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1561]],\n",
            "\n",
            "         [[-0.0541]],\n",
            "\n",
            "         [[-0.1742]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         [[ 0.1308]],\n",
            "\n",
            "         [[-0.0446]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1444]],\n",
            "\n",
            "         [[ 0.0883]],\n",
            "\n",
            "         [[ 0.1125]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0950]],\n",
            "\n",
            "         [[ 0.0024]],\n",
            "\n",
            "         [[ 0.1662]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1166]],\n",
            "\n",
            "         [[-0.0529]],\n",
            "\n",
            "         [[-0.0316]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0129]],\n",
            "\n",
            "         [[-0.0798]],\n",
            "\n",
            "         [[-0.0357]]],\n",
            "\n",
            "\n",
            "        [[[-0.0405]],\n",
            "\n",
            "         [[ 0.0626]],\n",
            "\n",
            "         [[-0.1263]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0932]],\n",
            "\n",
            "         [[ 0.0156]],\n",
            "\n",
            "         [[-0.0666]]]])), ('module.encoder_q.layer1.2.bn3.weight', tensor([0.9889, 0.9896, 0.9932, 0.9942, 0.9943, 0.9934, 0.9960, 0.9986, 0.9935,\n",
            "        0.9889, 0.9920, 0.9941, 0.9903, 0.9911, 0.9920, 0.9940, 0.9961, 0.9903,\n",
            "        0.9932, 0.9938, 0.9919, 0.9909, 0.9911, 0.9957, 0.9914, 0.9914, 0.9991,\n",
            "        0.9903, 0.9883, 0.9942, 0.9909, 0.9960, 0.9923, 0.9956, 0.9929, 0.9886,\n",
            "        0.9957, 0.9905, 0.9899, 0.9927, 0.9954, 0.9958, 0.9934, 0.9946, 0.9943,\n",
            "        0.9924, 0.9925, 0.9965, 0.9948, 0.9929, 0.9936, 0.9922, 0.9935, 0.9912,\n",
            "        0.9945, 0.9857, 0.9897, 0.9935, 0.9929, 0.9960, 0.9969, 0.9874, 0.9950,\n",
            "        0.9866, 0.9963, 0.9902, 0.9912, 0.9966, 0.9915, 0.9877, 0.9902, 0.9906,\n",
            "        0.9939, 0.9955, 0.9908, 0.9930, 0.9907, 0.9926, 0.9904, 0.9981, 0.9925,\n",
            "        0.9974, 0.9931, 0.9901, 0.9916, 0.9936, 0.9936, 0.9913, 0.9949, 0.9950,\n",
            "        0.9941, 0.9902, 0.9884, 0.9889, 0.9887, 0.9884, 0.9916, 0.9921, 0.9971,\n",
            "        0.9962, 0.9958, 0.9918, 0.9934, 0.9896, 0.9896, 0.9901, 0.9918, 0.9895,\n",
            "        0.9933, 0.9948, 0.9919, 0.9907, 0.9938, 0.9869, 0.9950, 0.9904, 0.9912,\n",
            "        0.9907, 0.9974, 0.9929, 0.9958, 0.9931, 0.9933, 0.9872, 0.9941, 0.9903,\n",
            "        0.9892, 0.9964, 0.9886, 0.9941, 0.9950, 0.9951, 0.9924, 0.9902, 0.9889,\n",
            "        0.9899, 0.9909, 0.9873, 0.9917, 0.9947, 0.9892, 0.9869, 0.9929, 0.9952,\n",
            "        0.9947, 0.9954, 0.9955, 0.9902, 0.9923, 0.9905, 0.9893, 0.9926, 0.9991,\n",
            "        0.9943, 0.9962, 0.9908, 0.9916, 0.9932, 0.9906, 0.9905, 0.9924, 0.9918,\n",
            "        0.9898, 0.9912, 0.9861, 0.9963, 0.9856, 0.9930, 0.9911, 0.9913, 0.9913,\n",
            "        0.9891, 0.9909, 0.9853, 0.9971, 0.9952, 0.9906, 0.9941, 0.9927, 0.9954,\n",
            "        0.9948, 0.9896, 0.9913, 0.9959, 0.9937, 0.9915, 0.9986, 0.9930, 0.9898,\n",
            "        0.9965, 0.9930, 0.9910, 0.9947, 0.9947, 0.9916, 0.9939, 0.9895, 0.9930,\n",
            "        0.9950, 0.9925, 0.9911, 0.9897, 0.9856, 0.9956, 0.9994, 0.9926, 0.9904,\n",
            "        0.9912, 0.9943, 0.9931, 0.9946, 0.9906, 0.9889, 0.9901, 0.9998, 0.9942,\n",
            "        0.9948, 0.9923, 0.9912, 0.9866, 0.9890, 0.9897, 0.9930, 0.9948, 0.9927,\n",
            "        0.9999, 0.9974, 0.9925, 0.9967, 0.9954, 0.9948, 0.9917, 0.9934, 0.9924,\n",
            "        0.9910, 0.9922, 0.9899, 0.9908, 0.9907, 0.9876, 0.9895, 0.9920, 0.9932,\n",
            "        0.9936, 0.9960, 0.9950, 0.9934, 0.9916, 0.9895, 0.9906, 0.9952, 0.9930,\n",
            "        0.9957, 0.9928, 0.9962, 0.9888])), ('module.encoder_q.layer1.2.bn3.bias', tensor([-1.3385e-03, -1.2783e-03,  3.3031e-03, -1.5446e-03, -4.1014e-04,\n",
            "         2.6305e-03,  9.6783e-04,  4.4351e-03,  2.0171e-04,  9.5591e-04,\n",
            "         2.7390e-05,  1.8604e-03,  1.8440e-03,  2.6393e-04,  1.6782e-03,\n",
            "         3.2162e-03,  5.4482e-05, -4.1391e-03,  1.1647e-03, -3.9888e-03,\n",
            "        -2.2544e-03,  2.0662e-03, -2.2751e-04,  1.5852e-03,  1.3379e-03,\n",
            "         9.3340e-04, -4.6752e-04,  4.0513e-04,  2.8434e-04, -7.9762e-04,\n",
            "         9.1580e-04,  1.3928e-03, -8.9876e-04, -1.3938e-03, -3.7872e-03,\n",
            "        -2.7819e-03,  2.3341e-03,  8.5307e-04, -2.9234e-03, -1.4825e-03,\n",
            "         3.1200e-03, -9.2499e-04, -1.5177e-03, -1.0141e-03,  6.4377e-04,\n",
            "         1.6737e-03,  9.4986e-04, -7.3148e-05, -5.9890e-04, -1.2606e-03,\n",
            "        -1.0537e-03,  8.0692e-05, -1.4800e-03,  6.7846e-04, -1.5813e-03,\n",
            "         1.4620e-03,  4.3944e-03,  2.5116e-03, -2.4359e-03,  4.0404e-03,\n",
            "         1.8626e-03, -2.4004e-03,  2.7080e-03, -7.4499e-05,  1.4839e-03,\n",
            "        -2.7700e-03, -1.8934e-03,  1.1285e-03,  3.2967e-03,  4.9414e-04,\n",
            "        -1.1224e-03, -1.7411e-03,  1.2617e-03,  1.0411e-03,  1.4350e-04,\n",
            "         3.4341e-03, -5.8364e-04, -7.6930e-04,  1.9858e-03,  2.8480e-03,\n",
            "         3.0771e-03,  1.7465e-05,  1.8234e-03, -2.6405e-03, -1.6916e-04,\n",
            "        -1.6088e-03,  4.5945e-04,  1.2598e-03, -2.9874e-03,  4.3982e-03,\n",
            "         1.4851e-03, -1.1427e-03, -4.2423e-03,  1.2814e-03, -1.4002e-03,\n",
            "        -3.6925e-03,  2.4583e-03, -1.5000e-03,  1.1137e-03,  1.2803e-03,\n",
            "        -1.3225e-03,  1.4745e-04,  1.1019e-03, -5.5672e-04, -1.8953e-03,\n",
            "        -2.4554e-03, -6.8866e-04, -5.3121e-03,  2.6002e-03,  2.2145e-03,\n",
            "         5.0882e-04, -3.3557e-03, -1.7393e-03, -2.2598e-03,  1.3882e-03,\n",
            "         1.6582e-04,  8.5174e-04,  3.3965e-03,  3.7504e-03, -2.9234e-04,\n",
            "         8.6912e-04, -5.0405e-04, -2.1859e-03,  8.8717e-04,  3.7867e-04,\n",
            "        -2.5436e-03, -4.9679e-03,  5.0549e-03,  4.2505e-03,  5.2743e-04,\n",
            "        -5.1828e-03,  1.1813e-03,  2.9340e-03,  1.6350e-03, -8.1137e-04,\n",
            "         9.5722e-05,  1.2499e-04, -3.5919e-04, -8.4213e-04,  7.8732e-04,\n",
            "         2.1562e-03, -2.2439e-03, -6.6412e-04, -1.2302e-03,  6.9743e-04,\n",
            "         2.7336e-03, -1.3693e-03,  1.6074e-03, -2.7045e-03, -1.2198e-03,\n",
            "         2.1012e-03, -2.1654e-03,  5.9087e-04, -3.2830e-04,  2.7014e-03,\n",
            "        -6.6120e-04, -1.2440e-03, -4.1162e-05,  2.8944e-03, -6.5510e-04,\n",
            "        -1.2840e-03,  1.6678e-04, -5.4215e-03,  2.6318e-05,  5.9569e-04,\n",
            "         8.1196e-04, -4.0277e-03,  1.5214e-03, -1.1306e-04, -2.6162e-03,\n",
            "         2.4685e-03, -1.4663e-03, -1.9434e-03, -3.0581e-03, -1.6604e-03,\n",
            "         2.0776e-03, -1.0902e-03,  1.2926e-03,  3.0987e-03,  2.1322e-03,\n",
            "         2.2219e-05,  2.5532e-04, -2.2457e-03,  6.2683e-04, -1.3223e-03,\n",
            "         1.7865e-03, -2.7136e-03,  3.9180e-04, -1.1536e-03, -9.8201e-05,\n",
            "         2.4903e-03,  1.3177e-03, -5.7822e-04,  1.1023e-03,  1.7373e-03,\n",
            "         2.4905e-03,  3.7637e-04,  1.6739e-03,  3.9055e-03,  1.7804e-03,\n",
            "        -3.8778e-03,  3.3636e-04, -1.5870e-03, -1.5854e-04,  3.1015e-03,\n",
            "         1.1625e-04,  2.0997e-03,  4.3321e-05,  3.0767e-04,  1.4389e-03,\n",
            "        -1.5308e-03, -1.4361e-03,  1.0345e-03, -1.5379e-03,  1.4873e-03,\n",
            "         3.7403e-04,  5.0898e-04, -3.3580e-03, -4.8326e-04, -4.2486e-03,\n",
            "         5.5509e-05, -4.6117e-04, -4.9077e-04,  3.5170e-05, -1.8895e-03,\n",
            "        -2.9508e-03,  1.0680e-03, -7.1850e-04, -2.6640e-04, -8.6350e-04,\n",
            "         9.5934e-04, -2.1061e-03,  2.1130e-04, -6.5234e-04,  2.0344e-04,\n",
            "        -1.1329e-04,  2.1019e-03, -1.7101e-03, -2.8270e-03, -5.1828e-03,\n",
            "         4.8914e-04,  3.7253e-06,  3.8909e-04,  4.0106e-03,  2.6551e-04,\n",
            "        -2.8848e-03, -1.8960e-03, -7.8229e-04,  3.8891e-04,  3.1277e-04,\n",
            "         1.2741e-03, -3.0883e-04,  2.7585e-03,  5.6324e-04,  1.3533e-03,\n",
            "        -3.0407e-03])), ('module.encoder_q.layer1.2.bn3.running_mean', tensor([-1.2599e-01,  1.7398e-02,  2.5998e-02, -1.4131e-02,  4.2390e-01,\n",
            "         1.6107e-01,  2.2148e-01, -6.7246e-04,  3.4531e-01, -1.9475e-01,\n",
            "        -5.2985e-02,  3.7291e-01,  9.7790e-02,  1.4391e-01,  8.7398e-02,\n",
            "         2.7156e-01,  1.9139e-01,  3.3245e-01,  1.8374e-02,  2.6868e-01,\n",
            "        -2.4553e-01,  2.3975e-01,  5.3297e-02,  2.8535e-01,  3.7010e-01,\n",
            "        -2.3479e-01, -9.4415e-02,  3.2562e-01,  4.4752e-02, -3.4801e-01,\n",
            "         3.0582e-02, -7.8924e-02,  1.3021e-01, -3.0096e-01,  6.4531e-01,\n",
            "         3.2019e-02,  2.1422e-02, -2.1451e-02,  1.3371e-01,  1.0299e-01,\n",
            "        -2.5093e-01,  3.2897e-01,  2.2450e-01, -3.4503e-01,  2.6939e-01,\n",
            "        -3.8254e-01,  2.4538e-01, -3.2032e-01, -2.9411e-01, -4.4398e-02,\n",
            "         2.8069e-01, -1.0191e-01,  1.4211e-01,  9.0180e-02, -5.5396e-02,\n",
            "        -6.0601e-02,  1.3390e-01,  2.7008e-01,  9.0125e-02, -6.1276e-02,\n",
            "         1.3360e-01, -1.2684e-01, -1.8986e-01, -6.4458e-02, -3.9502e-01,\n",
            "         2.8078e-01, -2.4290e-01, -2.2578e-01, -5.3971e-02, -3.1875e-01,\n",
            "        -7.5771e-01, -2.7841e-01,  6.1069e-02,  2.7580e-01,  2.9645e-01,\n",
            "        -1.2551e-01,  4.4915e-01,  4.7765e-01, -2.7687e-02,  1.0990e-01,\n",
            "        -6.3679e-03, -3.5654e-01, -1.1247e-01,  1.4566e-01,  9.6993e-02,\n",
            "         2.6391e-01, -1.5159e-01, -2.0777e-01,  1.5806e-01,  2.0744e-02,\n",
            "         5.5445e-01, -1.8504e-01, -3.5846e-01, -2.0135e-01,  1.9029e-01,\n",
            "         1.4030e-01,  1.3039e-01, -7.2748e-02,  1.5959e-01,  1.7228e-01,\n",
            "         1.1789e-01,  3.7060e-01,  1.0263e-01,  5.3818e-01,  8.1410e-02,\n",
            "         4.1356e-02, -8.4918e-02,  1.9126e-01, -4.2274e-02, -1.1560e-01,\n",
            "        -5.4304e-02,  3.0123e-01,  2.7890e-01, -1.1795e-02,  3.8901e-02,\n",
            "         2.3170e-02, -2.5524e-01, -1.5623e-01,  2.2782e-01, -4.6394e-01,\n",
            "        -2.5175e-01, -7.5854e-02, -4.9100e-02, -3.4506e-01,  4.1451e-02,\n",
            "        -1.2157e-01, -1.1470e-01,  2.6477e-01, -2.0005e-02,  6.4165e-02,\n",
            "         1.4637e-01,  3.6412e-01, -1.3480e-01,  4.4641e-01, -1.4593e-01,\n",
            "         1.1349e-01,  3.6354e-01,  2.6319e-01, -1.2139e-01,  2.3625e-03,\n",
            "         7.5670e-02, -6.0665e-01, -2.8543e-01, -1.4955e-01,  1.8703e-01,\n",
            "         9.0660e-02, -1.4970e-01,  4.3043e-01, -3.4119e-01, -2.4832e-01,\n",
            "        -1.2289e-01, -3.9557e-01, -1.9549e-01,  1.0616e-01,  2.6531e-01,\n",
            "        -1.4474e-01, -1.6187e-01,  3.8690e-01, -2.2586e-01, -1.1743e-01,\n",
            "         1.9913e-01,  1.1329e-01,  2.0431e-01, -9.6410e-02,  3.0973e-01,\n",
            "        -1.9920e-01, -3.5214e-01, -3.2179e-01, -1.2146e-01, -1.3622e-01,\n",
            "        -4.6951e-01, -7.6655e-02, -4.1508e-02,  3.7714e-01, -5.0038e-02,\n",
            "        -2.3033e-01,  6.1437e-02,  2.3318e-02,  2.4306e-01,  3.9445e-01,\n",
            "         4.5463e-01, -5.1225e-02, -4.7976e-01, -8.6485e-02,  4.7787e-01,\n",
            "        -4.9672e-02,  1.5486e-01,  8.4394e-02, -1.5230e-01, -1.6567e-01,\n",
            "        -2.9587e-01,  1.0778e-01,  5.8308e-01,  1.6165e-01, -3.5085e-02,\n",
            "         3.4392e-01,  3.6267e-01,  3.7110e-02,  3.9372e-02, -1.2604e-01,\n",
            "        -1.2647e-01,  1.6782e-01, -1.1214e-01, -3.2635e-01, -1.5589e-01,\n",
            "        -3.1192e-02, -1.9045e-01,  4.0640e-01, -4.5012e-01,  5.0325e-01,\n",
            "         9.9778e-02,  3.2251e-01, -1.9786e-01,  5.3277e-03,  7.1893e-02,\n",
            "         8.1388e-03, -2.0185e-02,  5.4426e-02, -3.2675e-01, -6.0464e-02,\n",
            "         1.8305e-01,  4.3146e-02, -3.0558e-01, -1.5009e-02, -2.1354e-01,\n",
            "        -6.1026e-02, -3.7101e-01,  4.8769e-01, -3.5956e-03,  1.1328e-01,\n",
            "         5.9686e-02, -2.8281e-01, -1.4349e-01,  9.7199e-02, -1.2700e-01,\n",
            "        -4.0491e-02,  3.0347e-01, -1.2480e-01,  2.4930e-01, -1.6191e-01,\n",
            "         1.0363e-02,  5.5824e-01, -3.9689e-01,  3.9534e-02, -1.6509e-01,\n",
            "         2.2753e-01, -3.6632e-01,  1.9297e-02,  6.7524e-01, -5.3159e-01,\n",
            "         3.9908e-01, -6.8825e-01, -2.7997e-01, -2.6324e-01,  5.8704e-02,\n",
            "         3.8127e-02])), ('module.encoder_q.layer1.2.bn3.running_var', tensor([0.1385, 0.0957, 0.1786, 0.0704, 0.3070, 0.2036, 0.1897, 0.1436, 0.1250,\n",
            "        0.1488, 0.1882, 0.1940, 0.1377, 0.1287, 0.2833, 0.3247, 0.1708, 0.3180,\n",
            "        0.2960, 0.1793, 0.3978, 0.2555, 0.2747, 0.2424, 0.2044, 0.1439, 0.1197,\n",
            "        0.0974, 0.1769, 0.4748, 0.2796, 0.1806, 0.1106, 0.1127, 0.6467, 0.1464,\n",
            "        0.1660, 0.1225, 0.2079, 0.1144, 0.2943, 0.2801, 0.2394, 0.5190, 0.1233,\n",
            "        0.2909, 0.2200, 0.0997, 0.1050, 0.2220, 0.1861, 0.1587, 0.1273, 0.1705,\n",
            "        0.3537, 0.2268, 0.3520, 0.1408, 0.2143, 0.1909, 0.2430, 0.2115, 0.2185,\n",
            "        0.1181, 0.2417, 0.2362, 0.2508, 0.2260, 0.0974, 0.1859, 0.1127, 0.1842,\n",
            "        0.1183, 0.1915, 0.2325, 0.2860, 0.1317, 0.2141, 0.1599, 0.2886, 0.1686,\n",
            "        0.2440, 0.1144, 0.1359, 0.1727, 0.2322, 0.2362, 0.2070, 0.2597, 0.0842,\n",
            "        0.3105, 0.2012, 0.3023, 0.1271, 0.1526, 0.2292, 0.3501, 0.1117, 0.2113,\n",
            "        0.1318, 0.1079, 0.1875, 0.1636, 0.4663, 0.2225, 0.3494, 0.1967, 0.1501,\n",
            "        0.3086, 0.1880, 0.1656, 0.1674, 0.2110, 0.2512, 0.2383, 0.1567, 0.1481,\n",
            "        0.2188, 0.1705, 0.1513, 0.2424, 0.1719, 0.1521, 0.1751, 0.2325, 0.1324,\n",
            "        0.2036, 0.3571, 0.1360, 0.2019, 0.1654, 0.2465, 0.1313, 0.2807, 0.3546,\n",
            "        0.2119, 0.1683, 0.2500, 0.1984, 0.1987, 0.1920, 0.2564, 0.1557, 0.1613,\n",
            "        0.1635, 0.3233, 0.2066, 0.1511, 0.2789, 0.1051, 0.1939, 0.2754, 0.2054,\n",
            "        0.2179, 0.1371, 0.4572, 0.0767, 0.1175, 0.1758, 0.1899, 0.2991, 0.1081,\n",
            "        0.1624, 0.1544, 0.1020, 0.1915, 0.2419, 0.1054, 0.0896, 0.4195, 0.2655,\n",
            "        0.2344, 0.2516, 0.1285, 0.0995, 0.1497, 0.1072, 0.1529, 0.0608, 0.2644,\n",
            "        0.2058, 0.2087, 0.1859, 0.1537, 0.2198, 0.1477, 0.2391, 0.1742, 0.4080,\n",
            "        0.0944, 0.0794, 0.1735, 0.5717, 0.1205, 0.1929, 0.1686, 0.1207, 0.1608,\n",
            "        0.2126, 0.1206, 0.1882, 0.5619, 0.4244, 0.2481, 0.1583, 0.1712, 0.1294,\n",
            "        0.2270, 0.2651, 0.5453, 0.1256, 0.3355, 0.1465, 0.0897, 0.1983, 0.2501,\n",
            "        0.1878, 0.1388, 0.2625, 0.1945, 0.2164, 0.2107, 0.1949, 0.1680, 0.2239,\n",
            "        0.1991, 0.2393, 0.1581, 0.0832, 0.2088, 0.1522, 0.2128, 0.1252, 0.1844,\n",
            "        0.1185, 0.2288, 0.3973, 0.1939, 0.4857, 0.3266, 0.1498, 0.2005, 0.1577,\n",
            "        0.0968, 0.1032, 0.2817, 0.3983, 0.2568, 0.2618, 0.3069, 0.1624, 0.1262,\n",
            "        0.1714, 0.0539, 0.1970, 0.2209])), ('module.encoder_q.layer1.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.0.conv1.weight', tensor([[[[-0.0018]],\n",
            "\n",
            "         [[ 0.0927]],\n",
            "\n",
            "         [[ 0.0598]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0358]],\n",
            "\n",
            "         [[ 0.0643]],\n",
            "\n",
            "         [[ 0.0782]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1971]],\n",
            "\n",
            "         [[ 0.2823]],\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0732]],\n",
            "\n",
            "         [[-0.1717]],\n",
            "\n",
            "         [[ 0.0646]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0662]],\n",
            "\n",
            "         [[-0.0410]],\n",
            "\n",
            "         [[-0.0804]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1051]],\n",
            "\n",
            "         [[-0.1438]],\n",
            "\n",
            "         [[-0.1355]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.2648]],\n",
            "\n",
            "         [[-0.0827]],\n",
            "\n",
            "         [[ 0.1343]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0580]],\n",
            "\n",
            "         [[ 0.0321]],\n",
            "\n",
            "         [[ 0.1374]]],\n",
            "\n",
            "\n",
            "        [[[-0.1402]],\n",
            "\n",
            "         [[ 0.0071]],\n",
            "\n",
            "         [[-0.1337]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1894]],\n",
            "\n",
            "         [[-0.1396]],\n",
            "\n",
            "         [[-0.0316]]],\n",
            "\n",
            "\n",
            "        [[[-0.0798]],\n",
            "\n",
            "         [[-0.1090]],\n",
            "\n",
            "         [[ 0.0078]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0302]],\n",
            "\n",
            "         [[-0.0874]],\n",
            "\n",
            "         [[ 0.1092]]]])), ('module.encoder_q.layer2.0.bn1.weight', tensor([0.9887, 0.9949, 0.9941, 0.9957, 0.9959, 0.9901, 0.9986, 0.9966, 0.9895,\n",
            "        0.9970, 0.9871, 0.9948, 0.9837, 0.9977, 0.9864, 0.9918, 0.9963, 0.9964,\n",
            "        0.9953, 0.9929, 0.9932, 0.9906, 0.9946, 0.9967, 0.9967, 0.9954, 0.9880,\n",
            "        0.9924, 0.9864, 0.9926, 0.9880, 0.9963, 0.9914, 0.9930, 0.9970, 0.9933,\n",
            "        0.9973, 0.9906, 0.9969, 0.9908, 0.9869, 0.9914, 0.9834, 0.9975, 0.9945,\n",
            "        0.9855, 0.9886, 0.9898, 0.9918, 0.9915, 0.9961, 0.9970, 0.9941, 0.9846,\n",
            "        0.9902, 0.9930, 0.9933, 0.9915, 0.9972, 0.9858, 0.9853, 1.0001, 1.0036,\n",
            "        0.9885, 0.9874, 0.9913, 0.9861, 0.9931, 0.9903, 1.0009, 0.9907, 0.9923,\n",
            "        0.9962, 0.9985, 0.9980, 0.9923, 0.9881, 0.9869, 0.9953, 0.9948, 0.9952,\n",
            "        0.9986, 0.9953, 0.9953, 0.9898, 0.9899, 0.9987, 0.9867, 0.9909, 0.9925,\n",
            "        0.9936, 0.9928, 0.9888, 0.9921, 0.9892, 0.9917, 0.9949, 0.9899, 0.9970,\n",
            "        0.9922, 0.9902, 0.9968, 0.9819, 0.9898, 0.9979, 0.9931, 0.9874, 0.9919,\n",
            "        0.9855, 0.9823, 0.9924, 0.9901, 0.9928, 0.9892, 1.0078, 0.9906, 0.9875,\n",
            "        0.9865, 0.9955, 0.9899, 0.9971, 0.9773, 0.9855, 0.9881, 0.9878, 0.9944,\n",
            "        1.0000, 0.9969])), ('module.encoder_q.layer2.0.bn1.bias', tensor([-9.8875e-04,  9.6781e-04,  4.8715e-03,  7.8908e-03,  1.8045e-03,\n",
            "         2.3539e-03,  1.5963e-03, -6.9224e-04,  3.2061e-03,  1.6833e-03,\n",
            "        -2.7987e-03,  3.8614e-03, -5.4629e-03,  3.4071e-03, -3.3997e-03,\n",
            "         7.2668e-03, -1.8820e-03, -1.5941e-03, -1.2954e-03,  5.6280e-03,\n",
            "         4.3370e-03, -2.6206e-03,  4.9022e-03, -3.7590e-04,  1.7692e-03,\n",
            "        -5.0413e-05, -8.0046e-03,  4.6033e-03,  3.1957e-03,  6.2646e-03,\n",
            "        -9.5928e-04,  4.0907e-03,  3.5274e-03, -5.4406e-03,  5.3052e-03,\n",
            "         4.8167e-03,  6.8970e-03, -2.2313e-03,  2.6708e-03, -2.2604e-04,\n",
            "        -7.1336e-03,  1.7707e-03, -6.6866e-03, -3.9728e-03, -6.8363e-04,\n",
            "        -3.3543e-03,  1.1575e-03, -6.0834e-04,  3.6269e-03,  6.1452e-04,\n",
            "         7.9781e-03,  4.8059e-03, -5.6511e-04, -5.5197e-03, -8.4586e-05,\n",
            "         9.9262e-04, -2.9261e-03, -4.1909e-03,  4.4526e-03,  1.9503e-03,\n",
            "        -6.1333e-03,  5.7235e-03,  1.1489e-03, -2.7311e-03,  1.9570e-03,\n",
            "         8.5776e-04, -6.3960e-03,  1.5079e-03, -1.4799e-04,  2.3641e-03,\n",
            "        -6.3190e-04,  2.1424e-03,  1.2902e-03,  6.4715e-03,  9.8154e-03,\n",
            "         2.8159e-03, -1.5100e-03,  4.6064e-03,  1.0743e-02, -5.6684e-04,\n",
            "         2.9059e-03,  2.6866e-03, -4.0808e-04,  2.0965e-03,  6.0735e-04,\n",
            "        -6.7216e-04,  7.0258e-03, -7.7664e-04, -2.6489e-03, -1.4344e-03,\n",
            "        -3.3792e-03,  1.2552e-03, -6.7842e-03, -6.3924e-04,  3.9384e-03,\n",
            "        -4.3282e-03, -2.4373e-03, -2.8444e-03,  5.1271e-03,  2.8873e-03,\n",
            "        -4.8171e-05,  2.7954e-03, -8.2701e-04,  3.0166e-03,  3.6766e-03,\n",
            "         4.1291e-03, -2.8875e-03,  2.0538e-03, -5.9879e-04, -8.0830e-03,\n",
            "         6.1433e-03,  9.7517e-05,  3.2960e-03, -1.1001e-02,  5.1692e-03,\n",
            "        -9.2990e-04, -4.6107e-03,  8.8077e-04,  1.6173e-03, -3.2328e-03,\n",
            "         3.5015e-03, -1.1295e-02, -9.1820e-03, -4.8552e-03, -2.8665e-03,\n",
            "        -6.3733e-04,  3.8120e-03,  6.0960e-03])), ('module.encoder_q.layer2.0.bn1.running_mean', tensor([ 5.2833e-01,  2.6401e+00, -1.2032e+00,  1.9288e+00,  2.3014e+00,\n",
            "        -1.5754e-01, -4.8332e+00, -6.8415e-01,  2.1647e+00,  1.5574e+00,\n",
            "         1.9536e+00, -2.6720e+00,  1.0221e+00,  5.0393e+00, -2.8291e+00,\n",
            "        -2.1188e-01,  1.1076e+00, -1.5542e+00,  3.1607e+00, -9.4431e-01,\n",
            "        -1.8532e+00, -5.9156e+00, -4.8573e+00,  1.0896e+00, -4.0066e-01,\n",
            "         2.2633e+00, -1.9739e+00,  3.5643e+00, -2.1707e+00, -1.4427e+00,\n",
            "         2.9399e+00,  2.6408e+00, -2.0986e+00,  1.1259e+00,  9.8800e-01,\n",
            "        -3.5253e+00,  2.4424e+00, -3.2148e-01,  1.7837e+00, -3.5115e+00,\n",
            "        -1.4438e+00,  4.2616e-01,  1.7713e+00, -2.9766e+00, -1.9488e+00,\n",
            "         9.4929e-01,  1.6741e+00,  1.6162e+00, -1.8919e+00, -5.6857e-03,\n",
            "        -2.2563e+00, -3.0864e-01, -4.7388e-02,  3.7572e-01, -2.1230e+00,\n",
            "        -4.4716e+00, -2.6870e+00,  3.2807e+00, -3.0049e+00,  5.2728e+00,\n",
            "         3.5350e+00,  2.6423e+00,  3.7427e+00,  4.2468e+00, -3.2058e-01,\n",
            "        -4.3383e-01,  3.8911e+00,  7.2674e-01, -1.0415e+00,  1.2824e+00,\n",
            "         9.2695e-01,  2.0746e+00,  1.7651e+00,  3.6265e-01, -4.6151e-01,\n",
            "        -1.7205e+00,  1.9881e+00,  2.1236e+00,  1.1201e+00, -6.6262e-01,\n",
            "        -1.7925e+00, -1.2185e+00,  1.6006e+00, -4.3768e-01, -1.4666e+00,\n",
            "        -1.2098e+00,  7.3340e-01,  1.8800e+00, -1.5793e+00,  2.2846e+00,\n",
            "        -4.9784e-01, -1.5717e-01,  1.4719e+00, -1.0899e+00,  7.7277e-01,\n",
            "        -2.5460e+00,  1.1587e+00,  3.9149e-01,  9.2855e-01, -2.7322e+00,\n",
            "        -2.0129e+00, -1.4338e+00, -9.4133e-02,  8.5281e-01,  2.1442e+00,\n",
            "        -1.0093e-01, -3.9038e+00,  8.1675e-02,  1.7194e+00,  1.5955e+00,\n",
            "        -3.3451e+00, -1.5964e+00,  1.1737e+00, -3.1459e+00,  2.4437e+00,\n",
            "        -6.4587e-01,  9.2109e-01, -3.3568e-01, -1.6618e+00, -1.6822e+00,\n",
            "        -3.3369e+00,  1.0522e+00,  1.3407e+00,  2.7573e+00, -1.2521e+00,\n",
            "         4.0963e-01,  1.8867e-01,  2.3552e+00])), ('module.encoder_q.layer2.0.bn1.running_var', tensor([ 7.0456,  9.3562,  6.0392,  7.6169, 11.6699,  4.9316,  5.1072,  4.4022,\n",
            "         7.3644, 10.8958,  6.6938,  9.4290,  5.7924,  7.9199, 10.0517,  3.8175,\n",
            "         9.4950,  4.1614,  7.2657,  5.5744,  5.8232, 21.5866, 17.8922, 10.8970,\n",
            "         8.3395,  5.0271, 10.0967,  8.6193,  8.3189, 17.3546,  6.8785,  9.9707,\n",
            "         6.8846,  4.5955,  5.3205, 12.2538, 12.5243,  9.4947,  9.7673,  7.0559,\n",
            "        10.8436,  8.0604,  4.3943,  5.9111,  6.5694,  5.4650,  3.9105,  4.5940,\n",
            "         4.8803,  4.8594,  9.0565,  4.1337,  3.9822,  4.1797,  8.0079, 12.2724,\n",
            "        17.5618, 12.7417,  8.7493,  5.4775,  5.6702,  8.4558, 13.4219, 13.2376,\n",
            "         7.8016,  3.7926, 15.7991,  4.5901,  7.9945,  9.6482,  4.1639,  7.2839,\n",
            "         7.6140,  5.7745,  3.7963,  8.6082, 15.6538,  4.8995,  4.8644,  4.4715,\n",
            "         3.1525,  8.0847, 10.8312,  6.1048,  7.0015,  5.8153,  9.9537,  6.9871,\n",
            "         8.9879, 13.7811,  4.6404,  6.4501,  5.6648,  4.6160,  7.7575,  4.1056,\n",
            "         5.3890,  6.8357,  8.8413,  1.9757,  6.3327,  5.4111,  8.2029,  5.7383,\n",
            "         9.1586,  5.5425,  5.1304, 12.1181,  3.3482,  9.0151, 10.2855,  4.3653,\n",
            "         3.8652,  6.1445,  5.5537,  4.9977,  8.2903, 14.4045,  6.3863,  5.7968,\n",
            "        13.3070,  5.8418,  7.7433,  5.5251,  5.1634,  6.1018,  3.3476,  9.3661])), ('module.encoder_q.layer2.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.0.conv2.weight', tensor([[[[-8.3708e-02,  2.1404e-02,  6.8469e-02],\n",
            "          [-4.1951e-05, -2.8076e-02,  5.1784e-02],\n",
            "          [-9.9446e-02,  4.5946e-03, -6.1897e-03]],\n",
            "\n",
            "         [[-2.9497e-04, -3.4992e-02,  3.5173e-02],\n",
            "          [ 4.0073e-02, -3.8016e-02, -1.9580e-02],\n",
            "          [ 5.0556e-02, -2.1077e-02, -1.6568e-02]],\n",
            "\n",
            "         [[ 2.2483e-02, -2.4014e-02, -4.5875e-02],\n",
            "          [-3.6842e-02,  2.6385e-02, -1.1540e-03],\n",
            "          [ 1.3561e-02, -4.6479e-02,  3.4401e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.4985e-03,  5.1914e-03, -1.7318e-02],\n",
            "          [ 2.2280e-02, -6.5812e-02,  3.4767e-02],\n",
            "          [ 5.8243e-03,  5.2090e-02, -8.4771e-02]],\n",
            "\n",
            "         [[-7.6398e-03, -3.7926e-02, -1.0338e-02],\n",
            "          [-2.3776e-02, -4.8330e-02, -3.7469e-02],\n",
            "          [ 1.9347e-02, -4.7307e-03, -6.2397e-02]],\n",
            "\n",
            "         [[-5.3100e-02,  2.9874e-03,  4.3456e-02],\n",
            "          [ 4.0486e-02,  2.3818e-03, -3.7098e-03],\n",
            "          [ 4.0806e-02,  1.4852e-02,  7.7311e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6776e-02, -1.7761e-02,  3.7267e-02],\n",
            "          [ 6.4790e-03,  3.4228e-02,  2.4968e-02],\n",
            "          [ 3.8626e-02,  7.2204e-02,  3.6775e-02]],\n",
            "\n",
            "         [[ 1.7604e-02, -1.2102e-01, -4.2581e-02],\n",
            "          [ 6.1307e-02,  4.9498e-02, -2.8118e-02],\n",
            "          [ 4.6486e-02, -3.1932e-02, -9.4294e-03]],\n",
            "\n",
            "         [[ 4.9289e-02, -2.1703e-02, -2.0266e-02],\n",
            "          [ 6.5756e-02,  6.3061e-02, -7.6341e-03],\n",
            "          [ 1.1906e-02, -3.6371e-02, -3.0832e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1605e-02,  3.7262e-03,  3.0270e-02],\n",
            "          [-5.2378e-02, -3.6591e-02,  4.6219e-02],\n",
            "          [ 4.9839e-02,  1.0102e-01,  4.0314e-03]],\n",
            "\n",
            "         [[-4.8735e-03, -1.0845e-02, -4.2425e-02],\n",
            "          [ 2.1137e-02, -3.5458e-02,  1.2477e-01],\n",
            "          [ 5.9500e-02,  5.9437e-02, -5.7226e-02]],\n",
            "\n",
            "         [[-4.4099e-02,  2.7610e-03,  2.1221e-02],\n",
            "          [-6.1120e-02, -3.1141e-02,  2.9963e-03],\n",
            "          [ 4.4566e-02,  5.2645e-02,  8.3534e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7205e-02,  8.9610e-03,  6.5208e-02],\n",
            "          [-5.0023e-02, -8.5744e-03, -2.5279e-02],\n",
            "          [ 1.7301e-02,  1.1980e-02,  4.1048e-02]],\n",
            "\n",
            "         [[-3.0025e-03, -6.8032e-02, -1.7953e-02],\n",
            "          [-1.8614e-02, -3.2737e-02,  6.4519e-02],\n",
            "          [-2.1168e-02, -1.8766e-02,  1.5959e-02]],\n",
            "\n",
            "         [[-5.0596e-02, -4.8508e-02, -4.9303e-03],\n",
            "          [ 4.6865e-02, -2.3709e-02, -6.1310e-02],\n",
            "          [ 1.1502e-01,  3.0014e-02, -1.5247e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.6792e-03,  4.0011e-02,  2.0394e-02],\n",
            "          [-2.9899e-03, -4.3475e-02, -1.4942e-02],\n",
            "          [ 1.4701e-02,  3.3729e-02, -1.6051e-02]],\n",
            "\n",
            "         [[ 2.2695e-02, -5.5446e-02,  2.2075e-02],\n",
            "          [-2.1921e-02,  3.1349e-02, -3.2281e-02],\n",
            "          [-5.1459e-02, -1.9835e-02, -3.7869e-02]],\n",
            "\n",
            "         [[ 2.5065e-02, -3.1134e-02, -2.5314e-02],\n",
            "          [ 2.0134e-02, -3.2111e-02,  2.1114e-02],\n",
            "          [-2.5059e-02, -3.5186e-03, -1.4984e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2939e-02,  3.1934e-02, -4.4590e-02],\n",
            "          [-1.4321e-02,  3.1942e-02,  1.5136e-02],\n",
            "          [ 4.2451e-02, -6.3497e-03, -2.3846e-02]],\n",
            "\n",
            "         [[ 3.3154e-03,  1.1239e-02,  1.4912e-02],\n",
            "          [-2.7783e-02, -2.9019e-02, -3.7985e-03],\n",
            "          [ 5.2388e-04, -6.8834e-03,  9.2030e-02]],\n",
            "\n",
            "         [[-2.7531e-02, -4.9406e-02, -5.0891e-03],\n",
            "          [-6.4192e-02,  3.5056e-02,  6.3264e-02],\n",
            "          [ 1.9538e-02, -4.0242e-02, -1.3368e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.0982e-03, -5.5763e-02, -1.7149e-02],\n",
            "          [ 3.7191e-02,  1.8010e-02, -3.7386e-02],\n",
            "          [ 1.1918e-02,  2.1002e-02, -2.4018e-02]],\n",
            "\n",
            "         [[-2.1456e-02, -1.9927e-02,  2.0353e-02],\n",
            "          [-5.9037e-02,  9.6503e-02,  2.1958e-02],\n",
            "          [ 1.2669e-02,  1.0916e-01,  9.8032e-03]],\n",
            "\n",
            "         [[ 1.1704e-02,  3.6796e-02,  5.3634e-02],\n",
            "          [ 4.0035e-02,  7.0403e-02,  3.6970e-02],\n",
            "          [ 1.7179e-02, -4.6238e-02,  4.7817e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.4936e-02, -1.1299e-02, -3.8937e-04],\n",
            "          [-4.3830e-02,  1.4101e-02, -5.6765e-02],\n",
            "          [-3.1348e-02,  3.2641e-02, -4.0152e-02]],\n",
            "\n",
            "         [[-5.2763e-03, -5.4573e-02, -1.0462e-02],\n",
            "          [-3.2918e-04,  1.7189e-02, -3.7509e-03],\n",
            "          [ 7.4657e-02, -2.1032e-02,  2.7819e-03]],\n",
            "\n",
            "         [[-2.5795e-02,  3.1611e-03,  3.2334e-02],\n",
            "          [-4.7940e-03,  3.4777e-02, -3.2057e-02],\n",
            "          [-2.9674e-02,  2.4787e-02,  4.8869e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7381e-02, -3.7062e-02,  7.7139e-03],\n",
            "          [ 1.9055e-02,  3.1675e-02,  3.5967e-02],\n",
            "          [-5.6598e-02, -9.7453e-03,  1.7030e-02]],\n",
            "\n",
            "         [[ 5.3043e-02,  2.1620e-02, -1.1138e-02],\n",
            "          [-1.5877e-03, -3.9257e-03,  7.3589e-02],\n",
            "          [-4.6246e-02,  3.5467e-03,  8.4569e-03]],\n",
            "\n",
            "         [[-7.5493e-03,  9.2088e-02, -3.0527e-02],\n",
            "          [ 2.3004e-02,  2.7014e-02, -5.7852e-02],\n",
            "          [ 9.4538e-02,  7.1846e-02, -7.2305e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.1670e-04, -7.2733e-02, -5.5675e-02],\n",
            "          [ 1.3413e-02, -2.0183e-02,  3.8207e-02],\n",
            "          [-6.3618e-02, -3.4898e-03, -1.0505e-01]],\n",
            "\n",
            "         [[ 1.0622e-03, -2.8338e-04,  2.0012e-02],\n",
            "          [ 4.3075e-02, -5.9145e-02,  4.1679e-02],\n",
            "          [ 2.0960e-02,  4.5575e-02, -2.9374e-02]],\n",
            "\n",
            "         [[-4.5418e-03, -4.0144e-02, -4.8289e-02],\n",
            "          [-8.0988e-02,  4.9983e-02,  2.2661e-02],\n",
            "          [-2.8676e-02,  2.3473e-02,  8.1397e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8206e-02, -5.4182e-02, -3.3995e-02],\n",
            "          [ 7.9677e-03, -2.7655e-02,  3.3439e-02],\n",
            "          [ 5.9790e-03,  1.0817e-01,  4.6474e-02]],\n",
            "\n",
            "         [[ 3.6862e-02, -6.0852e-03, -6.0841e-02],\n",
            "          [-4.2524e-02, -3.4956e-02,  3.3905e-02],\n",
            "          [-1.1719e-02, -1.0826e-02, -8.2042e-02]],\n",
            "\n",
            "         [[ 4.4976e-02,  2.7819e-02,  2.1389e-02],\n",
            "          [-3.4969e-03,  7.8467e-02, -5.0634e-02],\n",
            "          [-5.0494e-02, -1.3503e-03,  1.8495e-02]]]])), ('module.encoder_q.layer2.0.bn2.weight', tensor([0.9952, 0.9948, 0.9857, 0.9832, 0.9872, 0.9938, 0.9895, 0.9939, 0.9962,\n",
            "        0.9872, 0.9950, 0.9914, 0.9870, 0.9914, 0.9918, 0.9965, 0.9920, 0.9826,\n",
            "        0.9885, 0.9864, 0.9913, 0.9950, 0.9860, 0.9949, 0.9988, 0.9917, 1.0012,\n",
            "        0.9969, 0.9982, 0.9954, 0.9945, 0.9915, 0.9861, 0.9939, 0.9931, 0.9911,\n",
            "        1.0010, 0.9916, 0.9913, 0.9950, 0.9972, 0.9920, 0.9952, 0.9935, 0.9834,\n",
            "        0.9917, 0.9905, 0.9961, 0.9933, 0.9965, 0.9921, 0.9872, 0.9964, 0.9957,\n",
            "        0.9942, 0.9866, 0.9938, 1.0004, 0.9954, 0.9879, 0.9910, 0.9913, 0.9900,\n",
            "        0.9882, 0.9881, 0.9957, 0.9986, 0.9827, 0.9910, 0.9848, 1.0027, 0.9972,\n",
            "        0.9855, 0.9988, 0.9907, 0.9907, 0.9906, 0.9901, 0.9963, 0.9932, 0.9897,\n",
            "        0.9938, 0.9882, 0.9908, 0.9908, 0.9856, 1.0003, 0.9891, 0.9954, 0.9900,\n",
            "        0.9934, 0.9896, 1.0031, 0.9843, 0.9960, 0.9917, 0.9932, 0.9948, 0.9920,\n",
            "        0.9944, 0.9935, 0.9906, 0.9901, 0.9886, 0.9945, 0.9897, 0.9905, 0.9968,\n",
            "        0.9884, 0.9938, 0.9946, 1.0011, 0.9908, 0.9850, 0.9904, 0.9955, 0.9924,\n",
            "        0.9901, 0.9880, 0.9964, 0.9906, 0.9862, 0.9888, 0.9984, 0.9895, 0.9980,\n",
            "        1.0007, 0.9860])), ('module.encoder_q.layer2.0.bn2.bias', tensor([ 9.4277e-03,  2.7715e-03, -4.7450e-03, -3.6046e-03, -8.8219e-04,\n",
            "        -4.1913e-03,  5.4700e-04, -9.5249e-04,  7.2407e-04, -5.8183e-03,\n",
            "         7.1287e-03,  1.5944e-03,  4.5640e-03,  5.8358e-05, -2.4946e-03,\n",
            "        -1.7434e-03, -2.3910e-03, -4.1093e-03, -2.5821e-03, -2.3224e-03,\n",
            "         1.0264e-03,  1.2143e-04, -7.3586e-03, -3.6884e-03,  3.1546e-03,\n",
            "        -3.0643e-03,  6.5797e-03,  2.5679e-03,  4.0194e-03,  4.4911e-03,\n",
            "         1.5670e-03, -4.2168e-03, -2.5561e-03,  3.7524e-03,  3.4113e-03,\n",
            "        -1.0964e-03,  1.0746e-02, -1.6975e-03, -1.4627e-03,  2.2344e-03,\n",
            "         1.1599e-03,  3.7995e-03,  6.9276e-03,  3.1608e-03, -8.6190e-03,\n",
            "        -1.9971e-03, -7.3228e-04,  1.9253e-03,  2.3814e-03, -3.5012e-03,\n",
            "        -8.3495e-04,  9.0850e-04,  4.2189e-03,  4.9489e-03,  3.5827e-03,\n",
            "         2.0312e-03, -1.8586e-03,  6.1603e-03,  7.0998e-03, -7.4780e-03,\n",
            "        -3.6778e-04, -5.1932e-03,  3.5574e-03, -2.6299e-03, -7.2653e-04,\n",
            "         3.2006e-03,  2.8882e-03, -6.7280e-03,  4.3498e-03, -7.9905e-03,\n",
            "         6.6150e-03,  1.1361e-03, -2.6855e-03,  6.2572e-03, -1.3433e-03,\n",
            "        -5.4037e-03,  1.7507e-03, -1.5165e-03, -7.3501e-04,  2.8648e-03,\n",
            "        -1.5285e-03, -4.8236e-04, -2.9602e-03, -4.3762e-03, -2.1888e-03,\n",
            "        -3.1819e-03,  5.1895e-03, -1.7070e-03, -1.9221e-03, -1.2794e-03,\n",
            "        -2.3636e-03, -2.5598e-03,  5.2079e-03, -5.4756e-03,  5.4909e-03,\n",
            "         9.6384e-04,  2.8132e-03,  2.7238e-03, -1.9060e-03, -6.0098e-04,\n",
            "        -7.8304e-04,  9.6729e-04, -2.6166e-03, -2.9196e-03,  2.6666e-03,\n",
            "         2.2210e-05,  7.9437e-04,  4.9515e-03, -3.5951e-03,  3.3108e-03,\n",
            "         3.5893e-03,  6.1189e-03,  1.7214e-03, -1.9057e-03,  6.6363e-04,\n",
            "         4.4622e-03, -2.2213e-03, -4.6969e-03, -3.3656e-03,  4.7638e-03,\n",
            "        -3.4643e-03, -4.7111e-03, -4.8300e-04,  2.1947e-03, -1.7936e-03,\n",
            "         1.1147e-03,  5.5879e-03, -5.4868e-03])), ('module.encoder_q.layer2.0.bn2.running_mean', tensor([-0.6877, -0.8990, -0.8736,  0.9011, -0.6625, -0.1188, -0.0302, -0.0038,\n",
            "         0.3149, -0.2400, -0.3440,  0.3752, -0.9697, -0.3060, -0.6021, -0.2304,\n",
            "         0.5268,  0.6819, -0.6253, -0.2680, -0.6358, -1.0212,  0.4518, -0.5333,\n",
            "        -0.2319,  0.2821, -0.0163, -0.3358,  0.0985, -0.2578,  0.0805,  0.2231,\n",
            "         0.0622, -0.6263, -0.6780, -1.0018, -0.0250, -0.1147,  0.7506, -0.9734,\n",
            "         0.4254, -0.8889,  0.0247, -0.1348, -0.6403,  0.8370, -0.0613, -0.1845,\n",
            "        -0.9637, -0.5329,  0.3143, -0.1874,  0.5918,  0.1568,  0.2390, -1.0668,\n",
            "         0.1486,  0.1833, -0.5800, -0.7415,  0.8673,  0.6115,  0.1799, -0.3777,\n",
            "        -1.3348, -1.2779,  0.8703,  0.7901, -0.4385, -0.6521,  0.0100,  0.2941,\n",
            "        -0.5060,  0.2065, -0.1007,  0.2861, -0.1922,  0.4660, -0.6952,  0.6551,\n",
            "         0.9172,  0.5243,  0.1702, -0.5852,  0.2832, -0.6780, -0.4558, -0.0499,\n",
            "         1.0701, -1.3247,  0.0492,  0.0931,  0.1067, -0.1429, -0.5679,  0.0621,\n",
            "        -0.9544,  0.9977,  0.4991, -0.3857, -0.2157,  0.4879,  0.9468, -0.6313,\n",
            "        -0.6846,  0.8347, -1.0187, -0.4191,  0.8101, -0.3986, -0.1287, -0.1836,\n",
            "         0.8175,  1.2264,  1.3532,  0.5939,  0.1596, -0.4472,  0.9684, -0.3048,\n",
            "        -0.0939, -0.1644,  0.6444,  1.0688, -0.7113,  0.1075,  0.4278,  0.7453])), ('module.encoder_q.layer2.0.bn2.running_var', tensor([1.0734, 1.2009, 1.9689, 2.2096, 1.3039, 1.0751, 1.5522, 1.2647, 0.7273,\n",
            "        1.5656, 0.9756, 1.1338, 0.8933, 1.1660, 1.2030, 0.5829, 4.4376, 0.9394,\n",
            "        1.9722, 1.3190, 1.6066, 3.0909, 1.0702, 1.1834, 1.3268, 1.3278, 0.7620,\n",
            "        0.6138, 1.1666, 1.0430, 1.8837, 0.6090, 2.4276, 0.9639, 2.4161, 1.9297,\n",
            "        1.6708, 1.2357, 1.4815, 2.1103, 2.0081, 1.3204, 0.8433, 1.2368, 1.6551,\n",
            "        1.5833, 0.6605, 0.9100, 1.5694, 1.6426, 1.4111, 0.5728, 1.6389, 0.6278,\n",
            "        1.6253, 0.9355, 1.0421, 0.7173, 1.1769, 2.0296, 1.3157, 1.7860, 0.6565,\n",
            "        2.5337, 1.1385, 3.5740, 1.2011, 2.4012, 2.3491, 1.0013, 1.1217, 1.3156,\n",
            "        0.7836, 1.0454, 0.8413, 0.5236, 2.8127, 1.9726, 1.0742, 1.5096, 0.6066,\n",
            "        2.0273, 0.7745, 0.9082, 2.1920, 1.9178, 1.6318, 1.3645, 1.5473, 1.5494,\n",
            "        0.5687, 1.0084, 0.5499, 0.7334, 2.2240, 0.7937, 1.6282, 2.4038, 1.3202,\n",
            "        1.4629, 0.7275, 3.0931, 2.0174, 1.6155, 1.1064, 0.8658, 2.0966, 1.6797,\n",
            "        1.5563, 0.7282, 1.0681, 0.7707, 1.4610, 2.5056, 1.3513, 0.9245, 1.9711,\n",
            "        1.3965, 1.0481, 1.8553, 0.8899, 0.8466, 0.8698, 1.7346, 1.8611, 1.1221,\n",
            "        1.7548, 1.6688])), ('module.encoder_q.layer2.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.0.conv3.weight', tensor([[[[ 0.0299]],\n",
            "\n",
            "         [[-0.0564]],\n",
            "\n",
            "         [[ 0.1094]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0202]],\n",
            "\n",
            "         [[ 0.0115]],\n",
            "\n",
            "         [[-0.0173]]],\n",
            "\n",
            "\n",
            "        [[[-0.0205]],\n",
            "\n",
            "         [[-0.0095]],\n",
            "\n",
            "         [[ 0.1028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0132]],\n",
            "\n",
            "         [[ 0.0325]],\n",
            "\n",
            "         [[ 0.1006]]],\n",
            "\n",
            "\n",
            "        [[[-0.0702]],\n",
            "\n",
            "         [[-0.0095]],\n",
            "\n",
            "         [[ 0.1218]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0905]],\n",
            "\n",
            "         [[-0.0683]],\n",
            "\n",
            "         [[ 0.0244]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0981]],\n",
            "\n",
            "         [[ 0.0240]],\n",
            "\n",
            "         [[ 0.0244]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0617]],\n",
            "\n",
            "         [[ 0.0541]],\n",
            "\n",
            "         [[ 0.0514]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0303]],\n",
            "\n",
            "         [[-0.0472]],\n",
            "\n",
            "         [[-0.0135]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0817]],\n",
            "\n",
            "         [[ 0.1574]],\n",
            "\n",
            "         [[ 0.0263]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0233]],\n",
            "\n",
            "         [[ 0.0320]],\n",
            "\n",
            "         [[ 0.1084]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0532]],\n",
            "\n",
            "         [[-0.0134]],\n",
            "\n",
            "         [[ 0.0008]]]])), ('module.encoder_q.layer2.0.bn3.weight', tensor([0.9944, 0.9931, 0.9959, 0.9924, 0.9907, 0.9928, 0.9945, 0.9918, 0.9920,\n",
            "        0.9908, 0.9927, 0.9934, 0.9952, 0.9904, 0.9951, 0.9919, 0.9909, 0.9947,\n",
            "        0.9949, 0.9932, 0.9915, 0.9916, 0.9906, 0.9913, 0.9903, 0.9927, 0.9961,\n",
            "        0.9925, 0.9923, 0.9907, 0.9935, 0.9914, 0.9923, 0.9932, 0.9935, 0.9925,\n",
            "        0.9921, 0.9920, 0.9925, 0.9918, 0.9923, 0.9931, 0.9888, 0.9917, 0.9943,\n",
            "        0.9926, 0.9929, 0.9898, 0.9943, 0.9926, 0.9943, 0.9917, 0.9926, 0.9921,\n",
            "        0.9924, 0.9954, 0.9932, 0.9898, 0.9936, 0.9927, 0.9898, 0.9950, 0.9909,\n",
            "        0.9942, 0.9911, 0.9940, 0.9921, 0.9900, 0.9942, 0.9942, 0.9894, 0.9916,\n",
            "        0.9931, 0.9926, 0.9951, 0.9907, 0.9910, 0.9949, 0.9898, 0.9951, 0.9934,\n",
            "        0.9909, 0.9945, 0.9940, 0.9930, 0.9921, 0.9973, 0.9932, 0.9975, 0.9900,\n",
            "        0.9919, 0.9908, 0.9929, 0.9907, 0.9896, 0.9911, 0.9901, 0.9925, 0.9914,\n",
            "        0.9918, 0.9900, 0.9869, 0.9920, 0.9934, 0.9922, 0.9940, 0.9895, 0.9883,\n",
            "        0.9924, 0.9894, 0.9923, 0.9921, 0.9921, 0.9912, 0.9916, 0.9900, 0.9925,\n",
            "        0.9928, 0.9920, 0.9906, 0.9887, 0.9934, 0.9918, 0.9940, 0.9946, 0.9961,\n",
            "        0.9945, 0.9913, 0.9891, 0.9909, 0.9942, 0.9924, 0.9903, 0.9916, 0.9933,\n",
            "        0.9901, 0.9933, 0.9919, 0.9948, 0.9963, 0.9934, 0.9939, 0.9889, 0.9925,\n",
            "        0.9916, 0.9937, 0.9906, 0.9950, 0.9927, 0.9916, 0.9872, 0.9929, 0.9911,\n",
            "        0.9892, 0.9909, 0.9940, 0.9916, 0.9959, 0.9911, 0.9884, 0.9929, 0.9947,\n",
            "        0.9931, 0.9937, 0.9923, 0.9909, 0.9905, 0.9910, 0.9881, 0.9926, 0.9899,\n",
            "        0.9898, 0.9918, 0.9931, 0.9934, 0.9933, 0.9928, 0.9953, 0.9919, 0.9919,\n",
            "        0.9946, 0.9912, 0.9937, 0.9937, 0.9918, 0.9917, 0.9903, 0.9911, 0.9931,\n",
            "        0.9914, 0.9899, 0.9913, 0.9927, 0.9918, 0.9932, 0.9899, 0.9881, 0.9907,\n",
            "        0.9904, 0.9927, 0.9932, 0.9903, 0.9941, 0.9907, 0.9948, 0.9926, 0.9879,\n",
            "        0.9921, 0.9903, 0.9910, 0.9914, 0.9932, 0.9916, 0.9938, 0.9958, 0.9942,\n",
            "        0.9909, 0.9934, 0.9897, 0.9928, 0.9955, 0.9950, 0.9946, 0.9903, 0.9901,\n",
            "        0.9923, 0.9915, 0.9894, 0.9920, 0.9936, 0.9934, 0.9932, 0.9897, 0.9925,\n",
            "        0.9921, 0.9912, 0.9910, 0.9956, 0.9923, 0.9940, 0.9927, 0.9909, 0.9907,\n",
            "        0.9930, 0.9932, 0.9940, 0.9918, 0.9909, 0.9903, 0.9925, 0.9920, 0.9929,\n",
            "        0.9943, 0.9941, 0.9907, 0.9921, 0.9938, 0.9935, 0.9928, 0.9932, 0.9897,\n",
            "        0.9932, 0.9906, 0.9920, 0.9946, 0.9920, 0.9922, 0.9941, 0.9974, 0.9926,\n",
            "        0.9940, 0.9942, 0.9948, 0.9946, 0.9928, 0.9915, 0.9901, 0.9930, 0.9899,\n",
            "        0.9905, 0.9924, 0.9891, 0.9889, 0.9916, 0.9913, 0.9925, 0.9895, 0.9877,\n",
            "        0.9911, 0.9934, 0.9885, 0.9949, 0.9920, 0.9929, 0.9899, 0.9938, 0.9928,\n",
            "        0.9897, 0.9937, 0.9886, 0.9928, 0.9928, 0.9980, 0.9920, 0.9914, 0.9922,\n",
            "        0.9935, 0.9923, 0.9918, 0.9871, 0.9903, 0.9924, 0.9900, 0.9933, 0.9919,\n",
            "        0.9912, 0.9919, 0.9942, 0.9921, 0.9951, 0.9912, 0.9888, 0.9916, 0.9938,\n",
            "        0.9933, 0.9906, 0.9932, 0.9925, 0.9898, 0.9937, 0.9887, 0.9913, 0.9887,\n",
            "        0.9899, 0.9971, 0.9910, 0.9920, 0.9932, 0.9930, 0.9941, 0.9905, 0.9923,\n",
            "        0.9939, 0.9923, 0.9916, 0.9902, 0.9914, 0.9930, 0.9891, 0.9953, 0.9927,\n",
            "        0.9898, 0.9905, 0.9942, 0.9905, 0.9953, 0.9920, 0.9931, 0.9946, 0.9875,\n",
            "        0.9907, 0.9934, 0.9906, 0.9893, 0.9967, 0.9957, 0.9919, 0.9950, 0.9902,\n",
            "        0.9911, 0.9924, 0.9938, 0.9916, 0.9920, 0.9929, 0.9903, 0.9924, 0.9926,\n",
            "        0.9938, 0.9909, 0.9922, 0.9917, 0.9922, 0.9912, 0.9929, 0.9940, 0.9946,\n",
            "        0.9913, 0.9886, 0.9890, 0.9916, 0.9881, 0.9931, 0.9922, 0.9918, 0.9915,\n",
            "        0.9903, 0.9893, 0.9908, 0.9909, 0.9944, 0.9942, 0.9910, 0.9908, 0.9917,\n",
            "        0.9931, 0.9919, 0.9930, 0.9932, 0.9944, 0.9891, 0.9862, 0.9927, 0.9928,\n",
            "        0.9933, 0.9940, 0.9908, 0.9885, 0.9948, 0.9901, 0.9953, 0.9942, 0.9945,\n",
            "        0.9939, 0.9961, 0.9922, 0.9912, 0.9904, 0.9929, 0.9903, 0.9941, 0.9904,\n",
            "        0.9948, 0.9928, 0.9941, 0.9923, 0.9932, 0.9903, 0.9889, 0.9915, 0.9941,\n",
            "        0.9916, 0.9987, 0.9922, 0.9919, 0.9939, 0.9907, 0.9899, 0.9917, 0.9902,\n",
            "        0.9940, 0.9938, 0.9925, 0.9928, 0.9896, 0.9947, 0.9932, 0.9892, 0.9930,\n",
            "        0.9967, 0.9909, 0.9895, 0.9907, 0.9933, 0.9922, 0.9906, 0.9893, 0.9917,\n",
            "        0.9907, 0.9891, 0.9888, 0.9935, 0.9933, 0.9924, 0.9899, 0.9893, 0.9931,\n",
            "        0.9919, 0.9886, 0.9920, 0.9951, 0.9949, 0.9937, 0.9919, 0.9927, 0.9928,\n",
            "        0.9930, 0.9925, 0.9967, 0.9920, 0.9911, 0.9930, 0.9912, 0.9912, 0.9900,\n",
            "        0.9916, 0.9939, 0.9904, 0.9901, 0.9905, 0.9911, 0.9934, 0.9902, 0.9909,\n",
            "        0.9873, 0.9908, 0.9910, 0.9946, 0.9898, 0.9921, 0.9953, 0.9920])), ('module.encoder_q.layer2.0.bn3.bias', tensor([ 4.8611e-04,  2.5316e-04,  4.2613e-03, -2.9604e-03,  9.5614e-04,\n",
            "        -7.6312e-04,  1.4458e-03,  2.9739e-04,  2.8935e-03,  1.5486e-03,\n",
            "         2.9813e-03,  9.5415e-04,  2.5555e-04, -2.1837e-04,  1.9244e-03,\n",
            "         3.4095e-04,  2.4725e-03, -1.2040e-03,  9.1925e-04,  2.7059e-03,\n",
            "        -2.1669e-04,  8.9516e-04, -5.0136e-04, -5.3751e-03, -2.6630e-03,\n",
            "         3.7222e-03,  4.6992e-04,  1.5195e-04,  6.0320e-04, -3.7325e-04,\n",
            "         1.6521e-03, -1.2267e-03, -7.8500e-04,  1.1873e-04,  1.4702e-04,\n",
            "         4.8569e-04,  2.4601e-03, -5.9815e-04, -3.9193e-04,  1.5995e-03,\n",
            "         1.4426e-04,  8.1556e-04, -1.3002e-03, -1.4544e-03,  2.8514e-03,\n",
            "         9.8582e-04, -2.6443e-03, -6.7574e-04, -1.4844e-03, -1.1852e-03,\n",
            "         3.3110e-04, -5.8682e-04,  2.4884e-03,  2.9343e-03, -8.6382e-04,\n",
            "        -2.5869e-03, -9.8260e-04, -1.1521e-03, -3.3018e-04, -3.4878e-06,\n",
            "         1.4059e-04,  3.6816e-03, -1.1743e-03,  3.5369e-03, -9.6001e-04,\n",
            "        -7.2387e-04,  1.8113e-03, -2.5027e-03,  4.8468e-04, -5.1299e-04,\n",
            "        -1.4235e-04,  1.1449e-03,  1.8972e-03,  1.4258e-03, -1.1128e-03,\n",
            "         1.5168e-04, -2.6668e-03,  1.6727e-03,  1.1517e-04,  1.4399e-03,\n",
            "         6.3859e-04, -5.3594e-04, -2.1104e-03,  1.7551e-03,  1.5095e-03,\n",
            "        -1.0376e-04,  3.6132e-03, -2.8248e-03,  2.9955e-03, -2.2858e-03,\n",
            "         9.5211e-04, -1.2624e-03,  1.3095e-03, -1.3642e-03, -1.5653e-03,\n",
            "        -1.4515e-03, -8.3528e-04, -8.4684e-04, -6.9273e-04, -3.8440e-03,\n",
            "         2.8720e-04, -1.7866e-03, -2.0305e-03,  1.8260e-03,  2.0795e-03,\n",
            "         5.8953e-04, -5.5858e-04, -3.0352e-03, -2.0848e-04, -3.2318e-03,\n",
            "         1.9747e-04, -2.6794e-03,  9.9051e-04, -2.0286e-03,  1.0797e-03,\n",
            "         2.1793e-03,  2.3433e-03,  1.1091e-03,  5.6478e-04, -4.8889e-04,\n",
            "        -4.0127e-04,  2.1435e-03,  2.8424e-04,  7.7486e-05, -1.0048e-03,\n",
            "         2.0068e-03,  2.3737e-03, -8.4777e-04, -2.5420e-03, -2.8051e-04,\n",
            "         3.6488e-04, -1.5382e-03,  2.6694e-03, -2.3378e-04,  1.0858e-03,\n",
            "        -3.6512e-04,  2.3774e-03, -4.2911e-04, -1.4100e-03,  2.2551e-03,\n",
            "        -1.2765e-03, -6.6632e-05, -1.2488e-03,  1.7634e-03, -2.0554e-03,\n",
            "        -1.2746e-03, -3.9107e-03, -3.9052e-04, -5.9073e-06,  2.1491e-03,\n",
            "        -1.3751e-03,  8.1154e-04, -1.0655e-03,  2.2403e-03, -6.4187e-04,\n",
            "         7.1671e-04,  4.3238e-04,  3.0862e-03,  5.9985e-04, -3.4479e-03,\n",
            "         1.9840e-03,  3.4353e-03,  1.1250e-03,  2.9557e-03,  3.1342e-04,\n",
            "         1.5328e-03,  9.8213e-04,  1.2488e-03,  2.2874e-04, -2.3047e-03,\n",
            "         2.6960e-04, -1.1985e-04, -4.1161e-03, -8.2655e-04, -4.8731e-04,\n",
            "         8.8786e-04, -2.1119e-03,  2.4600e-03, -4.7619e-04, -2.0654e-04,\n",
            "         3.7925e-04, -3.8100e-04,  2.3066e-03, -4.2315e-04, -3.4804e-04,\n",
            "         3.5493e-03, -2.0366e-03, -1.0413e-03,  9.0094e-04, -1.4317e-03,\n",
            "        -2.6322e-03, -9.2018e-04,  4.1076e-04,  2.7067e-03,  2.5074e-03,\n",
            "        -2.8974e-03, -1.5969e-03, -1.5757e-03,  1.9491e-03,  9.9689e-04,\n",
            "         1.0729e-03,  3.0639e-03, -7.0905e-04, -3.1346e-03, -6.9020e-04,\n",
            "        -6.8638e-04, -1.0618e-03,  2.0246e-03, -3.8460e-04, -1.0814e-03,\n",
            "         1.8875e-03, -2.0956e-03, -7.6624e-04,  1.8825e-05,  1.1948e-03,\n",
            "         1.3962e-03, -1.0874e-03,  8.9060e-04, -1.6261e-03, -2.5174e-04,\n",
            "         1.3798e-03,  1.2731e-03,  3.7839e-03,  6.2528e-04, -3.2222e-03,\n",
            "         1.7550e-03,  1.9196e-03, -4.4954e-04, -8.4339e-04,  6.3233e-04,\n",
            "         2.4335e-03,  1.8606e-03, -7.1562e-04,  1.3904e-03, -5.0937e-04,\n",
            "        -1.2246e-03,  4.8999e-04,  2.5944e-03, -5.3864e-04,  8.2797e-04,\n",
            "        -3.6249e-03, -1.0078e-04, -1.6496e-03, -2.9623e-04, -2.9343e-03,\n",
            "        -6.1968e-04, -6.6300e-04,  2.0152e-03, -4.2388e-04, -5.2340e-04,\n",
            "        -2.7282e-03,  2.3067e-03,  1.6245e-03,  5.8759e-04, -4.2532e-03,\n",
            "        -1.5156e-03,  7.8527e-05,  1.3424e-03,  3.9160e-04,  1.3375e-03,\n",
            "        -1.7585e-03,  1.3326e-03,  1.2871e-03,  4.3530e-04,  2.4922e-03,\n",
            "        -2.1391e-03,  1.4922e-03,  3.3585e-03,  2.2858e-03,  1.7020e-03,\n",
            "         3.7919e-03,  4.9462e-04,  1.8223e-03,  1.2997e-03, -7.8038e-04,\n",
            "        -7.1195e-05,  1.2392e-03, -1.7277e-03, -2.7990e-03, -5.5401e-04,\n",
            "        -1.1526e-03, -2.2364e-03,  4.8396e-04, -1.7795e-03, -6.5267e-04,\n",
            "        -1.3785e-04, -3.0845e-03, -2.5899e-03,  2.4879e-03,  2.2610e-03,\n",
            "        -1.1102e-03,  1.5182e-03,  2.7054e-04,  4.9190e-05, -1.1944e-03,\n",
            "        -1.4970e-04,  2.6108e-03, -2.2554e-03, -2.1873e-03, -2.4598e-03,\n",
            "         1.0077e-03,  1.2453e-04,  2.3663e-03,  2.4779e-04, -5.5611e-04,\n",
            "         2.5996e-04, -1.0844e-04, -2.8631e-03,  1.5223e-04, -8.9983e-04,\n",
            "         5.4121e-04,  2.3127e-03, -1.2179e-03, -4.4737e-04,  1.7888e-03,\n",
            "         3.9142e-03, -1.0378e-03,  9.0005e-04, -4.8962e-04, -2.0677e-04,\n",
            "        -7.8495e-04, -2.8728e-03, -6.9127e-04,  4.2279e-04,  1.2134e-03,\n",
            "        -2.7743e-03,  2.8120e-03,  8.1083e-04,  4.1159e-03,  3.8166e-04,\n",
            "        -1.7073e-03, -2.4744e-04, -2.9954e-03, -2.3262e-03,  4.7472e-03,\n",
            "        -2.2202e-03,  1.7101e-04,  6.5436e-04,  1.0666e-03,  2.2743e-03,\n",
            "         8.2079e-04,  3.8240e-05,  2.2611e-03,  1.2827e-03,  1.6606e-04,\n",
            "        -6.8492e-04,  2.2185e-03, -1.3791e-03, -3.0850e-03,  1.1231e-03,\n",
            "        -1.6696e-03,  1.2631e-03, -2.5908e-03,  1.9626e-03, -1.6010e-03,\n",
            "         1.6583e-03,  1.1304e-03, -1.4475e-03,  2.4359e-03, -3.3052e-03,\n",
            "         5.3925e-04,  1.1942e-03, -8.1407e-04, -9.3571e-04,  4.2889e-03,\n",
            "         4.7802e-04, -1.0570e-03,  1.9667e-03,  8.6378e-04, -1.4283e-03,\n",
            "        -5.8004e-04,  2.8752e-04,  1.5719e-04, -6.1011e-04,  1.9388e-03,\n",
            "        -4.3126e-03,  1.0002e-03,  6.6893e-04,  2.7737e-04, -2.4037e-04,\n",
            "        -4.6522e-04, -4.5915e-04, -3.9900e-04,  2.9377e-03,  1.5767e-03,\n",
            "         2.0715e-03,  4.6315e-03,  2.2758e-03, -4.4833e-04, -8.6332e-04,\n",
            "         3.0135e-05,  2.9248e-04, -5.9171e-04,  8.9958e-05, -1.9843e-04,\n",
            "        -1.2789e-03,  1.3565e-03, -3.5038e-03, -1.9272e-03, -1.0259e-03,\n",
            "        -4.3143e-04, -1.1656e-04,  1.5914e-03, -4.0735e-03,  7.5863e-04,\n",
            "        -5.5172e-05, -5.5437e-04,  2.5889e-03, -1.0821e-03,  2.6699e-03,\n",
            "        -1.6065e-03, -1.6359e-03,  2.4712e-03,  1.2433e-03, -1.0694e-03,\n",
            "         1.5198e-03, -2.9910e-03, -1.7139e-03,  1.1313e-03, -2.0787e-04,\n",
            "         6.9876e-04,  5.3603e-04, -1.8200e-03,  8.6633e-04,  1.5020e-03,\n",
            "        -4.9074e-04,  4.8617e-04,  1.1914e-03,  1.1140e-03, -1.9192e-03,\n",
            "         1.5892e-03,  3.9472e-04,  4.9860e-04, -2.4754e-03, -4.7281e-04,\n",
            "        -1.1819e-03, -1.0747e-03, -1.6160e-03, -1.5688e-03,  7.6317e-04,\n",
            "         1.2465e-03, -8.7632e-04,  2.6737e-03, -3.6959e-04, -2.8436e-03,\n",
            "         1.5168e-03, -2.6560e-03,  2.7731e-04,  1.5133e-03, -1.4357e-03,\n",
            "        -2.8909e-04,  1.6996e-03, -1.0494e-03,  1.5215e-03,  5.2436e-05,\n",
            "        -1.2982e-03, -9.6489e-04, -5.2484e-04,  1.4278e-04,  3.5583e-04,\n",
            "         3.4980e-04, -1.1144e-03,  1.1948e-03,  1.3162e-03, -1.3513e-03,\n",
            "         4.8571e-04, -2.2273e-03, -9.4710e-04,  2.1166e-03, -3.3847e-03,\n",
            "        -2.5976e-03,  1.3328e-03, -7.2099e-04, -8.0443e-04, -9.9458e-04,\n",
            "        -4.8069e-04, -5.2432e-04,  1.4158e-03, -2.8830e-03, -1.7893e-03,\n",
            "         6.1553e-04,  7.5161e-05,  1.7746e-03, -1.6132e-03,  2.1295e-03,\n",
            "         4.6757e-04, -4.2905e-04,  6.9027e-04,  2.0272e-03, -9.3659e-04,\n",
            "         1.4460e-03,  4.2853e-03, -9.2195e-04, -1.7883e-04, -4.8140e-04,\n",
            "         2.2450e-03,  2.8083e-04, -6.6397e-04, -1.4900e-03,  2.0591e-03,\n",
            "        -1.4627e-03,  1.1453e-03,  1.2172e-04, -1.2821e-03, -4.3187e-04,\n",
            "        -9.0512e-04,  4.5905e-04,  1.2151e-04, -1.5423e-03, -2.0021e-03,\n",
            "        -2.6727e-03,  1.2604e-05])), ('module.encoder_q.layer2.0.bn3.running_mean', tensor([-1.7458e-01, -3.2044e-02,  1.4761e-01,  1.6025e-02, -2.2846e-03,\n",
            "        -3.0465e-01, -1.4302e-01,  7.3310e-02, -2.1459e-02,  8.5370e-02,\n",
            "         2.1988e-01,  1.4924e-01,  6.7179e-02,  1.3137e-01, -1.8919e-01,\n",
            "         1.3653e-01, -4.3155e-01, -1.3610e-01, -7.5444e-03,  4.2803e-02,\n",
            "        -1.6228e-01, -1.2174e-01, -5.2310e-02,  1.3450e-01, -4.1416e-01,\n",
            "         3.4517e-01, -1.7202e-02,  1.7225e-01, -2.5632e-01,  3.4369e-02,\n",
            "         2.6069e-01, -2.0030e-01,  2.5590e-01, -6.0716e-03,  5.8838e-01,\n",
            "         3.4864e-01,  1.8888e-01,  1.0494e-01,  4.8887e-01, -8.3908e-02,\n",
            "        -1.5984e-01, -3.3023e-01,  8.8711e-02,  6.7884e-02, -4.7750e-02,\n",
            "         2.9906e-01,  5.7889e-02,  3.0882e-01,  1.9649e-01, -6.9173e-02,\n",
            "        -1.6869e-01,  5.2308e-01,  4.2800e-01,  1.3512e-01, -8.1542e-02,\n",
            "         4.4635e-01,  2.3872e-01, -8.9703e-02,  7.6180e-02,  4.7367e-01,\n",
            "        -2.1896e-02, -7.0739e-02, -6.0216e-01,  3.3054e-02, -3.1774e-02,\n",
            "        -4.5303e-02, -3.1337e-02,  7.1328e-02,  1.4659e-01,  2.2081e-01,\n",
            "        -5.7323e-01, -3.8049e-02,  4.9427e-01,  4.9280e-01,  2.3264e-02,\n",
            "        -2.4426e-01,  1.6849e-01, -9.4279e-02,  2.8515e-01,  1.2924e-02,\n",
            "         1.2254e-02, -1.4676e-01,  1.6163e-01, -3.8534e-01, -4.4405e-01,\n",
            "        -1.2355e-01,  1.5429e-01,  3.5128e-01, -4.5316e-01,  2.7574e-01,\n",
            "        -3.4092e-01, -2.8607e-01,  7.2443e-02, -1.2317e-01,  3.3847e-01,\n",
            "        -3.1037e-02,  1.6826e-01, -3.9173e-01,  4.2370e-01, -3.3889e-01,\n",
            "         1.1897e-01, -3.9428e-02,  3.2906e-01,  2.3422e-01,  5.1890e-01,\n",
            "        -2.6997e-01,  3.7017e-01, -1.3901e-03,  5.8260e-02,  1.9117e-01,\n",
            "         2.2180e-01, -1.7660e-01, -3.1745e-01,  2.0854e-01,  3.0316e-01,\n",
            "        -1.9589e-01, -4.1896e-01, -2.4260e-01,  1.3315e-01,  2.7672e-02,\n",
            "         2.4586e-01,  1.6076e-01, -2.4044e-02, -6.5573e-02, -2.8226e-01,\n",
            "         2.7206e-02,  2.1763e-01,  2.6751e-01, -2.5467e-01,  9.1444e-02,\n",
            "         5.7352e-01, -4.4356e-01,  1.7087e-01,  2.1125e-01,  1.4305e-01,\n",
            "        -1.4315e-01,  1.6814e-02,  3.5565e-02,  4.6799e-02,  1.6125e-01,\n",
            "        -4.5020e-01,  2.3309e-01,  3.7054e-03, -1.2914e-01, -1.3635e-02,\n",
            "         7.5275e-02, -7.8849e-02, -2.4078e-01,  2.0121e-01,  6.9217e-02,\n",
            "         1.3411e-01, -1.7193e-01, -3.3329e-01,  1.9791e-01, -3.0082e-02,\n",
            "         1.9994e-01, -1.4215e-01,  8.2599e-02,  1.2582e-01, -4.3412e-02,\n",
            "         1.2728e-01, -1.3905e-02,  6.5790e-02, -1.5499e-01, -1.8488e-02,\n",
            "        -2.0938e-02, -3.6446e-01, -4.0319e-01, -6.2058e-02,  2.0446e-01,\n",
            "        -1.3314e-01,  1.2036e-01, -2.9835e-01,  2.9266e-01,  3.1697e-01,\n",
            "         6.2996e-03, -1.2403e-01,  3.2368e-01,  4.7933e-01, -1.5180e-01,\n",
            "         3.8668e-01, -4.7118e-02, -2.1132e-01,  6.5441e-01, -2.6306e-01,\n",
            "         2.0287e-01,  2.6949e-01,  3.0918e-01,  1.9705e-01,  3.9056e-01,\n",
            "        -2.0353e-01, -8.3930e-03,  1.3590e-01,  3.0105e-02, -1.7519e-01,\n",
            "         1.9391e-01,  4.9062e-01, -3.3142e-01,  1.3596e-01, -1.3480e-01,\n",
            "         3.8415e-01,  6.3013e-02,  5.4768e-02, -7.8441e-03,  1.5939e-01,\n",
            "         3.2623e-01, -1.4849e-02,  5.2295e-02,  9.0447e-02,  5.3345e-02,\n",
            "         1.9858e-02,  5.9373e-01, -1.1339e-01,  2.1733e-01,  3.0599e-01,\n",
            "         1.5929e-01, -2.4369e-04,  4.5311e-01, -1.9662e-02,  2.4483e-03,\n",
            "         5.1719e-02,  1.0004e-01,  3.2129e-01, -2.5735e-01, -1.8327e-02,\n",
            "        -3.1424e-01,  4.5251e-01,  4.5151e-01, -7.8889e-02, -7.3727e-02,\n",
            "         1.5293e-01, -2.0719e-01, -4.3247e-01, -6.2458e-01, -8.0467e-02,\n",
            "        -4.4298e-01,  2.5310e-01, -2.3346e-02,  1.8245e-01, -1.4310e-01,\n",
            "        -3.4294e-01,  7.3339e-02,  2.3172e-01,  2.3755e-01, -3.7793e-03,\n",
            "        -4.3112e-01, -2.7528e-02, -2.4608e-01, -4.5794e-01,  3.9347e-03,\n",
            "        -2.7751e-01, -6.1215e-03, -1.4726e-01, -2.8195e-02,  2.3882e-02,\n",
            "         1.7054e-01, -1.5146e-01,  7.6894e-02,  5.4241e-01,  7.8255e-02,\n",
            "         3.2873e-01, -2.7763e-01, -9.0672e-02, -4.0521e-01, -1.2115e-01,\n",
            "         3.7423e-01,  2.7400e-01, -2.7775e-01, -4.4667e-01, -5.7182e-01,\n",
            "         2.5034e-01,  2.0280e-01,  2.4154e-01, -4.1177e-01, -3.1107e-01,\n",
            "         1.6319e-01, -1.5663e-02, -4.3960e-02,  6.6710e-02, -1.7233e-01,\n",
            "        -3.4194e-01, -8.2670e-02, -3.3096e-01, -5.8987e-02, -2.0084e-01,\n",
            "         1.3517e-01, -1.1850e-01, -1.6139e-01,  1.8269e-02,  1.2018e-01,\n",
            "        -2.4312e-01, -1.8905e-01, -4.7713e-01, -2.7359e-01,  8.4322e-02,\n",
            "         3.0359e-01,  2.5606e-01,  1.4107e-01,  3.4263e-01,  1.5217e-01,\n",
            "        -2.2168e-01,  2.8351e-01, -8.1626e-02, -9.8990e-02,  5.1941e-01,\n",
            "         4.1643e-01,  2.4533e-01, -2.6386e-01,  2.8666e-02,  2.6919e-01,\n",
            "         6.5967e-03, -8.9882e-02, -1.7799e-01,  7.7851e-02, -3.0167e-01,\n",
            "         2.3181e-01,  8.2820e-02,  1.1207e-01,  3.9478e-01,  1.6649e-01,\n",
            "        -4.4181e-01, -2.1036e-01, -3.9892e-01, -6.1350e-02,  7.2550e-01,\n",
            "        -5.5548e-01, -3.4320e-01, -1.7151e-01, -2.2966e-01, -1.1498e-01,\n",
            "         3.7769e-01,  2.4359e-02, -8.3659e-02,  4.4436e-02,  1.8494e-01,\n",
            "        -9.6925e-03,  7.9453e-03, -1.2514e-02, -7.0451e-02,  4.6135e-01,\n",
            "        -1.7560e-01, -1.4943e-01, -2.5512e-01,  1.7958e-01, -5.3078e-01,\n",
            "         2.5819e-01, -6.8899e-02,  6.0168e-01, -2.9423e-01, -5.2602e-02,\n",
            "         3.5906e-01, -3.4676e-02,  3.8865e-01, -1.0762e-02,  6.1761e-01,\n",
            "         2.0162e-02, -2.9514e-01, -2.1379e-01, -1.2822e-01,  1.0792e-01,\n",
            "         2.9313e-01, -1.1427e-01,  3.3460e-01,  4.6892e-03,  4.3858e-02,\n",
            "         6.4511e-02, -5.8226e-02,  2.6160e-02,  1.5961e-01,  5.0035e-02,\n",
            "         1.7986e-01, -4.1939e-01, -3.2185e-01, -1.2170e-01,  2.0765e-03,\n",
            "        -3.9857e-01, -2.7058e-01,  1.9506e-01, -2.3858e-01,  7.2754e-02,\n",
            "         1.4029e-01, -1.7728e-01, -3.9942e-01,  1.0339e-01,  2.5730e-01,\n",
            "        -4.5384e-01, -5.6552e-02, -1.7602e-01, -1.6460e-01, -5.8272e-02,\n",
            "         2.7392e-01, -7.3778e-02,  1.1980e-01, -5.2358e-01, -3.6750e-01,\n",
            "         2.2724e-01,  3.3420e-01, -8.0248e-02, -5.6623e-01, -3.8573e-01,\n",
            "         2.0721e-01,  4.3312e-01, -9.4262e-02,  8.3509e-02, -4.4479e-02,\n",
            "         2.5225e-01, -4.1275e-01, -1.1232e-01, -2.2719e-01, -3.0896e-01,\n",
            "        -4.3055e-01,  1.4493e-01,  1.3135e-01,  3.0084e-01, -7.0684e-02,\n",
            "         1.1136e-01, -1.4601e-01, -3.8508e-01,  3.1843e-03, -1.4220e-01,\n",
            "        -7.8770e-02, -4.9804e-02,  1.7956e-01,  4.1033e-01, -1.4489e-01,\n",
            "         1.7113e-01, -4.4024e-01, -5.3087e-02, -3.1336e-02,  3.1070e-01,\n",
            "         2.1774e-01, -3.2373e-01, -2.7822e-01,  3.2858e-01, -3.0973e-01,\n",
            "        -1.0408e-01,  2.8268e-01, -2.3005e-01,  1.9950e-01, -2.5710e-02,\n",
            "         2.9682e-01, -3.8819e-01, -4.0124e-01, -2.3995e-01,  1.4723e-01,\n",
            "        -2.6700e-01, -2.1777e-01, -2.0128e-01,  1.3423e-01,  8.5036e-02,\n",
            "         4.2742e-01,  5.7481e-02,  4.9978e-01, -1.4778e-01,  4.4691e-01,\n",
            "        -5.2651e-02,  2.0139e-01, -1.1797e-01, -2.5616e-01, -1.3356e-02,\n",
            "        -2.9152e-01, -5.9896e-03, -2.9987e-01, -4.1685e-02,  2.5229e-02,\n",
            "         2.2585e-01, -2.1960e-01, -1.2269e-01, -1.1339e-01,  1.3596e-01,\n",
            "        -5.0109e-01, -3.3631e-01,  2.6572e-01, -3.2306e-01, -2.3501e-01,\n",
            "        -4.4575e-02,  1.3589e-01,  9.9190e-02, -6.0465e-01, -7.8777e-02,\n",
            "        -2.8644e-01, -4.5527e-01, -4.6948e-01,  2.9614e-01, -2.9783e-01,\n",
            "         1.5957e-01,  2.5273e-01, -2.3761e-01,  6.1156e-02, -7.0301e-01,\n",
            "         1.0529e-01, -1.4601e-01,  2.2408e-01,  2.3864e-01,  2.3718e-01,\n",
            "        -4.9359e-02, -2.6958e-02, -2.0874e-01, -1.0585e-01,  1.1795e-01,\n",
            "        -3.2474e-01, -5.5458e-01, -2.5847e-01, -3.4181e-01, -1.7600e-02,\n",
            "         1.1610e-01,  3.0028e-01,  2.1775e-01, -2.2303e-01, -2.1466e-02,\n",
            "        -7.6673e-02,  1.5725e-01])), ('module.encoder_q.layer2.0.bn3.running_var', tensor([0.1401, 0.2676, 0.2159, 0.1613, 0.1230, 0.2516, 0.1730, 0.1591, 0.3795,\n",
            "        0.1128, 0.0513, 0.1286, 0.0942, 0.3368, 0.2701, 0.1074, 0.1382, 0.1116,\n",
            "        0.2981, 0.1274, 0.1198, 0.4835, 0.1216, 0.0912, 0.1573, 0.2088, 0.2294,\n",
            "        0.1387, 0.2656, 0.1634, 0.1274, 0.1056, 0.2993, 0.1557, 0.7148, 0.4006,\n",
            "        0.1323, 0.1339, 0.1392, 0.1416, 0.3176, 0.2346, 0.2284, 0.2114, 0.1821,\n",
            "        0.1187, 0.2099, 0.1510, 0.1649, 0.2699, 0.1788, 0.1239, 0.4887, 0.6637,\n",
            "        0.1984, 0.4638, 0.1443, 0.1150, 0.3027, 0.3164, 0.1340, 0.1407, 0.2843,\n",
            "        0.1258, 0.1418, 0.1420, 0.2325, 0.1808, 0.1833, 0.1308, 0.2044, 0.2287,\n",
            "        0.1864, 0.4335, 0.1408, 0.2526, 0.0744, 0.1532, 0.1200, 0.2433, 0.2622,\n",
            "        0.3290, 0.2097, 0.1419, 0.2777, 0.2689, 0.1369, 0.1616, 0.1314, 0.3697,\n",
            "        0.1784, 0.1764, 0.1480, 0.1713, 0.3084, 0.0764, 0.8350, 0.1850, 0.1452,\n",
            "        0.2137, 0.1283, 0.4437, 0.1354, 0.2527, 0.1225, 0.2313, 0.5933, 0.2794,\n",
            "        0.0921, 0.1797, 0.1586, 0.0832, 0.1576, 0.1299, 0.2348, 0.0942, 0.3650,\n",
            "        0.1017, 0.2098, 0.1432, 0.1809, 0.0865, 0.2342, 0.1709, 0.0707, 0.2253,\n",
            "        0.1301, 0.6478, 0.1546, 0.1802, 0.1204, 0.6403, 0.2094, 0.1025, 0.3249,\n",
            "        0.1702, 0.4774, 0.2446, 0.0802, 0.2962, 0.2729, 0.0928, 0.1845, 0.1165,\n",
            "        0.1018, 0.1723, 0.2276, 0.2746, 0.1630, 0.1451, 0.3784, 0.1617, 0.1775,\n",
            "        0.1770, 0.2863, 0.1404, 0.0810, 0.1131, 0.0660, 0.1104, 0.0570, 0.2053,\n",
            "        0.2448, 0.1423, 0.0684, 0.0959, 0.2426, 0.1290, 0.3371, 0.1858, 0.1126,\n",
            "        0.1982, 0.1681, 0.1657, 0.1995, 0.1998, 0.0734, 0.1970, 0.1162, 0.5490,\n",
            "        0.2192, 0.0744, 0.1584, 1.3201, 0.2842, 0.2353, 0.2143, 0.3000, 0.0939,\n",
            "        0.0824, 0.3135, 0.1648, 0.6527, 0.1190, 0.3041, 0.1785, 0.2409, 0.1542,\n",
            "        0.1808, 0.0967, 0.1108, 0.1512, 0.1716, 0.4679, 0.1826, 0.3256, 0.2948,\n",
            "        0.0706, 0.3272, 0.2299, 0.1153, 0.0772, 0.1402, 0.2978, 0.1584, 0.4323,\n",
            "        0.2594, 0.4104, 0.1199, 0.2455, 0.3970, 0.3125, 0.1311, 0.3607, 0.1489,\n",
            "        0.1789, 0.1368, 0.1594, 0.0716, 0.1874, 0.1470, 0.3602, 0.5066, 0.5839,\n",
            "        0.0737, 0.1047, 0.2832, 0.0956, 0.1710, 0.2518, 0.5853, 0.2156, 0.2612,\n",
            "        0.3928, 0.3207, 0.1404, 0.2222, 0.1067, 0.1178, 0.1191, 0.1169, 0.1748,\n",
            "        0.0863, 0.0939, 0.2433, 0.2060, 0.3321, 0.1191, 0.4630, 0.1957, 0.1432,\n",
            "        0.4538, 0.1143, 0.1398, 0.2489, 0.1972, 0.1543, 0.1150, 0.2291, 0.2052,\n",
            "        0.1511, 0.1658, 0.0741, 0.4440, 0.1492, 0.1425, 0.1269, 0.1743, 0.2369,\n",
            "        0.1630, 0.1282, 0.1132, 0.3091, 0.2641, 0.1307, 0.1975, 0.1064, 0.1986,\n",
            "        0.1746, 0.1732, 0.1954, 0.1627, 0.1975, 0.2416, 0.1120, 0.0910, 0.1655,\n",
            "        0.1256, 0.0919, 0.1190, 0.1431, 0.3031, 0.1459, 0.1220, 0.1703, 0.2478,\n",
            "        0.6292, 0.1870, 0.1203, 0.1416, 0.0599, 0.1876, 0.1480, 0.3291, 0.1147,\n",
            "        0.1747, 0.1593, 0.2174, 0.4765, 0.4178, 0.1783, 0.2029, 0.1503, 0.0977,\n",
            "        0.1213, 0.1349, 0.6966, 0.2324, 0.1652, 0.1010, 0.1426, 0.1026, 0.2298,\n",
            "        0.1615, 0.1110, 0.1049, 0.0743, 0.1827, 0.2858, 0.1425, 0.2063, 0.1258,\n",
            "        0.1343, 0.3026, 0.2360, 0.2731, 0.1673, 0.6214, 0.1457, 0.1133, 0.1831,\n",
            "        0.1917, 0.1449, 0.4158, 0.2838, 0.2225, 0.1270, 0.1594, 0.2854, 0.1368,\n",
            "        0.1274, 0.4480, 0.1700, 0.1834, 0.0939, 0.1411, 0.0675, 0.2148, 0.1352,\n",
            "        0.4573, 0.3152, 0.0655, 0.2604, 0.3135, 0.1020, 0.3792, 0.1671, 0.3655,\n",
            "        0.1669, 0.3124, 0.4524, 0.0962, 0.3345, 0.1100, 0.1182, 0.7877, 0.1376,\n",
            "        0.5758, 0.1133, 0.1847, 0.1680, 0.1141, 0.1369, 0.4486, 0.1451, 0.1309,\n",
            "        0.1457, 0.1066, 0.3194, 1.6090, 0.2234, 0.2001, 0.1038, 0.1251, 0.1079,\n",
            "        0.1993, 0.2846, 0.1024, 0.1182, 0.1341, 0.2665, 0.1340, 0.1384, 0.2249,\n",
            "        0.1279, 0.2170, 0.0841, 0.5047, 0.1522, 0.0970, 0.2653, 0.1418, 0.1480,\n",
            "        0.1614, 0.1321, 0.1449, 0.1466, 0.2069, 0.1322, 0.1730, 0.1492, 0.4357,\n",
            "        0.2166, 0.2302, 0.1020, 0.1370, 0.1503, 0.1245, 0.1919, 0.0666, 0.0980,\n",
            "        0.0950, 0.3567, 0.0998, 0.2729, 0.2197, 0.0960, 0.1137, 0.2009, 0.0717,\n",
            "        0.2153, 0.1675, 0.2272, 0.2358, 0.1011, 0.2025, 0.1248, 0.4219, 0.2105,\n",
            "        0.1091, 0.1254, 0.1403, 0.2594, 0.1433, 0.1692, 0.2332, 0.1658, 0.2084,\n",
            "        0.1158, 0.1563, 0.1283, 0.1152, 0.2086, 0.1588, 0.6423, 0.1807, 0.2414,\n",
            "        0.2292, 0.2375, 0.2412, 0.3391, 0.1286, 0.1893, 0.1010, 0.1186, 0.1404,\n",
            "        0.1603, 0.1679, 0.1197, 0.0973, 0.3824, 0.1489, 0.1308, 0.2863, 0.4928,\n",
            "        0.1185, 0.1594, 0.1739, 0.1436, 0.1941, 0.2248, 0.4468, 0.0677, 0.3091,\n",
            "        0.0727, 0.1334, 0.4573, 0.1935, 0.1456, 0.1014, 0.2284, 0.1530])), ('module.encoder_q.layer2.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.0.downsample.0.weight', tensor([[[[ 0.0347]],\n",
            "\n",
            "         [[-0.1168]],\n",
            "\n",
            "         [[ 0.0229]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[-0.0588]],\n",
            "\n",
            "         [[-0.1049]]],\n",
            "\n",
            "\n",
            "        [[[-0.1141]],\n",
            "\n",
            "         [[ 0.0031]],\n",
            "\n",
            "         [[ 0.0125]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         [[ 0.0343]],\n",
            "\n",
            "         [[ 0.1341]]],\n",
            "\n",
            "\n",
            "        [[[-0.0136]],\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.1172]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[ 0.0636]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0325]],\n",
            "\n",
            "         [[ 0.0379]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0223]],\n",
            "\n",
            "         [[-0.0275]],\n",
            "\n",
            "         [[-0.0554]]],\n",
            "\n",
            "\n",
            "        [[[-0.0532]],\n",
            "\n",
            "         [[-0.0683]],\n",
            "\n",
            "         [[ 0.0500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0382]],\n",
            "\n",
            "         [[ 0.0185]],\n",
            "\n",
            "         [[ 0.1013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0789]],\n",
            "\n",
            "         [[ 0.0870]],\n",
            "\n",
            "         [[ 0.0587]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0548]],\n",
            "\n",
            "         [[ 0.0532]],\n",
            "\n",
            "         [[-0.1141]]]])), ('module.encoder_q.layer2.0.downsample.1.weight', tensor([0.9932, 0.9940, 0.9947, 0.9912, 0.9942, 0.9945, 0.9931, 0.9940, 0.9946,\n",
            "        0.9965, 0.9944, 0.9891, 0.9925, 0.9933, 0.9923, 0.9883, 0.9951, 0.9926,\n",
            "        0.9927, 0.9926, 0.9928, 0.9947, 0.9930, 0.9903, 0.9893, 0.9957, 0.9918,\n",
            "        0.9937, 0.9940, 0.9941, 0.9953, 0.9931, 0.9895, 0.9906, 0.9906, 0.9917,\n",
            "        0.9968, 0.9911, 0.9916, 0.9941, 0.9968, 0.9922, 0.9922, 0.9928, 0.9942,\n",
            "        0.9914, 0.9881, 0.9936, 0.9896, 0.9932, 0.9918, 0.9909, 0.9940, 0.9947,\n",
            "        0.9931, 0.9939, 0.9896, 0.9935, 0.9922, 0.9912, 0.9946, 0.9944, 0.9901,\n",
            "        0.9954, 0.9922, 0.9898, 0.9909, 0.9895, 0.9935, 0.9925, 0.9929, 0.9941,\n",
            "        0.9947, 0.9938, 0.9955, 0.9894, 0.9900, 0.9954, 0.9939, 0.9922, 0.9909,\n",
            "        0.9937, 0.9884, 0.9941, 0.9932, 0.9929, 0.9926, 0.9912, 0.9943, 0.9930,\n",
            "        0.9940, 0.9931, 0.9936, 0.9914, 0.9936, 0.9951, 0.9934, 0.9905, 0.9885,\n",
            "        0.9887, 0.9916, 0.9942, 0.9908, 0.9934, 0.9923, 0.9890, 0.9928, 0.9929,\n",
            "        0.9946, 0.9926, 0.9941, 0.9908, 0.9938, 0.9908, 0.9958, 0.9949, 0.9965,\n",
            "        0.9951, 0.9927, 0.9919, 0.9919, 0.9927, 0.9943, 0.9912, 0.9875, 0.9893,\n",
            "        0.9927, 0.9917, 0.9917, 0.9913, 0.9925, 0.9885, 0.9932, 0.9918, 0.9915,\n",
            "        0.9942, 0.9955, 0.9931, 0.9891, 0.9960, 0.9932, 0.9890, 0.9930, 0.9914,\n",
            "        0.9897, 0.9910, 0.9919, 0.9933, 0.9969, 0.9918, 0.9933, 0.9904, 0.9951,\n",
            "        0.9954, 0.9939, 0.9907, 0.9932, 0.9935, 0.9948, 0.9913, 0.9910, 0.9928,\n",
            "        0.9963, 0.9920, 0.9910, 0.9901, 0.9918, 0.9951, 0.9929, 0.9893, 0.9934,\n",
            "        0.9974, 0.9876, 0.9909, 0.9939, 0.9932, 0.9898, 0.9912, 0.9892, 0.9928,\n",
            "        0.9918, 0.9933, 0.9927, 0.9945, 0.9904, 0.9956, 0.9877, 0.9937, 0.9923,\n",
            "        0.9881, 0.9913, 0.9935, 0.9922, 0.9938, 0.9938, 0.9889, 0.9927, 0.9897,\n",
            "        0.9922, 0.9941, 0.9954, 0.9950, 0.9915, 0.9899, 0.9913, 0.9937, 0.9934,\n",
            "        0.9939, 0.9927, 0.9903, 0.9926, 0.9901, 0.9916, 0.9924, 0.9911, 0.9923,\n",
            "        0.9904, 0.9927, 0.9949, 0.9942, 0.9896, 0.9914, 0.9924, 0.9937, 0.9903,\n",
            "        0.9939, 0.9945, 0.9921, 0.9911, 0.9920, 0.9936, 0.9933, 0.9940, 0.9932,\n",
            "        0.9931, 0.9899, 0.9960, 0.9906, 0.9912, 0.9898, 0.9898, 0.9949, 0.9922,\n",
            "        0.9913, 0.9891, 0.9905, 0.9947, 0.9952, 0.9935, 0.9949, 0.9917, 0.9944,\n",
            "        0.9952, 0.9908, 0.9898, 0.9911, 0.9922, 0.9953, 0.9925, 0.9931, 0.9921,\n",
            "        0.9925, 0.9949, 0.9939, 0.9920, 0.9914, 0.9931, 0.9982, 0.9938, 0.9938,\n",
            "        0.9924, 0.9878, 0.9923, 0.9908, 0.9908, 0.9931, 0.9950, 0.9903, 0.9914,\n",
            "        0.9911, 0.9886, 0.9898, 0.9957, 0.9918, 0.9919, 0.9899, 0.9932, 0.9884,\n",
            "        0.9955, 0.9955, 0.9949, 0.9917, 0.9920, 0.9904, 0.9922, 0.9918, 0.9925,\n",
            "        0.9941, 0.9885, 0.9905, 0.9920, 0.9908, 0.9942, 0.9957, 0.9918, 0.9934,\n",
            "        0.9911, 0.9889, 0.9936, 0.9948, 0.9897, 0.9953, 0.9941, 0.9913, 0.9918,\n",
            "        0.9926, 0.9919, 0.9899, 0.9909, 0.9905, 0.9940, 0.9927, 0.9926, 0.9920,\n",
            "        0.9947, 0.9910, 0.9917, 0.9937, 0.9969, 0.9895, 0.9931, 0.9933, 0.9910,\n",
            "        0.9927, 0.9959, 0.9930, 0.9914, 0.9913, 0.9929, 0.9911, 0.9943, 0.9906,\n",
            "        0.9922, 0.9951, 0.9933, 0.9929, 0.9941, 0.9900, 0.9880, 0.9910, 0.9908,\n",
            "        0.9953, 0.9884, 0.9943, 0.9918, 0.9929, 0.9914, 0.9912, 0.9911, 0.9897,\n",
            "        0.9925, 0.9909, 0.9905, 0.9938, 0.9952, 0.9917, 0.9910, 0.9899, 0.9940,\n",
            "        0.9926, 0.9923, 0.9919, 0.9925, 0.9910, 0.9918, 0.9906, 0.9925, 0.9940,\n",
            "        0.9900, 0.9920, 0.9922, 0.9931, 0.9925, 0.9954, 0.9927, 0.9925, 0.9943,\n",
            "        0.9937, 0.9936, 0.9902, 0.9928, 0.9930, 0.9944, 0.9920, 0.9926, 0.9935,\n",
            "        0.9961, 0.9910, 0.9922, 0.9881, 0.9911, 0.9919, 0.9918, 0.9890, 0.9952,\n",
            "        0.9933, 0.9903, 0.9965, 0.9917, 0.9945, 0.9912, 0.9946, 0.9912, 0.9910,\n",
            "        0.9941, 0.9935, 0.9900, 0.9929, 0.9912, 0.9920, 0.9928, 0.9920, 0.9916,\n",
            "        0.9897, 0.9908, 0.9912, 0.9934, 0.9937, 0.9941, 0.9913, 0.9927, 0.9942,\n",
            "        0.9912, 0.9887, 0.9936, 0.9903, 0.9920, 0.9936, 0.9935, 0.9914, 0.9919,\n",
            "        0.9931, 0.9956, 0.9920, 0.9918, 0.9934, 0.9934, 0.9946, 0.9945, 0.9905,\n",
            "        0.9888, 0.9931, 0.9914, 0.9920, 0.9931, 0.9929, 0.9898, 0.9938, 0.9920,\n",
            "        0.9899, 0.9947, 0.9911, 0.9926, 0.9935, 0.9877, 0.9935, 0.9913, 0.9932,\n",
            "        0.9925, 0.9902, 0.9951, 0.9965, 0.9911, 0.9917, 0.9943, 0.9918, 0.9929,\n",
            "        0.9940, 0.9934, 0.9892, 0.9893, 0.9924, 0.9948, 0.9910, 0.9956, 0.9917,\n",
            "        0.9925, 0.9929, 0.9963, 0.9906, 0.9903, 0.9966, 0.9915, 0.9952, 0.9916,\n",
            "        0.9909, 0.9918, 0.9940, 0.9899, 0.9918, 0.9910, 0.9938, 0.9936, 0.9927,\n",
            "        0.9928, 0.9964, 0.9925, 0.9912, 0.9946, 0.9916, 0.9886, 0.9893])), ('module.encoder_q.layer2.0.downsample.1.bias', tensor([ 4.8611e-04,  2.5316e-04,  4.2613e-03, -2.9604e-03,  9.5614e-04,\n",
            "        -7.6312e-04,  1.4458e-03,  2.9739e-04,  2.8935e-03,  1.5486e-03,\n",
            "         2.9813e-03,  9.5415e-04,  2.5555e-04, -2.1837e-04,  1.9244e-03,\n",
            "         3.4095e-04,  2.4725e-03, -1.2040e-03,  9.1925e-04,  2.7059e-03,\n",
            "        -2.1669e-04,  8.9516e-04, -5.0136e-04, -5.3751e-03, -2.6630e-03,\n",
            "         3.7222e-03,  4.6992e-04,  1.5195e-04,  6.0320e-04, -3.7325e-04,\n",
            "         1.6521e-03, -1.2267e-03, -7.8500e-04,  1.1873e-04,  1.4702e-04,\n",
            "         4.8569e-04,  2.4601e-03, -5.9815e-04, -3.9193e-04,  1.5995e-03,\n",
            "         1.4426e-04,  8.1556e-04, -1.3002e-03, -1.4544e-03,  2.8514e-03,\n",
            "         9.8582e-04, -2.6443e-03, -6.7574e-04, -1.4844e-03, -1.1852e-03,\n",
            "         3.3110e-04, -5.8682e-04,  2.4884e-03,  2.9343e-03, -8.6382e-04,\n",
            "        -2.5869e-03, -9.8260e-04, -1.1521e-03, -3.3018e-04, -3.4878e-06,\n",
            "         1.4059e-04,  3.6816e-03, -1.1743e-03,  3.5369e-03, -9.6001e-04,\n",
            "        -7.2387e-04,  1.8113e-03, -2.5027e-03,  4.8468e-04, -5.1299e-04,\n",
            "        -1.4235e-04,  1.1449e-03,  1.8972e-03,  1.4258e-03, -1.1128e-03,\n",
            "         1.5168e-04, -2.6668e-03,  1.6727e-03,  1.1517e-04,  1.4399e-03,\n",
            "         6.3859e-04, -5.3594e-04, -2.1104e-03,  1.7551e-03,  1.5095e-03,\n",
            "        -1.0376e-04,  3.6132e-03, -2.8248e-03,  2.9955e-03, -2.2858e-03,\n",
            "         9.5211e-04, -1.2624e-03,  1.3095e-03, -1.3642e-03, -1.5653e-03,\n",
            "        -1.4515e-03, -8.3528e-04, -8.4684e-04, -6.9273e-04, -3.8440e-03,\n",
            "         2.8720e-04, -1.7866e-03, -2.0305e-03,  1.8260e-03,  2.0795e-03,\n",
            "         5.8953e-04, -5.5858e-04, -3.0352e-03, -2.0848e-04, -3.2318e-03,\n",
            "         1.9747e-04, -2.6794e-03,  9.9051e-04, -2.0286e-03,  1.0797e-03,\n",
            "         2.1793e-03,  2.3433e-03,  1.1091e-03,  5.6478e-04, -4.8889e-04,\n",
            "        -4.0127e-04,  2.1435e-03,  2.8424e-04,  7.7486e-05, -1.0048e-03,\n",
            "         2.0068e-03,  2.3737e-03, -8.4777e-04, -2.5420e-03, -2.8051e-04,\n",
            "         3.6488e-04, -1.5382e-03,  2.6694e-03, -2.3378e-04,  1.0858e-03,\n",
            "        -3.6512e-04,  2.3774e-03, -4.2911e-04, -1.4100e-03,  2.2551e-03,\n",
            "        -1.2765e-03, -6.6632e-05, -1.2488e-03,  1.7634e-03, -2.0554e-03,\n",
            "        -1.2746e-03, -3.9107e-03, -3.9052e-04, -5.9073e-06,  2.1491e-03,\n",
            "        -1.3751e-03,  8.1154e-04, -1.0655e-03,  2.2403e-03, -6.4187e-04,\n",
            "         7.1671e-04,  4.3238e-04,  3.0862e-03,  5.9985e-04, -3.4479e-03,\n",
            "         1.9840e-03,  3.4353e-03,  1.1250e-03,  2.9557e-03,  3.1342e-04,\n",
            "         1.5328e-03,  9.8213e-04,  1.2488e-03,  2.2874e-04, -2.3047e-03,\n",
            "         2.6960e-04, -1.1985e-04, -4.1161e-03, -8.2655e-04, -4.8731e-04,\n",
            "         8.8786e-04, -2.1119e-03,  2.4600e-03, -4.7619e-04, -2.0654e-04,\n",
            "         3.7925e-04, -3.8100e-04,  2.3066e-03, -4.2315e-04, -3.4804e-04,\n",
            "         3.5493e-03, -2.0366e-03, -1.0413e-03,  9.0094e-04, -1.4317e-03,\n",
            "        -2.6322e-03, -9.2018e-04,  4.1076e-04,  2.7067e-03,  2.5074e-03,\n",
            "        -2.8974e-03, -1.5969e-03, -1.5757e-03,  1.9491e-03,  9.9689e-04,\n",
            "         1.0729e-03,  3.0639e-03, -7.0905e-04, -3.1346e-03, -6.9020e-04,\n",
            "        -6.8638e-04, -1.0618e-03,  2.0246e-03, -3.8460e-04, -1.0814e-03,\n",
            "         1.8875e-03, -2.0956e-03, -7.6624e-04,  1.8825e-05,  1.1948e-03,\n",
            "         1.3962e-03, -1.0874e-03,  8.9060e-04, -1.6261e-03, -2.5174e-04,\n",
            "         1.3798e-03,  1.2731e-03,  3.7839e-03,  6.2528e-04, -3.2222e-03,\n",
            "         1.7550e-03,  1.9196e-03, -4.4954e-04, -8.4339e-04,  6.3233e-04,\n",
            "         2.4335e-03,  1.8606e-03, -7.1562e-04,  1.3904e-03, -5.0937e-04,\n",
            "        -1.2246e-03,  4.8999e-04,  2.5944e-03, -5.3864e-04,  8.2797e-04,\n",
            "        -3.6249e-03, -1.0078e-04, -1.6496e-03, -2.9623e-04, -2.9343e-03,\n",
            "        -6.1968e-04, -6.6300e-04,  2.0152e-03, -4.2388e-04, -5.2340e-04,\n",
            "        -2.7282e-03,  2.3067e-03,  1.6245e-03,  5.8759e-04, -4.2532e-03,\n",
            "        -1.5156e-03,  7.8527e-05,  1.3424e-03,  3.9160e-04,  1.3375e-03,\n",
            "        -1.7585e-03,  1.3326e-03,  1.2871e-03,  4.3530e-04,  2.4922e-03,\n",
            "        -2.1391e-03,  1.4922e-03,  3.3585e-03,  2.2858e-03,  1.7020e-03,\n",
            "         3.7919e-03,  4.9462e-04,  1.8223e-03,  1.2997e-03, -7.8038e-04,\n",
            "        -7.1195e-05,  1.2392e-03, -1.7277e-03, -2.7990e-03, -5.5401e-04,\n",
            "        -1.1526e-03, -2.2364e-03,  4.8396e-04, -1.7795e-03, -6.5267e-04,\n",
            "        -1.3785e-04, -3.0845e-03, -2.5899e-03,  2.4879e-03,  2.2610e-03,\n",
            "        -1.1102e-03,  1.5182e-03,  2.7054e-04,  4.9190e-05, -1.1944e-03,\n",
            "        -1.4970e-04,  2.6108e-03, -2.2554e-03, -2.1873e-03, -2.4598e-03,\n",
            "         1.0077e-03,  1.2453e-04,  2.3663e-03,  2.4779e-04, -5.5611e-04,\n",
            "         2.5996e-04, -1.0844e-04, -2.8631e-03,  1.5223e-04, -8.9983e-04,\n",
            "         5.4121e-04,  2.3127e-03, -1.2179e-03, -4.4737e-04,  1.7888e-03,\n",
            "         3.9142e-03, -1.0378e-03,  9.0005e-04, -4.8962e-04, -2.0677e-04,\n",
            "        -7.8495e-04, -2.8728e-03, -6.9127e-04,  4.2279e-04,  1.2134e-03,\n",
            "        -2.7743e-03,  2.8120e-03,  8.1083e-04,  4.1159e-03,  3.8166e-04,\n",
            "        -1.7073e-03, -2.4744e-04, -2.9954e-03, -2.3262e-03,  4.7472e-03,\n",
            "        -2.2202e-03,  1.7101e-04,  6.5436e-04,  1.0666e-03,  2.2743e-03,\n",
            "         8.2079e-04,  3.8240e-05,  2.2611e-03,  1.2827e-03,  1.6606e-04,\n",
            "        -6.8492e-04,  2.2185e-03, -1.3791e-03, -3.0850e-03,  1.1231e-03,\n",
            "        -1.6696e-03,  1.2631e-03, -2.5908e-03,  1.9626e-03, -1.6010e-03,\n",
            "         1.6583e-03,  1.1304e-03, -1.4475e-03,  2.4359e-03, -3.3052e-03,\n",
            "         5.3925e-04,  1.1942e-03, -8.1407e-04, -9.3571e-04,  4.2889e-03,\n",
            "         4.7802e-04, -1.0570e-03,  1.9667e-03,  8.6378e-04, -1.4283e-03,\n",
            "        -5.8004e-04,  2.8752e-04,  1.5719e-04, -6.1011e-04,  1.9388e-03,\n",
            "        -4.3126e-03,  1.0002e-03,  6.6893e-04,  2.7737e-04, -2.4037e-04,\n",
            "        -4.6522e-04, -4.5915e-04, -3.9900e-04,  2.9377e-03,  1.5767e-03,\n",
            "         2.0715e-03,  4.6315e-03,  2.2758e-03, -4.4833e-04, -8.6332e-04,\n",
            "         3.0135e-05,  2.9248e-04, -5.9171e-04,  8.9958e-05, -1.9843e-04,\n",
            "        -1.2789e-03,  1.3565e-03, -3.5038e-03, -1.9272e-03, -1.0259e-03,\n",
            "        -4.3143e-04, -1.1656e-04,  1.5914e-03, -4.0735e-03,  7.5863e-04,\n",
            "        -5.5172e-05, -5.5437e-04,  2.5889e-03, -1.0821e-03,  2.6699e-03,\n",
            "        -1.6065e-03, -1.6359e-03,  2.4712e-03,  1.2433e-03, -1.0694e-03,\n",
            "         1.5198e-03, -2.9910e-03, -1.7139e-03,  1.1313e-03, -2.0787e-04,\n",
            "         6.9876e-04,  5.3603e-04, -1.8200e-03,  8.6633e-04,  1.5020e-03,\n",
            "        -4.9074e-04,  4.8617e-04,  1.1914e-03,  1.1140e-03, -1.9192e-03,\n",
            "         1.5892e-03,  3.9472e-04,  4.9860e-04, -2.4754e-03, -4.7281e-04,\n",
            "        -1.1819e-03, -1.0747e-03, -1.6160e-03, -1.5688e-03,  7.6317e-04,\n",
            "         1.2465e-03, -8.7632e-04,  2.6737e-03, -3.6959e-04, -2.8436e-03,\n",
            "         1.5168e-03, -2.6560e-03,  2.7731e-04,  1.5133e-03, -1.4357e-03,\n",
            "        -2.8909e-04,  1.6996e-03, -1.0494e-03,  1.5215e-03,  5.2436e-05,\n",
            "        -1.2982e-03, -9.6489e-04, -5.2484e-04,  1.4278e-04,  3.5583e-04,\n",
            "         3.4980e-04, -1.1144e-03,  1.1948e-03,  1.3162e-03, -1.3513e-03,\n",
            "         4.8571e-04, -2.2273e-03, -9.4710e-04,  2.1166e-03, -3.3847e-03,\n",
            "        -2.5976e-03,  1.3328e-03, -7.2099e-04, -8.0443e-04, -9.9458e-04,\n",
            "        -4.8069e-04, -5.2432e-04,  1.4158e-03, -2.8830e-03, -1.7893e-03,\n",
            "         6.1553e-04,  7.5161e-05,  1.7746e-03, -1.6132e-03,  2.1295e-03,\n",
            "         4.6757e-04, -4.2905e-04,  6.9027e-04,  2.0272e-03, -9.3659e-04,\n",
            "         1.4460e-03,  4.2853e-03, -9.2195e-04, -1.7883e-04, -4.8140e-04,\n",
            "         2.2450e-03,  2.8083e-04, -6.6397e-04, -1.4900e-03,  2.0591e-03,\n",
            "        -1.4627e-03,  1.1453e-03,  1.2172e-04, -1.2821e-03, -4.3187e-04,\n",
            "        -9.0512e-04,  4.5905e-04,  1.2151e-04, -1.5423e-03, -2.0021e-03,\n",
            "        -2.6727e-03,  1.2604e-05])), ('module.encoder_q.layer2.0.downsample.1.running_mean', tensor([-2.3969e-01, -7.3401e-01, -8.0172e-01, -6.0611e-01,  2.5325e-01,\n",
            "        -9.8283e-01,  1.2700e+00,  9.4510e-01, -1.5974e+00, -9.1260e-01,\n",
            "         6.7899e-01,  1.4147e-01,  1.6564e+00, -1.2459e+00, -6.5933e-01,\n",
            "         1.5854e+00, -4.8811e-01,  1.0763e-01,  1.1085e+00,  1.9761e+00,\n",
            "         2.8542e+00,  5.9338e-01, -3.7007e-01,  8.9113e-03, -4.8824e-01,\n",
            "        -1.5122e+00, -2.6118e-01,  1.5405e+00, -7.0592e-01, -1.9216e+00,\n",
            "         6.6916e-02, -5.9056e-01,  2.4245e+00,  1.1539e+00, -1.2916e+00,\n",
            "         1.8359e-04,  7.6925e-01,  4.5184e-01, -6.7763e-01, -8.4672e-02,\n",
            "         4.4378e-01, -1.0113e+00, -1.1095e+00, -1.0450e+00,  5.0513e-01,\n",
            "         1.2282e+00, -1.0158e+00,  1.1204e+00,  2.4895e+00, -1.8030e-01,\n",
            "         3.9638e-01, -1.1816e+00, -7.5793e-01, -3.8924e-01,  2.5938e-02,\n",
            "         2.3946e+00,  3.8613e-01, -2.8420e-01, -1.6761e+00,  1.2132e+00,\n",
            "         3.4458e-01, -7.0365e-01,  2.1324e-01, -8.6610e-01,  9.1316e-01,\n",
            "         9.1462e-01, -3.9592e-01, -4.7439e-01,  1.3778e+00, -4.1463e-01,\n",
            "        -6.4103e-01,  6.4657e-01,  8.6956e-01, -4.7797e-02, -7.7486e-01,\n",
            "        -3.8068e-01, -1.3134e+00, -1.1821e-01,  1.7043e-01, -5.7649e-01,\n",
            "        -1.2330e+00,  7.7437e-01,  6.2511e-01, -8.3450e-01, -4.7074e-01,\n",
            "        -1.5948e-01,  1.2348e+00,  6.7586e-01, -8.9402e-02, -1.5474e+00,\n",
            "         2.7369e-01, -6.7798e-01, -5.8760e-01, -1.6406e+00,  2.9264e-02,\n",
            "         7.4700e-01, -1.1821e+00,  1.3038e+00,  9.5947e-01,  8.4041e-01,\n",
            "         9.2962e-01, -6.8461e-02,  5.7969e-02, -8.3721e-01,  1.2440e+00,\n",
            "         1.1932e+00, -2.8266e-01,  4.8726e-02, -3.0873e-01,  1.2336e+00,\n",
            "         1.5068e+00, -5.6732e-01,  7.9469e-01,  1.0674e-01, -2.2428e-02,\n",
            "        -9.6018e-01,  1.7393e-01, -1.6396e+00,  1.0041e-02, -5.9756e-01,\n",
            "         3.5739e-01, -5.6852e-01,  4.0723e-01, -5.4740e-01, -6.3281e-01,\n",
            "         1.8167e+00, -2.0396e+00, -4.7430e-01,  8.7281e-01, -9.3614e-01,\n",
            "        -1.8239e+00,  8.8923e-02,  6.7746e-01, -1.2288e+00, -3.3402e-01,\n",
            "         1.8615e-01,  8.8366e-01,  4.3560e-01, -8.4578e-01,  3.2233e-01,\n",
            "         5.3687e-01, -3.0291e-01, -9.3101e-01, -2.6162e-01,  2.2298e-01,\n",
            "         2.9888e-01, -5.3181e-01, -2.6590e-01,  4.1806e-01,  8.4687e-01,\n",
            "         1.3626e-02,  1.1529e-01, -1.5432e+00, -2.9906e-01,  8.7041e-01,\n",
            "         1.6500e+00,  9.0535e-02, -9.2833e-01, -5.0878e-01,  1.2332e-01,\n",
            "         6.4890e-02, -1.8181e-02,  4.2200e-01,  3.1529e-01, -2.4033e-02,\n",
            "         9.0396e-01,  1.7761e-02, -1.4860e+00, -7.6736e-01, -6.8301e-01,\n",
            "        -4.0416e-01, -8.7038e-01, -7.9070e-01, -8.8247e-01, -9.7400e-01,\n",
            "         1.1614e+00, -7.8798e-01, -1.2548e-01,  1.2802e+00, -4.0808e-01,\n",
            "         2.8740e-01, -2.7190e-01, -3.8865e-01,  3.1463e-01, -1.4520e+00,\n",
            "        -1.1839e-01,  8.1053e-01,  3.5582e-01, -6.1620e-01, -5.9911e-01,\n",
            "         1.1615e+00,  4.7137e-01, -2.6035e-01, -4.9170e-01,  3.8806e-01,\n",
            "        -1.6687e+00, -3.3294e-01,  1.0926e+00, -4.6654e-01, -1.5899e-01,\n",
            "        -1.9273e+00, -4.6530e-01, -1.0440e+00, -7.2689e-01,  6.8223e-02,\n",
            "         1.1075e+00,  1.5500e+00,  2.0055e+00,  1.4474e+00,  6.7793e-01,\n",
            "         1.0859e+00, -1.7115e-01,  1.1592e+00, -3.2708e-01,  1.5252e+00,\n",
            "        -1.7236e+00,  1.1913e+00,  7.1397e-01, -3.4008e-01, -4.0867e-01,\n",
            "        -1.1950e-01,  1.1514e+00, -3.8260e-01, -1.2589e+00, -1.4752e+00,\n",
            "        -1.0137e-01,  4.9927e-01,  2.2676e+00,  3.4029e-01,  1.5719e+00,\n",
            "        -1.2672e+00,  1.5523e+00, -7.2525e-01, -2.0601e-01, -2.3726e-01,\n",
            "         3.6530e-01, -2.2441e-01,  3.5050e-01,  3.2378e-01,  6.1485e-01,\n",
            "         1.9553e+00,  6.9758e-01, -4.0579e-01,  1.2991e+00,  1.4189e+00,\n",
            "         4.2036e-01,  7.8366e-01,  2.5834e-01,  6.7614e-01,  5.4231e-01,\n",
            "         5.0518e-01, -4.2749e-02, -7.4530e-01, -7.2018e-01, -8.6585e-01,\n",
            "        -1.2319e+00, -5.7757e-01,  2.1782e-01, -1.0126e+00, -7.2338e-01,\n",
            "        -1.1415e-01, -4.2556e-01,  1.0373e+00,  1.0315e+00, -9.9753e-01,\n",
            "         1.0173e-02, -6.6912e-01, -6.2212e-01, -1.2014e-01, -1.3140e-01,\n",
            "        -9.9437e-02, -5.7913e-01, -1.6482e+00, -8.0848e-02,  1.5020e+00,\n",
            "         2.0624e+00, -6.4218e-01,  9.7119e-01,  4.5075e-01, -8.4659e-02,\n",
            "         3.7485e-01,  1.1646e+00, -1.5814e+00,  9.9856e-02, -2.3453e+00,\n",
            "         4.1932e-01, -3.7546e-01, -8.7339e-01,  5.0505e-01, -2.0255e-01,\n",
            "         6.5500e-02, -2.0690e-01, -1.8130e+00,  1.7416e+00, -1.3954e+00,\n",
            "         2.1297e-01, -5.8536e-01,  1.7997e-01, -4.4359e-01, -1.0072e-01,\n",
            "        -4.1917e-01, -1.5068e+00,  1.7583e-01, -1.3258e+00,  4.7459e-01,\n",
            "         9.9505e-01,  1.7070e+00,  1.1880e-01, -3.8174e-01, -1.0760e+00,\n",
            "         3.0159e-01, -7.3456e-01,  1.6962e+00,  6.3003e-02,  1.5439e-01,\n",
            "        -8.4745e-01,  2.0592e-01,  4.2246e-01, -5.3462e-01,  8.0959e-01,\n",
            "         1.1264e-01, -4.8568e-01, -3.7320e-01, -1.8982e+00,  1.3994e+00,\n",
            "         5.7312e-01,  1.5478e+00,  3.1638e-01, -4.8183e-01,  2.0381e+00,\n",
            "        -2.0639e+00, -1.2787e+00,  2.3463e-01,  5.2558e-02, -6.4631e-01,\n",
            "         6.6926e-01, -1.8806e+00, -2.1045e+00,  5.3368e-01, -3.1029e-01,\n",
            "        -8.9408e-01, -2.0026e-01,  5.3145e-01,  3.7473e-01,  5.1082e-01,\n",
            "         2.5278e-01, -8.6879e-02, -1.1063e+00,  2.1824e-01, -2.0157e-01,\n",
            "         6.1814e-01,  2.6015e-02,  2.2494e-01, -1.5952e+00,  3.8353e-01,\n",
            "        -2.2447e-01, -6.4965e-01,  5.8616e-01,  1.6519e+00, -2.0311e+00,\n",
            "         2.3466e-01,  4.6781e-01, -5.6521e-01,  7.9761e-01,  7.5644e-01,\n",
            "        -7.2453e-02, -6.7761e-02, -5.3906e-01,  1.6307e+00, -1.7311e+00,\n",
            "        -1.0314e+00,  5.9706e-01,  9.0745e-01,  1.5083e-01,  3.1491e-01,\n",
            "        -1.6970e+00, -3.1910e-01,  4.1417e-01,  2.1019e-01, -5.3533e-01,\n",
            "         2.5204e-01, -1.9297e-01,  1.6727e-01, -2.9116e-01,  2.2161e-02,\n",
            "         4.6650e-01,  9.3547e-01,  2.1254e+00,  2.8667e-01, -1.5708e+00,\n",
            "         4.5030e-01, -6.1858e-01, -7.5745e-01, -1.0730e+00,  1.0794e+00,\n",
            "        -8.4305e-01,  1.8041e-01,  1.0038e+00, -1.1496e+00, -1.9294e-01,\n",
            "        -8.5594e-01,  1.4504e+00,  3.8414e-01,  1.0855e+00, -1.0643e+00,\n",
            "        -7.6693e-01, -1.4282e-01, -9.3693e-01, -1.4950e-01,  9.9848e-01,\n",
            "        -1.0397e-01, -3.1277e-01, -5.4000e-01, -7.8885e-03,  4.9671e-01,\n",
            "         7.1793e-01, -2.6370e-01, -3.9000e-01, -8.8409e-01,  6.4233e-01,\n",
            "        -3.0559e-02, -3.7291e-01,  1.8039e+00,  3.2779e-01,  9.8731e-01,\n",
            "         8.7591e-01, -2.6582e-01, -1.7054e-01, -1.4263e-02, -5.6348e-01,\n",
            "        -1.0665e+00,  1.9187e-01,  6.1311e-01, -1.3403e+00,  2.5032e-01,\n",
            "         7.5167e-01,  1.2579e-01, -2.5930e-01,  2.5811e-01,  3.6069e-01,\n",
            "        -6.7842e-01,  1.7194e-01,  6.9240e-01, -3.8903e-01, -4.9146e-01,\n",
            "        -3.7202e-01,  4.2725e-01,  9.2614e-01, -5.1691e-01, -1.7293e+00,\n",
            "         1.5677e+00, -5.0957e-01, -6.4743e-01, -2.9016e-01,  1.8397e-01,\n",
            "         3.2005e-01, -1.3482e+00,  1.6417e-02,  3.3329e-01, -1.4452e+00,\n",
            "        -2.4740e-02, -2.9123e-02, -4.7290e-01,  1.9042e+00, -8.5654e-01,\n",
            "        -4.7915e-01,  4.2848e-01, -7.3558e-01, -4.3962e-01, -9.2851e-01,\n",
            "         4.0268e-01, -1.6094e+00,  6.8937e-01, -6.6392e-01, -1.3675e+00,\n",
            "        -2.2251e+00, -6.5254e-01, -1.9253e+00,  1.0145e+00,  1.1674e+00,\n",
            "        -6.3545e-01,  4.8360e-01,  1.9449e+00, -3.9096e-01, -4.4963e-01,\n",
            "        -5.9288e-01, -1.7022e+00, -5.0638e-02,  1.7331e-01,  1.8061e+00,\n",
            "         1.4118e+00, -4.6769e-01,  3.7303e-02,  1.5780e-01,  1.2302e+00,\n",
            "         1.2189e+00,  1.4208e+00,  8.2026e-02,  7.0784e-01, -6.8046e-01,\n",
            "         7.5496e-01, -2.5713e-01,  8.5570e-02,  5.9486e-01,  2.3438e-02,\n",
            "         5.6156e-01,  1.7670e+00, -2.1357e-01,  1.0681e+00, -3.2138e-01,\n",
            "        -1.3542e-01,  8.9827e-01])), ('module.encoder_q.layer2.0.downsample.1.running_var', tensor([1.5913, 1.6379, 2.4346, 1.7507, 0.6663, 1.5945, 2.3564, 1.0487, 5.3493,\n",
            "        0.9228, 2.0000, 3.6276, 1.2885, 1.0500, 2.7282, 0.8299, 0.9601, 1.7010,\n",
            "        1.2388, 2.7605, 9.0416, 1.9846, 2.1010, 1.6045, 1.2352, 1.5785, 1.1798,\n",
            "        2.9229, 1.0866, 1.8722, 2.4953, 1.1071, 3.5045, 3.2221, 2.1992, 1.7102,\n",
            "        1.5115, 1.0978, 0.9216, 0.8684, 1.5541, 2.1165, 2.1019, 0.9860, 2.0398,\n",
            "        3.0529, 1.7132, 2.3000, 2.6133, 1.0164, 1.9804, 1.8424, 1.4317, 1.8365,\n",
            "        1.1619, 5.0293, 0.7327, 1.3834, 1.2941, 1.1077, 2.1161, 0.5198, 1.5787,\n",
            "        2.4796, 2.3837, 1.4684, 3.0901, 2.5016, 1.2371, 1.6347, 1.3072, 1.1157,\n",
            "        1.7244, 3.3006, 1.6960, 2.3401, 2.0347, 2.8764, 0.8910, 0.8870, 3.1134,\n",
            "        1.8582, 0.9397, 1.3061, 1.1499, 1.0253, 1.2970, 1.8517, 1.3755, 4.1627,\n",
            "        0.9194, 0.9203, 1.3488, 2.2910, 2.0717, 0.6569, 1.9837, 2.4807, 1.3132,\n",
            "        2.1334, 0.7581, 0.8320, 0.9364, 0.6937, 1.3527, 1.3648, 1.4762, 1.7729,\n",
            "        1.4518, 1.0105, 1.4140, 1.4604, 0.9488, 2.0923, 1.0182, 1.7462, 2.2170,\n",
            "        3.6433, 1.2421, 1.0930, 1.1045, 0.9921, 1.3373, 1.1450, 1.1428, 2.4450,\n",
            "        1.6193, 1.5962, 0.7890, 1.8242, 1.1970, 0.5978, 1.2486, 3.2393, 1.6721,\n",
            "        1.1449, 2.1069, 1.4059, 1.2292, 1.1020, 0.8596, 1.5052, 0.4672, 0.9765,\n",
            "        1.1863, 1.3896, 1.3637, 1.4781, 2.3727, 0.7743, 2.8715, 0.9561, 2.0361,\n",
            "        1.3807, 2.3516, 2.2718, 1.3027, 1.6339, 2.2832, 0.5163, 2.3349, 1.8332,\n",
            "        7.8444, 1.5011, 1.1101, 1.9308, 2.4831, 1.1611, 2.1617, 2.1578, 2.5263,\n",
            "        0.8706, 1.7369, 1.7942, 1.2279, 2.8488, 3.5357, 3.0848, 2.4363, 0.7657,\n",
            "        2.0417, 1.4730, 1.6341, 1.0245, 4.3964, 2.4178, 1.7682, 0.7417, 2.6230,\n",
            "        1.5439, 2.7617, 1.3952, 1.0667, 2.5738, 1.9252, 0.9432, 3.6552, 1.0602,\n",
            "        2.1884, 2.0405, 1.3923, 0.8862, 2.0641, 1.8523, 1.7935, 1.2412, 2.6592,\n",
            "        5.2297, 3.8765, 1.0337, 1.5562, 1.5859, 1.0084, 1.4821, 2.1303, 1.5216,\n",
            "        1.3215, 1.4910, 2.1809, 1.2170, 2.8509, 2.7480, 1.2492, 1.3694, 2.3472,\n",
            "        1.0316, 5.9133, 1.7272, 1.2247, 1.3742, 1.4327, 6.0877, 0.7066, 1.4105,\n",
            "        1.0201, 1.4754, 1.0303, 0.7270, 2.1859, 0.6185, 2.3079, 1.4789, 2.0362,\n",
            "        1.5025, 1.4817, 1.0264, 1.9823, 2.2804, 2.9278, 1.2197, 2.3060, 1.9995,\n",
            "        1.2826, 3.3106, 1.3460, 0.8361, 1.3447, 1.5167, 2.0674, 1.7054, 1.1403,\n",
            "        1.4897, 1.2518, 2.0813, 1.5400, 1.2969, 1.7144, 0.8991, 1.6293, 1.1639,\n",
            "        0.8046, 1.4073, 4.2741, 1.6397, 1.7184, 1.3033, 0.9161, 1.1612, 1.1765,\n",
            "        2.5240, 1.2289, 1.7334, 0.9620, 0.8803, 4.0194, 1.2762, 0.9091, 1.2011,\n",
            "        3.3141, 1.3388, 1.5018, 1.2846, 3.2733, 2.4122, 1.9233, 0.6240, 0.7080,\n",
            "        1.2916, 1.0938, 1.5126, 1.3031, 1.1619, 4.0060, 1.0148, 2.1766, 1.4511,\n",
            "        2.0567, 3.1248, 1.5269, 0.7019, 1.5834, 0.7564, 2.4007, 0.8127, 1.1896,\n",
            "        1.0664, 2.6100, 1.1789, 1.3210, 4.5447, 1.4277, 1.6884, 1.1007, 2.2929,\n",
            "        1.4859, 1.3392, 1.4145, 3.1469, 0.7937, 2.3420, 2.9124, 2.0142, 1.5808,\n",
            "        0.7596, 1.3035, 2.4790, 3.0670, 2.1499, 2.1125, 1.6288, 3.0087, 2.4024,\n",
            "        1.4488, 3.3156, 1.3442, 2.0420, 1.4912, 0.8370, 1.9792, 0.7396, 2.6569,\n",
            "        0.9716, 2.7919, 4.9075, 0.9872, 0.6955, 1.4691, 1.8896, 1.8244, 2.6697,\n",
            "        1.0071, 2.4736, 1.1308, 1.0495, 0.8641, 1.2391, 1.8288, 0.8905, 2.3413,\n",
            "        2.8967, 1.7196, 1.5646, 1.3568, 1.3432, 1.8893, 0.9145, 1.9383, 1.4225,\n",
            "        2.9799, 1.2623, 0.7073, 0.6425, 1.1145, 1.1877, 2.5306, 1.1050, 1.0730,\n",
            "        0.9131, 1.1498, 0.8619, 0.6055, 0.9894, 1.0299, 3.1588, 1.2971, 1.2324,\n",
            "        1.7322, 0.5994, 1.7076, 0.8228, 1.6091, 1.0923, 1.8865, 1.4580, 1.2636,\n",
            "        0.7951, 1.6170, 0.7832, 1.0804, 2.3447, 2.0890, 1.9929, 1.0751, 1.1519,\n",
            "        2.8745, 2.9621, 1.6526, 1.1406, 2.6874, 2.0512, 1.2614, 0.7634, 4.2143,\n",
            "        1.3283, 2.5700, 1.9292, 0.6469, 1.3639, 2.3721, 1.4272, 2.1197, 0.8731,\n",
            "        0.6152, 1.1365, 0.6760, 0.9341, 1.4524, 2.6341, 2.3080, 2.6019, 2.8408,\n",
            "        1.1174, 1.9433, 1.1587, 0.8737, 0.8871, 1.0942, 1.5517, 1.2644, 2.7943,\n",
            "        3.2997, 0.8955, 1.3069, 1.0061, 1.3171, 1.5182, 0.8232, 2.4082, 1.6774,\n",
            "        1.4967, 1.6476, 2.4336, 0.8388, 3.9986, 1.7501, 2.2798, 1.3378, 0.6014,\n",
            "        2.0459, 1.4381, 0.9843, 2.2554, 1.7022, 1.5760, 1.4152, 3.5242, 1.8547,\n",
            "        1.5370, 1.3455, 1.7522, 1.7017, 0.8728, 3.3171, 1.5266, 1.2670, 1.9153,\n",
            "        1.2436, 0.8779, 1.9432, 0.6681, 2.9051, 2.0862, 0.9698, 2.0712, 0.9465,\n",
            "        1.5981, 1.2730, 1.5260, 1.3023, 1.1845, 1.3787, 2.0218, 1.5530, 2.2744,\n",
            "        0.9109, 1.0649, 2.2097, 1.5556, 2.7990, 1.0659, 2.5636, 0.7791])), ('module.encoder_q.layer2.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.1.conv1.weight', tensor([[[[-0.0612]],\n",
            "\n",
            "         [[-0.0012]],\n",
            "\n",
            "         [[-0.0197]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0496]],\n",
            "\n",
            "         [[-0.2499]],\n",
            "\n",
            "         [[ 0.1991]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0471]],\n",
            "\n",
            "         [[-0.1442]],\n",
            "\n",
            "         [[-0.1113]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2015]],\n",
            "\n",
            "         [[-0.1820]],\n",
            "\n",
            "         [[ 0.1685]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0434]],\n",
            "\n",
            "         [[ 0.0632]],\n",
            "\n",
            "         [[-0.0348]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1115]],\n",
            "\n",
            "         [[ 0.1635]],\n",
            "\n",
            "         [[ 0.0700]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0540]],\n",
            "\n",
            "         [[-0.0752]],\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1702]],\n",
            "\n",
            "         [[ 0.1751]],\n",
            "\n",
            "         [[ 0.0654]]],\n",
            "\n",
            "\n",
            "        [[[-0.1912]],\n",
            "\n",
            "         [[-0.0807]],\n",
            "\n",
            "         [[-0.0642]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1222]],\n",
            "\n",
            "         [[ 0.1624]],\n",
            "\n",
            "         [[ 0.0277]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0297]],\n",
            "\n",
            "         [[ 0.0342]],\n",
            "\n",
            "         [[-0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0027]],\n",
            "\n",
            "         [[ 0.0614]],\n",
            "\n",
            "         [[ 0.1562]]]])), ('module.encoder_q.layer2.1.bn1.weight', tensor([0.9907, 0.9965, 0.9920, 0.9894, 0.9948, 0.9934, 0.9944, 0.9950, 0.9872,\n",
            "        0.9939, 0.9986, 0.9892, 0.9930, 0.9901, 0.9962, 0.9906, 0.9919, 0.9994,\n",
            "        0.9988, 0.9916, 0.9941, 0.9911, 0.9912, 0.9871, 0.9979, 0.9910, 0.9929,\n",
            "        0.9938, 0.9979, 0.9914, 0.9924, 0.9927, 0.9939, 0.9913, 0.9939, 0.9844,\n",
            "        0.9928, 0.9929, 0.9911, 0.9919, 0.9921, 0.9901, 0.9964, 0.9940, 0.9883,\n",
            "        0.9950, 0.9973, 0.9957, 0.9875, 0.9880, 0.9959, 0.9921, 0.9964, 0.9916,\n",
            "        0.9924, 0.9904, 0.9954, 0.9892, 0.9936, 0.9985, 0.9939, 0.9942, 0.9914,\n",
            "        0.9885, 0.9966, 0.9948, 0.9892, 0.9883, 0.9916, 0.9945, 0.9883, 0.9888,\n",
            "        0.9913, 0.9908, 0.9891, 0.9944, 0.9894, 0.9869, 0.9936, 0.9912, 0.9886,\n",
            "        0.9921, 0.9878, 0.9877, 0.9881, 0.9989, 0.9947, 0.9904, 0.9897, 0.9955,\n",
            "        0.9875, 0.9956, 0.9934, 0.9880, 0.9910, 0.9900, 0.9886, 0.9926, 0.9970,\n",
            "        0.9934, 0.9878, 0.9908, 0.9939, 0.9913, 0.9881, 0.9961, 0.9878, 0.9869,\n",
            "        0.9949, 0.9938, 0.9909, 0.9857, 0.9928, 0.9979, 0.9917, 0.9924, 0.9907,\n",
            "        1.0026, 0.9907, 0.9927, 0.9975, 0.9923, 0.9924, 0.9920, 0.9933, 0.9918,\n",
            "        0.9910, 0.9896])), ('module.encoder_q.layer2.1.bn1.bias', tensor([-3.1171e-04,  2.7754e-03, -1.0636e-03, -2.7944e-03,  3.1804e-03,\n",
            "        -1.1624e-03, -3.5307e-04,  1.7302e-03, -4.2004e-03, -9.3914e-04,\n",
            "         2.4764e-03,  4.7193e-04,  9.3078e-04,  6.2332e-04,  4.7658e-03,\n",
            "        -3.7288e-03, -4.2485e-03,  8.2377e-03,  6.3449e-03, -1.6443e-03,\n",
            "         3.5326e-03, -4.5384e-03,  8.8231e-04, -3.8189e-03,  5.1331e-03,\n",
            "        -1.4243e-03,  8.6760e-04,  4.2855e-04, -6.4312e-04,  5.9764e-04,\n",
            "         6.3477e-04,  2.6200e-03,  4.0044e-03, -1.8156e-03, -3.4372e-04,\n",
            "        -2.0612e-03,  4.7739e-03, -1.8611e-04,  8.0831e-04,  1.7913e-03,\n",
            "         5.4525e-03, -5.7263e-03,  5.7875e-04,  2.6683e-03, -4.2189e-03,\n",
            "         4.6446e-03,  4.1678e-03, -9.0832e-05,  1.8778e-03,  9.6639e-04,\n",
            "         2.3903e-03,  5.7465e-03,  1.8162e-03, -3.0004e-03,  1.2341e-03,\n",
            "        -8.6067e-04,  6.4096e-04, -3.5834e-03,  1.1607e-03,  2.9668e-03,\n",
            "         8.3900e-04, -2.7710e-03,  2.8449e-03, -1.6739e-03,  3.4764e-03,\n",
            "        -1.7831e-03,  4.9509e-04, -3.5422e-03,  1.3163e-03,  3.3063e-03,\n",
            "        -5.4487e-03, -4.4801e-03, -2.0816e-03, -7.7287e-03, -4.2101e-04,\n",
            "         2.0444e-04, -1.0057e-03, -7.9270e-03,  5.9918e-04, -2.8355e-03,\n",
            "         5.5089e-04, -9.2892e-04, -4.2211e-03, -4.1821e-03, -4.0379e-04,\n",
            "         2.6196e-03, -1.5985e-03, -7.3531e-04, -8.9548e-04,  4.1688e-03,\n",
            "        -5.9071e-05,  4.1998e-03, -4.8913e-04, -9.5941e-04, -3.8678e-04,\n",
            "         1.7659e-03, -7.2283e-03,  3.2414e-03,  9.6459e-04,  1.3371e-03,\n",
            "        -1.0249e-03, -4.9547e-04,  1.9559e-03, -1.0726e-03, -1.6832e-03,\n",
            "        -9.2342e-04, -5.4519e-03, -1.2255e-03,  3.8384e-03,  2.3227e-03,\n",
            "        -1.5161e-03, -5.3927e-03, -2.3058e-03,  1.4977e-03,  1.9491e-03,\n",
            "        -5.2385e-03, -2.7322e-03,  4.5378e-03, -4.2428e-03,  1.5334e-03,\n",
            "         1.3310e-03,  2.2102e-03,  1.3598e-03, -3.2858e-03, -2.0003e-03,\n",
            "        -2.1102e-03,  1.7930e-03, -4.1944e-04])), ('module.encoder_q.layer2.1.bn1.running_mean', tensor([ 1.0621, -1.5026, -1.7099,  2.2099, -0.0605, -1.0256,  0.6145, -1.1713,\n",
            "        -2.7545,  0.4209,  0.3607,  0.4157,  0.2932, -1.8536, -0.7440, -0.5452,\n",
            "        -1.1483,  0.6748, -1.4645, -1.8939, -1.6201, -1.5871,  0.3040,  0.8767,\n",
            "         1.1863,  2.1105,  0.6600, -0.0500,  0.9324,  0.5152, -1.5344,  2.0627,\n",
            "        -0.4555,  1.3825, -0.0958,  1.3497, -1.0553,  0.6505,  0.4849, -1.9930,\n",
            "         0.9518, -2.4033,  2.0354, -0.0790,  2.0032, -1.6091,  1.9633,  0.9476,\n",
            "        -0.9172, -0.8465,  1.3282,  0.3294,  0.0711, -0.2847, -1.6204,  2.0608,\n",
            "         0.6000, -2.0161,  2.9235, -1.0824,  0.3586,  1.8882,  2.0642, -1.3628,\n",
            "         2.1981,  0.7878, -1.3029, -0.5630,  0.6517,  2.4091, -2.5145, -1.4535,\n",
            "         0.6725,  0.8307, -0.4533,  1.8840, -0.2865,  1.5254, -2.6195, -2.1640,\n",
            "        -1.4551, -0.0129,  0.8798, -2.1794,  0.4915, -0.3283,  2.5249,  1.3400,\n",
            "        -0.4603,  1.2405,  0.4775,  2.2844, -2.1630,  1.2570,  1.3768,  0.7015,\n",
            "        -2.5289, -1.7924,  2.4509,  1.5367,  3.1730, -0.9710, -1.7098,  1.5822,\n",
            "         0.3707,  1.0908,  0.6423,  0.5651,  0.2716,  1.8031, -0.6715, -0.4835,\n",
            "         1.5935, -0.7813,  1.5201,  0.7963, -1.9924,  0.6612, -1.9523,  0.8673,\n",
            "         2.3200,  1.4469,  1.0355,  0.0737, -1.5790,  0.3811,  1.4422,  1.7396])), ('module.encoder_q.layer2.1.bn1.running_var', tensor([ 6.3740,  3.9448, 11.7406,  5.6122,  7.2381,  5.1435, 14.3561,  7.3986,\n",
            "        10.9078,  6.3653,  8.6224,  5.4904, 11.1400,  8.8998,  5.9537,  8.7533,\n",
            "         6.2108,  5.3661,  3.6509,  9.2905,  5.1589,  5.9531,  2.7595,  6.3662,\n",
            "         6.5664, 13.6908,  9.2514,  7.2511,  8.9530,  6.8510,  5.7870,  5.6697,\n",
            "         6.7674,  4.4574,  5.3188,  5.6648,  4.7328,  3.5191,  6.3958, 13.2088,\n",
            "         6.4577,  7.6706,  7.0980,  4.6282,  5.7596,  5.3398,  3.1651,  8.4418,\n",
            "         7.2872,  9.5660,  4.5530,  6.4123,  3.6987,  3.2914,  9.7856,  5.3899,\n",
            "         8.9399,  6.5721, 18.8563,  8.9051,  3.7056,  5.3622, 12.2421,  4.2159,\n",
            "         9.1465,  7.5612,  5.7024,  4.3991, 11.2803, 12.0151,  4.9815, 13.8256,\n",
            "         9.4412,  5.8655,  5.2360,  5.2095,  5.3426,  6.1615, 11.3642, 13.1402,\n",
            "         4.9152,  5.5915, 10.7615,  3.4803,  3.6593,  4.7295, 12.9441,  4.3053,\n",
            "         3.1675,  9.4220, 14.9758,  6.8325,  5.1047,  6.1035,  5.7972,  7.2256,\n",
            "         6.9495,  4.0563,  6.6458,  5.1301, 13.0794,  6.3283, 13.5987,  4.6155,\n",
            "         7.9695,  7.0688,  4.8922,  4.3190,  3.5864,  7.5087,  3.9634, 10.3701,\n",
            "         4.5218,  3.5402,  4.9650, 14.1657,  6.1329, 10.3160,  7.8237,  4.7773,\n",
            "         4.7648,  5.6529,  6.5477,  5.1800,  7.6436,  6.1022,  7.8400,  6.0807])), ('module.encoder_q.layer2.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.1.conv2.weight', tensor([[[[-0.0174,  0.0701,  0.0064],\n",
            "          [ 0.1084, -0.0501, -0.0633],\n",
            "          [-0.0409, -0.0948,  0.0133]],\n",
            "\n",
            "         [[-0.0267,  0.0504,  0.0165],\n",
            "          [-0.0341, -0.0788,  0.0103],\n",
            "          [ 0.0621,  0.0043, -0.0246]],\n",
            "\n",
            "         [[-0.0347,  0.0077,  0.0379],\n",
            "          [ 0.0175,  0.0730, -0.0993],\n",
            "          [ 0.0481, -0.0040, -0.0367]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0310, -0.0209,  0.0438],\n",
            "          [ 0.0360, -0.0073,  0.0025],\n",
            "          [-0.0552,  0.0221, -0.0553]],\n",
            "\n",
            "         [[ 0.0105, -0.0163, -0.0402],\n",
            "          [ 0.0051,  0.0144,  0.0510],\n",
            "          [-0.0321,  0.0076,  0.0559]],\n",
            "\n",
            "         [[-0.1229,  0.0082, -0.0662],\n",
            "          [ 0.0667,  0.0603, -0.0419],\n",
            "          [ 0.0646, -0.0209,  0.0333]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0012, -0.0120, -0.1050],\n",
            "          [ 0.0445,  0.0504,  0.0369],\n",
            "          [ 0.0082,  0.0142,  0.0045]],\n",
            "\n",
            "         [[ 0.0185, -0.0961,  0.0208],\n",
            "          [ 0.0635, -0.0279, -0.0271],\n",
            "          [-0.0438, -0.1063,  0.0722]],\n",
            "\n",
            "         [[-0.0234, -0.0101, -0.1132],\n",
            "          [-0.0106, -0.0177, -0.0268],\n",
            "          [-0.0676, -0.0019, -0.0097]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0439, -0.0066,  0.0005],\n",
            "          [ 0.0098,  0.0290,  0.0325],\n",
            "          [ 0.0115,  0.0623, -0.0026]],\n",
            "\n",
            "         [[ 0.0268,  0.0157, -0.0593],\n",
            "          [-0.0021,  0.0949, -0.0122],\n",
            "          [-0.0010, -0.0291,  0.0330]],\n",
            "\n",
            "         [[ 0.0186,  0.0035, -0.0190],\n",
            "          [-0.0248,  0.0358,  0.0941],\n",
            "          [ 0.0191,  0.0796, -0.0645]]],\n",
            "\n",
            "\n",
            "        [[[-0.0056,  0.0041,  0.0178],\n",
            "          [ 0.0238, -0.0248, -0.0433],\n",
            "          [ 0.0369,  0.0253,  0.0724]],\n",
            "\n",
            "         [[-0.0063, -0.0174,  0.0380],\n",
            "          [ 0.0224,  0.0264, -0.0164],\n",
            "          [-0.0237,  0.0323,  0.0787]],\n",
            "\n",
            "         [[-0.0280, -0.0043, -0.0343],\n",
            "          [-0.0100, -0.0175,  0.0504],\n",
            "          [-0.0614, -0.0638, -0.0231]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0257, -0.0514, -0.0462],\n",
            "          [ 0.0221, -0.0391,  0.1123],\n",
            "          [ 0.0506,  0.0226, -0.0020]],\n",
            "\n",
            "         [[-0.0318, -0.0831, -0.0196],\n",
            "          [-0.0618, -0.0030, -0.0116],\n",
            "          [ 0.0117, -0.0327, -0.0275]],\n",
            "\n",
            "         [[ 0.0093, -0.0069,  0.0075],\n",
            "          [-0.0216,  0.0071,  0.0093],\n",
            "          [-0.0185, -0.0244,  0.0746]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0095, -0.0505,  0.0450],\n",
            "          [ 0.0219,  0.0421,  0.0518],\n",
            "          [-0.0612,  0.0506, -0.0118]],\n",
            "\n",
            "         [[-0.0330, -0.0380, -0.0901],\n",
            "          [ 0.0283,  0.0570, -0.0241],\n",
            "          [-0.0152,  0.0416,  0.0532]],\n",
            "\n",
            "         [[ 0.0700,  0.0532,  0.0395],\n",
            "          [ 0.0165, -0.0487, -0.0168],\n",
            "          [ 0.0004, -0.0327, -0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0937,  0.0485, -0.0215],\n",
            "          [-0.0704, -0.0123, -0.0414],\n",
            "          [ 0.0285, -0.0349, -0.0210]],\n",
            "\n",
            "         [[-0.0388, -0.0139, -0.0186],\n",
            "          [ 0.0043,  0.0474,  0.0415],\n",
            "          [-0.0399,  0.0462, -0.0345]],\n",
            "\n",
            "         [[ 0.0231, -0.0827, -0.0118],\n",
            "          [ 0.0096, -0.0366, -0.0661],\n",
            "          [-0.0889,  0.0109, -0.0207]]],\n",
            "\n",
            "\n",
            "        [[[-0.0517, -0.0153, -0.0234],\n",
            "          [ 0.0423,  0.0332,  0.0678],\n",
            "          [-0.0357,  0.0453,  0.0488]],\n",
            "\n",
            "         [[-0.0199, -0.0642, -0.0065],\n",
            "          [ 0.0166, -0.0045,  0.0284],\n",
            "          [ 0.0829,  0.0264,  0.0310]],\n",
            "\n",
            "         [[ 0.0770,  0.0154, -0.0513],\n",
            "          [ 0.0443, -0.0477,  0.0104],\n",
            "          [-0.0773, -0.0538,  0.0009]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0027, -0.0175, -0.0092],\n",
            "          [ 0.0586, -0.0256,  0.0384],\n",
            "          [-0.0027,  0.0177, -0.0235]],\n",
            "\n",
            "         [[-0.0695,  0.0502, -0.0168],\n",
            "          [-0.0332, -0.0426, -0.0573],\n",
            "          [ 0.0287, -0.0528, -0.0173]],\n",
            "\n",
            "         [[ 0.0733,  0.0135, -0.0101],\n",
            "          [ 0.0122, -0.0024, -0.0080],\n",
            "          [-0.0242,  0.0183, -0.0300]]],\n",
            "\n",
            "\n",
            "        [[[-0.0314, -0.0087, -0.0059],\n",
            "          [ 0.0840,  0.0310, -0.0025],\n",
            "          [ 0.0300,  0.0101,  0.0171]],\n",
            "\n",
            "         [[-0.0262, -0.0710,  0.0514],\n",
            "          [ 0.0163, -0.0356, -0.0141],\n",
            "          [-0.0458,  0.0711,  0.0138]],\n",
            "\n",
            "         [[ 0.0991, -0.0064,  0.0274],\n",
            "          [ 0.0073, -0.0554,  0.0605],\n",
            "          [ 0.0173, -0.0653,  0.0473]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0337,  0.0033, -0.0223],\n",
            "          [ 0.0352,  0.0119, -0.0028],\n",
            "          [ 0.0893,  0.0170, -0.0272]],\n",
            "\n",
            "         [[-0.0421, -0.0040, -0.0473],\n",
            "          [ 0.0091,  0.0615,  0.1039],\n",
            "          [-0.0529, -0.0031, -0.0194]],\n",
            "\n",
            "         [[ 0.0018,  0.0659,  0.0224],\n",
            "          [ 0.0374, -0.0315, -0.0536],\n",
            "          [-0.0200,  0.0798, -0.0355]]]])), ('module.encoder_q.layer2.1.bn2.weight', tensor([0.9967, 0.9973, 0.9957, 0.9940, 0.9956, 0.9952, 0.9918, 0.9914, 0.9934,\n",
            "        0.9929, 0.9950, 0.9896, 0.9941, 0.9976, 0.9942, 0.9902, 0.9987, 0.9895,\n",
            "        0.9911, 0.9900, 0.9913, 0.9899, 0.9987, 0.9995, 0.9915, 0.9927, 0.9898,\n",
            "        0.9927, 0.9888, 0.9928, 0.9919, 0.9942, 0.9905, 0.9930, 0.9878, 0.9891,\n",
            "        0.9907, 0.9886, 0.9947, 0.9915, 0.9899, 0.9867, 0.9938, 0.9880, 0.9942,\n",
            "        0.9907, 0.9926, 0.9959, 0.9955, 0.9942, 0.9916, 0.9928, 0.9952, 0.9915,\n",
            "        0.9940, 0.9910, 0.9920, 0.9899, 0.9902, 0.9930, 0.9902, 0.9910, 0.9916,\n",
            "        0.9918, 0.9977, 0.9902, 0.9922, 0.9934, 0.9898, 0.9929, 0.9974, 0.9933,\n",
            "        0.9905, 0.9904, 0.9920, 0.9938, 0.9904, 0.9918, 0.9885, 0.9952, 0.9934,\n",
            "        0.9856, 0.9884, 0.9956, 0.9929, 0.9928, 0.9910, 0.9912, 1.0040, 0.9913,\n",
            "        0.9927, 0.9880, 0.9911, 0.9883, 0.9923, 0.9921, 0.9932, 0.9917, 0.9922,\n",
            "        0.9899, 0.9886, 0.9934, 0.9906, 0.9895, 0.9850, 0.9976, 0.9931, 0.9926,\n",
            "        0.9993, 0.9875, 0.9934, 0.9930, 0.9942, 0.9890, 0.9908, 0.9927, 0.9912,\n",
            "        0.9905, 0.9906, 0.9892, 0.9925, 0.9908, 0.9921, 0.9921, 0.9916, 0.9964,\n",
            "        0.9926, 0.9912])), ('module.encoder_q.layer2.1.bn2.bias', tensor([ 4.4917e-03,  1.9534e-03,  7.7577e-04, -1.0570e-03, -1.6590e-03,\n",
            "        -1.7992e-03, -1.5389e-03, -2.0743e-04,  3.2798e-03, -3.5479e-03,\n",
            "        -2.0087e-04,  1.2303e-03,  1.5088e-04,  6.3740e-03,  1.7413e-03,\n",
            "        -4.3163e-03,  3.4489e-03, -2.4674e-03, -5.1937e-04,  2.0503e-04,\n",
            "        -1.3778e-03, -1.8806e-03,  5.4679e-03,  6.6119e-03, -1.2089e-03,\n",
            "        -7.6912e-04, -1.8265e-03,  2.3924e-03, -4.9433e-03,  3.3407e-04,\n",
            "         2.5026e-03,  3.3476e-03,  3.4176e-03,  1.5013e-03, -1.4732e-03,\n",
            "        -4.2023e-03, -2.0048e-03, -5.2973e-03,  3.7832e-03,  1.3541e-05,\n",
            "        -4.5644e-03, -2.4225e-03, -5.4647e-05, -2.1145e-04,  3.4530e-03,\n",
            "        -4.9759e-03, -1.6652e-04,  1.0397e-04,  3.3165e-03, -1.3499e-03,\n",
            "         2.6538e-04, -1.2754e-03,  8.9491e-04, -2.6674e-03,  3.8470e-03,\n",
            "         1.9071e-03,  2.2162e-04, -1.1669e-03, -1.8251e-03, -2.2263e-04,\n",
            "        -2.9106e-03, -6.3007e-04, -5.1559e-04, -1.4763e-03,  7.9592e-04,\n",
            "         1.7363e-04,  4.1464e-04,  1.7914e-03, -1.0334e-03,  9.4307e-04,\n",
            "         1.2010e-03,  2.3458e-03,  2.2343e-03,  3.1578e-03, -3.2868e-04,\n",
            "         3.0780e-03, -1.4830e-03,  3.0297e-03, -5.6054e-03, -1.1861e-03,\n",
            "        -1.0769e-03, -2.5296e-03, -4.1910e-03,  3.2069e-03, -2.2059e-03,\n",
            "         3.6912e-04,  5.0139e-03, -1.1642e-03,  5.8314e-03, -9.5542e-04,\n",
            "        -2.5706e-03, -2.0856e-03,  1.3275e-03, -2.3779e-03,  3.6638e-04,\n",
            "         1.0584e-03, -4.1186e-03, -7.6515e-04,  2.7492e-03, -3.8628e-04,\n",
            "        -4.0607e-03,  1.3999e-03,  8.2861e-04, -2.9267e-03, -3.4895e-03,\n",
            "         6.5292e-03,  1.0303e-03,  2.0052e-03,  4.7592e-03, -1.9920e-03,\n",
            "         6.0036e-04, -2.7962e-03,  3.4040e-03, -4.8763e-03,  2.4244e-03,\n",
            "        -1.0717e-03,  1.0639e-03,  1.5783e-03, -3.3311e-03,  1.1545e-03,\n",
            "         2.1124e-03,  2.4095e-03, -2.2038e-03, -2.4439e-03,  4.4142e-03,\n",
            "         1.7885e-03, -1.3401e-03, -1.7639e-03])), ('module.encoder_q.layer2.1.bn2.running_mean', tensor([ 0.0289,  0.0813, -0.0455,  0.4543,  0.4425, -0.0667,  0.0547, -0.7610,\n",
            "        -0.1208, -0.1821,  0.6632, -0.5446,  0.1185, -0.1443, -0.2949,  0.1619,\n",
            "         0.4970,  0.8357, -0.4373,  0.7812, -0.4457,  1.1958,  0.2218, -0.3930,\n",
            "         0.2466,  0.4218,  0.5083,  0.7563,  0.0107,  0.0718,  0.2056, -0.7992,\n",
            "         0.9193, -0.0565, -0.1506, -0.6197,  0.4987,  0.2547, -0.5679,  0.5641,\n",
            "         0.5981, -0.6543,  0.1225,  0.1500, -0.9070, -0.1550,  0.3029,  0.7731,\n",
            "         0.9331,  0.4315,  0.2207, -1.2880,  0.1624,  0.0606,  0.8628, -0.6264,\n",
            "         0.1005,  0.4209, -0.0869, -0.5196,  0.4993, -0.0295,  0.4329, -0.0955,\n",
            "         0.5451,  0.1917, -0.0544, -0.4399,  0.1688,  0.4990, -0.1894, -0.7458,\n",
            "        -0.2614, -0.8280, -1.1952,  0.0678, -0.0361, -0.4220,  0.2515, -0.2191,\n",
            "         0.6296,  0.5647, -0.3298,  0.0934, -0.0349,  0.0946,  0.4806, -0.8844,\n",
            "         0.2413,  0.2942, -0.3625, -0.2578,  0.2545,  0.3746, -0.1064,  0.4152,\n",
            "         0.4380, -0.9290, -1.0503, -0.0116,  1.1393,  0.7310,  0.3055,  0.3653,\n",
            "         0.3975, -0.6520, -0.0793, -0.7120, -0.2284, -1.2776, -0.2892, -0.4077,\n",
            "        -0.5659, -0.9599, -0.3642,  1.2254, -0.0641,  1.1716,  0.0736,  0.6113,\n",
            "        -0.5618,  0.4433,  0.0896,  0.5345, -0.5549,  0.0919,  0.7569,  0.2965])), ('module.encoder_q.layer2.1.bn2.running_var', tensor([0.5498, 0.7883, 0.7261, 0.9533, 0.7267, 0.9600, 0.8833, 1.1968, 0.9221,\n",
            "        1.2847, 1.2443, 0.8140, 0.9911, 0.8014, 1.2472, 0.9037, 0.5298, 1.4752,\n",
            "        1.3044, 1.3935, 0.7508, 1.3722, 0.9634, 0.7177, 2.0699, 1.0004, 0.8323,\n",
            "        1.2415, 0.8092, 0.8855, 0.9949, 1.1143, 1.7914, 0.8434, 0.8759, 0.6252,\n",
            "        0.6601, 0.9306, 0.9771, 0.5045, 1.1892, 0.4525, 0.7544, 0.8464, 1.2906,\n",
            "        0.6930, 0.7667, 1.2418, 1.5266, 0.7933, 0.5750, 0.6988, 0.8164, 0.9579,\n",
            "        0.9878, 1.3071, 1.0282, 0.8760, 1.6162, 1.2017, 0.6653, 0.5898, 0.9893,\n",
            "        1.1596, 0.7069, 1.0505, 0.5443, 0.7267, 0.8863, 0.6782, 0.6792, 1.8732,\n",
            "        0.5431, 0.9767, 1.1120, 0.9506, 1.1219, 1.0876, 0.7385, 0.9079, 1.2594,\n",
            "        1.0553, 0.3753, 0.5499, 0.7094, 0.5433, 0.7174, 1.0188, 0.9926, 0.7305,\n",
            "        1.1288, 0.6848, 0.6102, 2.4604, 0.9562, 1.4987, 0.8494, 0.9203, 1.4799,\n",
            "        1.0914, 1.2815, 1.1791, 0.6375, 1.1767, 0.8382, 0.9811, 0.5104, 1.5822,\n",
            "        1.3222, 0.6958, 0.5922, 1.0480, 0.4269, 0.6340, 1.5300, 2.4595, 1.0537,\n",
            "        0.7005, 0.8122, 0.8083, 1.0503, 0.7078, 0.6374, 1.2703, 0.7354, 0.8678,\n",
            "        0.6381, 0.7647])), ('module.encoder_q.layer2.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.1.conv3.weight', tensor([[[[ 0.0094]],\n",
            "\n",
            "         [[-0.0112]],\n",
            "\n",
            "         [[-0.0786]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0311]],\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         [[ 0.0148]]],\n",
            "\n",
            "\n",
            "        [[[-0.0510]],\n",
            "\n",
            "         [[-0.0978]],\n",
            "\n",
            "         [[-0.0175]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0415]],\n",
            "\n",
            "         [[ 0.0446]],\n",
            "\n",
            "         [[ 0.0147]]],\n",
            "\n",
            "\n",
            "        [[[-0.1197]],\n",
            "\n",
            "         [[ 0.1118]],\n",
            "\n",
            "         [[-0.0713]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0418]],\n",
            "\n",
            "         [[ 0.0600]],\n",
            "\n",
            "         [[ 0.0706]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0271]],\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         [[-0.0326]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0602]],\n",
            "\n",
            "         [[ 0.0735]],\n",
            "\n",
            "         [[ 0.0197]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047]],\n",
            "\n",
            "         [[-0.0113]],\n",
            "\n",
            "         [[-0.1047]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0409]],\n",
            "\n",
            "         [[-0.0174]],\n",
            "\n",
            "         [[-0.1079]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0215]],\n",
            "\n",
            "         [[ 0.0181]],\n",
            "\n",
            "         [[ 0.0376]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0143]],\n",
            "\n",
            "         [[-0.0041]],\n",
            "\n",
            "         [[ 0.0032]]]])), ('module.encoder_q.layer2.1.bn3.weight', tensor([0.9928, 0.9934, 0.9939, 0.9930, 0.9917, 0.9956, 0.9946, 0.9926, 0.9905,\n",
            "        0.9927, 0.9900, 0.9916, 0.9929, 0.9942, 0.9915, 0.9925, 0.9911, 0.9911,\n",
            "        0.9930, 0.9903, 0.9917, 0.9942, 0.9909, 0.9921, 0.9947, 0.9923, 0.9912,\n",
            "        0.9922, 0.9913, 0.9942, 0.9925, 0.9911, 0.9927, 0.9925, 0.9934, 0.9927,\n",
            "        0.9958, 0.9925, 0.9917, 0.9930, 0.9921, 0.9924, 0.9913, 0.9924, 0.9902,\n",
            "        0.9925, 0.9915, 0.9932, 0.9952, 0.9900, 0.9926, 0.9916, 0.9939, 0.9936,\n",
            "        0.9916, 0.9919, 0.9922, 0.9929, 0.9911, 0.9956, 0.9904, 0.9933, 0.9891,\n",
            "        0.9935, 0.9928, 0.9926, 0.9908, 0.9907, 0.9909, 0.9919, 0.9941, 0.9908,\n",
            "        0.9909, 0.9938, 0.9937, 0.9923, 0.9934, 0.9921, 0.9925, 0.9950, 0.9928,\n",
            "        0.9935, 0.9909, 0.9922, 0.9914, 0.9913, 0.9927, 0.9917, 0.9907, 0.9926,\n",
            "        0.9917, 0.9924, 0.9932, 0.9925, 0.9929, 0.9895, 0.9912, 0.9909, 0.9938,\n",
            "        0.9931, 0.9896, 0.9909, 0.9911, 0.9902, 0.9921, 0.9929, 0.9919, 0.9909,\n",
            "        0.9936, 0.9915, 0.9920, 0.9931, 0.9927, 0.9908, 0.9903, 0.9914, 0.9920,\n",
            "        0.9917, 0.9902, 0.9908, 0.9940, 0.9912, 0.9906, 0.9910, 0.9950, 0.9949,\n",
            "        0.9940, 0.9922, 0.9927, 0.9915, 0.9917, 0.9927, 0.9926, 0.9910, 0.9911,\n",
            "        0.9912, 0.9949, 0.9920, 0.9918, 0.9917, 0.9901, 0.9902, 0.9895, 0.9928,\n",
            "        0.9913, 0.9925, 0.9928, 0.9909, 0.9897, 0.9930, 0.9919, 0.9914, 0.9939,\n",
            "        0.9909, 0.9954, 0.9931, 0.9938, 0.9934, 0.9933, 0.9912, 0.9908, 0.9926,\n",
            "        0.9940, 0.9955, 0.9909, 0.9951, 0.9933, 0.9949, 0.9932, 0.9918, 0.9916,\n",
            "        0.9942, 0.9924, 0.9921, 0.9907, 0.9907, 0.9935, 0.9931, 0.9913, 0.9910,\n",
            "        0.9939, 0.9899, 0.9923, 0.9943, 0.9927, 0.9914, 0.9915, 0.9900, 0.9932,\n",
            "        0.9910, 0.9927, 0.9915, 0.9905, 0.9913, 0.9910, 0.9919, 0.9941, 0.9934,\n",
            "        0.9937, 0.9918, 0.9918, 0.9926, 0.9926, 0.9926, 0.9914, 0.9940, 0.9905,\n",
            "        0.9916, 0.9898, 0.9918, 0.9928, 0.9930, 0.9923, 0.9906, 0.9890, 0.9898,\n",
            "        0.9916, 0.9911, 0.9930, 0.9910, 0.9901, 0.9938, 0.9938, 0.9913, 0.9914,\n",
            "        0.9931, 0.9929, 0.9910, 0.9922, 0.9932, 0.9931, 0.9919, 0.9906, 0.9924,\n",
            "        0.9943, 0.9910, 0.9929, 0.9937, 0.9899, 0.9919, 0.9931, 0.9928, 0.9932,\n",
            "        0.9918, 0.9939, 0.9929, 0.9920, 0.9948, 0.9900, 0.9934, 0.9953, 0.9931,\n",
            "        0.9902, 0.9947, 0.9947, 0.9912, 0.9937, 0.9935, 0.9916, 0.9929, 0.9926,\n",
            "        0.9934, 0.9913, 0.9937, 0.9934, 0.9924, 0.9948, 0.9916, 0.9917, 0.9930,\n",
            "        0.9907, 0.9918, 0.9929, 0.9939, 0.9921, 0.9938, 0.9900, 0.9921, 0.9953,\n",
            "        0.9930, 0.9909, 0.9924, 0.9915, 0.9918, 0.9928, 0.9905, 0.9908, 0.9888,\n",
            "        0.9922, 0.9944, 0.9916, 0.9911, 0.9918, 0.9918, 0.9903, 0.9919, 0.9926,\n",
            "        0.9914, 0.9904, 0.9943, 0.9935, 0.9926, 0.9925, 0.9924, 0.9910, 0.9917,\n",
            "        0.9924, 0.9937, 0.9923, 0.9908, 0.9930, 0.9912, 0.9925, 0.9920, 0.9934,\n",
            "        0.9929, 0.9913, 0.9922, 0.9914, 0.9902, 0.9916, 0.9928, 0.9906, 0.9915,\n",
            "        0.9894, 0.9903, 0.9909, 0.9927, 0.9931, 0.9954, 0.9921, 0.9922, 0.9932,\n",
            "        0.9921, 0.9912, 0.9941, 0.9938, 0.9925, 0.9921, 0.9926, 0.9932, 0.9889,\n",
            "        0.9928, 0.9950, 0.9923, 0.9920, 0.9932, 0.9948, 0.9921, 0.9931, 0.9911,\n",
            "        0.9939, 0.9943, 0.9932, 0.9930, 0.9929, 0.9926, 0.9899, 0.9947, 0.9899,\n",
            "        0.9930, 0.9943, 0.9894, 0.9924, 0.9911, 0.9912, 0.9944, 0.9901, 0.9924,\n",
            "        0.9919, 0.9926, 0.9942, 0.9923, 0.9937, 0.9921, 0.9914, 0.9920, 0.9907,\n",
            "        0.9924, 0.9924, 0.9922, 0.9945, 0.9944, 0.9904, 0.9907, 0.9906, 0.9932,\n",
            "        0.9910, 0.9920, 0.9921, 0.9933, 0.9926, 0.9902, 0.9946, 0.9932, 0.9904,\n",
            "        0.9910, 0.9949, 0.9908, 0.9949, 0.9932, 0.9941, 0.9924, 0.9927, 0.9896,\n",
            "        0.9899, 0.9912, 0.9942, 0.9926, 0.9931, 0.9914, 0.9922, 0.9922, 0.9927,\n",
            "        0.9946, 0.9959, 0.9919, 0.9922, 0.9902, 0.9920, 0.9922, 0.9926, 0.9947,\n",
            "        0.9910, 0.9932, 0.9910, 0.9928, 0.9931, 0.9912, 0.9909, 0.9910, 0.9923,\n",
            "        0.9919, 0.9915, 0.9943, 0.9922, 0.9947, 0.9922, 0.9915, 0.9948, 0.9930,\n",
            "        0.9902, 0.9932, 0.9918, 0.9927, 0.9906, 0.9940, 0.9933, 0.9939, 0.9935,\n",
            "        0.9904, 0.9922, 0.9911, 0.9931, 0.9940, 0.9920, 0.9935, 0.9919, 0.9925,\n",
            "        0.9915, 0.9918, 0.9893, 0.9915, 0.9930, 0.9939, 0.9919, 0.9928, 0.9935,\n",
            "        0.9915, 0.9917, 0.9920, 0.9905, 0.9907, 0.9943, 0.9909, 0.9936, 0.9932,\n",
            "        0.9906, 0.9895, 0.9905, 0.9914, 0.9921, 0.9919, 0.9951, 0.9917, 0.9899,\n",
            "        0.9927, 0.9958, 0.9942, 0.9913, 0.9905, 0.9907, 0.9919, 0.9931, 0.9931,\n",
            "        0.9906, 0.9923, 0.9913, 0.9915, 0.9935, 0.9930, 0.9918, 0.9918, 0.9930,\n",
            "        0.9909, 0.9920, 0.9906, 0.9902, 0.9931, 0.9904, 0.9919, 0.9933])), ('module.encoder_q.layer2.1.bn3.bias', tensor([ 5.7981e-04,  2.5586e-04,  1.4307e-03, -1.0852e-03, -4.8194e-05,\n",
            "         2.2666e-03,  1.5645e-03, -3.9975e-04,  9.3833e-04,  1.3415e-03,\n",
            "        -1.3396e-03,  1.2954e-03,  1.2487e-03,  5.4151e-04, -1.9403e-04,\n",
            "        -1.7464e-03,  1.0573e-03, -1.6735e-03, -3.9478e-04, -1.3839e-03,\n",
            "         6.1056e-04,  1.5935e-04, -4.1452e-04, -1.1164e-03,  6.7141e-04,\n",
            "         2.1106e-03, -9.1868e-04,  6.1306e-04,  4.5615e-04,  6.7667e-04,\n",
            "         6.0131e-04,  1.1136e-04, -4.5483e-04, -1.8706e-03,  1.0061e-03,\n",
            "         2.6373e-05,  1.3106e-03, -4.1712e-04, -9.8311e-04,  3.8181e-03,\n",
            "         9.2163e-04, -2.4278e-04, -7.7036e-04, -3.3423e-04, -9.0159e-04,\n",
            "        -8.5367e-04, -1.3320e-03,  3.1181e-04, -4.9374e-04, -1.3573e-03,\n",
            "        -2.6040e-04, -9.0775e-04, -1.1019e-03,  1.1066e-03, -7.2720e-04,\n",
            "        -8.8037e-04, -1.2980e-03, -7.6954e-04, -2.1868e-04,  3.3824e-04,\n",
            "        -1.3590e-03,  1.8633e-03,  1.0642e-03,  1.3068e-03,  5.3152e-05,\n",
            "        -3.2087e-04,  1.2946e-03, -7.6752e-04, -2.0882e-04,  8.5464e-05,\n",
            "         7.9687e-04,  7.2848e-04, -1.3124e-04,  1.5243e-03,  1.4015e-03,\n",
            "         1.7645e-03,  1.1990e-03,  5.5863e-04,  1.3502e-03,  1.2617e-03,\n",
            "         3.6677e-04,  1.5988e-03,  5.6738e-04,  1.5801e-03,  9.7619e-05,\n",
            "        -3.4755e-04,  1.2846e-03, -7.6574e-04,  1.0633e-03, -1.7214e-03,\n",
            "        -4.2526e-04, -5.1978e-04,  1.1651e-03, -1.0657e-03,  3.0487e-04,\n",
            "         1.9661e-04, -2.2229e-04, -1.4879e-03,  3.1231e-04, -2.0029e-03,\n",
            "        -9.5903e-05, -1.3493e-03, -1.7449e-03, -7.7708e-04,  1.0607e-03,\n",
            "        -1.1973e-03,  1.4242e-03,  8.2785e-04,  3.0563e-04, -1.6354e-03,\n",
            "         1.1767e-03, -1.7309e-04,  4.0900e-04, -2.2973e-03, -4.2115e-04,\n",
            "         5.1405e-04,  6.4275e-04,  1.1664e-04, -4.1786e-04, -1.4442e-03,\n",
            "         9.3445e-04,  9.0007e-05, -1.8046e-03, -6.9539e-04, -6.6137e-04,\n",
            "         8.7251e-04,  2.0265e-03, -1.1735e-03, -5.8114e-04, -9.9033e-04,\n",
            "         1.4837e-03,  1.2798e-03,  2.0376e-03,  3.2636e-04,  1.5645e-03,\n",
            "        -2.0578e-05,  1.2023e-03, -9.9885e-04, -2.2207e-04, -2.3991e-04,\n",
            "        -1.2520e-03, -2.6509e-04, -1.2165e-03,  6.4802e-04, -1.1149e-03,\n",
            "         5.7790e-04, -1.9402e-04,  1.1720e-03, -1.7050e-03,  4.1759e-04,\n",
            "        -5.3303e-04,  1.0619e-03, -8.3428e-04, -2.1051e-04,  6.5642e-04,\n",
            "         6.9502e-04,  5.5014e-05,  1.5514e-03, -3.5382e-05, -1.3083e-03,\n",
            "        -1.2159e-04, -4.6211e-04,  1.8083e-04,  9.4640e-04, -2.4194e-04,\n",
            "         1.5923e-03,  2.1133e-03,  8.8810e-04,  1.6866e-03, -6.8940e-04,\n",
            "         1.2652e-03,  7.0438e-04, -4.3037e-04, -6.0771e-04,  7.6803e-04,\n",
            "        -1.1086e-03,  3.9284e-04,  8.8217e-04,  3.1635e-04,  5.4547e-05,\n",
            "         2.2221e-03,  1.4040e-04,  5.1374e-05,  2.1296e-03,  1.4426e-03,\n",
            "         2.0877e-03, -1.8197e-04, -1.4057e-04,  1.3568e-03, -1.0951e-03,\n",
            "        -2.5109e-03, -3.7362e-04, -1.2541e-03, -6.5580e-04,  1.3267e-03,\n",
            "        -5.0059e-04, -3.0476e-04, -1.4363e-04,  2.7156e-03, -9.7058e-05,\n",
            "         5.2908e-04,  7.7349e-04,  7.5112e-04, -8.0728e-04, -1.2012e-03,\n",
            "         2.5781e-03,  5.7499e-04,  4.5433e-04, -7.7155e-04,  3.5161e-04,\n",
            "         2.4332e-03,  1.0787e-03,  1.7285e-04, -2.9089e-03,  1.0486e-04,\n",
            "        -1.4057e-04,  5.8781e-05, -1.4189e-03, -3.4024e-04, -6.1148e-04,\n",
            "        -1.4452e-03,  1.3207e-03,  7.5244e-04,  2.2777e-04, -1.3573e-03,\n",
            "         1.8433e-03,  8.9949e-04, -7.1115e-04,  8.8652e-04, -2.2603e-04,\n",
            "         5.7475e-04,  1.3411e-03, -2.4419e-03, -1.0060e-03,  4.6339e-04,\n",
            "        -9.9657e-04,  1.0162e-03,  1.3937e-03, -3.9467e-04,  1.4354e-04,\n",
            "        -5.4564e-04,  7.3188e-04,  1.2155e-03,  5.7395e-04, -3.7123e-04,\n",
            "        -1.3651e-04, -8.3693e-04,  8.0607e-04, -7.9869e-04, -4.1270e-04,\n",
            "         1.5044e-03,  1.1634e-03, -2.6444e-04,  9.0905e-04, -6.5763e-04,\n",
            "        -1.1871e-03,  3.2887e-04, -1.2476e-03, -2.6678e-04,  1.0818e-03,\n",
            "        -9.7103e-04, -1.2226e-04,  6.7289e-04,  1.5701e-03,  2.4435e-04,\n",
            "        -1.1082e-03,  1.0874e-03,  1.3087e-03,  1.5300e-03,  2.0488e-03,\n",
            "        -3.0802e-04, -1.8837e-03, -1.7292e-04,  9.7393e-04, -5.1168e-04,\n",
            "         6.9216e-04, -7.2557e-04, -1.9415e-04, -1.7239e-03,  1.9200e-04,\n",
            "        -1.5876e-03, -1.3787e-03, -5.2874e-04,  6.4107e-05, -8.3358e-04,\n",
            "        -6.6413e-04, -2.9875e-03, -1.6022e-03, -4.3370e-05,  8.2063e-04,\n",
            "        -1.2970e-03,  1.9825e-03,  3.5426e-04,  4.2846e-04, -8.2013e-04,\n",
            "        -1.9466e-04,  6.8861e-04,  1.4286e-03, -2.7926e-04,  8.9749e-04,\n",
            "        -3.0464e-04,  1.0216e-04,  1.6280e-03,  6.0451e-04,  3.8269e-04,\n",
            "         2.4736e-03, -1.2671e-03, -1.4707e-03,  5.9274e-05, -1.5957e-03,\n",
            "         9.4446e-04,  4.7763e-04, -7.0714e-04, -1.0883e-03,  1.0930e-04,\n",
            "         9.8728e-04,  7.0495e-04,  4.9077e-04,  2.1989e-04, -5.5791e-05,\n",
            "         9.8660e-04, -8.7331e-04, -1.2338e-03,  9.7108e-04,  2.7003e-04,\n",
            "        -6.4634e-04,  1.7468e-03,  9.1498e-04,  1.7262e-03,  1.0970e-03,\n",
            "         1.8567e-04,  8.3435e-04,  2.1868e-04, -2.0190e-04,  1.1480e-03,\n",
            "        -1.3680e-03,  3.9493e-04, -1.7742e-04,  4.9446e-04,  1.3326e-03,\n",
            "         8.0678e-04, -1.1619e-03,  1.7181e-03,  1.8839e-03, -4.2520e-04,\n",
            "         5.0805e-04,  1.5244e-05, -1.9081e-03,  1.7209e-04,  2.2915e-03,\n",
            "         1.2888e-06, -5.7047e-04, -3.7997e-04,  2.6968e-03,  2.0768e-03,\n",
            "         3.6313e-04, -9.7869e-05, -2.4114e-03,  2.2571e-03, -2.6738e-03,\n",
            "        -3.7436e-05,  1.4364e-03, -1.0580e-03, -3.4708e-04,  1.5290e-03,\n",
            "        -2.1143e-05,  1.2234e-03, -8.3065e-04,  7.5509e-04, -1.6483e-03,\n",
            "        -1.6033e-03,  5.1931e-04,  4.0744e-04,  1.1017e-03,  1.5900e-03,\n",
            "        -2.5236e-03,  3.4672e-04, -7.8458e-04, -7.3059e-04,  1.3287e-03,\n",
            "         1.5348e-04,  6.6987e-04, -1.9119e-03, -8.6072e-04, -7.4808e-04,\n",
            "        -2.1123e-03,  1.3138e-03, -3.5411e-04,  1.6948e-03, -1.6348e-04,\n",
            "         5.4932e-04, -9.4818e-04, -1.2907e-04,  3.3251e-04,  3.9701e-05,\n",
            "        -3.1796e-05,  1.8231e-03, -3.5348e-04, -5.3998e-04, -1.1189e-04,\n",
            "         9.7963e-05,  1.2028e-03, -1.6568e-03, -2.0547e-03, -3.7933e-04,\n",
            "         7.5052e-04,  3.4476e-04,  1.2936e-03, -7.2982e-04,  1.2859e-03,\n",
            "         3.2441e-04, -1.3513e-03,  6.0914e-04,  1.0187e-03,  2.6570e-03,\n",
            "         1.3489e-03, -6.1557e-04, -2.0465e-03, -8.7797e-04,  1.6048e-05,\n",
            "        -8.5517e-04, -7.6901e-04, -8.7841e-04, -8.9911e-04,  5.4907e-04,\n",
            "         1.2880e-03,  6.5966e-04,  4.4497e-04,  1.3740e-04, -1.2316e-03,\n",
            "         6.0471e-04,  1.2405e-03,  7.1687e-04, -6.9951e-05,  2.2221e-03,\n",
            "         7.0667e-04, -5.4248e-04, -5.6390e-04, -4.6714e-04,  1.4553e-03,\n",
            "         7.0611e-04,  4.7254e-04,  2.0405e-03, -3.0917e-04, -1.0107e-03,\n",
            "         1.4555e-06,  1.5502e-03,  2.2307e-04,  7.9922e-04, -9.8692e-04,\n",
            "        -4.6778e-04, -1.0125e-03, -7.2323e-06,  1.0055e-04,  9.8914e-04,\n",
            "         2.5276e-04, -1.5023e-04,  6.9028e-04, -9.8050e-04, -1.1994e-04,\n",
            "        -3.2385e-04, -1.9145e-03,  1.4800e-03, -6.9077e-04, -2.5263e-04,\n",
            "        -8.9529e-05,  1.2130e-03,  4.4442e-04,  2.0790e-03, -1.5706e-03,\n",
            "        -3.1810e-04,  6.8424e-04, -1.2667e-03,  1.0862e-03, -1.4919e-03,\n",
            "        -6.2753e-04, -6.8194e-04, -2.3832e-03, -6.9860e-04, -2.0467e-03,\n",
            "         1.2120e-04,  1.1118e-03,  4.2713e-04, -5.9958e-05,  3.1678e-04,\n",
            "        -2.4214e-04,  2.2518e-04,  5.1608e-04,  1.1445e-03, -2.1189e-03,\n",
            "         3.2899e-04,  3.0238e-04,  4.0375e-04,  1.6682e-03, -5.6617e-04,\n",
            "        -5.1365e-04,  6.8080e-04, -3.4121e-04,  4.2696e-04,  8.9766e-04,\n",
            "        -5.5851e-04,  1.0533e-03, -1.2760e-03, -4.1118e-04,  2.7736e-04,\n",
            "        -1.0394e-03, -1.0341e-03,  9.2810e-04,  7.4737e-04, -8.3119e-04,\n",
            "        -7.0278e-04,  2.8028e-04])), ('module.encoder_q.layer2.1.bn3.running_mean', tensor([-5.5101e-03, -1.4126e-01,  9.1400e-02,  4.1522e-01, -3.5582e-02,\n",
            "         1.3223e-01, -6.0568e-02, -4.0941e-03,  4.0215e-01, -1.3410e-01,\n",
            "        -4.0010e-01,  4.9810e-02, -6.8272e-02, -3.8998e-01,  3.5629e-02,\n",
            "         1.0639e-01,  2.0145e-01, -1.6805e-01, -2.3193e-01, -3.9537e-01,\n",
            "        -3.0997e-01,  5.1266e-02, -2.6351e-01,  1.4815e-01, -9.1914e-02,\n",
            "        -1.7211e-02,  2.1589e-01, -1.2264e-03, -9.9209e-02, -3.5749e-01,\n",
            "        -9.5842e-03,  5.6998e-01, -1.2199e-01,  1.0561e-01, -1.7602e-01,\n",
            "        -1.1542e-02,  4.4743e-01,  1.5881e-01,  2.7272e-01,  5.4553e-03,\n",
            "        -6.0271e-01, -1.0460e-01,  1.8157e-01, -3.6103e-02, -1.3078e-03,\n",
            "         7.5342e-02,  5.9605e-02,  3.6392e-02, -1.5438e-01, -3.4811e-01,\n",
            "         4.9555e-02,  7.7081e-02,  1.2007e-01,  3.1117e-01, -1.6412e-01,\n",
            "         3.5782e-01,  6.0133e-02, -7.1709e-03,  1.7266e-01,  6.3711e-02,\n",
            "        -1.6319e-01,  4.8699e-02,  1.0254e-01, -1.9790e-01, -5.5032e-02,\n",
            "        -2.3288e-03, -2.4839e-01,  2.4689e-02, -4.0162e-02,  4.0693e-01,\n",
            "         1.0673e-01, -1.2171e-01,  2.7604e-01,  9.2605e-02, -1.1419e-01,\n",
            "         4.8409e-02,  9.0587e-02, -3.3471e-01,  1.2266e-02,  1.3778e-01,\n",
            "        -1.0852e-01,  6.3953e-02,  6.3267e-01,  2.4824e-02,  4.0593e-01,\n",
            "         2.8288e-02,  1.4736e-01,  2.1334e-01,  3.3085e-01, -2.0782e-01,\n",
            "        -2.3942e-01,  4.9152e-02,  5.7846e-02, -6.8346e-02, -3.8401e-01,\n",
            "        -3.2661e-01,  5.1635e-01, -7.8308e-02,  6.6310e-02, -4.6278e-02,\n",
            "         5.1981e-01,  1.5218e-01,  2.3741e-01, -9.0419e-02,  2.6763e-01,\n",
            "         1.2691e-01,  4.5043e-03,  2.6504e-02,  5.6774e-01,  3.0100e-01,\n",
            "        -3.3086e-01,  8.5601e-02, -3.4624e-01, -2.3384e-01, -3.5094e-02,\n",
            "         1.1520e-01,  3.9167e-01,  2.1930e-01,  1.0427e-01,  4.0127e-01,\n",
            "         1.2550e-02,  1.4402e-01,  1.4452e-01, -3.5985e-01,  4.3217e-02,\n",
            "         2.5702e-01, -2.8986e-01, -3.4163e-01,  1.3340e-01,  2.6849e-01,\n",
            "        -3.6199e-02, -9.2065e-02,  6.0452e-02,  2.1559e-01,  3.5416e-01,\n",
            "         1.6087e-01, -2.7271e-01, -5.5034e-01,  2.2331e-01, -4.2832e-01,\n",
            "         1.0348e-01, -3.1054e-01,  1.9569e-01, -7.9577e-02,  4.1812e-01,\n",
            "        -8.0708e-02, -1.8986e-01, -2.8216e-01, -2.0100e-01, -1.4641e-01,\n",
            "         1.1271e-01, -1.2217e-01,  8.2489e-03, -2.5322e-02, -3.4236e-01,\n",
            "         1.8879e-01, -4.0340e-02, -2.2620e-01, -1.3705e-02,  1.6555e-01,\n",
            "        -2.7229e-01,  1.0668e-01, -3.1371e-01,  2.1102e-01,  6.4206e-02,\n",
            "        -4.3077e-01,  2.6763e-01, -1.5046e-01, -9.2451e-02,  1.0130e-01,\n",
            "        -8.4625e-02, -6.3428e-02,  4.8032e-01,  4.9460e-01, -3.4425e-01,\n",
            "        -2.1436e-01,  3.8776e-01, -8.9364e-02, -3.9349e-01, -1.0440e-01,\n",
            "         2.0757e-02, -2.5930e-01, -4.1748e-01,  4.3316e-02,  3.1311e-01,\n",
            "         6.5985e-02, -1.2265e-01, -1.0162e-01,  3.0620e-02,  5.3992e-01,\n",
            "        -6.5000e-01, -2.7758e-01,  3.5824e-01, -2.8166e-01,  2.3806e-01,\n",
            "         3.8463e-01, -8.1846e-02,  9.0998e-02, -1.2390e-01, -1.3376e-01,\n",
            "        -3.9880e-01,  2.9556e-02, -4.1049e-01, -2.3546e-02, -8.2173e-02,\n",
            "         1.9828e-01,  1.5839e-01, -2.3654e-01,  9.9674e-02, -5.7516e-01,\n",
            "        -1.1560e-01,  1.2372e-01, -3.1452e-01, -1.2322e-01,  5.5637e-02,\n",
            "        -1.3945e-01, -1.1289e-01,  5.6341e-01, -7.5634e-02, -2.7684e-02,\n",
            "        -1.3446e-01,  1.9835e-02,  3.3394e-01,  2.0181e-01,  6.6361e-02,\n",
            "         2.2489e-01, -1.2913e-01, -8.6481e-02,  4.1248e-01, -3.0442e-01,\n",
            "         3.0983e-01,  2.4527e-01, -1.6324e-01, -3.7893e-01, -6.0076e-02,\n",
            "        -3.7405e-01,  2.8031e-01, -4.4922e-01,  2.8677e-03, -6.4194e-03,\n",
            "         3.8874e-01,  1.0244e-01, -6.9426e-02,  3.0861e-02,  1.9497e-01,\n",
            "         4.5935e-01, -1.2427e-01,  4.5010e-02,  3.9728e-01, -7.2321e-02,\n",
            "         3.3818e-01, -1.3067e-01, -4.4460e-02,  5.0439e-02, -1.0474e-01,\n",
            "         1.8987e-01,  4.8500e-01, -9.2085e-02,  1.7917e-01, -3.3163e-01,\n",
            "         1.3559e-01,  1.4134e-01, -1.1965e-01, -1.0731e-01, -1.2634e-01,\n",
            "         1.0407e-01,  8.5924e-02,  3.5507e-01,  5.2002e-01, -1.5047e-01,\n",
            "        -2.3179e-01, -2.8246e-01, -7.3723e-02,  2.3624e-01, -4.5264e-01,\n",
            "         1.3615e-01,  5.0458e-04,  2.6214e-01,  1.0806e-01, -2.3699e-02,\n",
            "         2.5442e-02, -2.7168e-01,  1.4062e-01, -7.2479e-02,  1.5031e-01,\n",
            "        -2.3854e-01,  3.3564e-01, -1.0144e-02,  2.8269e-01, -1.2437e-01,\n",
            "        -1.7684e-01,  3.2480e-01, -2.3095e-01,  7.0660e-02, -2.3461e-01,\n",
            "         1.1224e-03, -1.5481e-01, -4.4027e-01, -6.3650e-01, -9.3713e-02,\n",
            "        -2.7339e-02,  8.4213e-02,  5.7060e-02, -3.3162e-01,  1.4356e-02,\n",
            "        -2.3525e-01,  4.0977e-01,  2.1228e-02,  1.1395e-01, -4.0426e-03,\n",
            "         5.4341e-01,  1.8468e-01, -3.4177e-01, -6.1335e-01,  6.5186e-02,\n",
            "        -6.2066e-01, -1.4272e-01, -6.2260e-02,  1.6750e-01, -1.1370e-01,\n",
            "         2.2004e-02, -8.6105e-02,  3.7973e-01,  1.6796e-02,  1.2617e-01,\n",
            "        -4.0392e-02,  2.2236e-01, -9.5746e-03, -2.1322e-01, -6.1987e-02,\n",
            "        -5.9810e-01,  1.1701e-01,  9.3896e-03,  6.5968e-02, -4.0475e-02,\n",
            "        -2.7337e-01, -2.1007e-01,  5.8600e-01, -5.3350e-02,  2.8700e-02,\n",
            "         4.0373e-01, -3.2068e-01, -5.7648e-02, -2.8417e-01, -2.1787e-01,\n",
            "        -1.7760e-01,  3.5201e-02, -2.0903e-01, -8.2428e-02,  3.2879e-02,\n",
            "         3.2238e-01, -1.7289e-01,  1.1768e-01,  1.1837e-02, -6.5770e-02,\n",
            "        -7.2687e-02, -1.8794e-01,  1.1733e-01,  1.5494e-01, -1.5100e-01,\n",
            "         1.3174e-01,  2.6437e-01, -6.2101e-01,  1.0277e-01, -8.1012e-02,\n",
            "         8.6461e-02, -2.5510e-01,  5.4802e-01,  1.2873e-01, -2.0089e-01,\n",
            "        -5.3793e-01, -1.0034e-01, -8.3100e-02, -2.4776e-01, -8.5754e-02,\n",
            "        -2.4464e-01, -4.1995e-02,  1.3306e-03, -7.6749e-03,  8.9372e-02,\n",
            "        -2.0108e-02,  3.7977e-02, -9.3085e-02,  4.9297e-01, -2.0266e-01,\n",
            "        -3.9689e-01,  1.2401e-01,  2.4360e-01, -3.6498e-01, -2.7368e-02,\n",
            "        -4.3878e-01,  5.1371e-02, -2.4534e-01,  6.1461e-02,  1.0782e-01,\n",
            "         1.0469e-01, -3.4478e-02, -5.3992e-02, -2.9427e-01,  1.3596e-01,\n",
            "        -6.2710e-02, -6.0313e-01,  1.1466e-02, -5.4742e-02, -2.4790e-01,\n",
            "         1.2907e-01, -4.2576e-01,  1.8645e-01,  7.7191e-02, -5.6766e-03,\n",
            "         1.5867e-01, -1.1617e-01,  5.1242e-01, -1.2858e-01,  1.6625e-02,\n",
            "         2.7309e-01, -6.8701e-01,  9.9705e-02, -1.7130e-01,  4.3148e-01,\n",
            "         2.0253e-02, -1.1528e-01, -1.2510e-01, -2.9608e-01,  2.4337e-01,\n",
            "         1.1795e-01,  2.3087e-01,  2.0462e-01,  2.3332e-01,  3.0846e-01,\n",
            "        -5.1004e-01,  1.3965e-01, -2.0987e-01,  1.7185e-02,  2.3573e-01,\n",
            "         1.1136e-01, -1.5318e-01,  4.4620e-01,  1.6749e-01,  2.1747e-01,\n",
            "         1.1555e-01, -2.6495e-01,  2.1658e-01, -1.4149e-01, -1.5899e-01,\n",
            "         1.8678e-01,  1.4983e-01, -3.7916e-01,  7.2318e-03, -1.1137e-01,\n",
            "         1.8915e-01,  1.5375e-01, -2.4427e-02,  1.0789e-01,  8.3656e-03,\n",
            "        -7.2699e-02,  1.6987e-01,  4.3426e-02, -2.7034e-01,  2.4534e-01,\n",
            "         2.5576e-01,  1.7288e-01,  3.7872e-02,  2.2106e-02,  3.6564e-01,\n",
            "         1.2115e-01,  6.0061e-03,  3.3093e-02,  5.5903e-02, -1.6053e-01,\n",
            "         3.6091e-01, -1.5473e-01,  1.3746e-01, -5.1900e-02,  2.0243e-01,\n",
            "         1.3285e-01,  2.1314e-01, -1.5472e-02, -6.9539e-03,  1.6766e-01,\n",
            "         8.7093e-02,  6.0854e-03, -9.4988e-02, -1.9296e-01, -6.4700e-01,\n",
            "        -7.4070e-02,  9.3652e-02, -2.3601e-02,  9.0092e-02,  1.1632e-01,\n",
            "        -1.2067e-01, -8.1187e-02, -6.9128e-02,  1.3139e-01, -2.1730e-02,\n",
            "        -3.3721e-01, -1.3211e-01, -4.8181e-01, -3.3263e-01, -5.0881e-02,\n",
            "         4.5339e-01,  1.1723e-01,  3.4034e-02,  5.7731e-02, -1.3354e-01,\n",
            "         1.0884e-01, -3.4195e-01,  3.3719e-01,  1.6083e-01,  3.1559e-01,\n",
            "         1.4950e-01, -1.6739e-01])), ('module.encoder_q.layer2.1.bn3.running_var', tensor([0.1752, 0.2496, 0.1471, 0.2518, 0.3386, 0.2097, 0.1562, 0.1829, 0.1376,\n",
            "        0.1548, 0.1386, 0.1041, 0.1421, 0.2017, 0.1373, 0.1503, 0.1254, 0.2776,\n",
            "        0.2738, 0.1650, 0.1921, 0.1383, 0.1471, 0.1252, 0.2092, 0.1528, 0.1183,\n",
            "        0.3100, 0.4660, 0.1568, 0.1209, 0.1613, 0.2262, 0.1674, 0.2112, 0.2452,\n",
            "        0.2087, 0.1403, 0.4056, 0.0953, 0.4049, 0.1373, 0.1627, 0.2750, 0.0991,\n",
            "        0.1413, 0.1399, 0.1551, 0.1332, 0.2842, 0.1293, 0.2551, 0.2025, 0.1448,\n",
            "        0.2305, 0.1888, 0.1983, 0.1074, 0.0872, 0.1228, 0.2158, 0.2371, 0.1980,\n",
            "        0.1916, 0.1419, 0.1334, 0.2195, 0.1933, 0.1540, 0.3262, 0.1483, 0.1393,\n",
            "        0.0846, 0.2119, 0.1778, 0.1280, 0.1124, 0.1326, 0.1035, 0.0979, 0.2218,\n",
            "        0.1452, 0.3427, 0.1890, 0.1690, 0.1377, 0.1928, 0.1200, 0.2015, 0.1546,\n",
            "        0.3164, 0.1245, 0.2022, 0.1234, 0.4744, 0.1708, 0.2629, 0.1134, 0.1227,\n",
            "        0.1734, 0.5804, 0.0979, 0.0885, 0.3488, 0.1630, 0.1926, 0.2445, 0.3388,\n",
            "        0.3276, 0.1876, 0.1119, 0.2644, 0.2571, 0.0944, 0.1274, 0.2207, 0.1903,\n",
            "        0.2437, 0.2123, 0.2249, 0.1991, 0.1180, 0.2024, 0.1181, 0.2006, 0.2484,\n",
            "        0.1153, 0.1010, 0.1514, 0.1289, 0.1607, 0.1657, 0.1552, 0.3716, 0.2087,\n",
            "        0.1160, 0.1552, 0.1678, 0.1361, 0.1522, 0.1781, 0.1826, 0.2773, 0.0951,\n",
            "        0.1717, 0.0829, 0.2193, 0.2087, 0.2208, 0.1328, 0.1142, 0.1204, 0.1844,\n",
            "        0.1469, 0.1900, 0.1091, 0.1177, 0.1266, 0.1217, 0.2483, 0.1477, 0.1373,\n",
            "        0.1998, 0.1720, 0.2177, 0.1290, 0.1023, 0.1875, 0.2557, 0.3545, 0.1175,\n",
            "        0.2711, 0.2898, 0.1964, 0.1894, 0.2614, 0.3469, 0.1916, 0.6248, 0.1925,\n",
            "        0.1128, 0.1498, 0.3496, 0.1526, 0.1755, 0.1200, 0.1718, 0.1872, 0.2307,\n",
            "        0.6754, 0.2403, 0.1449, 0.1260, 0.2487, 0.5343, 0.1346, 0.1450, 0.2210,\n",
            "        0.1848, 0.1271, 0.1741, 0.1534, 0.2770, 0.1297, 0.0933, 0.1907, 0.1342,\n",
            "        0.1753, 0.1514, 0.1811, 0.1549, 0.1980, 0.2058, 0.2060, 0.2267, 0.1197,\n",
            "        0.1826, 0.1394, 0.1541, 0.2581, 0.1304, 0.1813, 0.1531, 0.1786, 0.2998,\n",
            "        0.1276, 0.1229, 0.2161, 0.2507, 0.2129, 0.1045, 0.1229, 0.2410, 0.1197,\n",
            "        0.1682, 0.2500, 0.2592, 0.1760, 0.0939, 0.1663, 0.1586, 0.1960, 0.1177,\n",
            "        0.1576, 0.4949, 0.1534, 0.1744, 0.1814, 0.1322, 0.1001, 0.1428, 0.1801,\n",
            "        0.1316, 0.1996, 0.1333, 0.3362, 0.1422, 0.0951, 0.1356, 0.1771, 0.2206,\n",
            "        0.0982, 0.1023, 0.1478, 0.1942, 0.1375, 0.2109, 0.2477, 0.1234, 0.1838,\n",
            "        0.0936, 0.1086, 0.1424, 0.1866, 0.3377, 0.1030, 0.1361, 0.2047, 0.2261,\n",
            "        0.1704, 0.2399, 0.2488, 0.1805, 0.1413, 0.2466, 0.1402, 0.1900, 0.1082,\n",
            "        0.2731, 0.2427, 0.2370, 0.2146, 0.1828, 0.2041, 0.1492, 0.3277, 0.1349,\n",
            "        0.2224, 0.1076, 0.2915, 0.1781, 0.1797, 0.2338, 0.2379, 0.1786, 0.2554,\n",
            "        0.3481, 0.1226, 0.1145, 0.1870, 0.2215, 0.1158, 0.1283, 0.1951, 0.1647,\n",
            "        0.2478, 0.2515, 0.1323, 0.1660, 0.1855, 0.1105, 0.3401, 0.3156, 0.1507,\n",
            "        0.1138, 0.1304, 0.0980, 0.0960, 0.3951, 0.1548, 0.1210, 0.1685, 0.1528,\n",
            "        0.1108, 0.2158, 0.1591, 0.1894, 0.1548, 0.1997, 0.2759, 0.2315, 0.4369,\n",
            "        0.2024, 0.1117, 0.1552, 0.3323, 0.1655, 0.1956, 0.1826, 0.2186, 0.3981,\n",
            "        0.1708, 0.1872, 0.1644, 0.1731, 0.1619, 0.1921, 0.1914, 0.1383, 0.1455,\n",
            "        0.2000, 0.1189, 0.1874, 0.1511, 0.1591, 0.2654, 0.2330, 0.5082, 0.1242,\n",
            "        0.1417, 0.2390, 0.3092, 0.1277, 0.2283, 0.2574, 0.1715, 0.1254, 0.4208,\n",
            "        0.2697, 0.2267, 0.3814, 0.1058, 0.1404, 0.1873, 0.1605, 0.1439, 0.2675,\n",
            "        0.1387, 0.1816, 0.2422, 0.1818, 0.1777, 0.2145, 0.1382, 0.1416, 0.1669,\n",
            "        0.1475, 0.1433, 0.1820, 0.1568, 0.1228, 0.2396, 0.1246, 0.2098, 0.1415,\n",
            "        0.1640, 0.1241, 0.1689, 0.1653, 0.1371, 0.1368, 0.1195, 0.1930, 0.1386,\n",
            "        0.3359, 0.2428, 0.6494, 0.2893, 0.5398, 0.1047, 0.1747, 0.1771, 0.1304,\n",
            "        0.1741, 0.1580, 0.1178, 0.1546, 0.1407, 0.2168, 0.1845, 0.1785, 0.1298,\n",
            "        0.2237, 0.0931, 0.2345, 0.1635, 0.1367, 0.2057, 0.1439, 0.2078, 0.1259,\n",
            "        0.1438, 0.1709, 0.2104, 0.1525, 0.2053, 0.1722, 0.1222, 0.1873, 0.2641,\n",
            "        0.1687, 0.1532, 0.1442, 0.1591, 0.2777, 0.1732, 0.1320, 0.1188, 0.2360,\n",
            "        0.2898, 0.2139, 0.4478, 0.1560, 0.1214, 0.2255, 0.1600, 0.1988, 0.1549,\n",
            "        0.1071, 0.1856, 0.1343, 0.1254, 0.1667, 0.2045, 0.1344, 0.1666, 0.1448,\n",
            "        0.1435, 0.1736, 0.1022, 0.2324, 0.1239, 0.2722, 0.1480, 0.7902, 0.3813,\n",
            "        0.1386, 0.1774, 0.1350, 0.2494, 0.1760, 0.1371, 0.1256, 0.1621, 0.0904,\n",
            "        0.2786, 0.1052, 0.3231, 0.1252, 0.2123, 0.3251, 0.0759, 0.1788, 0.2246,\n",
            "        0.1421, 0.1067, 0.2853, 0.1636, 0.1737, 0.2867, 0.2263, 0.3711])), ('module.encoder_q.layer2.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.2.conv1.weight', tensor([[[[ 0.1012]],\n",
            "\n",
            "         [[ 0.0657]],\n",
            "\n",
            "         [[ 0.2550]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0362]],\n",
            "\n",
            "         [[-0.0986]],\n",
            "\n",
            "         [[ 0.0045]]],\n",
            "\n",
            "\n",
            "        [[[-0.1969]],\n",
            "\n",
            "         [[-0.0039]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0182]],\n",
            "\n",
            "         [[ 0.0841]],\n",
            "\n",
            "         [[-0.0350]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0801]],\n",
            "\n",
            "         [[-0.1219]],\n",
            "\n",
            "         [[ 0.1026]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0673]],\n",
            "\n",
            "         [[-0.1047]],\n",
            "\n",
            "         [[-0.2680]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2178]],\n",
            "\n",
            "         [[-0.0286]],\n",
            "\n",
            "         [[ 0.0112]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0378]],\n",
            "\n",
            "         [[ 0.1530]],\n",
            "\n",
            "         [[-0.0356]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1277]],\n",
            "\n",
            "         [[ 0.1530]],\n",
            "\n",
            "         [[-0.1567]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0074]],\n",
            "\n",
            "         [[ 0.0755]],\n",
            "\n",
            "         [[-0.0733]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0876]],\n",
            "\n",
            "         [[ 0.1227]],\n",
            "\n",
            "         [[-0.0728]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1945]],\n",
            "\n",
            "         [[ 0.0784]],\n",
            "\n",
            "         [[-0.1629]]]])), ('module.encoder_q.layer2.2.bn1.weight', tensor([0.9891, 0.9916, 0.9896, 0.9959, 0.9998, 0.9957, 0.9898, 0.9902, 0.9911,\n",
            "        0.9928, 0.9934, 0.9864, 0.9992, 0.9883, 0.9899, 0.9898, 0.9931, 0.9917,\n",
            "        0.9934, 0.9907, 0.9897, 0.9927, 0.9944, 0.9936, 0.9912, 0.9950, 0.9944,\n",
            "        0.9981, 0.9912, 0.9917, 0.9904, 0.9893, 0.9961, 0.9941, 0.9915, 0.9925,\n",
            "        0.9884, 0.9922, 0.9955, 0.9920, 0.9980, 0.9869, 0.9947, 0.9894, 0.9888,\n",
            "        0.9936, 0.9924, 0.9924, 0.9891, 0.9916, 0.9935, 0.9934, 0.9915, 0.9890,\n",
            "        0.9935, 0.9978, 0.9940, 0.9889, 0.9969, 0.9901, 0.9950, 0.9887, 0.9925,\n",
            "        0.9914, 0.9929, 0.9935, 0.9881, 0.9909, 0.9911, 0.9910, 0.9889, 0.9923,\n",
            "        0.9882, 0.9980, 0.9942, 0.9937, 0.9958, 0.9904, 0.9947, 0.9904, 0.9903,\n",
            "        0.9928, 0.9964, 0.9956, 0.9945, 0.9942, 0.9911, 0.9937, 0.9960, 0.9946,\n",
            "        0.9900, 0.9896, 0.9914, 0.9917, 0.9900, 0.9932, 0.9944, 0.9920, 0.9916,\n",
            "        0.9914, 0.9934, 0.9899, 1.0005, 0.9927, 0.9908, 0.9929, 0.9895, 0.9881,\n",
            "        0.9921, 0.9924, 0.9955, 0.9877, 0.9858, 0.9924, 0.9861, 0.9918, 0.9881,\n",
            "        0.9987, 0.9942, 0.9883, 0.9922, 0.9938, 0.9933, 0.9946, 0.9938, 0.9896,\n",
            "        0.9950, 0.9887])), ('module.encoder_q.layer2.2.bn1.bias', tensor([ 9.3452e-04,  4.7283e-04, -1.1764e-03,  1.7391e-03,  4.0100e-03,\n",
            "         1.2850e-03, -1.5955e-03,  1.4289e-04, -3.1326e-03,  1.6180e-03,\n",
            "         5.7655e-03, -4.8253e-03,  1.1483e-03,  6.3812e-04, -3.0520e-03,\n",
            "         3.1481e-03, -3.0221e-03, -1.7730e-03, -1.2422e-03,  4.6161e-04,\n",
            "        -1.5632e-05, -4.1736e-04, -7.1058e-04, -1.1327e-03, -1.9658e-03,\n",
            "        -5.3766e-06, -1.3506e-03,  5.7531e-03, -2.3178e-03,  2.0573e-03,\n",
            "        -3.9026e-03,  2.3128e-03,  3.9056e-03,  2.9237e-03,  1.6654e-03,\n",
            "        -2.0748e-03, -9.8258e-04,  9.7808e-04, -1.6474e-03,  2.3167e-03,\n",
            "         2.6477e-03, -1.9749e-03,  3.9951e-03, -2.9859e-03, -4.3096e-03,\n",
            "        -6.1230e-04, -2.7880e-03, -2.8867e-03, -2.8376e-03,  5.2078e-04,\n",
            "         1.9999e-03,  3.9598e-04, -1.9609e-03, -7.4108e-04,  1.2396e-03,\n",
            "         2.3106e-03,  1.6428e-03, -3.1057e-03,  3.2466e-03, -1.7571e-03,\n",
            "         4.5387e-04, -2.1947e-03,  1.6527e-03, -1.5047e-03,  2.8917e-03,\n",
            "         8.8703e-04, -4.8127e-03,  2.5511e-04, -8.5126e-04, -2.5050e-03,\n",
            "        -3.2952e-03,  1.0339e-03, -4.6367e-03,  3.9255e-03,  4.2079e-04,\n",
            "         4.2622e-03,  1.1103e-03, -3.1747e-04, -5.3354e-04, -3.3011e-03,\n",
            "         1.3277e-03,  2.2354e-03,  4.9020e-03,  2.5238e-03, -1.2543e-04,\n",
            "         1.8878e-03, -2.2008e-03,  2.5599e-03, -2.2479e-04, -1.3522e-03,\n",
            "        -2.4366e-03, -2.1621e-03, -6.3685e-04,  1.6555e-03, -3.0218e-03,\n",
            "         4.7778e-04, -1.4436e-03, -1.3351e-03, -1.3952e-03, -1.0820e-03,\n",
            "         1.0703e-03, -9.0478e-04,  7.0756e-03,  8.5063e-04,  6.5004e-04,\n",
            "         1.7427e-03, -1.2603e-03, -3.1382e-03, -1.2072e-03,  1.3636e-03,\n",
            "         8.1651e-04, -3.7966e-03, -4.7209e-03, -8.7560e-04, -6.9461e-04,\n",
            "        -3.7335e-03,  1.3265e-04,  2.0572e-03, -4.5679e-04, -2.8762e-03,\n",
            "         1.8756e-03,  1.7707e-03,  1.3535e-04,  6.2667e-04, -2.1227e-03,\n",
            "         9.1577e-04,  3.0746e-03, -2.9190e-03])), ('module.encoder_q.layer2.2.bn1.running_mean', tensor([ 0.6944,  2.3025, -0.6022,  1.3683, -1.5403,  4.5787,  3.6770,  4.1267,\n",
            "        -1.6690, -0.2660, -2.0736, -0.0411, -0.3973,  2.6357, -1.4694,  0.3253,\n",
            "         0.2579,  1.9336,  2.7873, -0.8794,  3.0611,  1.0497, -0.7945,  1.0196,\n",
            "        -2.4137,  0.2395,  1.3928, -0.2292, -1.0170, -0.8366, -1.3356,  3.4009,\n",
            "         2.0449,  1.1966,  1.6283, -1.1358,  2.1205, -0.8546,  0.9813,  3.1734,\n",
            "        -0.5925,  3.7911,  2.6810,  1.7332,  0.4128,  0.5764,  2.2148, -2.4799,\n",
            "        -0.3143, -0.3279, -0.8183,  2.6339,  1.2391,  4.0447,  4.9892, -4.8065,\n",
            "        -4.0627,  1.4511, -3.4154,  3.0966, -0.6671, -1.4267,  0.3046, -2.3184,\n",
            "         3.5740,  2.6780,  3.4384,  1.3902,  3.6585,  0.9467, -1.2483, -1.2158,\n",
            "         0.0879, -2.8839, -1.0080,  0.1607, -2.1169,  2.6440,  1.0933, -3.0902,\n",
            "         2.4340, -0.8177, -0.0373,  0.3713, -2.7993, -4.3167, -3.1344, -0.1448,\n",
            "         0.9844,  1.5125, -2.9164, -0.7869, -0.2304,  1.1803, -5.7618, -2.7749,\n",
            "         1.0847,  0.1243,  0.0119, -1.1715, -3.0361,  2.3610,  3.8698,  2.3118,\n",
            "         2.1230,  3.4320, -2.3189, -0.3287, -2.8735,  1.4002,  1.4529, -0.2934,\n",
            "        -3.8019, -0.8803,  3.6025, -0.0439,  0.7580,  1.6950,  2.2556, -1.9706,\n",
            "         3.0083, -4.6379,  1.6622,  1.6663,  2.5991, -0.0959, -0.4337, -3.9575])), ('module.encoder_q.layer2.2.bn1.running_var', tensor([15.2483,  9.4525,  7.9862,  6.6334, 10.2247, 16.1657, 16.0232, 22.5823,\n",
            "         5.3635,  6.6824, 10.7204,  7.7373, 10.5009, 10.0511,  8.1174,  6.2559,\n",
            "        10.9993, 12.4268, 13.9087,  6.9102,  9.2555,  6.6145,  6.4421, 13.4350,\n",
            "         7.7575,  9.7544, 14.1452, 11.0422,  9.8768,  7.8417,  6.2512, 10.3055,\n",
            "        17.7684,  5.5654, 24.2718,  9.4476, 10.0274,  6.6102,  6.3261, 14.2432,\n",
            "        14.1051, 14.8098,  5.7710,  8.9511,  7.7877, 11.0202, 14.5210,  5.4612,\n",
            "         6.7822,  7.4055,  4.7476,  9.7758, 11.9513, 17.9452, 32.6441, 19.1936,\n",
            "         5.2574, 12.1972,  5.3384,  6.8327, 10.1664,  7.4904,  8.8430,  9.7085,\n",
            "         5.8167,  7.8413,  6.0104,  7.8083, 12.0242,  6.6606,  5.7168,  7.8248,\n",
            "         7.3696,  9.8237,  6.9540, 10.3727,  6.9538,  6.3253,  5.1551,  5.9827,\n",
            "        11.4433,  8.9112,  7.4532,  8.0883, 10.3313, 11.1347,  6.9583,  7.0601,\n",
            "         6.4272,  6.7671,  6.7463, 12.2952, 14.6374,  6.5074, 12.3075,  6.2843,\n",
            "         8.3187,  5.3667,  6.6203, 29.9708,  9.2753,  7.3018,  9.7167, 13.3109,\n",
            "        12.5832,  9.9012,  7.8328, 10.7881, 13.4464,  8.4977,  7.1779,  6.3801,\n",
            "        12.9770, 11.5767, 10.7972, 13.5621,  7.7486, 10.2659, 13.3554,  9.3334,\n",
            "        11.8596, 13.8166,  9.3082,  8.3525, 10.5274, 10.2882,  4.4060, 10.4465])), ('module.encoder_q.layer2.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.2.conv2.weight', tensor([[[[ 1.4538e-03, -7.1587e-02, -9.6158e-03],\n",
            "          [ 3.0370e-02, -1.7623e-02, -6.3669e-02],\n",
            "          [ 2.0086e-02, -2.2897e-02,  6.1480e-02]],\n",
            "\n",
            "         [[ 1.0001e-01, -5.5794e-03,  2.8683e-02],\n",
            "          [-6.0495e-02, -1.3726e-02,  1.7192e-02],\n",
            "          [-2.4395e-02,  5.1273e-02, -5.4826e-02]],\n",
            "\n",
            "         [[ 3.3316e-02, -1.2814e-02,  6.8897e-02],\n",
            "          [ 4.7943e-02, -1.1359e-01,  1.6952e-02],\n",
            "          [-5.2568e-02,  1.9724e-02, -1.5607e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7852e-02, -2.0722e-02, -1.9037e-02],\n",
            "          [-4.6543e-02,  3.6290e-02, -2.8979e-02],\n",
            "          [ 3.9949e-02, -7.8416e-03, -6.9798e-02]],\n",
            "\n",
            "         [[ 6.9135e-02, -5.3528e-02,  4.7252e-02],\n",
            "          [-5.0492e-02,  9.2923e-03,  4.7871e-02],\n",
            "          [-3.1961e-03, -8.1482e-03, -1.2019e-02]],\n",
            "\n",
            "         [[-7.5914e-03, -1.4315e-02,  5.9774e-02],\n",
            "          [-4.0932e-02,  1.6014e-02, -2.9378e-02],\n",
            "          [-6.3507e-03, -2.2119e-02,  5.1908e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2657e-02,  5.0645e-02, -2.5622e-03],\n",
            "          [ 4.9981e-02, -7.6284e-02,  1.9248e-02],\n",
            "          [-2.3349e-02,  6.8030e-03,  4.5179e-02]],\n",
            "\n",
            "         [[ 1.0412e-02, -1.0855e-02, -2.1947e-02],\n",
            "          [ 3.7109e-02,  7.7520e-02, -4.0336e-03],\n",
            "          [-9.8933e-03, -1.8035e-02,  1.0875e-02]],\n",
            "\n",
            "         [[-6.6683e-03, -2.7154e-02, -5.7088e-03],\n",
            "          [-5.1167e-02, -3.2103e-02,  6.8013e-02],\n",
            "          [ 6.5337e-02, -6.6021e-03, -5.7948e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.4546e-04,  1.0282e-01,  1.1751e-02],\n",
            "          [-6.0040e-02,  5.9628e-02, -2.0063e-02],\n",
            "          [ 2.3497e-02, -6.9525e-02,  6.9176e-02]],\n",
            "\n",
            "         [[ 1.6064e-02, -1.4391e-02, -2.6632e-02],\n",
            "          [-2.9070e-03, -1.4755e-02, -1.2727e-02],\n",
            "          [ 5.8284e-02, -2.1608e-03, -1.6641e-02]],\n",
            "\n",
            "         [[ 4.2843e-02,  2.9770e-02, -2.2544e-02],\n",
            "          [ 1.4138e-02, -1.8063e-02, -1.4763e-02],\n",
            "          [ 1.6970e-02,  9.6891e-02,  2.4745e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.0485e-04,  6.6560e-03, -2.1124e-02],\n",
            "          [-7.5750e-02,  4.9148e-02, -3.7374e-02],\n",
            "          [-3.7984e-02, -4.0642e-02, -2.6827e-02]],\n",
            "\n",
            "         [[-1.0778e-02, -3.9711e-02, -1.2820e-02],\n",
            "          [-6.1027e-02, -3.7604e-02,  3.5713e-02],\n",
            "          [ 9.8042e-04, -6.6031e-02,  1.5327e-02]],\n",
            "\n",
            "         [[-4.5851e-02,  8.7817e-02,  4.4326e-02],\n",
            "          [-8.8483e-02,  3.9656e-02, -6.9960e-02],\n",
            "          [-5.2583e-02,  2.3170e-02, -8.8089e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5901e-02,  5.4202e-03, -2.7999e-02],\n",
            "          [-2.5244e-02,  1.7183e-02, -4.0256e-02],\n",
            "          [-3.5563e-02,  3.1355e-03,  3.4423e-02]],\n",
            "\n",
            "         [[-3.5277e-02, -3.0189e-02,  2.0346e-02],\n",
            "          [ 4.2959e-02,  2.9146e-02, -3.9097e-02],\n",
            "          [ 3.6118e-02, -1.2656e-01,  2.1738e-02]],\n",
            "\n",
            "         [[ 3.0993e-02, -5.0898e-02,  5.0293e-02],\n",
            "          [ 3.8599e-03,  1.1431e-02,  4.2774e-02],\n",
            "          [ 3.4991e-02,  8.1424e-02,  3.5143e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.6328e-02, -3.2851e-02, -4.3013e-02],\n",
            "          [ 3.4661e-02,  6.4518e-03, -5.4943e-02],\n",
            "          [ 9.1167e-03,  6.4655e-02, -2.2427e-02]],\n",
            "\n",
            "         [[-3.4776e-02,  9.4068e-03,  3.6661e-02],\n",
            "          [ 5.6256e-02,  3.4981e-02, -4.2765e-03],\n",
            "          [-1.2019e-02,  5.5883e-02,  3.2206e-02]],\n",
            "\n",
            "         [[-2.4877e-03,  4.1189e-02, -4.8742e-02],\n",
            "          [-6.7684e-02, -9.4629e-03, -4.7164e-02],\n",
            "          [ 7.4233e-03,  7.2929e-02,  3.2883e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5570e-02, -6.7383e-02,  1.4298e-02],\n",
            "          [-5.6823e-02,  5.3084e-02,  3.5939e-02],\n",
            "          [-7.8759e-02,  7.9166e-02, -3.6642e-02]],\n",
            "\n",
            "         [[-2.5528e-02, -7.3668e-03, -8.4173e-02],\n",
            "          [ 2.9678e-02, -3.0088e-02, -3.0731e-02],\n",
            "          [ 6.0380e-02,  3.1892e-02, -7.2318e-03]],\n",
            "\n",
            "         [[-1.1269e-02,  7.2609e-02, -5.0350e-02],\n",
            "          [ 2.0434e-02, -5.1394e-03, -2.1041e-02],\n",
            "          [-1.6060e-02,  2.6036e-02,  7.2270e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0584e-02,  1.4100e-02,  3.5543e-02],\n",
            "          [-4.9444e-02, -5.3032e-02,  4.7694e-02],\n",
            "          [-4.1930e-03, -1.3681e-02,  6.3135e-02]],\n",
            "\n",
            "         [[-3.5174e-02, -2.3075e-02, -1.7359e-02],\n",
            "          [-3.6436e-02,  1.1213e-02, -4.7710e-02],\n",
            "          [ 5.0459e-02, -8.1171e-02,  4.3469e-02]],\n",
            "\n",
            "         [[-1.3431e-02, -2.3991e-02, -2.2085e-02],\n",
            "          [ 3.8538e-02, -4.0282e-03, -2.6144e-02],\n",
            "          [-1.3366e-02, -3.0879e-02,  7.5859e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0335e-02,  2.1382e-02, -6.7808e-02],\n",
            "          [ 3.7313e-02, -4.2458e-03,  2.0241e-02],\n",
            "          [-7.1848e-02, -4.3292e-02, -2.7098e-02]],\n",
            "\n",
            "         [[-8.0592e-02, -1.7335e-02, -5.4389e-02],\n",
            "          [-1.7313e-03,  2.3785e-02, -6.8242e-02],\n",
            "          [ 1.3919e-02,  3.1300e-03, -1.3978e-02]],\n",
            "\n",
            "         [[-1.0640e-02,  5.3896e-02,  6.9468e-02],\n",
            "          [-3.9646e-02,  2.6743e-02,  4.8860e-02],\n",
            "          [-4.5801e-02,  6.8912e-02,  1.1882e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.0996e-02,  5.4070e-03, -1.1923e-01],\n",
            "          [-6.6784e-02, -8.4643e-03, -9.3739e-03],\n",
            "          [-7.9646e-02,  1.7110e-02, -3.7297e-03]],\n",
            "\n",
            "         [[ 5.0599e-02, -2.0515e-02, -2.9184e-02],\n",
            "          [ 1.1499e-03,  2.2741e-02,  7.8611e-03],\n",
            "          [ 1.0353e-01, -6.3339e-02,  8.5085e-02]],\n",
            "\n",
            "         [[ 1.7926e-03, -5.4707e-02,  3.5778e-02],\n",
            "          [ 6.4626e-02,  6.4512e-02, -9.4864e-03],\n",
            "          [ 6.6696e-02, -5.6908e-02,  4.9866e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3764e-02, -2.2452e-02,  2.0386e-02],\n",
            "          [-6.0019e-03,  2.4172e-02,  5.6545e-02],\n",
            "          [-8.0551e-03,  1.2725e-02,  8.3174e-03]],\n",
            "\n",
            "         [[-8.3528e-02, -1.3268e-05,  1.7915e-02],\n",
            "          [ 1.7089e-02, -1.9493e-02,  5.3732e-02],\n",
            "          [-3.0252e-02,  4.2195e-02,  5.0056e-02]],\n",
            "\n",
            "         [[-1.8836e-02, -2.3766e-02,  7.2855e-03],\n",
            "          [ 5.6213e-02,  6.9934e-03, -4.1031e-02],\n",
            "          [-6.8888e-02,  8.6937e-02, -2.3544e-03]]]])), ('module.encoder_q.layer2.2.bn2.weight', tensor([0.9948, 0.9942, 0.9922, 0.9928, 0.9912, 0.9922, 0.9941, 0.9903, 0.9940,\n",
            "        0.9917, 0.9930, 0.9935, 0.9928, 0.9919, 0.9931, 0.9938, 1.0009, 0.9939,\n",
            "        0.9895, 0.9907, 0.9923, 0.9941, 0.9953, 0.9913, 0.9913, 0.9954, 0.9873,\n",
            "        0.9884, 0.9925, 0.9945, 0.9902, 0.9928, 0.9936, 0.9934, 0.9863, 0.9886,\n",
            "        0.9969, 0.9956, 0.9926, 0.9876, 0.9919, 0.9907, 0.9984, 0.9938, 0.9919,\n",
            "        0.9896, 0.9938, 0.9942, 0.9930, 0.9922, 0.9927, 0.9901, 0.9943, 0.9932,\n",
            "        0.9937, 0.9936, 0.9917, 0.9868, 0.9905, 0.9914, 0.9919, 0.9874, 0.9904,\n",
            "        0.9921, 0.9920, 0.9931, 0.9963, 0.9907, 0.9961, 0.9918, 0.9917, 0.9916,\n",
            "        0.9917, 0.9903, 0.9900, 0.9918, 0.9958, 0.9909, 0.9928, 0.9903, 0.9918,\n",
            "        0.9952, 0.9919, 0.9956, 0.9938, 0.9933, 0.9923, 0.9916, 0.9905, 0.9961,\n",
            "        0.9937, 0.9907, 0.9902, 0.9923, 0.9916, 0.9914, 0.9907, 0.9927, 0.9925,\n",
            "        0.9909, 0.9898, 0.9955, 0.9907, 0.9891, 0.9926, 0.9898, 0.9920, 0.9897,\n",
            "        0.9901, 0.9931, 0.9929, 0.9894, 0.9931, 0.9930, 0.9902, 0.9912, 0.9939,\n",
            "        0.9923, 0.9906, 0.9915, 0.9910, 0.9913, 0.9958, 0.9918, 0.9915, 0.9938,\n",
            "        0.9942, 0.9937])), ('module.encoder_q.layer2.2.bn2.bias', tensor([ 1.7355e-03,  2.5132e-03,  2.0491e-04,  3.0737e-03, -2.3234e-03,\n",
            "         8.4361e-04,  7.5868e-04, -1.2327e-03,  2.4253e-03,  8.7806e-05,\n",
            "         3.9767e-04, -2.5617e-03,  6.9488e-05, -2.1662e-03, -2.2456e-04,\n",
            "         1.1271e-03,  3.6931e-03,  1.7525e-03, -1.7552e-03, -4.1630e-03,\n",
            "         3.5350e-03,  4.0300e-03,  3.6992e-03, -7.9689e-04, -2.1607e-03,\n",
            "         3.7147e-03, -3.0062e-03, -3.8377e-03,  2.9970e-03, -3.0586e-03,\n",
            "        -5.1499e-04, -5.1785e-04,  1.4005e-03,  1.1212e-03, -4.5524e-03,\n",
            "        -2.6185e-03,  5.0972e-03,  3.5643e-03,  4.4544e-04, -2.8892e-03,\n",
            "         7.2014e-04, -2.9503e-03,  3.9092e-03, -4.3686e-03,  2.8188e-04,\n",
            "        -3.1789e-03,  2.8587e-03,  7.5974e-04,  1.8279e-03, -2.8090e-04,\n",
            "        -2.0292e-03, -4.3898e-04,  5.7932e-04,  7.4506e-04,  8.8293e-04,\n",
            "         8.6295e-04,  2.4222e-03, -2.1025e-03, -4.8407e-04, -2.0136e-03,\n",
            "        -4.0057e-04, -4.3704e-03, -3.9360e-04, -1.9502e-03, -8.7725e-04,\n",
            "         2.6742e-03,  7.7791e-04, -9.9207e-04,  1.0143e-03,  1.0493e-03,\n",
            "        -2.2401e-03,  2.4422e-04,  3.9406e-03,  5.9532e-04, -1.6420e-03,\n",
            "        -1.4641e-03,  2.1663e-03,  8.2009e-04,  2.1873e-03,  2.2224e-03,\n",
            "         6.1906e-04,  6.1846e-04,  2.8680e-03,  3.3214e-03, -1.0341e-03,\n",
            "        -6.0679e-04, -1.0474e-03, -7.6148e-04,  6.2034e-04,  2.4425e-03,\n",
            "         8.2804e-04,  8.8413e-04, -1.9932e-03,  9.1055e-04,  8.7595e-04,\n",
            "         7.8640e-04, -1.9962e-03,  1.0082e-03,  3.1950e-03, -2.5863e-04,\n",
            "        -2.6793e-03,  6.1208e-04, -3.3182e-03, -2.1229e-03, -1.2516e-03,\n",
            "        -1.2055e-03, -1.7113e-03, -3.7482e-03,  1.6051e-03,  1.9861e-03,\n",
            "        -2.1259e-04, -1.9179e-03,  2.3090e-03,  1.0673e-03, -2.4207e-03,\n",
            "         2.6573e-04,  4.6721e-03,  3.1857e-03, -1.3795e-03,  9.1882e-05,\n",
            "        -2.2572e-03, -1.0080e-03,  2.3605e-04,  7.0278e-04, -2.7861e-04,\n",
            "         2.4932e-03,  1.5850e-03, -5.0498e-04])), ('module.encoder_q.layer2.2.bn2.running_mean', tensor([ 3.8261e-01, -5.1143e-01, -4.8817e-01, -4.6057e-01,  4.7617e-01,\n",
            "        -4.1761e-01, -3.4065e-01, -1.2771e-02,  3.6710e-01,  2.0479e-01,\n",
            "        -7.0661e-01, -3.5837e-01, -8.5130e-02,  4.2848e-03,  7.9874e-01,\n",
            "        -1.2636e-01,  6.3773e-01, -1.0567e+00,  5.5673e-01,  2.5318e-02,\n",
            "        -5.1313e-01,  1.4587e+00,  8.7732e-02, -1.0696e+00, -6.6145e-01,\n",
            "         5.2795e-01, -8.4844e-02, -1.6449e-01, -4.8475e-01,  3.5043e-01,\n",
            "         6.7714e-01, -1.2891e-01, -3.2024e-01, -6.0305e-01,  1.8574e-01,\n",
            "        -1.4988e-01, -4.4082e-01, -7.0474e-01, -6.1806e-02,  1.0977e-01,\n",
            "         3.3156e-02,  2.6802e-01,  4.4294e-02,  8.6407e-01, -3.7762e-01,\n",
            "         1.0412e+00,  4.5824e-01,  1.4111e+00, -6.8672e-01,  8.7593e-01,\n",
            "        -8.3370e-01, -2.7001e-02,  1.8189e-01,  2.1421e-01, -4.3119e-01,\n",
            "         4.9834e-01, -7.0512e-01,  5.7093e-01, -3.6991e-01, -6.6657e-01,\n",
            "        -7.8585e-01, -4.5173e-01, -5.9383e-01,  1.9519e-01, -2.2657e-01,\n",
            "        -3.8151e-01,  9.3890e-02, -2.7617e-01,  2.4565e-01, -9.0658e-01,\n",
            "         8.2309e-01,  2.1764e-01, -2.2654e-04, -8.0983e-01,  7.5604e-01,\n",
            "        -3.2564e-01,  5.0720e-02, -2.9328e-01, -5.5356e-01, -7.1022e-02,\n",
            "         7.2405e-01, -7.2687e-02,  2.2054e-01,  1.6605e-02, -3.0436e-02,\n",
            "        -4.7251e-02,  5.9868e-01, -8.3649e-01,  8.9660e-01,  2.8791e-01,\n",
            "         2.8395e-02, -9.5467e-02, -6.9062e-01, -1.3273e+00, -7.1720e-02,\n",
            "        -1.9235e-01, -1.4593e+00, -3.0780e-01,  3.7270e-01,  4.6332e-01,\n",
            "         9.0387e-01, -2.3250e-01,  3.9045e-01, -6.5122e-01,  2.3300e-01,\n",
            "        -2.9907e-01,  2.0778e-01, -7.0184e-01,  6.0105e-01,  2.4622e-01,\n",
            "         1.2546e+00,  9.5454e-01,  7.2989e-01, -7.0244e-01,  4.8550e-01,\n",
            "        -1.0681e+00, -3.9610e-02,  7.2464e-01, -4.3970e-01, -2.0906e-01,\n",
            "         2.7120e-01, -5.6015e-01, -2.6736e-01,  6.0174e-01, -1.0579e-01,\n",
            "        -1.1794e-01,  4.4082e-01,  5.6632e-01])), ('module.encoder_q.layer2.2.bn2.running_var', tensor([0.9281, 0.8707, 0.8518, 0.9029, 0.8242, 0.9485, 0.6182, 0.7820, 0.6285,\n",
            "        0.6285, 0.7277, 0.8720, 0.4876, 0.9380, 0.9983, 0.6234, 0.7006, 2.1774,\n",
            "        0.5867, 0.6541, 0.7004, 1.3574, 0.5746, 1.4097, 1.0765, 1.6808, 0.6866,\n",
            "        0.6783, 0.4934, 0.6141, 0.5701, 0.5579, 0.6769, 1.7431, 0.5596, 1.2040,\n",
            "        0.5043, 1.6826, 0.6540, 0.6981, 0.6807, 0.9480, 1.4823, 2.0129, 0.7961,\n",
            "        1.8822, 0.7201, 1.4365, 1.0878, 0.9757, 0.7295, 0.5911, 0.6294, 0.9385,\n",
            "        1.0195, 0.8495, 1.1673, 0.7260, 0.7861, 0.9053, 1.2972, 1.7671, 1.0311,\n",
            "        0.4644, 0.7061, 1.1415, 0.7606, 0.7180, 0.6752, 1.2132, 0.7761, 1.4255,\n",
            "        1.2155, 0.8563, 1.1444, 0.7952, 0.7807, 0.5912, 0.5501, 1.1892, 1.3105,\n",
            "        0.9502, 0.9529, 0.5757, 0.5948, 0.6595, 1.1552, 1.0783, 1.1185, 0.8438,\n",
            "        1.1296, 0.8105, 0.9864, 1.0595, 0.5761, 0.8552, 1.4350, 1.3909, 1.3298,\n",
            "        0.5694, 0.8991, 0.6846, 0.5711, 0.9452, 0.4245, 0.8539, 0.9661, 0.8238,\n",
            "        0.6701, 0.8062, 2.6125, 0.8426, 0.7445, 0.8353, 0.8903, 1.2515, 0.9600,\n",
            "        1.5749, 0.8407, 0.8145, 1.1136, 0.7023, 0.5976, 0.8842, 0.7241, 0.5473,\n",
            "        0.4543, 0.9672])), ('module.encoder_q.layer2.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.2.conv3.weight', tensor([[[[ 0.0984]],\n",
            "\n",
            "         [[-0.1231]],\n",
            "\n",
            "         [[-0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0261]],\n",
            "\n",
            "         [[-0.0258]],\n",
            "\n",
            "         [[-0.1618]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0426]],\n",
            "\n",
            "         [[ 0.0094]],\n",
            "\n",
            "         [[-0.1091]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0013]],\n",
            "\n",
            "         [[ 0.0326]],\n",
            "\n",
            "         [[ 0.0821]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0084]],\n",
            "\n",
            "         [[-0.0644]],\n",
            "\n",
            "         [[ 0.0538]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0471]],\n",
            "\n",
            "         [[ 0.0541]],\n",
            "\n",
            "         [[-0.0993]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1245]],\n",
            "\n",
            "         [[-0.0385]],\n",
            "\n",
            "         [[ 0.0835]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0440]],\n",
            "\n",
            "         [[-0.0556]],\n",
            "\n",
            "         [[ 0.0374]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0690]],\n",
            "\n",
            "         [[ 0.0365]],\n",
            "\n",
            "         [[ 0.0323]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0672]],\n",
            "\n",
            "         [[-0.0245]],\n",
            "\n",
            "         [[-0.0915]]],\n",
            "\n",
            "\n",
            "        [[[-0.0372]],\n",
            "\n",
            "         [[-0.0149]],\n",
            "\n",
            "         [[ 0.0984]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1013]],\n",
            "\n",
            "         [[ 0.0277]],\n",
            "\n",
            "         [[-0.0757]]]])), ('module.encoder_q.layer2.2.bn3.weight', tensor([0.9923, 0.9914, 0.9914, 0.9928, 0.9913, 0.9918, 0.9930, 0.9924, 0.9921,\n",
            "        0.9909, 0.9935, 0.9930, 0.9929, 0.9928, 0.9914, 0.9922, 0.9909, 0.9935,\n",
            "        0.9925, 0.9919, 0.9935, 0.9920, 0.9909, 0.9905, 0.9912, 0.9918, 0.9924,\n",
            "        0.9926, 0.9915, 0.9934, 0.9913, 0.9909, 0.9932, 0.9928, 0.9922, 0.9905,\n",
            "        0.9922, 0.9913, 0.9928, 0.9915, 0.9923, 0.9934, 0.9902, 0.9909, 0.9920,\n",
            "        0.9915, 0.9916, 0.9919, 0.9925, 0.9911, 0.9917, 0.9944, 0.9912, 0.9935,\n",
            "        0.9915, 0.9939, 0.9933, 0.9939, 0.9920, 0.9923, 0.9924, 0.9927, 0.9928,\n",
            "        0.9911, 0.9932, 0.9909, 0.9926, 0.9935, 0.9912, 0.9923, 0.9928, 0.9918,\n",
            "        0.9917, 0.9921, 0.9925, 0.9948, 0.9916, 0.9930, 0.9921, 0.9925, 0.9917,\n",
            "        0.9938, 0.9910, 0.9922, 0.9928, 0.9919, 0.9911, 0.9932, 0.9930, 0.9921,\n",
            "        0.9915, 0.9916, 0.9918, 0.9929, 0.9926, 0.9922, 0.9917, 0.9921, 0.9912,\n",
            "        0.9921, 0.9921, 0.9918, 0.9931, 0.9927, 0.9935, 0.9925, 0.9922, 0.9928,\n",
            "        0.9918, 0.9916, 0.9916, 0.9931, 0.9930, 0.9919, 0.9927, 0.9933, 0.9917,\n",
            "        0.9933, 0.9926, 0.9930, 0.9924, 0.9941, 0.9939, 0.9942, 0.9909, 0.9909,\n",
            "        0.9923, 0.9924, 0.9919, 0.9911, 0.9907, 0.9912, 0.9933, 0.9931, 0.9920,\n",
            "        0.9927, 0.9936, 0.9923, 0.9920, 0.9917, 0.9925, 0.9913, 0.9910, 0.9908,\n",
            "        0.9913, 0.9926, 0.9930, 0.9912, 0.9935, 0.9919, 0.9929, 0.9920, 0.9928,\n",
            "        0.9906, 0.9946, 0.9926, 0.9923, 0.9921, 0.9925, 0.9908, 0.9917, 0.9902,\n",
            "        0.9932, 0.9919, 0.9917, 0.9919, 0.9925, 0.9915, 0.9928, 0.9902, 0.9926,\n",
            "        0.9931, 0.9945, 0.9941, 0.9920, 0.9905, 0.9916, 0.9921, 0.9919, 0.9904,\n",
            "        0.9921, 0.9939, 0.9916, 0.9928, 0.9939, 0.9919, 0.9936, 0.9921, 0.9910,\n",
            "        0.9910, 0.9909, 0.9916, 0.9937, 0.9918, 0.9927, 0.9925, 0.9913, 0.9913,\n",
            "        0.9927, 0.9916, 0.9935, 0.9929, 0.9917, 0.9913, 0.9912, 0.9926, 0.9950,\n",
            "        0.9921, 0.9918, 0.9920, 0.9931, 0.9926, 0.9922, 0.9916, 0.9924, 0.9914,\n",
            "        0.9916, 0.9924, 0.9922, 0.9932, 0.9920, 0.9929, 0.9918, 0.9914, 0.9928,\n",
            "        0.9936, 0.9914, 0.9925, 0.9908, 0.9931, 0.9913, 0.9924, 0.9918, 0.9920,\n",
            "        0.9936, 0.9921, 0.9907, 0.9919, 0.9926, 0.9918, 0.9922, 0.9925, 0.9926,\n",
            "        0.9929, 0.9925, 0.9909, 0.9913, 0.9918, 0.9927, 0.9917, 0.9923, 0.9901,\n",
            "        0.9907, 0.9916, 0.9920, 0.9905, 0.9930, 0.9907, 0.9916, 0.9929, 0.9920,\n",
            "        0.9923, 0.9933, 0.9920, 0.9922, 0.9930, 0.9924, 0.9931, 0.9926, 0.9931,\n",
            "        0.9924, 0.9920, 0.9925, 0.9935, 0.9920, 0.9931, 0.9915, 0.9905, 0.9924,\n",
            "        0.9921, 0.9939, 0.9917, 0.9927, 0.9913, 0.9914, 0.9926, 0.9919, 0.9914,\n",
            "        0.9933, 0.9910, 0.9935, 0.9909, 0.9936, 0.9919, 0.9924, 0.9925, 0.9939,\n",
            "        0.9924, 0.9922, 0.9932, 0.9921, 0.9913, 0.9945, 0.9917, 0.9947, 0.9914,\n",
            "        0.9924, 0.9921, 0.9917, 0.9919, 0.9921, 0.9925, 0.9916, 0.9923, 0.9920,\n",
            "        0.9917, 0.9919, 0.9916, 0.9945, 0.9923, 0.9927, 0.9917, 0.9921, 0.9938,\n",
            "        0.9934, 0.9926, 0.9926, 0.9926, 0.9930, 0.9942, 0.9917, 0.9929, 0.9921,\n",
            "        0.9918, 0.9929, 0.9928, 0.9931, 0.9904, 0.9905, 0.9923, 0.9924, 0.9919,\n",
            "        0.9919, 0.9925, 0.9921, 0.9937, 0.9911, 0.9922, 0.9935, 0.9920, 0.9937,\n",
            "        0.9921, 0.9904, 0.9925, 0.9939, 0.9928, 0.9936, 0.9910, 0.9910, 0.9934,\n",
            "        0.9927, 0.9921, 0.9930, 0.9916, 0.9909, 0.9911, 0.9921, 0.9922, 0.9933,\n",
            "        0.9904, 0.9940, 0.9930, 0.9915, 0.9920, 0.9918, 0.9923, 0.9923, 0.9923,\n",
            "        0.9921, 0.9923, 0.9915, 0.9918, 0.9921, 0.9907, 0.9924, 0.9912, 0.9921,\n",
            "        0.9912, 0.9923, 0.9933, 0.9912, 0.9919, 0.9921, 0.9926, 0.9915, 0.9920,\n",
            "        0.9918, 0.9905, 0.9912, 0.9912, 0.9917, 0.9936, 0.9931, 0.9922, 0.9917,\n",
            "        0.9911, 0.9923, 0.9909, 0.9925, 0.9929, 0.9934, 0.9940, 0.9930, 0.9920,\n",
            "        0.9923, 0.9920, 0.9925, 0.9922, 0.9929, 0.9903, 0.9915, 0.9940, 0.9918,\n",
            "        0.9915, 0.9927, 0.9930, 0.9914, 0.9926, 0.9919, 0.9917, 0.9910, 0.9920,\n",
            "        0.9918, 0.9919, 0.9919, 0.9927, 0.9911, 0.9944, 0.9923, 0.9921, 0.9925,\n",
            "        0.9926, 0.9919, 0.9923, 0.9921, 0.9931, 0.9909, 0.9924, 0.9928, 0.9917,\n",
            "        0.9932, 0.9931, 0.9924, 0.9913, 0.9918, 0.9927, 0.9910, 0.9914, 0.9928,\n",
            "        0.9912, 0.9924, 0.9915, 0.9904, 0.9911, 0.9925, 0.9906, 0.9915, 0.9918,\n",
            "        0.9911, 0.9935, 0.9932, 0.9932, 0.9916, 0.9924, 0.9928, 0.9917, 0.9901,\n",
            "        0.9921, 0.9921, 0.9929, 0.9923, 0.9933, 0.9912, 0.9912, 0.9921, 0.9927,\n",
            "        0.9940, 0.9906, 0.9935, 0.9935, 0.9931, 0.9938, 0.9929, 0.9919, 0.9919,\n",
            "        0.9913, 0.9923, 0.9913, 0.9927, 0.9919, 0.9919, 0.9929, 0.9924, 0.9925,\n",
            "        0.9932, 0.9918, 0.9922, 0.9942, 0.9935, 0.9913, 0.9923, 0.9931])), ('module.encoder_q.layer2.2.bn3.bias', tensor([ 9.2327e-04,  1.1545e-03,  1.0804e-03, -5.6027e-04,  2.2009e-04,\n",
            "         1.4663e-03,  4.8608e-04, -2.0446e-04, -5.6989e-05,  3.7214e-04,\n",
            "         3.2792e-06,  1.3474e-03,  6.3501e-04,  7.7331e-05, -4.5454e-05,\n",
            "        -2.9195e-04, -4.2799e-04, -9.5292e-04,  8.0243e-04, -8.6711e-05,\n",
            "         1.4840e-03, -3.0612e-04, -7.5531e-04, -3.0485e-04, -2.8562e-04,\n",
            "         4.4126e-04, -7.1382e-04,  5.6836e-04, -5.2960e-04,  7.7113e-04,\n",
            "        -7.3838e-04,  5.8871e-05,  4.7917e-04,  9.7777e-06,  3.4237e-04,\n",
            "        -1.3558e-03,  4.5290e-04, -1.0878e-04,  5.7908e-04,  1.1592e-03,\n",
            "         9.8077e-04,  4.2993e-04,  2.9635e-04,  9.8350e-05,  8.3489e-04,\n",
            "        -5.1213e-04, -2.1534e-04,  9.9531e-05, -5.7482e-04, -3.3418e-04,\n",
            "         1.6743e-04, -9.5930e-04, -8.1842e-04, -1.2994e-04, -3.9103e-05,\n",
            "         1.6969e-04, -8.1865e-04,  5.7644e-04,  3.3022e-04, -1.7163e-04,\n",
            "        -9.1820e-04, -4.8204e-05,  1.4255e-04,  5.0891e-04,  4.1567e-04,\n",
            "        -9.3216e-04,  3.2664e-04,  1.6947e-04,  9.2191e-04, -6.1394e-05,\n",
            "         4.8664e-04, -3.5701e-05, -8.1690e-04,  8.9609e-05,  7.9581e-04,\n",
            "         1.5454e-03, -3.9800e-04,  1.0399e-03, -2.6705e-05,  1.1612e-03,\n",
            "        -1.8351e-03,  4.9392e-04, -2.8665e-04,  1.8597e-03, -1.6770e-04,\n",
            "        -8.0734e-04,  3.8905e-04,  7.5068e-05,  1.4114e-03,  9.7913e-05,\n",
            "        -8.4613e-04, -5.3593e-04, -3.8143e-04, -5.3521e-04,  2.6641e-04,\n",
            "         7.4348e-04, -3.2762e-04, -4.5382e-04,  7.0720e-05, -1.8250e-04,\n",
            "         4.5653e-04,  2.3558e-04, -1.5965e-03, -6.8396e-04,  5.7687e-04,\n",
            "        -2.8131e-04, -6.6326e-04,  3.0926e-04, -4.5341e-04,  7.0289e-05,\n",
            "        -7.0717e-05,  1.8415e-04,  1.3688e-03, -3.4762e-04,  4.3375e-04,\n",
            "         5.3329e-04,  4.5724e-04,  5.9558e-05, -7.2415e-04, -2.2671e-03,\n",
            "         8.5139e-04,  1.2320e-03,  8.2238e-04, -8.4052e-04, -3.4133e-05,\n",
            "        -4.3956e-04,  1.4580e-03, -1.1365e-04,  3.3537e-04, -6.3567e-05,\n",
            "         4.0925e-04,  3.5467e-04,  5.9184e-04, -9.5286e-06,  4.4679e-05,\n",
            "         2.2007e-04,  7.3195e-04,  8.6703e-05, -6.2607e-04,  3.7048e-04,\n",
            "        -1.1538e-03,  5.6818e-04, -1.6101e-04,  5.1888e-04, -2.2145e-03,\n",
            "        -1.1774e-03,  3.2510e-04,  5.9541e-05,  1.8196e-04, -8.4923e-04,\n",
            "         3.8080e-04,  6.4443e-04, -6.2090e-04, -1.0396e-03, -1.3794e-04,\n",
            "         8.5084e-04, -1.6092e-04, -9.3705e-05,  1.9221e-04, -3.1321e-04,\n",
            "        -2.0068e-04,  2.0745e-04,  4.0080e-04, -6.7777e-05, -1.2899e-03,\n",
            "         1.1560e-03,  4.9722e-04,  5.5114e-04,  4.1302e-04, -2.1537e-03,\n",
            "         6.0164e-04,  1.8691e-03,  3.8729e-04, -7.1826e-04, -7.2271e-04,\n",
            "        -8.3007e-04, -1.0244e-04, -1.4770e-04,  4.7151e-05, -2.1297e-04,\n",
            "         2.0668e-04,  3.8505e-04,  1.4363e-04,  1.2452e-03,  5.5499e-04,\n",
            "         6.3026e-04,  6.8717e-04,  8.6125e-04, -4.1404e-04, -8.0072e-04,\n",
            "        -9.1464e-04, -1.3104e-05, -5.1414e-04, -6.5208e-04,  1.8507e-03,\n",
            "        -7.3457e-04, -8.4812e-04,  1.1451e-04,  1.0274e-03,  4.3258e-04,\n",
            "        -5.7509e-05, -9.4512e-04,  2.8651e-04, -1.9368e-03, -1.5330e-03,\n",
            "         1.0050e-03,  1.7055e-04, -2.1166e-04,  6.8668e-05,  1.7153e-04,\n",
            "         1.0429e-03,  1.1553e-03, -3.2417e-04, -2.1044e-03, -1.0204e-03,\n",
            "        -5.1672e-04, -2.5505e-04, -1.1960e-03,  3.6143e-04,  1.6938e-04,\n",
            "        -2.1846e-04,  1.0807e-03,  3.6501e-04,  9.4969e-06,  2.0667e-07,\n",
            "         9.8348e-04, -1.7049e-04, -1.1465e-03, -1.4871e-04,  3.4510e-04,\n",
            "        -3.6377e-04,  4.5362e-04, -1.3912e-03, -5.7835e-04, -4.7327e-04,\n",
            "        -9.1788e-04,  4.7684e-04,  6.9254e-04,  1.5396e-04,  6.5745e-04,\n",
            "         2.5639e-04,  3.4814e-04,  2.3039e-04,  4.8609e-04, -1.0965e-03,\n",
            "        -1.0733e-04, -1.1318e-03,  5.9302e-04,  4.5127e-04, -2.5229e-04,\n",
            "         7.4269e-04,  9.3381e-05, -1.3959e-03, -3.6836e-05, -7.7096e-04,\n",
            "        -5.2678e-04,  6.7896e-04,  5.2591e-04,  6.9158e-04, -1.6415e-04,\n",
            "         2.6868e-04, -2.0084e-05,  9.3026e-04,  1.5829e-04, -2.9193e-04,\n",
            "        -1.0624e-03, -1.4629e-04, -3.1396e-05,  1.3365e-03,  8.6842e-04,\n",
            "         2.2565e-04, -1.2130e-03, -1.9990e-04,  5.2171e-04,  1.5229e-04,\n",
            "         5.0222e-04, -1.9236e-04, -1.1619e-03, -3.6297e-04,  9.2651e-04,\n",
            "         5.0545e-05, -8.1764e-04,  3.6787e-04,  2.3026e-04,  1.6385e-04,\n",
            "         3.0148e-04, -2.3416e-03, -1.8307e-03,  9.8212e-04,  4.3627e-04,\n",
            "        -1.1605e-03, -5.0316e-04, -2.5363e-04,  5.1712e-05,  2.9719e-04,\n",
            "        -3.0574e-04, -5.5893e-05,  2.6583e-04,  2.4899e-04,  6.3389e-04,\n",
            "        -2.9303e-04, -3.4481e-05,  8.3335e-04, -2.3705e-04,  1.5291e-03,\n",
            "         1.5983e-03,  2.3404e-04, -9.0246e-04, -9.3214e-05, -4.6915e-04,\n",
            "         1.6107e-04,  1.1333e-03,  5.1119e-04, -7.8301e-04,  4.9479e-05,\n",
            "         1.2925e-04,  3.6196e-04,  8.5020e-05, -1.4264e-05, -6.6003e-04,\n",
            "         6.1537e-04, -3.7174e-04, -1.2224e-04,  1.4971e-03,  1.8866e-03,\n",
            "        -3.6648e-04, -2.5738e-04,  2.3763e-04,  6.6260e-04,  6.7608e-04,\n",
            "        -4.2479e-04, -3.8145e-04, -2.6132e-04,  3.2956e-04,  8.5923e-04,\n",
            "        -3.4636e-04, -7.0632e-05, -1.1019e-03, -4.0306e-04,  7.0391e-04,\n",
            "         2.4917e-03, -5.5783e-04,  7.4668e-04,  1.1961e-03,  1.3924e-04,\n",
            "         3.0032e-04, -4.7536e-04, -1.4839e-04, -4.6322e-04,  2.2695e-04,\n",
            "         6.8250e-05,  2.4665e-05, -9.4245e-04,  1.0980e-03,  8.4526e-04,\n",
            "        -2.5714e-05,  3.1076e-04, -9.0363e-04,  1.1418e-03, -6.5110e-04,\n",
            "        -1.8950e-04,  6.8397e-04,  7.1366e-04,  2.3826e-04,  6.9536e-04,\n",
            "        -6.3663e-04,  7.2434e-04,  3.8979e-04,  7.7459e-04, -1.4664e-03,\n",
            "        -6.2242e-04,  1.0206e-03,  4.4278e-04,  1.1383e-04,  1.3172e-03,\n",
            "        -1.3989e-03,  1.0610e-03, -1.3227e-03,  9.0084e-04,  3.5235e-04,\n",
            "         6.7145e-04,  4.8585e-04, -3.1608e-04, -6.9159e-04,  9.3544e-05,\n",
            "        -9.6356e-04,  8.4952e-04, -6.5424e-06,  2.7962e-04, -3.4519e-04,\n",
            "        -2.5873e-05, -8.1118e-05,  4.5580e-04, -1.8101e-04,  6.1382e-04,\n",
            "        -6.1759e-04,  1.1559e-03,  2.1102e-04, -3.5645e-04,  1.2307e-04,\n",
            "        -8.6798e-04,  1.6418e-03, -8.0133e-04, -1.6798e-04, -5.9129e-04,\n",
            "        -1.0390e-04, -5.5353e-04,  3.2262e-04, -7.8624e-04,  1.0763e-03,\n",
            "         1.3146e-03, -2.0454e-03, -2.9485e-04,  1.3413e-04, -3.1406e-05,\n",
            "        -2.7686e-04,  5.1799e-04, -5.1690e-04, -3.6672e-04, -6.0777e-05,\n",
            "         7.8428e-04,  7.3882e-05,  7.0735e-04,  5.2337e-05,  5.0323e-04,\n",
            "         7.6482e-04, -6.6169e-05,  4.7195e-04, -2.6814e-04,  2.9664e-04,\n",
            "         6.4516e-04,  2.1061e-04, -3.0731e-04, -4.1783e-05,  9.4511e-04,\n",
            "         7.9813e-04,  1.0063e-03,  5.7519e-04, -4.0901e-04,  9.2376e-04,\n",
            "         3.2316e-04,  4.2115e-05,  6.1673e-04,  1.7890e-04, -2.7484e-05,\n",
            "        -2.2005e-04,  4.4724e-04, -3.2263e-04,  1.6532e-03, -8.2265e-04,\n",
            "         9.8053e-05, -1.3479e-03, -1.6948e-04, -1.4879e-03,  1.7624e-04,\n",
            "         2.6715e-04, -1.3245e-03,  1.0932e-03, -6.6446e-05,  1.3968e-04,\n",
            "         1.8522e-04, -5.1571e-04, -3.9938e-04, -3.7722e-04,  1.5716e-04,\n",
            "         4.9432e-04,  6.0889e-04,  7.5582e-04,  6.6430e-04, -9.1227e-04,\n",
            "         5.5540e-04,  2.2452e-04, -1.2288e-03,  1.7873e-04,  3.7474e-04,\n",
            "        -4.0113e-04, -5.2220e-04,  1.4428e-04, -1.2311e-03, -6.3819e-04,\n",
            "        -2.4021e-04,  7.1978e-04, -6.5790e-04,  9.7067e-04, -2.7241e-04,\n",
            "         1.7848e-04,  2.0656e-04,  1.0818e-04,  6.2794e-04, -9.1584e-04,\n",
            "         5.1219e-04,  3.9435e-04,  2.9462e-04,  7.6854e-05,  1.1704e-04,\n",
            "        -1.3032e-03,  1.1201e-03, -5.4251e-04, -1.6117e-04, -6.0488e-04,\n",
            "         4.7414e-04, -3.8838e-04,  1.4901e-03,  4.2769e-05, -1.7160e-06,\n",
            "        -5.4362e-04, -4.1647e-04,  1.8820e-04,  1.0880e-03, -1.0189e-03,\n",
            "         4.1869e-05,  9.0056e-05])), ('module.encoder_q.layer2.2.bn3.running_mean', tensor([-9.6211e-02,  9.2383e-02,  2.7176e-01,  3.0928e-01, -3.0513e-01,\n",
            "         2.4883e-01,  3.8522e-02, -1.0971e-01,  2.6669e-01,  3.9987e-01,\n",
            "         1.0565e-01,  2.5183e-01,  2.9703e-01,  3.5603e-01,  3.6886e-01,\n",
            "        -5.9485e-03,  9.6487e-02, -1.3685e-01, -2.0279e-02, -8.0026e-02,\n",
            "         4.3106e-01,  2.0994e-01, -4.5592e-02,  1.2994e-01, -3.8854e-02,\n",
            "        -1.2422e-01, -1.3191e-01, -1.7696e-01,  3.1570e-01, -1.0082e-01,\n",
            "         8.2605e-02,  6.7735e-02,  2.7573e-01,  2.9694e-01, -5.9877e-02,\n",
            "         1.8363e-01,  1.3729e-01,  2.1820e-01,  3.5671e-02,  2.0723e-01,\n",
            "        -8.0964e-02,  9.3877e-02,  1.8927e-01,  1.5120e-01, -1.8820e-01,\n",
            "        -5.5594e-01, -6.8421e-02,  3.4822e-01,  3.0054e-01,  5.0559e-01,\n",
            "        -2.6949e-01, -2.2647e-01,  1.1783e-01, -1.1436e-01,  2.0361e-01,\n",
            "         2.9341e-01,  2.4313e-01, -5.1980e-01, -1.9313e-01,  3.3866e-01,\n",
            "         3.3231e-01,  2.2004e-01, -3.6472e-01,  2.2655e-02,  1.8614e-01,\n",
            "         1.4400e-01, -8.5265e-02,  2.8851e-04, -1.5697e-01, -1.6265e-01,\n",
            "         3.5385e-01, -4.6530e-02,  1.8138e-01,  4.8449e-01, -2.3633e-01,\n",
            "        -7.9358e-02, -4.3774e-01, -7.6842e-02,  4.8407e-02, -1.8761e-01,\n",
            "         2.9767e-01,  2.1614e-01, -2.2504e-01, -5.5309e-02, -1.3832e-01,\n",
            "         1.6968e-01,  1.1511e-01, -4.3639e-01,  3.6506e-01, -1.3484e-02,\n",
            "         4.4596e-02, -2.7882e-01, -9.9742e-02, -4.6323e-02, -4.4110e-02,\n",
            "        -5.0237e-01, -1.5823e-01,  1.8420e-01, -9.1361e-02, -1.6665e-02,\n",
            "         3.8977e-01,  2.4295e-01, -1.8456e-02, -1.8687e-01,  1.1245e-02,\n",
            "         9.0463e-02,  1.4755e-01,  2.8941e-02,  1.9629e-01,  1.1826e-01,\n",
            "         2.4023e-01,  5.7940e-01,  3.4845e-03,  3.3378e-01,  2.5531e-01,\n",
            "        -1.5274e-01, -3.6974e-01, -4.9953e-02, -5.5037e-01,  8.5584e-02,\n",
            "         1.1383e-01,  2.7221e-01,  1.0626e-02,  4.1356e-01, -3.8447e-01,\n",
            "         4.2871e-01, -1.0289e-01, -4.0299e-02, -5.2639e-01,  1.6111e-02,\n",
            "        -2.0622e-01,  3.9547e-01,  3.2095e-01,  4.3164e-02, -1.7475e-01,\n",
            "         4.0986e-02, -1.1098e-01, -9.2550e-02, -3.3529e-01, -4.0071e-01,\n",
            "        -4.0257e-01, -1.0670e-01,  2.3908e-01,  2.2983e-02,  3.0609e-01,\n",
            "         1.4039e-01, -3.0082e-01, -3.3811e-01,  2.1882e-01,  1.6087e-01,\n",
            "         7.8707e-02,  7.8518e-02,  2.5661e-01,  2.4470e-01, -1.2101e-02,\n",
            "        -1.1185e-01, -4.0665e-02,  2.2229e-01,  1.6032e-02, -7.0551e-02,\n",
            "         5.9916e-02,  3.0553e-01,  4.0251e-01,  3.5560e-01, -1.4097e-01,\n",
            "         3.1331e-01, -8.5307e-02, -6.4584e-02, -3.5282e-01,  2.4851e-01,\n",
            "        -3.2524e-01,  3.0492e-01, -1.8983e-01, -1.8484e-01, -1.1543e-01,\n",
            "        -3.9280e-01, -4.8663e-02,  4.1843e-01, -8.4451e-02, -2.7912e-01,\n",
            "         2.6337e-01,  2.6541e-01, -6.3755e-01,  1.4782e-01,  1.5624e-02,\n",
            "         2.2528e-01,  2.3592e-01,  8.5511e-02, -1.4503e-01, -3.5655e-01,\n",
            "        -5.5759e-01, -8.6905e-02, -2.2020e-01, -4.5113e-01, -4.1982e-01,\n",
            "         9.0156e-02, -2.0892e-01, -1.6521e-01,  1.8044e-01, -6.2249e-02,\n",
            "        -4.9544e-01, -7.1394e-01, -2.6478e-01,  1.9535e-02, -1.1654e-01,\n",
            "         1.0027e-02, -1.5873e-01,  3.7503e-01, -7.3424e-02, -2.9539e-01,\n",
            "         2.6403e-01, -1.4565e-02, -2.7394e-01,  1.0013e-01,  3.3890e-01,\n",
            "        -2.9771e-01,  7.2091e-02, -3.6854e-01,  3.3034e-01, -1.4956e-01,\n",
            "        -2.0661e-01,  1.5538e-01,  1.5648e-01, -1.3824e-01,  6.3964e-02,\n",
            "        -8.1996e-02,  7.9424e-02, -1.0241e-01,  6.5101e-02, -1.5198e-01,\n",
            "        -1.8629e-01, -5.5737e-02,  1.0156e-01,  4.1240e-01, -1.9904e-01,\n",
            "         9.0292e-02, -1.9879e-02,  1.8097e-01,  2.6515e-01, -6.8956e-02,\n",
            "        -2.5533e-01, -1.7850e-01, -3.2113e-01,  2.7524e-01,  2.5173e-01,\n",
            "         4.2970e-01,  9.6093e-02, -2.3468e-01,  1.9748e-01, -3.0879e-01,\n",
            "        -2.0832e-01, -2.1073e-01,  3.6590e-01,  3.4305e-02,  3.8996e-02,\n",
            "         1.4739e-02,  8.1043e-02,  1.3881e-01,  7.1262e-02,  3.9473e-01,\n",
            "        -2.3059e-01, -2.4166e-02, -1.4359e-01,  9.9853e-02,  9.8270e-03,\n",
            "         2.6096e-01, -2.5531e-01,  6.2321e-01, -2.2734e-01, -2.2827e-01,\n",
            "        -4.6631e-01, -2.5879e-01, -2.9114e-01,  2.5446e-03, -1.4064e-02,\n",
            "         2.8953e-03, -4.9172e-02, -1.8126e-01, -8.7674e-02, -1.9092e-01,\n",
            "        -1.3088e-01, -1.6537e-01, -2.1144e-01,  2.5356e-01,  2.0907e-01,\n",
            "         2.1227e-01,  3.3800e-01, -1.7726e-01, -5.5075e-02,  5.4507e-01,\n",
            "         3.2815e-01,  3.1159e-01, -5.8907e-01, -5.8431e-02,  9.5682e-02,\n",
            "         5.4984e-01, -4.3525e-01,  5.3526e-01, -1.3687e-01,  1.5335e-01,\n",
            "        -4.0616e-01, -4.0552e-01, -6.7739e-02, -3.4671e-01, -4.9170e-02,\n",
            "        -4.0603e-01,  9.9863e-02,  1.2568e-01, -5.7732e-01, -1.1281e-01,\n",
            "        -1.8943e-01,  3.7737e-01,  5.7142e-01, -1.3005e-01, -2.1760e-01,\n",
            "        -2.4954e-01,  2.0218e-01,  6.1360e-03, -4.4762e-01,  8.5628e-02,\n",
            "        -1.3414e-01,  2.9275e-01,  1.5547e-01,  3.0637e-01,  1.3603e-01,\n",
            "         5.3579e-01,  1.0467e-03, -2.3977e-01,  5.0002e-02,  5.4137e-01,\n",
            "         7.5925e-02,  3.1204e-01, -6.1932e-02,  3.1030e-01,  5.1787e-01,\n",
            "        -1.7386e-02, -1.6997e-01,  5.3643e-02, -2.0536e-01,  1.4470e-01,\n",
            "        -2.2641e-01, -4.1758e-02,  7.3621e-02, -1.2031e-01, -2.2398e-01,\n",
            "        -3.6426e-01,  1.6762e-01, -6.0326e-02,  1.7278e-02, -2.2533e-01,\n",
            "        -1.4444e-01,  1.2569e-01,  9.3894e-02, -1.0237e-01, -1.4450e-01,\n",
            "         2.4917e-01,  6.3403e-02, -3.1960e-01,  1.6599e-01,  3.2568e-01,\n",
            "         2.0906e-02,  3.5662e-01, -1.6317e-01, -2.4520e-01,  1.3596e-01,\n",
            "        -2.1849e-01,  1.0747e-01, -3.7550e-01, -3.0197e-02,  2.5799e-02,\n",
            "        -1.6538e-01,  1.1461e-01, -4.7650e-02,  4.3534e-02,  1.3095e-01,\n",
            "        -2.3652e-01,  2.1556e-01,  2.3007e-01,  3.6919e-02,  2.9508e-01,\n",
            "        -2.0983e-01, -7.4962e-02, -5.0802e-01,  3.3651e-02,  4.7556e-02,\n",
            "         3.0803e-01,  1.6419e-03,  5.5938e-01, -8.7911e-02,  6.2512e-02,\n",
            "         1.7365e-01,  2.1359e-01,  1.8094e-01, -2.3466e-01, -4.8553e-02,\n",
            "         1.2332e-02,  1.6628e-01, -1.6618e-01, -1.4113e-01, -9.2036e-02,\n",
            "         8.7167e-02,  3.3396e-01,  1.8347e-02, -3.0213e-01,  2.9868e-02,\n",
            "         1.8296e-01,  2.8930e-01,  2.3888e-01, -7.4963e-02,  1.5980e-02,\n",
            "         4.6657e-01,  2.4873e-01, -1.0569e-01, -1.0742e-01,  2.9642e-01,\n",
            "         1.0521e-01, -3.2753e-01,  2.5061e-01,  2.3801e-01, -2.5629e-01,\n",
            "        -2.8897e-01, -3.4793e-02, -1.8262e-01, -5.4656e-03, -1.7162e-01,\n",
            "        -7.6394e-03, -2.3782e-01, -2.0430e-01, -2.5360e-01, -1.1780e-01,\n",
            "        -1.9891e-01, -7.0468e-02, -6.3012e-02, -5.2220e-03, -3.9309e-01,\n",
            "        -8.2540e-02,  7.0364e-02, -9.9158e-02, -3.2692e-01,  3.1877e-01,\n",
            "        -3.4718e-01,  1.5929e-02, -1.1813e-01, -7.3745e-02, -3.4641e-01,\n",
            "        -5.9253e-02,  1.6101e-01,  1.2705e-02, -2.0143e-01, -1.3056e-01,\n",
            "         3.7906e-02, -3.3971e-01, -9.7732e-02, -2.1720e-01,  8.7692e-03,\n",
            "        -3.2167e-01,  2.3948e-01,  5.4241e-03, -6.9483e-02,  3.0947e-02,\n",
            "        -1.5935e-01,  1.6059e-01,  7.9778e-02, -1.0924e-02, -4.7661e-01,\n",
            "         3.2556e-03,  2.3720e-01,  3.3814e-02,  2.1964e-01, -8.3906e-02,\n",
            "         9.7888e-02, -1.5100e-01, -1.2491e-01, -8.8099e-02,  7.1309e-02,\n",
            "         8.8977e-02, -3.3873e-01, -1.7190e-01,  2.4885e-01, -3.3313e-01,\n",
            "        -2.8403e-01, -2.1802e-02,  2.8032e-01,  1.1580e-01,  3.0424e-01,\n",
            "         6.2038e-02,  4.4717e-01, -9.7903e-02,  3.1555e-01,  6.5555e-01,\n",
            "         3.3079e-01, -6.8995e-03,  2.9604e-01,  2.7768e-01,  1.1427e-01,\n",
            "        -1.0759e-01,  5.0212e-01, -4.8988e-02,  4.8133e-02,  3.5018e-02,\n",
            "        -9.5764e-02, -1.8831e-01,  1.0973e-01,  3.6686e-01,  1.2663e-01,\n",
            "         2.8024e-01,  1.6869e-01, -1.8153e-01,  8.7960e-03, -7.0322e-02,\n",
            "        -3.0365e-01, -6.5833e-02])), ('module.encoder_q.layer2.2.bn3.running_var', tensor([0.1456, 0.1517, 0.1823, 0.1442, 0.1315, 0.1998, 0.1341, 0.0763, 0.1411,\n",
            "        0.2311, 0.2365, 0.2335, 0.1766, 0.2310, 0.1591, 0.1576, 0.0800, 0.1603,\n",
            "        0.1800, 0.1581, 0.1890, 0.1290, 0.1559, 0.1108, 0.2466, 0.2411, 0.1182,\n",
            "        0.1807, 0.1413, 0.1112, 0.1426, 0.1258, 0.2221, 0.1598, 0.1970, 0.2643,\n",
            "        0.3029, 0.2039, 0.2136, 0.1827, 0.1152, 0.2015, 0.1139, 0.1545, 0.1357,\n",
            "        0.1255, 0.2421, 0.2001, 0.1347, 0.1918, 0.4283, 0.1475, 0.1427, 0.2115,\n",
            "        0.1336, 0.1735, 0.4916, 0.1714, 0.1404, 0.0871, 0.1910, 0.4871, 0.2885,\n",
            "        0.1829, 0.2062, 0.1334, 0.1639, 0.1412, 0.1540, 0.1368, 0.1665, 0.1422,\n",
            "        0.1415, 0.3699, 0.1355, 0.1496, 0.1267, 0.1480, 0.0977, 0.1560, 0.1661,\n",
            "        0.0845, 0.2132, 0.1388, 0.1697, 0.2049, 0.1861, 0.5199, 0.4760, 0.1253,\n",
            "        0.1880, 0.1081, 0.2162, 0.1056, 0.1548, 0.3320, 0.1842, 0.1523, 0.2129,\n",
            "        0.1181, 0.2108, 0.1148, 0.1000, 0.1405, 0.0839, 0.1327, 0.1638, 0.1323,\n",
            "        0.1775, 0.1773, 0.1722, 0.3051, 0.1619, 0.2943, 0.1459, 0.0890, 0.1639,\n",
            "        0.1548, 0.2669, 0.1924, 0.4907, 0.1820, 0.1204, 0.4716, 0.1300, 0.4528,\n",
            "        0.1091, 0.1200, 0.1985, 0.0985, 0.1501, 0.2299, 0.1569, 0.1285, 0.1484,\n",
            "        0.1915, 0.1122, 0.1403, 0.2817, 0.1426, 0.1786, 0.1092, 0.2131, 0.1260,\n",
            "        0.0954, 0.1509, 0.1821, 0.1462, 0.0997, 0.1932, 0.1925, 0.2380, 0.2385,\n",
            "        0.2164, 0.2170, 0.1877, 0.1433, 0.1263, 0.1914, 0.2212, 0.1439, 0.1916,\n",
            "        0.5474, 0.1622, 0.1655, 0.1804, 0.1890, 0.1029, 0.2488, 0.2545, 0.1525,\n",
            "        0.1467, 0.1127, 0.1119, 0.1307, 0.1452, 0.3153, 0.1755, 0.3821, 0.1455,\n",
            "        0.3833, 0.1438, 0.6850, 0.2337, 0.2042, 0.2012, 0.1602, 0.1543, 0.1481,\n",
            "        0.1155, 0.2120, 0.1175, 0.1033, 0.3470, 0.4145, 0.1346, 0.1420, 0.1394,\n",
            "        0.1578, 0.2191, 0.1641, 0.4098, 0.3219, 0.2216, 0.1822, 0.1849, 0.1777,\n",
            "        0.3961, 0.2308, 0.1327, 0.1413, 0.1473, 0.1772, 0.1627, 0.2319, 0.1025,\n",
            "        0.1970, 0.1823, 0.1303, 0.1326, 0.1258, 0.1530, 0.2409, 0.3538, 0.2018,\n",
            "        0.2024, 0.1288, 0.1143, 0.1294, 0.3662, 0.2184, 0.1475, 0.1537, 0.0955,\n",
            "        0.1053, 0.1591, 0.2164, 0.2051, 0.1381, 0.1606, 0.3064, 0.2475, 0.1555,\n",
            "        0.1158, 0.1245, 0.1934, 0.2469, 0.3114, 0.1196, 0.1550, 0.1620, 0.1827,\n",
            "        0.1673, 0.1873, 0.1983, 0.1369, 0.3107, 0.2204, 0.1479, 0.1328, 0.1760,\n",
            "        0.0926, 0.2615, 0.1974, 0.2012, 0.1713, 0.1325, 0.2532, 0.1924, 0.1728,\n",
            "        0.2156, 0.1292, 0.2348, 0.1209, 0.0887, 0.1349, 0.1566, 0.2795, 0.1460,\n",
            "        0.1375, 0.1317, 0.1152, 0.2952, 0.1757, 0.1628, 0.1477, 0.2998, 0.1319,\n",
            "        0.1070, 0.2356, 0.3045, 0.4035, 0.2891, 0.2206, 0.1252, 0.2273, 0.1093,\n",
            "        0.1448, 0.1415, 0.1110, 0.2111, 0.2003, 0.1358, 0.1049, 0.1181, 0.2385,\n",
            "        0.1880, 0.1540, 0.2068, 0.1434, 0.1867, 0.1741, 0.4726, 0.2135, 0.1336,\n",
            "        0.1060, 0.2717, 0.1303, 0.1954, 0.1922, 0.1547, 0.1059, 0.1783, 0.6011,\n",
            "        0.3106, 0.1778, 0.1089, 0.3591, 0.1129, 0.1425, 0.1678, 0.1596, 0.1542,\n",
            "        0.1877, 0.3264, 0.3095, 0.1800, 0.1836, 0.2735, 0.1810, 0.1983, 0.1604,\n",
            "        0.1794, 0.1442, 0.1773, 0.2052, 0.1950, 0.1222, 0.2097, 0.2280, 0.0933,\n",
            "        0.0985, 0.2704, 0.1605, 0.1407, 0.0991, 0.1295, 0.2086, 0.3502, 0.1311,\n",
            "        0.1355, 0.2006, 0.1963, 0.2293, 0.1176, 0.2042, 0.1029, 0.2049, 0.1500,\n",
            "        0.1288, 0.2215, 0.1457, 0.1431, 0.1023, 0.2836, 0.1603, 0.1959, 0.2421,\n",
            "        0.1351, 0.1195, 0.1685, 0.1920, 0.4005, 0.1451, 0.3012, 0.3375, 0.1894,\n",
            "        0.1906, 0.1823, 0.2531, 0.1051, 0.3954, 0.1536, 0.2541, 0.1125, 0.1850,\n",
            "        0.1326, 0.2288, 0.1828, 0.1870, 0.1635, 0.1146, 0.2457, 0.1225, 0.1508,\n",
            "        0.1693, 0.2348, 0.1112, 0.1834, 0.1337, 0.1932, 0.1760, 0.1496, 0.2794,\n",
            "        0.1246, 0.1147, 0.1528, 0.1480, 0.1116, 0.1442, 0.1789, 0.1805, 0.1317,\n",
            "        0.1167, 0.2260, 0.1227, 0.1170, 0.1587, 0.2536, 0.1686, 0.2020, 0.1991,\n",
            "        0.1400, 0.1929, 0.2370, 0.1323, 0.1549, 0.1050, 0.1357, 0.2384, 0.2633,\n",
            "        0.1616, 0.2790, 0.1789, 0.2258, 0.1124, 0.1685, 0.1259, 0.2031, 0.0934,\n",
            "        0.1290, 0.4960, 0.1896, 0.1847, 0.1586, 0.1126, 0.1422, 0.0982, 0.1492,\n",
            "        0.1517, 0.1656, 0.1990, 0.1132, 0.1253, 0.2354, 0.1100, 0.2042, 0.2255,\n",
            "        0.1130, 0.2426, 0.1428, 0.1588, 0.2177, 0.1720, 0.1439, 0.1877, 0.2997,\n",
            "        0.2150, 0.1292, 0.1002, 0.2817, 0.1769, 0.1661, 0.3680, 0.3498, 0.1562,\n",
            "        0.1820, 0.4586, 0.1557, 0.2502, 0.1489, 0.1282, 0.1571, 0.4497, 0.1683,\n",
            "        0.2019, 0.3574, 0.2123, 0.2438, 0.3355, 0.1174, 0.1762, 0.2099, 0.1767,\n",
            "        0.1281, 0.1562, 0.2285, 0.1247, 0.1711, 0.1504, 0.1793, 0.2181])), ('module.encoder_q.layer2.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.3.conv1.weight', tensor([[[[-0.0838]],\n",
            "\n",
            "         [[-0.0844]],\n",
            "\n",
            "         [[ 0.0775]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0837]],\n",
            "\n",
            "         [[ 0.0214]],\n",
            "\n",
            "         [[-0.0771]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1157]],\n",
            "\n",
            "         [[ 0.1620]],\n",
            "\n",
            "         [[-0.0352]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0113]],\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[-0.1120]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0263]],\n",
            "\n",
            "         [[ 0.1575]],\n",
            "\n",
            "         [[ 0.1303]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1398]],\n",
            "\n",
            "         [[-0.0227]],\n",
            "\n",
            "         [[-0.0500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1704]],\n",
            "\n",
            "         [[-0.1635]],\n",
            "\n",
            "         [[ 0.0524]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0373]],\n",
            "\n",
            "         [[ 0.0500]],\n",
            "\n",
            "         [[ 0.1284]]],\n",
            "\n",
            "\n",
            "        [[[-0.0607]],\n",
            "\n",
            "         [[-0.0656]],\n",
            "\n",
            "         [[ 0.0620]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1901]],\n",
            "\n",
            "         [[-0.0686]],\n",
            "\n",
            "         [[-0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1245]],\n",
            "\n",
            "         [[ 0.0576]],\n",
            "\n",
            "         [[-0.1815]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1322]],\n",
            "\n",
            "         [[ 0.0602]],\n",
            "\n",
            "         [[ 0.1405]]]])), ('module.encoder_q.layer2.3.bn1.weight', tensor([0.9926, 0.9919, 0.9910, 0.9886, 0.9924, 0.9919, 0.9948, 0.9920, 0.9918,\n",
            "        0.9929, 0.9911, 0.9877, 0.9898, 0.9935, 0.9925, 0.9871, 0.9916, 0.9894,\n",
            "        0.9961, 0.9929, 0.9939, 0.9938, 0.9939, 0.9913, 0.9927, 0.9889, 0.9921,\n",
            "        0.9934, 0.9941, 0.9937, 0.9916, 0.9952, 0.9941, 0.9919, 0.9925, 0.9891,\n",
            "        0.9917, 0.9930, 0.9906, 0.9930, 0.9930, 0.9916, 0.9918, 0.9896, 0.9909,\n",
            "        0.9903, 0.9934, 0.9940, 0.9944, 0.9909, 0.9913, 0.9923, 0.9904, 0.9937,\n",
            "        0.9865, 0.9902, 0.9939, 0.9944, 0.9931, 0.9949, 0.9912, 0.9912, 0.9957,\n",
            "        0.9888, 0.9918, 0.9930, 0.9914, 0.9922, 0.9922, 0.9956, 0.9912, 0.9905,\n",
            "        0.9923, 0.9905, 0.9918, 0.9916, 0.9930, 0.9930, 0.9901, 0.9939, 0.9921,\n",
            "        0.9934, 0.9919, 0.9926, 0.9872, 0.9915, 0.9906, 0.9928, 0.9899, 0.9921,\n",
            "        0.9945, 0.9954, 0.9960, 0.9889, 0.9964, 0.9924, 0.9911, 0.9918, 0.9954,\n",
            "        0.9899, 0.9955, 0.9900, 0.9935, 0.9940, 0.9899, 0.9930, 0.9962, 0.9927,\n",
            "        0.9958, 0.9896, 0.9942, 0.9939, 0.9936, 0.9929, 0.9940, 0.9924, 0.9917,\n",
            "        0.9926, 0.9968, 0.9918, 0.9909, 0.9907, 0.9920, 0.9936, 0.9915, 0.9920,\n",
            "        0.9918, 0.9931])), ('module.encoder_q.layer2.3.bn1.bias', tensor([ 4.1397e-04,  3.7804e-04, -9.7343e-04, -6.1485e-04, -2.0084e-03,\n",
            "         5.8455e-04, -1.9591e-03,  3.8036e-04, -2.0162e-03,  3.0829e-04,\n",
            "        -3.1666e-05, -3.9601e-03, -3.0120e-03,  1.2218e-03,  4.0434e-04,\n",
            "        -3.5847e-03, -8.7356e-04, -1.8630e-03,  6.4289e-04, -7.0568e-04,\n",
            "         3.2320e-03,  1.6990e-03,  5.0852e-04, -1.2330e-04, -2.1977e-04,\n",
            "        -4.0654e-05,  8.1148e-04,  2.1838e-03,  1.8043e-04, -9.7745e-04,\n",
            "        -1.7625e-03,  3.2065e-03,  1.8629e-03,  2.4842e-03,  7.0792e-05,\n",
            "        -6.5365e-04, -1.2101e-03,  2.2074e-03, -8.9998e-04,  2.7021e-03,\n",
            "         4.6429e-04,  1.6224e-03, -3.6310e-04, -1.1406e-03, -2.3771e-03,\n",
            "         1.1938e-03,  2.1476e-03, -1.3268e-03,  1.5877e-03, -1.7003e-03,\n",
            "        -1.6463e-04,  1.5904e-04, -7.3916e-04,  1.0975e-03, -5.4774e-03,\n",
            "        -2.3999e-03,  1.4886e-03,  9.0357e-04,  2.1557e-03,  2.8514e-03,\n",
            "        -3.7904e-04, -2.1055e-03,  3.2409e-03, -2.3603e-03, -1.5511e-03,\n",
            "         2.3972e-04,  1.4048e-04,  8.4528e-05,  8.4156e-04,  3.4482e-03,\n",
            "         5.2425e-05,  1.6295e-03,  1.7047e-03, -1.6433e-03,  1.1011e-04,\n",
            "        -2.7795e-03, -6.2334e-04,  3.0344e-03,  9.2837e-04,  3.2501e-04,\n",
            "        -4.9436e-04,  3.8635e-04,  4.1969e-04,  5.7379e-04, -2.3400e-03,\n",
            "        -1.9157e-03, -1.6437e-03,  1.5352e-03, -2.9271e-03,  1.1831e-03,\n",
            "         3.9428e-03,  2.6846e-03,  2.7494e-05, -5.3361e-05,  4.3513e-03,\n",
            "         2.0273e-03, -9.2951e-04,  2.5388e-03,  8.0515e-04, -2.9429e-03,\n",
            "        -5.3647e-04,  7.4887e-04, -1.3065e-04,  1.3717e-03,  4.7049e-05,\n",
            "         9.3762e-04,  2.5536e-03,  7.5426e-05,  2.4085e-03,  6.1509e-04,\n",
            "         4.8169e-04, -7.0654e-05,  3.5280e-03, -9.5089e-04,  3.3002e-03,\n",
            "        -3.5991e-04, -7.7424e-04,  2.4569e-03,  2.9236e-03, -1.6751e-03,\n",
            "         1.9408e-04, -1.6732e-03,  9.2084e-04,  1.0788e-03,  6.1575e-04,\n",
            "         8.4383e-04, -1.4296e-03, -2.6474e-03])), ('module.encoder_q.layer2.3.bn1.running_mean', tensor([ 9.0365e-01,  2.7926e+00,  1.4691e+00, -1.8253e-01, -2.0520e+00,\n",
            "         1.0522e+00,  2.4622e+00, -1.7923e+00,  4.0024e+00, -1.2711e+00,\n",
            "         7.6132e-01, -8.6830e-01,  1.6191e+00, -1.7424e+00, -1.3184e+00,\n",
            "         2.0468e+00, -1.9350e+00, -2.9095e+00,  6.4040e+00,  2.8606e+00,\n",
            "         3.4412e-01,  2.4809e+00,  5.2121e-01, -1.6491e+00,  1.4978e+00,\n",
            "        -4.5807e+00, -4.4528e-02,  2.2658e+00, -3.4103e+00,  1.7587e+00,\n",
            "        -7.0307e-01,  2.4726e+00,  5.7479e-01,  1.1862e-02, -1.1379e+00,\n",
            "        -2.7219e+00,  1.7387e+00,  2.9606e+00, -6.9302e-01, -1.6621e+00,\n",
            "         1.7231e+00, -1.2571e+00,  9.2852e-01, -1.1315e+00,  2.4498e+00,\n",
            "         1.5437e+00,  5.3290e+00, -2.2809e-01,  4.8470e+00, -5.7811e+00,\n",
            "        -5.4851e+00,  4.3793e-01,  8.5323e-01, -2.1739e+00,  9.3978e-01,\n",
            "        -3.5079e+00, -1.4919e+00, -2.4169e+00,  3.5231e-01,  3.5086e-01,\n",
            "         1.2994e+00, -2.8455e+00, -2.8636e+00, -3.9293e+00,  2.1972e-01,\n",
            "        -9.5270e-01, -3.3202e+00,  2.6463e+00, -4.9297e+00, -6.9048e-01,\n",
            "         2.9326e-01, -5.8238e-01, -3.4690e+00,  1.6744e+00,  1.1338e+00,\n",
            "         6.4511e+00,  1.8403e+00, -1.0919e+00,  6.6625e+00, -3.1273e+00,\n",
            "        -6.3391e-03,  2.8352e+00, -3.0110e+00, -2.1479e+00,  6.3722e-01,\n",
            "        -5.6542e+00,  1.8021e+00, -5.2542e-01,  7.9315e+00,  2.0343e+00,\n",
            "         1.8550e+00,  1.4440e+00,  9.2769e-01,  2.0620e+00, -2.5095e+00,\n",
            "        -2.4934e+00,  3.6566e-01,  4.5085e-01,  1.6462e+00,  5.0526e-02,\n",
            "         1.1418e+00,  3.7637e+00, -1.2078e+00, -1.4722e+00,  5.3521e+00,\n",
            "        -2.7098e-01, -3.0648e-01,  6.6070e-01, -1.5574e+00, -1.9648e+00,\n",
            "        -5.7380e-01,  2.0052e+00, -5.1060e+00,  2.0800e+00,  1.0958e+00,\n",
            "         5.4020e-01,  1.1198e+00, -2.8130e-01,  7.2607e+00,  2.1646e+00,\n",
            "        -1.9186e-02, -1.1728e+00, -2.5225e+00, -4.1348e+00, -3.3227e+00,\n",
            "        -1.6391e+00, -7.6463e-01, -3.6698e+00])), ('module.encoder_q.layer2.3.bn1.running_var', tensor([11.1299, 13.8804, 17.8375,  9.1089, 12.9045,  7.7583, 14.2551, 15.5511,\n",
            "         6.3169, 21.5482, 11.8144, 11.9934, 10.9076, 17.0717, 11.0216,  9.9797,\n",
            "         8.3007, 12.4524, 32.9789, 17.4168, 10.9570, 11.7348, 11.8358,  8.1891,\n",
            "        17.9361, 19.4188,  8.5956, 17.7085, 15.6626, 11.2494,  7.9770, 10.2803,\n",
            "        11.0058,  8.2008,  8.6816, 12.2603, 16.6616, 16.0656,  9.5298, 15.2894,\n",
            "         9.8715,  9.2157, 13.3621, 13.9712, 24.7913, 18.4286, 31.7019,  8.1439,\n",
            "        11.2341, 27.0570, 10.8108, 16.2797, 15.2771, 10.1988,  7.7850, 10.8762,\n",
            "         9.0741,  7.9913,  8.1448, 10.9935, 17.3931, 19.0757, 13.4919, 12.4818,\n",
            "        11.1093, 11.9991, 15.1973, 20.6826, 24.7517, 17.1902,  8.9014,  8.0964,\n",
            "        10.6566, 13.4386, 11.5080, 36.9349, 13.2140, 14.7981, 52.8141,  8.6962,\n",
            "         7.5863, 26.8118, 14.2414, 20.5902,  9.8820, 17.8498,  9.5557,  8.5323,\n",
            "        66.5810, 13.3459, 15.4320, 14.4351, 13.0864, 17.9523,  8.8732, 10.5684,\n",
            "        15.3984, 10.1669, 12.4631, 13.9772,  8.9034, 24.7321, 12.9441,  9.7923,\n",
            "        21.9613, 16.2073, 11.4141,  8.8050, 22.3325, 13.8419, 10.5343, 10.6661,\n",
            "        15.9213, 13.9025,  9.0990,  8.7362, 10.9111,  9.4583, 24.4820,  7.1107,\n",
            "        10.4245,  9.0825, 28.0490, 19.8342, 10.2675,  9.0583,  9.7894, 15.2898])), ('module.encoder_q.layer2.3.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.3.conv2.weight', tensor([[[[-3.3131e-02, -6.3167e-02, -4.0613e-02],\n",
            "          [-8.1107e-02, -2.3174e-02, -2.5541e-02],\n",
            "          [-8.5656e-02,  3.2317e-02, -4.0000e-02]],\n",
            "\n",
            "         [[ 1.7484e-02, -2.7256e-02, -2.0829e-02],\n",
            "          [-3.4751e-02,  4.0028e-03, -1.4731e-02],\n",
            "          [ 1.4676e-02, -2.3370e-02, -7.5059e-02]],\n",
            "\n",
            "         [[-8.1303e-02,  4.4937e-02, -1.1746e-01],\n",
            "          [ 6.1374e-02,  4.2553e-03, -3.3772e-02],\n",
            "          [ 2.6359e-02,  3.6393e-02,  2.3341e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8057e-02, -1.9586e-02, -1.5485e-02],\n",
            "          [ 1.8434e-02, -3.2212e-03,  1.9315e-02],\n",
            "          [ 1.7946e-02,  5.0820e-02, -3.8234e-04]],\n",
            "\n",
            "         [[-2.6061e-02, -2.6287e-02,  9.5633e-02],\n",
            "          [ 6.8732e-02,  1.0976e-01, -3.2099e-02],\n",
            "          [-9.1238e-03,  3.0589e-02,  1.8438e-02]],\n",
            "\n",
            "         [[ 1.1854e-02,  2.1416e-02,  1.4330e-01],\n",
            "          [ 8.1954e-02,  2.9516e-02,  3.7058e-02],\n",
            "          [ 4.7190e-02,  5.1146e-02, -3.8983e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2298e-02,  1.0188e-02, -1.0168e-02],\n",
            "          [-4.8658e-02,  8.5004e-02, -5.2319e-03],\n",
            "          [ 2.2438e-02,  4.9714e-02, -2.4256e-02]],\n",
            "\n",
            "         [[-9.5115e-03, -6.1502e-02,  4.1198e-02],\n",
            "          [ 3.5915e-02, -2.7503e-02, -1.0908e-02],\n",
            "          [-3.9543e-03, -1.0060e-03, -1.9369e-02]],\n",
            "\n",
            "         [[-4.4610e-02, -4.0302e-02,  2.6556e-02],\n",
            "          [ 1.4351e-02,  6.0984e-02, -6.6210e-03],\n",
            "          [-5.2637e-02, -2.1911e-02,  4.6395e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2404e-03,  2.1691e-02,  2.8305e-04],\n",
            "          [ 3.8051e-03,  6.7715e-02,  6.0591e-02],\n",
            "          [ 4.6078e-02, -6.2604e-02, -3.6326e-02]],\n",
            "\n",
            "         [[-7.0376e-02, -3.7249e-02, -2.1901e-02],\n",
            "          [-1.7410e-02,  6.2158e-03, -2.9444e-02],\n",
            "          [-2.1458e-02,  4.0078e-02,  2.9463e-03]],\n",
            "\n",
            "         [[ 4.6733e-02, -1.2925e-02,  7.0796e-02],\n",
            "          [-9.8242e-03, -1.2667e-02, -3.6067e-02],\n",
            "          [-1.4001e-02,  1.9684e-02,  7.7030e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9151e-02, -1.2523e-03,  3.9976e-02],\n",
            "          [-5.1733e-02, -1.0531e-02, -4.1000e-02],\n",
            "          [ 2.7246e-02, -2.3029e-02,  2.2569e-02]],\n",
            "\n",
            "         [[ 3.6105e-02,  1.1861e-03,  3.6388e-02],\n",
            "          [ 3.9673e-02,  5.1091e-02,  1.5555e-02],\n",
            "          [-6.0738e-03,  1.4719e-02, -4.5803e-02]],\n",
            "\n",
            "         [[-5.2505e-02,  9.4253e-03, -1.7759e-02],\n",
            "          [-5.8233e-03, -1.0563e-02, -1.3830e-03],\n",
            "          [-2.3383e-02, -2.5501e-02,  8.4584e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.4716e-02,  1.5004e-02,  1.7625e-02],\n",
            "          [-4.6408e-02,  5.0424e-02, -3.2237e-02],\n",
            "          [ 3.1609e-03,  1.2347e-02, -2.3584e-02]],\n",
            "\n",
            "         [[ 3.3531e-03, -4.0817e-02, -2.6115e-02],\n",
            "          [ 8.9996e-02, -2.1780e-02,  3.2231e-02],\n",
            "          [-3.0379e-02,  7.4418e-02, -6.6362e-02]],\n",
            "\n",
            "         [[-1.3953e-02,  2.5767e-02, -5.1298e-03],\n",
            "          [-1.9246e-02, -2.3022e-02,  2.7531e-02],\n",
            "          [-4.2609e-02, -2.5393e-02,  3.6164e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 7.5424e-04,  8.2918e-02,  4.5190e-02],\n",
            "          [-9.1673e-02,  4.5243e-02,  1.4415e-02],\n",
            "          [ 1.9557e-02, -1.6259e-02, -5.1363e-02]],\n",
            "\n",
            "         [[-1.1962e-02,  3.9355e-02,  1.8498e-02],\n",
            "          [-3.5387e-02,  5.6685e-02,  8.8048e-02],\n",
            "          [ 1.8091e-02, -8.5821e-02,  5.7106e-03]],\n",
            "\n",
            "         [[-1.1247e-02, -1.8037e-02,  3.4278e-03],\n",
            "          [ 3.1275e-02,  1.5180e-02,  1.6169e-02],\n",
            "          [-1.0753e-02, -4.6691e-02,  1.1008e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.3037e-03, -1.0547e-01, -4.0506e-02],\n",
            "          [-2.4685e-02, -6.6570e-02,  2.7177e-03],\n",
            "          [-1.0365e-02, -9.0738e-02, -5.2594e-02]],\n",
            "\n",
            "         [[ 4.9950e-02,  1.8578e-03,  6.8606e-02],\n",
            "          [ 2.3408e-03,  3.4203e-03,  1.3700e-02],\n",
            "          [-1.4655e-02,  4.0145e-02, -3.1946e-02]],\n",
            "\n",
            "         [[-2.8609e-02, -3.4680e-02, -4.0443e-02],\n",
            "          [ 3.4743e-02, -7.5917e-02, -3.9772e-03],\n",
            "          [ 5.3518e-02,  7.7554e-02,  6.6804e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.8428e-02, -4.4697e-02,  6.4170e-02],\n",
            "          [ 9.2302e-02, -7.0899e-03,  2.1371e-02],\n",
            "          [ 8.6800e-03, -6.4066e-02,  1.2232e-01]],\n",
            "\n",
            "         [[-5.2176e-03, -5.5326e-02, -3.3890e-02],\n",
            "          [-2.9486e-02, -2.6306e-02, -2.5210e-03],\n",
            "          [ 1.9777e-03,  5.4770e-02,  8.0591e-03]],\n",
            "\n",
            "         [[-5.4611e-02,  1.1760e-02,  3.9944e-03],\n",
            "          [ 4.3831e-02,  1.2607e-02, -2.0915e-02],\n",
            "          [-3.7542e-02,  5.6181e-02, -3.3690e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1488e-02, -5.7570e-02, -4.1021e-02],\n",
            "          [ 3.7078e-02, -3.1086e-02, -5.9855e-02],\n",
            "          [ 2.0218e-02, -1.8357e-02,  1.0263e-01]],\n",
            "\n",
            "         [[-1.0153e-02,  2.9034e-02, -1.4055e-02],\n",
            "          [ 6.9629e-02,  2.2174e-02,  1.8117e-03],\n",
            "          [ 4.4686e-02,  3.6011e-02, -9.3123e-02]],\n",
            "\n",
            "         [[-1.2976e-02, -1.8562e-02, -5.6478e-02],\n",
            "          [-3.0715e-02,  1.7322e-02,  6.1848e-02],\n",
            "          [-9.2573e-03, -3.6176e-03,  2.0579e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.0618e-04, -2.4192e-02, -1.3562e-02],\n",
            "          [ 6.8595e-03, -1.9629e-02, -3.8591e-02],\n",
            "          [ 2.6610e-02, -2.1794e-03, -1.4419e-02]],\n",
            "\n",
            "         [[ 2.9429e-02, -1.5894e-02, -2.9629e-02],\n",
            "          [-5.1909e-02,  1.2775e-02,  2.9335e-02],\n",
            "          [ 6.3896e-02, -2.5451e-02, -2.1692e-02]],\n",
            "\n",
            "         [[ 8.7660e-02, -2.8019e-02,  3.0326e-02],\n",
            "          [ 5.1426e-03,  1.1705e-02, -2.3750e-02],\n",
            "          [ 6.9008e-03,  3.9281e-02,  2.3106e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2141e-02,  2.3408e-02, -4.0679e-02],\n",
            "          [ 3.8027e-03,  9.4813e-03, -1.8692e-02],\n",
            "          [-4.6369e-02, -2.7433e-02, -1.8393e-02]],\n",
            "\n",
            "         [[ 5.6343e-02,  5.3663e-02, -6.2488e-02],\n",
            "          [ 2.4434e-02,  8.4685e-03,  5.8431e-02],\n",
            "          [-7.9033e-02, -2.4973e-02,  2.9173e-02]],\n",
            "\n",
            "         [[-3.8880e-02, -3.1020e-02, -5.6997e-02],\n",
            "          [-2.5608e-02, -1.3754e-02, -2.1273e-02],\n",
            "          [ 5.9534e-02, -2.6983e-03,  3.4536e-02]]]])), ('module.encoder_q.layer2.3.bn2.weight', tensor([0.9916, 0.9914, 0.9921, 0.9916, 0.9922, 0.9916, 0.9931, 0.9888, 0.9923,\n",
            "        0.9915, 0.9899, 0.9903, 0.9927, 0.9933, 0.9911, 0.9958, 0.9920, 0.9914,\n",
            "        0.9930, 0.9926, 0.9940, 0.9951, 0.9932, 0.9918, 0.9920, 0.9907, 0.9927,\n",
            "        0.9929, 0.9940, 0.9943, 0.9915, 0.9920, 0.9930, 0.9925, 0.9910, 0.9899,\n",
            "        0.9907, 0.9921, 0.9916, 0.9940, 0.9901, 0.9917, 0.9929, 0.9936, 0.9936,\n",
            "        0.9917, 0.9912, 0.9938, 0.9936, 0.9894, 0.9921, 0.9914, 0.9942, 0.9929,\n",
            "        0.9926, 0.9903, 0.9899, 0.9922, 0.9921, 0.9938, 0.9926, 0.9934, 0.9931,\n",
            "        0.9926, 0.9921, 0.9939, 0.9947, 0.9897, 0.9931, 0.9929, 0.9936, 0.9945,\n",
            "        0.9914, 0.9869, 0.9934, 0.9900, 0.9940, 0.9920, 0.9936, 0.9940, 0.9916,\n",
            "        0.9906, 0.9961, 0.9904, 0.9957, 0.9912, 0.9941, 0.9915, 0.9907, 0.9915,\n",
            "        0.9906, 0.9923, 0.9907, 0.9927, 0.9904, 0.9913, 0.9944, 0.9928, 0.9920,\n",
            "        0.9936, 0.9917, 0.9929, 0.9907, 0.9923, 0.9914, 0.9923, 0.9923, 0.9933,\n",
            "        0.9901, 0.9915, 0.9920, 0.9921, 0.9952, 0.9957, 0.9939, 0.9889, 0.9919,\n",
            "        0.9923, 0.9915, 0.9901, 0.9951, 0.9916, 0.9930, 0.9910, 0.9923, 0.9927,\n",
            "        0.9931, 0.9920])), ('module.encoder_q.layer2.3.bn2.bias', tensor([ 9.3280e-05,  8.2315e-04, -1.8670e-03, -9.2026e-04,  1.7046e-03,\n",
            "        -3.2641e-04,  6.1187e-04, -1.5681e-03,  2.0615e-04,  1.2251e-03,\n",
            "        -4.2434e-04, -7.6487e-04, -7.9088e-04, -7.8070e-04,  5.3370e-04,\n",
            "         2.2342e-03, -1.5273e-03, -2.1163e-03,  3.9393e-04,  9.3451e-04,\n",
            "         2.0377e-03,  1.7408e-03,  2.0354e-03,  2.1008e-03, -7.0260e-04,\n",
            "        -2.0064e-03,  2.5314e-03,  4.0534e-04,  1.2723e-03,  1.6901e-04,\n",
            "        -2.2265e-03, -1.2344e-04,  2.7303e-03,  9.0028e-04, -3.0949e-03,\n",
            "        -5.2338e-04, -3.3886e-03, -3.0494e-04, -7.2747e-05,  1.6052e-03,\n",
            "        -1.8084e-03, -1.0005e-03, -1.7591e-03, -2.3354e-04, -6.0336e-04,\n",
            "         7.5752e-04,  1.5394e-03,  1.4882e-03,  2.7672e-04, -7.9703e-04,\n",
            "        -1.2722e-03,  3.9285e-04, -2.0917e-04,  1.2603e-03, -2.9012e-04,\n",
            "         2.1579e-03, -2.9055e-03,  3.4989e-04,  4.9779e-04, -2.2147e-04,\n",
            "        -2.1769e-04,  2.0534e-03,  1.2547e-03,  7.7953e-04, -2.1962e-04,\n",
            "         2.8660e-03,  1.0109e-03, -4.0694e-03,  1.7642e-03,  1.8944e-03,\n",
            "         2.0631e-03,  2.5153e-03,  1.6311e-03, -2.5651e-03, -8.3098e-05,\n",
            "         6.5615e-04,  1.5737e-03,  1.6171e-03,  2.4434e-03,  6.8366e-04,\n",
            "        -1.7983e-03, -1.9157e-03,  3.3536e-03, -4.8401e-04,  4.7696e-04,\n",
            "        -1.1701e-03, -2.8919e-04, -3.4159e-04,  1.8460e-04, -2.2040e-03,\n",
            "        -2.1380e-03, -2.8395e-04, -1.6090e-03,  1.0303e-03, -1.4341e-03,\n",
            "        -1.1324e-03, -4.2541e-04,  1.3382e-03,  7.0935e-04, -5.8264e-04,\n",
            "         1.2011e-03,  1.6898e-03, -1.9952e-03,  1.0619e-03, -6.3832e-04,\n",
            "        -1.1703e-03, -1.9512e-03, -1.6431e-04, -8.6662e-04, -2.6974e-04,\n",
            "         9.5464e-04, -4.7529e-04,  2.8719e-03,  1.6439e-03,  3.6868e-03,\n",
            "        -1.5765e-03, -3.3218e-04,  1.2262e-03, -1.9747e-03, -1.3639e-03,\n",
            "         1.5410e-03,  2.8714e-04,  3.6008e-04,  1.5974e-03, -6.0772e-04,\n",
            "         2.0906e-03,  1.0681e-03, -6.5329e-05])), ('module.encoder_q.layer2.3.bn2.running_mean', tensor([ 0.5272,  0.5126,  1.4731, -0.1380,  0.5676, -0.3409,  0.4192,  0.3020,\n",
            "        -0.0076,  0.4585,  1.2640, -0.4186, -0.0690, -0.0956, -0.2634, -0.2535,\n",
            "         0.5878, -0.0755,  0.6292, -0.4778,  0.6006,  0.4540,  0.0056,  0.4885,\n",
            "         1.2982,  0.6799,  0.0689,  0.1970,  0.2551,  0.4148, -0.8241,  0.3772,\n",
            "        -0.1452, -0.7405, -0.1424, -0.3241, -0.9531,  0.5085, -1.0481,  0.5812,\n",
            "        -0.0487, -0.8504,  0.3246, -0.9938,  0.8438,  0.4555,  0.4250,  0.3452,\n",
            "        -0.2980, -0.1228,  0.0665,  0.2103, -0.1627, -0.7701,  0.6319,  1.3566,\n",
            "        -0.2480,  0.2421, -0.0918, -0.2962,  0.1733, -0.1486,  0.1963,  0.1991,\n",
            "        -0.0661, -0.1719,  0.2227,  0.8830,  0.3981, -0.6057,  0.2137,  0.5869,\n",
            "         0.1726, -0.6165,  0.2278, -0.4210,  0.0256, -0.3880, -0.2331, -0.2187,\n",
            "        -0.3405, -0.1845, -0.2883, -0.0246,  0.7205,  0.7027,  0.4885, -0.1717,\n",
            "         0.4203, -0.1175,  0.2892,  0.6953, -0.6068,  0.1260,  1.0759, -0.5347,\n",
            "        -0.9594,  0.1007,  0.1370,  0.4429,  0.3403, -0.5743, -0.3542, -0.2882,\n",
            "        -0.3298,  0.1006,  0.3412, -0.1956,  0.6938,  0.1542,  0.6060, -1.1645,\n",
            "         0.1030,  1.1313, -0.7307,  0.5779, -0.8462, -0.0706, -0.6748,  0.4971,\n",
            "         0.5480, -0.7221, -0.6409,  0.0988,  0.9703,  0.1495, -0.3549, -0.9813])), ('module.encoder_q.layer2.3.bn2.running_var', tensor([0.8622, 0.6924, 1.6677, 0.6377, 0.8937, 0.4652, 0.5244, 0.6020, 0.5313,\n",
            "        1.0910, 0.8848, 0.5509, 0.6844, 0.4939, 0.6790, 0.8158, 0.4730, 0.6676,\n",
            "        0.6076, 0.4631, 0.6361, 0.7272, 0.7791, 0.6466, 1.6392, 1.4138, 1.0343,\n",
            "        0.4675, 0.7771, 0.9421, 1.5987, 1.2399, 1.1538, 0.7519, 0.5760, 0.8397,\n",
            "        1.7501, 0.7052, 0.9603, 0.4640, 0.6657, 0.7030, 0.9087, 1.1345, 0.5063,\n",
            "        0.7798, 0.6220, 0.5757, 1.0613, 0.5695, 0.7812, 0.8907, 0.3957, 0.9557,\n",
            "        0.6861, 0.8482, 0.5297, 0.8549, 0.4844, 1.0482, 1.2451, 0.5219, 0.4570,\n",
            "        0.5022, 0.7497, 0.7293, 0.6943, 0.7407, 0.5712, 0.8434, 0.7219, 0.9519,\n",
            "        0.5798, 0.7408, 1.5528, 0.4649, 0.4820, 1.0540, 0.6268, 0.8628, 0.8171,\n",
            "        0.6611, 0.6599, 0.4904, 2.8721, 0.4936, 1.0784, 0.7584, 0.8731, 0.5687,\n",
            "        0.7841, 1.0052, 1.2118, 0.7145, 1.7948, 0.7762, 0.8903, 0.8432, 0.5143,\n",
            "        0.5684, 1.1531, 0.6767, 0.7279, 0.5605, 0.5159, 1.1638, 0.5713, 0.6946,\n",
            "        0.5897, 0.8732, 0.9175, 1.6101, 0.5173, 1.3235, 1.3946, 0.7724, 0.5816,\n",
            "        0.7572, 0.8342, 0.7029, 1.0359, 0.6812, 0.6469, 1.5290, 0.5901, 0.5393,\n",
            "        0.5827, 0.6371])), ('module.encoder_q.layer2.3.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer2.3.conv3.weight', tensor([[[[-0.0448]],\n",
            "\n",
            "         [[ 0.0194]],\n",
            "\n",
            "         [[ 0.0711]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1010]],\n",
            "\n",
            "         [[-0.0709]],\n",
            "\n",
            "         [[ 0.0573]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0239]],\n",
            "\n",
            "         [[ 0.0830]],\n",
            "\n",
            "         [[-0.1602]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0965]],\n",
            "\n",
            "         [[-0.0035]]],\n",
            "\n",
            "\n",
            "        [[[-0.0948]],\n",
            "\n",
            "         [[-0.0101]],\n",
            "\n",
            "         [[ 0.0066]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0298]],\n",
            "\n",
            "         [[ 0.0208]],\n",
            "\n",
            "         [[ 0.1141]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0649]],\n",
            "\n",
            "         [[-0.0277]],\n",
            "\n",
            "         [[ 0.0731]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0191]],\n",
            "\n",
            "         [[ 0.0405]],\n",
            "\n",
            "         [[ 0.0839]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0987]],\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[ 0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0452]],\n",
            "\n",
            "         [[ 0.0856]],\n",
            "\n",
            "         [[-0.0304]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0318]],\n",
            "\n",
            "         [[ 0.0202]],\n",
            "\n",
            "         [[ 0.0768]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1218]],\n",
            "\n",
            "         [[-0.0768]],\n",
            "\n",
            "         [[-0.0072]]]])), ('module.encoder_q.layer2.3.bn3.weight', tensor([0.9916, 0.9920, 0.9911, 0.9908, 0.9916, 0.9920, 0.9917, 0.9924, 0.9925,\n",
            "        0.9924, 0.9934, 0.9920, 0.9911, 0.9926, 0.9912, 0.9925, 0.9915, 0.9911,\n",
            "        0.9922, 0.9925, 0.9913, 0.9934, 0.9915, 0.9928, 0.9914, 0.9927, 0.9929,\n",
            "        0.9931, 0.9925, 0.9929, 0.9920, 0.9927, 0.9928, 0.9943, 0.9915, 0.9923,\n",
            "        0.9903, 0.9917, 0.9931, 0.9919, 0.9925, 0.9936, 0.9932, 0.9920, 0.9917,\n",
            "        0.9913, 0.9932, 0.9909, 0.9936, 0.9921, 0.9939, 0.9914, 0.9926, 0.9922,\n",
            "        0.9916, 0.9924, 0.9926, 0.9922, 0.9922, 0.9930, 0.9920, 0.9918, 0.9925,\n",
            "        0.9928, 0.9908, 0.9923, 0.9914, 0.9928, 0.9911, 0.9915, 0.9913, 0.9926,\n",
            "        0.9938, 0.9928, 0.9927, 0.9925, 0.9919, 0.9920, 0.9931, 0.9923, 0.9918,\n",
            "        0.9924, 0.9908, 0.9927, 0.9931, 0.9924, 0.9920, 0.9920, 0.9920, 0.9920,\n",
            "        0.9923, 0.9931, 0.9931, 0.9917, 0.9918, 0.9925, 0.9926, 0.9911, 0.9923,\n",
            "        0.9925, 0.9913, 0.9921, 0.9918, 0.9930, 0.9923, 0.9912, 0.9925, 0.9918,\n",
            "        0.9925, 0.9903, 0.9917, 0.9923, 0.9928, 0.9934, 0.9928, 0.9924, 0.9925,\n",
            "        0.9912, 0.9924, 0.9929, 0.9917, 0.9913, 0.9917, 0.9931, 0.9931, 0.9920,\n",
            "        0.9925, 0.9925, 0.9924, 0.9919, 0.9920, 0.9927, 0.9922, 0.9918, 0.9925,\n",
            "        0.9925, 0.9913, 0.9926, 0.9920, 0.9928, 0.9926, 0.9915, 0.9924, 0.9929,\n",
            "        0.9920, 0.9921, 0.9928, 0.9914, 0.9935, 0.9906, 0.9920, 0.9924, 0.9931,\n",
            "        0.9924, 0.9922, 0.9927, 0.9927, 0.9913, 0.9921, 0.9921, 0.9918, 0.9913,\n",
            "        0.9926, 0.9930, 0.9923, 0.9919, 0.9923, 0.9921, 0.9926, 0.9932, 0.9931,\n",
            "        0.9915, 0.9932, 0.9919, 0.9926, 0.9915, 0.9923, 0.9927, 0.9924, 0.9923,\n",
            "        0.9914, 0.9919, 0.9928, 0.9924, 0.9921, 0.9912, 0.9916, 0.9927, 0.9912,\n",
            "        0.9923, 0.9931, 0.9912, 0.9903, 0.9916, 0.9923, 0.9922, 0.9934, 0.9922,\n",
            "        0.9921, 0.9916, 0.9919, 0.9922, 0.9935, 0.9924, 0.9925, 0.9926, 0.9918,\n",
            "        0.9918, 0.9916, 0.9907, 0.9917, 0.9915, 0.9933, 0.9918, 0.9924, 0.9924,\n",
            "        0.9919, 0.9930, 0.9931, 0.9915, 0.9923, 0.9926, 0.9940, 0.9919, 0.9921,\n",
            "        0.9918, 0.9914, 0.9914, 0.9927, 0.9932, 0.9916, 0.9925, 0.9923, 0.9918,\n",
            "        0.9916, 0.9933, 0.9921, 0.9920, 0.9928, 0.9920, 0.9928, 0.9918, 0.9921,\n",
            "        0.9925, 0.9926, 0.9911, 0.9912, 0.9914, 0.9923, 0.9927, 0.9931, 0.9923,\n",
            "        0.9924, 0.9918, 0.9924, 0.9928, 0.9914, 0.9913, 0.9929, 0.9924, 0.9931,\n",
            "        0.9925, 0.9924, 0.9924, 0.9923, 0.9927, 0.9925, 0.9928, 0.9910, 0.9924,\n",
            "        0.9915, 0.9938, 0.9922, 0.9928, 0.9930, 0.9911, 0.9927, 0.9925, 0.9922,\n",
            "        0.9932, 0.9925, 0.9919, 0.9924, 0.9918, 0.9927, 0.9926, 0.9930, 0.9923,\n",
            "        0.9914, 0.9924, 0.9928, 0.9926, 0.9928, 0.9924, 0.9927, 0.9917, 0.9921,\n",
            "        0.9918, 0.9925, 0.9928, 0.9905, 0.9921, 0.9923, 0.9909, 0.9919, 0.9927,\n",
            "        0.9919, 0.9919, 0.9931, 0.9920, 0.9920, 0.9915, 0.9923, 0.9930, 0.9911,\n",
            "        0.9921, 0.9921, 0.9922, 0.9928, 0.9925, 0.9930, 0.9930, 0.9926, 0.9914,\n",
            "        0.9927, 0.9937, 0.9914, 0.9926, 0.9932, 0.9914, 0.9919, 0.9914, 0.9926,\n",
            "        0.9925, 0.9923, 0.9926, 0.9935, 0.9926, 0.9925, 0.9925, 0.9931, 0.9914,\n",
            "        0.9922, 0.9931, 0.9932, 0.9923, 0.9918, 0.9927, 0.9912, 0.9918, 0.9926,\n",
            "        0.9913, 0.9931, 0.9926, 0.9924, 0.9927, 0.9918, 0.9914, 0.9915, 0.9926,\n",
            "        0.9921, 0.9914, 0.9921, 0.9919, 0.9922, 0.9919, 0.9930, 0.9929, 0.9920,\n",
            "        0.9930, 0.9927, 0.9946, 0.9937, 0.9931, 0.9916, 0.9922, 0.9920, 0.9918,\n",
            "        0.9914, 0.9939, 0.9920, 0.9923, 0.9931, 0.9922, 0.9916, 0.9921, 0.9916,\n",
            "        0.9923, 0.9913, 0.9925, 0.9907, 0.9923, 0.9926, 0.9926, 0.9930, 0.9936,\n",
            "        0.9919, 0.9929, 0.9920, 0.9913, 0.9921, 0.9919, 0.9929, 0.9922, 0.9927,\n",
            "        0.9918, 0.9940, 0.9915, 0.9915, 0.9924, 0.9929, 0.9928, 0.9925, 0.9923,\n",
            "        0.9926, 0.9925, 0.9924, 0.9922, 0.9923, 0.9902, 0.9914, 0.9921, 0.9918,\n",
            "        0.9917, 0.9923, 0.9922, 0.9920, 0.9918, 0.9930, 0.9919, 0.9912, 0.9918,\n",
            "        0.9930, 0.9917, 0.9924, 0.9920, 0.9913, 0.9925, 0.9924, 0.9929, 0.9923,\n",
            "        0.9924, 0.9927, 0.9927, 0.9917, 0.9928, 0.9922, 0.9923, 0.9922, 0.9915,\n",
            "        0.9916, 0.9924, 0.9925, 0.9915, 0.9919, 0.9928, 0.9918, 0.9933, 0.9922,\n",
            "        0.9906, 0.9938, 0.9920, 0.9928, 0.9915, 0.9924, 0.9930, 0.9923, 0.9924,\n",
            "        0.9929, 0.9937, 0.9924, 0.9916, 0.9920, 0.9925, 0.9926, 0.9917, 0.9925,\n",
            "        0.9922, 0.9924, 0.9908, 0.9929, 0.9916, 0.9934, 0.9930, 0.9924, 0.9925,\n",
            "        0.9918, 0.9933, 0.9926, 0.9923, 0.9928, 0.9937, 0.9918, 0.9922, 0.9915,\n",
            "        0.9923, 0.9927, 0.9926, 0.9932, 0.9931, 0.9932, 0.9923, 0.9916, 0.9913,\n",
            "        0.9931, 0.9931, 0.9923, 0.9931, 0.9907, 0.9917, 0.9916, 0.9934])), ('module.encoder_q.layer2.3.bn3.bias', tensor([-1.9431e-04,  7.1358e-05,  3.5972e-04, -4.8319e-04,  1.9389e-04,\n",
            "         1.0161e-03, -3.6520e-04, -3.7566e-05,  1.4354e-04, -2.3885e-04,\n",
            "         1.0090e-04,  4.4689e-04, -1.4769e-04, -3.3679e-04, -8.1335e-04,\n",
            "         4.4357e-04,  7.7796e-05, -2.3137e-04,  2.1435e-04,  6.5150e-07,\n",
            "         1.9835e-04, -1.9231e-04, -5.0848e-04, -2.9852e-04, -1.7164e-04,\n",
            "         9.2082e-04, -4.9995e-04,  6.0007e-04, -1.5120e-04,  1.2557e-04,\n",
            "         5.2185e-06,  1.2600e-04, -9.7507e-05, -2.7917e-04,  7.3292e-04,\n",
            "         4.9564e-04,  3.5945e-04,  2.2460e-04,  5.7696e-05,  2.1402e-04,\n",
            "         5.3686e-04,  2.6304e-04,  1.8047e-04, -4.1229e-04,  5.8774e-04,\n",
            "        -7.8028e-04, -2.9743e-04,  4.1390e-04,  3.8345e-04, -1.8661e-04,\n",
            "         5.8702e-04, -7.7451e-04,  1.7604e-04, -6.3320e-04, -5.5231e-04,\n",
            "         3.0849e-04, -1.9309e-04, -8.7414e-04,  7.1681e-04, -1.6937e-04,\n",
            "        -3.7558e-04, -2.1980e-04,  7.3982e-04,  7.3247e-04, -2.3991e-04,\n",
            "        -5.1804e-04, -1.6396e-04,  2.0847e-04,  6.5493e-04,  1.5724e-04,\n",
            "         2.3824e-04, -5.9865e-04, -2.4515e-04, -4.9495e-04,  7.1134e-04,\n",
            "         1.2727e-04, -1.0339e-04, -1.0406e-05,  4.4269e-04,  1.2098e-03,\n",
            "         1.1812e-04,  1.8329e-04, -6.1468e-04,  7.2310e-04,  1.3040e-04,\n",
            "         4.1323e-05, -2.6932e-04,  5.1112e-04,  1.2462e-03,  1.3204e-03,\n",
            "        -1.1649e-03, -7.1325e-04,  8.2959e-05, -3.9526e-04, -5.8309e-04,\n",
            "         8.2667e-05,  7.1518e-04, -4.7846e-04,  3.6493e-04, -3.0450e-06,\n",
            "         5.3399e-04,  6.4055e-04, -2.4431e-04, -4.1495e-04,  9.3962e-04,\n",
            "        -3.5955e-04,  5.9969e-04, -2.5863e-04,  2.4430e-04,  4.1999e-05,\n",
            "        -1.9024e-04,  1.1275e-03,  1.3802e-04,  3.1397e-04,  4.6512e-04,\n",
            "        -3.6606e-05, -7.8106e-05, -1.7806e-04, -1.8519e-04, -7.8339e-04,\n",
            "         7.8414e-04, -5.0883e-06,  2.1393e-04, -4.2748e-04, -5.6564e-05,\n",
            "        -6.2720e-04,  5.9863e-04,  1.5809e-04,  3.0058e-05, -1.9573e-04,\n",
            "         7.2490e-04, -2.2118e-04,  1.2709e-04, -4.0354e-05,  3.3455e-04,\n",
            "         2.4732e-04, -7.8517e-04, -2.1806e-04, -3.2054e-04,  7.2353e-04,\n",
            "        -4.6711e-04,  1.7056e-05,  7.1607e-04,  4.3549e-04, -8.8124e-04,\n",
            "        -7.1983e-04, -3.6598e-04, -4.5558e-04,  7.1222e-04, -8.0574e-04,\n",
            "         4.4574e-04,  4.6312e-04,  6.9930e-05, -2.9985e-04, -1.1874e-04,\n",
            "         4.4423e-04, -5.0599e-04,  3.4664e-05, -6.1023e-04, -4.0053e-04,\n",
            "         4.1156e-05,  3.7459e-05,  4.5913e-04,  1.4202e-04, -1.2179e-04,\n",
            "         1.2761e-05,  5.3988e-04,  6.4965e-04,  6.3987e-04,  9.4906e-05,\n",
            "         6.9693e-04,  8.6186e-04,  8.9543e-05, -4.3679e-04, -7.9997e-05,\n",
            "        -9.9750e-04,  2.2175e-06,  1.4261e-04, -4.8467e-04, -2.1682e-04,\n",
            "        -3.7906e-04,  6.6799e-04, -4.5200e-04, -4.2057e-05,  4.4625e-05,\n",
            "        -4.1256e-04,  8.6061e-05,  6.0548e-04, -6.1885e-04, -4.8561e-04,\n",
            "        -8.4058e-04, -5.7163e-04, -4.4526e-04, -2.9465e-04,  1.3696e-03,\n",
            "        -5.1406e-04, -2.9428e-04,  1.5951e-04,  1.9923e-04,  9.8420e-05,\n",
            "        -3.0534e-04, -2.7298e-04,  3.5670e-04, -1.3118e-03, -3.3376e-04,\n",
            "        -6.1011e-05, -2.2174e-04,  1.8492e-04,  3.6413e-04,  9.8251e-05,\n",
            "         2.9724e-04,  7.0129e-04,  7.0451e-05, -1.0449e-03, -6.8562e-05,\n",
            "        -6.7519e-04,  1.4973e-04, -1.8858e-04, -6.8731e-05, -7.9537e-05,\n",
            "        -4.5154e-04,  1.2399e-04,  9.7904e-04, -2.5989e-05,  1.2009e-04,\n",
            "         3.5071e-04, -1.7217e-05,  2.0436e-04,  3.4877e-04, -6.5362e-05,\n",
            "        -2.9348e-05,  1.0250e-03, -5.8662e-04,  1.4788e-04, -4.4505e-04,\n",
            "        -1.1287e-04, -1.1250e-04, -4.5727e-04, -9.1914e-05,  3.3484e-04,\n",
            "        -5.7163e-05,  1.3680e-04,  1.2019e-04,  3.1341e-04,  5.0104e-04,\n",
            "        -5.1841e-04, -2.7333e-04,  4.2080e-05,  5.6238e-04, -5.3246e-04,\n",
            "         6.1703e-04, -5.2966e-04, -7.1814e-04,  9.5033e-04, -6.0315e-04,\n",
            "         3.1601e-04, -2.3956e-04, -6.6244e-04,  1.2672e-04,  3.5884e-04,\n",
            "         7.6694e-04,  5.4607e-04,  2.8696e-04,  1.7578e-04, -1.9111e-05,\n",
            "        -1.0305e-03, -2.4051e-04,  1.3139e-04, -1.5605e-04,  7.3305e-05,\n",
            "         5.7782e-04, -1.4324e-04, -4.0078e-04,  8.3913e-04,  8.0045e-04,\n",
            "        -2.7563e-04, -1.9594e-04, -4.4210e-04, -1.5832e-04,  8.9455e-04,\n",
            "        -3.0149e-04, -4.1993e-04, -2.2014e-04, -1.4700e-04, -6.5097e-06,\n",
            "        -2.5126e-04, -1.4448e-04, -1.5702e-03,  8.3974e-05,  3.8948e-04,\n",
            "        -5.4096e-04, -4.4313e-05,  1.5365e-04,  3.2122e-04,  2.6883e-04,\n",
            "        -4.0434e-04, -5.7023e-04, -6.6723e-04,  7.4026e-05,  2.7182e-04,\n",
            "         2.2228e-05,  4.4007e-04,  9.2375e-04, -5.3712e-04,  1.1982e-03,\n",
            "         4.8260e-04,  2.3163e-04, -5.4730e-04, -2.5119e-04, -1.7891e-04,\n",
            "         1.0620e-04,  6.5536e-04,  2.7828e-04,  3.6826e-05, -4.1225e-04,\n",
            "        -2.7266e-04, -3.2659e-05,  4.0570e-04,  1.6262e-04, -8.5656e-04,\n",
            "         7.3657e-04, -2.3112e-04, -6.7291e-04,  5.7559e-04,  6.7399e-04,\n",
            "         8.3698e-05, -3.5057e-04, -4.4717e-05,  5.0174e-04, -3.9692e-04,\n",
            "        -4.7796e-04, -4.1041e-04, -9.2008e-04,  5.6848e-04,  3.7843e-04,\n",
            "         3.7185e-04,  8.0139e-04, -1.4766e-04, -8.4415e-05,  7.9467e-04,\n",
            "         1.4331e-03, -7.9853e-04,  5.4269e-04,  9.7992e-04,  3.0178e-04,\n",
            "        -1.2218e-05, -3.0466e-04, -1.1469e-03, -9.8128e-04,  3.3585e-04,\n",
            "        -4.1597e-04,  6.0622e-04,  5.3120e-04,  1.9278e-04,  6.2900e-04,\n",
            "        -2.0671e-04,  1.1279e-04, -1.1846e-03, -4.4229e-04, -2.7137e-04,\n",
            "         7.3718e-05,  2.5457e-04, -1.8077e-04, -3.6559e-04,  1.6452e-04,\n",
            "        -5.9333e-04,  8.6887e-04, -6.8818e-04,  2.4043e-04, -9.0331e-04,\n",
            "        -3.6975e-04,  1.3049e-04, -3.6885e-04,  3.0709e-04, -7.6965e-05,\n",
            "        -5.4670e-04,  5.1498e-04,  1.7585e-04,  7.2776e-05, -3.4582e-04,\n",
            "         2.0085e-04,  2.9495e-04,  2.8161e-04, -1.8970e-04, -5.3003e-04,\n",
            "        -4.1501e-04,  5.1005e-04, -5.3203e-05,  3.9735e-04,  4.7274e-05,\n",
            "        -7.5999e-06, -6.5843e-04,  6.0809e-04, -2.6170e-04,  4.8957e-04,\n",
            "         3.3362e-05,  4.1269e-04, -1.2743e-05, -3.5664e-04, -1.0860e-04,\n",
            "        -1.0174e-03,  1.5595e-04, -2.6748e-04,  1.4184e-04, -4.2986e-04,\n",
            "         3.9838e-05,  5.1812e-05,  9.7439e-05, -4.0698e-04,  5.0147e-04,\n",
            "         4.3671e-04, -1.0952e-03,  1.3641e-04,  9.6048e-05,  3.5332e-04,\n",
            "        -4.0944e-04,  4.4069e-04, -2.0331e-04, -1.4325e-05, -5.9984e-04,\n",
            "         2.3267e-04,  1.5483e-05,  4.0560e-04,  4.4371e-05, -1.3658e-04,\n",
            "         5.6438e-04, -2.7870e-04,  3.5326e-04,  3.4247e-04, -3.1141e-04,\n",
            "         2.2597e-04,  4.0756e-04, -7.1509e-04,  2.7228e-04,  1.6230e-03,\n",
            "        -3.9690e-04, -1.4651e-04,  2.8421e-04,  1.8101e-04, -2.9998e-04,\n",
            "         7.8453e-04,  2.0201e-04,  3.6728e-04, -2.2998e-04,  1.0353e-04,\n",
            "        -6.7352e-04,  5.1211e-04, -2.6658e-04,  8.2089e-04, -7.1402e-04,\n",
            "         3.5253e-04,  3.9103e-04, -1.4428e-04, -4.6978e-04,  2.0311e-04,\n",
            "        -1.7645e-04, -1.0376e-03, -6.9868e-05, -1.3891e-04,  3.9467e-05,\n",
            "         7.4478e-04, -3.6910e-04,  4.6465e-05, -8.7941e-05, -2.2660e-04,\n",
            "         8.6074e-05,  1.9304e-04,  5.4881e-04,  7.4693e-06, -1.3475e-04,\n",
            "        -1.1997e-04,  2.4742e-04, -8.9779e-04, -3.7189e-04,  2.8712e-04,\n",
            "         5.0990e-04, -7.3113e-04, -2.5772e-05, -2.0284e-04, -2.6843e-04,\n",
            "         1.7061e-04,  3.8101e-05, -6.7887e-04,  5.7905e-04, -4.8103e-04,\n",
            "         8.0657e-04,  1.1050e-03,  1.8988e-04,  2.7238e-04, -7.2025e-04,\n",
            "         4.5042e-04,  6.9790e-04, -4.5158e-04, -3.7371e-04,  4.8679e-04,\n",
            "        -1.3556e-03, -2.6401e-04,  2.2010e-04,  3.3545e-04, -3.6155e-04,\n",
            "         7.4535e-04, -5.7416e-04,  2.4514e-05,  2.2329e-04,  1.1459e-04,\n",
            "        -3.0736e-04, -2.2808e-04,  9.2309e-05,  2.4021e-04, -7.1393e-04,\n",
            "         2.9502e-04,  6.8043e-04])), ('module.encoder_q.layer2.3.bn3.running_mean', tensor([ 5.7078e-02,  8.5777e-02, -1.8493e-01,  9.1121e-02, -3.0816e-01,\n",
            "        -1.9848e-01,  1.7017e-01, -8.7770e-03,  1.2889e-01,  9.3373e-02,\n",
            "         3.4113e-01, -7.0323e-02, -2.5948e-03, -2.2438e-01,  1.3651e-01,\n",
            "        -3.1804e-01, -4.8762e-01,  2.0584e-02,  2.9942e-01,  1.9832e-01,\n",
            "         1.8481e-01, -2.9305e-01,  4.0403e-01, -1.1132e-01, -5.6561e-02,\n",
            "         9.2121e-02, -1.2865e-01, -4.8352e-01,  4.0980e-01, -5.4573e-02,\n",
            "        -2.7408e-01, -2.0226e-01,  1.0416e-01,  1.5496e-01,  8.3317e-02,\n",
            "        -4.6749e-02, -9.9559e-02,  5.3596e-02, -1.5623e-01,  1.5060e-01,\n",
            "        -2.1665e-02, -4.5749e-02,  7.7081e-02, -2.7590e-01,  3.2723e-02,\n",
            "         5.4411e-02,  3.0348e-01,  1.9451e-01,  3.0442e-01,  5.4015e-02,\n",
            "         2.6345e-01, -1.9155e-01,  6.9083e-02,  2.7552e-01, -2.8194e-02,\n",
            "        -1.6874e-01,  1.1210e-01,  4.0368e-02,  8.4564e-02, -5.7008e-01,\n",
            "         2.0638e-02,  4.5875e-02,  1.2928e-01, -1.5865e-02, -2.0281e-01,\n",
            "        -1.3603e-01, -2.9597e-01, -4.2786e-01,  1.2208e-02, -2.0902e-01,\n",
            "        -1.3180e-01,  1.0296e-02,  7.1780e-02,  6.7615e-02,  1.8681e-01,\n",
            "        -1.0104e-01,  5.0683e-02, -3.1394e-02,  5.3479e-01, -1.0698e-01,\n",
            "        -8.4440e-02,  1.9296e-01, -1.0371e-01,  1.0747e-01, -3.9715e-02,\n",
            "        -2.4316e-01, -4.4823e-02, -1.8115e-02,  2.7790e-01, -1.5459e-01,\n",
            "        -5.2123e-01, -3.1596e-02, -1.9245e-01,  1.5962e-01, -2.7604e-02,\n",
            "        -2.3286e-01,  5.7347e-02,  6.8297e-02,  1.0225e-01, -1.2058e-02,\n",
            "        -1.4065e-01, -1.0205e-02, -1.8366e-01,  8.6075e-03, -7.0027e-02,\n",
            "        -5.6719e-01, -3.1551e-01, -2.6186e-01,  5.9995e-02,  1.9648e-02,\n",
            "         1.1000e-02, -4.2383e-01, -5.1428e-02, -1.6759e-01,  2.3871e-01,\n",
            "        -9.5693e-02,  3.7349e-01,  1.1271e-02, -1.4478e-01, -3.3825e-01,\n",
            "        -7.3357e-02, -2.6998e-01, -5.3702e-03, -1.4542e-01,  1.8650e-01,\n",
            "         3.8378e-01,  1.1904e-01, -2.1366e-02,  4.1754e-01,  4.5774e-03,\n",
            "         1.5019e-01,  2.7435e-01,  2.2752e-02, -1.9165e-01,  1.1169e-01,\n",
            "        -2.6662e-01, -7.3570e-01, -1.1368e-01,  2.0732e-01, -1.3601e-01,\n",
            "        -3.4460e-01,  1.9171e-02, -5.1664e-01,  1.2283e-01, -1.8888e-01,\n",
            "         1.5056e-01,  2.5628e-01, -3.1484e-01,  1.7434e-01,  4.3688e-01,\n",
            "         2.0112e-01, -1.8465e-01,  5.1123e-01,  3.4102e-01,  5.8111e-02,\n",
            "        -1.4839e-01, -2.1083e-02, -3.0868e-01,  2.5797e-01, -1.2051e-01,\n",
            "        -1.4616e-01,  1.4754e-02,  1.5226e-01, -1.3319e-01, -4.2236e-01,\n",
            "        -2.3768e-01,  1.2290e-01, -3.2835e-01,  3.8990e-01,  1.7595e-01,\n",
            "         2.2629e-01, -3.5077e-01, -1.3029e-01, -2.5261e-02, -1.6602e-01,\n",
            "         1.8624e-01, -6.3406e-02,  1.0881e-01, -1.8153e-01, -1.4453e-01,\n",
            "        -1.2760e-01, -2.7992e-01,  5.2951e-01,  2.0891e-01, -6.7202e-02,\n",
            "        -2.3256e-01,  1.2903e-01,  1.7293e-01, -8.1050e-02,  9.8993e-02,\n",
            "        -1.2499e-02,  1.3566e-01,  3.8532e-01, -3.6758e-02, -5.2962e-01,\n",
            "        -1.2346e-01,  2.0329e-01,  3.6308e-02, -2.4238e-01,  1.4995e-01,\n",
            "        -3.0067e-02, -6.9888e-02,  1.2100e-01, -3.0442e-01,  1.2165e-01,\n",
            "         4.6411e-01, -1.1114e-01, -6.0441e-01, -1.6151e-01,  5.9081e-01,\n",
            "         2.1677e-01, -1.9286e-01, -1.5598e-01,  4.1209e-01, -1.7138e-01,\n",
            "        -3.7691e-02, -5.5612e-02,  3.4554e-01, -1.0642e-01,  4.1100e-01,\n",
            "        -5.1599e-01, -1.1761e-01,  2.3836e-01,  9.8010e-02,  2.0123e-01,\n",
            "         1.7603e-01, -1.6448e-01, -3.8163e-02,  1.2552e-01,  1.7444e-01,\n",
            "         2.5382e-01,  1.1116e-01, -4.1087e-01,  3.7185e-01,  3.2121e-02,\n",
            "         1.6598e-01, -5.4653e-01,  1.6641e-01,  8.5089e-02, -2.5497e-01,\n",
            "         2.5178e-02,  5.4730e-01, -5.4763e-02, -4.3363e-01,  1.3694e-01,\n",
            "        -3.1312e-01,  3.4016e-02,  4.6253e-01,  1.8308e-01,  1.0291e-01,\n",
            "         2.4173e-01,  2.9744e-01, -5.6009e-01, -3.0245e-01,  2.4713e-01,\n",
            "        -1.1005e-01, -6.3670e-02, -2.0932e-01, -7.0854e-02,  6.0819e-01,\n",
            "         2.1904e-01, -2.4126e-01,  2.0148e-01, -3.3091e-01,  5.1572e-01,\n",
            "        -1.1917e-01,  4.6772e-01, -1.9763e-01,  1.7312e-01, -1.4136e-02,\n",
            "        -5.3902e-02, -4.3465e-01, -1.7743e-01,  3.8381e-01, -2.2082e-01,\n",
            "         2.6822e-02, -2.5516e-01, -3.3297e-01,  5.2972e-02, -1.3984e-01,\n",
            "        -1.7209e-01, -3.0705e-01, -3.1737e-01,  3.1452e-01, -3.0921e-01,\n",
            "         3.1215e-01, -4.1427e-01,  1.9914e-01, -8.9808e-02, -1.5822e-01,\n",
            "        -1.6485e-01, -2.7884e-01, -2.0644e-01,  2.1018e-01,  1.4949e-01,\n",
            "         6.3959e-02, -1.5650e-01, -6.7897e-02,  3.8961e-03,  9.0274e-02,\n",
            "         3.3159e-01, -9.1439e-02,  3.5795e-01, -3.1710e-01, -1.5874e-01,\n",
            "        -3.2726e-01,  2.4614e-01, -9.9731e-02,  5.8988e-02, -3.0087e-01,\n",
            "        -3.1260e-01, -1.1819e-01, -1.4087e-01,  3.0064e-02, -1.1135e-01,\n",
            "         3.1802e-01, -4.1408e-01,  3.3876e-01, -2.7308e-01,  4.1432e-01,\n",
            "         2.2525e-01,  2.3628e-01, -4.2134e-01, -2.5313e-01,  6.2222e-02,\n",
            "         3.5097e-01,  7.3906e-02, -1.2317e-01, -5.6805e-02,  7.6052e-02,\n",
            "         7.8719e-02, -9.6905e-02, -9.8936e-02,  4.0105e-01,  3.1114e-01,\n",
            "         2.4499e-01, -2.0317e-02, -1.5445e-01,  1.6785e-01, -2.1677e-01,\n",
            "        -3.6131e-01, -4.3689e-01, -3.4149e-01,  2.8550e-01, -1.3037e-01,\n",
            "         9.0615e-02,  2.7993e-02, -1.4749e-01,  2.4117e-01,  4.4023e-02,\n",
            "        -6.5019e-02,  2.4389e-01, -1.0614e-01,  1.8104e-01, -1.0725e-01,\n",
            "        -2.5465e-01,  8.4231e-05, -1.7521e-01,  2.6134e-01, -7.8106e-02,\n",
            "        -2.9862e-01,  3.0221e-02,  7.9313e-02, -3.0047e-01,  6.3465e-01,\n",
            "        -3.0719e-01,  4.5361e-02,  2.0938e-01,  3.6575e-01,  3.2540e-01,\n",
            "        -1.6572e-01,  6.5797e-02, -4.1745e-02, -2.3055e-01,  3.8208e-01,\n",
            "        -5.0645e-02,  4.1480e-01,  7.2368e-02, -1.8014e-02, -1.3214e-01,\n",
            "        -2.7250e-01,  1.9451e-01, -6.0419e-02, -1.7689e-01,  1.6977e-02,\n",
            "         6.7073e-02,  2.5615e-01,  4.6897e-01,  6.2801e-02,  5.3114e-01,\n",
            "        -3.0967e-01, -1.9191e-01,  3.0211e-01, -2.6382e-01,  3.8549e-01,\n",
            "         4.8892e-01, -6.7322e-03, -2.8911e-02, -2.2917e-01, -3.4306e-01,\n",
            "         9.0067e-02, -3.2520e-01,  1.7385e-01,  2.5086e-02, -3.0097e-01,\n",
            "         2.8118e-01,  7.1164e-01, -4.2573e-02,  2.9026e-01,  3.1721e-01,\n",
            "        -1.5704e-01, -1.9891e-02, -3.1049e-01, -1.6415e-01,  1.1573e-01,\n",
            "        -1.7447e-01, -4.3026e-01,  8.8623e-02,  1.9618e-01,  7.3072e-02,\n",
            "         3.7184e-01,  1.2824e-01, -7.0126e-01,  1.2363e-01, -1.4796e-01,\n",
            "        -1.2797e-01, -1.8772e-01,  3.2117e-01, -2.0144e-02,  2.1013e-02,\n",
            "         3.1618e-01,  3.0158e-01,  2.4630e-01,  2.5550e-01, -8.3070e-02,\n",
            "        -3.5121e-01, -2.8572e-01,  5.1006e-02,  8.3546e-02, -2.1170e-02,\n",
            "         1.6037e-01, -1.8676e-01,  6.8979e-03,  2.0817e-01, -1.2063e-01,\n",
            "         9.1882e-02, -1.2829e-01,  7.1283e-02,  1.6734e-02,  4.1492e-01,\n",
            "        -1.7819e-02, -1.5893e-01,  2.2455e-01,  1.1785e-01, -5.4231e-02,\n",
            "         1.1801e-01,  3.5542e-01,  1.3334e-01, -1.5696e-01,  4.3255e-02,\n",
            "         1.4575e-01,  2.8641e-01, -8.0868e-02,  1.4872e-01,  3.7124e-01,\n",
            "         4.8294e-02,  1.0229e-01,  1.1449e-01, -3.2542e-01,  2.7245e-01,\n",
            "        -2.7208e-01,  1.5092e-01,  3.1044e-01, -2.5216e-01, -2.2130e-01,\n",
            "        -2.4418e-01, -6.4469e-02,  9.1686e-02, -1.8145e-01,  1.0295e-01,\n",
            "         8.4407e-02,  1.9638e-02,  9.9731e-02,  2.8762e-01, -1.0323e-01,\n",
            "        -2.8688e-01, -3.1941e-02, -3.1135e-03, -1.5700e-01,  5.5933e-02,\n",
            "         1.0044e-01,  3.7189e-01,  2.5977e-01,  1.2866e-01, -6.0301e-02,\n",
            "         1.5204e-01,  4.5680e-02, -1.7777e-01,  1.6818e-01, -1.1265e-01,\n",
            "         1.5220e-01,  1.3751e-01, -3.6484e-02, -1.4623e-01,  7.6460e-02,\n",
            "         4.5120e-01, -4.7693e-01,  1.1684e-01,  1.4024e-01,  4.0941e-02,\n",
            "         3.1783e-02,  2.0975e-01])), ('module.encoder_q.layer2.3.bn3.running_var', tensor([0.1424, 0.1541, 0.1626, 0.1738, 0.1744, 0.2366, 0.1391, 0.1531, 0.2309,\n",
            "        0.1829, 0.1063, 0.1340, 0.1629, 0.2722, 0.1709, 0.2513, 0.2983, 0.1729,\n",
            "        0.3635, 0.1174, 0.2228, 0.1908, 0.2677, 0.1400, 0.1250, 0.1398, 0.1435,\n",
            "        0.1532, 0.1370, 0.1662, 0.3380, 0.1786, 0.2037, 0.1696, 0.1664, 0.1856,\n",
            "        0.2832, 0.1997, 0.2000, 0.1588, 0.2711, 0.1732, 0.1365, 0.3863, 0.2386,\n",
            "        0.1432, 0.2387, 0.2066, 0.1740, 0.1794, 0.3550, 0.1523, 0.1675, 0.1849,\n",
            "        0.1889, 0.2035, 0.1818, 0.2323, 0.1305, 0.6023, 0.1013, 0.1802, 0.3739,\n",
            "        0.1521, 0.1371, 0.1465, 0.2342, 0.3780, 0.1287, 0.1510, 0.2309, 0.2518,\n",
            "        0.1264, 0.1436, 0.1526, 0.1665, 0.2757, 0.1385, 0.1465, 0.1170, 0.1457,\n",
            "        0.2440, 0.1974, 0.1172, 0.2291, 0.2778, 0.2396, 0.1047, 0.3265, 0.1502,\n",
            "        0.3396, 0.1750, 0.1295, 0.1506, 0.1299, 0.1731, 0.2558, 0.3336, 0.1323,\n",
            "        0.1362, 0.1490, 0.2065, 0.1438, 0.1433, 0.2347, 0.1555, 0.2501, 0.1817,\n",
            "        0.1294, 0.2056, 0.3233, 0.2229, 0.1884, 0.1983, 0.1400, 0.2233, 0.2957,\n",
            "        0.1045, 0.2025, 0.1744, 0.1229, 0.1415, 0.1019, 0.1343, 0.1699, 0.1138,\n",
            "        0.1190, 0.1484, 0.1698, 0.1263, 0.1274, 0.1315, 0.1196, 0.1536, 0.2182,\n",
            "        0.1215, 0.2637, 0.1636, 0.3498, 0.2341, 0.3225, 0.2000, 0.3455, 0.1242,\n",
            "        0.1713, 0.1473, 0.1697, 0.1469, 0.2033, 0.2947, 0.1711, 0.1505, 0.1438,\n",
            "        0.1217, 0.1453, 0.1472, 0.2905, 0.1718, 0.1937, 0.1255, 0.2106, 0.1269,\n",
            "        0.1285, 0.1611, 0.4019, 0.1646, 0.1662, 0.1905, 0.2937, 0.1337, 0.0750,\n",
            "        0.2818, 0.2338, 0.1182, 0.1058, 0.2033, 0.3363, 0.1543, 0.1593, 0.1447,\n",
            "        0.2074, 0.2359, 0.1968, 0.1299, 0.1516, 0.1250, 0.1553, 0.1098, 0.2178,\n",
            "        0.1112, 0.1411, 0.1233, 0.1635, 0.1570, 0.1417, 0.1643, 0.1087, 0.1138,\n",
            "        0.1765, 0.4306, 0.1446, 0.1355, 0.1408, 0.2413, 0.1276, 0.2471, 0.1408,\n",
            "        0.2874, 0.2529, 0.3174, 0.1799, 0.2876, 0.2608, 0.2400, 0.1095, 0.1832,\n",
            "        0.1887, 0.4584, 0.1099, 0.4625, 0.2302, 0.1239, 0.1866, 0.1599, 0.1509,\n",
            "        0.1978, 0.1186, 0.1506, 0.1697, 0.2183, 0.1140, 0.1750, 0.1634, 0.2775,\n",
            "        0.1372, 0.1222, 0.5207, 0.1772, 0.2043, 0.2785, 0.2165, 0.1229, 0.2299,\n",
            "        0.1869, 0.1773, 0.2060, 0.1799, 0.3519, 0.1645, 0.1690, 0.2058, 0.2144,\n",
            "        0.3117, 0.1873, 0.2376, 0.1616, 0.1426, 0.3498, 0.1485, 0.3911, 0.1242,\n",
            "        0.1412, 0.2410, 0.1575, 0.5098, 0.1508, 0.5151, 0.1510, 0.2233, 0.1728,\n",
            "        0.1496, 0.0947, 0.2604, 0.2140, 0.2701, 0.2028, 0.1814, 0.2436, 0.1950,\n",
            "        0.1515, 0.1240, 0.1739, 0.2853, 0.2918, 0.2294, 0.1492, 0.2596, 0.2827,\n",
            "        0.1215, 0.1148, 0.1096, 0.1168, 0.1354, 0.2100, 0.6197, 0.1199, 0.2225,\n",
            "        0.1541, 0.1885, 0.2119, 0.2770, 0.1327, 0.1717, 0.1712, 0.2093, 0.1442,\n",
            "        0.2473, 0.1256, 0.1379, 0.1862, 0.2463, 0.1461, 0.1583, 0.1839, 0.1902,\n",
            "        0.2247, 0.6296, 0.1534, 0.1465, 0.2933, 0.1823, 0.2357, 0.3903, 0.2043,\n",
            "        0.1531, 0.1616, 0.1675, 0.1488, 0.1695, 0.3225, 0.1761, 0.1132, 0.1727,\n",
            "        0.1379, 0.1799, 0.1928, 0.1337, 0.1394, 0.1143, 0.2345, 0.1672, 0.3097,\n",
            "        0.2702, 0.1430, 0.1661, 0.1641, 0.1840, 0.1124, 0.1435, 0.1687, 0.2065,\n",
            "        0.1479, 0.1284, 0.1108, 0.1420, 0.3221, 0.2244, 0.2612, 0.1763, 0.1694,\n",
            "        0.1083, 0.2895, 0.1033, 0.2250, 0.2010, 0.1393, 0.2496, 0.1475, 0.1683,\n",
            "        0.2970, 0.1874, 0.1845, 0.1200, 0.1797, 0.1682, 0.1147, 0.1543, 0.1694,\n",
            "        0.1126, 0.1517, 0.1275, 0.1457, 0.1663, 0.2367, 0.2229, 0.2193, 0.1792,\n",
            "        0.5140, 0.1236, 0.4365, 0.1400, 0.1635, 0.1379, 0.1064, 0.7204, 0.1178,\n",
            "        0.1034, 0.1244, 0.1621, 0.1143, 0.2170, 0.1457, 0.1554, 0.1819, 0.1895,\n",
            "        0.2032, 0.2776, 0.1182, 0.1328, 0.1731, 0.1597, 0.1574, 0.3025, 0.1548,\n",
            "        0.2079, 0.3016, 0.3040, 0.1474, 0.1806, 0.3135, 0.1856, 0.1577, 0.2923,\n",
            "        0.1662, 0.2051, 0.1865, 0.2238, 0.3024, 0.1128, 0.1588, 0.2315, 0.3815,\n",
            "        0.1783, 0.1908, 0.1385, 0.2802, 0.1800, 0.1621, 0.1593, 0.1346, 0.1679,\n",
            "        0.2073, 0.1103, 0.1409, 0.1437, 0.1016, 0.1238, 0.1255, 0.1510, 0.1667,\n",
            "        0.1556, 0.1521, 0.1654, 0.1489, 0.1541, 0.1775, 0.3755, 0.1263, 0.1785,\n",
            "        0.2799, 0.2665, 0.1708, 0.1772, 0.1236, 0.1950, 0.1481, 0.2059, 0.2002,\n",
            "        0.1734, 0.2119, 0.1161, 0.2183, 0.1218, 0.2748, 0.1469, 0.1588, 0.2766,\n",
            "        0.1077, 0.1310, 0.1669, 0.1033, 0.1414, 0.1965, 0.2386, 0.1528, 0.3790,\n",
            "        0.1362, 0.1301, 0.1797, 0.2649, 0.1304, 0.1141, 0.1276, 0.1947, 0.1510,\n",
            "        0.4201, 0.1975, 0.1202, 0.1953, 0.1008, 0.1316, 0.1580, 0.1933, 0.1001,\n",
            "        0.1821, 0.6042, 0.2363, 0.1738, 0.2512, 0.0987, 0.1133, 0.1809])), ('module.encoder_q.layer2.3.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.0.conv1.weight', tensor([[[[ 1.9409e-02]],\n",
            "\n",
            "         [[ 1.8527e-02]],\n",
            "\n",
            "         [[-2.6021e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5429e-02]],\n",
            "\n",
            "         [[ 1.3982e-01]],\n",
            "\n",
            "         [[-8.6507e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3480e-02]],\n",
            "\n",
            "         [[-1.0644e-01]],\n",
            "\n",
            "         [[-1.5335e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2469e-01]],\n",
            "\n",
            "         [[-1.5501e-02]],\n",
            "\n",
            "         [[-1.1839e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.0410e-02]],\n",
            "\n",
            "         [[-1.4202e-01]],\n",
            "\n",
            "         [[ 4.4855e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3007e-02]],\n",
            "\n",
            "         [[-6.5241e-02]],\n",
            "\n",
            "         [[-1.8478e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5322e-01]],\n",
            "\n",
            "         [[-5.2809e-02]],\n",
            "\n",
            "         [[ 2.0737e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2491e-04]],\n",
            "\n",
            "         [[ 4.0282e-03]],\n",
            "\n",
            "         [[ 1.5347e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.9018e-01]],\n",
            "\n",
            "         [[-2.1799e-02]],\n",
            "\n",
            "         [[ 1.1432e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.2481e-02]],\n",
            "\n",
            "         [[ 2.9773e-02]],\n",
            "\n",
            "         [[ 6.6203e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3264e-01]],\n",
            "\n",
            "         [[ 1.0210e-01]],\n",
            "\n",
            "         [[ 9.2243e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6360e-02]],\n",
            "\n",
            "         [[-1.6907e-01]],\n",
            "\n",
            "         [[ 4.7882e-02]]]])), ('module.encoder_q.layer3.0.bn1.weight', tensor([0.9904, 0.9913, 0.9912, 0.9910, 0.9934, 0.9908, 0.9905, 0.9921, 0.9933,\n",
            "        0.9923, 0.9906, 0.9924, 0.9928, 0.9946, 0.9899, 0.9924, 0.9954, 0.9929,\n",
            "        0.9937, 0.9934, 0.9937, 0.9923, 0.9912, 0.9896, 0.9911, 0.9934, 0.9938,\n",
            "        0.9925, 0.9914, 0.9903, 0.9926, 0.9907, 0.9936, 0.9910, 0.9932, 0.9912,\n",
            "        0.9927, 0.9896, 0.9929, 0.9897, 0.9913, 0.9911, 0.9919, 0.9906, 0.9931,\n",
            "        0.9914, 0.9939, 0.9921, 0.9924, 0.9930, 0.9927, 0.9928, 0.9928, 0.9930,\n",
            "        0.9927, 0.9914, 0.9942, 0.9928, 0.9949, 0.9911, 0.9922, 0.9937, 0.9876,\n",
            "        0.9925, 0.9910, 0.9932, 0.9900, 0.9941, 0.9931, 0.9933, 0.9897, 0.9923,\n",
            "        0.9919, 0.9908, 0.9922, 0.9932, 0.9916, 0.9920, 0.9915, 0.9924, 0.9936,\n",
            "        0.9908, 0.9954, 0.9910, 0.9914, 0.9926, 0.9897, 0.9913, 0.9906, 0.9924,\n",
            "        0.9914, 0.9920, 0.9925, 0.9911, 0.9909, 0.9915, 0.9921, 0.9916, 0.9925,\n",
            "        0.9927, 0.9932, 0.9920, 0.9933, 0.9894, 0.9932, 0.9953, 0.9917, 0.9935,\n",
            "        0.9940, 0.9930, 0.9902, 0.9931, 0.9930, 0.9924, 0.9926, 0.9929, 0.9929,\n",
            "        0.9910, 0.9889, 0.9912, 0.9929, 0.9929, 0.9904, 0.9921, 0.9934, 0.9911,\n",
            "        0.9910, 0.9927, 0.9926, 0.9920, 0.9924, 0.9939, 0.9929, 0.9925, 0.9918,\n",
            "        0.9931, 0.9937, 0.9934, 0.9918, 0.9931, 0.9908, 0.9906, 0.9913, 0.9910,\n",
            "        0.9921, 0.9929, 0.9936, 0.9932, 0.9926, 0.9957, 0.9925, 0.9930, 0.9905,\n",
            "        0.9934, 0.9931, 0.9910, 0.9921, 0.9937, 0.9952, 0.9948, 0.9919, 0.9922,\n",
            "        0.9919, 0.9921, 0.9921, 0.9934, 0.9924, 0.9937, 0.9928, 0.9912, 0.9905,\n",
            "        0.9921, 0.9916, 0.9938, 0.9911, 0.9917, 0.9915, 0.9920, 0.9912, 0.9894,\n",
            "        0.9946, 0.9911, 0.9897, 0.9938, 0.9961, 0.9922, 0.9935, 0.9933, 0.9909,\n",
            "        0.9953, 0.9934, 0.9920, 0.9917, 0.9948, 0.9917, 0.9906, 0.9913, 0.9912,\n",
            "        0.9915, 0.9928, 0.9894, 0.9925, 0.9934, 0.9926, 0.9905, 0.9917, 0.9933,\n",
            "        0.9917, 0.9920, 0.9955, 0.9933, 0.9934, 0.9922, 0.9931, 0.9915, 0.9913,\n",
            "        0.9909, 0.9910, 0.9932, 0.9912, 0.9944, 0.9947, 0.9961, 0.9903, 0.9929,\n",
            "        0.9923, 0.9921, 0.9928, 0.9915, 0.9923, 0.9902, 0.9928, 0.9916, 0.9911,\n",
            "        0.9944, 0.9924, 0.9903, 0.9919, 0.9911, 0.9943, 0.9931, 0.9914, 0.9949,\n",
            "        0.9919, 0.9907, 0.9916, 0.9924, 0.9921, 0.9918, 0.9919, 0.9912, 0.9952,\n",
            "        0.9947, 0.9930, 0.9919, 0.9912])), ('module.encoder_q.layer3.0.bn1.bias', tensor([-1.0563e-03, -2.0275e-03, -7.6593e-04,  3.9705e-05,  9.8940e-04,\n",
            "        -1.9896e-03, -1.0053e-03,  1.2811e-03,  1.0089e-03,  1.1583e-03,\n",
            "        -1.7507e-03, -8.9006e-04,  8.7891e-04,  9.4553e-04,  3.5391e-05,\n",
            "         7.3444e-04,  1.5369e-03,  9.2442e-05,  2.4620e-03,  2.0672e-03,\n",
            "         5.0168e-04,  7.0549e-04, -2.4532e-03, -2.7001e-03, -5.1243e-04,\n",
            "         5.2464e-04,  7.3952e-04, -7.0972e-04, -7.1308e-04,  7.2002e-04,\n",
            "        -1.9014e-03, -1.9490e-04,  1.1547e-03, -8.0391e-04,  1.1676e-03,\n",
            "        -7.0550e-06,  1.7294e-03, -1.3796e-03, -6.7254e-04, -2.0282e-03,\n",
            "        -1.4783e-03, -1.2622e-03,  9.6162e-05, -1.7803e-03,  5.8871e-04,\n",
            "        -8.1603e-04,  5.7439e-04, -3.5421e-04, -5.2541e-05,  9.1350e-04,\n",
            "         9.3429e-04, -3.5677e-04, -3.7350e-04,  2.6086e-03, -1.8543e-06,\n",
            "        -1.9426e-03,  1.4923e-03, -1.0512e-03,  1.4516e-03, -5.5863e-05,\n",
            "         9.9986e-04,  1.3809e-03, -2.7947e-03,  2.3752e-04,  7.8741e-04,\n",
            "         5.4283e-04, -2.4987e-03,  2.8325e-04, -2.3073e-04, -8.1415e-04,\n",
            "        -2.2785e-03, -2.1482e-04, -9.3621e-04, -2.0781e-03,  3.8744e-04,\n",
            "         1.1847e-03,  1.9006e-03, -1.9307e-03, -6.3608e-05, -3.0765e-04,\n",
            "         1.7304e-04,  1.2075e-03,  2.4287e-03, -1.9926e-03, -2.6725e-03,\n",
            "         6.5981e-05, -8.5978e-04, -1.6538e-03, -3.9888e-04,  6.1755e-04,\n",
            "        -3.1592e-04, -1.9190e-03, -6.0741e-04, -7.1225e-05, -1.0642e-03,\n",
            "        -1.1184e-03,  1.2200e-03, -8.4849e-04, -3.0040e-04,  2.9862e-04,\n",
            "         1.7899e-03, -6.3967e-04,  2.1600e-03, -1.6301e-03,  1.4044e-03,\n",
            "         1.9683e-03, -9.9171e-05,  2.3948e-03,  4.2549e-04,  9.9976e-04,\n",
            "        -1.0812e-03,  1.4700e-03, -3.5148e-04, -5.7785e-04,  1.6119e-03,\n",
            "        -1.5392e-03,  9.5037e-04, -1.1465e-03, -7.2605e-04, -8.6461e-04,\n",
            "        -1.6149e-05,  3.8760e-04, -1.1723e-03,  1.1687e-03,  7.7682e-04,\n",
            "         3.9233e-05,  4.4643e-04,  1.2330e-03,  8.7640e-05,  2.6502e-04,\n",
            "        -8.7367e-05,  1.1883e-03,  7.4698e-04,  9.7431e-04, -1.9227e-04,\n",
            "        -2.4236e-03, -1.7234e-04,  2.4197e-03, -1.0740e-03,  1.2079e-03,\n",
            "        -7.2277e-04,  5.2886e-04, -6.8242e-04, -2.8273e-03, -2.9891e-03,\n",
            "         6.5148e-04,  3.8601e-03,  5.1807e-04,  9.3075e-04,  2.8031e-03,\n",
            "        -6.1738e-04,  6.0529e-04, -2.3345e-04,  1.2110e-03,  2.7532e-03,\n",
            "        -4.7035e-04,  1.3511e-03,  4.1250e-04,  1.2302e-03,  1.7577e-03,\n",
            "        -6.5423e-04, -6.4364e-04, -9.7218e-04, -7.4548e-05,  7.2194e-04,\n",
            "         6.8475e-04,  1.4358e-03, -3.7651e-04,  1.1640e-03,  9.8335e-04,\n",
            "        -1.4640e-03,  2.0984e-03, -9.8731e-04,  1.8729e-03, -8.6428e-04,\n",
            "        -4.8899e-04,  7.5656e-05, -7.6119e-04, -1.6243e-03, -1.2058e-03,\n",
            "         1.1042e-03, -1.3103e-03, -2.3365e-03,  7.2165e-04,  2.7801e-03,\n",
            "         1.2216e-03,  1.5184e-03,  5.9227e-04, -8.2795e-04,  3.1525e-03,\n",
            "         7.9539e-04,  4.7124e-04,  4.3561e-04,  2.7425e-03, -7.7614e-04,\n",
            "        -1.8310e-04,  9.2323e-05, -1.8140e-03, -8.5094e-05, -8.6396e-05,\n",
            "        -1.5512e-03,  4.1886e-04,  3.1174e-04, -9.8273e-04, -1.0263e-03,\n",
            "        -4.2852e-04,  2.3488e-03,  7.3767e-04, -6.7086e-04, -5.4418e-04,\n",
            "         1.0899e-03,  1.7717e-03,  6.5256e-04,  1.3139e-03, -4.7070e-04,\n",
            "         6.3449e-04, -3.7839e-03, -9.2551e-04,  1.1637e-03, -6.4541e-04,\n",
            "        -4.6448e-05,  1.4809e-03,  1.2531e-03, -6.1037e-04,  1.4591e-03,\n",
            "        -4.0673e-04, -1.0094e-04,  1.5922e-03, -1.5493e-03,  4.7946e-04,\n",
            "        -1.0402e-03, -3.9076e-04,  1.2235e-03, -6.7641e-04,  1.1488e-03,\n",
            "        -1.8326e-03, -1.4674e-03, -9.0261e-04, -6.0085e-04,  2.8699e-04,\n",
            "         1.0374e-03,  4.6976e-04,  1.4110e-03,  5.6693e-04, -9.6144e-04,\n",
            "        -3.3908e-04,  1.6145e-03,  8.1849e-04, -9.6166e-05, -9.2406e-04,\n",
            "         1.5417e-03,  1.5835e-03,  2.9944e-04,  1.3997e-03, -1.0415e-03,\n",
            "        -7.5309e-04])), ('module.encoder_q.layer3.0.bn1.running_mean', tensor([-1.3568,  4.0649, -1.7645, -1.9370,  4.3354, -0.8607,  2.3303, -1.4313,\n",
            "         0.4260,  2.1017,  2.5339,  0.1158, -0.1127, -0.5931,  4.1179, -2.9434,\n",
            "         1.8126,  0.3465,  0.0525,  0.3409, -2.7568, -1.7989,  1.9478, -3.1683,\n",
            "         0.3196,  0.8354,  1.9893,  4.2534, -1.9247,  3.8670, -3.3645,  1.9213,\n",
            "         1.4813, -0.3594, -1.6991, -4.4403, -0.3227, -0.9147, -0.7018, -1.2751,\n",
            "        -2.2707,  1.4453, -2.3426, -2.7714,  0.2833,  1.9287, -0.6702, -4.2426,\n",
            "         0.0101, -3.2789,  4.3315,  1.3441, -0.7749, -5.6017, -0.9994, -2.9053,\n",
            "        -1.2550,  1.5184, -1.1690,  0.7598,  5.1459,  0.4304, -1.2111, -0.6435,\n",
            "        -1.6205, -2.8921,  0.6092,  2.9298,  0.7228,  2.2774, -0.3710,  5.6093,\n",
            "         0.7257, -1.1858,  0.7032,  3.8508,  0.6828,  0.4820, -0.0464,  0.4771,\n",
            "         3.9636, -0.8344,  0.8362, -1.3962, -2.7314,  1.0083,  0.2339,  1.6118,\n",
            "         2.8476,  2.9059, -0.8500,  0.0831,  1.1738, -1.3695,  1.0414, -0.8000,\n",
            "         2.4776,  2.8953, -0.2808,  5.0089, -1.8192, -1.4973, -1.9309,  2.3009,\n",
            "         1.2924, -1.1752, -0.8170, -0.4491,  0.1425,  1.4573, -3.1828, -0.3231,\n",
            "        -0.4486, -2.6057,  1.1904,  2.5560,  4.8022,  4.0964, -1.1537, -1.2531,\n",
            "         2.3133, -2.4247, -1.9075,  2.9905,  3.6466,  0.5425, -4.0961,  1.0954,\n",
            "         0.4131, -1.6466,  8.2075, -0.5122, -0.8842, -1.6539, -4.5022, -0.2680,\n",
            "         2.6937,  0.2401,  1.3768,  1.2334,  0.1150,  4.2533, -2.7208,  2.9652,\n",
            "        -0.2718, -0.0651, -2.0102,  2.7635, -0.0604, -0.0707, -1.9873, -0.5878,\n",
            "         1.6080, -1.0157, -4.5647,  3.6570,  0.7805,  0.0807, -0.3202,  0.3050,\n",
            "        -0.8690,  0.5302, -4.0535,  0.0608, -0.8775,  1.3833,  0.6488,  2.2536,\n",
            "        -2.5391,  4.7422,  4.0919,  1.0708,  1.0327,  3.4809, -0.8829,  0.4982,\n",
            "         2.7509, -2.1440, -2.1894,  3.0047,  0.0793, -2.0314, -2.2822,  1.9648,\n",
            "         1.0090,  1.0283, -4.8028, -0.0928,  0.4544,  4.1401,  0.7223,  2.0132,\n",
            "        -3.1417, -2.2321,  3.0982, -1.6230, -0.0887, -2.5438, -0.1529,  0.1023,\n",
            "         3.4256,  3.7466, -3.0379,  1.3360,  2.5684, -1.6086, -1.1411,  0.0087,\n",
            "         0.2204, -1.1651, -1.9710,  1.1576,  2.3716, -0.9385,  5.4077, -0.3711,\n",
            "         3.5465, -0.0797,  1.4207,  3.3336,  0.2603,  1.1680,  0.1220, -0.1156,\n",
            "        -0.0934, -0.0739, -2.4845,  2.3826, -4.0087, -0.5355, -2.7816,  0.8677,\n",
            "        -0.2268,  2.3242,  1.3799, -0.3232,  0.4230, -0.8423, -1.6648,  1.1877,\n",
            "         0.8860, -1.4856, -0.1253,  0.8034, -0.8109,  2.0461,  0.3443, -0.8557,\n",
            "        -2.5492,  0.8479, -0.2713,  2.6196, -0.6588, -2.4946, -0.1639, -2.0410])), ('module.encoder_q.layer3.0.bn1.running_var', tensor([ 6.4918, 11.0470,  6.8059,  6.7033,  7.3869,  5.5489,  8.0533,  5.7716,\n",
            "         6.8740,  9.3429,  5.0580,  9.1541, 11.2271,  8.8154, 14.4192, 13.7949,\n",
            "         6.7548,  7.3340,  7.8636,  5.3058,  7.0293,  7.0278, 14.3892,  5.9054,\n",
            "         5.9538,  6.7271,  5.4097, 13.1153,  8.2894,  9.0302,  4.2204,  6.1810,\n",
            "         6.7265,  7.5450,  8.8976, 15.0944,  4.6988,  4.8637,  8.3726, 10.8110,\n",
            "         6.8072,  6.0734, 10.2784,  9.4842, 10.8617,  8.8894,  6.4005, 19.8202,\n",
            "         8.3993, 15.5117,  8.4498,  4.7606, 15.5804, 18.5091,  8.9261, 10.9708,\n",
            "         5.7811, 10.0676,  5.3607,  7.6733, 15.8859,  5.9881,  4.1275,  6.1790,\n",
            "         6.4945,  6.6382,  6.7455,  8.0620,  6.9182, 11.2903,  6.3629, 29.5909,\n",
            "         5.3650,  7.1323,  6.0976, 12.1934,  5.7518,  5.7270,  8.5720,  7.0619,\n",
            "        11.6506,  4.9945,  9.6151,  9.3472,  5.3437,  6.9557,  4.8080,  8.7078,\n",
            "         5.7694, 11.0337, 12.1674,  8.3463,  5.6723,  9.4211,  9.1872,  5.1174,\n",
            "         6.6896, 20.3913,  6.8964, 22.8970, 14.2141,  4.6933, 22.8236,  9.4699,\n",
            "         6.5440,  5.6420,  8.8299,  7.2431,  4.0104,  7.0705,  7.5189,  7.0722,\n",
            "         7.6692, 14.3474,  4.1050,  6.5666, 14.7371, 13.3015,  7.4081,  9.6361,\n",
            "         9.8658, 11.5012,  8.5356,  8.5889, 13.7312,  5.6735, 24.9110,  5.8487,\n",
            "         7.2777,  6.4914, 40.2979, 11.1551,  7.8662,  6.0370, 12.0684, 10.3111,\n",
            "         9.5313,  8.5830, 20.0500,  7.6369,  7.7981, 14.9798,  9.1828, 14.4891,\n",
            "         5.4360,  9.7526,  9.9634, 11.4194,  8.1158,  5.2103, 12.5027,  8.2151,\n",
            "         8.4019,  4.9546, 15.3304, 12.7846,  4.7730,  8.3551,  9.2864,  8.6996,\n",
            "         6.0343,  7.8990,  9.1532,  5.0337,  5.4805, 10.6965,  6.6608, 11.6945,\n",
            "        15.3313,  8.5887,  8.2433,  5.5203,  5.1673, 11.4178,  8.0952,  7.2188,\n",
            "        26.1678,  7.7079,  7.5019,  9.5674,  6.9086,  8.4811, 15.3143,  7.2538,\n",
            "         7.3181,  8.0456, 10.6097,  7.5937,  4.6355,  8.4392,  7.0622,  5.8284,\n",
            "        24.8016,  4.8696,  9.7083, 10.2464,  5.5122,  6.6907,  8.7487,  7.4039,\n",
            "        10.2553, 13.9863,  9.4803,  5.0887,  7.2336,  8.6117, 19.9590,  6.1117,\n",
            "         6.9333,  6.6306,  8.4542,  7.8515,  5.4463, 13.5648, 14.2053,  7.2976,\n",
            "        13.5226,  6.8229,  6.5004,  7.5852, 10.5808,  8.1830,  8.3682,  6.6772,\n",
            "         9.9028,  7.6326,  8.8697,  8.1605, 13.0316,  7.3110, 14.6236,  6.0202,\n",
            "         6.9061,  5.5644,  5.6901,  7.7733,  5.4739,  8.0717,  7.9166,  7.1474,\n",
            "         5.4312,  8.4721, 10.2797,  3.8605,  4.6512,  5.9397,  5.1675,  7.8307,\n",
            "         8.2040,  8.0744,  8.0763, 17.7870,  6.1166, 10.9006,  7.1291, 10.1338])), ('module.encoder_q.layer3.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.0.conv2.weight', tensor([[[[ 5.1971e-03,  2.8363e-02,  3.2408e-03],\n",
            "          [ 5.5301e-02, -2.1845e-03,  4.8413e-02],\n",
            "          [ 2.7977e-02,  1.6760e-02,  2.0978e-02]],\n",
            "\n",
            "         [[ 3.8136e-02, -5.7592e-03, -2.7512e-02],\n",
            "          [ 3.4127e-02, -9.7771e-02,  1.6230e-02],\n",
            "          [ 2.8819e-02, -5.8597e-02,  6.0758e-02]],\n",
            "\n",
            "         [[-3.9902e-03,  2.4297e-02, -1.7600e-02],\n",
            "          [-3.6852e-02,  1.6872e-02,  1.0539e-02],\n",
            "          [ 4.4967e-03, -4.7980e-02,  6.0499e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2670e-02, -5.8442e-04,  1.6996e-02],\n",
            "          [-2.8884e-02,  6.7642e-02, -4.4444e-03],\n",
            "          [-2.7473e-02, -2.0472e-02,  3.8405e-02]],\n",
            "\n",
            "         [[ 1.8915e-02, -8.5694e-02, -5.3626e-02],\n",
            "          [-1.8894e-02,  1.2117e-02, -1.0915e-02],\n",
            "          [ 1.1189e-02,  7.1549e-03, -2.6880e-02]],\n",
            "\n",
            "         [[-6.6558e-03,  1.2827e-02,  2.7603e-02],\n",
            "          [-3.6083e-02,  8.3780e-03,  4.2291e-02],\n",
            "          [ 8.0074e-03, -3.1736e-02, -5.0109e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7650e-02,  3.6661e-02,  4.6581e-03],\n",
            "          [-3.6070e-02,  1.8666e-02, -9.1544e-03],\n",
            "          [-4.7929e-02, -1.4902e-02,  6.9835e-04]],\n",
            "\n",
            "         [[ 4.3462e-02,  1.9035e-02,  3.5736e-02],\n",
            "          [-3.1986e-02,  1.4262e-02,  3.4802e-03],\n",
            "          [ 9.3735e-03, -5.2438e-02, -1.0363e-02]],\n",
            "\n",
            "         [[-4.4691e-02,  3.5859e-02, -2.6496e-02],\n",
            "          [ 4.9196e-02, -9.4927e-03,  4.2213e-02],\n",
            "          [-7.0765e-03, -3.4905e-02,  3.9345e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7604e-02, -3.2807e-02,  5.4066e-02],\n",
            "          [ 1.0187e-02, -1.3632e-02,  2.4291e-02],\n",
            "          [ 1.0273e-02, -5.4438e-04,  2.5231e-02]],\n",
            "\n",
            "         [[-3.4765e-04, -1.2972e-02, -1.1272e-02],\n",
            "          [ 2.1742e-02,  2.0824e-03,  1.7615e-03],\n",
            "          [ 9.2265e-02,  2.3805e-02,  6.6287e-03]],\n",
            "\n",
            "         [[-1.0869e-02,  1.9837e-02,  1.9031e-02],\n",
            "          [-5.0961e-02,  6.4837e-03,  3.7702e-02],\n",
            "          [ 6.8282e-03,  9.3845e-03, -8.6498e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.3826e-02, -1.7405e-02,  4.7805e-03],\n",
            "          [ 2.9148e-02, -3.8637e-02, -3.5575e-03],\n",
            "          [-7.6364e-04, -3.9544e-02,  3.3278e-02]],\n",
            "\n",
            "         [[ 1.9014e-02,  2.4078e-02,  6.2405e-03],\n",
            "          [ 5.6862e-02, -9.0285e-03,  1.7460e-02],\n",
            "          [ 7.3761e-03, -5.5141e-02, -3.2084e-02]],\n",
            "\n",
            "         [[-2.8427e-02, -6.9063e-03,  2.7013e-02],\n",
            "          [ 4.3247e-02, -6.8295e-03,  3.6450e-03],\n",
            "          [-7.2747e-03,  2.8061e-02,  4.4992e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.6739e-03,  1.7984e-02, -2.2824e-02],\n",
            "          [ 6.7278e-03,  5.4188e-02, -4.3989e-02],\n",
            "          [-7.2829e-03,  1.0333e-02, -7.9752e-03]],\n",
            "\n",
            "         [[ 1.4175e-02, -2.3500e-02, -4.1365e-02],\n",
            "          [-7.6731e-03, -3.9841e-02, -1.7009e-02],\n",
            "          [-2.6130e-02,  2.5226e-03, -3.8872e-02]],\n",
            "\n",
            "         [[-2.2621e-02,  6.8542e-02, -5.4718e-02],\n",
            "          [ 2.9762e-02,  2.8016e-02,  3.6449e-02],\n",
            "          [-2.9908e-02,  3.0756e-02,  2.1926e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1229e-02,  2.7442e-02,  7.3121e-03],\n",
            "          [ 3.9796e-02, -4.7189e-03,  4.1070e-02],\n",
            "          [-3.5456e-03, -4.6054e-02,  1.8690e-02]],\n",
            "\n",
            "         [[-4.0602e-02, -2.0684e-02,  2.8200e-02],\n",
            "          [-3.7374e-02, -1.5151e-02, -1.8877e-02],\n",
            "          [ 2.2907e-02,  1.1689e-02,  1.4607e-02]],\n",
            "\n",
            "         [[ 4.9109e-03, -1.3265e-02,  8.7797e-03],\n",
            "          [ 2.1129e-02,  2.2118e-02, -7.8199e-02],\n",
            "          [ 2.9740e-02,  1.5747e-02,  6.7860e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6729e-02, -1.1616e-02, -5.0351e-02],\n",
            "          [-3.6963e-03, -1.7292e-02,  4.6490e-03],\n",
            "          [ 2.5373e-02, -6.3037e-03, -3.5068e-02]],\n",
            "\n",
            "         [[ 1.4090e-02, -9.9650e-03,  1.7515e-02],\n",
            "          [ 1.2734e-02,  1.1506e-02,  5.1761e-02],\n",
            "          [-3.2837e-02,  4.1465e-02,  4.3279e-03]],\n",
            "\n",
            "         [[-8.9456e-03,  2.4823e-02, -3.1858e-03],\n",
            "          [ 1.6472e-02,  2.9804e-02, -3.2308e-02],\n",
            "          [-2.3614e-02, -1.2411e-03,  2.2739e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.7889e-03, -1.1156e-02,  4.4423e-02],\n",
            "          [ 2.1435e-02,  1.0222e-02,  1.4771e-02],\n",
            "          [ 4.5000e-02, -8.8753e-03, -5.3760e-02]],\n",
            "\n",
            "         [[ 1.4076e-02,  2.8560e-02, -2.4164e-02],\n",
            "          [ 2.2249e-02, -3.1606e-02, -4.1242e-02],\n",
            "          [-1.2626e-02,  5.2684e-02,  2.9054e-02]],\n",
            "\n",
            "         [[ 1.8604e-02,  8.3373e-02,  3.7377e-02],\n",
            "          [-1.0878e-03,  2.0916e-02, -8.9397e-03],\n",
            "          [-6.4058e-02, -4.8524e-03, -3.4323e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4055e-02, -1.0521e-02, -2.5945e-02],\n",
            "          [-3.4542e-02,  5.7805e-03, -3.2480e-02],\n",
            "          [ 5.4805e-02, -7.0750e-02, -5.0418e-02]],\n",
            "\n",
            "         [[ 9.2421e-03,  6.2651e-03,  4.1590e-02],\n",
            "          [ 1.0728e-02, -4.1590e-02, -4.0812e-02],\n",
            "          [ 1.6253e-03, -2.9550e-02,  1.0728e-02]],\n",
            "\n",
            "         [[ 8.1307e-03,  3.7971e-03, -6.9418e-03],\n",
            "          [ 4.7194e-02, -1.3726e-02,  4.6807e-02],\n",
            "          [ 1.4517e-02,  6.2645e-02,  1.6035e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.2482e-04, -3.7984e-02, -3.4067e-03],\n",
            "          [ 3.2126e-02, -1.9778e-02, -1.9999e-02],\n",
            "          [-3.1853e-02,  2.0727e-02,  2.2845e-02]],\n",
            "\n",
            "         [[-1.0202e-03,  2.8933e-02, -4.0307e-03],\n",
            "          [ 5.4524e-02,  3.5836e-02,  8.7418e-03],\n",
            "          [ 6.2365e-04,  1.8261e-02, -5.1713e-02]],\n",
            "\n",
            "         [[ 4.9975e-03, -1.9210e-02, -3.7747e-03],\n",
            "          [ 2.1128e-03, -2.6318e-02, -3.9675e-03],\n",
            "          [ 2.6425e-02,  1.1674e-02,  2.6686e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8142e-02,  1.6720e-02,  1.9679e-02],\n",
            "          [ 1.4299e-02, -5.4741e-02, -2.4532e-03],\n",
            "          [ 1.9730e-02,  1.3861e-02,  5.7970e-02]],\n",
            "\n",
            "         [[-1.3831e-02,  1.0197e-02, -3.1097e-02],\n",
            "          [ 4.3118e-03,  3.3103e-02, -4.4831e-02],\n",
            "          [ 3.6533e-02, -7.8635e-03, -3.9574e-02]],\n",
            "\n",
            "         [[ 1.4479e-02,  1.2135e-02, -5.2952e-03],\n",
            "          [ 3.6440e-03, -2.8773e-02, -4.0316e-02],\n",
            "          [-1.5806e-02, -4.3980e-02, -3.2950e-02]]]])), ('module.encoder_q.layer3.0.bn2.weight', tensor([0.9922, 0.9927, 0.9935, 0.9914, 0.9913, 0.9917, 0.9921, 0.9915, 0.9928,\n",
            "        0.9921, 0.9919, 0.9922, 0.9918, 0.9911, 0.9931, 0.9932, 0.9929, 0.9947,\n",
            "        0.9950, 0.9934, 0.9919, 0.9904, 0.9935, 0.9902, 0.9913, 0.9943, 0.9931,\n",
            "        0.9912, 0.9886, 0.9925, 0.9931, 0.9924, 0.9919, 0.9916, 0.9937, 0.9932,\n",
            "        0.9923, 0.9918, 0.9928, 0.9919, 0.9908, 0.9921, 0.9914, 0.9932, 0.9925,\n",
            "        0.9915, 0.9925, 0.9908, 0.9914, 0.9906, 0.9933, 0.9924, 0.9932, 0.9933,\n",
            "        0.9927, 0.9913, 0.9909, 0.9947, 0.9907, 0.9917, 0.9933, 0.9922, 0.9931,\n",
            "        0.9923, 0.9932, 0.9915, 0.9929, 0.9904, 0.9932, 0.9920, 0.9936, 0.9919,\n",
            "        0.9907, 0.9901, 0.9918, 0.9926, 0.9916, 0.9907, 0.9926, 0.9912, 0.9928,\n",
            "        0.9913, 0.9950, 0.9936, 0.9947, 0.9947, 0.9913, 0.9923, 0.9927, 0.9921,\n",
            "        0.9913, 0.9918, 0.9910, 0.9925, 0.9924, 0.9929, 0.9927, 0.9924, 0.9909,\n",
            "        0.9930, 0.9921, 0.9927, 0.9901, 0.9931, 0.9914, 0.9932, 0.9927, 0.9940,\n",
            "        0.9906, 0.9917, 0.9932, 0.9923, 0.9906, 0.9915, 0.9931, 0.9934, 0.9910,\n",
            "        0.9946, 0.9922, 0.9931, 0.9920, 0.9920, 0.9910, 0.9910, 0.9908, 0.9919,\n",
            "        0.9926, 0.9902, 0.9906, 0.9933, 0.9925, 0.9914, 0.9912, 0.9925, 0.9932,\n",
            "        0.9904, 0.9940, 0.9919, 0.9900, 0.9926, 0.9911, 0.9926, 0.9955, 0.9924,\n",
            "        0.9916, 0.9939, 0.9916, 0.9928, 0.9925, 0.9938, 0.9905, 0.9925, 0.9914,\n",
            "        0.9918, 0.9919, 0.9926, 0.9918, 0.9915, 0.9928, 0.9931, 0.9914, 0.9934,\n",
            "        0.9914, 0.9912, 0.9913, 0.9913, 0.9926, 0.9909, 0.9934, 0.9914, 0.9923,\n",
            "        0.9915, 0.9910, 0.9916, 0.9924, 0.9913, 0.9933, 0.9911, 0.9933, 0.9924,\n",
            "        0.9931, 0.9915, 0.9926, 0.9921, 0.9899, 0.9919, 0.9923, 0.9930, 0.9923,\n",
            "        0.9912, 0.9939, 0.9936, 0.9932, 0.9917, 0.9916, 0.9902, 0.9919, 0.9935,\n",
            "        0.9921, 0.9923, 0.9904, 0.9939, 0.9909, 0.9918, 0.9942, 0.9921, 0.9946,\n",
            "        0.9947, 0.9925, 0.9910, 0.9928, 0.9937, 0.9922, 0.9942, 0.9918, 0.9917,\n",
            "        0.9933, 0.9931, 0.9949, 0.9912, 0.9943, 0.9953, 0.9910, 0.9933, 0.9921,\n",
            "        0.9920, 0.9920, 0.9923, 0.9929, 0.9959, 0.9918, 0.9933, 0.9907, 0.9929,\n",
            "        0.9922, 0.9924, 0.9906, 0.9945, 0.9937, 0.9940, 0.9924, 0.9909, 0.9901,\n",
            "        0.9910, 0.9917, 0.9916, 0.9922, 0.9916, 0.9937, 0.9931, 0.9928, 0.9912,\n",
            "        0.9905, 0.9914, 0.9924, 0.9917])), ('module.encoder_q.layer3.0.bn2.bias', tensor([ 3.7128e-04,  1.6462e-04, -5.6192e-04, -8.5036e-04,  1.3951e-04,\n",
            "        -3.7953e-04,  6.5633e-04, -8.5504e-04,  3.0017e-04, -1.3013e-03,\n",
            "         4.9750e-04,  7.6782e-04, -5.5312e-05, -4.1162e-04,  2.0839e-03,\n",
            "         1.2145e-03,  1.9905e-03,  1.7683e-03,  2.8950e-03,  3.9028e-04,\n",
            "        -5.3724e-04, -1.0601e-03,  8.9206e-04, -1.0122e-03,  6.4246e-04,\n",
            "         9.4643e-04,  1.7856e-04, -1.1025e-03, -1.3332e-03,  2.1648e-04,\n",
            "         2.2037e-03, -4.7594e-04, -8.3049e-04, -5.0787e-04,  6.9355e-04,\n",
            "        -8.7921e-04, -2.2307e-03, -2.4270e-04,  2.2755e-04, -4.3153e-04,\n",
            "        -1.4552e-03,  1.0466e-04, -1.4304e-03, -5.1928e-04, -6.1331e-04,\n",
            "        -1.5423e-03,  1.0172e-03, -1.3298e-03, -3.5688e-04, -2.1228e-03,\n",
            "         3.0382e-04,  1.1954e-03,  4.3415e-04,  4.8557e-04, -3.9969e-04,\n",
            "         4.2009e-04, -6.8827e-04,  3.5540e-03,  2.9622e-04, -4.5218e-04,\n",
            "         2.5284e-04,  1.8284e-04,  4.7277e-04, -1.0824e-03, -3.5998e-03,\n",
            "        -9.0595e-04,  7.9608e-05, -1.7998e-04,  7.4055e-04,  1.1734e-03,\n",
            "         2.3868e-03,  1.5065e-04, -1.0942e-03,  7.2924e-05,  2.1281e-04,\n",
            "         7.7272e-04,  5.7315e-04, -2.2325e-04,  2.2946e-03, -7.8608e-04,\n",
            "         2.1296e-04, -1.6638e-05,  1.6855e-03,  4.1329e-04,  3.7599e-04,\n",
            "         1.5707e-03, -1.0188e-03, -1.0133e-03,  1.1030e-03,  3.2864e-04,\n",
            "        -1.1498e-03,  1.8977e-04, -1.3802e-03, -7.4404e-04,  8.1054e-04,\n",
            "         1.9465e-03,  1.6079e-03,  7.5399e-04, -5.3838e-04, -1.7470e-04,\n",
            "         8.8630e-04,  1.2163e-03, -3.7168e-04,  1.9425e-04, -9.1540e-04,\n",
            "         8.4394e-04, -7.1681e-06,  5.2151e-04, -7.3099e-04, -5.8141e-04,\n",
            "        -4.2028e-04, -9.9679e-05, -1.6807e-03, -2.4845e-04,  1.2915e-03,\n",
            "        -1.2869e-04, -1.0683e-03,  2.9183e-03,  1.0045e-03, -4.2360e-04,\n",
            "        -3.3431e-04,  2.6506e-04, -1.2757e-03, -3.3976e-04, -9.9071e-04,\n",
            "        -2.9567e-04, -1.8405e-03, -1.2581e-03, -1.1436e-03,  1.0430e-03,\n",
            "        -1.9385e-04, -1.5748e-03, -1.3532e-03,  8.9272e-04,  8.8220e-04,\n",
            "        -8.5032e-04,  1.7797e-03,  3.5118e-04, -3.9098e-04, -2.6489e-04,\n",
            "         1.2357e-04, -1.5512e-04,  1.0114e-03, -4.8671e-04, -9.1033e-04,\n",
            "         6.4878e-04, -6.1836e-04, -5.9959e-04,  6.2194e-04,  1.9029e-04,\n",
            "        -1.1787e-03,  1.7973e-03, -4.6687e-04, -1.3750e-03, -7.7433e-04,\n",
            "         1.4474e-03, -1.6303e-03, -1.0591e-04,  1.7341e-03,  1.7834e-03,\n",
            "        -5.6677e-04,  1.9506e-03,  6.4318e-04, -5.9975e-04, -1.6172e-03,\n",
            "        -6.9557e-04,  1.1939e-03, -1.9352e-03,  1.7309e-04, -4.4900e-04,\n",
            "         5.9346e-04,  8.0286e-04,  1.2944e-03,  8.9474e-04, -5.6532e-05,\n",
            "        -1.5343e-03,  5.6168e-05,  4.3208e-04,  1.5869e-03,  2.5453e-04,\n",
            "        -1.8299e-04, -2.3475e-03, -9.1178e-06,  3.8182e-04, -1.3681e-03,\n",
            "        -1.0589e-03,  1.6944e-04, -3.4996e-04,  2.1389e-04,  1.0302e-03,\n",
            "         3.2402e-04,  1.1596e-03, -3.7515e-04,  2.9424e-04, -3.4638e-04,\n",
            "        -3.2696e-04, -1.1817e-04, -1.1281e-04,  6.0795e-04,  1.1678e-03,\n",
            "         5.9403e-04,  8.1150e-04, -1.1401e-03, -1.3154e-03,  2.3670e-03,\n",
            "        -7.2039e-04,  1.7208e-03,  1.8621e-03, -5.6038e-06,  4.9637e-04,\n",
            "        -1.0209e-03,  3.4826e-04,  7.7922e-05, -4.7114e-04,  4.0151e-04,\n",
            "         1.1984e-03, -5.7455e-04, -6.7082e-04,  1.6052e-03, -9.4514e-04,\n",
            "         6.3668e-04,  2.7563e-03, -2.1113e-04, -1.4685e-03,  7.2534e-04,\n",
            "        -1.2701e-03, -2.1358e-04,  5.4299e-04,  1.0809e-04,  1.3057e-03,\n",
            "        -1.2530e-03,  2.2008e-04, -2.0053e-03,  1.2794e-04, -2.4759e-04,\n",
            "        -1.6594e-04, -5.9372e-04,  2.5973e-03,  2.7820e-04,  1.1666e-03,\n",
            "        -9.8518e-04, -1.2951e-03, -1.2008e-03,  2.0521e-04, -1.5550e-03,\n",
            "        -3.1572e-04,  6.0009e-04,  1.6083e-04,  1.9201e-03,  3.2375e-03,\n",
            "         1.1647e-03, -1.1778e-03, -4.8324e-05,  4.1920e-05, -1.3719e-04,\n",
            "         4.3907e-04])), ('module.encoder_q.layer3.0.bn2.running_mean', tensor([-2.4147e-01,  7.0008e-02,  3.5468e-01, -3.9443e-01, -1.0695e+00,\n",
            "        -8.7120e-01, -8.9001e-01, -9.8409e-01, -4.1451e-01,  8.8305e-01,\n",
            "         1.0346e-01,  7.9714e-01, -4.7960e-01, -9.4056e-01, -2.6856e-01,\n",
            "        -2.6176e-01,  1.6886e-01,  5.4332e-01, -8.4376e-01,  6.9453e-01,\n",
            "        -6.4008e-01,  1.7642e+00, -3.6277e-01, -6.4207e-01,  1.0923e-02,\n",
            "        -3.6972e-01,  2.8253e-01,  1.0334e+00,  2.7967e-01,  3.1031e-01,\n",
            "        -4.5773e-01,  1.0217e+00,  8.8301e-01, -2.5227e-01,  1.9390e-01,\n",
            "         8.2561e-02,  1.1868e-01, -2.3958e-01,  4.6594e-01,  2.8015e-01,\n",
            "        -1.8656e-01,  4.3594e-01, -6.3624e-02,  1.3176e-01,  6.1803e-01,\n",
            "        -1.1847e-01, -5.9773e-01,  5.6176e-01,  3.5147e-02, -5.4538e-01,\n",
            "         7.0235e-01, -7.9124e-02,  1.5036e-01, -3.9443e-01, -8.2104e-01,\n",
            "         2.2236e-01, -2.8197e-01, -1.9286e-02, -2.3700e-01,  2.2613e-01,\n",
            "         5.3809e-01,  1.8854e-03,  1.6512e-01,  4.3126e-02,  3.8727e-01,\n",
            "        -2.2410e-01,  2.9507e-01,  4.4354e-01, -2.4260e-01, -5.0399e-01,\n",
            "         3.8508e-01, -5.4180e-01, -5.3264e-01, -5.3903e-01,  6.0551e-01,\n",
            "        -1.6316e-01, -2.8777e-02,  5.5842e-01,  2.0900e-01, -4.5467e-01,\n",
            "         6.4917e-01,  7.6149e-02, -7.1652e-03,  6.8809e-03,  3.8968e-01,\n",
            "        -1.4209e-01, -6.6235e-01, -1.1765e+00, -5.9012e-02, -1.3161e-01,\n",
            "        -7.4360e-02,  3.7000e-02,  2.4171e-01, -1.5002e-01,  1.9963e-02,\n",
            "         3.0925e-01, -6.6530e-02, -7.6518e-02,  6.9783e-01, -4.6437e-01,\n",
            "        -5.9154e-01, -3.1332e-02,  1.2698e+00, -5.9265e-03, -5.1886e-02,\n",
            "        -2.8809e-02, -2.8655e-02,  5.6227e-01,  7.0434e-01,  1.4160e-02,\n",
            "         1.9271e-01, -3.4903e-01, -5.4453e-01, -3.1976e-01, -4.7533e-02,\n",
            "         1.5975e-01, -2.8135e-01,  3.2999e-01,  6.0042e-01,  2.9422e-01,\n",
            "        -3.0845e-01, -1.5236e-01, -7.5743e-01,  3.2897e-01,  5.2359e-01,\n",
            "         6.5231e-02,  1.7119e-01,  1.0222e+00,  3.6342e-01,  5.9645e-01,\n",
            "        -3.2331e-01,  8.5388e-01, -7.8003e-01, -1.2132e-01,  2.0878e-02,\n",
            "        -7.1354e-01,  1.5528e-03, -9.9182e-01, -3.5975e-01,  1.1361e-01,\n",
            "         3.4281e-01, -6.1610e-01,  8.7472e-03, -3.0241e-01, -4.4329e-01,\n",
            "         1.9211e-01, -1.2135e-01,  6.8073e-01, -1.8573e-01,  2.2347e-01,\n",
            "        -1.9989e-01, -3.9320e-02,  1.9926e-01, -9.1545e-01,  3.1127e-01,\n",
            "        -1.0595e+00,  4.3113e-01, -4.1912e-02, -1.5771e-02, -2.4148e-01,\n",
            "        -2.6168e-01,  5.6241e-01,  2.2676e-01,  2.1112e-01,  9.8712e-01,\n",
            "         1.1114e+00,  1.7445e-02,  1.7625e-01,  2.4980e-01, -1.2163e-01,\n",
            "        -2.7616e-01, -2.0040e-01,  9.2398e-01, -5.8205e-01,  8.9013e-02,\n",
            "         2.2659e-01, -6.6143e-01,  6.9489e-01,  3.5875e-01, -2.4301e-01,\n",
            "        -3.4197e-01, -5.3266e-01,  4.7671e-01, -4.5387e-02, -4.6448e-01,\n",
            "        -4.7478e-01,  8.0170e-01,  1.7489e-01, -1.3546e-01,  4.1691e-01,\n",
            "         9.4330e-02, -4.9025e-02, -4.3923e-01, -1.3586e-01, -6.7682e-02,\n",
            "         1.9864e-01, -4.2688e-01,  3.9232e-01, -7.5726e-02,  2.8931e-01,\n",
            "        -6.3891e-02,  6.4306e-02, -5.9081e-02,  3.5045e-01, -4.0024e-01,\n",
            "         5.7593e-01,  8.4536e-02, -3.7459e-01,  5.1569e-01, -8.5081e-01,\n",
            "         7.4710e-01,  5.1585e-01,  1.1495e+00, -1.7137e-01,  4.3815e-01,\n",
            "        -5.3396e-01,  9.4658e-03,  8.7705e-02,  1.5076e-01, -4.3825e-01,\n",
            "         4.3042e-01,  4.5632e-02, -6.0121e-01,  6.5181e-01, -5.6895e-01,\n",
            "         5.3827e-01, -2.9373e-01, -2.4835e-01, -6.6279e-01,  8.8969e-02,\n",
            "         3.7036e-01,  2.5043e-01, -1.6438e-01, -7.2387e-02, -5.5567e-01,\n",
            "         5.2760e-01, -7.9952e-02, -1.2140e-01,  3.4041e-01,  4.4844e-01,\n",
            "        -5.2269e-01, -8.2311e-01, -2.3992e-01, -2.0036e-01, -3.5313e-01,\n",
            "        -1.0366e+00, -3.5095e-01, -3.9970e-01, -5.0212e-01, -4.5592e-01,\n",
            "         3.3246e-01,  5.8568e-01,  3.0907e-01, -6.4686e-01, -1.6679e-01,\n",
            "         3.8182e-02])), ('module.encoder_q.layer3.0.bn2.running_var', tensor([0.5687, 0.6261, 0.8554, 0.6920, 0.9252, 0.5829, 1.1883, 1.4464, 0.4937,\n",
            "        1.2518, 0.9455, 0.6324, 0.5488, 1.2054, 0.5628, 0.6501, 0.4805, 0.6744,\n",
            "        0.7075, 0.6094, 0.9347, 1.5081, 0.6057, 1.0402, 0.9675, 0.5752, 0.6476,\n",
            "        1.5658, 0.5371, 0.8461, 1.3017, 0.6767, 0.9875, 0.4900, 0.9587, 0.6509,\n",
            "        0.9312, 0.9791, 0.5766, 1.3676, 0.6542, 0.7103, 0.6343, 0.9085, 1.2010,\n",
            "        0.4609, 0.5663, 0.7186, 0.6049, 1.0318, 0.9543, 0.5704, 1.5813, 0.6081,\n",
            "        0.9525, 1.0112, 0.6240, 0.5655, 0.5188, 1.7717, 0.5795, 0.9687, 1.0504,\n",
            "        0.4894, 0.7322, 0.5422, 0.6926, 1.0498, 0.5949, 0.8501, 0.6687, 0.5526,\n",
            "        0.5969, 0.6903, 1.1727, 0.5706, 0.6640, 1.0079, 0.7033, 1.0205, 0.8791,\n",
            "        0.9815, 0.7413, 1.3325, 0.7300, 0.6604, 0.9241, 1.4599, 0.6467, 0.9826,\n",
            "        0.8057, 0.4218, 0.6551, 0.9568, 0.5647, 0.7811, 0.7133, 0.8203, 0.6376,\n",
            "        0.9171, 1.2123, 1.1282, 3.7802, 0.7338, 1.0832, 0.5881, 0.6323, 1.3333,\n",
            "        0.5202, 0.7050, 0.7144, 0.6022, 1.0625, 0.7076, 0.5682, 0.6214, 0.7721,\n",
            "        0.4545, 1.2749, 0.5419, 0.4508, 0.5724, 1.4535, 1.0979, 0.8041, 0.5109,\n",
            "        0.9533, 1.1093, 0.7771, 0.7268, 0.6637, 0.9472, 0.8292, 0.7906, 0.4877,\n",
            "        0.6155, 0.4982, 1.9542, 0.6536, 1.3843, 0.6082, 1.2898, 0.7136, 0.9602,\n",
            "        0.5772, 0.7107, 0.8650, 1.2167, 0.6730, 0.7176, 0.6556, 0.7866, 1.1646,\n",
            "        1.4863, 0.9135, 0.9521, 0.7065, 0.8268, 0.5290, 0.6264, 1.3791, 0.4986,\n",
            "        0.7417, 1.1585, 0.8637, 3.3138, 0.8757, 0.7697, 0.6199, 0.9508, 0.4878,\n",
            "        1.8022, 0.6794, 1.3837, 0.7767, 0.6999, 0.5914, 1.0302, 0.6280, 0.9228,\n",
            "        0.6425, 0.8009, 0.6269, 0.7424, 0.8187, 0.5958, 0.6566, 0.9099, 0.8245,\n",
            "        0.9551, 0.6530, 0.7612, 0.6104, 0.5598, 0.5255, 0.9380, 0.8704, 0.9852,\n",
            "        0.8839, 0.6664, 0.5012, 1.3087, 0.6547, 0.8644, 0.5708, 0.9093, 0.5514,\n",
            "        0.6423, 1.2216, 0.7604, 1.0660, 1.3588, 1.5266, 0.8354, 0.4628, 0.9853,\n",
            "        0.6964, 0.7090, 0.7357, 0.7170, 0.9096, 0.6316, 1.3091, 1.2676, 1.0056,\n",
            "        0.5569, 1.1735, 0.6452, 1.4265, 0.6943, 0.7158, 0.4744, 0.4764, 0.6904,\n",
            "        0.7563, 1.8715, 0.4907, 0.6874, 0.8031, 0.5649, 0.6608, 1.6679, 0.7522,\n",
            "        0.6348, 0.7206, 0.7657, 0.7260, 0.6160, 1.2805, 1.0002, 0.8044, 0.5609,\n",
            "        0.9562, 1.3038, 0.6177, 0.7599])), ('module.encoder_q.layer3.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.0.conv3.weight', tensor([[[[-0.0623]],\n",
            "\n",
            "         [[-0.0840]],\n",
            "\n",
            "         [[ 0.0590]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0202]],\n",
            "\n",
            "         [[-0.0021]],\n",
            "\n",
            "         [[ 0.0549]]],\n",
            "\n",
            "\n",
            "        [[[-0.1044]],\n",
            "\n",
            "         [[ 0.0371]],\n",
            "\n",
            "         [[ 0.0675]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0239]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[-0.0499]]],\n",
            "\n",
            "\n",
            "        [[[-0.0305]],\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         [[ 0.0555]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[-0.0240]],\n",
            "\n",
            "         [[ 0.0273]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0107]],\n",
            "\n",
            "         [[-0.0111]],\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0153]],\n",
            "\n",
            "         [[ 0.0035]],\n",
            "\n",
            "         [[-0.0869]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0398]],\n",
            "\n",
            "         [[ 0.0025]],\n",
            "\n",
            "         [[-0.0034]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0394]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         [[ 0.0277]]],\n",
            "\n",
            "\n",
            "        [[[-0.0237]],\n",
            "\n",
            "         [[-0.0579]],\n",
            "\n",
            "         [[-0.0359]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0107]],\n",
            "\n",
            "         [[-0.0250]],\n",
            "\n",
            "         [[-0.0572]]]])), ('module.encoder_q.layer3.0.bn3.weight', tensor([0.9922, 0.9915, 0.9916,  ..., 0.9927, 0.9914, 0.9924])), ('module.encoder_q.layer3.0.bn3.bias', tensor([-0.0002,  0.0008, -0.0001,  ...,  0.0002, -0.0008,  0.0003])), ('module.encoder_q.layer3.0.bn3.running_mean', tensor([-4.3010e-01,  1.4717e-04, -1.1836e-01,  ..., -4.9886e-02,\n",
            "        -2.6171e-01,  3.3210e-01])), ('module.encoder_q.layer3.0.bn3.running_var', tensor([0.1354, 0.3448, 0.1651,  ..., 0.1550, 0.3494, 0.2561])), ('module.encoder_q.layer3.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.0.downsample.0.weight', tensor([[[[ 0.0391]],\n",
            "\n",
            "         [[-0.0578]],\n",
            "\n",
            "         [[ 0.0369]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0681]],\n",
            "\n",
            "         [[ 0.0724]],\n",
            "\n",
            "         [[ 0.0510]]],\n",
            "\n",
            "\n",
            "        [[[-0.0454]],\n",
            "\n",
            "         [[ 0.0293]],\n",
            "\n",
            "         [[ 0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0065]],\n",
            "\n",
            "         [[-0.0057]],\n",
            "\n",
            "         [[-0.0295]]],\n",
            "\n",
            "\n",
            "        [[[-0.0642]],\n",
            "\n",
            "         [[ 0.0127]],\n",
            "\n",
            "         [[ 0.0122]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0302]],\n",
            "\n",
            "         [[-0.0518]],\n",
            "\n",
            "         [[-0.0494]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0062]],\n",
            "\n",
            "         [[-0.0611]],\n",
            "\n",
            "         [[ 0.0287]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0239]],\n",
            "\n",
            "         [[-0.0299]],\n",
            "\n",
            "         [[-0.0092]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0029]],\n",
            "\n",
            "         [[ 0.0280]],\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0107]],\n",
            "\n",
            "         [[-0.0247]],\n",
            "\n",
            "         [[-0.0029]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0635]],\n",
            "\n",
            "         [[ 0.0539]],\n",
            "\n",
            "         [[ 0.0134]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0886]],\n",
            "\n",
            "         [[ 0.0526]],\n",
            "\n",
            "         [[ 0.0187]]]])), ('module.encoder_q.layer3.0.downsample.1.weight', tensor([0.9921, 0.9926, 0.9923,  ..., 0.9920, 0.9917, 0.9929])), ('module.encoder_q.layer3.0.downsample.1.bias', tensor([-0.0002,  0.0008, -0.0001,  ...,  0.0002, -0.0008,  0.0003])), ('module.encoder_q.layer3.0.downsample.1.running_mean', tensor([ 0.2838, -0.3646, -1.0985,  ..., -0.4170, -0.1682,  0.3614])), ('module.encoder_q.layer3.0.downsample.1.running_var', tensor([1.7354, 4.4088, 1.0646,  ..., 1.3100, 1.9604, 1.3918])), ('module.encoder_q.layer3.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.1.conv1.weight', tensor([[[[-0.0212]],\n",
            "\n",
            "         [[-0.0130]],\n",
            "\n",
            "         [[-0.0030]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         [[-0.0871]],\n",
            "\n",
            "         [[ 0.0577]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0057]],\n",
            "\n",
            "         [[-0.1395]],\n",
            "\n",
            "         [[ 0.0931]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0476]],\n",
            "\n",
            "         [[ 0.1442]],\n",
            "\n",
            "         [[-0.0137]]],\n",
            "\n",
            "\n",
            "        [[[-0.0899]],\n",
            "\n",
            "         [[ 0.0246]],\n",
            "\n",
            "         [[-0.0501]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0455]],\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         [[ 0.0176]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0183]],\n",
            "\n",
            "         [[-0.1522]],\n",
            "\n",
            "         [[ 0.0053]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1087]],\n",
            "\n",
            "         [[-0.1305]],\n",
            "\n",
            "         [[ 0.0957]]],\n",
            "\n",
            "\n",
            "        [[[-0.2103]],\n",
            "\n",
            "         [[ 0.0617]],\n",
            "\n",
            "         [[ 0.0431]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1208]],\n",
            "\n",
            "         [[ 0.0568]],\n",
            "\n",
            "         [[-0.1096]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0324]],\n",
            "\n",
            "         [[ 0.0397]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1091]],\n",
            "\n",
            "         [[ 0.0041]],\n",
            "\n",
            "         [[ 0.0784]]]])), ('module.encoder_q.layer3.1.bn1.weight', tensor([0.9931, 0.9927, 0.9929, 0.9933, 0.9925, 0.9925, 0.9917, 0.9914, 0.9927,\n",
            "        0.9927, 0.9913, 0.9925, 0.9925, 0.9923, 0.9929, 0.9921, 0.9923, 0.9941,\n",
            "        0.9922, 0.9915, 0.9931, 0.9931, 0.9927, 0.9916, 0.9919, 0.9919, 0.9922,\n",
            "        0.9924, 0.9940, 0.9942, 0.9930, 0.9906, 0.9926, 0.9921, 0.9923, 0.9909,\n",
            "        0.9917, 0.9923, 0.9918, 0.9912, 0.9907, 0.9936, 0.9922, 0.9909, 0.9920,\n",
            "        0.9922, 0.9917, 0.9938, 0.9915, 0.9931, 0.9916, 0.9913, 0.9919, 0.9923,\n",
            "        0.9930, 0.9916, 0.9938, 0.9925, 0.9915, 0.9916, 0.9910, 0.9947, 0.9897,\n",
            "        0.9945, 0.9906, 0.9919, 0.9920, 0.9923, 0.9926, 0.9913, 0.9911, 0.9930,\n",
            "        0.9900, 0.9922, 0.9907, 0.9946, 0.9920, 0.9925, 0.9913, 0.9913, 0.9938,\n",
            "        0.9924, 0.9909, 0.9923, 0.9922, 0.9913, 0.9917, 0.9917, 0.9904, 0.9918,\n",
            "        0.9922, 0.9907, 0.9923, 0.9922, 0.9933, 0.9925, 0.9915, 0.9932, 0.9921,\n",
            "        0.9922, 0.9921, 0.9927, 0.9922, 0.9918, 0.9921, 0.9932, 0.9914, 0.9912,\n",
            "        0.9923, 0.9937, 0.9931, 0.9925, 0.9922, 0.9929, 0.9921, 0.9942, 0.9928,\n",
            "        0.9923, 0.9930, 0.9918, 0.9911, 0.9912, 0.9937, 0.9924, 0.9931, 0.9921,\n",
            "        0.9916, 0.9935, 0.9895, 0.9923, 0.9923, 0.9924, 0.9909, 0.9915, 0.9907,\n",
            "        0.9928, 0.9922, 0.9911, 0.9930, 0.9921, 0.9917, 0.9924, 0.9952, 0.9937,\n",
            "        0.9930, 0.9914, 0.9923, 0.9927, 0.9910, 0.9935, 0.9917, 0.9932, 0.9932,\n",
            "        0.9929, 0.9918, 0.9936, 0.9913, 0.9915, 0.9932, 0.9909, 0.9913, 0.9940,\n",
            "        0.9940, 0.9936, 0.9921, 0.9940, 0.9897, 0.9938, 0.9918, 0.9934, 0.9922,\n",
            "        0.9912, 0.9935, 0.9925, 0.9913, 0.9921, 0.9933, 0.9926, 0.9935, 0.9926,\n",
            "        0.9911, 0.9918, 0.9895, 0.9926, 0.9912, 0.9931, 0.9932, 0.9918, 0.9929,\n",
            "        0.9907, 0.9931, 0.9913, 0.9920, 0.9922, 0.9901, 0.9927, 0.9936, 0.9923,\n",
            "        0.9931, 0.9922, 0.9933, 0.9915, 0.9934, 0.9928, 0.9910, 0.9924, 0.9934,\n",
            "        0.9927, 0.9923, 0.9911, 0.9922, 0.9917, 0.9916, 0.9922, 0.9907, 0.9921,\n",
            "        0.9923, 0.9926, 0.9927, 0.9907, 0.9935, 0.9923, 0.9905, 0.9923, 0.9907,\n",
            "        0.9920, 0.9915, 0.9931, 0.9926, 0.9940, 0.9924, 0.9925, 0.9926, 0.9909,\n",
            "        0.9927, 0.9931, 0.9930, 0.9912, 0.9925, 0.9922, 0.9917, 0.9931, 0.9936,\n",
            "        0.9914, 0.9917, 0.9932, 0.9919, 0.9921, 0.9955, 0.9922, 0.9910, 0.9924,\n",
            "        0.9915, 0.9917, 0.9927, 0.9940])), ('module.encoder_q.layer3.1.bn1.bias', tensor([-1.4760e-03,  4.3856e-04,  5.3612e-04,  1.3627e-03,  3.7955e-04,\n",
            "        -3.7006e-04, -3.3505e-04, -1.8756e-04,  1.3953e-03,  1.2658e-03,\n",
            "        -1.1530e-03, -4.0555e-04,  2.7206e-04,  4.7970e-04,  1.1874e-03,\n",
            "        -4.9762e-04, -6.8939e-04,  2.0925e-03, -1.9941e-04,  6.9714e-05,\n",
            "         5.3844e-04, -3.2115e-04,  1.2588e-05, -3.3478e-04, -4.1760e-04,\n",
            "         2.0252e-04,  1.0075e-03, -1.2422e-03,  5.3475e-04,  1.1086e-03,\n",
            "         1.9800e-03, -1.8139e-03, -8.9107e-04, -4.0091e-04,  8.0087e-04,\n",
            "         9.2055e-04, -9.3771e-04,  6.1189e-04,  2.1059e-04,  8.4724e-06,\n",
            "        -1.5564e-03,  8.8363e-04, -4.2005e-04,  3.4309e-04, -8.4615e-04,\n",
            "         6.9202e-04,  2.5584e-04,  9.5221e-04, -3.7913e-04,  9.8718e-04,\n",
            "         3.2195e-04,  5.5804e-04, -1.1394e-03,  3.4639e-04,  3.3626e-04,\n",
            "        -4.6936e-04,  1.2669e-03, -7.7618e-04,  2.5548e-04, -3.4959e-04,\n",
            "        -7.7654e-04,  9.7246e-04, -1.5195e-03,  1.7055e-03, -9.3780e-04,\n",
            "        -5.2280e-04, -5.4995e-04,  6.2398e-04, -2.2306e-04, -6.4194e-04,\n",
            "        -1.5468e-03,  1.2154e-03, -7.3540e-04,  1.1241e-03, -2.2671e-03,\n",
            "         1.8140e-03,  8.4655e-04,  2.6864e-05, -9.4078e-04, -7.8504e-04,\n",
            "        -4.0960e-04, -3.4744e-04, -5.0064e-04,  7.6559e-04,  3.1483e-04,\n",
            "         3.1569e-04, -4.0338e-05, -7.2139e-04, -1.3881e-03, -2.1773e-04,\n",
            "         4.8579e-04, -9.8713e-04,  5.7674e-04, -3.8380e-04,  1.9826e-03,\n",
            "        -4.4778e-05, -2.1045e-04,  4.9659e-04,  3.2662e-04, -1.2869e-04,\n",
            "        -1.1287e-04,  6.8498e-04, -6.0255e-04, -7.1801e-04,  3.9406e-04,\n",
            "        -1.7506e-04,  1.0316e-04,  3.8616e-04,  5.3941e-04, -4.9577e-04,\n",
            "         3.3379e-04, -1.1743e-04,  8.9963e-05, -3.8291e-04, -8.5462e-04,\n",
            "         1.8198e-03,  1.1154e-03,  3.1673e-04,  5.8184e-04, -9.7255e-04,\n",
            "        -1.6933e-03, -1.0298e-03,  2.4529e-04, -1.0722e-03,  1.3247e-03,\n",
            "         9.9598e-04, -4.8950e-04,  2.8950e-04, -4.5046e-04, -2.0748e-04,\n",
            "         2.6039e-05, -7.1715e-04, -4.8028e-04, -1.7308e-03, -5.7702e-04,\n",
            "         1.1039e-04, -2.3461e-04, -1.2443e-03,  6.3443e-04, -1.3734e-04,\n",
            "         1.9011e-04,  4.8101e-04,  1.8839e-03,  8.0441e-04,  7.9303e-04,\n",
            "        -9.0802e-04, -6.3476e-04,  2.3580e-04, -7.8898e-04,  1.9712e-03,\n",
            "        -1.1532e-04, -5.1122e-04,  3.2898e-04, -4.2666e-04,  3.0193e-04,\n",
            "         1.3289e-03,  1.1466e-03, -8.9973e-04,  1.0289e-03, -2.0232e-03,\n",
            "        -3.0014e-04,  5.6062e-04,  1.2296e-03, -5.1186e-04, -3.4353e-04,\n",
            "         9.4010e-04, -1.2110e-03,  3.6727e-04, -3.7038e-04,  1.1553e-03,\n",
            "         9.8952e-04, -1.0972e-03,  9.7344e-04,  6.9991e-04, -7.3126e-04,\n",
            "        -1.0277e-03,  1.1061e-03, -1.3160e-04,  4.6369e-04, -1.9858e-04,\n",
            "        -1.0720e-03,  4.2089e-04, -1.4904e-03,  1.0688e-03, -1.9728e-04,\n",
            "        -5.3993e-05,  3.8302e-04,  8.7366e-04, -3.8407e-04, -1.1448e-03,\n",
            "         6.3757e-04, -1.2401e-03, -1.6469e-03, -1.1839e-03, -1.8341e-03,\n",
            "         7.5887e-04,  1.7325e-03,  1.4866e-04,  1.1272e-04,  3.9520e-04,\n",
            "         9.9582e-04,  4.1936e-04, -4.5944e-04,  5.8870e-04, -1.0300e-04,\n",
            "         9.6703e-04,  3.4623e-04,  1.8910e-04,  7.5063e-04, -8.7524e-04,\n",
            "        -2.2738e-04,  1.2508e-03, -2.0391e-05, -7.2577e-04, -7.8915e-04,\n",
            "         4.1904e-05,  4.3883e-04, -3.1191e-04,  4.4143e-04,  6.8677e-04,\n",
            "         5.8656e-04, -1.6132e-05, -7.6209e-04,  2.5897e-04, -8.4314e-04,\n",
            "        -4.7948e-05, -8.7285e-04,  1.8199e-04,  1.6588e-04,  1.4571e-03,\n",
            "         5.6156e-04,  4.9063e-04,  3.2088e-05, -2.1459e-03, -2.2877e-04,\n",
            "         1.8394e-03,  1.8121e-03, -5.7177e-04,  1.3879e-03,  1.3091e-04,\n",
            "        -3.1408e-04,  1.4414e-04,  3.6527e-04, -8.9151e-04, -2.3666e-03,\n",
            "         5.8886e-04,  7.3523e-04,  8.9301e-04,  6.2738e-04,  4.0909e-04,\n",
            "        -8.4956e-04,  6.2466e-04, -4.3547e-04,  4.2627e-04,  8.8650e-04,\n",
            "         9.5311e-04])), ('module.encoder_q.layer3.1.bn1.running_mean', tensor([ 0.5771,  0.8719,  0.4484,  0.8385, -1.6001, -2.2236, -1.6529,  3.1766,\n",
            "        -2.4919, -0.2333, -1.1766,  0.3075, -0.1295,  0.5225, -5.4219,  0.5734,\n",
            "         1.1737,  0.1584, -0.0546, -1.8375, -0.1765,  0.0427,  0.6095, -1.9573,\n",
            "        -1.8692,  1.4290,  0.5033,  0.7031,  2.0826,  0.4615, -0.4948,  0.2601,\n",
            "        -4.9771,  1.0210, -0.5061,  1.0161,  0.8202,  1.3166,  1.8863,  0.2062,\n",
            "        -0.2940, -0.4746,  0.5606,  2.2011, -0.2489,  0.2964, -0.0845,  1.1423,\n",
            "         1.6047, -0.6845,  0.5180,  0.8516, -1.1493, -1.3216,  1.1161, -1.6029,\n",
            "        -0.3123, -1.1539, -1.1444, -0.5062,  0.5230, -1.5263,  0.9719, -0.8221,\n",
            "         0.9699, -0.1357,  1.2674, -0.6945, -1.9027, -0.8022,  0.9751, -2.6886,\n",
            "        -0.2225, -0.1207, -0.6257,  0.0451,  0.9686,  0.7721,  0.5161, -1.1734,\n",
            "        -0.3003, -0.5826,  2.6430, -0.1396, -0.9255,  0.8802,  1.4083,  0.3111,\n",
            "        -0.7759,  1.0845, -1.8213,  2.6818, -1.3905, -1.8904, -0.1428,  0.5583,\n",
            "         0.8929,  2.5047, -0.5765, -0.7551, -2.0593,  0.1090, -1.7094, -0.5940,\n",
            "        -1.0927,  1.6371,  2.3766,  0.2044, -2.8166,  0.2399, -2.0175,  0.0550,\n",
            "        -1.3391, -2.5159, -1.3172,  1.1175, -1.5534, -0.5887, -0.7268,  0.6631,\n",
            "        -2.1543, -0.7489,  1.0230, -0.5767,  1.0051, -0.2480,  1.0925,  0.8220,\n",
            "         0.5711,  0.6859, -0.3304,  0.4655,  0.9412, -0.2662,  1.3071,  0.8279,\n",
            "         0.1488, -2.4669, -1.4441,  2.8639,  0.0209, -0.9372,  0.6400, -0.0659,\n",
            "        -1.3730,  0.9486,  1.4047,  0.2792, -2.3552,  0.2901,  1.0651,  1.0311,\n",
            "         0.1799, -1.5343, -0.2563,  0.6373, -1.5723, -0.1391, -1.1962, -0.2576,\n",
            "        -2.0204,  0.4597, -0.7375,  0.7699,  1.4466,  1.4983,  0.6884,  0.6735,\n",
            "         0.0292, -1.5722, -0.6832,  0.4261,  0.5254,  0.6428,  2.5952,  2.6304,\n",
            "        -1.2581, -0.3705, -0.2210, -0.5829, -0.2987,  0.2727,  0.0989, -2.4209,\n",
            "        -0.6691, -0.2218, -3.2961,  1.4424,  2.3175, -0.5128,  1.5936,  0.6165,\n",
            "        -0.7146, -0.9224, -0.5371,  0.5587,  1.9301,  2.2727, -0.4702, -2.3828,\n",
            "        -1.5869, -0.6482,  0.3270,  1.2511,  1.6476, -1.5331, -2.9163, -2.0557,\n",
            "        -0.8247,  1.4988,  1.5455, -0.4466, -1.4665, -1.0346,  3.0528,  1.6488,\n",
            "        -1.6186, -1.4822,  0.9652,  1.3377,  1.2174, -2.0688,  0.4822,  0.7245,\n",
            "         1.4196, -2.3323,  1.3915, -0.7769,  1.2254, -1.5677,  2.8374, -2.5242,\n",
            "         0.2100,  1.2944, -1.4927, -0.2926, -2.3634,  2.6257, -0.8719, -0.1737,\n",
            "         0.3200, -2.2301, -0.5117, -1.0061,  0.4225,  0.5766,  1.8463,  0.6868,\n",
            "        -0.1997, -0.0657, -1.2116,  1.4259,  1.7098, -1.8589, -0.6522,  0.2525])), ('module.encoder_q.layer3.1.bn1.running_var', tensor([ 5.9001,  3.5869,  6.2052,  4.4208,  5.4647,  4.4670,  6.2029, 11.1664,\n",
            "         8.5191,  8.2293,  5.4445,  5.0166,  7.3855,  4.3794, 16.5328,  7.1821,\n",
            "         6.1263,  4.6754,  4.7998, 10.9728,  3.4934,  4.5538,  4.8173, 10.7300,\n",
            "         3.5810,  4.4534,  5.1731,  4.6038,  4.6117,  4.3056,  8.0267,  5.7967,\n",
            "        12.3055, 10.5862,  7.3290,  4.6356,  5.6361,  3.7607,  4.7025,  5.7444,\n",
            "         5.6382,  4.3621,  4.6680,  4.0441,  9.5383,  4.7572,  5.4577,  6.6580,\n",
            "         5.7091,  6.4330,  8.3093,  4.5570,  4.4698,  4.5536,  5.6204, 14.0031,\n",
            "         5.6094,  6.3341,  6.5388,  6.0464,  3.9207,  7.8197,  7.1153,  3.7017,\n",
            "         6.1958,  8.8157,  6.3217,  3.6623,  9.0989,  5.0455,  4.0510, 18.9881,\n",
            "         5.0581,  5.9996,  9.5165,  5.4319,  7.8151,  4.0090,  4.3886,  4.0978,\n",
            "         5.0020,  4.2325,  4.4787,  4.3998, 11.4675,  6.0577,  5.3209,  6.1581,\n",
            "         4.3966,  5.1986,  8.6429,  5.8725,  9.2640,  7.1843,  5.9827,  5.4173,\n",
            "         4.7318, 10.1700,  4.9921,  4.5269,  4.9815,  3.6013,  4.6374,  6.2427,\n",
            "         5.1618,  5.6964,  3.2557,  4.1638, 20.6351,  7.4653,  5.0564,  4.2734,\n",
            "         6.6985,  4.9644,  4.6174,  5.4596, 23.3805,  5.4225,  5.8937,  4.1482,\n",
            "         9.8948,  4.1499,  4.4876,  6.0302,  4.2633,  8.9236,  5.6522,  4.4323,\n",
            "         5.4073,  8.4239,  5.0454,  5.2810,  5.1066,  7.2426,  8.1908,  4.0532,\n",
            "         5.2779,  4.6502,  4.8648, 13.8738,  4.4532,  5.6728,  4.9615,  4.8502,\n",
            "         5.3153,  3.5969,  4.7061,  7.6971,  7.5617,  6.3308,  7.5776,  4.7983,\n",
            "         9.6205,  7.6571,  4.5302,  5.9090,  3.9226,  4.9449,  3.7575,  5.3437,\n",
            "         4.8841,  8.0866,  5.6270,  7.7212,  5.6207, 14.7560, 10.8768,  4.4571,\n",
            "         7.3712,  8.7901, 13.8608,  4.4845,  6.7770,  6.1169, 15.3155, 10.4251,\n",
            "         8.4687,  5.6000,  5.1532,  4.5546,  4.8109,  3.9913,  5.0519,  4.3661,\n",
            "         5.3767,  4.7579, 13.3825,  4.5882, 11.7896,  4.8278,  5.1469,  5.0516,\n",
            "         3.6461,  4.6625,  3.6129, 16.4643,  8.4289,  4.5186,  3.5217, 13.7922,\n",
            "         4.4074,  4.4774,  4.8835,  5.5941,  4.4369,  8.0320,  4.7118,  6.7611,\n",
            "         4.3386,  5.6486,  7.3860,  7.8912,  5.4711,  3.7675,  5.0872,  7.5897,\n",
            "         8.3669,  7.1533,  9.0016,  5.1082,  6.6750,  7.3055, 11.7403,  4.7704,\n",
            "         4.5478, 15.1603,  4.7338,  4.4238,  4.3708,  5.1176, 11.7384,  6.8761,\n",
            "         5.9316, 10.0875,  4.6522,  4.1823,  3.5815,  5.0959,  6.0915,  3.7582,\n",
            "         4.9972,  6.9805,  5.9577,  3.8892,  4.9418,  4.5137,  4.3707,  4.6938,\n",
            "         6.7548,  6.6973,  4.8216,  6.9433,  7.9305,  4.5419,  5.0670,  9.6660])), ('module.encoder_q.layer3.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.1.conv2.weight', tensor([[[[-7.4887e-03, -3.7785e-02,  3.7206e-02],\n",
            "          [-5.7047e-02,  1.0827e-02, -6.0167e-02],\n",
            "          [-4.0577e-03, -2.1551e-03, -2.4850e-02]],\n",
            "\n",
            "         [[ 3.9643e-02, -3.3702e-02,  6.4932e-03],\n",
            "          [ 6.3825e-02,  3.5915e-02,  2.2037e-02],\n",
            "          [ 3.9756e-02,  2.0384e-02, -3.0195e-02]],\n",
            "\n",
            "         [[ 2.3077e-02,  4.4032e-03, -1.6958e-02],\n",
            "          [-3.9073e-02,  2.8625e-02,  8.1310e-03],\n",
            "          [ 4.5722e-02,  9.3158e-03,  7.0099e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2820e-02,  5.1355e-02, -1.8066e-02],\n",
            "          [ 4.0322e-02,  2.9519e-02, -6.0586e-03],\n",
            "          [ 8.2251e-03,  1.6640e-02,  1.1599e-02]],\n",
            "\n",
            "         [[-3.2265e-02,  1.5870e-02,  1.1650e-02],\n",
            "          [ 5.0049e-02,  2.8760e-02,  4.5287e-02],\n",
            "          [-1.6807e-02, -3.5856e-02, -4.5160e-02]],\n",
            "\n",
            "         [[ 1.6891e-02,  4.9680e-02,  6.9802e-02],\n",
            "          [-1.5094e-02,  4.0828e-02,  1.7804e-02],\n",
            "          [ 1.8970e-02,  5.7966e-02, -2.4837e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.1800e-03, -5.9606e-02,  3.3158e-02],\n",
            "          [-1.4598e-02, -2.2307e-02,  4.2714e-02],\n",
            "          [-2.7353e-02, -1.0714e-02, -3.5044e-02]],\n",
            "\n",
            "         [[-2.8373e-02,  9.2327e-04,  1.1409e-02],\n",
            "          [ 1.2881e-02,  3.5416e-02, -1.7298e-02],\n",
            "          [-1.3535e-03, -2.8345e-02,  4.1410e-02]],\n",
            "\n",
            "         [[-1.5174e-02, -3.8115e-02, -2.7408e-02],\n",
            "          [ 5.9834e-03, -7.2143e-03,  3.5500e-02],\n",
            "          [ 5.4708e-02, -1.0844e-02,  5.7351e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3238e-02,  4.5829e-04,  2.9302e-02],\n",
            "          [-1.2026e-02,  2.1242e-02,  2.0155e-02],\n",
            "          [ 3.5721e-02, -2.9629e-02,  1.0124e-02]],\n",
            "\n",
            "         [[ 4.4335e-02, -2.3463e-02,  5.7952e-02],\n",
            "          [-4.0447e-02, -5.6936e-03,  2.5573e-02],\n",
            "          [-8.3230e-02,  2.4768e-02,  4.0999e-03]],\n",
            "\n",
            "         [[ 1.8258e-03,  5.2235e-03,  4.5375e-02],\n",
            "          [ 4.1671e-02, -3.1079e-02, -1.3920e-02],\n",
            "          [ 3.3657e-02,  1.9382e-02,  1.9113e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0750e-02,  3.0260e-02, -1.1044e-03],\n",
            "          [ 4.3363e-03,  2.2510e-02, -6.2146e-04],\n",
            "          [-1.5099e-02,  1.3594e-04, -5.4466e-02]],\n",
            "\n",
            "         [[ 2.1241e-02, -3.9979e-02,  2.2082e-02],\n",
            "          [-3.0997e-04, -4.3301e-02, -8.1454e-03],\n",
            "          [ 2.9166e-02,  3.0532e-02,  3.1327e-02]],\n",
            "\n",
            "         [[-3.1116e-03,  3.5612e-02,  8.3083e-03],\n",
            "          [ 4.0572e-02, -1.3870e-02, -6.7992e-02],\n",
            "          [ 2.1610e-02, -3.7528e-03,  1.4822e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.4324e-03, -6.4965e-02, -1.3330e-03],\n",
            "          [ 1.1111e-02,  1.9631e-02,  6.5965e-03],\n",
            "          [-9.8036e-03, -1.5100e-03,  1.8833e-02]],\n",
            "\n",
            "         [[ 3.8149e-02, -2.8986e-02, -8.0791e-03],\n",
            "          [-2.9255e-02, -2.8477e-02,  6.9389e-02],\n",
            "          [ 1.4030e-02,  2.4470e-02, -1.2319e-02]],\n",
            "\n",
            "         [[ 3.4686e-02, -1.2715e-02, -6.0538e-02],\n",
            "          [ 1.0766e-02,  1.3986e-02, -2.1297e-02],\n",
            "          [-3.6890e-02,  2.9557e-02, -2.4314e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1299e-02,  2.0113e-02,  4.7930e-03],\n",
            "          [ 5.0670e-02, -7.1716e-04,  9.2579e-03],\n",
            "          [-2.1343e-02,  1.4272e-03,  2.0678e-02]],\n",
            "\n",
            "         [[-1.3115e-02,  8.6567e-03, -2.5528e-02],\n",
            "          [ 4.0418e-02,  2.8879e-02,  6.5410e-03],\n",
            "          [-4.8353e-03, -3.7079e-03, -1.1155e-02]],\n",
            "\n",
            "         [[-4.6917e-02, -1.8236e-02,  2.6736e-02],\n",
            "          [ 3.1060e-02, -6.9147e-03,  3.7622e-02],\n",
            "          [ 3.0983e-02, -1.6475e-02,  4.3748e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4688e-02, -1.0504e-02, -1.4380e-02],\n",
            "          [ 9.9391e-03,  4.1877e-03, -6.1387e-02],\n",
            "          [-2.5434e-02,  3.8178e-02, -6.1726e-02]],\n",
            "\n",
            "         [[ 4.3925e-02, -9.8185e-03, -4.2287e-02],\n",
            "          [-2.4620e-02, -2.8057e-02, -2.9000e-02],\n",
            "          [-1.6088e-02,  1.5033e-02, -1.0475e-02]],\n",
            "\n",
            "         [[ 6.0763e-02, -2.4716e-02,  2.5117e-02],\n",
            "          [-2.9038e-02,  1.7525e-03,  6.0057e-04],\n",
            "          [-2.3140e-02, -1.5930e-02, -2.1150e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.2608e-02, -2.9244e-03,  2.9285e-02],\n",
            "          [-1.5158e-02, -1.3234e-02,  5.6245e-03],\n",
            "          [ 2.3840e-02, -2.5424e-02,  1.4640e-02]],\n",
            "\n",
            "         [[ 3.1383e-02, -3.1389e-02, -2.6798e-02],\n",
            "          [-3.5271e-02, -2.2784e-02, -1.4304e-02],\n",
            "          [ 3.0872e-02,  1.8542e-02,  2.7369e-02]],\n",
            "\n",
            "         [[ 2.8979e-02, -7.6031e-02,  2.6484e-02],\n",
            "          [ 1.4333e-02,  1.0013e-02,  6.4612e-03],\n",
            "          [ 1.3806e-02,  2.8331e-02, -2.5880e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3851e-04, -2.4558e-02, -4.5404e-03],\n",
            "          [ 2.9884e-02,  3.5211e-03, -1.4263e-02],\n",
            "          [ 2.6431e-02, -1.9879e-02,  2.2474e-05]],\n",
            "\n",
            "         [[-2.1369e-02,  2.2285e-02, -5.8878e-03],\n",
            "          [ 2.2378e-02, -1.3163e-02, -2.2699e-02],\n",
            "          [-5.8738e-02,  6.5617e-03,  3.8019e-02]],\n",
            "\n",
            "         [[ 1.4447e-02, -1.7120e-02, -1.0599e-02],\n",
            "          [-3.6585e-02,  2.2893e-02,  1.7289e-02],\n",
            "          [-1.7241e-02, -5.6439e-02, -6.3110e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5545e-02,  3.3658e-02,  6.6639e-02],\n",
            "          [-2.8273e-02,  2.5731e-02,  2.2933e-02],\n",
            "          [ 1.7759e-02, -2.5013e-02,  2.3301e-02]],\n",
            "\n",
            "         [[ 1.6383e-02, -1.4615e-03,  1.8405e-02],\n",
            "          [ 5.9498e-02,  1.1152e-02, -8.7318e-03],\n",
            "          [-2.1024e-02,  1.7609e-02,  4.0261e-02]],\n",
            "\n",
            "         [[-3.4439e-02, -4.6220e-02,  1.5684e-02],\n",
            "          [ 1.8278e-02, -2.2844e-02,  6.6956e-02],\n",
            "          [ 1.1217e-02,  6.7116e-02,  2.2346e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8508e-02,  2.6111e-02,  2.5101e-02],\n",
            "          [-1.5742e-02, -1.8510e-02,  3.0705e-02],\n",
            "          [-3.0859e-02,  2.3451e-02,  7.4460e-03]],\n",
            "\n",
            "         [[ 5.1662e-02,  2.3508e-02, -1.6252e-02],\n",
            "          [ 2.5822e-02, -2.0408e-02,  3.1853e-02],\n",
            "          [ 4.0998e-02, -7.0248e-03, -2.7267e-02]],\n",
            "\n",
            "         [[ 9.8509e-03, -9.8886e-03,  5.4797e-02],\n",
            "          [-3.8990e-02, -1.6699e-02, -5.1087e-03],\n",
            "          [-4.6600e-02,  5.2519e-02, -5.3437e-02]]]])), ('module.encoder_q.layer3.1.bn2.weight', tensor([0.9939, 0.9920, 0.9930, 0.9910, 0.9925, 0.9932, 0.9925, 0.9927, 0.9932,\n",
            "        0.9912, 0.9940, 0.9916, 0.9926, 0.9945, 0.9906, 0.9934, 0.9902, 0.9930,\n",
            "        0.9922, 0.9930, 0.9916, 0.9911, 0.9930, 0.9919, 0.9913, 0.9926, 0.9925,\n",
            "        0.9930, 0.9932, 0.9950, 0.9937, 0.9914, 0.9921, 0.9932, 0.9930, 0.9930,\n",
            "        0.9932, 0.9915, 0.9922, 0.9918, 0.9909, 0.9924, 0.9921, 0.9921, 0.9920,\n",
            "        0.9919, 0.9917, 0.9924, 0.9934, 0.9913, 0.9943, 0.9925, 0.9926, 0.9927,\n",
            "        0.9934, 0.9926, 0.9921, 0.9922, 0.9903, 0.9942, 0.9925, 0.9931, 0.9922,\n",
            "        0.9916, 0.9919, 0.9937, 0.9915, 0.9925, 0.9920, 0.9901, 0.9911, 0.9906,\n",
            "        0.9924, 0.9913, 0.9925, 0.9929, 0.9925, 0.9922, 0.9920, 0.9923, 0.9929,\n",
            "        0.9908, 0.9928, 0.9924, 0.9922, 0.9911, 0.9922, 0.9918, 0.9919, 0.9915,\n",
            "        0.9935, 0.9912, 0.9924, 0.9911, 0.9924, 0.9913, 0.9924, 0.9930, 0.9932,\n",
            "        0.9920, 0.9923, 0.9900, 0.9918, 0.9925, 0.9915, 0.9929, 0.9931, 0.9925,\n",
            "        0.9923, 0.9934, 0.9918, 0.9928, 0.9911, 0.9925, 0.9918, 0.9925, 0.9893,\n",
            "        0.9938, 0.9924, 0.9931, 0.9923, 0.9920, 0.9925, 0.9918, 0.9906, 0.9916,\n",
            "        0.9926, 0.9904, 0.9926, 0.9914, 0.9929, 0.9929, 0.9926, 0.9914, 0.9925,\n",
            "        0.9923, 0.9922, 0.9938, 0.9912, 0.9923, 0.9916, 0.9921, 0.9921, 0.9932,\n",
            "        0.9917, 0.9931, 0.9933, 0.9924, 0.9912, 0.9918, 0.9918, 0.9908, 0.9919,\n",
            "        0.9939, 0.9910, 0.9929, 0.9924, 0.9925, 0.9919, 0.9929, 0.9924, 0.9924,\n",
            "        0.9920, 0.9923, 0.9936, 0.9927, 0.9936, 0.9916, 0.9924, 0.9912, 0.9921,\n",
            "        0.9925, 0.9911, 0.9915, 0.9926, 0.9922, 0.9929, 0.9913, 0.9936, 0.9914,\n",
            "        0.9933, 0.9920, 0.9936, 0.9930, 0.9928, 0.9912, 0.9914, 0.9917, 0.9916,\n",
            "        0.9907, 0.9915, 0.9924, 0.9920, 0.9929, 0.9939, 0.9936, 0.9921, 0.9914,\n",
            "        0.9911, 0.9907, 0.9925, 0.9925, 0.9928, 0.9939, 0.9913, 0.9943, 0.9934,\n",
            "        0.9923, 0.9922, 0.9930, 0.9929, 0.9929, 0.9942, 0.9915, 0.9927, 0.9939,\n",
            "        0.9919, 0.9906, 0.9910, 0.9926, 0.9920, 0.9930, 0.9925, 0.9913, 0.9906,\n",
            "        0.9905, 0.9918, 0.9935, 0.9912, 0.9928, 0.9916, 0.9910, 0.9915, 0.9930,\n",
            "        0.9929, 0.9920, 0.9922, 0.9925, 0.9920, 0.9916, 0.9924, 0.9915, 0.9940,\n",
            "        0.9918, 0.9931, 0.9928, 0.9913, 0.9917, 0.9925, 0.9925, 0.9925, 0.9913,\n",
            "        0.9928, 0.9923, 0.9926, 0.9918])), ('module.encoder_q.layer3.1.bn2.bias', tensor([ 8.4377e-04,  7.1269e-04, -7.8386e-05, -5.1766e-04,  8.1388e-04,\n",
            "        -6.6509e-05,  6.7524e-04,  1.4747e-03,  3.4462e-04, -1.5042e-03,\n",
            "         1.2744e-03,  7.6740e-05,  7.8351e-04,  9.5194e-04, -2.5845e-04,\n",
            "         5.7737e-05, -9.4786e-04,  7.8538e-04, -6.3894e-04,  1.7578e-03,\n",
            "         3.1662e-04, -5.1405e-04,  9.5735e-04, -2.3265e-05,  7.1675e-04,\n",
            "         6.9816e-04,  1.5924e-03, -1.1217e-04,  1.5349e-03,  5.9442e-04,\n",
            "         8.3509e-05,  3.4307e-06,  5.7672e-04,  3.6143e-04,  1.1924e-05,\n",
            "         6.0775e-04,  1.0493e-04, -8.3633e-04,  1.3773e-04,  4.4304e-04,\n",
            "        -8.1907e-04,  8.4957e-04, -2.7593e-04,  3.4683e-04,  9.6957e-04,\n",
            "         7.0814e-04,  5.8369e-04, -3.5994e-04,  2.1821e-04, -8.4348e-04,\n",
            "         1.7710e-03,  6.8520e-04,  5.7488e-04, -1.1463e-03,  8.7363e-04,\n",
            "         3.0829e-04, -2.9535e-04, -1.5032e-04, -2.7122e-03,  2.2843e-03,\n",
            "        -7.6903e-05, -1.0726e-04, -4.3139e-05, -5.4998e-05,  1.3716e-05,\n",
            "         7.1729e-04, -3.6652e-05,  3.0830e-04, -3.1689e-04, -2.7490e-04,\n",
            "        -2.0842e-04, -1.0553e-03,  4.1339e-04,  4.9337e-04,  1.1896e-03,\n",
            "        -5.3486e-04, -2.8160e-04,  1.1275e-05, -3.3493e-04,  1.7059e-03,\n",
            "        -5.8071e-05, -1.0800e-03,  8.2274e-05, -8.7008e-06, -8.4888e-05,\n",
            "        -6.5846e-04, -1.0920e-04, -3.2050e-04,  7.7247e-05, -6.7336e-04,\n",
            "         9.2827e-04, -1.5161e-03, -5.3323e-04,  4.8938e-04, -7.1048e-04,\n",
            "         5.7282e-04,  3.6525e-04,  1.1107e-03,  6.8466e-04, -1.0582e-03,\n",
            "         2.0350e-04, -1.5767e-03, -3.4913e-04,  3.1176e-04,  3.9901e-04,\n",
            "         1.2189e-03, -4.0626e-05,  5.3505e-04,  1.0722e-05,  1.2808e-03,\n",
            "         1.8243e-04, -3.0496e-04, -5.3743e-04, -5.5261e-04, -4.6875e-05,\n",
            "        -4.0904e-04, -7.6522e-04,  1.4133e-03,  3.2223e-04, -1.2491e-03,\n",
            "         5.0280e-04,  1.9051e-04,  4.1797e-04, -1.0805e-03, -1.0301e-03,\n",
            "        -9.8685e-04,  9.1313e-04, -1.2553e-03,  1.4797e-04,  4.0399e-04,\n",
            "        -6.9413e-05, -2.5658e-04,  7.7969e-04,  4.1204e-06, -4.4931e-04,\n",
            "         5.3522e-04, -1.3968e-04,  1.2299e-03, -1.7078e-03,  1.0025e-03,\n",
            "        -4.3055e-04, -6.8121e-04, -1.1471e-03, -9.4749e-05, -1.6214e-03,\n",
            "        -3.5564e-04,  9.3532e-04, -6.0073e-04, -1.1423e-03, -1.2054e-05,\n",
            "        -6.9263e-04, -1.4106e-03, -5.4745e-04,  8.9665e-04,  3.7995e-04,\n",
            "         1.5403e-03,  9.0143e-05,  6.8309e-04, -2.1102e-05,  3.2348e-04,\n",
            "         3.8500e-05, -9.9439e-04, -1.0014e-03,  6.5251e-04, -3.7109e-04,\n",
            "         1.0420e-03,  8.8039e-04, -1.5119e-04,  4.4834e-05, -4.6632e-04,\n",
            "        -2.1780e-04, -5.2693e-04,  1.8998e-04, -4.2540e-04,  4.2726e-04,\n",
            "         9.3068e-04,  7.7687e-04, -1.7994e-04,  5.6477e-04, -4.9281e-04,\n",
            "         1.2546e-03,  7.6874e-04,  1.2832e-03,  2.3303e-04, -1.1922e-03,\n",
            "        -7.9334e-04, -7.6433e-04, -1.1616e-04, -9.4990e-04, -2.6318e-04,\n",
            "        -4.0285e-04, -2.2997e-04, -5.2097e-05,  1.0074e-03,  3.6173e-04,\n",
            "         1.0585e-03, -5.5585e-04, -3.0610e-04, -1.5838e-03, -3.2008e-04,\n",
            "        -3.7298e-04,  5.7743e-04,  1.3457e-03,  8.4157e-04, -7.1045e-04,\n",
            "         7.9409e-04,  1.0050e-03, -1.1290e-03,  1.4430e-04,  8.5078e-04,\n",
            "        -2.7343e-04, -2.2751e-04,  6.5184e-04, -4.8567e-04, -8.2587e-04,\n",
            "         2.8097e-04,  7.4212e-04, -1.0677e-03, -5.7264e-04, -2.1583e-04,\n",
            "        -3.8817e-04, -3.3144e-04,  4.0148e-04, -6.3093e-04, -1.1748e-03,\n",
            "        -1.6768e-03,  2.0709e-04,  1.7082e-03, -1.1017e-03,  8.3437e-04,\n",
            "        -8.0726e-04, -5.6884e-04,  8.1006e-05,  1.3159e-03,  5.4061e-04,\n",
            "         3.5750e-04,  2.7767e-04,  4.8841e-04, -8.7435e-05,  2.4336e-04,\n",
            "         2.5449e-04, -3.8517e-04,  2.8439e-04, -3.5634e-04,  1.2630e-03,\n",
            "         8.9971e-04, -6.9686e-04,  1.6060e-03, -8.1025e-04,  6.5666e-04,\n",
            "        -3.3150e-04, -1.2360e-03,  4.6003e-04,  1.3413e-03,  2.8251e-04,\n",
            "        -1.0280e-03])), ('module.encoder_q.layer3.1.bn2.running_mean', tensor([-8.3957e-02,  1.3337e-01,  6.6510e-03,  2.9310e-01,  4.5965e-01,\n",
            "        -8.2563e-02, -2.6852e-01, -4.2614e-01, -3.0193e-02, -6.8117e-01,\n",
            "         6.8437e-02, -5.4882e-01,  2.2040e-01,  1.3543e-01,  2.6369e-01,\n",
            "         3.2616e-02,  6.4967e-01, -1.0890e-01, -3.8643e-02, -1.4692e-01,\n",
            "         6.0162e-01,  2.3000e-01,  4.4410e-01, -3.1467e-01, -1.0918e-01,\n",
            "        -1.8023e-01, -5.2357e-01,  4.0880e-01, -3.3730e-02, -5.2949e-02,\n",
            "        -3.3981e-02, -8.1370e-02, -1.4359e-01, -3.2552e-01,  1.2863e-02,\n",
            "         3.3760e-01, -4.4046e-02, -5.1774e-01,  1.1172e-01, -4.1360e-01,\n",
            "        -3.6016e-01,  9.8717e-02, -6.9659e-02, -1.0259e-01, -1.3573e-01,\n",
            "        -2.6312e-01,  1.3661e-01,  3.5582e-01,  1.0252e+00,  8.6510e-02,\n",
            "        -3.3920e-01, -2.1895e-01,  6.4733e-01,  5.6014e-01,  3.4310e-01,\n",
            "        -1.1918e-01, -3.8187e-02,  1.7250e-01,  2.5277e-01, -4.8139e-01,\n",
            "         3.4164e-02, -4.2400e-03,  1.6624e-01, -2.3694e-01, -7.5578e-01,\n",
            "         2.4317e-01, -5.0562e-01, -4.3279e-01, -1.6760e-01, -4.6581e-01,\n",
            "         2.6257e-01, -7.8906e-01,  8.6303e-01, -2.7087e-01, -4.9617e-01,\n",
            "        -1.9763e-01,  7.6111e-01, -5.4059e-01, -3.2434e-01,  3.0979e-01,\n",
            "        -3.1429e-01, -2.6338e-01,  3.3802e-01,  7.9018e-02, -8.7818e-01,\n",
            "         1.5059e-01, -2.9605e-01,  3.1712e-01, -8.5926e-02,  8.6978e-02,\n",
            "         1.8957e-01,  2.8727e-01, -7.2456e-01, -2.3454e-01, -3.4316e-01,\n",
            "         5.8298e-02,  6.4281e-01,  6.8205e-01,  2.9936e-01, -3.8518e-01,\n",
            "        -9.7087e-02,  1.2860e-01,  1.8586e-01, -3.9026e-02, -5.0041e-01,\n",
            "         1.2412e-01,  5.0257e-01, -4.4518e-01,  2.8558e-01, -1.5794e-01,\n",
            "        -7.2593e-01,  3.2064e-01,  6.4289e-01,  3.8849e-01,  1.7817e-01,\n",
            "         1.8332e-02,  9.7694e-01,  6.4104e-02,  7.8876e-01,  4.1402e-01,\n",
            "         7.6520e-02, -1.7285e-01, -7.4421e-01, -5.7674e-01,  3.6178e-01,\n",
            "        -7.0015e-01, -9.5117e-02, -5.9828e-01,  3.5324e-01,  6.1653e-02,\n",
            "         4.1035e-01,  9.0788e-01,  6.8294e-01,  3.6707e-01, -1.5616e-01,\n",
            "        -9.1901e-01, -3.0142e-01,  6.4830e-01,  2.3003e-01, -4.6098e-01,\n",
            "        -8.5363e-01, -2.8078e-01, -6.3059e-01, -5.7285e-01, -1.0929e-01,\n",
            "        -3.1716e-01,  2.1907e-01,  5.8522e-01, -3.8732e-01, -1.6031e-01,\n",
            "        -9.5746e-02,  3.1323e-01, -3.1357e-01, -1.1691e-01, -2.6875e-02,\n",
            "         1.6097e-01, -6.2073e-01,  1.0298e-01, -3.5759e-01, -7.0240e-01,\n",
            "         2.5092e-01, -4.8532e-01,  4.2793e-02, -6.9275e-02, -9.1069e-02,\n",
            "         2.6904e-01, -1.6094e-02, -6.7783e-04, -4.2940e-02,  2.1381e-01,\n",
            "         8.4183e-01, -6.9995e-01, -7.9198e-03, -1.8312e-01,  1.7868e-01,\n",
            "        -5.5373e-01, -5.0623e-01,  5.9350e-01,  8.2200e-01,  2.9521e-01,\n",
            "        -4.5590e-01,  5.3337e-02,  1.1910e+00,  3.2194e-01,  1.1308e-01,\n",
            "        -6.2637e-01, -1.5152e-01, -4.7756e-01,  3.1486e-01,  2.0875e-03,\n",
            "         1.8418e-02,  3.6098e-01,  8.2066e-02,  6.2757e-02, -1.4173e-01,\n",
            "         3.7703e-01,  3.9885e-02,  5.5207e-01,  1.2376e-01,  2.1182e-01,\n",
            "        -9.7333e-02, -9.1926e-02, -1.4961e-02, -1.4896e-01, -3.3836e-01,\n",
            "         6.0466e-01, -5.5627e-01,  2.9838e-01, -3.2371e-01, -3.6628e-01,\n",
            "         3.9769e-01,  7.7455e-01,  1.6934e-01,  2.9160e-01,  3.3389e-01,\n",
            "        -1.1949e-01,  3.6416e-01, -4.6960e-01, -2.8779e-01,  5.3724e-01,\n",
            "        -3.4822e-01, -1.2840e-01,  4.4562e-02, -2.8612e-01,  1.2397e+00,\n",
            "         4.8459e-01,  5.5708e-01, -2.4010e-01,  5.2398e-02, -4.8730e-01,\n",
            "        -5.6419e-02, -4.4272e-02,  2.7761e-01,  1.5842e-01, -6.5740e-03,\n",
            "         7.3134e-02,  3.3652e-01,  3.4858e-01, -2.7834e-01,  1.6681e-01,\n",
            "         3.7530e-01,  4.8435e-01,  2.4493e-01, -1.1047e-01, -8.2329e-01,\n",
            "        -1.5543e-01, -9.4637e-02,  6.7650e-01, -1.1830e-01,  6.9137e-01,\n",
            "        -3.9160e-01,  5.0688e-01,  5.0125e-02, -7.9743e-01, -5.7811e-01,\n",
            "         1.2313e+00])), ('module.encoder_q.layer3.1.bn2.running_var', tensor([0.6524, 0.4868, 1.0804, 0.7218, 0.7229, 0.5857, 0.6216, 1.2076, 0.5422,\n",
            "        1.0382, 0.6016, 0.6910, 0.6637, 0.5355, 0.6896, 0.7692, 0.5907, 0.6916,\n",
            "        0.5536, 0.4895, 0.5728, 0.6817, 0.6434, 0.7096, 0.5565, 0.8439, 0.6666,\n",
            "        0.7412, 0.7915, 0.5991, 0.7164, 0.8147, 0.7572, 0.6472, 0.6545, 0.6531,\n",
            "        0.5884, 0.5336, 0.7862, 0.6265, 0.9115, 0.6280, 0.6644, 0.6498, 0.8682,\n",
            "        0.6410, 0.6421, 0.8410, 1.3735, 0.5979, 0.6590, 0.6172, 1.5663, 1.2092,\n",
            "        0.5896, 0.8349, 0.6108, 0.7457, 0.4857, 0.7942, 0.6511, 0.6427, 0.5384,\n",
            "        0.7058, 0.6518, 0.9222, 0.7346, 0.6890, 0.6247, 0.5310, 0.6743, 0.5560,\n",
            "        0.6466, 0.5143, 0.5908, 0.7378, 0.6989, 0.5252, 0.5112, 0.6088, 0.7897,\n",
            "        0.6555, 0.7104, 1.0385, 0.7500, 0.6404, 0.5675, 0.4933, 0.6458, 0.6427,\n",
            "        0.7969, 0.6933, 1.1120, 0.4454, 0.8539, 0.5032, 0.5432, 0.7544, 0.4558,\n",
            "        0.5536, 0.6617, 0.5958, 0.8000, 0.5452, 0.7230, 0.5052, 0.6307, 1.0236,\n",
            "        0.6029, 0.6095, 1.0508, 1.0439, 1.7319, 1.1486, 0.9855, 0.5398, 0.6362,\n",
            "        0.5594, 0.8873, 0.6489, 0.6372, 0.6229, 0.7434, 0.9873, 0.5153, 1.0837,\n",
            "        0.9364, 0.5298, 0.9821, 0.5038, 0.5518, 0.9141, 1.2690, 1.0670, 0.6424,\n",
            "        1.0709, 0.8447, 0.7717, 0.9128, 2.0764, 0.9818, 0.8088, 0.7437, 1.0747,\n",
            "        0.5174, 0.6094, 0.8333, 0.5065, 0.6642, 1.1776, 0.5967, 0.7468, 0.6872,\n",
            "        0.5403, 0.6607, 0.7739, 0.8190, 0.7127, 0.9154, 0.5464, 0.7639, 0.7215,\n",
            "        0.5854, 0.6686, 0.5215, 0.7262, 0.5298, 0.6773, 0.9986, 0.5510, 1.5822,\n",
            "        0.7238, 0.6232, 0.9513, 0.5984, 1.0369, 0.5943, 0.5880, 0.9471, 0.7515,\n",
            "        0.8017, 0.6119, 2.4992, 0.8328, 0.8528, 0.5998, 0.5205, 0.4593, 0.9886,\n",
            "        0.5951, 0.5130, 0.7952, 0.5402, 0.6722, 0.5219, 0.8466, 0.6303, 0.7436,\n",
            "        0.7789, 0.5684, 0.5389, 0.6604, 0.7470, 0.6452, 0.5928, 1.3121, 0.6919,\n",
            "        0.8570, 0.7878, 0.6066, 0.6248, 0.8105, 0.7287, 0.7599, 0.6942, 0.4950,\n",
            "        0.7941, 0.8048, 0.6825, 0.9515, 0.8099, 0.7392, 0.5322, 0.6064, 0.7812,\n",
            "        0.9329, 0.6908, 1.2253, 0.5919, 0.5737, 0.5526, 0.6527, 0.7117, 0.6726,\n",
            "        0.5749, 0.7861, 0.5042, 0.5761, 1.2564, 0.7619, 0.5822, 0.8542, 0.8084,\n",
            "        0.6276, 0.6912, 0.6377, 0.5915, 1.2414, 0.5528, 0.8405, 0.5449, 1.1540,\n",
            "        0.5805, 1.5678, 0.6216, 1.0227])), ('module.encoder_q.layer3.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.1.conv3.weight', tensor([[[[-0.0655]],\n",
            "\n",
            "         [[-0.0078]],\n",
            "\n",
            "         [[-0.0378]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0207]],\n",
            "\n",
            "         [[ 0.0611]],\n",
            "\n",
            "         [[-0.0245]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0031]],\n",
            "\n",
            "         [[ 0.0048]],\n",
            "\n",
            "         [[ 0.0339]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0400]],\n",
            "\n",
            "         [[-0.0513]],\n",
            "\n",
            "         [[ 0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0372]],\n",
            "\n",
            "         [[-0.0254]],\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0447]],\n",
            "\n",
            "         [[ 0.0065]],\n",
            "\n",
            "         [[-0.0880]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0317]],\n",
            "\n",
            "         [[-0.0048]],\n",
            "\n",
            "         [[-0.0670]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0267]],\n",
            "\n",
            "         [[-0.1035]],\n",
            "\n",
            "         [[-0.0380]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0374]],\n",
            "\n",
            "         [[ 0.0412]],\n",
            "\n",
            "         [[ 0.0462]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0505]],\n",
            "\n",
            "         [[ 0.0422]],\n",
            "\n",
            "         [[ 0.0231]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0071]],\n",
            "\n",
            "         [[ 0.0220]],\n",
            "\n",
            "         [[ 0.0240]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0624]],\n",
            "\n",
            "         [[-0.0694]],\n",
            "\n",
            "         [[-0.0816]]]])), ('module.encoder_q.layer3.1.bn3.weight', tensor([0.9923, 0.9927, 0.9931,  ..., 0.9929, 0.9919, 0.9924])), ('module.encoder_q.layer3.1.bn3.bias', tensor([-9.7195e-05, -3.4522e-05,  2.7863e-04,  ...,  1.9262e-04,\n",
            "        -4.0665e-04, -3.3235e-04])), ('module.encoder_q.layer3.1.bn3.running_mean', tensor([-0.1543, -0.2657, -0.0370,  ..., -0.3090, -0.1264, -0.2417])), ('module.encoder_q.layer3.1.bn3.running_var', tensor([0.1269, 0.2199, 0.1416,  ..., 0.1391, 0.1630, 0.1656])), ('module.encoder_q.layer3.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.2.conv1.weight', tensor([[[[ 0.1731]],\n",
            "\n",
            "         [[-0.0581]],\n",
            "\n",
            "         [[ 0.0243]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0338]],\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[ 0.0539]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1230]],\n",
            "\n",
            "         [[ 0.1041]],\n",
            "\n",
            "         [[ 0.0072]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0681]],\n",
            "\n",
            "         [[-0.1058]],\n",
            "\n",
            "         [[-0.0992]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0397]],\n",
            "\n",
            "         [[ 0.0042]],\n",
            "\n",
            "         [[ 0.0890]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0546]],\n",
            "\n",
            "         [[-0.0910]],\n",
            "\n",
            "         [[ 0.0302]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0235]],\n",
            "\n",
            "         [[-0.0640]],\n",
            "\n",
            "         [[ 0.0786]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0579]],\n",
            "\n",
            "         [[ 0.0286]],\n",
            "\n",
            "         [[ 0.0192]]],\n",
            "\n",
            "\n",
            "        [[[-0.1193]],\n",
            "\n",
            "         [[ 0.0966]],\n",
            "\n",
            "         [[ 0.0999]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0430]],\n",
            "\n",
            "         [[-0.0992]],\n",
            "\n",
            "         [[ 0.0058]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0115]],\n",
            "\n",
            "         [[-0.0989]],\n",
            "\n",
            "         [[-0.0434]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0674]],\n",
            "\n",
            "         [[ 0.0203]],\n",
            "\n",
            "         [[-0.0296]]]])), ('module.encoder_q.layer3.2.bn1.weight', tensor([0.9928, 0.9945, 0.9918, 0.9925, 0.9932, 0.9926, 0.9911, 0.9928, 0.9920,\n",
            "        0.9934, 0.9919, 0.9924, 0.9912, 0.9918, 0.9926, 0.9929, 0.9915, 0.9930,\n",
            "        0.9923, 0.9923, 0.9932, 0.9933, 0.9919, 0.9933, 0.9926, 0.9926, 0.9930,\n",
            "        0.9942, 0.9923, 0.9913, 0.9929, 0.9917, 0.9922, 0.9929, 0.9915, 0.9924,\n",
            "        0.9928, 0.9911, 0.9917, 0.9916, 0.9937, 0.9923, 0.9922, 0.9923, 0.9913,\n",
            "        0.9917, 0.9920, 0.9925, 0.9918, 0.9919, 0.9915, 0.9927, 0.9925, 0.9914,\n",
            "        0.9925, 0.9927, 0.9919, 0.9926, 0.9922, 0.9928, 0.9922, 0.9914, 0.9920,\n",
            "        0.9918, 0.9921, 0.9916, 0.9925, 0.9914, 0.9909, 0.9927, 0.9924, 0.9913,\n",
            "        0.9914, 0.9916, 0.9926, 0.9915, 0.9916, 0.9925, 0.9928, 0.9917, 0.9924,\n",
            "        0.9913, 0.9908, 0.9921, 0.9925, 0.9930, 0.9930, 0.9921, 0.9906, 0.9910,\n",
            "        0.9914, 0.9931, 0.9920, 0.9924, 0.9923, 0.9920, 0.9927, 0.9921, 0.9904,\n",
            "        0.9917, 0.9916, 0.9929, 0.9914, 0.9927, 0.9913, 0.9921, 0.9927, 0.9916,\n",
            "        0.9915, 0.9923, 0.9923, 0.9930, 0.9926, 0.9936, 0.9919, 0.9926, 0.9941,\n",
            "        0.9910, 0.9925, 0.9930, 0.9933, 0.9923, 0.9918, 0.9920, 0.9917, 0.9919,\n",
            "        0.9933, 0.9932, 0.9921, 0.9927, 0.9919, 0.9930, 0.9922, 0.9920, 0.9923,\n",
            "        0.9921, 0.9927, 0.9937, 0.9931, 0.9928, 0.9925, 0.9921, 0.9916, 0.9915,\n",
            "        0.9922, 0.9917, 0.9919, 0.9942, 0.9915, 0.9926, 0.9918, 0.9923, 0.9914,\n",
            "        0.9908, 0.9918, 0.9912, 0.9933, 0.9924, 0.9925, 0.9918, 0.9915, 0.9922,\n",
            "        0.9936, 0.9911, 0.9932, 0.9932, 0.9927, 0.9916, 0.9919, 0.9929, 0.9920,\n",
            "        0.9929, 0.9926, 0.9931, 0.9936, 0.9920, 0.9920, 0.9924, 0.9928, 0.9918,\n",
            "        0.9907, 0.9927, 0.9921, 0.9916, 0.9926, 0.9923, 0.9926, 0.9915, 0.9929,\n",
            "        0.9917, 0.9926, 0.9921, 0.9935, 0.9923, 0.9919, 0.9915, 0.9924, 0.9917,\n",
            "        0.9921, 0.9930, 0.9925, 0.9928, 0.9934, 0.9934, 0.9932, 0.9917, 0.9943,\n",
            "        0.9932, 0.9928, 0.9924, 0.9925, 0.9930, 0.9925, 0.9910, 0.9926, 0.9916,\n",
            "        0.9918, 0.9909, 0.9930, 0.9921, 0.9919, 0.9932, 0.9918, 0.9907, 0.9926,\n",
            "        0.9921, 0.9918, 0.9918, 0.9919, 0.9933, 0.9922, 0.9931, 0.9923, 0.9918,\n",
            "        0.9924, 0.9924, 0.9929, 0.9917, 0.9926, 0.9928, 0.9917, 0.9922, 0.9916,\n",
            "        0.9913, 0.9929, 0.9926, 0.9916, 0.9918, 0.9923, 0.9934, 0.9917, 0.9906,\n",
            "        0.9920, 0.9923, 0.9928, 0.9924])), ('module.encoder_q.layer3.2.bn1.bias', tensor([ 7.6982e-04,  1.4162e-03,  6.8791e-05, -1.2269e-04,  5.8089e-04,\n",
            "         3.2379e-04, -9.1926e-04, -1.3038e-04, -7.8050e-05,  7.5832e-04,\n",
            "        -6.0272e-04,  1.6888e-04, -6.6608e-04, -7.0236e-04,  1.5670e-03,\n",
            "         6.3222e-04, -6.9030e-04,  9.4328e-04,  1.1696e-04, -4.1937e-04,\n",
            "         1.2200e-03,  2.7318e-04, -6.3806e-04,  7.6620e-04,  7.4314e-04,\n",
            "         7.6204e-05,  1.0527e-03,  1.6244e-03,  7.1071e-04, -5.1208e-04,\n",
            "        -1.7582e-04, -1.9572e-04,  9.2660e-04,  1.1385e-03, -2.6114e-04,\n",
            "        -3.5533e-05,  6.6330e-04, -1.3952e-03, -5.6342e-04, -4.6299e-04,\n",
            "         1.6410e-03, -3.0507e-04,  1.5255e-04, -3.5054e-04, -1.3978e-03,\n",
            "        -6.4611e-04, -8.7103e-05,  1.4035e-04, -1.5789e-04, -1.4474e-03,\n",
            "         1.7350e-05,  7.8957e-04,  8.6268e-04, -1.9357e-04,  4.5471e-04,\n",
            "         1.4020e-04, -1.2000e-03,  4.6924e-04, -5.7773e-04, -1.3137e-04,\n",
            "         1.8509e-04, -3.0430e-04, -6.5788e-04, -1.5339e-03,  8.2617e-04,\n",
            "        -8.8279e-04,  3.1880e-04, -5.1769e-04, -2.0900e-03,  1.0716e-03,\n",
            "         2.6751e-04, -1.4558e-04, -6.4554e-04,  2.1037e-04, -1.9766e-04,\n",
            "        -5.2038e-04, -8.4236e-04,  7.8757e-05,  3.8028e-04, -9.2173e-05,\n",
            "        -1.0433e-03,  3.3128e-04, -3.7359e-04, -2.5118e-04, -1.8307e-04,\n",
            "        -1.9405e-04,  2.1893e-04, -4.4878e-04, -1.2624e-03, -1.4324e-03,\n",
            "        -5.0176e-05,  1.0149e-03, -5.4336e-04,  2.4038e-04, -9.8152e-05,\n",
            "        -1.1577e-03,  5.4696e-04,  1.7801e-05, -9.2065e-04, -1.4856e-04,\n",
            "        -6.7754e-04,  3.7234e-04, -5.6389e-04,  1.4662e-03, -3.8032e-04,\n",
            "        -6.7886e-04,  6.3847e-04, -1.3487e-03, -8.4301e-04, -3.9850e-05,\n",
            "        -5.5034e-04,  9.9853e-04,  8.0618e-04,  1.6527e-03, -1.0371e-04,\n",
            "         5.2087e-04,  3.6960e-04, -4.7292e-04, -6.7195e-04, -1.4196e-05,\n",
            "         5.1042e-05, -3.2031e-05, -6.6665e-04,  2.4585e-04,  2.4982e-04,\n",
            "         1.0433e-04,  9.7148e-04,  1.0439e-03, -5.1822e-04,  3.2198e-04,\n",
            "        -9.1953e-06,  8.8607e-04, -5.3129e-04,  5.4289e-05,  1.6617e-05,\n",
            "        -4.5762e-04,  1.0300e-03,  8.0030e-04,  9.9487e-04,  5.5003e-04,\n",
            "        -4.1118e-04, -1.0143e-03, -1.3938e-04, -5.4943e-04,  4.7309e-05,\n",
            "         5.3397e-05, -4.6826e-04,  1.3404e-03, -1.0010e-03, -5.8170e-04,\n",
            "        -2.4537e-04, -6.8321e-04, -9.1864e-04, -1.6618e-03,  6.3196e-04,\n",
            "        -6.9802e-04,  1.8328e-04,  3.3536e-04,  2.4673e-04, -4.3789e-04,\n",
            "        -9.6052e-04, -6.8737e-07,  3.5817e-04, -9.1172e-04,  9.1094e-04,\n",
            "         1.6017e-03, -2.9952e-04, -3.1101e-04,  5.8462e-04,  7.7868e-04,\n",
            "        -1.0211e-03, -3.3427e-04,  2.9806e-04,  6.0596e-04,  2.6739e-04,\n",
            "         1.6400e-04, -7.1942e-04,  1.2301e-03,  5.3615e-05, -1.4782e-04,\n",
            "        -7.2744e-04,  1.8743e-04,  2.0561e-04, -3.2827e-04,  1.1303e-03,\n",
            "         6.9538e-04,  4.0210e-04, -1.9664e-04,  2.5768e-04, -8.2893e-04,\n",
            "         2.3163e-04,  3.4961e-04,  5.9585e-04,  7.0599e-05,  4.4957e-04,\n",
            "         2.6615e-05, -3.2597e-04,  1.4613e-04, -8.5238e-04,  3.7006e-04,\n",
            "         1.4287e-05,  7.2654e-04,  5.2876e-04,  3.6779e-04,  4.4455e-04,\n",
            "        -4.2441e-04,  1.7425e-03,  3.0285e-04,  1.7906e-05, -3.8890e-04,\n",
            "        -9.7081e-04,  2.8336e-05, -1.3188e-04, -5.6505e-04, -2.9819e-04,\n",
            "        -1.2270e-03, -2.8610e-04, -5.4001e-04,  8.9103e-04,  3.7716e-04,\n",
            "        -1.6456e-04,  1.1979e-03, -4.2690e-04, -1.6516e-03,  1.2110e-03,\n",
            "        -3.4585e-04, -5.9125e-04, -9.4760e-04, -7.1719e-04, -5.9014e-04,\n",
            "         8.3455e-04,  1.3799e-03,  1.2435e-04, -1.5610e-04,  3.9013e-05,\n",
            "         2.2774e-04,  7.5868e-04, -5.1133e-04,  5.4224e-05,  1.8708e-05,\n",
            "         4.5558e-05,  7.0807e-04,  5.5800e-05, -8.7450e-04,  9.9835e-04,\n",
            "        -1.3700e-03, -1.3229e-04, -1.0339e-03, -2.6279e-04,  5.7289e-04,\n",
            "        -1.1105e-04, -8.8158e-04, -4.4046e-04, -6.8452e-04, -3.7448e-04,\n",
            "        -1.2155e-04])), ('module.encoder_q.layer3.2.bn1.running_mean', tensor([-3.4039e-01,  1.4905e+00,  8.6798e-01, -1.5228e+00,  1.8196e+00,\n",
            "        -1.0678e+00,  2.2368e+00,  3.2048e+00, -6.5184e-01,  1.0264e+00,\n",
            "        -1.6749e+00,  4.5221e-01,  4.7228e-01,  3.7480e-01,  1.1204e+00,\n",
            "        -2.1987e+00,  1.0686e+00,  1.0298e+00, -3.4608e+00, -1.3652e+00,\n",
            "        -4.8935e+00,  2.1240e+00,  1.9485e-01,  2.1605e+00, -8.1539e-01,\n",
            "         1.2035e+00,  4.4046e+00,  1.0013e+00, -1.0326e+00,  4.9537e-01,\n",
            "         1.7640e-01, -2.1103e+00,  2.7785e+00,  1.7081e+00, -1.1550e+00,\n",
            "         7.4957e-01,  5.1684e-01, -9.4617e-01, -6.1430e-01,  7.6058e-01,\n",
            "         6.7243e-01,  2.7729e+00, -9.2581e-01, -2.8211e-01,  2.7434e-01,\n",
            "         1.1494e+00, -3.3212e+00,  1.0720e+00,  1.0174e-01, -1.2131e-01,\n",
            "         1.4100e+00,  1.6896e+00, -1.3981e+00,  1.0439e+00, -1.8197e+00,\n",
            "        -6.4410e-01, -2.4732e+00,  3.5282e+00, -6.6142e-02, -1.5060e-01,\n",
            "        -1.4893e+00,  1.1690e+00, -2.6319e+00,  1.9184e+00, -2.6437e+00,\n",
            "        -3.2077e-01, -4.5383e+00, -1.4503e+00,  1.3750e+00,  4.6999e+00,\n",
            "        -1.5395e+00,  4.8058e-02, -1.6346e+00, -7.5657e-01, -1.6776e+00,\n",
            "        -2.2718e+00, -1.3312e-01, -6.4044e-01,  5.3448e-01, -1.3314e+00,\n",
            "        -3.3212e-01,  2.1486e+00, -1.9269e+00,  7.1317e-01, -2.5922e+00,\n",
            "        -1.4597e+00, -2.1168e-01, -3.9682e+00, -1.3620e+00,  2.8160e-02,\n",
            "        -4.5770e-01,  1.6246e+00, -1.9598e+00,  1.7544e+00, -1.7060e+00,\n",
            "        -1.7937e+00, -5.2781e-01,  3.5836e-01,  2.9305e+00, -3.2249e+00,\n",
            "         1.0188e+00,  2.6552e+00, -4.6411e+00, -1.8929e+00,  5.7470e-01,\n",
            "         5.2803e-01,  9.0458e-01,  3.7025e+00, -3.7947e+00,  1.9660e+00,\n",
            "         1.0679e+00, -8.7882e-01, -3.9555e+00,  9.5969e-01,  2.5998e-01,\n",
            "         1.1066e+00,  2.0157e+00,  2.9644e+00,  3.0700e-01,  1.5046e+00,\n",
            "         3.4738e+00,  6.4841e-01,  1.7972e+00,  2.5874e+00,  2.3193e+00,\n",
            "         1.2626e+00, -5.0424e-01,  1.9041e+00,  5.9350e-01, -1.4386e+00,\n",
            "        -4.1979e-01,  3.2634e-01, -3.0893e+00, -3.1203e+00,  2.1939e+00,\n",
            "         1.3972e+00, -4.9158e+00,  1.1091e-01, -8.9600e-01,  5.3405e-01,\n",
            "         1.7584e+00,  1.9369e+00, -4.7400e-01, -2.4141e+00, -9.6811e-01,\n",
            "         2.8811e+00, -4.5242e-01,  5.7956e-01,  4.6596e-01,  2.0920e-01,\n",
            "         1.2437e+00, -2.7277e-01, -1.7766e+00,  1.6312e-01, -2.9147e+00,\n",
            "        -1.9869e-01,  2.4270e+00,  3.0676e-02, -5.2669e-01, -7.7015e-01,\n",
            "         2.2101e+00,  1.0621e+00,  1.5730e+00, -2.6683e+00,  1.7952e+00,\n",
            "        -3.5533e+00,  5.1949e-01, -1.5247e+00,  2.5368e-01, -1.3585e+00,\n",
            "         8.2413e-01, -1.7715e+00,  3.1643e+00, -5.5036e-01, -1.7865e-01,\n",
            "        -6.7348e-02, -1.3924e+00,  2.6351e+00,  2.0232e+00,  6.8406e-01,\n",
            "        -1.2083e+00, -5.5090e+00, -7.3880e-01, -5.8909e-01, -1.2290e-01,\n",
            "        -1.1467e-03, -1.3184e+00,  3.2041e+00, -3.2649e+00,  4.5561e-01,\n",
            "         1.5374e+00, -2.0839e+00, -1.3651e+00,  2.2408e+00,  1.2179e+00,\n",
            "         3.5094e-02, -9.9957e-01, -7.9987e-01,  8.4045e-02, -7.0250e-01,\n",
            "        -1.1240e+00,  1.9764e+00,  1.2897e+00, -3.7347e+00,  1.0320e+00,\n",
            "        -7.8223e-01,  2.0195e+00,  1.5849e+00,  1.1561e+00, -3.0921e+00,\n",
            "        -4.8272e-02, -6.2333e-01,  1.7700e-01, -1.2360e+00,  4.6547e+00,\n",
            "        -9.7230e-01,  4.7694e-01,  3.7921e-01,  1.7272e+00,  1.2915e+00,\n",
            "         2.9599e+00,  6.1700e-01, -4.6661e-01,  2.3058e+00, -1.0383e+00,\n",
            "        -1.0615e+00,  2.4514e+00, -3.3464e+00, -1.6356e+00, -7.7157e-01,\n",
            "        -1.3020e+00,  1.3748e-01, -2.9987e+00,  3.0312e+00, -3.7014e-01,\n",
            "        -2.0581e+00,  1.9539e+00, -1.3162e+00,  2.0963e+00,  4.7407e-01,\n",
            "        -2.7702e+00, -1.2841e+00, -2.7996e+00, -5.7906e-01,  1.9015e+00,\n",
            "         2.6933e+00,  2.6687e+00,  1.0526e+00,  3.8948e-01,  4.8298e+00,\n",
            "        -3.0884e+00, -5.0789e-01,  1.3053e+00,  4.6759e+00,  1.2891e+00,\n",
            "         5.1962e-01])), ('module.encoder_q.layer3.2.bn1.running_var', tensor([ 5.7145,  8.0161,  6.8082, 16.5891,  5.8844, 13.6349, 11.1519, 29.4166,\n",
            "         5.5351,  8.3186,  9.3453,  6.1328,  6.9718,  8.7767,  6.5789, 18.5508,\n",
            "         9.9988,  8.0165, 16.1731,  5.7482, 15.8996, 14.8527,  9.3498, 10.3151,\n",
            "         9.2635, 11.7115, 12.4715,  8.4643,  7.6138,  6.2762,  6.1694,  9.1534,\n",
            "         9.9502, 13.0607,  8.6458, 15.3283,  7.1480,  5.9590,  8.7479,  7.5462,\n",
            "         7.6828,  6.5038,  7.1899,  9.3429,  8.0546,  8.0985, 11.3193,  7.1803,\n",
            "         6.2110,  6.1115, 11.0569,  7.5725,  9.1184,  6.9667,  7.9831, 12.6526,\n",
            "         6.7640,  7.5896,  8.7932,  8.9577, 10.7610, 10.5211,  5.2518,  9.4654,\n",
            "        12.8683,  5.5319, 18.7110,  7.9184,  6.3083,  9.8756,  7.6985, 14.2123,\n",
            "        10.3021,  7.4473,  6.4524,  8.7186,  6.3243,  9.3251,  6.7938,  7.6834,\n",
            "         6.7382, 10.8620,  8.1554,  7.5753, 16.7234,  7.6531,  9.1728, 34.6204,\n",
            "         7.9317,  8.3898,  7.8985, 11.7666, 10.0515,  7.9138,  9.5392,  6.3341,\n",
            "         8.3054,  7.2395,  8.6476,  7.1772,  8.7010, 11.2292, 21.1540,  7.3134,\n",
            "         7.5278,  9.7223,  7.1068,  8.6056, 14.6150, 10.2140,  9.9669,  6.6114,\n",
            "        12.8355, 14.1925,  7.9201,  8.2931, 33.8352,  7.7443,  6.5196, 11.1454,\n",
            "        13.4860,  9.5836,  6.9977, 14.0423, 12.8438,  6.9316,  7.8746, 14.0858,\n",
            "        12.6140,  6.9018, 12.8686,  7.1668, 12.3544, 12.3932,  9.5868,  8.8973,\n",
            "         9.6735,  8.1867,  7.2033, 10.1985,  7.4800, 12.1569,  7.2036, 12.0219,\n",
            "         8.2331, 13.9816,  6.5247,  7.1276, 10.4105,  9.8279, 10.5318,  7.4282,\n",
            "         5.4508,  8.4759,  9.3395, 16.0096,  8.3211,  7.5440,  7.4388, 19.1292,\n",
            "         7.4441,  6.6418, 20.1939, 10.9600,  7.3121,  9.2007,  6.5698,  6.6790,\n",
            "         8.8760,  9.8258,  5.7103,  7.0573,  7.6492,  6.6545,  9.4793,  6.6778,\n",
            "         9.8695,  7.5263, 13.8050,  6.1784,  9.4799, 13.0931,  5.2697,  7.2329,\n",
            "         7.9716,  7.5430,  6.3209, 13.8089,  8.2175,  9.1381, 11.9140,  7.2637,\n",
            "         7.0096,  6.0795,  6.6144,  8.4197,  5.9421,  8.2172, 10.2565,  6.6490,\n",
            "        11.1257,  7.6282,  6.8338,  6.8337,  9.1630,  9.3192,  6.6508,  8.5433,\n",
            "         6.3142,  9.2162, 11.1947,  7.5530,  6.0416,  9.5797, 16.6351,  5.4191,\n",
            "         8.7381,  8.8900,  6.6265,  5.5892,  8.8112,  7.6600,  9.9297, 12.5425,\n",
            "        14.8563,  5.4538,  8.2863,  7.5678, 16.5458,  7.9165, 10.3334,  7.8739,\n",
            "        14.9846, 14.5086,  9.1014,  7.2725,  8.3138, 19.5294,  7.6368,  8.8548,\n",
            "        15.3262,  7.2676,  7.6746,  5.5204,  5.6962, 10.1276,  8.6635,  6.7653,\n",
            "         8.4728, 14.9853,  6.9290, 10.2998,  5.4620, 14.3902,  6.7700,  7.8292])), ('module.encoder_q.layer3.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.2.conv2.weight', tensor([[[[-5.4168e-04,  1.0339e-02, -1.6587e-02],\n",
            "          [-1.7533e-02, -8.7808e-02, -1.0902e-02],\n",
            "          [ 6.2177e-02, -3.5370e-03, -4.1143e-02]],\n",
            "\n",
            "         [[-4.9695e-02, -2.7556e-02, -1.7843e-02],\n",
            "          [ 1.3183e-02, -2.7516e-02,  1.2126e-02],\n",
            "          [-3.0227e-02,  1.3107e-02, -6.3945e-03]],\n",
            "\n",
            "         [[-1.3602e-03, -1.8315e-02, -2.0239e-03],\n",
            "          [-3.5908e-02,  3.2231e-02, -1.2276e-02],\n",
            "          [ 4.8907e-03,  4.1454e-02,  8.6346e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8977e-02,  6.2603e-03,  4.3345e-02],\n",
            "          [-3.3647e-02, -2.9910e-02, -2.3436e-02],\n",
            "          [-4.0683e-03,  4.0610e-02, -5.9588e-02]],\n",
            "\n",
            "         [[ 2.2954e-02,  1.6462e-02, -5.2061e-04],\n",
            "          [ 7.5954e-03,  1.9910e-03, -2.1001e-02],\n",
            "          [-2.2131e-02,  1.9120e-02,  7.5926e-02]],\n",
            "\n",
            "         [[ 4.7659e-02, -1.3732e-02,  4.2728e-02],\n",
            "          [ 3.0401e-02, -4.8219e-02, -1.6298e-02],\n",
            "          [-1.7102e-02,  3.4528e-02, -1.9049e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.2676e-02, -2.3943e-02,  4.0902e-02],\n",
            "          [ 2.9706e-02, -2.3447e-03, -1.5748e-03],\n",
            "          [ 2.4131e-02,  1.7064e-02, -1.0673e-02]],\n",
            "\n",
            "         [[ 2.9037e-03, -1.4935e-02,  2.9900e-02],\n",
            "          [ 1.1150e-02, -4.1628e-02,  9.6721e-03],\n",
            "          [-3.6123e-02,  8.6614e-03,  2.7426e-03]],\n",
            "\n",
            "         [[ 2.0368e-02,  3.1964e-02,  1.9109e-02],\n",
            "          [ 5.4560e-05, -2.4806e-02,  1.9932e-02],\n",
            "          [ 1.2960e-02,  1.0500e-02, -9.5038e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1298e-02, -5.4673e-03, -1.2730e-02],\n",
            "          [-1.7791e-02,  8.4529e-02, -3.5636e-03],\n",
            "          [ 3.0105e-02, -3.9702e-02,  5.8817e-02]],\n",
            "\n",
            "         [[-1.9831e-02, -2.1341e-02,  1.9143e-02],\n",
            "          [-8.2904e-03,  3.5111e-02,  1.4167e-02],\n",
            "          [-2.5732e-02, -1.5582e-02, -2.4325e-02]],\n",
            "\n",
            "         [[-3.2494e-02,  4.6181e-02,  4.3478e-02],\n",
            "          [-3.4011e-02, -4.0990e-02,  5.0778e-02],\n",
            "          [-3.0518e-02,  1.3209e-02,  5.6890e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.7551e-03,  5.2057e-02,  1.0056e-02],\n",
            "          [-4.0230e-02,  3.1678e-02, -5.4616e-02],\n",
            "          [-1.5961e-02, -6.1150e-02,  1.0793e-02]],\n",
            "\n",
            "         [[ 2.7394e-02, -2.6028e-03, -6.0080e-02],\n",
            "          [-2.4589e-02, -2.8538e-02,  3.4193e-02],\n",
            "          [ 7.8233e-03,  1.7275e-02, -4.8757e-03]],\n",
            "\n",
            "         [[ 2.2772e-02,  1.2981e-02, -2.0641e-02],\n",
            "          [ 2.7020e-02, -1.4294e-02, -4.5964e-02],\n",
            "          [ 2.0589e-02, -2.8332e-02, -6.5079e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5993e-03, -1.6798e-02,  2.1003e-02],\n",
            "          [-1.9093e-02,  2.7468e-03, -1.4196e-02],\n",
            "          [ 2.3257e-02, -4.5500e-03, -5.2348e-02]],\n",
            "\n",
            "         [[-2.5587e-03,  1.0613e-02, -4.3555e-02],\n",
            "          [-2.0225e-02, -1.9691e-02,  2.2501e-02],\n",
            "          [ 2.3606e-02, -3.6953e-02,  2.8408e-02]],\n",
            "\n",
            "         [[ 3.8348e-03,  4.8856e-02, -1.3682e-02],\n",
            "          [-1.6585e-02, -1.1090e-03, -1.1490e-02],\n",
            "          [-3.0541e-02, -6.9315e-03, -1.7122e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.1356e-04, -3.1964e-02,  1.4811e-02],\n",
            "          [ 1.6274e-02, -2.1792e-02, -1.6272e-02],\n",
            "          [-9.1928e-03,  3.5074e-02, -3.1775e-02]],\n",
            "\n",
            "         [[ 3.8800e-02,  6.1190e-02,  3.6118e-02],\n",
            "          [-6.8331e-02, -4.5392e-02,  5.1494e-03],\n",
            "          [ 2.4394e-02, -3.7025e-02,  6.6163e-03]],\n",
            "\n",
            "         [[ 4.9750e-02, -1.5008e-02, -1.3730e-03],\n",
            "          [-1.6301e-02,  1.1482e-02,  2.6874e-02],\n",
            "          [-2.9568e-02,  4.8946e-03,  1.0343e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2839e-02, -6.4477e-02,  4.5242e-02],\n",
            "          [ 3.8689e-04, -4.7284e-02,  3.8690e-03],\n",
            "          [-4.1928e-03,  1.4552e-02, -4.0109e-03]],\n",
            "\n",
            "         [[-2.7907e-02,  2.4875e-02, -3.6380e-03],\n",
            "          [-7.9978e-02,  2.4132e-02,  9.0164e-03],\n",
            "          [ 3.1312e-02,  4.5227e-02,  1.7890e-02]],\n",
            "\n",
            "         [[-5.3040e-04,  4.6226e-02, -5.4934e-02],\n",
            "          [ 8.4473e-03,  2.8950e-02,  3.4158e-02],\n",
            "          [ 5.2543e-02, -1.7913e-03, -2.8127e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1056e-02, -4.6818e-03, -8.4885e-03],\n",
            "          [-2.0396e-02, -1.7501e-03,  3.5095e-03],\n",
            "          [ 4.4179e-02,  3.7546e-03, -5.4442e-03]],\n",
            "\n",
            "         [[-3.6688e-02,  4.6713e-02,  3.1785e-02],\n",
            "          [-2.5131e-02, -6.0888e-02,  1.7683e-03],\n",
            "          [-3.0407e-03, -1.1833e-02,  2.6968e-02]],\n",
            "\n",
            "         [[ 2.9034e-02,  1.3320e-02,  2.4615e-02],\n",
            "          [-5.7686e-03, -3.2835e-02, -3.5133e-03],\n",
            "          [ 6.6079e-03, -1.1575e-03,  1.5798e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8429e-02, -2.0794e-02,  6.1056e-02],\n",
            "          [ 2.6777e-02,  1.9370e-02, -2.4641e-02],\n",
            "          [ 2.1497e-02, -2.2025e-02, -3.0430e-02]],\n",
            "\n",
            "         [[ 2.5745e-02,  7.8561e-03,  1.7921e-02],\n",
            "          [ 1.9577e-02, -2.5057e-02, -6.4645e-03],\n",
            "          [-1.9825e-02,  3.0840e-02,  3.1031e-03]],\n",
            "\n",
            "         [[-8.8098e-03, -1.9962e-02,  1.1012e-02],\n",
            "          [-3.7840e-03, -2.9776e-02, -2.4879e-03],\n",
            "          [ 2.3987e-02,  5.4485e-03, -1.6400e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.1759e-02, -3.3252e-02,  2.5154e-02],\n",
            "          [ 5.3209e-02,  3.6945e-02, -1.3985e-02],\n",
            "          [-1.4515e-02, -1.5452e-02,  1.5415e-02]],\n",
            "\n",
            "         [[ 3.3794e-02, -9.1467e-03, -2.8968e-02],\n",
            "          [ 5.4053e-02, -2.1830e-02, -1.9901e-02],\n",
            "          [-2.1631e-02,  8.3061e-03, -4.6135e-02]],\n",
            "\n",
            "         [[ 1.3512e-02,  2.6337e-02, -3.1979e-02],\n",
            "          [-2.9507e-02, -2.3943e-02,  1.5345e-02],\n",
            "          [ 1.7225e-02,  1.0872e-02, -1.2107e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9911e-02,  1.7616e-02, -1.7073e-02],\n",
            "          [-2.4325e-02, -2.0983e-03,  2.5379e-02],\n",
            "          [-9.4005e-03,  2.7426e-02,  2.7398e-02]],\n",
            "\n",
            "         [[-1.0048e-02, -4.6251e-02,  1.2511e-02],\n",
            "          [-2.4991e-03, -9.2513e-04,  4.0922e-02],\n",
            "          [-2.0555e-02,  6.6282e-02,  3.9750e-02]],\n",
            "\n",
            "         [[-7.7553e-03,  5.4904e-02, -1.3507e-02],\n",
            "          [-3.9610e-02,  1.9236e-02, -3.3304e-02],\n",
            "          [-6.1590e-03,  1.5040e-02,  3.1869e-02]]]])), ('module.encoder_q.layer3.2.bn2.weight', tensor([0.9922, 0.9927, 0.9917, 0.9916, 0.9929, 0.9917, 0.9920, 0.9932, 0.9911,\n",
            "        0.9917, 0.9924, 0.9919, 0.9916, 0.9920, 0.9926, 0.9920, 0.9922, 0.9928,\n",
            "        0.9930, 0.9917, 0.9922, 0.9938, 0.9929, 0.9924, 0.9917, 0.9930, 0.9933,\n",
            "        0.9928, 0.9931, 0.9922, 0.9931, 0.9918, 0.9916, 0.9919, 0.9916, 0.9926,\n",
            "        0.9923, 0.9927, 0.9925, 0.9925, 0.9924, 0.9916, 0.9915, 0.9913, 0.9923,\n",
            "        0.9923, 0.9925, 0.9922, 0.9914, 0.9920, 0.9922, 0.9912, 0.9925, 0.9922,\n",
            "        0.9922, 0.9928, 0.9927, 0.9926, 0.9911, 0.9921, 0.9914, 0.9929, 0.9921,\n",
            "        0.9931, 0.9914, 0.9920, 0.9931, 0.9927, 0.9921, 0.9917, 0.9932, 0.9931,\n",
            "        0.9916, 0.9922, 0.9929, 0.9929, 0.9929, 0.9914, 0.9919, 0.9916, 0.9917,\n",
            "        0.9927, 0.9919, 0.9918, 0.9932, 0.9921, 0.9928, 0.9914, 0.9927, 0.9920,\n",
            "        0.9929, 0.9925, 0.9917, 0.9924, 0.9918, 0.9905, 0.9922, 0.9924, 0.9924,\n",
            "        0.9916, 0.9925, 0.9927, 0.9929, 0.9914, 0.9930, 0.9920, 0.9924, 0.9922,\n",
            "        0.9929, 0.9925, 0.9920, 0.9918, 0.9921, 0.9929, 0.9923, 0.9931, 0.9929,\n",
            "        0.9924, 0.9931, 0.9925, 0.9912, 0.9915, 0.9917, 0.9930, 0.9927, 0.9926,\n",
            "        0.9926, 0.9923, 0.9922, 0.9915, 0.9921, 0.9919, 0.9916, 0.9929, 0.9926,\n",
            "        0.9924, 0.9923, 0.9932, 0.9923, 0.9916, 0.9920, 0.9908, 0.9918, 0.9924,\n",
            "        0.9919, 0.9920, 0.9922, 0.9931, 0.9922, 0.9911, 0.9926, 0.9924, 0.9920,\n",
            "        0.9943, 0.9926, 0.9925, 0.9918, 0.9940, 0.9926, 0.9932, 0.9921, 0.9909,\n",
            "        0.9920, 0.9929, 0.9932, 0.9927, 0.9922, 0.9912, 0.9929, 0.9922, 0.9924,\n",
            "        0.9929, 0.9922, 0.9927, 0.9918, 0.9917, 0.9921, 0.9912, 0.9918, 0.9920,\n",
            "        0.9923, 0.9918, 0.9924, 0.9908, 0.9933, 0.9915, 0.9929, 0.9923, 0.9924,\n",
            "        0.9917, 0.9925, 0.9914, 0.9925, 0.9924, 0.9916, 0.9926, 0.9941, 0.9928,\n",
            "        0.9918, 0.9930, 0.9922, 0.9919, 0.9921, 0.9918, 0.9920, 0.9922, 0.9923,\n",
            "        0.9917, 0.9920, 0.9943, 0.9916, 0.9918, 0.9924, 0.9932, 0.9938, 0.9925,\n",
            "        0.9929, 0.9926, 0.9918, 0.9944, 0.9913, 0.9928, 0.9918, 0.9922, 0.9910,\n",
            "        0.9900, 0.9932, 0.9919, 0.9923, 0.9926, 0.9921, 0.9928, 0.9924, 0.9923,\n",
            "        0.9920, 0.9926, 0.9919, 0.9918, 0.9933, 0.9919, 0.9925, 0.9922, 0.9907,\n",
            "        0.9916, 0.9915, 0.9922, 0.9917, 0.9917, 0.9937, 0.9924, 0.9928, 0.9917,\n",
            "        0.9926, 0.9918, 0.9919, 0.9928])), ('module.encoder_q.layer3.2.bn2.bias', tensor([ 3.5194e-04, -9.0044e-05, -1.3457e-03, -4.9313e-05,  9.6255e-04,\n",
            "        -6.6553e-04, -9.6994e-05,  1.1049e-03, -1.4441e-03,  6.3704e-05,\n",
            "        -1.7550e-04, -1.0631e-03,  1.3613e-04, -8.5618e-05, -5.8687e-04,\n",
            "        -1.6829e-04, -1.3072e-03, -3.3291e-04,  9.7038e-05,  3.2157e-04,\n",
            "         5.4166e-04,  1.4729e-03,  5.3034e-04,  1.3026e-03, -1.1398e-03,\n",
            "        -8.8438e-05,  8.4957e-04, -2.3763e-05,  6.6749e-04, -1.6816e-04,\n",
            "         1.3871e-04, -2.5331e-05, -3.7318e-04, -8.2056e-04, -8.7020e-04,\n",
            "         1.6261e-04, -2.0382e-04,  2.3368e-04,  2.5432e-04,  8.3383e-04,\n",
            "         1.0931e-03,  4.5144e-04, -4.1143e-05, -1.0492e-03,  8.7016e-05,\n",
            "        -1.3086e-04,  6.7699e-05, -6.3609e-04, -7.3195e-04, -2.4326e-04,\n",
            "        -2.8141e-04, -9.6877e-05,  3.6933e-04,  2.4398e-04, -1.0777e-04,\n",
            "        -1.1087e-03, -4.7369e-04,  3.7504e-04, -5.1597e-04, -7.1679e-04,\n",
            "         2.1441e-04, -5.7624e-06, -1.6089e-04,  2.6497e-04,  1.1841e-04,\n",
            "        -1.6361e-04, -1.9665e-04,  1.1660e-03,  4.8520e-05, -8.9399e-05,\n",
            "         1.2920e-04,  4.9205e-04, -5.8683e-04, -3.1874e-04,  1.9536e-04,\n",
            "         8.8326e-04, -2.5283e-05, -2.8728e-04, -1.3314e-03, -4.6389e-04,\n",
            "        -6.1097e-04,  1.6361e-04, -7.9361e-04, -1.7313e-04,  6.1893e-04,\n",
            "         8.0927e-06,  5.7711e-04, -5.6998e-04,  8.3090e-06,  3.0240e-04,\n",
            "        -6.4592e-04, -2.9231e-04, -3.1443e-06,  9.2148e-04, -8.1535e-04,\n",
            "        -1.0789e-03,  3.5787e-05,  1.0322e-03, -4.3913e-04, -8.0628e-04,\n",
            "        -2.2566e-04,  2.2278e-04, -6.5327e-05, -1.2027e-03,  6.9736e-04,\n",
            "        -4.1149e-04,  7.4716e-04,  2.4640e-04,  6.9696e-04,  5.0660e-04,\n",
            "        -4.9410e-04, -2.8688e-04,  4.8597e-04,  2.7306e-05,  2.6845e-04,\n",
            "         7.2494e-04,  5.0772e-04,  6.5079e-04, -3.4980e-04,  2.5885e-04,\n",
            "        -1.6047e-04, -5.0210e-04, -6.0557e-04,  1.3965e-03,  3.7978e-04,\n",
            "         1.2299e-03,  1.3557e-04, -3.2014e-04,  3.8774e-04, -8.9503e-04,\n",
            "        -1.0600e-04, -4.6859e-04, -5.2410e-04,  1.6997e-04, -2.5770e-04,\n",
            "        -1.2351e-04, -5.0947e-04,  1.4235e-04, -1.8008e-04, -3.3324e-04,\n",
            "        -3.7343e-04, -9.1079e-04, -3.0969e-04, -3.0978e-04, -2.7116e-04,\n",
            "        -3.1258e-04, -3.5011e-04,  5.2067e-04, -2.6851e-04, -1.1175e-03,\n",
            "         1.9388e-04, -3.2187e-04, -1.7887e-04,  1.4374e-03, -2.6537e-04,\n",
            "         5.4098e-04, -3.4469e-04,  6.9674e-04, -3.4128e-04,  4.0450e-04,\n",
            "         1.7563e-04, -2.2460e-04, -2.0804e-04,  7.3668e-04,  1.1051e-03,\n",
            "         4.7175e-04,  5.0498e-04, -1.1846e-04,  5.0076e-04, -3.4750e-04,\n",
            "         3.2308e-05,  5.1755e-04, -2.5059e-04, -3.4708e-04, -1.1328e-04,\n",
            "        -1.2323e-04,  1.9232e-04, -6.2247e-04, -2.1898e-04,  1.1584e-04,\n",
            "         3.2970e-04, -4.6932e-04, -6.2865e-07, -5.2514e-04,  2.5031e-04,\n",
            "        -2.6169e-04,  2.5126e-04,  4.6242e-04,  9.6714e-04,  4.9176e-05,\n",
            "        -4.8365e-04, -3.7140e-04,  4.4300e-04, -6.8736e-04,  4.9914e-05,\n",
            "        -4.0261e-04,  8.0332e-04, -2.1858e-04, -1.9801e-04,  3.2260e-04,\n",
            "         2.8635e-04, -2.8026e-04,  8.2823e-04, -8.1726e-04, -8.1294e-05,\n",
            "        -3.2606e-04,  6.4402e-04, -1.2387e-03,  3.8621e-04,  1.6955e-03,\n",
            "        -2.9593e-04, -2.1518e-04,  1.1524e-04,  1.0974e-03,  9.9250e-04,\n",
            "         2.2109e-04,  5.4776e-04,  6.9768e-04, -6.6914e-04,  1.6167e-03,\n",
            "        -1.8434e-03, -2.4141e-04, -1.8695e-04, -4.1564e-04, -1.7837e-05,\n",
            "        -1.0282e-03,  8.9020e-04,  4.0702e-04, -9.4699e-05,  1.8538e-04,\n",
            "        -1.0220e-04,  5.4982e-04,  2.5951e-04,  3.7834e-05,  4.2621e-04,\n",
            "         1.8110e-04,  6.1242e-05, -5.8138e-04,  4.8316e-04,  5.4748e-04,\n",
            "        -4.2117e-04, -1.9998e-04, -1.4769e-03, -1.0584e-03,  1.3509e-04,\n",
            "         2.8863e-04,  9.1856e-05, -2.3440e-04,  1.0972e-03, -1.5171e-04,\n",
            "        -3.2716e-04,  1.9380e-04,  3.9166e-04, -1.6906e-04, -1.0452e-05,\n",
            "         1.4850e-04])), ('module.encoder_q.layer3.2.bn2.running_mean', tensor([-5.5670e-01, -2.0834e-01, -3.2531e-01,  3.6948e-01, -4.6433e-01,\n",
            "         1.5381e-01,  2.7872e-01,  5.1203e-01, -7.5875e-03, -3.9951e-02,\n",
            "         3.2489e-01, -2.3413e-01, -6.6729e-01, -4.2008e-01,  4.6056e-01,\n",
            "        -3.5299e-01, -5.4448e-01,  5.3773e-02, -2.2088e-01, -4.4441e-01,\n",
            "        -8.4100e-01, -7.0285e-01, -5.8364e-02,  3.6649e-01,  5.1866e-01,\n",
            "         2.1287e-01, -4.7457e-01,  6.0329e-01, -2.1987e-01, -1.6310e-01,\n",
            "         2.1258e-01, -2.3787e-01,  6.2388e-01, -1.1492e+00,  2.3889e-01,\n",
            "         1.4220e-01, -7.8490e-01,  7.5973e-01,  3.3410e-01, -2.1750e-01,\n",
            "         3.6377e-01,  9.3855e-02, -1.1199e+00,  3.8214e-01, -6.0413e-01,\n",
            "        -3.3865e-01, -4.8227e-01,  4.5363e-02,  1.0585e-01, -2.1544e-01,\n",
            "         8.0753e-02, -4.3433e-01,  3.5298e-01,  7.1286e-01, -2.4036e-03,\n",
            "         5.0633e-01,  2.5716e-01, -1.3049e-01, -2.4817e-01,  3.1471e-01,\n",
            "         2.6372e-01, -6.2976e-02,  4.1889e-02,  1.3450e-01, -1.8221e-02,\n",
            "         3.4746e-01,  3.6952e-01, -1.2683e-01,  3.5531e-01,  4.6813e-02,\n",
            "         7.2407e-01,  3.7458e-01,  9.2633e-01,  1.7320e-03, -4.7959e-01,\n",
            "        -2.0826e-01,  2.1158e-01,  2.3373e-01, -2.4980e-01, -5.8141e-01,\n",
            "        -3.0272e-01, -2.9038e-01,  2.8489e-01, -4.1198e-01, -8.5598e-02,\n",
            "         1.8833e-01, -1.0215e-02,  8.7328e-01,  6.1040e-02, -2.0255e-01,\n",
            "        -1.0315e-01, -3.3278e-01,  1.2912e-01, -4.0872e-01, -2.9679e-01,\n",
            "         2.4732e-01, -3.7157e-01, -2.7515e-01,  1.2499e-01, -4.9812e-01,\n",
            "        -2.4078e-01, -1.4537e-01,  6.0314e-01, -5.7100e-01,  3.0330e-01,\n",
            "         3.8842e-01,  1.1121e-01, -2.5948e-01,  7.9608e-02, -5.8244e-02,\n",
            "         3.3161e-01,  2.1129e-01, -1.1285e-01,  2.6918e-01, -3.7137e-01,\n",
            "         1.1663e+00, -3.2594e-02,  1.4388e-02,  4.0066e-01, -5.8760e-01,\n",
            "         4.1699e-01, -1.4347e-01, -4.0850e-01,  1.0745e-01, -3.7316e-01,\n",
            "        -9.0518e-02, -6.1966e-02,  4.6600e-01,  1.2812e-01, -2.6999e-01,\n",
            "        -2.5232e-01,  5.8227e-02, -2.4722e-01,  5.0808e-01,  1.3867e-01,\n",
            "         1.6392e-01,  1.7920e-01,  3.4481e-01,  4.4552e-01, -4.2947e-01,\n",
            "         1.5463e-01, -1.6198e-01,  4.1870e-01, -6.1871e-01, -1.0799e+00,\n",
            "         1.1255e-01, -1.8150e-01,  1.8318e-01,  6.1120e-01, -2.8112e-01,\n",
            "        -2.7103e-01, -4.8579e-01,  3.4534e-01, -3.6398e-02, -8.5768e-02,\n",
            "        -2.0599e-01, -1.7026e-01,  7.7493e-01,  1.8713e-01,  1.1498e-01,\n",
            "        -3.3099e-01,  1.6331e-01, -3.2996e-01,  6.6486e-01, -7.7812e-01,\n",
            "         6.4379e-01, -4.1647e-01,  3.0896e-01, -3.1746e-01,  2.7250e-02,\n",
            "         1.5820e-01, -6.5354e-01,  3.6977e-01,  3.6088e-01,  3.6141e-01,\n",
            "         4.2600e-01, -3.0335e-02,  4.6816e-01,  4.4976e-01, -1.0441e-01,\n",
            "        -1.5537e-01, -2.8609e-01, -9.0426e-01, -1.6172e-01,  5.9290e-01,\n",
            "         5.4974e-01,  2.9774e-01, -5.9534e-01, -2.6443e-01, -3.2498e-02,\n",
            "         9.4707e-02, -2.0071e-01,  2.5017e-01, -5.1249e-01, -7.7148e-01,\n",
            "         3.8081e-01,  3.7491e-01, -1.3226e-01, -6.5712e-01,  1.7482e-01,\n",
            "         8.2295e-02, -6.6959e-01, -6.2682e-01, -3.7587e-01,  2.3109e-01,\n",
            "        -5.1350e-02, -9.9845e-01,  4.2525e-01, -1.1507e-01, -2.5460e-01,\n",
            "        -2.8108e-01,  1.3975e-01,  2.5839e-01,  7.3310e-02, -5.9944e-01,\n",
            "         7.1487e-02,  4.2200e-02,  5.8932e-03,  3.9518e-01,  7.6575e-01,\n",
            "        -1.3743e-01, -4.8818e-01,  6.9203e-02,  4.5363e-01,  3.3070e-01,\n",
            "         2.1347e-01,  5.4151e-01,  3.8270e-01,  9.5785e-02, -2.5909e-01,\n",
            "        -3.6603e-02, -4.4414e-01, -3.4174e-01,  3.6228e-01, -2.2496e-01,\n",
            "        -4.7374e-02, -2.1037e-01, -1.8323e+00, -6.8778e-01,  5.0944e-02,\n",
            "         5.9080e-01, -4.4579e-01, -5.8633e-02, -5.6094e-01,  2.1368e-01,\n",
            "         4.5861e-01, -6.3766e-01,  7.3585e-02, -1.3898e-01,  2.2528e-01,\n",
            "        -2.2663e-01, -2.1481e-01, -2.5884e-01,  4.8324e-01,  7.8865e-01,\n",
            "        -3.3360e-02])), ('module.encoder_q.layer3.2.bn2.running_var', tensor([1.4377, 0.8020, 0.6497, 0.5918, 0.7049, 0.6061, 0.7429, 1.3929, 1.0083,\n",
            "        0.6648, 0.8088, 0.7047, 1.2486, 0.6157, 1.3059, 0.8559, 0.6105, 0.5208,\n",
            "        0.9815, 0.8699, 0.8671, 0.5246, 0.6409, 0.5820, 0.5963, 0.4646, 0.5855,\n",
            "        1.2284, 0.5961, 0.7434, 0.9171, 0.6693, 1.1913, 1.0466, 0.5755, 0.9345,\n",
            "        0.7303, 1.0243, 0.6675, 0.7003, 0.8540, 0.6952, 0.9288, 0.5706, 0.5855,\n",
            "        0.5961, 0.8037, 0.7327, 0.6237, 0.6099, 0.6251, 1.0123, 0.7322, 0.6322,\n",
            "        1.1221, 0.5888, 0.9666, 0.4984, 0.5313, 0.7125, 0.7404, 0.6583, 0.5869,\n",
            "        0.6236, 0.6431, 0.6779, 0.6735, 0.5817, 0.7739, 1.0894, 1.0787, 0.4731,\n",
            "        1.0701, 0.5945, 0.6943, 0.7748, 0.6288, 0.5300, 0.6299, 0.6250, 0.5444,\n",
            "        0.5982, 0.9239, 1.0254, 0.8252, 0.5283, 0.6478, 0.5825, 0.6137, 0.7220,\n",
            "        0.5710, 0.5775, 0.8106, 1.1673, 0.5943, 0.5857, 0.5616, 0.8184, 0.5671,\n",
            "        0.7024, 1.0251, 0.5974, 1.4068, 1.0629, 0.5743, 1.0630, 0.6660, 0.6941,\n",
            "        0.7142, 1.0849, 0.8893, 0.8335, 1.3584, 0.6000, 1.2556, 1.0414, 0.4498,\n",
            "        0.5987, 0.6332, 0.7395, 0.6741, 0.5969, 0.6132, 0.6028, 0.5389, 0.5317,\n",
            "        0.5999, 0.7908, 0.7119, 0.8253, 0.5094, 0.5558, 0.7959, 0.7193, 1.0132,\n",
            "        0.6738, 1.2024, 0.6824, 0.8372, 0.7068, 0.6657, 0.8930, 0.7843, 0.6191,\n",
            "        0.6936, 0.5804, 0.7338, 0.8080, 0.6018, 0.4902, 0.5053, 1.0617, 0.6258,\n",
            "        0.6496, 0.7094, 0.6705, 0.5985, 0.5774, 0.5868, 0.6816, 0.5730, 0.5238,\n",
            "        1.1512, 0.6525, 0.6892, 0.7008, 0.7066, 0.5554, 0.6844, 0.7077, 0.5353,\n",
            "        0.6518, 1.0768, 0.9798, 0.5576, 0.8412, 0.6191, 0.5022, 1.2744, 0.8780,\n",
            "        0.6913, 0.7147, 0.8450, 0.5981, 0.6166, 0.9670, 0.7366, 1.2755, 0.5362,\n",
            "        0.6673, 0.6324, 0.6597, 0.6676, 0.5278, 0.6475, 0.5401, 0.6779, 0.5540,\n",
            "        1.2549, 0.6299, 0.5138, 1.3492, 1.2638, 0.6459, 0.4991, 0.5992, 1.1151,\n",
            "        0.4997, 0.5895, 0.6843, 0.6744, 0.7396, 0.6360, 0.9034, 0.6779, 1.0652,\n",
            "        0.5226, 0.7300, 0.6210, 0.8581, 0.7937, 0.7025, 0.7510, 0.6946, 0.6381,\n",
            "        0.5853, 1.0129, 0.6392, 0.6586, 1.3014, 0.6663, 0.5029, 0.6724, 0.5515,\n",
            "        0.9471, 0.4889, 0.5735, 1.2355, 0.5587, 0.6200, 0.6149, 0.5178, 0.5772,\n",
            "        0.7535, 0.5448, 0.8538, 1.0913, 0.4864, 0.5632, 0.7161, 0.6339, 1.2129,\n",
            "        0.5676, 0.5553, 1.0575, 0.7826])), ('module.encoder_q.layer3.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.2.conv3.weight', tensor([[[[ 0.0511]],\n",
            "\n",
            "         [[-0.0202]],\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         [[ 0.0437]],\n",
            "\n",
            "         [[ 0.0100]]],\n",
            "\n",
            "\n",
            "        [[[-0.0779]],\n",
            "\n",
            "         [[ 0.0214]],\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0044]],\n",
            "\n",
            "         [[ 0.0368]],\n",
            "\n",
            "         [[ 0.0462]]],\n",
            "\n",
            "\n",
            "        [[[-0.0353]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.0054]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0330]],\n",
            "\n",
            "         [[-0.0146]],\n",
            "\n",
            "         [[ 0.0518]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0210]],\n",
            "\n",
            "         [[-0.0839]],\n",
            "\n",
            "         [[-0.0273]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0369]],\n",
            "\n",
            "         [[ 0.0556]],\n",
            "\n",
            "         [[-0.0399]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0402]],\n",
            "\n",
            "         [[ 0.0348]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0033]],\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         [[ 0.0792]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[-0.0110]],\n",
            "\n",
            "         [[-0.0208]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0409]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[-0.0233]]]])), ('module.encoder_q.layer3.2.bn3.weight', tensor([0.9919, 0.9919, 0.9925,  ..., 0.9921, 0.9919, 0.9921])), ('module.encoder_q.layer3.2.bn3.bias', tensor([-0.0004,  0.0003,  0.0002,  ..., -0.0001, -0.0004, -0.0002])), ('module.encoder_q.layer3.2.bn3.running_mean', tensor([-0.0197, -0.1183, -0.3978,  ..., -0.6184,  0.2228, -0.2560])), ('module.encoder_q.layer3.2.bn3.running_var', tensor([0.1643, 0.1612, 0.1691,  ..., 0.2859, 0.1275, 0.1931])), ('module.encoder_q.layer3.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.3.conv1.weight', tensor([[[[ 0.1266]],\n",
            "\n",
            "         [[-0.0304]],\n",
            "\n",
            "         [[-0.0221]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1503]],\n",
            "\n",
            "         [[-0.0579]],\n",
            "\n",
            "         [[-0.0081]]],\n",
            "\n",
            "\n",
            "        [[[-0.0558]],\n",
            "\n",
            "         [[ 0.0842]],\n",
            "\n",
            "         [[ 0.0409]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0688]],\n",
            "\n",
            "         [[ 0.0075]],\n",
            "\n",
            "         [[-0.0751]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0163]],\n",
            "\n",
            "         [[ 0.1276]],\n",
            "\n",
            "         [[-0.1326]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0703]],\n",
            "\n",
            "         [[-0.1338]],\n",
            "\n",
            "         [[ 0.0800]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0175]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         [[ 0.1160]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0777]],\n",
            "\n",
            "         [[-0.0528]],\n",
            "\n",
            "         [[-0.0360]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0641]],\n",
            "\n",
            "         [[ 0.0960]],\n",
            "\n",
            "         [[ 0.1424]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1005]],\n",
            "\n",
            "         [[ 0.0589]],\n",
            "\n",
            "         [[-0.0441]]],\n",
            "\n",
            "\n",
            "        [[[-0.0724]],\n",
            "\n",
            "         [[ 0.1746]],\n",
            "\n",
            "         [[ 0.0770]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0761]],\n",
            "\n",
            "         [[-0.1230]],\n",
            "\n",
            "         [[-0.0482]]]])), ('module.encoder_q.layer3.3.bn1.weight', tensor([0.9926, 0.9922, 0.9918, 0.9922, 0.9919, 0.9922, 0.9922, 0.9927, 0.9918,\n",
            "        0.9928, 0.9916, 0.9918, 0.9927, 0.9920, 0.9914, 0.9919, 0.9924, 0.9914,\n",
            "        0.9921, 0.9920, 0.9919, 0.9920, 0.9927, 0.9930, 0.9925, 0.9923, 0.9923,\n",
            "        0.9923, 0.9930, 0.9928, 0.9924, 0.9932, 0.9919, 0.9928, 0.9929, 0.9923,\n",
            "        0.9925, 0.9922, 0.9927, 0.9926, 0.9933, 0.9920, 0.9924, 0.9917, 0.9922,\n",
            "        0.9929, 0.9917, 0.9918, 0.9924, 0.9916, 0.9920, 0.9926, 0.9915, 0.9919,\n",
            "        0.9925, 0.9915, 0.9929, 0.9927, 0.9930, 0.9924, 0.9925, 0.9924, 0.9922,\n",
            "        0.9923, 0.9934, 0.9925, 0.9919, 0.9925, 0.9922, 0.9922, 0.9925, 0.9914,\n",
            "        0.9915, 0.9912, 0.9927, 0.9922, 0.9920, 0.9926, 0.9928, 0.9923, 0.9928,\n",
            "        0.9924, 0.9926, 0.9922, 0.9918, 0.9925, 0.9924, 0.9911, 0.9926, 0.9924,\n",
            "        0.9922, 0.9915, 0.9926, 0.9930, 0.9926, 0.9929, 0.9918, 0.9925, 0.9916,\n",
            "        0.9918, 0.9927, 0.9925, 0.9924, 0.9926, 0.9930, 0.9920, 0.9924, 0.9918,\n",
            "        0.9919, 0.9920, 0.9915, 0.9924, 0.9932, 0.9931, 0.9915, 0.9916, 0.9931,\n",
            "        0.9922, 0.9930, 0.9924, 0.9922, 0.9921, 0.9924, 0.9914, 0.9924, 0.9926,\n",
            "        0.9923, 0.9928, 0.9926, 0.9917, 0.9919, 0.9928, 0.9919, 0.9920, 0.9923,\n",
            "        0.9926, 0.9919, 0.9929, 0.9922, 0.9923, 0.9920, 0.9920, 0.9918, 0.9922,\n",
            "        0.9915, 0.9914, 0.9920, 0.9917, 0.9922, 0.9935, 0.9924, 0.9923, 0.9926,\n",
            "        0.9927, 0.9925, 0.9929, 0.9914, 0.9918, 0.9923, 0.9927, 0.9919, 0.9911,\n",
            "        0.9928, 0.9925, 0.9932, 0.9932, 0.9930, 0.9924, 0.9922, 0.9922, 0.9925,\n",
            "        0.9925, 0.9919, 0.9926, 0.9924, 0.9913, 0.9924, 0.9919, 0.9922, 0.9933,\n",
            "        0.9933, 0.9937, 0.9924, 0.9925, 0.9922, 0.9926, 0.9911, 0.9919, 0.9919,\n",
            "        0.9926, 0.9923, 0.9921, 0.9926, 0.9918, 0.9924, 0.9922, 0.9925, 0.9912,\n",
            "        0.9922, 0.9928, 0.9914, 0.9919, 0.9925, 0.9909, 0.9913, 0.9919, 0.9925,\n",
            "        0.9920, 0.9925, 0.9922, 0.9927, 0.9922, 0.9920, 0.9920, 0.9918, 0.9920,\n",
            "        0.9911, 0.9915, 0.9919, 0.9922, 0.9931, 0.9918, 0.9920, 0.9936, 0.9927,\n",
            "        0.9921, 0.9924, 0.9923, 0.9920, 0.9926, 0.9923, 0.9928, 0.9919, 0.9915,\n",
            "        0.9922, 0.9924, 0.9919, 0.9926, 0.9920, 0.9914, 0.9918, 0.9923, 0.9921,\n",
            "        0.9927, 0.9922, 0.9922, 0.9924, 0.9929, 0.9932, 0.9925, 0.9912, 0.9920,\n",
            "        0.9912, 0.9923, 0.9924, 0.9929])), ('module.encoder_q.layer3.3.bn1.bias', tensor([ 7.1265e-04, -9.3253e-05, -3.4346e-04,  4.5250e-04,  9.4854e-05,\n",
            "        -2.7519e-04,  7.2210e-04,  7.4708e-04,  3.5650e-04, -1.0242e-04,\n",
            "        -9.5418e-04, -4.8515e-04,  2.1130e-04, -1.6012e-04, -1.3214e-03,\n",
            "        -2.5038e-04, -7.3735e-05, -1.3739e-03,  5.6101e-05,  7.5622e-04,\n",
            "        -8.2766e-04, -8.7078e-05,  1.5697e-04, -2.6425e-04, -1.6653e-04,\n",
            "        -4.6613e-04,  1.9674e-04, -4.4163e-05,  1.0710e-03,  7.3778e-05,\n",
            "        -1.5736e-04,  3.4235e-04, -4.0585e-04,  6.6722e-04,  6.1405e-04,\n",
            "        -1.7194e-05,  1.2004e-04,  3.7111e-04, -1.2432e-04,  4.6258e-04,\n",
            "         4.6169e-04, -4.9843e-04, -6.3746e-04, -1.6638e-04, -2.0734e-04,\n",
            "         3.0820e-04, -4.5438e-04, -3.5751e-04,  1.0190e-04, -4.3869e-04,\n",
            "        -6.8435e-04,  7.6869e-04, -5.7068e-05,  9.1255e-05,  6.8292e-04,\n",
            "        -9.1801e-04,  6.0766e-04,  8.0978e-05,  1.1270e-04,  1.7921e-04,\n",
            "        -1.7467e-04, -7.3562e-05, -2.6289e-04,  4.8413e-04,  4.2616e-04,\n",
            "         1.4372e-04, -2.4517e-04, -7.8899e-05,  5.8964e-04, -2.7039e-04,\n",
            "         7.4310e-04, -3.7910e-04, -8.6716e-04, -6.1147e-04, -1.0479e-04,\n",
            "         4.7065e-04, -2.3437e-04,  4.6576e-04, -1.2422e-04,  5.8679e-04,\n",
            "        -1.6577e-05, -5.1691e-05,  1.1671e-03, -1.7808e-04, -6.0754e-04,\n",
            "        -1.4739e-04,  4.8282e-04, -7.6646e-04,  8.9189e-05, -3.7111e-04,\n",
            "         1.9853e-04, -1.1385e-03,  6.7281e-04,  2.7032e-04, -7.3643e-04,\n",
            "        -5.1547e-05,  9.3139e-05, -6.0474e-05, -5.9114e-04, -6.9371e-04,\n",
            "         1.1887e-04,  9.4422e-05, -4.1551e-04,  1.2689e-04,  9.7804e-04,\n",
            "         4.5432e-05,  1.2964e-04, -1.0328e-03, -5.6728e-05, -7.7518e-05,\n",
            "        -7.6426e-04, -2.9625e-04,  9.2575e-04,  3.7365e-04, -7.5779e-04,\n",
            "        -9.2430e-04,  6.8891e-04,  6.3421e-05,  5.0090e-04,  4.5703e-05,\n",
            "        -1.1299e-04, -3.5809e-04,  3.8593e-04, -9.0628e-04,  2.9488e-04,\n",
            "         2.8647e-04, -2.6856e-04, -7.0631e-05, -5.2131e-04, -7.2953e-04,\n",
            "        -1.9245e-04,  5.3829e-04, -3.3363e-04,  5.5115e-05, -3.1926e-04,\n",
            "        -9.1423e-04, -6.7506e-04,  1.0993e-03, -2.0034e-04,  2.1419e-04,\n",
            "         4.3363e-04, -7.1589e-04, -6.3626e-04,  1.0857e-04, -6.6545e-04,\n",
            "        -9.3942e-04, -1.6989e-04, -5.8969e-04,  7.3662e-04,  9.3336e-04,\n",
            "         5.6506e-04,  2.2693e-04,  5.9256e-04,  8.8061e-04, -4.6649e-04,\n",
            "         2.8499e-04, -1.1706e-03, -3.9223e-04,  1.5626e-04,  1.2288e-03,\n",
            "         1.4464e-04, -3.6319e-04,  9.5862e-04,  3.2555e-04,  6.9332e-04,\n",
            "         3.4094e-04,  1.2036e-03,  2.2815e-04, -4.8085e-04, -3.1535e-04,\n",
            "         9.2321e-04,  7.0512e-04, -7.8965e-05,  7.6341e-04, -6.0219e-05,\n",
            "        -1.5185e-04,  9.3112e-05,  8.9874e-04,  2.4271e-04,  4.5201e-04,\n",
            "         5.4550e-04,  1.4852e-03,  1.9384e-04,  6.0244e-04, -8.3118e-04,\n",
            "         4.0729e-04, -1.1808e-03, -5.1503e-04, -1.3295e-04,  8.5529e-04,\n",
            "         4.6569e-04, -4.5431e-04,  8.3540e-04, -1.0566e-03,  5.2880e-04,\n",
            "        -2.2874e-04,  3.5344e-04, -1.7392e-03, -3.8093e-04,  7.7820e-04,\n",
            "        -1.3088e-04, -3.8398e-04,  1.0664e-04, -1.5254e-03, -1.1779e-03,\n",
            "        -3.2094e-04,  1.2237e-04, -1.9830e-04, -3.1139e-04, -9.1568e-05,\n",
            "         5.4258e-04,  6.2682e-05,  4.8289e-05,  4.6520e-04, -5.6640e-04,\n",
            "        -5.3764e-04, -6.6697e-04, -1.0505e-03, -3.3263e-04, -7.2088e-04,\n",
            "         5.4892e-04, -1.5881e-04, -6.2862e-04,  9.5091e-04,  6.1026e-05,\n",
            "        -3.9235e-05,  4.1691e-04,  2.8701e-04, -4.1792e-05,  1.0571e-03,\n",
            "         1.7958e-06,  3.8127e-04, -3.9070e-04, -6.5464e-05,  3.8002e-04,\n",
            "        -3.9285e-04, -4.2647e-04,  1.3708e-04, -2.2435e-04, -1.9985e-04,\n",
            "        -6.0700e-04,  4.8624e-04,  2.4266e-04, -4.0706e-05, -2.4836e-04,\n",
            "        -1.2721e-04,  5.1183e-05,  5.9068e-04,  2.8591e-04,  7.7968e-04,\n",
            "        -1.3931e-04,  1.8531e-04, -1.3446e-03, -5.1204e-04,  5.0612e-04,\n",
            "         3.5646e-04])), ('module.encoder_q.layer3.3.bn1.running_mean', tensor([-3.7258e-01,  4.4164e+00, -3.4942e-01, -1.2148e+00,  3.2476e+00,\n",
            "         6.2250e-02, -1.1307e+00, -8.3781e-01,  2.3187e+00,  3.1879e+00,\n",
            "        -8.0538e-01,  2.5534e+00,  4.0817e+00, -1.0347e+00, -2.2858e-01,\n",
            "         3.7579e+00,  8.2008e-01,  2.5200e+00, -5.3175e-01, -2.7223e+00,\n",
            "         2.6535e+00, -2.8815e+00, -5.0660e-01,  3.9640e+00, -3.3800e+00,\n",
            "         2.2785e+00,  8.3995e-01,  1.6804e+00,  7.7386e-01,  3.5429e-02,\n",
            "        -4.0891e-01, -4.1826e-01,  2.6292e+00,  1.4147e+00,  4.0797e-01,\n",
            "        -9.9315e-01,  3.2924e+00, -1.2379e-01,  2.9466e+00, -1.7101e+00,\n",
            "         4.2015e-01, -3.5973e+00,  2.2535e+00,  4.1410e+00, -1.0616e+00,\n",
            "        -3.2630e+00, -1.2794e+00,  1.5002e+00, -6.5824e+00, -8.8669e-01,\n",
            "         4.2269e-02, -3.5179e+00, -1.7143e+00,  4.0705e+00,  2.0787e+00,\n",
            "         2.1611e+00,  2.1030e+00,  7.8305e-01, -3.7125e+00, -4.8469e+00,\n",
            "        -2.6608e+00,  1.5838e+00, -1.2254e-03, -3.8560e+00, -1.1604e+00,\n",
            "         3.9732e-01, -2.3680e+00, -7.0873e-01, -3.0108e-01,  7.9703e-01,\n",
            "         1.0987e+00,  9.3207e-01,  1.1283e+00, -7.6159e-01,  1.6250e+00,\n",
            "         2.5714e+00, -2.5629e+00, -1.4627e+00,  5.3783e+00,  3.1353e+00,\n",
            "         4.8270e+00, -1.7879e-01, -8.3709e-01, -2.4660e+00, -2.9344e+00,\n",
            "        -8.1126e-01, -3.5473e+00, -4.1981e+00, -4.7610e-01, -9.5879e-03,\n",
            "        -4.0945e+00, -2.0648e+00, -6.2077e+00,  2.5875e-01, -4.6698e-02,\n",
            "        -4.7246e-02, -5.2809e+00,  1.6562e+00, -3.2779e+00,  2.1278e+00,\n",
            "        -2.1335e+00, -6.0514e-01,  5.9684e-01,  1.9426e+00, -1.9741e+00,\n",
            "        -4.5983e+00, -2.5500e+00, -4.6682e-01, -6.1032e-02, -3.8943e-02,\n",
            "         2.4620e+00, -9.9773e-01, -3.0038e+00,  5.8106e-01,  1.9492e+00,\n",
            "        -2.6519e-01,  3.2541e-01,  2.3655e+00, -2.0153e+00,  3.4861e+00,\n",
            "        -1.1134e+00, -8.5991e-01,  3.2078e+00, -1.4462e+00, -3.4198e+00,\n",
            "         1.2246e+00,  1.1351e+00, -2.8167e+00, -4.8193e-02,  1.8287e+00,\n",
            "        -2.4023e+00,  2.0300e+00,  2.4537e+00,  1.9362e+00, -7.0797e-01,\n",
            "        -1.0029e+00, -2.2965e+00,  1.6775e+00,  1.9502e+00,  1.0844e+00,\n",
            "        -2.1217e-01,  1.4858e+00, -6.2757e-01,  1.6126e+00, -6.2135e-01,\n",
            "        -2.5104e+00, -5.3390e+00, -2.8446e+00,  1.1460e+00,  1.3026e+00,\n",
            "         5.6873e-01,  3.6230e+00, -4.2978e+00,  1.6727e-01, -5.5887e-01,\n",
            "         1.9446e+00, -1.5404e+00,  2.1286e+00, -2.8064e+00, -4.0379e-01,\n",
            "        -1.6532e+00, -5.2798e-01,  4.3359e-01,  1.9088e+00,  4.2091e+00,\n",
            "        -1.9924e+00, -1.3510e+00, -1.9108e+00,  1.3124e-01,  9.7295e-01,\n",
            "        -3.5013e+00,  4.7870e-02, -3.7254e+00, -9.5999e-02, -1.9258e+00,\n",
            "         2.5454e+00, -6.7605e-01, -7.8623e-03, -7.4124e+00,  5.3375e+00,\n",
            "         1.1209e+00,  1.5078e+00, -2.2458e+00,  9.8802e-01, -1.7268e-01,\n",
            "        -3.3558e+00,  3.5990e-01, -1.4376e+00, -7.0108e-01, -1.4837e+00,\n",
            "        -1.4223e+00, -2.9731e-01,  3.3291e+00, -6.7906e-02,  5.9686e+00,\n",
            "        -2.7610e+00,  4.3342e-01, -7.2015e-01,  2.2353e+00, -1.3941e+00,\n",
            "        -2.3561e+00, -5.5130e+00, -2.0767e+00, -7.6654e-01,  7.2371e-01,\n",
            "         2.0797e+00, -1.2880e+00,  1.2562e+00,  2.4622e+00, -2.2252e+00,\n",
            "        -6.1835e+00,  1.0912e+00, -3.9387e+00,  2.1870e+00,  3.2540e-01,\n",
            "        -6.7333e+00, -2.2227e+00, -2.5254e+00, -3.3005e+00,  1.5800e+00,\n",
            "         8.7214e+00, -1.4980e+00, -4.0248e+00, -3.6394e-02, -1.0261e+00,\n",
            "        -4.9848e-01, -2.0315e+00,  1.3015e+00,  6.9963e+00,  1.5485e-01,\n",
            "        -1.0326e+00, -4.9966e+00, -5.9045e-01,  2.0740e+00, -3.4775e+00,\n",
            "         3.1611e+00, -2.3052e+00, -2.5432e+00, -2.7866e+00,  3.5178e+00,\n",
            "         3.3781e+00, -2.9644e+00, -4.6587e+00, -1.0113e+00,  7.1283e-01,\n",
            "         7.5236e-02,  2.1817e+00, -3.3119e+00,  1.8073e+00,  1.1023e+00,\n",
            "         2.1324e+00, -1.9996e-01,  2.4352e+00,  2.9579e+00,  2.6385e+00,\n",
            "         2.7159e+00])), ('module.encoder_q.layer3.3.bn1.running_var', tensor([11.8790, 21.6586,  9.6981, 14.2758, 10.7643,  9.2478,  8.1939,  8.8263,\n",
            "        14.0899, 14.5633, 10.2141, 10.9108, 11.6870,  9.8661, 10.0238, 12.8737,\n",
            "        10.2603, 10.4088,  7.6267, 17.2437, 11.4645, 22.5060, 13.6147, 12.4526,\n",
            "        26.3160, 10.8307, 11.3877, 12.3483, 20.0239, 13.4333, 10.2350, 10.0557,\n",
            "         8.5334, 15.6650, 22.0234,  9.4364, 14.7721,  9.4472, 11.1336, 11.8260,\n",
            "         8.7571,  9.2845, 12.3981, 11.8497,  7.6034, 11.9443, 13.7411, 13.4861,\n",
            "        17.8427,  8.5556, 14.7442, 11.7342,  9.8060, 16.8977,  9.4335,  8.1491,\n",
            "        15.2905, 20.4559, 10.0834,  8.5367,  9.1036, 12.1673, 11.4231, 26.7950,\n",
            "         8.7008,  9.7830, 17.6750,  9.6126, 11.4603, 12.7030,  9.7424, 20.2083,\n",
            "        13.2320, 13.1290,  8.7357,  9.8342, 36.8147, 11.5730, 22.8267, 25.3606,\n",
            "        12.0131,  9.0090, 15.1872, 13.4624, 11.9754, 10.2151, 12.5934, 11.7535,\n",
            "        11.2150, 12.3766, 22.3222,  8.4763, 28.9702,  9.3477,  8.8601,  9.8729,\n",
            "        18.0864, 10.2178, 16.2086, 11.3614,  9.0939,  9.6238,  8.7468,  8.8685,\n",
            "        11.9985, 23.1527, 11.9601,  9.8542,  7.3514,  8.9715, 11.0570,  9.7897,\n",
            "        19.4970, 21.6628, 11.7417, 15.4856, 12.0260,  8.7977,  7.0912, 14.6978,\n",
            "         9.3255,  8.2825, 13.2866, 12.6834, 17.9141, 10.1726,  9.2727,  9.7175,\n",
            "        10.8966, 17.5315, 18.6997,  9.2429, 12.8341, 10.3741, 14.2236, 12.7231,\n",
            "        17.6401, 14.3411, 10.1589,  9.4569, 21.1052, 17.5583, 10.4506,  7.5928,\n",
            "        11.2811,  9.2491, 38.8241, 11.1017,  8.2619,  9.6286, 26.7065, 20.8192,\n",
            "        21.4022, 12.7433, 11.2738,  9.9874,  8.3364,  7.9885, 19.7914, 13.9437,\n",
            "         9.7636, 10.1571, 11.6554,  9.8475, 22.8008,  9.4746, 26.0674, 11.0773,\n",
            "        10.9515, 13.2783, 14.6990,  8.3065, 14.4283,  9.5068,  9.3759,  9.4741,\n",
            "         9.0245, 17.9082, 39.7330, 23.2932, 10.4099, 11.0430, 23.3373, 12.9054,\n",
            "         8.3150, 19.7949, 15.1353,  8.5185, 12.5027, 17.7953,  8.3560, 10.8726,\n",
            "        15.4444, 11.8954, 21.0054, 19.9628, 14.4059, 16.7405,  9.4353,  7.7868,\n",
            "         8.3716, 25.0146, 10.5374,  8.9912,  8.1896, 12.8749,  9.0336, 10.8611,\n",
            "         9.0302, 13.6932, 60.6550,  9.4202, 16.7232,  9.0154,  9.0767, 24.7307,\n",
            "         7.7499, 10.2752,  7.5010, 12.9564, 37.5324, 16.2753, 14.4069,  7.6355,\n",
            "         9.6922,  8.0710, 15.8635,  9.8942, 31.7385, 14.1675,  9.2083, 10.2754,\n",
            "         9.2528,  9.3729, 13.3746, 11.5888,  7.8830, 18.4712, 11.8214, 14.6808,\n",
            "        10.7184,  8.9038, 22.5133, 10.1654, 10.4671,  9.9828,  9.7148, 10.3398,\n",
            "         9.8465,  7.5398, 17.0696,  7.5795, 14.3406,  8.8440,  9.6560,  9.0137])), ('module.encoder_q.layer3.3.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.3.conv2.weight', tensor([[[[-0.0043, -0.0130, -0.0162],\n",
            "          [ 0.0269, -0.0154,  0.0005],\n",
            "          [ 0.0352,  0.0316, -0.0096]],\n",
            "\n",
            "         [[ 0.0198,  0.0599,  0.0570],\n",
            "          [ 0.0183,  0.0085, -0.0327],\n",
            "          [ 0.0343,  0.0211, -0.0488]],\n",
            "\n",
            "         [[ 0.0110,  0.0426,  0.0035],\n",
            "          [-0.0022, -0.0281, -0.0332],\n",
            "          [ 0.0136,  0.0281,  0.0259]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0215, -0.0555, -0.0183],\n",
            "          [-0.0199, -0.0136,  0.0240],\n",
            "          [ 0.0221, -0.0330,  0.0090]],\n",
            "\n",
            "         [[-0.0448,  0.0254,  0.0470],\n",
            "          [-0.0797, -0.0160, -0.0104],\n",
            "          [-0.0488,  0.0258,  0.0108]],\n",
            "\n",
            "         [[ 0.0296,  0.0299, -0.0648],\n",
            "          [-0.0500, -0.0913,  0.0212],\n",
            "          [-0.0119, -0.0286,  0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0531,  0.0136, -0.0186],\n",
            "          [-0.0311,  0.0863,  0.0092],\n",
            "          [ 0.0396, -0.0139, -0.0034]],\n",
            "\n",
            "         [[ 0.0194,  0.0064, -0.0209],\n",
            "          [-0.0127, -0.0052,  0.0120],\n",
            "          [-0.0645, -0.0568, -0.0173]],\n",
            "\n",
            "         [[ 0.0065, -0.0385,  0.0326],\n",
            "          [-0.0290,  0.0127, -0.0339],\n",
            "          [ 0.0229, -0.0384, -0.0235]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0253,  0.0288, -0.0225],\n",
            "          [-0.0036,  0.0016, -0.0152],\n",
            "          [ 0.0008, -0.0381,  0.0023]],\n",
            "\n",
            "         [[ 0.0247, -0.0039, -0.0046],\n",
            "          [-0.0141, -0.0461, -0.0109],\n",
            "          [-0.0080,  0.0005, -0.0234]],\n",
            "\n",
            "         [[ 0.0460,  0.0281, -0.0556],\n",
            "          [-0.0317,  0.0184,  0.0025],\n",
            "          [ 0.0460,  0.0465, -0.0131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0468,  0.0494, -0.0064],\n",
            "          [-0.0576, -0.0127, -0.0049],\n",
            "          [ 0.0108,  0.0017,  0.0029]],\n",
            "\n",
            "         [[ 0.0017,  0.0009,  0.0162],\n",
            "          [-0.0056,  0.0042,  0.0104],\n",
            "          [ 0.0171,  0.0074, -0.0401]],\n",
            "\n",
            "         [[-0.0305, -0.0064, -0.0219],\n",
            "          [ 0.0122,  0.0101,  0.0083],\n",
            "          [-0.0377,  0.0283, -0.0361]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0105,  0.0538, -0.0402],\n",
            "          [ 0.0162,  0.0126, -0.0472],\n",
            "          [ 0.0026, -0.0448,  0.0161]],\n",
            "\n",
            "         [[ 0.0099, -0.0115, -0.0306],\n",
            "          [ 0.0096, -0.0364,  0.0317],\n",
            "          [-0.0512,  0.0496,  0.0789]],\n",
            "\n",
            "         [[-0.0176,  0.0355, -0.0053],\n",
            "          [-0.0073,  0.0151,  0.0365],\n",
            "          [ 0.0198,  0.0178,  0.0746]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0015,  0.0559,  0.0255],\n",
            "          [-0.0075, -0.0107,  0.0105],\n",
            "          [-0.0149, -0.0040, -0.0362]],\n",
            "\n",
            "         [[ 0.0286, -0.0023, -0.0217],\n",
            "          [ 0.0037,  0.0013, -0.0114],\n",
            "          [-0.0457, -0.0028,  0.0112]],\n",
            "\n",
            "         [[ 0.0643, -0.0550, -0.0097],\n",
            "          [ 0.0196,  0.0403,  0.0252],\n",
            "          [-0.0087, -0.0703,  0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0379, -0.0244,  0.0262],\n",
            "          [-0.0227,  0.0379,  0.0405],\n",
            "          [-0.0189,  0.0314, -0.0129]],\n",
            "\n",
            "         [[ 0.0291,  0.0550, -0.0205],\n",
            "          [ 0.0574,  0.0060,  0.0164],\n",
            "          [-0.0033, -0.0441,  0.0211]],\n",
            "\n",
            "         [[-0.0336,  0.0093,  0.0077],\n",
            "          [ 0.0126,  0.0124, -0.0564],\n",
            "          [ 0.0233, -0.0440,  0.0079]]],\n",
            "\n",
            "\n",
            "        [[[-0.0349, -0.0131,  0.0166],\n",
            "          [-0.0144, -0.0485, -0.0550],\n",
            "          [-0.0518, -0.0225, -0.0374]],\n",
            "\n",
            "         [[ 0.0446,  0.0336,  0.0365],\n",
            "          [-0.0085, -0.0322, -0.0581],\n",
            "          [-0.0113, -0.0020, -0.0070]],\n",
            "\n",
            "         [[ 0.0029,  0.0376, -0.0319],\n",
            "          [-0.0774, -0.0101, -0.0431],\n",
            "          [-0.0737, -0.0193,  0.0516]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0732,  0.0241, -0.0227],\n",
            "          [ 0.0270,  0.0430, -0.0045],\n",
            "          [-0.0249,  0.0395,  0.0209]],\n",
            "\n",
            "         [[ 0.0004, -0.0022,  0.0275],\n",
            "          [ 0.0650,  0.0080,  0.0024],\n",
            "          [-0.0099, -0.0173, -0.0130]],\n",
            "\n",
            "         [[ 0.0783, -0.0073,  0.0157],\n",
            "          [-0.0091,  0.0181, -0.0084],\n",
            "          [ 0.0203, -0.0225,  0.0332]]],\n",
            "\n",
            "\n",
            "        [[[-0.0205, -0.0025, -0.0571],\n",
            "          [ 0.0731, -0.0276,  0.0505],\n",
            "          [-0.0232,  0.0028,  0.0044]],\n",
            "\n",
            "         [[ 0.0222, -0.0158, -0.0005],\n",
            "          [-0.0165, -0.0761, -0.0069],\n",
            "          [-0.0522, -0.0658,  0.0213]],\n",
            "\n",
            "         [[-0.0145, -0.0130,  0.0078],\n",
            "          [-0.0276, -0.0025, -0.0047],\n",
            "          [-0.0605,  0.0132,  0.0118]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0288, -0.0116, -0.0076],\n",
            "          [-0.0309, -0.0087, -0.0182],\n",
            "          [-0.0866, -0.0125,  0.0156]],\n",
            "\n",
            "         [[ 0.0199, -0.0205, -0.0047],\n",
            "          [ 0.0956, -0.0100,  0.0145],\n",
            "          [-0.0156, -0.0628,  0.0052]],\n",
            "\n",
            "         [[-0.0021,  0.0384,  0.0323],\n",
            "          [-0.0185, -0.0527, -0.0219],\n",
            "          [-0.0103, -0.0373, -0.0491]]]])), ('module.encoder_q.layer3.3.bn2.weight', tensor([0.9918, 0.9917, 0.9930, 0.9929, 0.9927, 0.9927, 0.9919, 0.9934, 0.9928,\n",
            "        0.9922, 0.9913, 0.9924, 0.9919, 0.9921, 0.9929, 0.9925, 0.9922, 0.9924,\n",
            "        0.9921, 0.9924, 0.9919, 0.9920, 0.9925, 0.9920, 0.9920, 0.9922, 0.9920,\n",
            "        0.9923, 0.9918, 0.9928, 0.9920, 0.9922, 0.9919, 0.9920, 0.9923, 0.9928,\n",
            "        0.9918, 0.9924, 0.9927, 0.9924, 0.9928, 0.9927, 0.9925, 0.9923, 0.9917,\n",
            "        0.9921, 0.9927, 0.9921, 0.9923, 0.9917, 0.9924, 0.9921, 0.9924, 0.9925,\n",
            "        0.9918, 0.9918, 0.9922, 0.9917, 0.9932, 0.9918, 0.9929, 0.9917, 0.9928,\n",
            "        0.9922, 0.9928, 0.9920, 0.9924, 0.9918, 0.9929, 0.9923, 0.9923, 0.9910,\n",
            "        0.9925, 0.9918, 0.9922, 0.9923, 0.9921, 0.9925, 0.9923, 0.9920, 0.9911,\n",
            "        0.9921, 0.9921, 0.9927, 0.9932, 0.9919, 0.9928, 0.9926, 0.9929, 0.9921,\n",
            "        0.9923, 0.9916, 0.9928, 0.9913, 0.9920, 0.9922, 0.9918, 0.9925, 0.9919,\n",
            "        0.9926, 0.9930, 0.9918, 0.9919, 0.9919, 0.9914, 0.9917, 0.9924, 0.9922,\n",
            "        0.9926, 0.9921, 0.9920, 0.9927, 0.9916, 0.9927, 0.9922, 0.9919, 0.9918,\n",
            "        0.9920, 0.9922, 0.9922, 0.9920, 0.9919, 0.9925, 0.9919, 0.9915, 0.9923,\n",
            "        0.9922, 0.9925, 0.9929, 0.9919, 0.9921, 0.9921, 0.9921, 0.9921, 0.9926,\n",
            "        0.9926, 0.9918, 0.9923, 0.9918, 0.9920, 0.9919, 0.9918, 0.9928, 0.9924,\n",
            "        0.9922, 0.9918, 0.9925, 0.9917, 0.9917, 0.9929, 0.9918, 0.9931, 0.9925,\n",
            "        0.9929, 0.9918, 0.9921, 0.9925, 0.9912, 0.9922, 0.9929, 0.9925, 0.9938,\n",
            "        0.9928, 0.9930, 0.9926, 0.9927, 0.9921, 0.9921, 0.9917, 0.9920, 0.9925,\n",
            "        0.9925, 0.9920, 0.9921, 0.9928, 0.9924, 0.9919, 0.9929, 0.9921, 0.9918,\n",
            "        0.9923, 0.9924, 0.9923, 0.9921, 0.9919, 0.9918, 0.9940, 0.9915, 0.9923,\n",
            "        0.9924, 0.9926, 0.9929, 0.9929, 0.9921, 0.9928, 0.9932, 0.9920, 0.9919,\n",
            "        0.9930, 0.9924, 0.9920, 0.9924, 0.9925, 0.9926, 0.9926, 0.9918, 0.9918,\n",
            "        0.9914, 0.9932, 0.9918, 0.9929, 0.9915, 0.9919, 0.9928, 0.9919, 0.9921,\n",
            "        0.9923, 0.9920, 0.9919, 0.9923, 0.9917, 0.9916, 0.9921, 0.9917, 0.9924,\n",
            "        0.9922, 0.9920, 0.9922, 0.9936, 0.9920, 0.9923, 0.9931, 0.9926, 0.9921,\n",
            "        0.9908, 0.9924, 0.9929, 0.9924, 0.9920, 0.9921, 0.9923, 0.9920, 0.9925,\n",
            "        0.9924, 0.9924, 0.9924, 0.9917, 0.9926, 0.9933, 0.9919, 0.9922, 0.9928,\n",
            "        0.9918, 0.9925, 0.9924, 0.9922])), ('module.encoder_q.layer3.3.bn2.bias', tensor([-1.0798e-04, -4.1739e-04,  8.8923e-04, -1.7935e-04, -2.2502e-04,\n",
            "         9.0482e-04, -2.3763e-05,  5.5066e-04,  8.6681e-04,  4.6343e-05,\n",
            "        -1.6965e-04, -1.3493e-04, -3.7241e-04,  2.1319e-04,  6.7175e-04,\n",
            "        -9.6299e-05, -2.6558e-04,  2.5366e-04,  9.0879e-05, -1.2064e-04,\n",
            "        -3.0854e-04, -5.4556e-04,  9.4707e-04, -7.9016e-04,  3.6467e-04,\n",
            "         2.7544e-04, -1.4833e-04,  3.9548e-06, -3.1436e-05,  4.7028e-04,\n",
            "        -2.9670e-04, -1.2143e-04, -7.2683e-05,  6.0409e-04, -1.8754e-05,\n",
            "         5.6422e-04, -4.9472e-04, -3.4042e-04,  8.9774e-04, -2.4880e-04,\n",
            "         3.0037e-04,  5.3966e-04,  2.4612e-04,  3.0146e-04, -5.8311e-04,\n",
            "        -3.8759e-04,  6.2657e-04, -2.4402e-04,  8.3799e-05, -4.1153e-04,\n",
            "         1.4600e-04,  2.9709e-04, -1.6942e-05, -4.6995e-04,  6.6591e-05,\n",
            "        -2.1335e-04, -6.8378e-05, -1.8883e-04,  1.2365e-03,  4.6132e-05,\n",
            "         3.6946e-04, -1.0864e-03,  3.9175e-04, -2.2827e-04,  7.1861e-04,\n",
            "        -5.3300e-04,  2.1839e-04, -3.4448e-04,  4.1388e-05,  4.2885e-04,\n",
            "         6.2675e-05, -8.5219e-04,  3.6371e-04, -6.0602e-04,  2.7602e-04,\n",
            "         1.3009e-05,  2.1972e-04,  5.2605e-04,  5.9370e-04,  8.2168e-05,\n",
            "        -2.1992e-04, -8.5052e-04,  2.1881e-04,  1.3876e-04,  1.2176e-03,\n",
            "        -3.8820e-04,  2.5889e-04, -2.6182e-04,  8.8616e-04, -7.3635e-05,\n",
            "        -3.1656e-04, -2.3186e-04,  3.7090e-04, -3.7539e-04,  3.9370e-04,\n",
            "        -4.3281e-04,  8.7786e-05,  1.2243e-04, -5.1448e-04, -2.4453e-05,\n",
            "         2.3601e-04, -9.6242e-06,  5.5326e-05, -6.4973e-04, -5.9679e-04,\n",
            "         1.3029e-04, -2.8865e-04, -5.4019e-04,  4.0722e-05,  1.8027e-04,\n",
            "        -1.7435e-04,  6.3041e-04, -1.9216e-04,  8.2469e-04,  2.8872e-04,\n",
            "        -8.9609e-04, -3.8466e-04, -1.1110e-04, -9.7690e-04,  1.0505e-04,\n",
            "        -1.1435e-04, -2.2125e-04,  6.0196e-04, -1.7537e-04, -6.2424e-04,\n",
            "         1.3928e-04,  5.5433e-05,  2.1141e-04,  4.1765e-04, -5.2055e-04,\n",
            "        -1.9042e-04, -3.3970e-05,  6.2040e-05, -3.5911e-04, -2.6821e-04,\n",
            "         2.3958e-04, -5.5847e-04, -7.3700e-05, -6.4384e-04, -1.2206e-05,\n",
            "        -2.6505e-04, -3.3465e-04, -1.1526e-04, -1.7047e-04,  6.5296e-04,\n",
            "        -4.3243e-04,  2.4257e-05,  7.5407e-05, -1.5777e-04, -2.9201e-05,\n",
            "        -8.4259e-05,  1.0555e-03,  4.7997e-04,  5.0922e-04,  5.3790e-05,\n",
            "         2.8039e-04, -9.2198e-05, -9.4942e-04, -4.7020e-04,  5.6506e-04,\n",
            "         4.0976e-05,  1.1443e-03,  7.5910e-04,  7.8945e-04,  1.6815e-04,\n",
            "         3.2503e-04,  6.3468e-05, -4.9466e-04, -8.3800e-04, -3.1011e-04,\n",
            "         2.3551e-04,  1.3035e-04, -7.3402e-05, -2.7133e-04,  8.4031e-04,\n",
            "        -3.5984e-04,  3.5475e-04,  2.9954e-04,  1.2901e-04, -4.8367e-04,\n",
            "         2.5589e-05,  1.5378e-05,  1.9939e-04, -4.1051e-04, -4.3347e-05,\n",
            "        -2.0275e-04,  1.2053e-03, -8.5080e-04, -9.8800e-05,  1.4929e-04,\n",
            "        -1.5276e-06,  7.4098e-04,  5.0955e-04, -2.7137e-04,  5.8691e-05,\n",
            "         2.9971e-04,  3.0766e-04,  1.2272e-04,  5.6248e-04, -5.8121e-04,\n",
            "        -3.4574e-04,  2.6264e-04,  3.1099e-04, -2.3467e-04,  1.7651e-04,\n",
            "        -7.5163e-04, -3.7854e-04, -5.7234e-04,  3.0988e-04, -3.2339e-04,\n",
            "         6.0054e-04, -4.5737e-04, -2.8769e-05, -3.3448e-04,  5.6313e-05,\n",
            "        -1.1296e-04, -8.0728e-04, -5.8101e-04,  6.0078e-04,  5.0762e-04,\n",
            "        -8.8582e-05, -4.4813e-04,  4.2365e-04,  1.6060e-05, -4.7218e-04,\n",
            "        -3.9780e-04, -5.5241e-04,  3.1800e-04,  9.0114e-04,  6.9292e-05,\n",
            "         5.1661e-05,  4.7953e-04,  3.9087e-04, -6.4241e-05, -1.1992e-03,\n",
            "         7.5297e-05,  4.9874e-04,  3.5705e-04, -4.3473e-04,  1.7850e-04,\n",
            "         8.9805e-05, -1.0399e-04, -3.5468e-04,  4.1833e-04,  1.7162e-04,\n",
            "         1.7591e-04, -1.2030e-03, -4.5770e-04,  1.0003e-03, -1.3879e-04,\n",
            "        -2.2386e-04,  1.3389e-05, -5.7298e-04,  1.9734e-04, -1.5593e-04,\n",
            "        -1.5846e-04])), ('module.encoder_q.layer3.3.bn2.running_mean', tensor([-1.2075,  0.1808, -0.0537,  0.2494,  0.2963,  0.7030, -0.1024, -0.0469,\n",
            "        -0.9400, -0.4156, -0.1081,  0.3641,  0.1591, -0.2007,  0.0689, -0.7321,\n",
            "         0.8817, -0.3576, -0.8161, -0.3993, -0.9324, -0.4917,  0.0963, -0.5699,\n",
            "         0.0088,  0.3351, -1.1650,  1.4281, -0.1803, -0.0202,  0.4394, -0.6564,\n",
            "        -0.0491, -0.1224,  0.4098, -0.2752,  0.0558,  0.1425,  0.4041,  0.6538,\n",
            "         0.8336, -0.5591, -0.0938, -0.0956, -1.4876,  0.3126, -0.8599, -0.3044,\n",
            "        -0.0204,  0.3227, -0.3081, -0.8048,  0.0389,  0.2534, -0.0926, -1.0812,\n",
            "        -0.2678, -0.4284,  0.5391,  0.2322,  0.1115, -0.2601, -0.5496, -0.4885,\n",
            "        -0.4729, -0.0428, -0.3132,  0.3554, -0.3904,  0.5579, -0.5117,  0.4984,\n",
            "        -0.1074, -0.4216, -0.5713, -0.7816, -0.4578,  0.6473, -0.0537, -0.0478,\n",
            "        -0.1746,  0.4983,  1.4182, -0.1035,  0.0680,  0.5765,  0.4802,  0.9244,\n",
            "        -0.1911,  0.3995, -0.0830,  0.1525, -0.1656,  0.1851,  0.3813, -0.0324,\n",
            "         0.2914, -0.3688, -0.5447, -0.2076, -0.5420,  0.0293, -0.0500, -0.5009,\n",
            "         0.4900, -0.2906, -0.8967,  0.0153, -0.3014,  0.4885,  0.1838, -0.1732,\n",
            "        -0.0509, -0.2940, -0.4651,  0.5458, -0.1441, -0.0167,  0.4275,  0.1215,\n",
            "        -0.1377,  0.2716,  0.7501,  0.0815,  0.1600, -0.3581,  0.7787,  0.3274,\n",
            "        -0.0315,  0.5514,  0.0717, -1.1968, -0.1702,  0.3420,  0.3559, -0.6577,\n",
            "         0.0932,  0.1722, -0.0790, -0.4163,  0.1276,  0.1277, -0.2358, -0.3924,\n",
            "         0.0513, -0.1283,  0.3644,  0.2826,  0.4238,  0.1194, -0.6068, -0.2322,\n",
            "         0.0897, -0.5709,  0.1826, -0.3554, -0.0609,  0.4787, -0.3278,  0.1070,\n",
            "        -0.7565,  0.4316, -0.7119, -0.0672, -0.2596, -0.1747,  0.2255, -0.2261,\n",
            "         0.3388,  1.1243, -0.3465, -0.1161, -0.3965, -0.2861,  0.2425, -0.4496,\n",
            "        -0.6921,  0.4847,  0.7630, -0.6946,  0.8113, -0.2769,  0.5221,  0.0716,\n",
            "        -0.2203,  0.0787,  0.3636,  0.5005, -0.3010, -0.2597,  0.1013,  0.2089,\n",
            "         0.4899, -0.8558,  0.2683,  0.3373,  0.5414,  0.9259,  0.8947, -0.3601,\n",
            "         0.3254, -0.4399, -1.1255,  0.6767, -0.1564, -0.3954, -0.2038, -0.3610,\n",
            "         0.3320,  0.3238, -0.3133, -0.2379,  0.1037,  0.2607,  0.1276, -0.3368,\n",
            "         0.6362, -1.1460,  0.0039,  0.3728, -0.2746,  0.2334, -0.2431, -0.7297,\n",
            "        -0.5074, -0.0951,  1.0562, -0.2141,  0.4809,  0.4419, -0.3099, -0.5254,\n",
            "        -0.0181, -0.2831, -0.3949,  0.6856,  0.1481,  0.5414,  0.1107,  0.0352,\n",
            "        -0.0691, -0.0452,  0.0119, -0.2903, -0.3262,  0.1307, -0.1798,  0.3731,\n",
            "         0.3065,  0.8073, -0.4715, -0.5356,  0.8132,  0.4155,  0.7892, -0.5420])), ('module.encoder_q.layer3.3.bn2.running_var', tensor([1.1939, 0.7553, 0.6552, 0.5721, 0.7607, 0.8896, 0.5702, 0.7468, 1.1110,\n",
            "        0.5221, 0.5491, 0.8550, 0.5503, 0.7709, 0.6866, 0.9890, 1.2300, 0.5099,\n",
            "        0.8712, 0.5619, 0.6331, 0.5567, 0.5784, 0.8783, 0.5661, 0.6091, 1.3443,\n",
            "        1.7090, 0.4917, 0.6207, 0.8571, 0.8052, 0.5565, 0.6580, 0.8201, 0.7000,\n",
            "        0.5916, 0.7239, 0.6476, 0.7147, 0.9269, 0.6706, 0.7450, 0.5603, 1.2402,\n",
            "        0.9451, 1.7375, 0.6210, 0.5190, 0.6919, 0.7511, 2.0120, 0.6319, 0.7827,\n",
            "        0.5234, 1.0080, 0.5016, 1.0505, 0.5894, 1.1121, 0.5745, 0.4756, 0.6203,\n",
            "        0.8909, 1.0380, 0.5368, 0.6170, 0.7630, 0.6881, 1.7070, 0.5576, 0.5489,\n",
            "        0.6938, 0.5356, 0.6732, 1.0301, 0.6736, 0.6248, 0.9009, 1.0054, 0.5846,\n",
            "        0.5130, 1.2971, 0.5382, 0.4398, 1.1030, 0.8959, 1.4639, 0.9579, 0.6508,\n",
            "        0.6558, 0.6918, 0.5479, 1.0788, 0.5660, 0.8671, 0.5143, 0.7141, 0.8410,\n",
            "        0.5649, 0.6141, 0.5548, 0.7742, 0.7705, 1.0480, 0.6406, 1.6387, 0.7062,\n",
            "        0.5025, 0.7945, 0.7756, 0.9242, 0.7056, 0.5904, 1.0169, 0.8076, 0.7160,\n",
            "        0.6277, 0.9093, 0.7854, 0.5687, 1.2116, 1.6436, 0.7253, 0.6954, 0.6887,\n",
            "        1.2892, 0.5164, 0.5438, 0.6671, 0.5498, 1.2958, 0.6715, 0.8661, 0.8650,\n",
            "        0.6965, 0.7319, 0.5866, 0.5606, 0.6529, 0.7828, 0.6635, 0.8604, 0.6218,\n",
            "        0.5912, 0.5822, 1.1533, 0.6880, 0.5438, 0.4877, 0.8303, 1.0026, 0.6434,\n",
            "        0.5100, 0.7671, 0.6052, 0.5400, 0.5606, 0.5700, 0.5287, 0.6548, 0.7441,\n",
            "        0.4958, 0.6500, 0.7439, 0.7004, 0.6829, 0.6035, 0.6368, 0.8003, 0.6026,\n",
            "        0.6783, 0.7157, 0.6846, 0.5359, 0.6458, 0.7365, 0.7660, 0.6063, 0.7285,\n",
            "        1.1522, 0.5286, 0.6513, 0.5756, 0.5658, 0.6275, 0.8441, 0.6680, 0.6434,\n",
            "        0.5336, 0.5346, 0.4945, 0.8213, 0.8778, 1.0578, 0.6639, 0.5576, 0.7673,\n",
            "        0.7030, 0.6990, 0.7565, 0.5597, 1.3103, 0.7762, 0.6592, 0.5726, 0.5249,\n",
            "        0.6061, 0.4870, 0.9044, 0.6241, 1.0306, 0.6544, 0.8200, 0.4764, 0.5901,\n",
            "        1.0532, 1.0220, 0.5387, 0.5502, 0.8050, 0.6698, 1.0111, 0.8812, 0.6126,\n",
            "        0.6242, 1.3869, 0.8048, 0.7658, 0.6235, 0.5537, 0.5786, 0.6817, 0.6017,\n",
            "        0.5234, 1.4413, 0.9755, 0.7184, 0.5434, 0.5199, 0.6313, 0.5779, 0.5294,\n",
            "        1.1186, 0.7251, 0.7105, 0.6008, 0.8716, 0.8932, 1.1398, 0.9210, 0.6319,\n",
            "        0.5627, 0.5406, 0.7533, 1.3707])), ('module.encoder_q.layer3.3.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.3.conv3.weight', tensor([[[[ 0.0281]],\n",
            "\n",
            "         [[-0.0037]],\n",
            "\n",
            "         [[-0.0138]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[-0.0008]],\n",
            "\n",
            "         [[-0.0158]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0841]],\n",
            "\n",
            "         [[-0.0912]],\n",
            "\n",
            "         [[ 0.0345]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0203]],\n",
            "\n",
            "         [[-0.0039]],\n",
            "\n",
            "         [[-0.0155]]],\n",
            "\n",
            "\n",
            "        [[[-0.0610]],\n",
            "\n",
            "         [[ 0.0228]],\n",
            "\n",
            "         [[-0.0259]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0717]],\n",
            "\n",
            "         [[ 0.0045]],\n",
            "\n",
            "         [[ 0.0057]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0154]],\n",
            "\n",
            "         [[-0.0491]],\n",
            "\n",
            "         [[ 0.0269]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1003]],\n",
            "\n",
            "         [[ 0.0868]],\n",
            "\n",
            "         [[-0.0521]]],\n",
            "\n",
            "\n",
            "        [[[-0.0327]],\n",
            "\n",
            "         [[-0.0279]],\n",
            "\n",
            "         [[ 0.0305]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0223]],\n",
            "\n",
            "         [[-0.0637]],\n",
            "\n",
            "         [[ 0.0291]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0454]],\n",
            "\n",
            "         [[-0.0592]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0662]],\n",
            "\n",
            "         [[ 0.0501]],\n",
            "\n",
            "         [[-0.0534]]]])), ('module.encoder_q.layer3.3.bn3.weight', tensor([0.9921, 0.9924, 0.9922,  ..., 0.9921, 0.9923, 0.9920])), ('module.encoder_q.layer3.3.bn3.bias', tensor([-2.0404e-04,  3.0033e-04,  4.1785e-05,  ..., -5.1044e-05,\n",
            "        -1.5625e-04, -1.9956e-04])), ('module.encoder_q.layer3.3.bn3.running_mean', tensor([ 0.3850, -0.0435, -0.0143,  ..., -0.0824,  0.1177, -0.1400])), ('module.encoder_q.layer3.3.bn3.running_var', tensor([0.2913, 0.1398, 0.1784,  ..., 0.1404, 0.1804, 0.2904])), ('module.encoder_q.layer3.3.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.4.conv1.weight', tensor([[[[-0.0167]],\n",
            "\n",
            "         [[ 0.0313]],\n",
            "\n",
            "         [[-0.1218]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0054]],\n",
            "\n",
            "         [[-0.0978]],\n",
            "\n",
            "         [[-0.0354]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0437]],\n",
            "\n",
            "         [[-0.0599]],\n",
            "\n",
            "         [[ 0.0168]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1604]],\n",
            "\n",
            "         [[-0.0348]],\n",
            "\n",
            "         [[-0.2521]]],\n",
            "\n",
            "\n",
            "        [[[-0.0508]],\n",
            "\n",
            "         [[ 0.0332]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1550]],\n",
            "\n",
            "         [[-0.1089]],\n",
            "\n",
            "         [[ 0.0967]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0133]],\n",
            "\n",
            "         [[-0.0557]],\n",
            "\n",
            "         [[ 0.0715]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[-0.0660]],\n",
            "\n",
            "         [[ 0.1178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0728]],\n",
            "\n",
            "         [[-0.0154]],\n",
            "\n",
            "         [[ 0.0936]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0900]],\n",
            "\n",
            "         [[ 0.0486]],\n",
            "\n",
            "         [[-0.0738]]],\n",
            "\n",
            "\n",
            "        [[[-0.0687]],\n",
            "\n",
            "         [[-0.0708]],\n",
            "\n",
            "         [[-0.0722]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0738]],\n",
            "\n",
            "         [[-0.0067]],\n",
            "\n",
            "         [[ 0.0852]]]])), ('module.encoder_q.layer3.4.bn1.weight', tensor([0.9926, 0.9913, 0.9927, 0.9918, 0.9923, 0.9924, 0.9923, 0.9917, 0.9925,\n",
            "        0.9917, 0.9919, 0.9924, 0.9923, 0.9924, 0.9926, 0.9922, 0.9929, 0.9920,\n",
            "        0.9928, 0.9922, 0.9922, 0.9919, 0.9918, 0.9924, 0.9926, 0.9918, 0.9919,\n",
            "        0.9924, 0.9926, 0.9924, 0.9912, 0.9919, 0.9930, 0.9912, 0.9923, 0.9920,\n",
            "        0.9920, 0.9935, 0.9919, 0.9917, 0.9916, 0.9924, 0.9923, 0.9918, 0.9931,\n",
            "        0.9942, 0.9924, 0.9934, 0.9921, 0.9924, 0.9925, 0.9924, 0.9924, 0.9928,\n",
            "        0.9927, 0.9925, 0.9915, 0.9921, 0.9921, 0.9924, 0.9933, 0.9920, 0.9912,\n",
            "        0.9920, 0.9921, 0.9922, 0.9927, 0.9919, 0.9920, 0.9921, 0.9921, 0.9924,\n",
            "        0.9919, 0.9920, 0.9918, 0.9919, 0.9924, 0.9921, 0.9917, 0.9920, 0.9922,\n",
            "        0.9926, 0.9930, 0.9931, 0.9919, 0.9924, 0.9921, 0.9921, 0.9924, 0.9923,\n",
            "        0.9933, 0.9919, 0.9926, 0.9923, 0.9912, 0.9918, 0.9918, 0.9926, 0.9920,\n",
            "        0.9927, 0.9922, 0.9923, 0.9922, 0.9927, 0.9926, 0.9927, 0.9924, 0.9926,\n",
            "        0.9922, 0.9920, 0.9927, 0.9925, 0.9926, 0.9923, 0.9919, 0.9921, 0.9923,\n",
            "        0.9925, 0.9925, 0.9924, 0.9927, 0.9923, 0.9928, 0.9921, 0.9922, 0.9917,\n",
            "        0.9932, 0.9921, 0.9920, 0.9920, 0.9924, 0.9922, 0.9931, 0.9919, 0.9918,\n",
            "        0.9926, 0.9922, 0.9928, 0.9925, 0.9931, 0.9926, 0.9920, 0.9925, 0.9918,\n",
            "        0.9920, 0.9919, 0.9923, 0.9923, 0.9924, 0.9918, 0.9920, 0.9921, 0.9920,\n",
            "        0.9930, 0.9926, 0.9920, 0.9928, 0.9923, 0.9921, 0.9921, 0.9921, 0.9923,\n",
            "        0.9919, 0.9922, 0.9919, 0.9920, 0.9921, 0.9923, 0.9924, 0.9917, 0.9919,\n",
            "        0.9919, 0.9926, 0.9917, 0.9927, 0.9922, 0.9927, 0.9927, 0.9925, 0.9919,\n",
            "        0.9925, 0.9928, 0.9927, 0.9918, 0.9923, 0.9934, 0.9926, 0.9934, 0.9925,\n",
            "        0.9921, 0.9920, 0.9927, 0.9921, 0.9919, 0.9917, 0.9923, 0.9917, 0.9922,\n",
            "        0.9924, 0.9926, 0.9925, 0.9915, 0.9917, 0.9924, 0.9918, 0.9921, 0.9922,\n",
            "        0.9922, 0.9917, 0.9923, 0.9922, 0.9922, 0.9920, 0.9920, 0.9926, 0.9919,\n",
            "        0.9923, 0.9923, 0.9928, 0.9920, 0.9925, 0.9930, 0.9919, 0.9917, 0.9926,\n",
            "        0.9926, 0.9921, 0.9923, 0.9915, 0.9919, 0.9923, 0.9916, 0.9920, 0.9917,\n",
            "        0.9923, 0.9923, 0.9926, 0.9920, 0.9928, 0.9917, 0.9917, 0.9929, 0.9929,\n",
            "        0.9920, 0.9922, 0.9922, 0.9919, 0.9916, 0.9924, 0.9922, 0.9917, 0.9921,\n",
            "        0.9924, 0.9928, 0.9915, 0.9927])), ('module.encoder_q.layer3.4.bn1.bias', tensor([ 7.3285e-05, -8.7525e-04,  5.4745e-04, -4.8473e-04, -2.2834e-04,\n",
            "         1.6955e-05, -8.9805e-05, -7.9557e-04,  2.2917e-04,  8.8910e-07,\n",
            "         3.7325e-04, -1.2891e-04,  2.8610e-05,  2.1371e-04, -6.6881e-06,\n",
            "        -1.9929e-04,  2.2222e-04, -4.0224e-04,  3.2153e-04,  7.1521e-07,\n",
            "        -8.1544e-08, -3.5312e-04, -1.7615e-04, -8.0322e-05, -2.4498e-04,\n",
            "        -1.7374e-04, -1.1163e-04,  1.6373e-04,  6.5936e-04,  1.7446e-04,\n",
            "        -8.2456e-04, -4.9426e-04,  2.3505e-04, -1.0276e-03, -2.7481e-05,\n",
            "        -6.4218e-04, -4.9791e-04,  1.0205e-04,  1.9092e-04,  3.0287e-04,\n",
            "        -6.5126e-04,  3.7309e-04, -4.7204e-04, -4.0981e-04,  4.1740e-04,\n",
            "         1.2123e-03,  3.9513e-04,  8.2157e-04, -7.7609e-05,  4.7157e-04,\n",
            "        -2.2661e-04,  1.3755e-05,  3.5178e-04,  5.9936e-04,  1.1773e-04,\n",
            "         1.2662e-04, -3.4052e-04, -6.2841e-04,  3.0290e-04, -2.0975e-04,\n",
            "         5.9340e-04, -1.4916e-04, -1.8246e-04, -3.2612e-04, -1.6697e-04,\n",
            "        -5.0813e-04,  3.0993e-04, -2.7494e-05, -4.1363e-04,  3.3874e-04,\n",
            "         4.4114e-04,  1.7801e-04, -1.4912e-04, -6.4576e-04, -6.1945e-04,\n",
            "        -3.8220e-04,  6.1068e-05, -2.1082e-04, -1.0777e-03, -1.7964e-04,\n",
            "         6.3742e-04, -1.0734e-04,  3.2308e-04,  3.7781e-04, -4.9032e-04,\n",
            "         3.3671e-04, -3.9428e-04,  7.7081e-04,  8.2297e-04, -4.2127e-04,\n",
            "         7.7427e-04, -3.5413e-04, -2.4958e-04, -3.5754e-04, -7.4122e-04,\n",
            "        -1.6814e-04, -2.6265e-04,  8.4822e-04, -1.3600e-04, -2.2959e-04,\n",
            "         6.3445e-05,  2.4599e-04, -3.7295e-04, -1.8427e-05,  5.4170e-04,\n",
            "        -4.3248e-04, -6.1073e-05,  2.3735e-04,  2.2834e-04, -8.5322e-04,\n",
            "         6.9596e-04,  5.2482e-04,  9.4314e-04,  2.3155e-04, -3.4920e-04,\n",
            "        -3.4473e-05,  4.0906e-04, -3.7400e-04, -6.2152e-04,  4.6225e-05,\n",
            "         4.7030e-04, -1.7825e-04,  5.2182e-04, -2.3316e-04,  3.2828e-05,\n",
            "        -7.1369e-04,  3.6220e-04, -4.0589e-04,  8.5016e-05, -4.7342e-05,\n",
            "        -9.4941e-05, -8.7375e-05, -1.4564e-04, -5.0367e-04, -1.5460e-04,\n",
            "        -1.5427e-04, -6.5429e-05, -1.1193e-04,  9.4923e-04,  3.3520e-05,\n",
            "         6.5082e-04, -6.8433e-04, -5.7304e-05, -1.3335e-04, -4.7306e-05,\n",
            "        -4.8949e-04,  2.0948e-04, -4.5318e-05, -1.1502e-04, -2.2984e-04,\n",
            "        -2.0775e-04, -2.0556e-04, -1.9598e-04,  2.7611e-04,  4.2688e-05,\n",
            "        -4.6360e-04,  1.0597e-03,  2.8206e-04, -1.5917e-04,  5.9946e-04,\n",
            "        -1.0206e-04, -3.3434e-04, -7.9298e-05, -5.5163e-05, -1.2989e-04,\n",
            "        -8.9212e-05,  8.1312e-05,  3.2048e-04,  7.2098e-05, -3.8685e-04,\n",
            "        -6.5666e-04, -1.3418e-04, -1.0207e-04, -1.7885e-04,  5.1971e-04,\n",
            "        -2.3977e-04,  9.8398e-04,  3.4267e-04,  4.2260e-04, -5.0610e-04,\n",
            "        -1.5710e-04,  5.2193e-04,  4.0728e-04, -7.5338e-05, -2.6828e-04,\n",
            "         1.2476e-03,  3.0077e-04,  8.2537e-04, -1.8288e-04, -5.9376e-04,\n",
            "         2.5103e-04,  3.1333e-04, -1.2557e-04, -1.0852e-04,  1.5613e-04,\n",
            "        -4.4036e-04, -1.1088e-03,  3.7324e-04,  1.8240e-04,  8.3163e-05,\n",
            "        -9.5524e-06, -1.9368e-04, -9.5478e-05, -2.1500e-04, -6.9607e-04,\n",
            "        -4.6826e-04,  3.3036e-04, -2.7718e-05, -2.2635e-04,  1.9286e-04,\n",
            "         1.2072e-04,  2.3163e-04, -1.1325e-04,  4.1854e-04,  2.6046e-04,\n",
            "         2.1212e-04, -1.8478e-04,  2.6211e-04,  2.0697e-05, -4.2094e-04,\n",
            "         4.2662e-04,  5.1887e-04, -4.4039e-05, -7.5325e-05, -4.5866e-04,\n",
            "         4.9675e-04,  5.3122e-04,  8.0422e-05, -4.7933e-04, -5.9564e-04,\n",
            "         7.1006e-04, -7.8381e-04, -3.0204e-04, -5.0182e-04,  2.4274e-04,\n",
            "         3.3603e-04,  1.0190e-04, -2.2013e-04,  9.6738e-04, -3.3020e-04,\n",
            "        -1.2385e-04,  2.5877e-04,  2.3375e-04, -3.4672e-04,  3.4529e-04,\n",
            "         5.8425e-04, -3.6582e-04, -5.4498e-04, -2.7914e-04,  4.8737e-04,\n",
            "        -2.6475e-04, -1.4808e-04, -8.8215e-05,  7.2611e-04, -5.0679e-04,\n",
            "        -6.9415e-05])), ('module.encoder_q.layer3.4.bn1.running_mean', tensor([-1.1952e-01,  6.0113e+00, -2.5057e+00,  8.3215e-01,  1.3735e-01,\n",
            "         3.3061e+00, -3.2203e+00, -2.4225e+00,  2.4159e+00,  2.2125e+00,\n",
            "        -3.2977e-01,  1.6256e+00,  3.1575e+00,  8.1844e-01, -2.8279e+00,\n",
            "        -1.7048e+00,  2.6960e+00,  3.0876e+00,  3.5079e+00, -4.1936e-01,\n",
            "        -3.4546e+00, -4.7428e+00,  2.7053e+00,  1.2195e+00,  9.6329e-01,\n",
            "         8.9146e-01,  2.6657e+00,  1.7605e+00, -2.9157e+00, -6.8985e-01,\n",
            "        -8.4437e-01, -2.7500e+00,  3.5049e+00,  1.4981e-01,  2.3168e+00,\n",
            "        -1.1770e+00, -2.4344e-01,  4.7422e-01,  4.1078e+00,  1.5778e+00,\n",
            "        -1.6427e+00, -2.7695e+00,  4.3600e+00,  2.4391e+00,  5.4361e+00,\n",
            "        -1.8003e+00,  2.0919e+00,  2.7093e+00, -7.6167e+00,  1.0363e+00,\n",
            "        -1.4849e+00,  5.4749e-01, -2.1221e-01, -2.8038e-01, -1.0891e+00,\n",
            "         3.1928e-01, -2.0897e+00, -4.5647e-01,  2.1318e+00, -1.7064e+00,\n",
            "         1.8171e+00, -4.9975e-01,  1.8833e+00,  2.2591e+00, -3.6396e+00,\n",
            "        -5.2565e-01,  3.0464e+00, -3.0594e+00, -1.1223e+00,  1.4879e+00,\n",
            "         7.8432e-01, -1.7166e+00,  2.6415e-01, -3.6628e+00,  4.4074e-02,\n",
            "         1.6551e+00,  4.8189e+00, -3.5054e+00, -1.7817e-01, -2.1708e+00,\n",
            "        -1.1859e+00, -2.9687e+00, -8.6695e-01,  2.1331e+00,  3.3811e+00,\n",
            "         1.9938e+00, -2.9361e+00, -2.5304e+00, -8.9101e-01,  2.8897e+00,\n",
            "        -4.1612e-02, -4.7042e+00, -1.7538e-01, -5.4119e-01,  3.5459e-02,\n",
            "        -9.3523e-01, -1.3835e+00, -1.0582e+00, -2.4186e-01,  2.2499e+00,\n",
            "         2.0872e+00, -1.2842e+00, -4.1747e+00,  4.6906e-01,  5.3880e+00,\n",
            "        -3.2558e+00,  1.1125e-01,  1.7927e+00,  5.0211e-01, -1.9339e+00,\n",
            "         4.5499e+00,  1.3917e+00,  2.7886e+00, -2.2813e+00, -3.6531e+00,\n",
            "        -3.0346e+00, -4.7476e+00,  9.6080e-01,  5.3315e+00, -5.0245e+00,\n",
            "         4.2075e+00,  8.2412e-01, -5.1112e-01,  2.1498e+00, -1.5968e-01,\n",
            "        -1.9009e+00,  1.2083e+00, -3.5624e+00,  4.8583e+00,  1.6097e-01,\n",
            "        -3.1743e+00, -2.7180e+00,  2.2352e+00, -1.5257e-01, -3.0747e+00,\n",
            "         2.3340e+00,  1.0838e-01,  2.3455e+00, -5.1449e-01, -4.2954e+00,\n",
            "        -3.4364e+00,  1.4524e+00, -1.9085e-01, -4.1292e+00,  2.5675e+00,\n",
            "         1.5624e+00,  4.4023e+00,  8.8586e-01,  1.6232e+00, -7.0313e-01,\n",
            "        -4.5232e+00, -1.7236e+00,  1.2285e-01,  1.8064e+00, -2.6147e-01,\n",
            "        -7.5163e-01,  9.2087e-01,  1.5934e+00, -2.9880e+00,  1.1542e+00,\n",
            "         5.2590e-01,  3.0835e+00, -2.9410e+00,  3.5945e+00, -4.5431e+00,\n",
            "         5.0501e-01, -2.3845e+00, -4.2796e+00,  1.2966e+00, -1.0886e+00,\n",
            "         2.6551e+00, -8.3280e-01,  4.4833e-01, -6.6959e-01,  2.3068e+00,\n",
            "         2.4914e-01, -1.7551e+00, -1.3649e+00,  1.1346e+00,  1.0790e+00,\n",
            "         1.4416e-01, -1.6127e+00, -3.9901e+00, -1.4695e+00, -2.3733e+00,\n",
            "        -2.3952e+00, -5.7573e-01,  3.4240e+00,  2.6963e+00,  1.5976e+00,\n",
            "        -1.0828e+00,  1.7012e+00,  2.3571e-02, -1.2245e+00,  4.4321e+00,\n",
            "        -2.2059e+00, -4.1533e+00, -1.0994e-01,  1.0981e+00,  1.7152e+00,\n",
            "        -2.0054e+00,  4.8738e+00,  1.6405e+00, -2.8507e+00,  1.7440e+00,\n",
            "         1.5177e+00, -7.7288e-01,  3.7536e+00, -2.3039e+00,  1.1500e+00,\n",
            "         2.5749e-01, -3.2037e+00, -3.8718e+00,  2.5819e+00, -7.3391e-03,\n",
            "         3.5751e+00, -5.4554e+00, -4.9838e+00, -3.9902e+00, -4.6581e+00,\n",
            "         3.7365e+00,  7.8515e-01, -3.3180e+00, -1.0525e+00,  1.8330e+00,\n",
            "        -3.6874e+00, -5.8264e-02, -3.8396e-01, -1.3230e+00,  4.3327e-01,\n",
            "        -2.2274e+00,  2.5679e+00, -1.6342e+00,  1.2421e-01, -2.8099e+00,\n",
            "         1.7216e+00,  2.5697e+00, -5.7848e-01,  2.1096e+00, -6.8648e+00,\n",
            "         1.4844e-01,  2.5901e+00,  4.0875e+00,  1.0931e+00,  3.0803e+00,\n",
            "         4.2118e+00, -1.5313e+00,  5.2599e+00, -2.9497e+00,  3.0369e+00,\n",
            "         4.2822e-02, -2.1278e+00,  2.7988e+00, -2.9874e-01, -1.5189e+00,\n",
            "         1.8011e+00])), ('module.encoder_q.layer3.4.bn1.running_var', tensor([12.5803, 21.0316, 16.5057, 10.7248, 11.6879, 10.7294, 14.2390, 10.7160,\n",
            "        45.9586, 16.8398, 14.5150, 17.0259, 17.5027, 13.3016, 12.2038, 11.8010,\n",
            "        17.2811, 11.0616, 22.9196, 12.4752, 22.0776, 19.8949, 22.6423, 11.8461,\n",
            "        10.4647, 16.0808, 12.4667, 11.5304, 20.4600, 13.5457, 12.9706, 22.9034,\n",
            "        22.4648, 10.7889, 21.0058, 11.2461, 10.9957, 17.7324, 15.6958, 20.5128,\n",
            "        11.7734, 17.9077, 17.3185, 16.2203, 22.3846,  9.9054, 16.2163, 14.8011,\n",
            "        69.7446, 11.3281, 14.0922, 18.4681, 13.9324, 18.7829, 12.0335, 11.8246,\n",
            "        11.1326, 12.8116, 10.8534, 19.6286, 23.2702, 12.5919, 24.2246, 12.0958,\n",
            "        34.2623, 19.2173, 13.4599, 13.1881, 10.7223, 11.0563, 10.1561, 38.2113,\n",
            "        18.4891, 11.6820,  9.5917, 12.5837, 25.8087, 14.2009, 11.2253, 17.8619,\n",
            "        16.8686, 11.9820, 11.8648, 13.0155, 11.6719, 14.0533, 15.3027, 13.1828,\n",
            "        22.6510, 17.4186, 11.2112, 12.5593,  9.6502, 17.4705, 14.5303, 10.0872,\n",
            "        11.1869, 18.1955, 11.4145, 26.8372, 15.2861, 12.0361, 12.8643, 15.7958,\n",
            "        27.8793, 11.7676, 10.9837, 23.5633, 13.8644, 11.2140, 16.2438, 14.5725,\n",
            "        14.0773, 10.3391, 20.9956, 36.8490, 25.7060, 17.3465, 40.4149, 31.6071,\n",
            "        26.1982, 13.0729, 16.4297, 10.9564, 13.5081, 18.8922, 11.8568, 11.6762,\n",
            "        21.9076, 13.7769, 20.8644, 22.5117, 23.0560, 19.8317, 11.3674, 13.4031,\n",
            "        12.1969, 18.3300, 10.3761, 10.8441, 14.2817, 11.6970, 12.1133, 29.5193,\n",
            "        18.0511, 11.6907, 31.8072, 11.3593, 12.0307, 12.2815, 23.8400, 13.8454,\n",
            "        15.9796, 14.6498, 23.6105, 11.9383, 14.7947, 13.3177, 14.8091,  9.9853,\n",
            "        13.0019, 24.1318, 22.6817, 21.0368, 17.2181, 10.5558, 21.0207, 23.6894,\n",
            "        11.2485, 11.6630, 14.3450, 18.0715, 12.4799, 25.5904, 13.4525, 13.2316,\n",
            "        14.8864, 12.2115, 10.1389, 16.2329, 11.5399, 12.3313, 20.9031, 13.7414,\n",
            "        10.8373,  9.3601, 16.0205, 24.8192, 18.6285, 13.5004, 11.1417, 12.1133,\n",
            "        11.3522, 22.0227, 26.2744, 12.4909, 21.8506, 11.3991, 14.0479, 16.0403,\n",
            "        16.6177, 16.8546, 13.7989, 10.6593, 11.4649, 10.8651, 10.6729, 16.1661,\n",
            "        10.0671, 25.9444,  8.7989,  9.5829, 16.4354, 12.5789, 11.6651, 12.2660,\n",
            "        11.8026, 22.8091, 10.4049, 24.1159, 15.0516, 15.4807, 13.6283, 12.8500,\n",
            "        14.3598, 24.4077, 18.9976, 11.8179, 11.7991, 18.1710, 12.4724, 10.5621,\n",
            "        11.9750,  9.6773, 13.6763, 12.2386, 17.5430, 11.6280, 26.5933, 48.7287,\n",
            "        15.3296, 10.2569, 20.6146, 12.5382,  9.2261, 13.3796, 10.9595, 23.3662,\n",
            "         9.6249, 11.0188, 10.1864, 13.9572, 11.0410, 14.9164, 12.8907, 16.0823])), ('module.encoder_q.layer3.4.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.4.conv2.weight', tensor([[[[ 0.0410, -0.0218, -0.0194],\n",
            "          [ 0.0145,  0.0136, -0.0042],\n",
            "          [-0.0470, -0.0237, -0.0296]],\n",
            "\n",
            "         [[-0.0218,  0.0332,  0.0018],\n",
            "          [-0.0004,  0.0094,  0.0270],\n",
            "          [-0.0669,  0.0222, -0.0097]],\n",
            "\n",
            "         [[ 0.0111,  0.0205,  0.0126],\n",
            "          [ 0.0290, -0.0271, -0.0297],\n",
            "          [ 0.0510, -0.0307, -0.0216]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0411,  0.0150, -0.0174],\n",
            "          [-0.0250,  0.0167, -0.0154],\n",
            "          [ 0.0046, -0.0032,  0.0175]],\n",
            "\n",
            "         [[ 0.0129, -0.0337, -0.0358],\n",
            "          [-0.0203, -0.0053,  0.0370],\n",
            "          [-0.0034, -0.0460,  0.0005]],\n",
            "\n",
            "         [[-0.0061, -0.0214,  0.0238],\n",
            "          [ 0.1022,  0.0161,  0.0006],\n",
            "          [-0.0112, -0.0180, -0.0632]]],\n",
            "\n",
            "\n",
            "        [[[-0.0305,  0.0137,  0.0162],\n",
            "          [-0.0555,  0.0019,  0.0010],\n",
            "          [-0.0061, -0.0215, -0.0115]],\n",
            "\n",
            "         [[ 0.0122,  0.0507, -0.0250],\n",
            "          [ 0.0433,  0.0324,  0.0277],\n",
            "          [ 0.0265,  0.0087, -0.0260]],\n",
            "\n",
            "         [[-0.0586, -0.0131, -0.0101],\n",
            "          [-0.0207, -0.0087, -0.0637],\n",
            "          [-0.0020,  0.0223,  0.0028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0025,  0.0271, -0.0395],\n",
            "          [ 0.0017, -0.0809,  0.0197],\n",
            "          [ 0.0101, -0.0487, -0.0257]],\n",
            "\n",
            "         [[ 0.0446, -0.0100, -0.0201],\n",
            "          [-0.0131, -0.0242,  0.0032],\n",
            "          [-0.0082, -0.0029,  0.0449]],\n",
            "\n",
            "         [[ 0.0043, -0.0125,  0.0247],\n",
            "          [-0.0316,  0.0163,  0.0386],\n",
            "          [ 0.0216,  0.0118, -0.0259]]],\n",
            "\n",
            "\n",
            "        [[[-0.0693, -0.0048,  0.0162],\n",
            "          [-0.0247, -0.0382,  0.0086],\n",
            "          [ 0.0054,  0.0080, -0.0207]],\n",
            "\n",
            "         [[ 0.0185,  0.0798,  0.0088],\n",
            "          [-0.0341,  0.0149,  0.0401],\n",
            "          [-0.0255, -0.0313,  0.0044]],\n",
            "\n",
            "         [[-0.0372, -0.0348,  0.0080],\n",
            "          [ 0.0036, -0.0074,  0.0049],\n",
            "          [-0.0062,  0.0131, -0.0065]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0212, -0.0183,  0.0546],\n",
            "          [ 0.0271, -0.0145, -0.0522],\n",
            "          [ 0.0062,  0.0049, -0.0201]],\n",
            "\n",
            "         [[-0.0457, -0.0433,  0.0049],\n",
            "          [-0.0066, -0.0374, -0.0168],\n",
            "          [ 0.0389, -0.0085, -0.0252]],\n",
            "\n",
            "         [[ 0.0264, -0.0289,  0.0044],\n",
            "          [-0.0066,  0.0415,  0.0057],\n",
            "          [-0.0022, -0.0434, -0.0027]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0295,  0.0182, -0.0050],\n",
            "          [ 0.0295, -0.0014,  0.0057],\n",
            "          [ 0.0083,  0.0942, -0.0150]],\n",
            "\n",
            "         [[-0.0497,  0.0089,  0.0165],\n",
            "          [-0.0049,  0.0424,  0.0219],\n",
            "          [-0.0042, -0.0351, -0.0274]],\n",
            "\n",
            "         [[ 0.0460,  0.0025,  0.0190],\n",
            "          [ 0.0153, -0.0278, -0.0204],\n",
            "          [-0.0032, -0.0144, -0.0105]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0245, -0.0318, -0.0106],\n",
            "          [-0.0382,  0.0235, -0.0143],\n",
            "          [-0.0022, -0.0508, -0.0072]],\n",
            "\n",
            "         [[ 0.0186, -0.0088,  0.0300],\n",
            "          [ 0.0146, -0.0182,  0.0118],\n",
            "          [ 0.0113, -0.0116,  0.0834]],\n",
            "\n",
            "         [[ 0.0542, -0.0105,  0.0074],\n",
            "          [-0.0138,  0.0143,  0.0351],\n",
            "          [ 0.0111,  0.0617,  0.0013]]],\n",
            "\n",
            "\n",
            "        [[[-0.0215,  0.0521,  0.0189],\n",
            "          [-0.0373, -0.0321,  0.0703],\n",
            "          [-0.0168,  0.0746, -0.0325]],\n",
            "\n",
            "         [[ 0.0352, -0.0367,  0.0067],\n",
            "          [ 0.0114,  0.0023, -0.0172],\n",
            "          [ 0.0173, -0.0297, -0.0022]],\n",
            "\n",
            "         [[-0.0015, -0.0174,  0.0123],\n",
            "          [ 0.0719, -0.0154, -0.0492],\n",
            "          [ 0.0114, -0.0095,  0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0032, -0.0351,  0.0093],\n",
            "          [-0.0139, -0.0033, -0.0046],\n",
            "          [ 0.0346,  0.0143,  0.0577]],\n",
            "\n",
            "         [[-0.0135,  0.0297,  0.0070],\n",
            "          [-0.0203,  0.0095,  0.0095],\n",
            "          [ 0.0367,  0.0423, -0.0646]],\n",
            "\n",
            "         [[ 0.0247,  0.0129, -0.0123],\n",
            "          [-0.0370, -0.0147, -0.0106],\n",
            "          [-0.0082, -0.0706, -0.0274]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0235, -0.0078, -0.0325],\n",
            "          [ 0.0209, -0.0341,  0.0278],\n",
            "          [ 0.0152,  0.0030,  0.0136]],\n",
            "\n",
            "         [[ 0.0122,  0.0003,  0.0294],\n",
            "          [ 0.0177, -0.0262, -0.0275],\n",
            "          [ 0.0235, -0.0495,  0.0084]],\n",
            "\n",
            "         [[ 0.0220,  0.0132,  0.0131],\n",
            "          [-0.0043, -0.0117,  0.0318],\n",
            "          [-0.0450,  0.0599,  0.0165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0028,  0.0161, -0.0717],\n",
            "          [-0.0430,  0.0228, -0.0357],\n",
            "          [ 0.0015,  0.0206,  0.0076]],\n",
            "\n",
            "         [[ 0.0598,  0.0227,  0.0404],\n",
            "          [ 0.0084,  0.0027,  0.0538],\n",
            "          [ 0.0205, -0.0280,  0.0342]],\n",
            "\n",
            "         [[ 0.0237, -0.0233,  0.0122],\n",
            "          [-0.0113, -0.0098, -0.0005],\n",
            "          [-0.0078, -0.0142,  0.0279]]]])), ('module.encoder_q.layer3.4.bn2.weight', tensor([0.9919, 0.9922, 0.9917, 0.9918, 0.9922, 0.9923, 0.9929, 0.9924, 0.9925,\n",
            "        0.9930, 0.9924, 0.9919, 0.9925, 0.9923, 0.9921, 0.9920, 0.9923, 0.9918,\n",
            "        0.9927, 0.9923, 0.9922, 0.9915, 0.9919, 0.9918, 0.9926, 0.9930, 0.9923,\n",
            "        0.9921, 0.9926, 0.9921, 0.9919, 0.9919, 0.9920, 0.9918, 0.9920, 0.9920,\n",
            "        0.9919, 0.9923, 0.9920, 0.9918, 0.9928, 0.9922, 0.9917, 0.9919, 0.9921,\n",
            "        0.9923, 0.9925, 0.9923, 0.9931, 0.9924, 0.9921, 0.9931, 0.9920, 0.9927,\n",
            "        0.9922, 0.9926, 0.9918, 0.9924, 0.9918, 0.9919, 0.9922, 0.9921, 0.9920,\n",
            "        0.9930, 0.9921, 0.9925, 0.9923, 0.9922, 0.9930, 0.9916, 0.9912, 0.9922,\n",
            "        0.9920, 0.9929, 0.9924, 0.9928, 0.9926, 0.9917, 0.9924, 0.9918, 0.9919,\n",
            "        0.9923, 0.9926, 0.9921, 0.9917, 0.9925, 0.9920, 0.9923, 0.9922, 0.9925,\n",
            "        0.9924, 0.9918, 0.9919, 0.9921, 0.9924, 0.9927, 0.9921, 0.9921, 0.9923,\n",
            "        0.9922, 0.9929, 0.9922, 0.9920, 0.9919, 0.9917, 0.9920, 0.9930, 0.9930,\n",
            "        0.9927, 0.9926, 0.9920, 0.9926, 0.9920, 0.9924, 0.9933, 0.9923, 0.9923,\n",
            "        0.9926, 0.9922, 0.9920, 0.9925, 0.9928, 0.9917, 0.9924, 0.9922, 0.9930,\n",
            "        0.9925, 0.9920, 0.9920, 0.9924, 0.9922, 0.9925, 0.9923, 0.9928, 0.9927,\n",
            "        0.9920, 0.9923, 0.9926, 0.9922, 0.9921, 0.9925, 0.9924, 0.9916, 0.9928,\n",
            "        0.9927, 0.9923, 0.9922, 0.9919, 0.9920, 0.9929, 0.9921, 0.9921, 0.9921,\n",
            "        0.9929, 0.9923, 0.9917, 0.9918, 0.9927, 0.9928, 0.9920, 0.9926, 0.9921,\n",
            "        0.9923, 0.9925, 0.9920, 0.9922, 0.9920, 0.9914, 0.9917, 0.9917, 0.9927,\n",
            "        0.9923, 0.9924, 0.9922, 0.9919, 0.9923, 0.9925, 0.9922, 0.9920, 0.9917,\n",
            "        0.9927, 0.9928, 0.9918, 0.9927, 0.9917, 0.9919, 0.9929, 0.9923, 0.9920,\n",
            "        0.9925, 0.9920, 0.9923, 0.9923, 0.9923, 0.9921, 0.9920, 0.9926, 0.9921,\n",
            "        0.9925, 0.9926, 0.9927, 0.9928, 0.9924, 0.9921, 0.9918, 0.9921, 0.9927,\n",
            "        0.9914, 0.9919, 0.9925, 0.9916, 0.9925, 0.9923, 0.9917, 0.9919, 0.9927,\n",
            "        0.9925, 0.9923, 0.9919, 0.9917, 0.9922, 0.9923, 0.9917, 0.9926, 0.9922,\n",
            "        0.9926, 0.9922, 0.9923, 0.9925, 0.9922, 0.9921, 0.9925, 0.9919, 0.9927,\n",
            "        0.9930, 0.9928, 0.9927, 0.9932, 0.9921, 0.9925, 0.9920, 0.9921, 0.9920,\n",
            "        0.9919, 0.9924, 0.9919, 0.9921, 0.9918, 0.9921, 0.9919, 0.9926, 0.9919,\n",
            "        0.9923, 0.9924, 0.9925, 0.9926])), ('module.encoder_q.layer3.4.bn2.bias', tensor([-1.2439e-04, -4.9421e-05, -2.6823e-04, -2.3804e-04,  2.9151e-04,\n",
            "        -1.9649e-04,  2.4176e-04, -1.1786e-04,  1.7422e-04,  7.0499e-04,\n",
            "         2.6078e-04, -3.8059e-04,  3.5178e-04,  2.5942e-04,  3.0105e-05,\n",
            "        -4.1200e-05, -1.5717e-04, -2.8158e-04,  1.4848e-04,  4.5995e-04,\n",
            "        -5.9074e-04,  1.7237e-04, -5.4714e-04, -1.1670e-04,  4.4812e-04,\n",
            "         4.5704e-04, -1.9536e-04, -2.3070e-04,  6.8522e-05,  2.3027e-04,\n",
            "        -6.0623e-04, -7.0707e-06, -1.7966e-05, -4.8564e-04, -4.8865e-04,\n",
            "         2.8320e-04, -6.7331e-04,  2.7084e-05, -6.5804e-04, -2.3474e-04,\n",
            "        -5.1369e-05, -5.3696e-04, -1.7092e-04, -2.4546e-04,  2.7315e-04,\n",
            "        -2.0223e-05,  1.2553e-04, -1.5090e-04,  5.8965e-04, -5.9034e-05,\n",
            "         1.7774e-04,  8.3283e-04, -2.9131e-04,  1.7802e-04,  1.7956e-04,\n",
            "         7.1832e-05,  8.9076e-05,  4.3545e-05, -3.2221e-05, -7.5468e-05,\n",
            "        -3.2758e-04, -5.1190e-04,  1.8141e-04,  2.1334e-04, -1.5503e-04,\n",
            "         4.1501e-04, -2.4632e-04,  2.7855e-05,  6.8616e-05, -6.5559e-04,\n",
            "        -6.4336e-05, -5.3949e-05, -4.0462e-04,  4.8359e-04, -1.9193e-04,\n",
            "         3.2348e-04,  2.8975e-05, -2.2128e-04,  1.3920e-04,  1.2710e-04,\n",
            "         2.8464e-05, -1.5578e-04,  2.2088e-04, -5.2724e-04, -7.3448e-04,\n",
            "        -4.2006e-06,  3.0367e-04, -2.4120e-04,  3.4916e-05,  2.5256e-04,\n",
            "         1.4100e-06, -6.0896e-04, -1.3983e-04, -2.9617e-04,  1.2698e-04,\n",
            "         5.4722e-05, -1.8415e-04, -1.3864e-04, -1.2885e-04,  5.6296e-04,\n",
            "         2.6918e-04, -8.2748e-05, -2.8652e-04,  6.1105e-05, -3.4336e-04,\n",
            "        -6.0686e-05,  1.9433e-04,  2.9144e-04,  1.1093e-04,  3.0413e-04,\n",
            "        -4.1720e-04,  5.0353e-04,  6.2218e-06,  3.0908e-04,  4.5659e-04,\n",
            "        -1.4381e-05, -2.8113e-05,  8.5913e-05, -5.6063e-05,  2.9793e-05,\n",
            "         1.1192e-04,  2.3686e-04, -6.1822e-04, -3.4448e-04, -3.3122e-04,\n",
            "         5.1342e-04, -1.0078e-04, -3.1102e-04,  1.1267e-04,  2.5878e-04,\n",
            "        -9.6212e-06, -1.3203e-04, -1.5466e-04,  2.0726e-05,  5.7763e-04,\n",
            "        -5.0724e-04, -7.7580e-04,  8.2324e-04,  9.8802e-05, -2.3024e-04,\n",
            "        -1.3325e-05, -4.3115e-05, -4.7728e-04,  2.8958e-04,  8.6997e-04,\n",
            "        -3.3155e-04, -1.2856e-04, -6.4506e-04,  2.8609e-04,  5.1596e-04,\n",
            "         2.6585e-06, -3.7585e-04,  4.1694e-04,  3.5953e-04, -4.6652e-05,\n",
            "        -1.9815e-04, -1.5890e-05,  4.6036e-04,  4.5389e-05, -3.2617e-04,\n",
            "         3.9198e-05, -6.0561e-04, -1.0782e-04,  5.5776e-05, -5.5481e-04,\n",
            "        -4.5947e-05, -2.1006e-04, -3.8287e-04, -4.8365e-04, -1.6215e-04,\n",
            "         8.1052e-05,  2.0304e-04, -2.1709e-04,  2.6380e-05, -5.1524e-04,\n",
            "        -7.6739e-05,  9.7285e-05,  1.9305e-04, -4.3672e-04,  3.4182e-05,\n",
            "         4.0647e-04, -5.0968e-04, -1.9801e-04,  1.3059e-04, -3.0766e-04,\n",
            "        -5.2593e-04,  5.3878e-04, -2.3967e-06,  8.2105e-05, -4.2531e-05,\n",
            "         1.0964e-04, -4.7787e-04, -2.7284e-04, -6.2858e-05,  1.7730e-04,\n",
            "        -6.6912e-04,  2.1615e-04, -1.2172e-05,  3.6267e-04,  5.4745e-04,\n",
            "         2.8627e-04,  5.5987e-04,  3.6626e-04, -5.7449e-04, -4.2862e-04,\n",
            "         5.5304e-05,  3.7151e-04, -5.7353e-04, -7.3543e-06,  4.4630e-04,\n",
            "        -6.8305e-04, -2.2045e-04,  1.8186e-04, -1.0571e-04, -4.1255e-04,\n",
            "        -2.7514e-04,  2.4527e-05, -2.9614e-04, -1.0665e-04, -8.4730e-04,\n",
            "         3.1896e-04,  2.2039e-04, -1.5652e-04,  6.5672e-05, -1.4176e-04,\n",
            "         5.3155e-04, -7.5683e-04,  1.5571e-04,  5.3575e-04,  1.2708e-04,\n",
            "        -8.3820e-05, -6.9178e-05, -1.9648e-04,  6.5706e-04,  7.3736e-04,\n",
            "         4.6159e-04,  2.5722e-05,  2.2627e-04, -1.6157e-04,  6.9322e-04,\n",
            "        -3.6670e-04, -2.2959e-04,  3.4255e-04, -2.1501e-05,  1.2293e-04,\n",
            "        -2.3953e-04,  9.2937e-05, -1.0598e-04, -1.4148e-04, -9.7619e-05,\n",
            "         1.3228e-04, -5.3118e-04,  5.5372e-04, -7.0368e-05, -1.3852e-04,\n",
            "         5.5621e-04])), ('module.encoder_q.layer3.4.bn2.running_mean', tensor([-5.6854e-01, -1.4815e-01,  2.9789e-01, -1.7013e-01, -2.9393e-01,\n",
            "        -1.0655e-01, -2.5508e-01,  1.6935e-01,  5.4629e-01,  2.6824e-01,\n",
            "         6.2111e-01, -5.4560e-01,  3.9898e-01,  3.9088e-01, -6.9620e-01,\n",
            "         5.6773e-01,  1.1279e-01, -8.9123e-01,  5.0986e-01, -1.0507e-01,\n",
            "         3.5815e-03,  5.1595e-01,  5.7190e-01, -1.0774e-01,  2.8286e-01,\n",
            "         9.4406e-01, -5.3480e-01, -9.0655e-01,  4.0135e-02, -4.5204e-01,\n",
            "        -4.3648e-01,  5.4469e-01,  1.8824e-01, -8.4020e-01, -4.6897e-01,\n",
            "        -1.0320e-01,  4.9077e-01, -2.6819e-01, -1.7492e-01, -2.1101e-01,\n",
            "        -5.3041e-01, -8.7923e-02, -1.7904e-02,  8.3181e-01,  3.4083e-01,\n",
            "        -2.2347e-01,  3.6356e-01,  3.0447e-01,  1.2336e-01, -1.9180e-01,\n",
            "        -3.8251e-01,  2.9183e-01,  1.0894e-01, -7.0337e-01,  7.6542e-02,\n",
            "         4.8883e-02,  4.9983e-01,  2.0946e-01, -6.4696e-02,  4.2681e-01,\n",
            "        -2.8770e-02,  2.4465e-01, -1.9644e-01,  1.3199e-02, -3.1161e-01,\n",
            "         6.0022e-02, -5.5572e-01, -6.1120e-01, -3.8341e-01, -3.1832e-01,\n",
            "         9.6523e-02,  3.1747e-01, -1.7492e-01,  2.5931e-01,  1.2723e-01,\n",
            "         6.9073e-02, -3.9254e-01,  1.7639e-01,  5.4541e-02, -5.2041e-01,\n",
            "        -3.8309e-01,  6.4867e-01, -1.3247e-01, -2.1733e-01,  1.6578e-01,\n",
            "        -1.1623e-01, -7.2650e-01,  5.9903e-02, -2.4075e-01, -7.7233e-02,\n",
            "        -3.1623e-01, -2.5867e-01, -1.2324e-01, -5.5089e-01,  1.6539e-01,\n",
            "         7.9854e-01,  9.6078e-02,  2.4394e-01, -3.1277e-01, -2.0673e-01,\n",
            "         2.6132e-01,  2.3134e-01, -2.4420e-01,  4.9189e-01,  2.5540e-01,\n",
            "        -9.1180e-02,  6.0081e-01, -1.1274e-01, -4.5224e-01,  4.7464e-02,\n",
            "         2.3427e-01,  9.4579e-02, -5.3369e-01,  5.4272e-01,  4.8056e-01,\n",
            "         6.4684e-01, -2.7380e-01, -8.9028e-02, -4.2522e-01, -1.1770e+00,\n",
            "        -2.0720e-03,  4.5392e-01,  8.8125e-01,  4.8002e-01, -4.0386e-01,\n",
            "         2.9117e-02,  1.8557e-01,  1.1364e-01, -3.2721e-01,  2.1492e-01,\n",
            "         7.6392e-01,  1.9093e-01,  6.0344e-01, -1.6688e-02,  8.3332e-02,\n",
            "         3.0111e-01, -3.4833e-01, -2.3124e-01, -1.6201e-01, -1.0393e+00,\n",
            "         9.7051e-01, -5.3841e-01, -1.2001e-01,  9.4823e-02, -8.0782e-01,\n",
            "         4.9280e-01,  1.1654e-01,  4.8853e-01, -4.4917e-01, -1.9106e-01,\n",
            "         6.0272e-01,  2.3321e-01, -4.8136e-01,  3.2180e-01,  6.4179e-01,\n",
            "        -2.0635e-01, -2.1054e-01, -1.5073e-01, -1.2084e-01, -1.6719e-01,\n",
            "        -4.4615e-01,  5.9259e-02,  1.2051e-01, -4.3141e-01,  2.4997e-01,\n",
            "         5.8431e-01, -4.8819e-01,  5.0280e-01, -2.4275e-01,  3.1009e-01,\n",
            "        -1.0511e-02,  3.6535e-01,  3.9294e-01,  3.3241e-01,  7.7454e-01,\n",
            "        -1.1366e-01,  3.6768e-01, -8.9071e-02, -1.9398e-01,  7.4329e-01,\n",
            "        -2.7358e-01,  4.7690e-01, -3.4566e-01, -4.0239e-01,  4.1254e-02,\n",
            "         3.7942e-01,  1.3449e-01, -2.4476e-01, -1.8947e-01,  2.7180e-01,\n",
            "        -8.0726e-01, -2.4448e-01, -2.3574e-01,  5.1039e-01, -5.1458e-02,\n",
            "        -5.9870e-02,  7.4375e-01,  3.8176e-01,  5.8512e-01, -1.4290e-01,\n",
            "         2.2668e-01,  2.8464e-01,  3.4649e-01, -4.9194e-01,  2.9672e-02,\n",
            "         5.5832e-01,  4.9996e-01, -2.5519e-01, -1.7695e-01, -1.7054e-01,\n",
            "        -5.8525e-01, -8.4864e-01, -5.3525e-01, -9.9540e-02, -4.4538e-01,\n",
            "         6.6442e-01,  3.3858e-01,  1.5946e-01,  1.4925e+00,  8.5865e-02,\n",
            "         3.4519e-02,  7.8900e-01,  2.5799e-01, -1.9552e-02, -7.7239e-01,\n",
            "        -1.7218e-01,  1.0332e+00,  8.1667e-02, -1.7020e-01,  3.1521e-02,\n",
            "        -2.1001e-01, -5.0775e-02, -6.3544e-01, -5.6696e-01,  4.1963e-01,\n",
            "        -6.6078e-01, -8.0416e-01,  1.9678e-01, -3.3535e-01, -4.7572e-01,\n",
            "        -2.2361e-01,  1.6045e-01, -3.9099e-01,  2.0512e-01, -9.8693e-04,\n",
            "        -7.2861e-01, -9.2402e-01,  9.2313e-01,  1.3237e-01,  8.5186e-01,\n",
            "         8.3348e-02,  2.7059e-01, -6.5333e-02, -1.2350e-01,  3.2292e-01,\n",
            "         4.8653e-01])), ('module.encoder_q.layer3.4.bn2.running_var', tensor([0.6521, 0.6312, 0.5930, 0.5627, 1.0179, 0.6778, 0.7295, 0.5931, 0.8861,\n",
            "        0.8611, 0.5575, 0.6128, 0.5288, 0.5357, 1.3038, 0.9725, 0.5809, 0.7992,\n",
            "        0.5303, 0.6322, 0.8088, 1.0986, 1.0303, 0.5460, 0.6891, 0.8953, 0.5367,\n",
            "        0.5624, 0.6490, 0.6490, 1.0958, 0.6497, 0.7439, 0.6756, 1.5581, 0.5317,\n",
            "        0.6694, 0.7656, 0.9287, 0.8882, 0.5490, 0.6897, 0.6009, 1.0695, 0.5941,\n",
            "        1.1732, 0.5578, 0.9160, 0.5106, 0.6003, 0.5267, 0.5082, 0.8836, 0.5510,\n",
            "        0.6167, 0.5454, 0.6998, 0.7394, 1.0830, 0.5719, 0.6662, 0.7522, 0.7964,\n",
            "        0.5818, 1.6150, 0.5106, 0.7119, 1.4737, 0.7586, 0.6711, 0.5859, 0.7438,\n",
            "        0.7078, 0.6914, 0.6373, 0.5489, 0.5441, 0.6841, 0.4690, 0.5952, 0.8751,\n",
            "        0.7953, 0.6175, 0.6738, 0.5997, 0.6706, 0.6962, 0.6531, 1.0133, 0.5202,\n",
            "        0.9739, 0.8836, 0.5848, 0.6154, 0.5252, 1.5460, 0.7886, 0.6138, 0.5041,\n",
            "        0.7557, 1.0485, 0.6461, 0.6518, 0.8186, 0.7774, 0.6183, 0.6522, 0.8924,\n",
            "        0.5446, 0.5667, 0.5610, 0.6903, 0.5600, 0.6066, 0.7104, 0.8360, 1.1171,\n",
            "        0.5782, 0.7145, 1.0199, 0.6066, 0.8903, 1.0433, 1.2125, 0.5555, 0.5225,\n",
            "        0.5519, 0.5016, 0.7935, 0.5619, 1.5944, 0.7233, 1.1380, 0.7784, 0.5718,\n",
            "        0.7088, 0.6069, 0.6148, 0.8320, 0.7844, 2.5396, 0.5319, 0.6613, 0.5554,\n",
            "        1.7917, 0.8136, 0.5542, 0.9955, 0.6524, 0.5935, 0.8330, 0.6543, 0.9658,\n",
            "        0.5894, 0.6231, 0.6048, 0.7330, 0.9486, 0.5159, 0.5071, 0.8257, 0.6951,\n",
            "        0.5441, 0.5871, 0.4688, 0.6364, 0.8015, 0.5322, 0.5431, 0.6252, 0.6378,\n",
            "        0.9942, 0.8889, 0.6017, 0.6613, 0.7163, 1.0353, 0.5275, 0.6250, 1.7234,\n",
            "        0.6665, 0.5789, 0.6476, 0.5760, 0.6895, 0.6297, 0.6150, 0.6903, 0.5783,\n",
            "        0.6172, 1.3133, 0.5909, 0.6985, 0.6650, 0.9964, 0.8336, 1.4642, 0.5673,\n",
            "        0.6872, 0.9520, 0.6568, 0.6307, 0.5308, 0.6999, 0.8476, 0.9276, 0.6541,\n",
            "        1.1036, 0.8822, 0.5169, 0.6082, 0.7340, 1.3493, 0.5784, 0.5323, 0.7777,\n",
            "        0.6870, 0.5051, 1.5504, 0.5115, 0.7913, 0.9761, 0.7534, 0.6260, 0.8619,\n",
            "        0.5584, 1.4122, 0.6866, 0.9894, 0.5694, 0.5488, 0.6119, 0.7062, 0.5787,\n",
            "        1.4791, 0.6669, 0.5053, 0.7906, 0.5717, 0.6456, 0.5133, 0.7096, 0.7992,\n",
            "        0.5430, 0.6879, 0.6866, 0.7046, 0.5944, 0.7414, 1.7542, 0.5870, 0.6211,\n",
            "        1.2669, 0.5114, 0.5888, 0.7414])), ('module.encoder_q.layer3.4.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.4.conv3.weight', tensor([[[[ 0.0531]],\n",
            "\n",
            "         [[ 0.0060]],\n",
            "\n",
            "         [[-0.0328]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0251]],\n",
            "\n",
            "         [[-0.0164]],\n",
            "\n",
            "         [[ 0.0801]]],\n",
            "\n",
            "\n",
            "        [[[-0.0454]],\n",
            "\n",
            "         [[-0.0165]],\n",
            "\n",
            "         [[-0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0440]],\n",
            "\n",
            "         [[ 0.0011]],\n",
            "\n",
            "         [[ 0.0176]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0555]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         [[-0.1085]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0495]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[-0.0672]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0471]],\n",
            "\n",
            "         [[ 0.0034]],\n",
            "\n",
            "         [[ 0.0106]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0152]],\n",
            "\n",
            "         [[-0.0105]],\n",
            "\n",
            "         [[ 0.0339]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0007]],\n",
            "\n",
            "         [[ 0.0455]],\n",
            "\n",
            "         [[ 0.0240]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0312]],\n",
            "\n",
            "         [[-0.0445]]],\n",
            "\n",
            "\n",
            "        [[[-0.0612]],\n",
            "\n",
            "         [[-0.0034]],\n",
            "\n",
            "         [[-0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0027]],\n",
            "\n",
            "         [[ 0.0649]],\n",
            "\n",
            "         [[-0.0058]]]])), ('module.encoder_q.layer3.4.bn3.weight', tensor([0.9924, 0.9921, 0.9921,  ..., 0.9923, 0.9923, 0.9922])), ('module.encoder_q.layer3.4.bn3.bias', tensor([-2.9795e-05,  2.2208e-04,  1.6837e-05,  ..., -4.9301e-05,\n",
            "        -5.5647e-05, -2.3973e-04])), ('module.encoder_q.layer3.4.bn3.running_mean', tensor([ 0.1314, -0.1404, -0.0382,  ...,  0.0631,  0.1139,  0.0210])), ('module.encoder_q.layer3.4.bn3.running_var', tensor([0.1700, 0.1516, 0.1919,  ..., 0.2096, 0.1520, 0.1451])), ('module.encoder_q.layer3.4.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.5.conv1.weight', tensor([[[[-0.1059]],\n",
            "\n",
            "         [[ 0.1113]],\n",
            "\n",
            "         [[ 0.0466]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0808]],\n",
            "\n",
            "         [[ 0.1361]],\n",
            "\n",
            "         [[ 0.1734]]],\n",
            "\n",
            "\n",
            "        [[[-0.1397]],\n",
            "\n",
            "         [[-0.0669]],\n",
            "\n",
            "         [[ 0.0396]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0283]],\n",
            "\n",
            "         [[ 0.1866]],\n",
            "\n",
            "         [[-0.1270]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0185]],\n",
            "\n",
            "         [[ 0.1140]],\n",
            "\n",
            "         [[-0.0611]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0490]],\n",
            "\n",
            "         [[-0.0553]],\n",
            "\n",
            "         [[ 0.0717]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0759]],\n",
            "\n",
            "         [[ 0.0378]],\n",
            "\n",
            "         [[ 0.0333]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0611]],\n",
            "\n",
            "         [[ 0.1605]],\n",
            "\n",
            "         [[-0.0808]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0117]],\n",
            "\n",
            "         [[-0.2268]],\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0461]],\n",
            "\n",
            "         [[-0.0360]],\n",
            "\n",
            "         [[-0.0226]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0853]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0590]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1132]],\n",
            "\n",
            "         [[-0.0254]],\n",
            "\n",
            "         [[-0.1190]]]])), ('module.encoder_q.layer3.5.bn1.weight', tensor([0.9924, 0.9935, 0.9924, 0.9918, 0.9925, 0.9927, 0.9919, 0.9917, 0.9922,\n",
            "        0.9922, 0.9919, 0.9932, 0.9920, 0.9918, 0.9923, 0.9920, 0.9928, 0.9918,\n",
            "        0.9919, 0.9922, 0.9924, 0.9924, 0.9921, 0.9926, 0.9923, 0.9923, 0.9917,\n",
            "        0.9928, 0.9924, 0.9923, 0.9918, 0.9919, 0.9926, 0.9924, 0.9934, 0.9921,\n",
            "        0.9920, 0.9924, 0.9923, 0.9923, 0.9915, 0.9924, 0.9913, 0.9923, 0.9917,\n",
            "        0.9914, 0.9922, 0.9923, 0.9923, 0.9926, 0.9927, 0.9919, 0.9928, 0.9926,\n",
            "        0.9923, 0.9923, 0.9932, 0.9922, 0.9922, 0.9927, 0.9926, 0.9923, 0.9922,\n",
            "        0.9921, 0.9914, 0.9921, 0.9925, 0.9923, 0.9922, 0.9926, 0.9928, 0.9922,\n",
            "        0.9921, 0.9930, 0.9921, 0.9924, 0.9926, 0.9923, 0.9921, 0.9931, 0.9919,\n",
            "        0.9917, 0.9929, 0.9924, 0.9924, 0.9923, 0.9924, 0.9924, 0.9925, 0.9918,\n",
            "        0.9925, 0.9929, 0.9922, 0.9919, 0.9917, 0.9925, 0.9918, 0.9922, 0.9924,\n",
            "        0.9923, 0.9923, 0.9920, 0.9927, 0.9920, 0.9924, 0.9918, 0.9933, 0.9921,\n",
            "        0.9929, 0.9927, 0.9921, 0.9920, 0.9914, 0.9920, 0.9919, 0.9928, 0.9928,\n",
            "        0.9916, 0.9919, 0.9921, 0.9917, 0.9928, 0.9927, 0.9916, 0.9924, 0.9920,\n",
            "        0.9923, 0.9918, 0.9919, 0.9917, 0.9925, 0.9920, 0.9928, 0.9924, 0.9925,\n",
            "        0.9923, 0.9927, 0.9920, 0.9921, 0.9922, 0.9925, 0.9921, 0.9924, 0.9929,\n",
            "        0.9913, 0.9924, 0.9924, 0.9919, 0.9925, 0.9928, 0.9929, 0.9923, 0.9924,\n",
            "        0.9915, 0.9921, 0.9921, 0.9922, 0.9920, 0.9922, 0.9916, 0.9921, 0.9927,\n",
            "        0.9920, 0.9921, 0.9926, 0.9931, 0.9918, 0.9915, 0.9926, 0.9928, 0.9919,\n",
            "        0.9924, 0.9923, 0.9923, 0.9913, 0.9920, 0.9918, 0.9925, 0.9918, 0.9922,\n",
            "        0.9928, 0.9924, 0.9923, 0.9916, 0.9920, 0.9923, 0.9915, 0.9922, 0.9919,\n",
            "        0.9919, 0.9923, 0.9924, 0.9918, 0.9920, 0.9921, 0.9929, 0.9924, 0.9922,\n",
            "        0.9925, 0.9921, 0.9915, 0.9928, 0.9922, 0.9918, 0.9925, 0.9930, 0.9926,\n",
            "        0.9921, 0.9923, 0.9928, 0.9923, 0.9922, 0.9919, 0.9921, 0.9928, 0.9922,\n",
            "        0.9927, 0.9923, 0.9921, 0.9926, 0.9919, 0.9924, 0.9927, 0.9920, 0.9924,\n",
            "        0.9923, 0.9925, 0.9923, 0.9926, 0.9920, 0.9918, 0.9925, 0.9933, 0.9926,\n",
            "        0.9927, 0.9926, 0.9922, 0.9919, 0.9920, 0.9928, 0.9923, 0.9920, 0.9921,\n",
            "        0.9920, 0.9919, 0.9922, 0.9927, 0.9913, 0.9916, 0.9927, 0.9921, 0.9925,\n",
            "        0.9919, 0.9924, 0.9924, 0.9920])), ('module.encoder_q.layer3.5.bn1.bias', tensor([-1.4485e-04,  9.5240e-04, -2.8423e-04, -4.3803e-04,  1.4634e-04,\n",
            "         2.5419e-04,  1.0256e-04, -1.3170e-04, -6.2354e-04, -9.8049e-05,\n",
            "        -6.9769e-04,  9.2319e-04,  2.3937e-04, -6.7054e-04, -2.4752e-04,\n",
            "        -5.4027e-04,  8.4944e-04, -1.4238e-04, -1.2206e-04, -9.9478e-05,\n",
            "        -2.8165e-04,  1.4150e-04, -5.1996e-04,  2.5264e-04, -2.7473e-04,\n",
            "         2.4547e-04,  2.8361e-04,  7.2747e-04, -2.9774e-04, -1.5812e-04,\n",
            "        -1.2468e-04, -3.5464e-04,  3.0362e-05, -7.8185e-05,  9.4955e-04,\n",
            "         5.4175e-05, -3.3591e-04,  4.3271e-04, -3.4069e-05,  5.8671e-05,\n",
            "        -5.5129e-04, -8.6314e-05, -8.2876e-04, -4.9521e-05, -4.6961e-04,\n",
            "        -9.4414e-04,  4.3486e-04,  2.2517e-04, -2.4192e-04, -9.0018e-05,\n",
            "         5.8885e-05,  2.8354e-04, -2.0356e-04,  1.1348e-04,  1.6346e-04,\n",
            "         6.5239e-05,  1.1095e-03,  5.6025e-05, -8.6019e-05,  3.0687e-04,\n",
            "         2.9627e-04, -1.4759e-04, -2.6201e-04,  1.2773e-04, -6.5833e-04,\n",
            "        -6.5637e-05,  2.6562e-04,  1.7235e-04, -4.5339e-04, -9.0976e-05,\n",
            "         1.6639e-04, -2.9346e-04,  2.4185e-04,  6.0770e-04,  1.9357e-04,\n",
            "        -1.8413e-04, -1.5580e-04, -3.0586e-06, -4.2296e-05,  3.6628e-04,\n",
            "         2.6003e-04, -5.5925e-04,  3.2065e-04,  3.2681e-04,  1.7987e-04,\n",
            "        -6.7938e-05,  5.5701e-05,  3.6870e-04,  5.3127e-05, -1.2761e-04,\n",
            "         1.5622e-04,  3.6108e-04, -3.4796e-04, -5.7874e-05, -2.1567e-04,\n",
            "         2.5473e-06,  7.2530e-06, -2.5708e-04,  1.4184e-04,  5.6768e-05,\n",
            "         8.3907e-07, -2.9222e-04,  5.0899e-04, -2.4448e-04,  6.2199e-04,\n",
            "        -4.0365e-04,  1.6473e-03,  1.8996e-04,  2.7809e-04,  5.8057e-04,\n",
            "        -2.1089e-04, -4.7352e-04, -3.5395e-04, -1.1217e-03, -3.3927e-04,\n",
            "        -1.1517e-04,  9.2088e-05, -7.4107e-04, -1.5067e-04,  1.2070e-04,\n",
            "        -3.8404e-04,  1.7150e-04,  3.2241e-04, -1.2735e-04,  1.7558e-04,\n",
            "        -4.1709e-04,  8.4309e-05,  4.0962e-05, -4.5635e-04, -3.9239e-04,\n",
            "         1.4791e-04, -2.2424e-04,  2.4413e-04, -2.9602e-04,  5.9646e-04,\n",
            "         2.5500e-04,  5.6608e-04,  2.0716e-05, -1.1945e-04, -2.8639e-05,\n",
            "         4.9617e-04, -3.8197e-04, -2.2166e-04,  1.0858e-04, -7.7894e-04,\n",
            "        -5.2522e-04,  4.1809e-05, -2.1533e-04, -2.4401e-04,  5.7283e-04,\n",
            "         7.6374e-04, -8.1086e-05, -1.8513e-04, -3.2244e-04, -6.4208e-05,\n",
            "         5.0559e-04,  9.4530e-06, -1.2342e-04,  4.4498e-05, -6.2697e-04,\n",
            "         2.8994e-05,  6.9492e-04, -3.0875e-04,  8.2270e-05,  2.7243e-04,\n",
            "         6.9163e-04,  1.0542e-04,  1.9195e-04,  6.5334e-04,  7.9045e-04,\n",
            "        -3.5636e-04, -8.6652e-05, -3.0904e-05,  1.9612e-05, -3.7372e-04,\n",
            "         1.6195e-04, -4.1387e-04,  4.2876e-04, -4.6902e-04,  4.4232e-04,\n",
            "        -1.3657e-04,  2.1653e-05, -2.8856e-05, -7.8387e-04, -4.8984e-04,\n",
            "         1.5339e-04, -1.1125e-03, -4.6502e-04, -3.3145e-04, -3.3551e-04,\n",
            "        -1.7579e-04, -1.1014e-04,  6.4340e-05, -1.2509e-04, -3.5559e-04,\n",
            "         4.2502e-04, -2.1121e-04,  2.7117e-04,  5.1485e-04,  2.8716e-05,\n",
            "        -4.3182e-04,  3.4086e-04, -5.7634e-04, -7.7551e-04,  1.7052e-04,\n",
            "         7.5881e-04,  6.0758e-04, -1.5462e-04, -9.1362e-05, -1.2058e-04,\n",
            "         1.6395e-04, -3.7420e-05, -4.7908e-04, -3.5288e-04,  1.1911e-04,\n",
            "         2.0320e-04,  3.2818e-04,  1.7193e-04,  6.5435e-05,  6.9553e-04,\n",
            "        -1.3495e-04, -8.0856e-05,  4.9616e-04, -4.5706e-04, -3.2688e-04,\n",
            "        -2.8221e-04,  4.2746e-04,  1.7625e-04, -6.3031e-06, -9.1162e-05,\n",
            "        -3.7943e-04,  4.0883e-04,  5.3064e-04,  1.8377e-04, -1.3209e-04,\n",
            "         5.0626e-04, -2.6115e-04, -2.6049e-04, -3.0020e-04,  4.9559e-04,\n",
            "        -6.7309e-05,  7.5368e-06,  5.1220e-04, -5.9933e-04, -2.7149e-04,\n",
            "         1.0195e-04,  2.4548e-04, -5.8849e-04, -6.5229e-04,  5.8952e-04,\n",
            "         9.5693e-04, -3.0524e-05,  8.9493e-05, -1.3447e-04,  2.1094e-04,\n",
            "         1.4638e-04])), ('module.encoder_q.layer3.5.bn1.running_mean', tensor([-2.4302e+00, -8.0523e-02,  7.4214e+00, -2.7064e+00, -7.4127e-01,\n",
            "        -1.0239e+00,  2.8813e+00,  4.2497e-01,  3.4629e+00,  2.2438e+00,\n",
            "         2.7518e+00,  2.9971e+00,  1.1588e+00, -2.8565e+00,  4.6564e-01,\n",
            "        -4.8364e+00, -6.0547e-01,  1.5616e+00,  2.2096e+00, -2.1825e+00,\n",
            "        -3.5608e+00, -1.3854e+00, -3.3951e+00, -3.5913e+00, -1.7391e+00,\n",
            "        -4.2273e+00, -1.8582e-01, -1.9935e+00,  1.7755e+00, -1.8188e+00,\n",
            "         1.3767e+00,  1.9297e+00,  2.8313e+00,  4.0743e-01,  3.5916e+00,\n",
            "         2.3709e+00,  3.5973e+00, -4.1916e+00, -5.4666e+00,  4.9930e+00,\n",
            "         6.0979e-01,  2.5491e+00,  1.1315e+00, -1.0343e+00,  2.5019e+00,\n",
            "         1.2426e+00, -5.1030e+00, -8.5496e-01,  1.2147e-01,  2.5733e+00,\n",
            "        -2.3778e-01,  4.2143e+00,  5.6093e+00,  5.0983e+00,  1.2679e+00,\n",
            "        -2.0991e+00,  7.6942e+00, -3.8421e+00, -1.1767e-01,  3.6420e+00,\n",
            "        -1.4744e+00,  2.6426e-01, -1.7197e+00,  2.4302e+00,  1.8507e+00,\n",
            "        -5.0276e-01,  8.3257e+00,  2.8781e-01,  4.8226e+00,  1.9786e+00,\n",
            "         1.3663e+00, -1.6559e+00,  3.1553e+00,  3.4474e+00, -2.3734e+00,\n",
            "         4.5174e+00,  6.8545e+00, -7.4223e-02,  4.3360e+00, -7.2706e-01,\n",
            "        -2.7454e-01, -1.7077e+00, -9.5911e-01,  3.1479e-01, -5.1559e+00,\n",
            "         1.0065e+00,  6.6270e+00, -3.9134e+00, -2.2439e+00, -1.6646e+00,\n",
            "        -2.4422e+00,  3.4260e+00,  4.7426e-01,  8.5499e-01, -2.3033e+00,\n",
            "         2.9598e+00, -1.1947e+00, -3.1843e+00,  1.2720e+00,  9.6758e-01,\n",
            "         3.6880e-01, -3.2138e-01, -2.5166e+00, -3.1474e+00, -4.0281e-01,\n",
            "         3.0441e+00, -2.6522e+00, -1.5293e+00, -1.1820e+00, -3.2072e+00,\n",
            "         3.9894e-01, -4.7900e+00,  4.2847e+00,  2.9130e+00,  1.7069e+00,\n",
            "         3.7612e+00,  1.6396e+00,  8.6134e-01,  7.2143e+00,  3.6390e+00,\n",
            "        -5.0749e+00,  6.0232e-01, -3.9719e+00,  5.0651e+00, -3.1199e+00,\n",
            "        -3.3195e+00, -1.0467e+00,  9.6097e-01, -4.4226e+00,  1.9517e+00,\n",
            "         5.2148e+00,  4.0256e+00, -1.0971e+00, -1.6360e+00,  2.4342e+00,\n",
            "        -3.5662e+00,  4.7035e+00,  2.5562e+00, -1.4197e+00,  2.9029e+00,\n",
            "         1.5895e+00,  6.0893e+00,  4.6883e+00,  2.5548e+00, -4.7807e+00,\n",
            "         1.9533e+00,  1.1155e+00, -2.0802e+00,  1.6972e+00,  3.3948e+00,\n",
            "        -5.4509e+00,  4.1389e+00, -1.0832e-01, -2.1072e+00,  8.3713e+00,\n",
            "        -3.2289e+00, -2.6613e+00,  6.1981e-01,  1.5158e+00,  2.0731e-01,\n",
            "        -6.3722e+00,  1.5697e+00,  2.9776e-01,  1.0416e-01,  3.5789e+00,\n",
            "        -3.8337e+00,  1.7145e+00, -2.6544e+00,  3.6158e+00, -1.1233e+00,\n",
            "         3.8458e+00, -2.4790e+00,  8.3770e-01,  2.6871e-01,  6.4152e+00,\n",
            "        -1.1694e+00, -1.6082e+00,  6.5667e-01, -3.5702e+00,  5.3543e+00,\n",
            "         3.2547e+00, -2.0863e-01, -1.4526e+00, -4.7796e+00, -1.4335e+00,\n",
            "         2.4854e+00, -1.1846e+00, -1.1651e+00,  9.8810e-01,  2.0696e+00,\n",
            "         6.2194e-01,  2.2414e-02,  4.4735e-03, -8.6354e+00, -2.9678e+00,\n",
            "         4.4657e+00,  2.4592e+00, -7.1463e+00, -6.6116e+00, -2.1592e+00,\n",
            "         6.2861e+00,  1.3098e+00, -3.4833e+00,  9.5370e+00,  4.0103e+00,\n",
            "         1.7087e+00,  2.8566e+00,  1.4308e+00, -2.2001e+00,  2.5590e+00,\n",
            "        -9.2410e-01,  1.5334e-01, -1.3391e+00,  4.3596e+00,  4.9539e+00,\n",
            "        -1.6354e+00, -1.5295e+00, -4.1751e+00, -1.7413e+00,  3.7031e+00,\n",
            "         3.9675e-01, -4.0544e+00,  6.3005e+00, -3.2124e+00, -8.6019e-01,\n",
            "         2.1526e+00,  7.4161e+00, -2.8453e-01,  1.7843e+00,  5.9328e-01,\n",
            "        -2.5698e+00, -6.5901e+00, -3.8882e+00,  2.7079e+00,  2.9391e+00,\n",
            "         5.1849e+00, -4.2233e+00, -5.6269e+00,  1.3027e+00, -5.9706e-01,\n",
            "         9.0640e-02, -2.9782e+00, -8.4297e-01, -3.7246e+00,  1.3629e+00,\n",
            "        -4.2665e+00, -2.3305e+00,  2.4304e-01,  2.6362e+00,  2.5431e+00,\n",
            "         7.3145e+00,  3.7019e+00,  4.4035e+00,  1.6894e+00, -4.4450e+00,\n",
            "         1.9947e+00])), ('module.encoder_q.layer3.5.bn1.running_var', tensor([14.4957, 13.5000, 34.1866, 22.8832, 16.2481, 16.7895, 14.1732, 19.1572,\n",
            "        29.1712, 23.6412, 21.4932, 20.7637, 16.2729, 40.6249, 14.8618, 19.0520,\n",
            "        20.3162, 14.0738, 14.1088, 12.7044, 12.9667, 15.2233, 23.2357, 14.7972,\n",
            "        13.5362, 14.3952, 14.9218, 24.2407, 14.1726, 14.8736, 15.7795, 13.0018,\n",
            "        15.1056, 12.8328, 22.7263, 18.5633, 21.3035, 32.9526, 23.8703, 26.0943,\n",
            "        11.2507, 14.6435, 15.1272, 13.7500, 15.2645, 12.9183, 46.3833, 17.0619,\n",
            "        16.2148, 17.6533, 13.9865, 29.2955, 17.1374, 75.0642, 17.5191, 14.3247,\n",
            "        34.2454, 13.1124, 17.1088, 14.8469, 29.3520, 11.2900, 11.4323, 15.2938,\n",
            "        13.3983, 11.7210, 47.2584, 25.9352, 34.1207, 15.4787, 17.2887, 13.3990,\n",
            "        21.5551, 16.8492, 14.8790, 19.3842, 40.5681, 12.7075, 19.4415, 14.5669,\n",
            "        14.3705, 13.2121, 11.9330, 14.8781, 30.0349, 14.8534, 19.0714, 21.6205,\n",
            "        18.9867, 16.2201, 11.8567, 13.6039, 18.5127, 17.0390, 21.6245, 13.8580,\n",
            "        12.4844, 28.5109, 21.8155, 21.7390, 14.7686, 13.8494, 18.3693, 28.7425,\n",
            "        15.7093, 15.2093, 18.0103, 19.6740, 14.9408, 15.8858, 13.2895, 16.2967,\n",
            "        15.2363, 18.3406, 16.1092, 28.0781, 20.3213, 41.5998, 50.0197, 19.5984,\n",
            "        28.2612, 15.5100, 20.3960, 46.2195, 13.4724, 35.7542, 17.2618, 15.5353,\n",
            "        39.7240, 11.2873, 21.5215, 25.7357, 23.8307, 16.3216, 16.1214, 40.6348,\n",
            "        19.9525, 21.3346, 13.9520, 14.0126, 11.9849, 59.7297, 31.6943, 46.2695,\n",
            "        23.4449, 16.8931, 18.2315, 15.1807, 19.9417, 13.5971, 16.3573, 29.3479,\n",
            "        14.7993, 24.9933, 27.9754, 17.9660, 17.6162, 13.4599, 14.0656, 13.0850,\n",
            "        27.8555, 18.3468, 12.9913, 13.3700, 16.9925, 20.2822, 22.0064, 22.7393,\n",
            "        27.7593, 13.3797, 39.1215, 15.4240, 18.8584, 21.1634, 18.8977, 15.1061,\n",
            "        13.2225, 16.6761, 54.2459, 23.8652, 11.7492, 21.6450, 14.5000, 30.5527,\n",
            "        25.0577, 20.5625, 15.7279, 18.6281, 13.5387, 15.2514, 20.4383, 14.6813,\n",
            "        18.7437, 57.5575, 13.6741, 22.6982, 12.7964, 64.3025, 43.8126, 17.6380,\n",
            "        50.5282, 16.1425, 15.1348, 57.9629, 17.3929, 15.1599, 27.6614, 18.3912,\n",
            "        18.5508, 19.0775, 12.2422, 14.2706, 13.3566, 17.1010, 46.9001, 17.0252,\n",
            "        13.3702, 33.6955, 16.8679, 32.1218, 15.2912, 13.6555, 84.2897, 14.5699,\n",
            "        14.4184, 24.6377, 46.6007, 12.6311, 14.9402, 11.9402, 18.0844, 43.9859,\n",
            "        14.2022, 21.6034, 18.5705, 37.0449, 14.0619, 33.3947, 16.0937, 14.5650,\n",
            "        13.3879, 32.2547, 12.3753, 16.0417, 13.8797, 25.7368, 16.9030, 16.2603,\n",
            "        35.7750, 16.5666, 58.3254, 19.1221, 25.1884, 11.9353, 32.9194, 12.7878])), ('module.encoder_q.layer3.5.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.5.conv2.weight', tensor([[[[-0.0280,  0.0345,  0.0212],\n",
            "          [ 0.0253, -0.0063,  0.0260],\n",
            "          [ 0.0247,  0.0023, -0.0250]],\n",
            "\n",
            "         [[-0.0503, -0.0319, -0.0134],\n",
            "          [-0.0471,  0.0125,  0.0411],\n",
            "          [ 0.0040, -0.0214, -0.0288]],\n",
            "\n",
            "         [[ 0.0074, -0.0027, -0.0114],\n",
            "          [-0.0196,  0.0479, -0.0249],\n",
            "          [-0.0068,  0.0130, -0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0590,  0.0366,  0.0092],\n",
            "          [-0.0063,  0.0375,  0.0729],\n",
            "          [-0.0041, -0.0239, -0.0008]],\n",
            "\n",
            "         [[ 0.0383, -0.0174,  0.0113],\n",
            "          [ 0.0493,  0.0194,  0.0052],\n",
            "          [-0.0509,  0.0156, -0.0078]],\n",
            "\n",
            "         [[-0.0264,  0.0037,  0.0231],\n",
            "          [ 0.0268, -0.0384, -0.0137],\n",
            "          [-0.0277,  0.0216,  0.0222]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0335, -0.0018,  0.0172],\n",
            "          [ 0.0630, -0.0330,  0.0171],\n",
            "          [-0.0149,  0.0122,  0.0300]],\n",
            "\n",
            "         [[ 0.0220, -0.0034, -0.0111],\n",
            "          [ 0.0106, -0.0219,  0.0516],\n",
            "          [ 0.0408, -0.0341,  0.0275]],\n",
            "\n",
            "         [[-0.0302,  0.0075,  0.0087],\n",
            "          [ 0.0115, -0.0415,  0.0195],\n",
            "          [ 0.0287, -0.0634, -0.0212]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0164, -0.0595,  0.0291],\n",
            "          [ 0.0043, -0.0678, -0.0161],\n",
            "          [ 0.0163,  0.0327,  0.0223]],\n",
            "\n",
            "         [[ 0.0134,  0.0155,  0.0234],\n",
            "          [ 0.0052, -0.0032, -0.0074],\n",
            "          [ 0.0271, -0.0186, -0.0396]],\n",
            "\n",
            "         [[ 0.0463,  0.0198, -0.0002],\n",
            "          [ 0.0130, -0.0167,  0.0547],\n",
            "          [ 0.0300,  0.0016, -0.0272]]],\n",
            "\n",
            "\n",
            "        [[[-0.0018, -0.0238,  0.0207],\n",
            "          [-0.0188,  0.0110,  0.0268],\n",
            "          [-0.0302,  0.0135,  0.0068]],\n",
            "\n",
            "         [[-0.0299,  0.0310, -0.0106],\n",
            "          [-0.0224,  0.0156,  0.0544],\n",
            "          [ 0.0502,  0.0146,  0.0013]],\n",
            "\n",
            "         [[ 0.0096, -0.0252,  0.0053],\n",
            "          [-0.0234, -0.0279, -0.0552],\n",
            "          [-0.0012, -0.0564,  0.0165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0579, -0.0067, -0.0199],\n",
            "          [ 0.0372, -0.0207,  0.0122],\n",
            "          [ 0.0502, -0.0098, -0.0238]],\n",
            "\n",
            "         [[ 0.0429,  0.0131,  0.0399],\n",
            "          [-0.0505,  0.0501, -0.0174],\n",
            "          [ 0.0016,  0.0007,  0.0004]],\n",
            "\n",
            "         [[-0.0107,  0.0105,  0.0254],\n",
            "          [ 0.0238, -0.0059, -0.0238],\n",
            "          [-0.0073, -0.0345,  0.0346]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0513, -0.0387,  0.0338],\n",
            "          [-0.0277, -0.0268,  0.0126],\n",
            "          [-0.0188,  0.0021,  0.0375]],\n",
            "\n",
            "         [[-0.0141,  0.0568,  0.0025],\n",
            "          [ 0.0398,  0.0525,  0.0172],\n",
            "          [-0.0054,  0.0263,  0.0003]],\n",
            "\n",
            "         [[-0.0145, -0.0622,  0.0151],\n",
            "          [-0.0008,  0.0199,  0.0120],\n",
            "          [-0.0571, -0.0157, -0.0210]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0338, -0.0441, -0.0217],\n",
            "          [ 0.0089,  0.0395, -0.0600],\n",
            "          [ 0.0138,  0.0028, -0.0240]],\n",
            "\n",
            "         [[-0.0369,  0.0194, -0.0567],\n",
            "          [ 0.0256,  0.0443,  0.0069],\n",
            "          [ 0.0257,  0.0235, -0.0343]],\n",
            "\n",
            "         [[-0.0011,  0.0261,  0.0457],\n",
            "          [-0.0415,  0.0035,  0.0229],\n",
            "          [ 0.0044,  0.0325,  0.0410]]],\n",
            "\n",
            "\n",
            "        [[[-0.0040, -0.0606,  0.0146],\n",
            "          [ 0.0180,  0.0380,  0.0153],\n",
            "          [-0.0519, -0.0312, -0.0218]],\n",
            "\n",
            "         [[ 0.0086, -0.0103,  0.0096],\n",
            "          [-0.0452, -0.0029,  0.0071],\n",
            "          [-0.0058, -0.0365,  0.0160]],\n",
            "\n",
            "         [[ 0.0226,  0.0074,  0.0417],\n",
            "          [ 0.0008,  0.0264, -0.0136],\n",
            "          [-0.0082, -0.0578, -0.0076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0358, -0.0006, -0.0109],\n",
            "          [-0.0319, -0.0215, -0.0280],\n",
            "          [-0.0258,  0.0463,  0.0072]],\n",
            "\n",
            "         [[ 0.0369, -0.0298,  0.0224],\n",
            "          [-0.0284, -0.0089, -0.0253],\n",
            "          [ 0.0181, -0.0059,  0.0129]],\n",
            "\n",
            "         [[-0.0300, -0.0227,  0.0066],\n",
            "          [-0.0278, -0.0257, -0.0213],\n",
            "          [-0.0009, -0.0138, -0.0178]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0164,  0.0237,  0.0232],\n",
            "          [ 0.0293,  0.0170,  0.0378],\n",
            "          [-0.0112,  0.0500,  0.0020]],\n",
            "\n",
            "         [[ 0.0024, -0.0023,  0.0296],\n",
            "          [ 0.0069,  0.0662, -0.0328],\n",
            "          [-0.0232,  0.0010, -0.0110]],\n",
            "\n",
            "         [[-0.0313,  0.0277,  0.0002],\n",
            "          [ 0.0507, -0.0143,  0.0091],\n",
            "          [ 0.0002, -0.0291, -0.0332]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0171, -0.0002,  0.0187],\n",
            "          [ 0.0093, -0.0209, -0.0231],\n",
            "          [-0.0032,  0.0262,  0.0166]],\n",
            "\n",
            "         [[-0.0074, -0.0409, -0.0014],\n",
            "          [ 0.0417, -0.0186,  0.0401],\n",
            "          [-0.0005, -0.0336, -0.0163]],\n",
            "\n",
            "         [[-0.0514, -0.0147, -0.0121],\n",
            "          [-0.0829, -0.0292, -0.0294],\n",
            "          [ 0.0238,  0.0029,  0.0341]]]])), ('module.encoder_q.layer3.5.bn2.weight', tensor([0.9922, 0.9919, 0.9923, 0.9922, 0.9917, 0.9920, 0.9928, 0.9919, 0.9921,\n",
            "        0.9922, 0.9916, 0.9924, 0.9925, 0.9921, 0.9924, 0.9917, 0.9926, 0.9924,\n",
            "        0.9920, 0.9922, 0.9920, 0.9919, 0.9921, 0.9928, 0.9923, 0.9935, 0.9923,\n",
            "        0.9921, 0.9920, 0.9923, 0.9923, 0.9925, 0.9923, 0.9926, 0.9918, 0.9921,\n",
            "        0.9925, 0.9919, 0.9921, 0.9928, 0.9929, 0.9924, 0.9919, 0.9924, 0.9925,\n",
            "        0.9920, 0.9925, 0.9920, 0.9921, 0.9926, 0.9929, 0.9921, 0.9919, 0.9925,\n",
            "        0.9922, 0.9916, 0.9922, 0.9918, 0.9925, 0.9923, 0.9919, 0.9922, 0.9931,\n",
            "        0.9922, 0.9920, 0.9922, 0.9920, 0.9921, 0.9922, 0.9927, 0.9923, 0.9921,\n",
            "        0.9919, 0.9925, 0.9925, 0.9921, 0.9927, 0.9924, 0.9923, 0.9917, 0.9927,\n",
            "        0.9922, 0.9923, 0.9922, 0.9926, 0.9926, 0.9924, 0.9919, 0.9923, 0.9921,\n",
            "        0.9924, 0.9919, 0.9920, 0.9918, 0.9924, 0.9924, 0.9924, 0.9922, 0.9921,\n",
            "        0.9926, 0.9919, 0.9920, 0.9926, 0.9923, 0.9920, 0.9920, 0.9918, 0.9918,\n",
            "        0.9923, 0.9919, 0.9922, 0.9918, 0.9925, 0.9920, 0.9922, 0.9918, 0.9923,\n",
            "        0.9927, 0.9919, 0.9921, 0.9921, 0.9917, 0.9919, 0.9917, 0.9927, 0.9923,\n",
            "        0.9922, 0.9924, 0.9917, 0.9917, 0.9925, 0.9917, 0.9920, 0.9923, 0.9918,\n",
            "        0.9926, 0.9925, 0.9924, 0.9919, 0.9921, 0.9920, 0.9925, 0.9921, 0.9916,\n",
            "        0.9918, 0.9926, 0.9924, 0.9923, 0.9924, 0.9923, 0.9926, 0.9922, 0.9921,\n",
            "        0.9922, 0.9922, 0.9926, 0.9922, 0.9923, 0.9922, 0.9922, 0.9917, 0.9925,\n",
            "        0.9923, 0.9924, 0.9921, 0.9917, 0.9921, 0.9921, 0.9923, 0.9919, 0.9929,\n",
            "        0.9926, 0.9925, 0.9924, 0.9927, 0.9930, 0.9923, 0.9925, 0.9923, 0.9921,\n",
            "        0.9924, 0.9924, 0.9922, 0.9928, 0.9916, 0.9919, 0.9928, 0.9925, 0.9917,\n",
            "        0.9920, 0.9926, 0.9911, 0.9922, 0.9924, 0.9923, 0.9925, 0.9923, 0.9923,\n",
            "        0.9924, 0.9927, 0.9941, 0.9928, 0.9926, 0.9918, 0.9926, 0.9919, 0.9923,\n",
            "        0.9921, 0.9917, 0.9926, 0.9929, 0.9927, 0.9919, 0.9922, 0.9928, 0.9919,\n",
            "        0.9915, 0.9924, 0.9933, 0.9922, 0.9924, 0.9921, 0.9927, 0.9925, 0.9924,\n",
            "        0.9925, 0.9924, 0.9924, 0.9928, 0.9925, 0.9921, 0.9921, 0.9917, 0.9929,\n",
            "        0.9926, 0.9926, 0.9922, 0.9921, 0.9924, 0.9922, 0.9927, 0.9925, 0.9921,\n",
            "        0.9921, 0.9918, 0.9924, 0.9922, 0.9924, 0.9927, 0.9923, 0.9924, 0.9919,\n",
            "        0.9919, 0.9919, 0.9918, 0.9922])), ('module.encoder_q.layer3.5.bn2.bias', tensor([-6.8330e-05, -2.2734e-04, -6.4233e-04,  3.3039e-04, -7.2694e-04,\n",
            "         1.0210e-04,  1.0685e-04, -7.1708e-05, -8.9489e-05,  4.4100e-05,\n",
            "        -7.2158e-04,  4.6729e-04,  5.0073e-04,  1.1533e-05,  3.5273e-04,\n",
            "        -1.7145e-04,  1.9011e-04,  3.3246e-04, -3.4173e-04,  7.8178e-05,\n",
            "         3.2820e-04, -3.0438e-04,  4.8165e-07,  7.9140e-04,  2.1472e-04,\n",
            "         9.4955e-04, -1.3906e-05, -9.1099e-05, -5.9129e-04, -3.2246e-06,\n",
            "        -6.1366e-05,  1.8003e-04,  3.6499e-04,  1.1013e-04, -3.2340e-04,\n",
            "         2.0407e-04,  3.0035e-04, -9.1779e-04, -5.7828e-04,  1.9770e-04,\n",
            "         2.7799e-04,  8.8677e-04, -2.0647e-04, -1.4254e-04, -3.4718e-04,\n",
            "        -7.9056e-04,  2.2963e-04, -7.0744e-05, -1.2758e-04,  1.4933e-04,\n",
            "         1.0876e-03, -3.8590e-04, -1.4515e-04, -1.5300e-04, -2.8243e-04,\n",
            "        -5.3605e-04,  2.6904e-05, -8.6493e-05,  1.2778e-04,  1.1499e-04,\n",
            "        -2.7202e-04,  4.1076e-05,  1.8317e-04,  8.5521e-06, -1.0879e-04,\n",
            "         1.4964e-04,  4.5579e-05, -2.6453e-04, -2.2628e-04,  8.8238e-04,\n",
            "        -7.8903e-05,  1.7578e-04, -6.6122e-04,  1.4880e-04,  4.7517e-04,\n",
            "         1.7184e-04,  7.8842e-04,  1.4938e-04, -1.5151e-04, -5.2752e-04,\n",
            "         3.5502e-04,  1.7197e-04,  5.0614e-05, -1.8097e-04,  3.4517e-04,\n",
            "         1.4422e-04,  1.8821e-04, -6.9561e-04,  2.0467e-04, -5.1429e-04,\n",
            "        -2.0923e-05,  2.2298e-05, -1.8657e-04, -1.2155e-04,  2.6618e-05,\n",
            "         8.2200e-05, -4.2481e-05,  6.4015e-05, -2.2203e-04,  1.3054e-04,\n",
            "        -5.0696e-04, -7.6911e-04, -2.9646e-04, -3.4187e-04, -6.2751e-04,\n",
            "        -3.9859e-04, -2.6572e-04,  3.4187e-05,  9.5944e-06,  1.5129e-04,\n",
            "         1.3833e-04, -5.6602e-04,  3.3396e-04, -2.5800e-04,  2.5711e-04,\n",
            "        -2.6141e-04,  1.9402e-04,  1.9431e-04,  2.1763e-04, -2.1617e-04,\n",
            "        -3.9071e-04, -2.5386e-04, -4.4126e-05, -6.2671e-04,  3.5162e-04,\n",
            "         9.5275e-05,  3.3344e-06, -1.1125e-04, -1.7943e-04, -5.4501e-04,\n",
            "        -4.3174e-04, -7.9187e-04,  1.3301e-04,  5.0838e-04, -9.9588e-05,\n",
            "         1.7928e-05,  3.6668e-04,  6.9362e-04,  2.4023e-04, -8.0275e-05,\n",
            "        -6.2409e-05,  3.1774e-04,  1.9677e-05, -1.0810e-03, -4.1044e-04,\n",
            "         1.0241e-03,  2.5461e-04,  9.8863e-05,  1.9082e-06,  2.3993e-04,\n",
            "        -1.4720e-04, -9.7363e-05, -1.3097e-04, -1.6000e-04,  8.9252e-05,\n",
            "         1.9813e-04,  1.5637e-04, -3.3145e-04,  1.1747e-05,  4.3838e-04,\n",
            "        -9.3669e-05, -1.8699e-04, -1.7673e-04,  3.6511e-04, -8.2788e-05,\n",
            "        -4.0328e-04,  2.1768e-04, -1.3919e-04, -1.2675e-04, -5.0072e-04,\n",
            "         4.5822e-04,  2.1336e-04, -1.3272e-04,  1.1587e-04,  2.6852e-04,\n",
            "         5.0657e-04, -7.0163e-05,  5.4079e-05, -7.3082e-05, -1.5053e-04,\n",
            "         4.3250e-05,  1.5132e-04, -8.7937e-07,  3.9868e-04, -3.6445e-04,\n",
            "         5.7669e-05,  7.5440e-05,  4.9745e-05, -5.9937e-04, -1.7150e-05,\n",
            "        -1.3353e-04, -8.7249e-04, -2.1520e-05,  2.6641e-04, -2.2061e-04,\n",
            "         3.4414e-04, -2.1641e-04,  1.5399e-04,  1.1589e-04,  2.5989e-04,\n",
            "         1.2195e-03, -1.2299e-04,  1.9998e-04, -1.2695e-04,  4.1413e-04,\n",
            "        -2.3686e-04, -1.1391e-04, -9.9415e-05, -5.0654e-04,  3.8220e-04,\n",
            "         8.8689e-04,  6.7775e-04, -2.6017e-04, -1.5627e-04,  9.5173e-04,\n",
            "        -1.3704e-05, -3.3855e-04,  2.7108e-04,  9.9028e-04,  1.2435e-06,\n",
            "         2.9513e-04, -1.0092e-05,  1.0431e-04,  3.1082e-04,  1.8277e-04,\n",
            "         1.0152e-04, -4.5753e-05, -4.3508e-04,  1.5695e-04,  2.5627e-04,\n",
            "        -9.0788e-05,  1.8653e-04, -6.2204e-04,  3.1802e-04, -1.1305e-04,\n",
            "         9.9974e-05, -2.4817e-04, -2.5594e-04, -7.4634e-05, -1.8470e-04,\n",
            "         2.1038e-04,  1.1721e-04, -1.5464e-04, -4.1640e-05,  2.8126e-05,\n",
            "         4.1734e-04,  1.5274e-04, -1.4003e-04,  2.8052e-04,  1.1105e-04,\n",
            "        -1.5508e-04, -2.5265e-04,  2.0781e-06, -5.5449e-04, -1.0527e-04,\n",
            "        -6.7827e-05])), ('module.encoder_q.layer3.5.bn2.running_mean', tensor([ 0.1331,  0.2151, -0.0085, -0.0283,  0.2384, -0.2353, -0.0200, -0.1356,\n",
            "        -0.7337, -0.6938,  0.3118, -0.1268, -0.1816, -0.2540, -0.9365,  0.0489,\n",
            "         0.1041, -0.1325,  0.7806, -0.0899, -0.3945, -0.1765, -0.1159,  0.1809,\n",
            "         0.3132,  0.3443, -0.0620,  0.5607,  0.1783, -0.8868, -0.2924,  0.2734,\n",
            "        -0.1335,  1.1248,  0.2984,  0.0551,  0.2772, -0.1552, -0.3252, -0.3949,\n",
            "         0.4318,  0.1301, -0.5791,  0.1652, -0.1777, -0.2580, -0.2313,  0.5826,\n",
            "         0.5107,  0.4096, -0.0431,  0.2272, -0.2416,  0.4786, -0.7445,  0.4559,\n",
            "        -0.3671,  0.5095, -0.2819, -0.3483,  0.4411,  0.0841,  0.2999,  1.2125,\n",
            "        -0.0563, -0.2763, -0.4839, -1.0457,  0.0070, -0.8596,  0.1022, -0.1080,\n",
            "        -0.2195, -0.3740, -0.0990, -0.1893, -0.1459, -0.6448, -0.0567, -0.5267,\n",
            "         0.2159,  0.1668,  0.0529, -0.4254,  0.3349, -0.1881, -0.3008, -0.4103,\n",
            "         0.6727,  0.2365, -0.6351,  0.1321, -0.3357, -0.7180,  0.6217, -0.6572,\n",
            "        -0.1257, -1.5049, -0.8597,  0.0167,  0.0806, -0.1380, -0.5425,  0.5230,\n",
            "        -0.0231, -0.4270,  0.4794,  0.0568, -0.6258, -0.3290, -0.3864,  0.2620,\n",
            "         0.0489, -0.0210,  0.0775,  0.2852, -0.8571,  0.1409, -0.1601, -0.3816,\n",
            "        -0.2853,  0.0456,  0.0362, -0.1147,  0.0688, -0.7195, -0.1686, -0.1984,\n",
            "         0.2336, -0.3935,  0.0808,  0.1857, -0.3684,  0.5183, -0.3859, -0.0743,\n",
            "        -0.1919, -0.4395,  0.5245,  0.2007, -0.3125,  0.5020, -0.1089, -0.2575,\n",
            "         0.3542, -0.1054,  0.0953,  0.0707,  0.9630, -0.5133,  0.0650,  0.0264,\n",
            "         0.4234,  0.0588,  0.4939, -0.3566,  0.1450,  0.0309,  0.1862, -0.2993,\n",
            "         0.6940,  1.7695,  0.7341,  0.0381, -0.4599,  0.3594,  0.0175,  0.6674,\n",
            "         0.0468,  0.0533,  0.1869,  0.3282, -0.4938, -0.8937, -0.0557,  0.8415,\n",
            "        -0.5976,  0.2922,  0.2661, -0.5362,  0.6964,  0.5392,  0.0419,  0.7491,\n",
            "         0.2726,  0.1478,  0.2798, -0.0583, -0.1892,  0.7515,  0.8106,  0.3481,\n",
            "         0.5425,  0.2094, -0.0312, -0.0564,  0.2261, -1.0603,  0.3638,  0.3070,\n",
            "         0.3235,  0.2513,  0.3960,  0.4537, -0.1176, -0.1690,  0.8446, -0.4726,\n",
            "         0.1187,  0.8344, -0.1079, -0.5787, -0.4926, -0.8337,  0.3228,  0.0670,\n",
            "         0.6339,  0.1143,  0.2131, -0.5366, -0.4566, -0.4508, -0.0824,  1.1002,\n",
            "        -0.4430, -0.3545, -0.3583,  1.2293, -0.0082, -0.4870, -0.2125, -0.4566,\n",
            "         0.6364,  0.8291, -0.1042, -0.0657, -0.4779,  0.1620, -0.2272,  0.3667,\n",
            "         0.2229,  0.0521, -0.6083, -0.2920,  0.5810,  0.0084,  0.1183,  0.8024,\n",
            "        -0.3324,  0.4183,  0.3827,  0.2849, -0.8089,  0.3966, -0.7569,  0.0238])), ('module.encoder_q.layer3.5.bn2.running_var', tensor([0.5444, 0.5210, 0.5979, 0.6378, 0.5736, 1.0963, 0.5511, 0.5764, 0.6756,\n",
            "        1.0722, 0.8663, 0.6238, 0.6721, 0.6817, 1.2175, 0.5969, 0.7578, 0.6848,\n",
            "        0.7021, 0.6873, 0.6229, 0.6130, 0.7645, 0.9202, 1.2071, 0.6965, 0.6260,\n",
            "        0.9639, 0.6303, 0.6918, 0.5980, 1.0735, 0.5189, 1.4665, 1.0772, 0.5808,\n",
            "        0.5983, 0.6696, 0.6171, 0.8201, 0.6568, 0.7338, 1.5949, 0.5047, 0.5786,\n",
            "        0.5827, 0.5315, 0.9897, 1.1174, 0.7468, 0.6223, 0.7466, 1.5296, 0.8477,\n",
            "        0.6114, 0.7097, 0.5394, 0.8010, 0.5561, 0.7407, 0.5291, 1.1176, 0.6476,\n",
            "        1.7330, 0.6506, 1.4341, 0.9069, 1.1922, 1.0272, 0.7844, 0.5623, 0.5389,\n",
            "        0.5838, 0.7429, 0.5524, 0.5353, 0.7104, 1.1155, 0.5138, 0.7381, 0.5848,\n",
            "        0.5987, 0.5685, 0.6993, 1.0559, 0.6623, 0.5739, 0.5886, 1.1114, 0.5481,\n",
            "        1.3144, 0.5089, 0.5335, 0.7937, 0.7565, 0.8287, 0.5244, 1.1183, 1.3023,\n",
            "        0.6744, 0.5792, 0.9399, 0.6418, 1.9743, 0.6885, 0.5612, 0.7432, 0.5541,\n",
            "        1.4121, 0.5900, 0.6177, 0.6988, 0.8633, 0.5391, 0.6055, 0.5829, 0.8798,\n",
            "        0.5531, 0.6074, 0.6448, 0.5724, 0.4794, 0.5659, 0.7265, 0.6890, 1.1905,\n",
            "        0.7441, 0.6183, 0.9305, 0.7743, 0.6118, 0.8225, 0.5251, 0.8445, 0.7022,\n",
            "        0.5795, 0.5714, 2.0178, 0.9309, 0.6914, 0.5149, 0.6886, 0.5633, 0.5118,\n",
            "        0.6780, 0.6947, 0.4846, 0.5076, 0.7723, 0.5155, 0.6600, 0.9673, 0.5838,\n",
            "        0.5561, 0.5962, 1.2314, 0.6958, 0.5914, 0.5164, 0.5452, 0.6290, 3.3556,\n",
            "        0.6218, 0.7377, 0.5797, 0.8124, 0.6570, 1.0203, 0.6514, 0.5571, 0.6303,\n",
            "        0.6047, 0.6085, 1.4805, 0.8766, 0.8028, 0.6705, 0.5901, 0.8789, 0.8844,\n",
            "        0.9747, 1.3464, 0.4737, 1.1395, 0.5495, 0.7020, 0.7812, 0.5885, 0.7582,\n",
            "        0.7405, 0.8583, 1.0980, 0.6506, 0.5400, 0.5796, 0.5434, 0.6381, 2.2524,\n",
            "        0.6756, 0.5636, 0.6406, 1.0455, 0.6367, 1.0032, 0.6057, 0.5940, 0.6381,\n",
            "        1.0939, 1.1139, 0.4995, 0.9031, 0.8347, 0.5609, 1.0975, 0.8985, 0.5746,\n",
            "        0.8105, 0.5561, 0.7376, 0.5431, 1.0182, 0.8607, 0.7210, 1.3145, 0.4966,\n",
            "        0.6331, 0.6904, 2.1218, 0.5654, 1.2455, 0.5961, 0.7638, 0.9524, 1.1304,\n",
            "        0.5520, 0.6730, 0.5400, 0.5421, 0.4738, 0.5405, 0.6709, 1.5542, 1.4031,\n",
            "        0.7627, 1.4585, 1.0988, 0.7531, 0.8225, 0.6615, 0.7052, 0.9207, 0.8626,\n",
            "        1.0686, 0.6632, 1.1427, 0.5900])), ('module.encoder_q.layer3.5.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer3.5.conv3.weight', tensor([[[[-0.0222]],\n",
            "\n",
            "         [[-0.0443]],\n",
            "\n",
            "         [[-0.0661]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0220]],\n",
            "\n",
            "         [[-0.0431]],\n",
            "\n",
            "         [[-0.0261]]],\n",
            "\n",
            "\n",
            "        [[[-0.0610]],\n",
            "\n",
            "         [[-0.0255]],\n",
            "\n",
            "         [[-0.0612]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         [[ 0.0242]],\n",
            "\n",
            "         [[-0.0579]]],\n",
            "\n",
            "\n",
            "        [[[-0.0494]],\n",
            "\n",
            "         [[ 0.0081]],\n",
            "\n",
            "         [[ 0.0106]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0712]],\n",
            "\n",
            "         [[ 0.0802]],\n",
            "\n",
            "         [[-0.0905]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0250]],\n",
            "\n",
            "         [[-0.1055]],\n",
            "\n",
            "         [[-0.0855]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0223]],\n",
            "\n",
            "         [[-0.0076]],\n",
            "\n",
            "         [[-0.0264]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0748]],\n",
            "\n",
            "         [[ 0.0488]],\n",
            "\n",
            "         [[ 0.0059]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0525]],\n",
            "\n",
            "         [[-0.0066]],\n",
            "\n",
            "         [[ 0.0273]]],\n",
            "\n",
            "\n",
            "        [[[-0.0892]],\n",
            "\n",
            "         [[-0.0857]],\n",
            "\n",
            "         [[-0.0396]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0115]],\n",
            "\n",
            "         [[-0.0126]],\n",
            "\n",
            "         [[-0.0105]]]])), ('module.encoder_q.layer3.5.bn3.weight', tensor([0.9922, 0.9923, 0.9921,  ..., 0.9921, 0.9922, 0.9924])), ('module.encoder_q.layer3.5.bn3.bias', tensor([-3.9356e-05,  1.3236e-04, -1.8175e-06,  ..., -1.6932e-05,\n",
            "        -1.4264e-04, -5.4893e-05])), ('module.encoder_q.layer3.5.bn3.running_mean', tensor([-0.2493, -0.0227, -0.2426,  ...,  0.1229,  0.0031,  0.1587])), ('module.encoder_q.layer3.5.bn3.running_var', tensor([0.1206, 0.1777, 0.2133,  ..., 0.1422, 0.1535, 0.2185])), ('module.encoder_q.layer3.5.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.0.conv1.weight', tensor([[[[-0.0637]],\n",
            "\n",
            "         [[ 0.0524]],\n",
            "\n",
            "         [[ 0.0300]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0360]],\n",
            "\n",
            "         [[-0.0649]],\n",
            "\n",
            "         [[-0.0354]]],\n",
            "\n",
            "\n",
            "        [[[-0.0590]],\n",
            "\n",
            "         [[-0.0350]],\n",
            "\n",
            "         [[-0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0757]],\n",
            "\n",
            "         [[ 0.1031]],\n",
            "\n",
            "         [[ 0.0894]]],\n",
            "\n",
            "\n",
            "        [[[-0.0438]],\n",
            "\n",
            "         [[-0.0046]],\n",
            "\n",
            "         [[-0.0304]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0112]],\n",
            "\n",
            "         [[-0.0504]],\n",
            "\n",
            "         [[ 0.0452]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0031]],\n",
            "\n",
            "         [[-0.0761]],\n",
            "\n",
            "         [[-0.0231]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0731]],\n",
            "\n",
            "         [[ 0.0720]],\n",
            "\n",
            "         [[-0.1237]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1008]],\n",
            "\n",
            "         [[-0.0823]],\n",
            "\n",
            "         [[-0.0236]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0031]],\n",
            "\n",
            "         [[-0.0194]],\n",
            "\n",
            "         [[-0.1551]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0084]],\n",
            "\n",
            "         [[-0.0547]],\n",
            "\n",
            "         [[-0.0520]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0153]],\n",
            "\n",
            "         [[ 0.0122]],\n",
            "\n",
            "         [[-0.1013]]]])), ('module.encoder_q.layer4.0.bn1.weight', tensor([0.9925, 0.9916, 0.9919, 0.9925, 0.9917, 0.9926, 0.9922, 0.9930, 0.9916,\n",
            "        0.9921, 0.9920, 0.9920, 0.9916, 0.9928, 0.9922, 0.9929, 0.9920, 0.9919,\n",
            "        0.9925, 0.9922, 0.9921, 0.9920, 0.9918, 0.9918, 0.9923, 0.9925, 0.9918,\n",
            "        0.9920, 0.9921, 0.9921, 0.9921, 0.9924, 0.9918, 0.9921, 0.9918, 0.9919,\n",
            "        0.9920, 0.9922, 0.9921, 0.9920, 0.9920, 0.9922, 0.9925, 0.9924, 0.9923,\n",
            "        0.9924, 0.9920, 0.9920, 0.9923, 0.9923, 0.9919, 0.9919, 0.9921, 0.9919,\n",
            "        0.9924, 0.9923, 0.9918, 0.9924, 0.9923, 0.9920, 0.9926, 0.9924, 0.9926,\n",
            "        0.9924, 0.9924, 0.9922, 0.9923, 0.9921, 0.9924, 0.9920, 0.9923, 0.9923,\n",
            "        0.9925, 0.9922, 0.9924, 0.9925, 0.9927, 0.9921, 0.9925, 0.9920, 0.9919,\n",
            "        0.9926, 0.9921, 0.9922, 0.9922, 0.9927, 0.9924, 0.9923, 0.9923, 0.9923,\n",
            "        0.9922, 0.9926, 0.9919, 0.9922, 0.9925, 0.9921, 0.9923, 0.9925, 0.9921,\n",
            "        0.9924, 0.9922, 0.9925, 0.9922, 0.9922, 0.9922, 0.9930, 0.9923, 0.9921,\n",
            "        0.9920, 0.9918, 0.9919, 0.9925, 0.9918, 0.9922, 0.9919, 0.9928, 0.9924,\n",
            "        0.9924, 0.9930, 0.9921, 0.9922, 0.9923, 0.9921, 0.9924, 0.9924, 0.9925,\n",
            "        0.9920, 0.9923, 0.9928, 0.9925, 0.9926, 0.9927, 0.9922, 0.9925, 0.9922,\n",
            "        0.9928, 0.9925, 0.9920, 0.9922, 0.9925, 0.9927, 0.9921, 0.9919, 0.9927,\n",
            "        0.9926, 0.9917, 0.9926, 0.9924, 0.9923, 0.9926, 0.9925, 0.9923, 0.9920,\n",
            "        0.9922, 0.9920, 0.9917, 0.9925, 0.9926, 0.9922, 0.9924, 0.9915, 0.9924,\n",
            "        0.9925, 0.9924, 0.9923, 0.9924, 0.9916, 0.9924, 0.9924, 0.9918, 0.9919,\n",
            "        0.9933, 0.9919, 0.9924, 0.9921, 0.9926, 0.9916, 0.9924, 0.9922, 0.9920,\n",
            "        0.9924, 0.9922, 0.9922, 0.9921, 0.9923, 0.9921, 0.9924, 0.9922, 0.9921,\n",
            "        0.9919, 0.9928, 0.9925, 0.9923, 0.9924, 0.9917, 0.9924, 0.9918, 0.9927,\n",
            "        0.9920, 0.9918, 0.9921, 0.9926, 0.9924, 0.9922, 0.9925, 0.9924, 0.9921,\n",
            "        0.9922, 0.9920, 0.9921, 0.9926, 0.9927, 0.9929, 0.9922, 0.9923, 0.9920,\n",
            "        0.9924, 0.9923, 0.9923, 0.9916, 0.9922, 0.9925, 0.9927, 0.9923, 0.9920,\n",
            "        0.9920, 0.9923, 0.9918, 0.9920, 0.9923, 0.9919, 0.9930, 0.9916, 0.9919,\n",
            "        0.9929, 0.9920, 0.9919, 0.9926, 0.9922, 0.9919, 0.9921, 0.9918, 0.9928,\n",
            "        0.9922, 0.9925, 0.9923, 0.9923, 0.9920, 0.9919, 0.9919, 0.9930, 0.9920,\n",
            "        0.9921, 0.9926, 0.9929, 0.9920, 0.9923, 0.9923, 0.9921, 0.9919, 0.9923,\n",
            "        0.9927, 0.9922, 0.9922, 0.9919, 0.9926, 0.9922, 0.9921, 0.9918, 0.9918,\n",
            "        0.9923, 0.9919, 0.9933, 0.9922, 0.9917, 0.9924, 0.9925, 0.9921, 0.9930,\n",
            "        0.9921, 0.9920, 0.9923, 0.9920, 0.9939, 0.9922, 0.9921, 0.9925, 0.9917,\n",
            "        0.9921, 0.9924, 0.9924, 0.9922, 0.9921, 0.9917, 0.9924, 0.9920, 0.9926,\n",
            "        0.9924, 0.9916, 0.9920, 0.9925, 0.9918, 0.9923, 0.9916, 0.9919, 0.9926,\n",
            "        0.9920, 0.9920, 0.9922, 0.9920, 0.9924, 0.9922, 0.9918, 0.9923, 0.9922,\n",
            "        0.9923, 0.9920, 0.9919, 0.9916, 0.9920, 0.9924, 0.9921, 0.9918, 0.9931,\n",
            "        0.9920, 0.9922, 0.9921, 0.9918, 0.9924, 0.9919, 0.9920, 0.9926, 0.9921,\n",
            "        0.9924, 0.9923, 0.9929, 0.9922, 0.9923, 0.9918, 0.9922, 0.9918, 0.9920,\n",
            "        0.9919, 0.9923, 0.9927, 0.9925, 0.9922, 0.9921, 0.9921, 0.9922, 0.9932,\n",
            "        0.9928, 0.9923, 0.9926, 0.9921, 0.9923, 0.9921, 0.9921, 0.9922, 0.9921,\n",
            "        0.9924, 0.9928, 0.9921, 0.9923, 0.9919, 0.9925, 0.9927, 0.9924, 0.9925,\n",
            "        0.9924, 0.9923, 0.9921, 0.9920, 0.9922, 0.9920, 0.9920, 0.9934, 0.9920,\n",
            "        0.9923, 0.9922, 0.9924, 0.9921, 0.9926, 0.9922, 0.9921, 0.9926, 0.9920,\n",
            "        0.9931, 0.9924, 0.9925, 0.9920, 0.9921, 0.9931, 0.9920, 0.9921, 0.9923,\n",
            "        0.9920, 0.9924, 0.9926, 0.9921, 0.9922, 0.9919, 0.9922, 0.9922, 0.9926,\n",
            "        0.9920, 0.9924, 0.9921, 0.9918, 0.9917, 0.9922, 0.9922, 0.9921, 0.9927,\n",
            "        0.9920, 0.9925, 0.9925, 0.9919, 0.9924, 0.9926, 0.9923, 0.9923, 0.9919,\n",
            "        0.9925, 0.9923, 0.9922, 0.9926, 0.9923, 0.9918, 0.9926, 0.9921, 0.9922,\n",
            "        0.9925, 0.9921, 0.9923, 0.9927, 0.9927, 0.9922, 0.9923, 0.9925, 0.9919,\n",
            "        0.9919, 0.9925, 0.9930, 0.9928, 0.9928, 0.9930, 0.9922, 0.9925, 0.9919,\n",
            "        0.9929, 0.9923, 0.9923, 0.9918, 0.9924, 0.9924, 0.9921, 0.9922, 0.9925,\n",
            "        0.9926, 0.9923, 0.9921, 0.9921, 0.9926, 0.9922, 0.9918, 0.9920, 0.9921,\n",
            "        0.9919, 0.9919, 0.9929, 0.9924, 0.9924, 0.9924, 0.9922, 0.9922, 0.9920,\n",
            "        0.9926, 0.9921, 0.9926, 0.9925, 0.9922, 0.9929, 0.9921, 0.9924, 0.9923,\n",
            "        0.9923, 0.9922, 0.9923, 0.9927, 0.9926, 0.9922, 0.9919, 0.9919, 0.9926,\n",
            "        0.9918, 0.9921, 0.9930, 0.9927, 0.9921, 0.9925, 0.9924, 0.9932, 0.9921,\n",
            "        0.9923, 0.9923, 0.9924, 0.9922, 0.9920, 0.9921, 0.9920, 0.9922])), ('module.encoder_q.layer4.0.bn1.bias', tensor([ 6.7691e-04, -7.5845e-04, -5.2198e-04, -4.1919e-05, -3.0047e-04,\n",
            "        -1.0297e-04,  1.7718e-04,  9.3772e-04, -8.5514e-04,  2.3105e-04,\n",
            "         2.7742e-06, -1.4273e-04, -2.6801e-04,  8.4959e-04,  6.2044e-05,\n",
            "         8.7108e-04, -1.8226e-04, -3.6744e-04,  1.4151e-05,  2.1468e-04,\n",
            "        -4.0294e-04, -2.5035e-04, -6.0249e-04,  6.7905e-05,  4.7174e-04,\n",
            "         3.1792e-05, -2.5116e-04,  5.4443e-05,  3.4466e-05, -4.6248e-05,\n",
            "         2.2182e-05,  8.0236e-05, -7.5950e-04,  1.9085e-04, -2.8009e-04,\n",
            "        -2.3123e-04, -4.0601e-04, -6.4216e-05, -3.2294e-05, -3.1904e-04,\n",
            "        -2.0715e-05,  2.9757e-05, -1.8632e-04,  8.5287e-05, -7.9971e-05,\n",
            "         8.1871e-06,  6.9171e-05, -4.0056e-04,  5.2704e-04, -1.8271e-04,\n",
            "        -2.9342e-04, -2.6318e-04, -1.7833e-04, -7.8370e-05,  1.4000e-04,\n",
            "         2.6868e-04, -3.4155e-04, -3.2491e-05, -2.5662e-05, -2.0867e-04,\n",
            "         6.7682e-04,  1.5018e-04, -1.2051e-05,  3.5964e-04,  6.8144e-04,\n",
            "         2.5969e-05, -1.7793e-04, -4.5062e-04,  7.7517e-05, -6.0803e-04,\n",
            "         1.1409e-04,  1.1218e-04,  4.2291e-05, -2.8335e-04,  1.6054e-04,\n",
            "         1.4604e-04, -9.1543e-05, -2.3103e-04, -1.6445e-04, -4.1284e-04,\n",
            "        -2.3002e-04,  4.4240e-04,  7.5085e-05, -6.9956e-05, -3.2150e-04,\n",
            "         2.3034e-04,  2.9611e-04, -4.1201e-04,  2.6055e-04, -1.6310e-05,\n",
            "         1.0410e-05,  6.5214e-05, -1.2341e-04, -2.6568e-04, -3.9399e-05,\n",
            "         3.5216e-05,  1.3347e-04, -3.6052e-05, -9.6185e-05, -2.3034e-04,\n",
            "         2.6262e-04,  4.5376e-04, -2.1251e-04,  2.5575e-04, -1.2642e-05,\n",
            "         2.7813e-04,  3.1396e-04, -4.8100e-05, -1.6315e-04, -5.4864e-04,\n",
            "        -1.0578e-04,  1.8176e-04, -2.2775e-04, -1.5264e-05, -1.4302e-04,\n",
            "         3.7990e-04, -1.2501e-04,  5.1126e-04,  5.2745e-04,  1.2118e-04,\n",
            "        -4.3224e-04,  3.9292e-04,  8.6966e-05,  1.2450e-05,  6.7366e-05,\n",
            "        -9.8461e-05, -1.7473e-04,  4.0288e-04,  7.1136e-04, -1.4914e-04,\n",
            "        -1.0002e-04, -4.6135e-05, -1.6040e-04,  2.7282e-04,  1.2953e-06,\n",
            "         2.9191e-04,  3.7408e-05,  1.2334e-04,  2.9589e-04, -3.7712e-05,\n",
            "         3.3954e-04,  2.2849e-05, -2.8460e-04,  5.7192e-04,  2.9935e-04,\n",
            "        -7.7487e-04, -2.2351e-04, -4.5923e-05,  3.1415e-04,  1.3024e-04,\n",
            "         1.9495e-04,  1.7121e-04, -1.3664e-04,  7.7896e-05, -1.3152e-04,\n",
            "        -6.1103e-04, -3.9006e-04,  1.0541e-04, -1.6184e-04,  1.7829e-05,\n",
            "        -5.6558e-04,  7.4709e-05,  3.5167e-05,  1.9628e-04,  4.3098e-04,\n",
            "        -1.2154e-05, -5.2268e-04, -2.8713e-05,  2.1254e-04, -2.2442e-04,\n",
            "        -5.0307e-04,  5.6596e-04, -5.9542e-04,  1.7345e-04,  1.6821e-05,\n",
            "         3.4807e-04, -7.9290e-04,  6.6366e-04,  3.0649e-04,  1.3257e-04,\n",
            "         2.0403e-04,  1.7637e-04, -3.8698e-04,  1.6574e-04, -2.8643e-04,\n",
            "         1.2902e-04, -3.9267e-05,  2.7845e-04,  2.1748e-04, -5.5496e-04,\n",
            "        -4.2665e-05, -7.6893e-05,  8.4529e-05,  1.9365e-04, -7.6569e-04,\n",
            "        -9.4120e-05, -4.1584e-04,  3.1063e-04, -2.1348e-04, -2.6322e-04,\n",
            "         8.4971e-05,  1.3732e-04,  3.6386e-04,  1.1508e-04, -2.3021e-04,\n",
            "        -3.3758e-04,  2.5324e-04, -3.4965e-04, -2.7275e-04, -3.4310e-04,\n",
            "         4.9434e-04, -2.1126e-05,  1.4139e-04,  2.6790e-04, -4.0013e-04,\n",
            "        -9.5149e-05, -4.4418e-05, -7.8548e-06,  7.5685e-05, -3.4525e-04,\n",
            "        -3.4051e-04,  4.3739e-04,  3.7982e-04,  8.9369e-06, -7.8152e-04,\n",
            "        -2.0293e-04, -1.8777e-04, -1.4129e-04, -2.5401e-04, -1.0864e-04,\n",
            "        -4.3244e-04,  8.7059e-04, -3.1208e-04, -6.1503e-05,  1.4922e-04,\n",
            "        -1.9259e-04, -2.3161e-05,  1.6281e-04, -2.0792e-04, -1.9760e-04,\n",
            "         2.9501e-04, -3.3104e-04,  3.4617e-04, -5.3442e-04,  1.6895e-04,\n",
            "         2.8577e-04,  3.9637e-04, -1.1559e-04, -2.8323e-04, -4.4056e-04,\n",
            "         5.7701e-04, -4.4401e-05, -1.0260e-04,  5.4849e-04,  4.0672e-04,\n",
            "        -2.2462e-04, -6.2481e-04,  7.4717e-05, -2.3072e-04, -4.1233e-04,\n",
            "        -1.9030e-04,  1.8070e-04,  1.5433e-04, -3.5553e-04, -6.9569e-04,\n",
            "         4.7996e-04, -2.5970e-04,  1.4572e-04, -3.5017e-04, -1.8030e-04,\n",
            "         3.4312e-04, -3.1414e-04,  2.9256e-04, -4.5935e-04,  4.2204e-04,\n",
            "         1.6352e-04,  5.3938e-06, -7.1806e-05,  5.8259e-04, -2.4711e-04,\n",
            "         2.5448e-04, -2.3250e-04, -1.6024e-04,  7.2924e-04,  1.5890e-04,\n",
            "        -3.1861e-05,  1.3534e-04, -2.4424e-04, -1.7322e-04,  3.8748e-04,\n",
            "         1.7021e-04,  1.2868e-04,  9.0169e-05, -5.3140e-04,  3.0131e-04,\n",
            "        -6.0478e-05, -3.5166e-04,  4.0632e-05, -3.8892e-04, -2.4984e-04,\n",
            "         3.6854e-04, -2.7817e-04,  9.7298e-05, -5.4133e-04, -4.5671e-04,\n",
            "         3.5069e-04, -2.2201e-04, -3.0783e-04, -8.6739e-05, -3.2099e-04,\n",
            "        -1.2963e-04,  1.9845e-04, -2.2659e-04, -3.7809e-04, -2.6874e-04,\n",
            "         1.5936e-04, -3.2685e-04, -1.5912e-04, -5.9111e-04, -2.9317e-04,\n",
            "         3.7946e-04, -3.1076e-04, -4.5891e-04,  3.3801e-04, -1.9265e-04,\n",
            "        -3.7740e-04, -1.5596e-04, -5.4820e-04,  3.4784e-04, -3.9127e-04,\n",
            "        -4.4258e-04,  4.2817e-04, -3.5594e-04, -2.2793e-04,  2.3754e-04,\n",
            "         1.7169e-04, -2.9067e-05, -3.5148e-04, -1.7857e-04,  1.3431e-04,\n",
            "        -2.9228e-04, -2.5853e-04, -7.6180e-05, -2.3636e-04,  3.4932e-04,\n",
            "        -5.1510e-05, -3.3574e-04, -3.9735e-04, -1.3205e-04, -3.9639e-05,\n",
            "         5.4408e-04,  1.2630e-04,  7.3868e-05,  3.1069e-04, -2.6734e-04,\n",
            "         2.1286e-04, -4.7683e-06, -8.6991e-05, -2.7532e-04,  3.6072e-04,\n",
            "         1.1304e-04,  9.8325e-05,  5.5146e-05, -2.2780e-04,  4.5190e-05,\n",
            "         3.7915e-04,  6.3904e-04,  2.6083e-04,  1.3234e-04, -1.4447e-04,\n",
            "         1.0368e-05, -6.1953e-05, -2.6078e-04, -1.5807e-04, -1.8276e-04,\n",
            "        -1.1283e-04,  7.0643e-04,  1.1916e-04,  2.5734e-04, -1.2318e-04,\n",
            "        -8.6987e-05, -5.8346e-04,  6.7103e-04,  4.7804e-05, -2.1549e-04,\n",
            "         3.4971e-04, -6.6796e-05,  5.9083e-04, -4.7490e-05, -9.2962e-05,\n",
            "        -4.3875e-04, -1.0017e-04,  6.3126e-04,  2.1111e-04,  3.9183e-05,\n",
            "         1.0821e-04, -2.9027e-04,  2.3465e-04,  1.2329e-04, -6.9267e-05,\n",
            "        -2.6242e-04, -2.0385e-04,  1.5487e-04,  2.1779e-04,  3.0145e-04,\n",
            "         4.1305e-05,  1.0218e-04, -5.1884e-04, -5.9105e-04, -6.7371e-04,\n",
            "        -6.3435e-04, -9.3430e-06, -4.4362e-04,  2.5607e-04, -2.0850e-04,\n",
            "         8.7493e-05,  1.8281e-04, -2.7604e-04,  9.8302e-05, -5.4923e-05,\n",
            "         2.9905e-05, -4.9108e-05,  1.5082e-05, -6.4137e-05,  3.5944e-05,\n",
            "        -3.1900e-04,  2.5411e-04,  4.6025e-04, -1.7794e-04,  4.4246e-04,\n",
            "        -1.4320e-04, -2.9793e-04, -1.5341e-04, -3.1528e-05,  2.0247e-04,\n",
            "         2.4827e-04, -1.4051e-04,  1.1561e-04, -1.7749e-04,  3.8811e-04,\n",
            "        -3.9238e-04, -4.0847e-04,  2.8839e-05,  6.6184e-04,  3.9526e-04,\n",
            "         4.0440e-04,  4.8129e-04, -3.7860e-04,  2.6254e-04, -3.8775e-04,\n",
            "         1.1333e-03,  5.2677e-05,  1.6142e-04, -2.1090e-04,  1.1567e-04,\n",
            "        -6.6861e-05, -6.7126e-04, -2.5312e-04,  4.2599e-04,  7.0242e-04,\n",
            "         4.9097e-05, -1.9580e-04, -2.7400e-04,  7.4276e-05, -5.3731e-05,\n",
            "        -8.1849e-06, -4.2441e-05, -7.6147e-05,  3.6749e-05, -3.6457e-04,\n",
            "         2.2250e-04,  3.3622e-04, -1.1838e-04,  2.4105e-04, -1.8203e-04,\n",
            "        -2.8979e-04,  3.2390e-04,  9.2606e-05,  1.0905e-04,  4.8897e-04,\n",
            "        -1.4616e-04, -3.3804e-04,  4.8653e-04, -1.4758e-04, -1.0513e-04,\n",
            "         1.6387e-04, -4.5156e-05, -3.9124e-04,  3.1059e-04,  4.7645e-05,\n",
            "         8.7867e-05,  1.1703e-04, -2.4485e-04, -5.2432e-04,  1.6241e-04,\n",
            "        -3.1707e-04, -9.3162e-05,  8.3469e-04,  5.2042e-04, -2.8186e-04,\n",
            "         8.8937e-05,  3.2382e-04,  3.2101e-04, -3.2757e-04, -2.9152e-04,\n",
            "         6.5737e-05,  7.6630e-05,  2.0724e-04,  1.8651e-05, -1.1540e-04,\n",
            "        -1.5275e-05, -9.7486e-05])), ('module.encoder_q.layer4.0.bn1.running_mean', tensor([-6.7256e-01, -5.6474e-01, -9.0097e-01, -5.2724e-01,  2.3587e+00,\n",
            "         6.5459e-01, -1.6675e+00, -9.3535e-01,  4.6349e-01, -1.3035e-01,\n",
            "        -1.7873e+00, -2.2697e+00, -1.4193e+00, -3.2598e+00, -1.0178e+00,\n",
            "        -3.9467e+00,  3.5328e+00, -8.1789e-01, -5.0540e+00,  1.7971e+00,\n",
            "        -9.7839e-01,  2.5433e+00,  4.5779e+00,  9.7020e-01,  5.0352e+00,\n",
            "         4.5318e-01,  8.1067e-01,  1.8291e+00,  7.6371e-01,  3.7067e+00,\n",
            "         1.5645e+00,  1.0768e+00,  4.7041e+00,  2.2585e+00, -1.1822e+00,\n",
            "        -2.1728e+00, -2.6359e+00, -7.5815e-01, -1.4492e+00, -3.1369e+00,\n",
            "         4.1887e+00, -3.7594e-01,  5.8375e-01, -5.1278e+00,  5.1367e+00,\n",
            "        -7.1424e-01, -1.7075e-01,  7.9875e-01,  1.5215e+00,  2.4808e+00,\n",
            "        -1.5629e+00, -1.7493e+00,  6.7136e-01,  1.9762e+00,  1.1362e+00,\n",
            "        -1.7813e-01, -3.3297e-01, -3.3777e-02, -5.1682e+00, -3.0171e+00,\n",
            "         7.5124e-01, -9.3338e-01,  3.5440e+00, -5.5689e-01,  1.0156e+00,\n",
            "        -6.4399e-01, -7.8095e-01,  7.4895e-01, -4.0362e+00,  8.2038e-01,\n",
            "         9.1984e-01, -9.2031e-01,  8.3289e-01, -3.1294e+00,  7.7484e-01,\n",
            "         3.4317e+00, -1.6591e+00, -1.1858e+00, -8.0074e-01, -2.5785e+00,\n",
            "        -4.5167e+00,  4.0664e+00, -4.4607e+00,  2.1335e+00,  2.5682e+00,\n",
            "         5.9363e+00, -4.9106e+00, -1.4310e+00,  3.1102e-01, -2.1406e+00,\n",
            "        -1.4367e+00,  2.1429e+00, -1.5154e+00,  1.4651e+00, -1.4361e+00,\n",
            "         2.4110e+00, -2.8517e-01,  3.1671e+00,  2.3462e+00, -7.8520e-01,\n",
            "        -4.8427e+00,  3.4729e-01,  9.3877e-01,  3.0792e-01,  1.1201e+00,\n",
            "         3.6396e+00,  3.7763e-01,  9.4137e-01, -2.0045e+00, -3.0923e+00,\n",
            "        -3.7619e-01,  7.9182e-01,  3.2483e+00,  5.7767e+00, -6.0007e-01,\n",
            "         2.1340e+00, -9.7085e-01,  2.8766e-01, -1.4802e+00,  3.1569e+00,\n",
            "         2.8637e-01,  4.1823e+00,  3.2999e+00,  4.3623e+00,  6.0892e-01,\n",
            "         9.7268e-01,  2.0663e+00, -5.3212e-02,  2.7303e+00,  7.8869e+00,\n",
            "         2.5719e+00,  3.3311e+00, -4.2912e-02, -1.6429e+00,  1.1611e+00,\n",
            "         9.1773e+00, -5.6833e-01,  1.7998e+00, -9.6914e-01,  1.2266e+00,\n",
            "         1.3307e+00, -6.3364e-01, -5.3205e-01,  3.4022e+00,  4.1488e+00,\n",
            "        -2.7267e+00,  4.2850e-01, -2.9821e+00, -3.5072e+00,  4.2086e-01,\n",
            "         1.3127e+00,  5.2451e+00, -2.1306e+00,  3.8664e+00,  4.1902e+00,\n",
            "         2.0589e+00,  4.4791e+00,  1.0487e-02,  3.7123e+00,  3.6697e-01,\n",
            "         5.1455e+00,  1.6549e+00, -9.5298e-01, -2.4613e+00,  2.8445e+00,\n",
            "        -4.5076e-01, -2.0404e-01,  4.0049e+00,  1.6383e+00, -5.3591e+00,\n",
            "         1.5787e+00, -3.7024e-01, -3.4184e+00, -2.4359e+00, -4.2602e+00,\n",
            "         1.6855e+00, -1.7808e+00, -8.0549e-01, -1.5287e+00, -1.9280e-01,\n",
            "        -1.4495e+00, -2.1208e+00, -2.3112e+00,  1.8099e+00,  4.5190e+00,\n",
            "        -1.0319e+00,  8.3757e-01, -1.4171e+00, -1.9564e+00, -5.4214e+00,\n",
            "        -2.5827e+00,  5.7019e+00, -1.8861e+00,  2.3102e+00,  2.5425e-01,\n",
            "         1.0758e+00,  6.2932e-01, -8.7485e-01, -8.8586e-01, -1.8604e+00,\n",
            "        -3.5643e+00,  1.1236e+00,  5.9334e-01,  9.0186e-01, -2.5326e+00,\n",
            "         3.2615e+00,  7.5909e-02, -1.3177e+00,  6.6823e-01, -5.4659e+00,\n",
            "         1.0761e+00,  2.0211e+00,  1.5021e+00,  1.6939e+00, -7.5853e-01,\n",
            "         2.2224e+00, -2.1977e+00, -1.9413e+00, -1.7571e+00, -6.5248e-02,\n",
            "         4.2512e+00, -2.4326e+00, -2.8131e+00,  7.2640e+00, -1.7658e+00,\n",
            "         1.3074e+00, -3.3726e-01, -2.7461e+00,  2.1559e+00, -1.0438e+00,\n",
            "         4.4903e+00, -4.2763e-01,  2.9064e+00,  9.3653e-01,  5.4475e+00,\n",
            "        -1.3534e+00, -4.5295e+00, -3.3705e+00, -1.8918e+00,  2.0678e+00,\n",
            "        -1.3250e+00, -1.8671e+00,  4.5922e+00,  9.8041e-01, -2.2055e+00,\n",
            "        -1.4358e+00,  2.9836e+00, -1.3046e+00,  2.1225e+00, -2.5758e+00,\n",
            "         4.6655e+00, -1.0130e+00,  5.9255e-02,  2.6988e+00,  3.7979e+00,\n",
            "        -1.4980e+00, -1.1510e-01,  5.1831e-01, -4.2101e+00, -1.1712e+00,\n",
            "         5.5023e-01,  7.7941e-01, -2.5077e+00, -4.2176e-01, -2.1157e+00,\n",
            "         4.5149e+00,  8.1955e-01,  4.2351e+00,  8.0889e-01, -1.5343e+00,\n",
            "         9.7124e-01, -3.2970e-01,  6.0621e-01,  1.3759e+00,  3.0307e+00,\n",
            "         1.7623e+00,  3.5710e-01, -2.2748e+00,  3.3810e+00,  3.4524e-01,\n",
            "         5.3133e+00, -3.1108e+00, -1.7485e+00, -1.7895e+00, -9.0571e-01,\n",
            "         5.6315e-01,  2.0718e+00,  1.7808e+00, -1.2106e+00, -1.3036e+00,\n",
            "        -1.5803e+00, -5.0839e+00, -4.0144e+00, -3.7390e+00,  1.8865e+00,\n",
            "         3.3987e+00,  4.5537e-03, -6.9994e-01,  4.2986e+00, -1.6839e-01,\n",
            "        -3.9283e-01, -3.3651e+00,  3.7021e+00, -2.2344e+00, -5.3015e+00,\n",
            "         2.3214e+00, -3.3783e-01, -3.2965e+00, -2.5096e+00,  1.1488e+00,\n",
            "         4.5397e+00,  5.5274e+00,  2.3520e-01,  4.3421e+00,  3.4999e+00,\n",
            "         7.9060e-02, -1.8322e+00, -1.7129e+00, -3.6074e-01, -1.3589e+00,\n",
            "         4.9071e-01,  2.4787e+00,  1.6601e-01,  2.8709e-01,  1.8013e-01,\n",
            "         3.3455e+00, -3.6714e+00,  1.2516e+00,  4.7001e-01, -1.9560e+00,\n",
            "        -3.3148e-01,  1.6464e+00, -1.2736e+00, -6.9819e-01, -5.3377e-01,\n",
            "        -3.2577e+00, -4.1063e+00, -6.4694e-01, -4.1390e+00, -3.0110e+00,\n",
            "         1.2607e+00,  6.1594e-02,  1.7237e+00, -6.4263e-01, -2.8077e+00,\n",
            "         1.1525e+00, -4.0742e+00, -1.5578e+00,  2.7197e+00, -3.4877e-02,\n",
            "         2.5208e+00,  1.6509e+00,  2.0501e+00,  1.2539e+00,  1.9262e+00,\n",
            "        -1.9838e+00,  9.8879e-02, -5.1683e+00, -4.4168e-01,  3.7140e+00,\n",
            "        -6.3886e-01,  8.7790e-02, -1.5751e-01,  2.6162e-01,  1.2007e+00,\n",
            "        -2.6204e+00, -3.1309e-01, -4.0130e+00, -4.4887e-01,  1.4547e+00,\n",
            "         2.2518e+00,  1.2581e-01, -3.3667e-01, -1.2888e+00,  1.8845e+00,\n",
            "        -2.2988e+00,  2.7191e+00, -1.4437e+00,  4.1436e+00,  3.6255e+00,\n",
            "        -1.7105e-01, -1.0020e+00, -2.5861e+00,  5.3097e-01,  2.5015e+00,\n",
            "         4.0421e+00,  7.9158e-01,  1.1443e-01,  5.1959e+00, -2.1779e+00,\n",
            "        -5.7073e+00,  7.1359e-01,  7.4548e-01,  3.4018e+00, -2.9568e+00,\n",
            "        -1.4237e+00,  1.7123e+00,  9.3560e-01,  2.5502e+00, -5.4836e-01,\n",
            "         9.8879e-01,  2.9258e+00,  2.0138e+00,  4.4996e-01,  2.8949e+00,\n",
            "        -2.6952e+00, -2.8799e+00,  5.3385e-01,  2.1332e+00,  1.2924e+00,\n",
            "        -1.8093e+00, -3.4201e+00, -3.0077e+00,  1.8016e+00,  6.1907e+00,\n",
            "         1.5296e+00,  1.6789e+00,  5.3386e-01,  1.8554e+00,  6.7120e-01,\n",
            "         4.5285e+00, -1.0627e+00,  4.0559e+00,  1.7560e+00, -2.6392e+00,\n",
            "         7.0420e-02,  1.7535e+00,  2.8677e+00, -4.1462e+00,  5.0312e-01,\n",
            "        -7.1919e-01, -1.7065e-02,  9.7862e+00, -2.3686e+00,  1.7077e+00,\n",
            "         1.6318e+00,  3.5938e+00, -2.1458e-02,  6.6116e-01, -1.4857e-01,\n",
            "        -2.0777e+00, -6.2449e-01, -2.2600e+00,  4.2672e+00,  6.8564e-01,\n",
            "        -4.6280e+00, -4.0654e-01,  1.1337e-01, -1.0441e-01, -4.8240e-01,\n",
            "        -5.5276e+00, -4.5679e-01,  2.4286e+00,  1.2529e+00, -5.0657e-01,\n",
            "        -4.8196e+00, -4.3578e+00, -9.6245e-02,  6.4740e+00, -7.9906e-01,\n",
            "         2.0277e+00, -4.1983e+00, -3.0043e-01, -8.3221e-01, -3.3029e-01,\n",
            "         4.0168e+00, -2.5288e+00, -2.2284e+00, -5.3030e-02,  5.1534e+00,\n",
            "         9.5482e-02, -7.9409e-01,  3.1954e-01,  9.5992e-01, -3.0541e-01,\n",
            "        -3.9278e+00,  2.0557e+00, -1.0444e+00,  4.7700e-01,  3.7984e-01,\n",
            "         3.7904e+00, -1.6732e-01, -8.8467e-01,  2.2012e+00,  2.5885e+00,\n",
            "        -1.7211e+00,  5.3623e-01, -1.2589e+00, -1.4870e+00, -1.9109e+00,\n",
            "         2.1518e+00, -2.3115e+00, -7.9431e-02, -5.2597e-01, -5.4371e-01,\n",
            "         9.0818e-01, -1.3599e-01,  2.2923e+00,  1.1701e+00, -9.4995e-01,\n",
            "        -2.9254e-02,  3.5669e+00, -1.7809e+00,  2.7432e+00, -2.4747e+00,\n",
            "        -1.4585e+00, -6.3969e-01,  7.8006e+00,  5.3809e-01,  1.3934e-01,\n",
            "         2.0054e+00,  1.8913e+00])), ('module.encoder_q.layer4.0.bn1.running_var', tensor([12.6511,  8.3364,  7.5925, 10.4418,  7.9280, 14.8191,  9.9891, 10.6635,\n",
            "         9.5875, 14.8198, 11.7873, 11.8899,  9.5304, 21.4571, 11.8984, 35.7675,\n",
            "         9.6592,  7.4793, 18.5194, 12.9143,  8.7778, 16.2681, 20.1895, 18.4686,\n",
            "        12.3580,  9.6232,  8.1303, 16.9994,  7.7628,  8.6366, 18.7758,  7.8994,\n",
            "         8.6357, 26.0809,  8.7745, 12.0307, 10.8605, 16.4958,  7.7249, 35.7385,\n",
            "        18.8307, 11.5393,  7.5999, 14.9628,  7.5763,  8.4791, 12.8677, 12.6093,\n",
            "         8.9660,  8.2073, 17.4327,  8.3700,  9.9357,  8.3225, 17.9994,  9.1508,\n",
            "         9.7988,  9.7604, 19.5599, 18.1195,  8.6508, 10.1713, 15.4913, 11.5952,\n",
            "         8.5827, 10.7471, 12.9948,  8.3940, 26.9914,  7.9769,  7.7214,  9.2333,\n",
            "        11.2664, 10.6953,  7.7998, 11.2267,  8.8636,  7.7961,  9.5490, 10.2699,\n",
            "        34.5010, 10.3437, 19.7899, 10.7675, 12.5629, 25.2495, 45.4282,  6.9670,\n",
            "         7.7298,  8.5843,  9.1433, 12.7674,  9.2931, 10.6909,  9.6440,  8.8185,\n",
            "         8.2608, 10.6505, 15.2482, 11.3889, 18.0656, 13.0510,  6.9695,  7.8900,\n",
            "        11.8169, 12.2779, 12.7641,  8.2483, 12.4104, 13.2508, 10.3684,  8.4116,\n",
            "        13.2557, 16.2896, 12.1231, 16.4934,  8.9020,  8.7250,  7.4879, 10.8068,\n",
            "         7.9213, 11.9831, 10.7237, 20.5071,  8.8533,  8.9781,  9.4355,  7.4788,\n",
            "        11.5524, 63.1390, 10.0096, 19.8046, 20.9085, 14.6398,  9.1610, 37.8894,\n",
            "         8.2925,  8.4830,  7.4236,  7.4172,  8.7942, 10.9579, 14.3626, 12.9816,\n",
            "        21.5031, 24.6427, 10.7038, 12.6731,  9.0367, 10.3940, 12.1619, 11.7176,\n",
            "        21.1702, 25.6343, 10.5754, 11.3702, 25.3570,  9.9414, 10.0761,  8.0764,\n",
            "        37.7127,  7.2108, 10.5940, 20.8265, 18.2193, 12.1496,  8.8866, 24.0725,\n",
            "        20.8904, 20.5688,  9.1827,  9.0803, 33.2225,  7.9215, 27.9454,  8.4144,\n",
            "        10.9226,  8.5479, 21.0291,  7.2332, 10.7122,  9.9613, 17.1542, 16.5108,\n",
            "        21.1109, 10.5848,  8.4594, 10.9371, 10.1444, 40.0571,  8.5146, 14.4567,\n",
            "         9.7196, 13.8111, 10.8898,  8.6046, 11.0045,  7.4912, 11.0166, 15.1231,\n",
            "        11.9959,  8.2196,  8.3389,  8.8437, 11.5301, 16.6506, 13.2980,  8.3017,\n",
            "         8.5192, 13.9119, 10.3657, 17.9582,  9.3518, 17.0249, 11.8494,  8.5384,\n",
            "        12.7219, 10.7684,  7.2210, 11.6314, 18.4916, 11.1795, 18.8923, 65.4511,\n",
            "        11.2638, 11.9586,  8.8959, 12.0798, 22.7893,  9.2353, 20.7244,  9.4612,\n",
            "         7.2147,  8.8009, 21.4698,  9.3351, 13.3451, 14.7833, 12.3865, 21.4360,\n",
            "        16.9929, 11.5900, 18.8196, 11.1890, 10.0575, 10.8576, 10.6732, 12.5275,\n",
            "         9.8459, 12.9414, 22.2312, 12.7510,  8.7080, 19.5511, 10.6815, 20.3005,\n",
            "         8.7816, 16.0853, 21.7657, 14.5167,  8.2358, 11.7238, 13.0320, 11.3666,\n",
            "        12.7376, 29.4974,  8.8248, 20.2453, 10.5049, 12.5026,  7.8866, 10.3321,\n",
            "        10.1032, 11.2917, 30.6529,  8.1124,  8.7316, 18.0710, 33.3557,  7.1923,\n",
            "        28.4151, 11.7405,  7.5092,  8.0769, 14.5741,  9.4876, 12.8075, 10.7142,\n",
            "         8.8089, 19.8134,  7.1814, 17.1656, 10.6520,  7.6286,  8.3110,  8.1602,\n",
            "         7.6552, 10.1879, 15.9904,  8.3082,  8.1992,  7.5661, 11.0423, 11.2776,\n",
            "        34.7356, 11.8450,  8.9336, 33.2985,  7.5869,  7.4414, 31.4757, 22.0102,\n",
            "         9.9779, 17.0971, 18.9415,  9.3582, 11.8405, 10.4996,  9.5308,  9.0371,\n",
            "         7.3521, 11.9166,  7.3890, 10.7754,  8.5511, 21.1877, 16.4604,  8.8528,\n",
            "        13.2439, 16.0796,  8.0432, 12.6021,  8.9277, 10.0112, 14.6671, 12.7429,\n",
            "        28.4136, 11.4335, 12.7511, 15.6589, 11.2191,  7.9093,  8.6653, 10.3359,\n",
            "         9.3860,  8.0649, 13.1261,  7.7553, 12.9924, 11.0761, 11.2175,  8.8602,\n",
            "        10.0768, 11.7343, 10.0330, 11.8169, 15.4646, 20.2601,  7.2354, 12.6135,\n",
            "         7.2291,  8.0142, 12.7647,  7.7203, 17.6376,  9.4438, 14.4456, 29.2208,\n",
            "         8.0647,  9.2983, 17.2697, 10.2766, 12.1668, 42.2453,  8.5901, 18.3194,\n",
            "         8.9876,  8.7937, 12.9795, 15.9606, 11.1809,  8.3708, 11.2857,  7.6844,\n",
            "         9.9293,  8.2699,  8.0595,  8.7088, 47.8883,  7.0428, 17.1915,  6.5047,\n",
            "         8.4394, 13.0159,  9.5890,  9.1969, 10.2917, 11.3710, 18.1155,  8.7383,\n",
            "        15.4561, 11.8766, 14.2569, 14.6675, 19.0614,  8.0597, 20.6256,  8.9197,\n",
            "        10.4930,  7.2368,  8.0291, 10.4964, 16.6777,  9.4889, 25.2986, 18.3580,\n",
            "        11.8506,  8.2687, 12.0835, 10.5207, 17.7295, 10.6162, 15.9644, 17.4355,\n",
            "        23.0095, 11.0188,  8.7316, 20.5929, 15.9510,  8.9595,  9.6649,  9.6650,\n",
            "        46.6024, 16.1583, 13.3856,  8.3957, 20.3237, 12.0748, 15.0928, 14.1488,\n",
            "         9.4641,  8.5089, 11.1563, 27.7703, 12.0037,  9.3364, 10.6605,  9.0673,\n",
            "        11.3721,  7.5519, 24.2305, 11.2339, 17.3471,  9.7157,  8.5030, 23.0100,\n",
            "        16.6589, 10.0677, 55.0912,  7.4057,  8.6411, 13.3481,  9.2440,  8.1460,\n",
            "        13.5057, 22.6349, 28.0673, 15.8162,  8.7900, 15.3425,  9.9631,  8.8922,\n",
            "         9.1487, 14.8122,  7.1251, 13.3446, 10.9426, 14.9005,  7.6353,  8.2749,\n",
            "        13.9466,  9.0070,  8.8967, 13.8703,  9.3234, 10.5437,  7.1630,  8.1728,\n",
            "         8.8994, 11.6761, 11.7877, 11.5993, 10.3897, 10.5032,  7.6470,  7.1676,\n",
            "        24.0875, 14.0475,  7.8220,  8.8208,  9.1485, 24.0046,  8.2004, 13.9277,\n",
            "        20.2435, 13.7576, 10.1161, 19.2120,  8.4633, 10.5661, 12.6879, 10.3750])), ('module.encoder_q.layer4.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.0.conv2.weight', tensor([[[[ 0.0149, -0.0461, -0.0200],\n",
            "          [ 0.0101, -0.0086,  0.0077],\n",
            "          [ 0.0010,  0.0015,  0.0331]],\n",
            "\n",
            "         [[ 0.0121,  0.0033,  0.0129],\n",
            "          [-0.0099,  0.0020,  0.0242],\n",
            "          [-0.0324, -0.0559, -0.0098]],\n",
            "\n",
            "         [[-0.0191,  0.0050, -0.0172],\n",
            "          [-0.0327, -0.0140, -0.0251],\n",
            "          [ 0.0226,  0.0117, -0.0440]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0314, -0.0008, -0.0159],\n",
            "          [-0.0079,  0.0090,  0.0272],\n",
            "          [-0.0175,  0.0091,  0.0236]],\n",
            "\n",
            "         [[-0.0119, -0.0014, -0.0207],\n",
            "          [ 0.0154, -0.0164, -0.0130],\n",
            "          [ 0.0187, -0.0046, -0.0151]],\n",
            "\n",
            "         [[ 0.0089, -0.0253, -0.0009],\n",
            "          [-0.0274, -0.0416, -0.0006],\n",
            "          [ 0.0016, -0.0110, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024,  0.0032,  0.0144],\n",
            "          [-0.0303, -0.0080, -0.0078],\n",
            "          [-0.0084,  0.0007, -0.0022]],\n",
            "\n",
            "         [[-0.0206, -0.0215, -0.0296],\n",
            "          [ 0.0290, -0.0017,  0.0297],\n",
            "          [ 0.0210,  0.0103,  0.0356]],\n",
            "\n",
            "         [[ 0.0140,  0.0669,  0.0307],\n",
            "          [-0.0182,  0.0320, -0.0047],\n",
            "          [-0.0235, -0.0030, -0.0179]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0142, -0.0338, -0.0189],\n",
            "          [-0.0113, -0.0097, -0.0069],\n",
            "          [-0.0171, -0.0381,  0.0074]],\n",
            "\n",
            "         [[ 0.0080, -0.0424, -0.0042],\n",
            "          [-0.0302,  0.0139,  0.0651],\n",
            "          [ 0.0056,  0.0408, -0.0103]],\n",
            "\n",
            "         [[ 0.0060, -0.0040, -0.0078],\n",
            "          [-0.0118, -0.0235,  0.0077],\n",
            "          [-0.0004, -0.0031,  0.0373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0207,  0.0017,  0.0174],\n",
            "          [ 0.0310, -0.0148, -0.0213],\n",
            "          [-0.0132, -0.0528,  0.0198]],\n",
            "\n",
            "         [[ 0.0051, -0.0312, -0.0066],\n",
            "          [ 0.0038,  0.0121, -0.0319],\n",
            "          [-0.0058,  0.0197, -0.0218]],\n",
            "\n",
            "         [[ 0.0168, -0.0120, -0.0032],\n",
            "          [ 0.0301,  0.0043,  0.0372],\n",
            "          [-0.0524,  0.0112, -0.0407]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0265, -0.0228,  0.0086],\n",
            "          [-0.0231, -0.0142,  0.0170],\n",
            "          [-0.0129,  0.0078, -0.0006]],\n",
            "\n",
            "         [[-0.0288, -0.0146, -0.0004],\n",
            "          [-0.0100,  0.0042, -0.0110],\n",
            "          [ 0.0084, -0.0132,  0.0210]],\n",
            "\n",
            "         [[ 0.0138,  0.0486, -0.0208],\n",
            "          [ 0.0187,  0.0051, -0.0204],\n",
            "          [-0.0113, -0.0013,  0.0427]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0069,  0.0170,  0.0011],\n",
            "          [-0.0369, -0.0290,  0.0208],\n",
            "          [-0.0039, -0.0041, -0.0104]],\n",
            "\n",
            "         [[ 0.0258, -0.0160,  0.0179],\n",
            "          [-0.0136,  0.0007,  0.0058],\n",
            "          [-0.0251,  0.0044, -0.0258]],\n",
            "\n",
            "         [[ 0.0243,  0.0143, -0.0268],\n",
            "          [ 0.0140,  0.0212, -0.0008],\n",
            "          [ 0.0353,  0.0199, -0.0173]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0050, -0.0087, -0.0390],\n",
            "          [ 0.0167,  0.0031, -0.0194],\n",
            "          [ 0.0058, -0.0074, -0.0110]],\n",
            "\n",
            "         [[-0.0034,  0.0429,  0.0154],\n",
            "          [-0.0222, -0.0345, -0.0229],\n",
            "          [-0.0262, -0.0475, -0.0032]],\n",
            "\n",
            "         [[-0.0267, -0.0073, -0.0384],\n",
            "          [-0.0057,  0.0023, -0.0281],\n",
            "          [ 0.0159, -0.0037, -0.0048]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0023,  0.0539, -0.0033],\n",
            "          [-0.0102, -0.0260, -0.0231],\n",
            "          [ 0.0067,  0.0054,  0.0055]],\n",
            "\n",
            "         [[-0.0162, -0.0132,  0.0060],\n",
            "          [ 0.0149,  0.0144,  0.0012],\n",
            "          [ 0.0047, -0.0347, -0.0134]],\n",
            "\n",
            "         [[-0.0140, -0.0290, -0.0011],\n",
            "          [ 0.0035, -0.0244,  0.0086],\n",
            "          [ 0.0582, -0.0302,  0.0165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0135,  0.0050,  0.0169],\n",
            "          [ 0.0090, -0.0099,  0.0215],\n",
            "          [ 0.0199, -0.0255,  0.0037]],\n",
            "\n",
            "         [[ 0.0078, -0.0143, -0.0160],\n",
            "          [ 0.0003,  0.0297,  0.0214],\n",
            "          [-0.0202,  0.0351,  0.0022]],\n",
            "\n",
            "         [[ 0.0030,  0.0211,  0.0059],\n",
            "          [ 0.0004, -0.0089, -0.0021],\n",
            "          [ 0.0063, -0.0116,  0.0063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0346,  0.0074, -0.0356],\n",
            "          [ 0.0123,  0.0360,  0.0072],\n",
            "          [-0.0071,  0.0114,  0.0167]],\n",
            "\n",
            "         [[ 0.0285, -0.0130,  0.0175],\n",
            "          [ 0.0124,  0.0078,  0.0096],\n",
            "          [-0.0167, -0.0115,  0.0021]],\n",
            "\n",
            "         [[-0.0018, -0.0019,  0.0215],\n",
            "          [ 0.0120, -0.0192, -0.0125],\n",
            "          [-0.0086, -0.0108, -0.0330]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0292,  0.0213,  0.0074],\n",
            "          [-0.0240,  0.0413,  0.0131],\n",
            "          [-0.0056,  0.0113,  0.0232]],\n",
            "\n",
            "         [[ 0.0101,  0.0139, -0.0338],\n",
            "          [ 0.0203,  0.0269, -0.0054],\n",
            "          [-0.0663,  0.0053, -0.0122]],\n",
            "\n",
            "         [[-0.0269,  0.0054, -0.0110],\n",
            "          [ 0.0100,  0.0013,  0.0150],\n",
            "          [-0.0207, -0.0180, -0.0262]]]])), ('module.encoder_q.layer4.0.bn2.weight', tensor([0.9921, 0.9920, 0.9921, 0.9925, 0.9919, 0.9921, 0.9922, 0.9921, 0.9925,\n",
            "        0.9923, 0.9924, 0.9929, 0.9920, 0.9922, 0.9918, 0.9923, 0.9927, 0.9923,\n",
            "        0.9923, 0.9918, 0.9921, 0.9920, 0.9923, 0.9930, 0.9924, 0.9923, 0.9928,\n",
            "        0.9926, 0.9924, 0.9927, 0.9929, 0.9921, 0.9918, 0.9922, 0.9922, 0.9921,\n",
            "        0.9926, 0.9924, 0.9925, 0.9920, 0.9924, 0.9920, 0.9922, 0.9921, 0.9916,\n",
            "        0.9919, 0.9929, 0.9927, 0.9921, 0.9924, 0.9921, 0.9927, 0.9921, 0.9925,\n",
            "        0.9921, 0.9932, 0.9926, 0.9927, 0.9927, 0.9919, 0.9924, 0.9926, 0.9923,\n",
            "        0.9927, 0.9923, 0.9923, 0.9920, 0.9920, 0.9919, 0.9929, 0.9917, 0.9928,\n",
            "        0.9913, 0.9924, 0.9917, 0.9921, 0.9920, 0.9917, 0.9923, 0.9922, 0.9927,\n",
            "        0.9922, 0.9928, 0.9928, 0.9921, 0.9922, 0.9918, 0.9918, 0.9919, 0.9922,\n",
            "        0.9920, 0.9922, 0.9922, 0.9922, 0.9921, 0.9923, 0.9922, 0.9930, 0.9923,\n",
            "        0.9925, 0.9921, 0.9925, 0.9919, 0.9923, 0.9927, 0.9927, 0.9916, 0.9923,\n",
            "        0.9923, 0.9928, 0.9919, 0.9919, 0.9927, 0.9920, 0.9923, 0.9921, 0.9918,\n",
            "        0.9919, 0.9924, 0.9923, 0.9927, 0.9922, 0.9928, 0.9922, 0.9923, 0.9921,\n",
            "        0.9922, 0.9925, 0.9921, 0.9921, 0.9925, 0.9921, 0.9924, 0.9921, 0.9923,\n",
            "        0.9923, 0.9918, 0.9921, 0.9922, 0.9928, 0.9927, 0.9923, 0.9923, 0.9925,\n",
            "        0.9921, 0.9926, 0.9920, 0.9923, 0.9923, 0.9929, 0.9919, 0.9922, 0.9918,\n",
            "        0.9922, 0.9914, 0.9922, 0.9926, 0.9926, 0.9925, 0.9924, 0.9919, 0.9927,\n",
            "        0.9924, 0.9923, 0.9930, 0.9926, 0.9925, 0.9922, 0.9926, 0.9929, 0.9917,\n",
            "        0.9928, 0.9929, 0.9922, 0.9921, 0.9925, 0.9931, 0.9920, 0.9922, 0.9922,\n",
            "        0.9925, 0.9924, 0.9923, 0.9925, 0.9924, 0.9924, 0.9920, 0.9927, 0.9922,\n",
            "        0.9924, 0.9921, 0.9928, 0.9928, 0.9921, 0.9923, 0.9923, 0.9918, 0.9924,\n",
            "        0.9916, 0.9926, 0.9923, 0.9920, 0.9921, 0.9923, 0.9919, 0.9919, 0.9922,\n",
            "        0.9922, 0.9923, 0.9926, 0.9923, 0.9920, 0.9923, 0.9921, 0.9922, 0.9919,\n",
            "        0.9925, 0.9919, 0.9919, 0.9921, 0.9923, 0.9917, 0.9924, 0.9924, 0.9924,\n",
            "        0.9922, 0.9921, 0.9921, 0.9921, 0.9920, 0.9924, 0.9920, 0.9924, 0.9921,\n",
            "        0.9920, 0.9923, 0.9917, 0.9926, 0.9921, 0.9920, 0.9923, 0.9933, 0.9924,\n",
            "        0.9924, 0.9921, 0.9920, 0.9920, 0.9918, 0.9917, 0.9921, 0.9925, 0.9920,\n",
            "        0.9928, 0.9923, 0.9928, 0.9924, 0.9922, 0.9927, 0.9918, 0.9926, 0.9921,\n",
            "        0.9922, 0.9923, 0.9921, 0.9921, 0.9917, 0.9920, 0.9923, 0.9922, 0.9917,\n",
            "        0.9925, 0.9913, 0.9919, 0.9922, 0.9921, 0.9923, 0.9916, 0.9921, 0.9917,\n",
            "        0.9926, 0.9923, 0.9922, 0.9921, 0.9919, 0.9930, 0.9925, 0.9923, 0.9921,\n",
            "        0.9923, 0.9923, 0.9925, 0.9920, 0.9920, 0.9922, 0.9924, 0.9922, 0.9922,\n",
            "        0.9922, 0.9924, 0.9920, 0.9921, 0.9922, 0.9924, 0.9923, 0.9921, 0.9917,\n",
            "        0.9926, 0.9922, 0.9916, 0.9925, 0.9922, 0.9921, 0.9920, 0.9925, 0.9921,\n",
            "        0.9919, 0.9928, 0.9922, 0.9921, 0.9920, 0.9926, 0.9923, 0.9924, 0.9916,\n",
            "        0.9927, 0.9926, 0.9922, 0.9921, 0.9923, 0.9922, 0.9920, 0.9923, 0.9920,\n",
            "        0.9918, 0.9919, 0.9919, 0.9923, 0.9922, 0.9925, 0.9921, 0.9923, 0.9922,\n",
            "        0.9922, 0.9926, 0.9927, 0.9925, 0.9916, 0.9925, 0.9922, 0.9918, 0.9925,\n",
            "        0.9925, 0.9923, 0.9926, 0.9920, 0.9923, 0.9923, 0.9920, 0.9927, 0.9925,\n",
            "        0.9924, 0.9924, 0.9922, 0.9927, 0.9916, 0.9919, 0.9924, 0.9922, 0.9928,\n",
            "        0.9924, 0.9922, 0.9922, 0.9923, 0.9919, 0.9920, 0.9926, 0.9921, 0.9924,\n",
            "        0.9922, 0.9917, 0.9921, 0.9920, 0.9919, 0.9923, 0.9927, 0.9921, 0.9920,\n",
            "        0.9922, 0.9928, 0.9927, 0.9930, 0.9926, 0.9926, 0.9921, 0.9923, 0.9927,\n",
            "        0.9922, 0.9922, 0.9921, 0.9922, 0.9922, 0.9918, 0.9922, 0.9925, 0.9922,\n",
            "        0.9925, 0.9924, 0.9921, 0.9924, 0.9921, 0.9922, 0.9925, 0.9923, 0.9922,\n",
            "        0.9926, 0.9925, 0.9923, 0.9922, 0.9921, 0.9931, 0.9922, 0.9919, 0.9918,\n",
            "        0.9918, 0.9918, 0.9922, 0.9926, 0.9923, 0.9920, 0.9919, 0.9926, 0.9918,\n",
            "        0.9918, 0.9931, 0.9922, 0.9917, 0.9927, 0.9920, 0.9921, 0.9923, 0.9925,\n",
            "        0.9922, 0.9915, 0.9921, 0.9927, 0.9924, 0.9915, 0.9932, 0.9925, 0.9921,\n",
            "        0.9921, 0.9923, 0.9923, 0.9923, 0.9919, 0.9920, 0.9930, 0.9926, 0.9926,\n",
            "        0.9923, 0.9929, 0.9923, 0.9917, 0.9923, 0.9925, 0.9918, 0.9925, 0.9927,\n",
            "        0.9925, 0.9926, 0.9926, 0.9925, 0.9922, 0.9928, 0.9917, 0.9919, 0.9927,\n",
            "        0.9927, 0.9925, 0.9921, 0.9924, 0.9923, 0.9920, 0.9919, 0.9921, 0.9921,\n",
            "        0.9921, 0.9924, 0.9925, 0.9922, 0.9920, 0.9924, 0.9923, 0.9926, 0.9919,\n",
            "        0.9921, 0.9921, 0.9918, 0.9921, 0.9924, 0.9920, 0.9923, 0.9919, 0.9922,\n",
            "        0.9920, 0.9924, 0.9927, 0.9923, 0.9929, 0.9922, 0.9919, 0.9919])), ('module.encoder_q.layer4.0.bn2.bias', tensor([ 9.5114e-05, -1.5496e-04, -3.3178e-04,  3.2970e-05,  1.1531e-05,\n",
            "         8.9507e-05, -1.2864e-04,  9.2051e-05,  1.6346e-04,  3.8963e-05,\n",
            "        -1.4361e-04,  6.2372e-04, -1.8277e-04, -5.4829e-05, -7.3104e-04,\n",
            "         1.0144e-04, -1.6140e-04,  1.3928e-04,  4.6080e-06, -4.0265e-04,\n",
            "         7.6901e-05, -5.7277e-04, -5.1231e-05,  3.4484e-04,  8.6368e-05,\n",
            "        -1.1518e-04,  4.3913e-04,  1.6618e-04,  1.9388e-04,  7.3170e-04,\n",
            "         1.1632e-03, -6.9978e-05,  6.6287e-05, -6.7969e-05, -2.8035e-06,\n",
            "        -3.2334e-04,  5.8974e-04, -7.1495e-05,  6.5896e-04, -2.0534e-05,\n",
            "        -2.1951e-04, -2.0376e-04, -6.1890e-06, -1.9601e-04, -3.0146e-04,\n",
            "        -8.9123e-05,  3.3827e-04, -1.0164e-04, -2.1840e-04,  6.9040e-04,\n",
            "        -1.1965e-04,  6.4222e-04, -1.5440e-04,  6.7326e-05,  1.7728e-05,\n",
            "         6.4514e-04,  1.6098e-04,  2.7880e-04,  3.9376e-04, -3.7975e-04,\n",
            "        -1.3518e-04,  2.3086e-04, -2.8716e-04, -1.4557e-05, -6.0146e-05,\n",
            "         1.0100e-04, -1.3013e-04, -1.9878e-04, -5.3272e-05,  9.6434e-04,\n",
            "        -4.0037e-04,  3.2201e-04, -5.8339e-04,  5.1877e-04, -5.2299e-05,\n",
            "        -2.5137e-04, -3.4255e-04, -2.4167e-04, -4.9708e-05, -2.0513e-04,\n",
            "         6.6040e-04,  1.9872e-04,  2.7472e-04,  2.4377e-04,  3.6491e-04,\n",
            "        -1.9508e-04, -3.1579e-04, -4.8798e-04, -4.0016e-04, -3.7398e-04,\n",
            "         1.4766e-04, -1.0517e-04,  1.3940e-04,  4.2925e-04, -2.9170e-04,\n",
            "        -1.8700e-04, -1.1394e-04,  5.2315e-04,  4.1946e-04, -2.3629e-04,\n",
            "        -2.0878e-04, -1.9579e-04,  1.5369e-04, -1.0242e-04,  5.6596e-04,\n",
            "         3.8575e-04, -6.0510e-04,  1.4488e-04, -5.4573e-05,  4.1301e-04,\n",
            "        -1.2202e-04, -2.2564e-04,  3.9723e-06, -3.7056e-04,  6.1620e-05,\n",
            "        -5.3418e-05, -3.4061e-04, -2.0279e-04, -6.2830e-05,  3.3761e-04,\n",
            "         6.3374e-05,  3.5894e-04,  4.3631e-04,  3.1549e-04,  1.1642e-05,\n",
            "        -4.7049e-06, -1.4608e-04,  2.3255e-05, -2.2622e-04, -3.0896e-04,\n",
            "        -1.1083e-06,  2.0757e-04,  3.9551e-04, -4.4993e-04,  3.1023e-05,\n",
            "         1.8782e-04, -1.3210e-05,  7.7812e-05,  2.4482e-06,  4.3752e-04,\n",
            "        -1.2196e-05,  1.8401e-04,  8.8001e-05,  1.4426e-04,  3.7585e-05,\n",
            "         9.8665e-05, -5.4493e-05,  9.1347e-05,  2.1624e-04,  5.2667e-04,\n",
            "         2.8783e-05,  8.3933e-05, -3.8798e-04, -1.0705e-04, -1.6958e-04,\n",
            "         1.2940e-04,  4.2287e-04,  5.0519e-04,  1.4680e-04, -2.1212e-05,\n",
            "        -4.1656e-04,  1.5730e-04, -9.3427e-06, -9.2121e-06,  3.0556e-04,\n",
            "         6.2395e-05,  1.4973e-04,  2.7041e-05, -1.4408e-06,  6.9439e-04,\n",
            "        -3.6589e-04,  6.4788e-04,  8.6475e-04,  3.1221e-04, -3.0568e-06,\n",
            "         4.1108e-04,  9.8386e-04,  2.4254e-04,  1.9599e-04,  3.9148e-04,\n",
            "        -2.3815e-05, -5.3266e-05,  9.3643e-05,  5.5298e-05,  5.5422e-07,\n",
            "         2.2899e-04, -4.4047e-04,  2.6755e-04,  3.5011e-04,  2.5832e-04,\n",
            "         1.9656e-04,  2.8948e-04,  3.1525e-04, -1.1748e-04, -2.0320e-04,\n",
            "         1.4766e-04, -6.3172e-04,  9.0139e-05, -6.7330e-04, -7.7204e-05,\n",
            "         1.1158e-04,  3.4463e-05, -4.8819e-05, -2.8254e-04,  3.3732e-04,\n",
            "         8.9110e-06,  5.5928e-05,  3.7891e-04,  1.2305e-04,  6.1600e-04,\n",
            "         6.4335e-04, -1.1135e-04,  1.2915e-04,  2.5664e-05, -1.8125e-04,\n",
            "        -6.8070e-05,  2.8238e-04, -4.7682e-05, -4.3725e-04, -4.0679e-07,\n",
            "        -2.3607e-04, -5.3678e-04,  2.6256e-04, -4.3014e-06, -3.2743e-04,\n",
            "        -2.9794e-04, -3.7463e-05, -1.9108e-04, -1.8208e-04,  3.7474e-04,\n",
            "        -9.5717e-06, -2.0312e-04,  3.1191e-04, -2.0619e-04, -9.2010e-05,\n",
            "         1.5431e-04, -2.6918e-04,  4.1933e-04,  4.9237e-06, -1.0583e-04,\n",
            "         1.0937e-04,  5.7681e-04,  2.4690e-04,  6.8756e-04,  1.2792e-05,\n",
            "         5.5098e-05, -5.2693e-05, -3.2435e-04, -6.1449e-04,  7.6050e-05,\n",
            "         1.7793e-04, -2.8095e-04,  4.3768e-04,  2.0766e-06, -1.7529e-04,\n",
            "         3.3767e-05, -2.3978e-04,  1.9246e-07, -3.4543e-04,  5.0009e-04,\n",
            "        -2.7070e-04,  2.7011e-04,  3.2182e-04,  3.2590e-04, -4.0515e-04,\n",
            "        -2.4006e-04,  5.8450e-05, -1.6523e-04,  1.6745e-04,  1.6232e-05,\n",
            "         4.9992e-04, -6.4377e-04, -4.5176e-04, -1.8568e-04, -7.9261e-05,\n",
            "        -1.1820e-04, -4.4479e-04, -3.7040e-04, -3.0671e-04,  8.8567e-04,\n",
            "         1.3895e-04,  1.4285e-04, -4.6566e-05, -2.0225e-04,  4.6872e-05,\n",
            "         1.7118e-04,  4.4154e-05, -7.4002e-05,  2.6575e-04, -3.0259e-04,\n",
            "         7.5023e-06,  2.1239e-04, -3.2748e-04, -5.7548e-05, -1.2943e-04,\n",
            "        -2.7410e-04,  3.3322e-04,  1.7525e-04,  2.2541e-04, -1.2296e-04,\n",
            "        -1.6688e-04, -3.0196e-04, -2.3875e-04,  4.1058e-04, -5.0130e-05,\n",
            "        -5.1625e-04,  1.7174e-05, -1.1714e-05, -5.5870e-04,  5.7938e-04,\n",
            "         4.0089e-04, -9.3380e-05, -1.0775e-04, -1.8093e-04, -1.7402e-04,\n",
            "        -3.9581e-04,  6.9265e-05,  8.6994e-05, -2.3844e-04, -1.3865e-04,\n",
            "         1.2791e-04, -4.1596e-05,  4.1672e-04, -1.9762e-04,  4.9391e-05,\n",
            "        -6.6349e-05,  5.6119e-05, -3.9914e-04, -1.1954e-04,  1.4950e-04,\n",
            "        -1.4490e-04,  3.6495e-05, -2.9122e-04, -5.2938e-04, -3.8704e-04,\n",
            "        -2.7051e-04, -3.0032e-05,  2.0344e-05,  3.1560e-04,  1.3108e-05,\n",
            "        -1.8339e-04, -4.6924e-05, -1.7086e-04,  2.3131e-04,  1.2837e-04,\n",
            "        -2.4682e-04, -1.5163e-04,  1.0216e-04,  6.9296e-05, -1.5640e-04,\n",
            "         9.3976e-05,  3.6631e-04, -1.6466e-04,  8.8900e-05, -4.2495e-04,\n",
            "        -1.2276e-04, -1.4581e-04, -1.0327e-04,  1.0586e-04,  1.4168e-04,\n",
            "        -3.5374e-05,  4.6764e-05, -6.1662e-05,  7.7660e-04, -4.8294e-04,\n",
            "        -2.8205e-04, -3.6912e-04,  1.7202e-04,  2.4852e-04,  8.4326e-05,\n",
            "        -1.7771e-04, -3.7219e-04,  1.8258e-04, -5.0614e-04,  9.8261e-05,\n",
            "         1.7425e-04, -3.4291e-04,  4.5438e-04, -3.7352e-04, -8.7131e-04,\n",
            "        -3.9708e-05,  8.8344e-05,  3.8048e-05,  5.3830e-05,  3.0283e-04,\n",
            "        -2.8206e-04, -1.5557e-04,  9.2840e-05,  3.0122e-04,  3.3251e-04,\n",
            "         7.3276e-04, -5.5481e-05,  2.9288e-04,  3.0829e-06, -2.5912e-05,\n",
            "         5.0048e-06, -2.6380e-04,  4.6729e-04, -1.7946e-05, -1.5370e-04,\n",
            "        -2.1799e-05, -3.2815e-04, -2.8515e-04,  1.3056e-04, -2.5590e-04,\n",
            "         2.5693e-05,  4.0744e-04,  1.2114e-04, -1.7258e-04, -4.9125e-04,\n",
            "         1.9271e-04,  8.5239e-04,  1.6827e-04,  1.8572e-06,  2.5065e-04,\n",
            "         4.4163e-05, -1.9393e-04,  6.2786e-05, -4.3063e-06,  3.5790e-04,\n",
            "        -2.0956e-04, -4.7817e-04, -4.0161e-04, -2.0374e-04, -6.3210e-04,\n",
            "         3.9572e-08, -1.2266e-04,  1.2039e-04, -3.9995e-04, -6.2137e-04,\n",
            "         2.4441e-04, -5.9923e-04, -4.1335e-04,  4.1880e-04, -7.8917e-06,\n",
            "        -2.6800e-04,  2.3451e-04, -5.1140e-05, -8.0075e-05, -1.6695e-04,\n",
            "         1.5816e-04, -1.5622e-04, -2.7046e-04, -6.1554e-05,  1.5015e-04,\n",
            "         3.7595e-04, -2.7860e-04,  7.1687e-04,  2.2245e-04, -1.1312e-04,\n",
            "        -8.1893e-05,  3.9213e-04,  1.3048e-05, -1.9854e-04,  2.0145e-05,\n",
            "        -3.2396e-04,  1.4414e-05, -3.6019e-05,  1.6447e-04, -3.4174e-04,\n",
            "         5.4939e-04,  7.4436e-05, -5.5686e-04,  3.7392e-04,  9.4602e-05,\n",
            "        -6.0836e-04,  1.6552e-04,  6.6339e-04, -4.0071e-04,  2.5592e-04,\n",
            "         6.0145e-05, -3.7084e-05,  4.7911e-05,  2.8622e-04, -2.5705e-04,\n",
            "        -1.9836e-04,  3.0315e-04,  5.9192e-04,  3.1053e-05, -4.8579e-04,\n",
            "         2.5640e-04, -1.9071e-04, -1.0698e-04,  3.5883e-06, -2.3478e-04,\n",
            "         2.4009e-04, -2.2048e-04, -2.6207e-04,  5.9851e-05,  1.8159e-04,\n",
            "        -4.2697e-04,  2.5000e-04, -3.0163e-04,  1.1854e-04, -1.6301e-04,\n",
            "         3.5829e-05,  1.2326e-04, -1.1694e-05,  2.1409e-04,  9.5769e-05,\n",
            "        -4.4551e-04,  1.5368e-04, -2.8841e-05,  1.8706e-04, -3.8216e-04,\n",
            "         5.2789e-05,  6.6864e-05,  8.0551e-05,  7.8469e-04, -1.0112e-04,\n",
            "        -3.7388e-04, -2.8831e-04])), ('module.encoder_q.layer4.0.bn2.running_mean', tensor([-7.9739e-01,  8.9312e-02,  2.8137e-03, -1.9391e-01,  7.6446e-01,\n",
            "         6.1190e-01, -2.9199e-01, -2.1282e-01,  8.1026e-02, -5.6530e-01,\n",
            "         5.7587e-01, -3.3329e-01,  2.5163e-01,  5.1109e-01, -1.8823e-01,\n",
            "         1.6437e-01,  2.1401e-01,  5.9767e-01, -3.5903e-01, -5.3558e-01,\n",
            "        -1.2402e-01,  1.0077e-02, -1.2641e-02,  1.2579e-01, -1.7007e-01,\n",
            "         2.7799e-01,  6.7253e-02,  4.4211e-01, -5.0139e-01, -3.0587e-01,\n",
            "         6.7251e-01,  1.8130e-01, -2.3824e-02,  2.9283e-01,  4.2040e-01,\n",
            "         3.9324e-01, -6.2261e-02,  6.8524e-01, -8.6368e-03, -1.2712e+00,\n",
            "         7.6093e-01,  9.8882e-02,  7.1400e-01, -4.8997e-01,  9.2831e-02,\n",
            "        -8.4785e-02, -7.0118e-02,  9.4280e-01,  4.9749e-01, -4.7010e-01,\n",
            "        -4.5575e-01, -1.1100e-02, -1.9337e-01,  9.7891e-01, -1.4973e-01,\n",
            "         4.5029e-02,  5.6315e-01,  5.5550e-01,  8.4329e-02,  2.3771e-01,\n",
            "        -1.3673e-01,  3.7112e-01, -1.8167e-01,  2.7770e-01, -3.1766e-01,\n",
            "         2.2259e-02, -6.1499e-01,  8.1409e-01, -1.9540e-01,  2.5481e-01,\n",
            "        -7.1206e-01,  6.6343e-01,  2.5849e-01,  6.3117e-01, -2.7478e-02,\n",
            "         5.2089e-01,  1.9819e-01, -4.7977e-01,  1.2399e-01,  1.5189e-01,\n",
            "         7.1659e-01, -3.2182e-01,  1.2589e-01,  3.8370e-01, -1.5564e-01,\n",
            "         2.9925e-01,  3.0082e-01,  6.0360e-01,  9.3631e-02,  5.3833e-01,\n",
            "        -1.3650e-01, -6.7385e-01, -3.9556e-01, -4.2501e-01,  3.7542e-01,\n",
            "        -2.0735e-01,  7.3853e-02,  2.2099e-01, -1.5214e-01,  5.5622e-02,\n",
            "        -4.9736e-01,  6.4932e-01, -6.5689e-01,  7.9998e-02,  9.6929e-02,\n",
            "         1.2436e-01, -4.2457e-01, -5.9021e-01,  2.6758e-01,  2.7818e-01,\n",
            "        -1.9253e-01, -6.6798e-01,  3.0175e-01,  4.4875e-01,  2.6091e-01,\n",
            "         1.1169e-01,  5.2213e-01, -4.8442e-02,  2.8460e-01, -3.3643e-01,\n",
            "         2.7875e-01,  7.9098e-02,  2.8526e-01, -5.1328e-01, -6.3526e-01,\n",
            "        -1.9158e-01, -3.4399e-01, -3.5511e-01, -5.1342e-01, -7.9598e-01,\n",
            "         2.6431e-01,  3.7474e-01, -7.0281e-02,  1.6705e-01,  4.8033e-01,\n",
            "        -8.3217e-02,  2.1764e-01,  3.4458e-02,  1.2140e-01, -6.4433e-01,\n",
            "         3.4838e-01, -7.3984e-01,  4.2244e-01,  1.9703e-01,  3.4935e-01,\n",
            "         2.3527e-01,  6.5022e-01, -4.2144e-01, -1.9108e-01,  5.2237e-01,\n",
            "        -2.1116e-01, -2.6276e-01, -1.8216e-01,  4.3830e-01,  8.0231e-01,\n",
            "        -1.3909e-01,  5.0182e-01, -8.3232e-01, -1.6942e-01, -1.6380e-01,\n",
            "         8.6733e-01, -4.9737e-01,  2.3767e-01,  1.3869e-01,  4.1158e-01,\n",
            "         8.1010e-01,  7.8320e-01,  9.2921e-01,  2.4095e-02,  7.9236e-01,\n",
            "         1.7856e-01,  1.4076e-01, -4.8851e-01,  5.2131e-01, -3.7380e-01,\n",
            "        -1.2126e-01,  1.2459e+00,  2.5693e-02, -7.6285e-01,  1.9821e-01,\n",
            "         9.8482e-01, -2.8696e-01,  3.1650e-01, -1.1564e-01, -6.6944e-01,\n",
            "         1.7229e-01,  1.2508e-01,  6.6327e-01, -8.8832e-01, -6.3994e-01,\n",
            "        -9.2915e-02,  4.7926e-01, -9.1155e-02,  2.5575e-01,  1.0277e+00,\n",
            "        -2.2197e-01,  1.0878e-01, -4.5428e-01,  4.9531e-01,  2.9610e-01,\n",
            "        -1.0623e-01,  5.6064e-02,  4.5084e-01,  9.4431e-01, -4.5404e-01,\n",
            "         4.4753e-01, -3.2886e-01, -3.0768e-01, -5.2788e-01, -1.7258e-01,\n",
            "         2.6422e-01, -5.5068e-01, -3.3340e-01,  6.0177e-01, -3.1856e-01,\n",
            "         7.3723e-02, -2.5150e-01,  2.0590e-02,  3.5116e-01, -6.4802e-01,\n",
            "        -7.0938e-04,  1.0024e-01,  3.4631e-02,  1.0653e-01, -4.9594e-01,\n",
            "        -1.5450e-01,  1.6370e-01,  8.5595e-02, -5.9424e-01,  3.4534e-01,\n",
            "        -1.8006e-01, -3.7324e-01, -2.7396e-01,  2.3599e-01,  6.1503e-01,\n",
            "        -5.7820e-01, -3.9182e-01,  9.3796e-01,  4.5867e-01,  9.4570e-02,\n",
            "         2.1739e-01, -8.3056e-02, -3.2938e-01, -2.1462e-01,  4.4288e-01,\n",
            "        -6.3122e-01,  2.6867e-01, -2.5002e-01,  2.5052e-01, -3.4004e-02,\n",
            "         4.0661e-01, -2.6192e-02, -3.9693e-01,  1.1464e-01,  1.0602e+00,\n",
            "         2.8657e-01,  5.4260e-02, -6.6078e-01, -4.5007e-01,  7.7819e-01,\n",
            "         4.3328e-01, -1.6917e-01, -7.6843e-01, -2.0997e-02, -2.6762e-01,\n",
            "         7.7102e-01,  1.8334e-01,  3.7017e-01, -6.5135e-01,  1.9943e-01,\n",
            "        -2.9272e-01,  7.3164e-01,  3.6208e-01, -2.6170e-01,  9.3098e-01,\n",
            "        -9.3021e-01, -3.0251e-01, -2.3437e-01,  1.9993e-01, -6.2748e-01,\n",
            "         7.5429e-01, -5.5089e-01,  1.9502e-01,  2.6894e-01,  5.2819e-01,\n",
            "         1.6664e-01,  1.0502e-01, -3.5792e-01, -1.3410e-01,  5.1533e-01,\n",
            "        -9.0287e-02,  5.3519e-01, -1.8142e-01,  4.2808e-01, -2.8572e-01,\n",
            "        -6.2273e-01, -9.8616e-02, -7.0833e-01, -4.5980e-01,  6.0317e-01,\n",
            "        -3.7939e-01,  9.0239e-02,  4.4291e-01,  3.1738e-03, -5.7116e-01,\n",
            "         4.3771e-01,  3.5064e-01,  3.8276e-01, -4.2839e-02, -2.5403e-01,\n",
            "        -7.1964e-01, -3.8920e-01, -1.1522e-01,  5.3961e-01, -3.9407e-01,\n",
            "         6.2374e-01, -2.3843e-02,  2.7829e-01,  3.2439e-01, -4.2798e-01,\n",
            "         9.6163e-01, -3.3309e-01, -9.4920e-01,  5.8890e-01,  2.1485e-01,\n",
            "         4.8435e-01, -4.3557e-02,  4.9898e-01,  1.7196e-01, -1.9769e-01,\n",
            "         5.7018e-02,  2.6949e-01,  6.3580e-02,  6.4227e-01,  5.0049e-01,\n",
            "         8.5015e-01,  6.1561e-01, -2.1878e-01, -4.1076e-01,  2.0603e-01,\n",
            "        -5.4053e-01,  7.5426e-02,  3.7774e-01, -3.0044e-01, -2.0756e-02,\n",
            "         4.1102e-01,  1.1652e-01, -9.2555e-02, -1.1549e+00,  8.1542e-01,\n",
            "         5.1628e-01, -2.9008e-02, -5.3143e-01, -1.9366e-01, -7.9856e-02,\n",
            "         1.5167e-02,  4.7531e-01,  1.7700e-01, -1.3868e-02,  3.0729e-01,\n",
            "         3.5919e-01, -1.8208e-01, -2.7134e-01,  1.2789e-01,  4.1325e-01,\n",
            "        -2.3704e-01,  2.7936e-01, -1.1576e+00,  2.6946e-01,  8.7293e-02,\n",
            "        -4.6007e-01, -1.5763e-01,  8.5469e-02,  3.3713e-01, -2.3769e-01,\n",
            "        -5.4819e-01,  5.7054e-01, -6.1743e-02, -3.5730e-01,  2.9253e-01,\n",
            "        -4.6984e-01, -6.7770e-01, -2.3638e-01,  4.1826e-01, -1.2493e-02,\n",
            "        -6.8408e-01, -1.2485e-01,  6.9510e-02, -9.3863e-02,  6.1282e-01,\n",
            "        -9.6464e-04,  1.1066e+00,  9.9838e-01,  5.7015e-01, -1.0058e-01,\n",
            "         3.6686e-01, -1.9763e-02, -7.6666e-01,  7.6080e-01,  5.7432e-01,\n",
            "        -1.9256e-01, -9.3078e-02, -6.2306e-01,  2.8132e-01,  8.1261e-02,\n",
            "        -1.8065e-01, -2.4300e-01, -1.4332e-01, -5.5818e-02,  6.0754e-01,\n",
            "         2.8791e-01, -2.4094e-01, -5.1826e-01,  3.1458e-01,  1.6310e-01,\n",
            "         3.2202e-01,  5.2102e-02, -2.4798e-01,  5.7040e-02,  3.5829e-01,\n",
            "         2.2601e-01,  7.3194e-02,  3.5136e-01, -4.1043e-01,  1.8499e-01,\n",
            "        -2.9594e-01,  4.1850e-01,  1.0331e-01,  7.6467e-01,  4.5761e-02,\n",
            "         7.6199e-01, -3.9870e-01,  2.4875e-01,  1.3369e-01, -1.6738e-01,\n",
            "         8.7610e-01,  7.1611e-01,  3.7233e-02,  2.2434e-01,  3.4315e-01,\n",
            "        -5.4350e-01,  9.0697e-01, -8.8320e-02, -4.2675e-02, -9.9547e-02,\n",
            "        -7.0919e-01,  1.8256e-01, -5.7506e-02,  4.8128e-01,  7.4801e-01,\n",
            "         3.6618e-02, -5.9744e-01,  1.7606e-01, -6.0555e-01, -7.0598e-01,\n",
            "         1.4337e-01,  3.1695e-01,  3.8840e-04, -9.4784e-02, -3.4126e-01,\n",
            "        -2.2710e-01,  6.4841e-01, -1.3988e-01,  6.7671e-01, -3.8643e-01,\n",
            "        -1.2901e-01, -3.8179e-01, -1.8047e-01, -1.6293e-01,  2.7378e-01,\n",
            "         2.0086e-01, -8.5067e-02,  1.5552e-01, -2.1481e-02,  6.0146e-01,\n",
            "         6.6141e-01,  5.7436e-01,  2.5001e-01,  8.4377e-01, -2.1418e-01,\n",
            "        -4.6544e-01, -1.1038e-01, -5.3542e-02, -2.0717e-01, -9.4231e-01,\n",
            "        -2.3135e-01, -5.5577e-02, -3.1262e-01,  5.7540e-01, -8.6931e-01,\n",
            "        -2.4511e-02,  5.2247e-01,  1.8529e-01,  1.6651e-01, -7.2131e-01,\n",
            "        -1.1226e+00, -3.6974e-01, -4.1545e-01, -5.6623e-01,  3.8833e-01,\n",
            "        -2.9489e-01,  1.7866e-01, -2.8605e-01,  3.8756e-01, -2.3934e-01,\n",
            "        -1.7871e-01, -4.5455e-01,  3.7006e-02,  4.3043e-01, -4.7441e-01,\n",
            "         2.3825e-01,  2.2897e-01])), ('module.encoder_q.layer4.0.bn2.running_var', tensor([1.5994, 0.5070, 0.5012, 0.5653, 1.1202, 0.7909, 0.5665, 0.7963, 0.6526,\n",
            "        0.5630, 0.4938, 0.5716, 0.7612, 0.5890, 0.5299, 0.4908, 0.5131, 1.3054,\n",
            "        1.0254, 0.8207, 0.8404, 0.7920, 0.6229, 0.5802, 0.5898, 0.6174, 0.5517,\n",
            "        1.0215, 1.3710, 1.1451, 0.8332, 0.6392, 0.7425, 0.5641, 0.6483, 0.5410,\n",
            "        1.0361, 0.9902, 0.7283, 1.2684, 0.8331, 1.4150, 1.1403, 1.0543, 0.5146,\n",
            "        1.0235, 0.7768, 0.7205, 0.8002, 1.2202, 1.0145, 0.5821, 0.7107, 0.8533,\n",
            "        0.5906, 0.5940, 1.1778, 0.6857, 0.7080, 0.8740, 0.4999, 1.0522, 0.5986,\n",
            "        0.5523, 1.1018, 0.8805, 1.3993, 0.7101, 0.8969, 0.6258, 0.6411, 2.1013,\n",
            "        0.5598, 0.6350, 0.4772, 0.5394, 0.5172, 0.4987, 0.6187, 0.6083, 2.0959,\n",
            "        1.1695, 0.5576, 0.8424, 1.1682, 0.5363, 0.5269, 0.5386, 0.6529, 0.8606,\n",
            "        0.7853, 0.5214, 1.0259, 0.8202, 0.7885, 0.7143, 0.5008, 0.5757, 0.5423,\n",
            "        0.7048, 1.1686, 0.9118, 0.7780, 0.4628, 0.5356, 0.8666, 0.5837, 0.8933,\n",
            "        0.6529, 0.7174, 0.5443, 0.8156, 0.6396, 0.6482, 0.6652, 0.6123, 0.9121,\n",
            "        1.0714, 0.5716, 0.7939, 0.5983, 0.6206, 0.9083, 0.8763, 0.7239, 0.8124,\n",
            "        0.5893, 0.5717, 0.5957, 1.2614, 1.5720, 0.6705, 0.6620, 0.5651, 0.8703,\n",
            "        0.8247, 1.1173, 0.7756, 0.6716, 0.7999, 0.7029, 0.7979, 0.6004, 0.5047,\n",
            "        0.9536, 1.2927, 2.4222, 0.4796, 0.9950, 0.6280, 0.6552, 0.8635, 1.0250,\n",
            "        1.6959, 1.0397, 1.2387, 1.1316, 1.9628, 0.4749, 0.6068, 0.7572, 1.1448,\n",
            "        0.4839, 0.5256, 0.8785, 0.7198, 1.1106, 0.9561, 0.7683, 1.5039, 0.6475,\n",
            "        0.6842, 0.5666, 0.7084, 1.2517, 0.5260, 1.1999, 1.4124, 1.5092, 0.9961,\n",
            "        1.4122, 0.5857, 0.7200, 0.4882, 1.0217, 0.4901, 0.5528, 0.5477, 1.1013,\n",
            "        1.4598, 0.6429, 0.7410, 1.1718, 0.7308, 1.0833, 0.7682, 0.7426, 0.5137,\n",
            "        1.2155, 1.7598, 0.4643, 0.7341, 0.6798, 0.9055, 0.5111, 0.6685, 1.8113,\n",
            "        1.0265, 0.5986, 1.4688, 1.0480, 0.6267, 0.8680, 0.9077, 0.7354, 0.5790,\n",
            "        0.6757, 0.4705, 1.0275, 0.6601, 0.7934, 0.5523, 0.6794, 0.7117, 0.6861,\n",
            "        0.5107, 0.9846, 0.9499, 1.3366, 0.7902, 0.5547, 0.6461, 0.6649, 0.5581,\n",
            "        0.9837, 0.6489, 0.6351, 2.3236, 1.4526, 0.5568, 0.7614, 0.6411, 0.5177,\n",
            "        0.9150, 0.6287, 0.9352, 0.8206, 0.6187, 0.4551, 0.5719, 0.5406, 1.6009,\n",
            "        0.5917, 0.5335, 2.2760, 0.7280, 1.1452, 0.5800, 0.5004, 2.0758, 0.5545,\n",
            "        0.6333, 0.8295, 0.8416, 0.6809, 0.7939, 0.8590, 0.5440, 0.7363, 0.5495,\n",
            "        1.2236, 1.2269, 0.5373, 0.4517, 0.8746, 1.1092, 0.9857, 0.5465, 0.5314,\n",
            "        2.5621, 1.0085, 1.4320, 0.6282, 0.9364, 1.4432, 0.5365, 0.4908, 0.6013,\n",
            "        0.5551, 0.8937, 0.5644, 0.4800, 1.0066, 0.5415, 0.6412, 1.2237, 0.5320,\n",
            "        0.7006, 0.8703, 1.3302, 0.6250, 0.6553, 0.8872, 1.0279, 0.6919, 0.5885,\n",
            "        1.1973, 0.5530, 0.4904, 0.8644, 1.2463, 0.5515, 0.6360, 0.6190, 1.0199,\n",
            "        1.2015, 0.9012, 1.0766, 2.1612, 0.7599, 1.4163, 1.3172, 0.9827, 1.0085,\n",
            "        0.6480, 0.4760, 0.4898, 0.8176, 0.5743, 0.8737, 0.6758, 0.5004, 0.5814,\n",
            "        0.5898, 0.4585, 1.4435, 0.6819, 0.5224, 0.8636, 0.6934, 0.7412, 0.5691,\n",
            "        0.6650, 0.5700, 0.6540, 1.1468, 0.9976, 0.6374, 1.5467, 1.0213, 1.2921,\n",
            "        0.6103, 0.8462, 0.7230, 0.5871, 0.4677, 0.6314, 0.4656, 0.5531, 0.5906,\n",
            "        1.0847, 0.6843, 0.8134, 0.6250, 0.6511, 0.9563, 1.1871, 2.2177, 0.8079,\n",
            "        0.6504, 0.9134, 0.6753, 0.5158, 0.5102, 1.0707, 0.5928, 0.7052, 0.8590,\n",
            "        0.7328, 0.5035, 0.7540, 1.7786, 0.6101, 0.8539, 0.4610, 1.1038, 0.5319,\n",
            "        0.6381, 0.5305, 0.7463, 0.6101, 1.4558, 2.1692, 0.6182, 0.4921, 0.8891,\n",
            "        0.5474, 1.1824, 1.8482, 0.7577, 0.5311, 1.2725, 0.6411, 0.7424, 1.1204,\n",
            "        0.5741, 0.7649, 0.9645, 0.5629, 0.8821, 0.6246, 1.0413, 1.6332, 0.5444,\n",
            "        0.9073, 0.8583, 0.6582, 0.8998, 0.6555, 0.8402, 0.5547, 0.5461, 0.7706,\n",
            "        0.5299, 0.5582, 1.4247, 0.6065, 0.8373, 0.6988, 0.6122, 0.9727, 1.0068,\n",
            "        0.5900, 0.6200, 0.6958, 1.5209, 0.6261, 0.5084, 0.5079, 0.5963, 0.6764,\n",
            "        0.7673, 0.4733, 0.5657, 0.7852, 0.8205, 0.6563, 0.5743, 0.8387, 0.8277,\n",
            "        0.9475, 0.6169, 0.5499, 0.4441, 1.2419, 1.0064, 0.5117, 1.1152, 0.5441,\n",
            "        0.5704, 0.5009, 0.8012, 0.5743, 0.9651, 0.6734, 0.7901, 0.4872, 1.0058,\n",
            "        0.6386, 0.8638, 0.5274, 0.5739, 0.5465, 0.5122, 0.5897, 0.5957, 0.8064,\n",
            "        0.6114, 1.2530, 0.4550, 1.5246, 0.4797, 0.5016, 0.5296, 2.3028, 0.7074,\n",
            "        0.7849, 0.6068, 0.5119, 0.8120, 0.4666, 0.8143, 0.6378, 0.7505, 1.2361,\n",
            "        1.1131, 0.7108, 0.5449, 0.6722, 0.8606, 0.7232, 1.0013, 0.6007, 1.6347,\n",
            "        0.5989, 0.5227, 0.5031, 0.6180, 1.2483, 2.0512, 0.4487, 0.6032])), ('module.encoder_q.layer4.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.0.conv3.weight', tensor([[[[ 0.0158]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[ 0.0357]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0438]],\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         [[ 0.0134]]],\n",
            "\n",
            "\n",
            "        [[[-0.0201]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         [[-0.0443]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0233]],\n",
            "\n",
            "         [[-0.0157]],\n",
            "\n",
            "         [[ 0.0264]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0274]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[-0.0747]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0250]],\n",
            "\n",
            "         [[-0.0183]],\n",
            "\n",
            "         [[-0.0292]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0100]],\n",
            "\n",
            "         [[-0.0097]],\n",
            "\n",
            "         [[-0.0354]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0096]],\n",
            "\n",
            "         [[ 0.0426]],\n",
            "\n",
            "         [[-0.0480]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0117]],\n",
            "\n",
            "         [[-0.0365]],\n",
            "\n",
            "         [[-0.0420]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0176]],\n",
            "\n",
            "         [[-0.0001]],\n",
            "\n",
            "         [[-0.0104]]],\n",
            "\n",
            "\n",
            "        [[[-0.0057]],\n",
            "\n",
            "         [[-0.0051]],\n",
            "\n",
            "         [[ 0.0563]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0059]],\n",
            "\n",
            "         [[ 0.0320]],\n",
            "\n",
            "         [[-0.0146]]]])), ('module.encoder_q.layer4.0.bn3.weight', tensor([0.9924, 0.9924, 0.9923,  ..., 0.9921, 0.9922, 0.9924])), ('module.encoder_q.layer4.0.bn3.bias', tensor([ 1.8082e-04,  3.5653e-05,  3.1938e-04,  ..., -3.7338e-04,\n",
            "        -5.1811e-05, -4.6567e-05])), ('module.encoder_q.layer4.0.bn3.running_mean', tensor([ 0.3440,  0.0521,  0.1271,  ...,  0.0065, -0.1740,  0.1049])), ('module.encoder_q.layer4.0.bn3.running_var', tensor([0.1235, 0.1768, 0.2147,  ..., 0.1382, 0.1512, 0.1351])), ('module.encoder_q.layer4.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.0.downsample.0.weight', tensor([[[[-0.0092]],\n",
            "\n",
            "         [[ 0.0398]],\n",
            "\n",
            "         [[-0.0040]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0229]],\n",
            "\n",
            "         [[-0.0216]],\n",
            "\n",
            "         [[ 0.0301]]],\n",
            "\n",
            "\n",
            "        [[[-0.0107]],\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[ 0.0124]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0257]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         [[ 0.0578]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0094]],\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         [[-0.0019]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0161]],\n",
            "\n",
            "         [[ 0.0114]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0108]],\n",
            "\n",
            "         [[ 0.0107]],\n",
            "\n",
            "         [[ 0.0005]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0106]],\n",
            "\n",
            "         [[ 0.0208]],\n",
            "\n",
            "         [[-0.0380]]],\n",
            "\n",
            "\n",
            "        [[[-0.0085]],\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0554]],\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[-0.0075]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0495]],\n",
            "\n",
            "         [[-0.0128]],\n",
            "\n",
            "         [[-0.0125]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0070]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[ 0.0187]]]])), ('module.encoder_q.layer4.0.downsample.1.weight', tensor([0.9923, 0.9922, 0.9923,  ..., 0.9921, 0.9921, 0.9922])), ('module.encoder_q.layer4.0.downsample.1.bias', tensor([ 1.8082e-04,  3.5653e-05,  3.1938e-04,  ..., -3.7338e-04,\n",
            "        -5.1811e-05, -4.6567e-05])), ('module.encoder_q.layer4.0.downsample.1.running_mean', tensor([-0.3151,  0.7141, -0.2049,  ...,  0.9067,  1.1441,  0.3655])), ('module.encoder_q.layer4.0.downsample.1.running_var', tensor([2.3751, 2.8124, 2.2774,  ..., 2.4789, 1.8253, 1.7981])), ('module.encoder_q.layer4.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.1.conv1.weight', tensor([[[[ 0.1067]],\n",
            "\n",
            "         [[-0.0202]],\n",
            "\n",
            "         [[-0.0365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0533]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         [[-0.0783]]],\n",
            "\n",
            "\n",
            "        [[[-0.0635]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         [[ 0.1183]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1622]],\n",
            "\n",
            "         [[-0.0334]],\n",
            "\n",
            "         [[-0.1331]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0062]],\n",
            "\n",
            "         [[ 0.0587]],\n",
            "\n",
            "         [[ 0.0980]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0336]],\n",
            "\n",
            "         [[ 0.0676]],\n",
            "\n",
            "         [[-0.0237]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0539]],\n",
            "\n",
            "         [[ 0.0597]],\n",
            "\n",
            "         [[-0.0643]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0876]],\n",
            "\n",
            "         [[ 0.0783]],\n",
            "\n",
            "         [[ 0.1144]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0114]],\n",
            "\n",
            "         [[-0.0770]],\n",
            "\n",
            "         [[-0.0679]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0410]],\n",
            "\n",
            "         [[ 0.0039]],\n",
            "\n",
            "         [[-0.0701]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0064]],\n",
            "\n",
            "         [[ 0.0448]],\n",
            "\n",
            "         [[-0.0338]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0137]],\n",
            "\n",
            "         [[-0.0370]],\n",
            "\n",
            "         [[-0.0739]]]])), ('module.encoder_q.layer4.1.bn1.weight', tensor([0.9920, 0.9921, 0.9923, 0.9928, 0.9923, 0.9927, 0.9925, 0.9919, 0.9924,\n",
            "        0.9923, 0.9917, 0.9935, 0.9918, 0.9923, 0.9922, 0.9922, 0.9922, 0.9926,\n",
            "        0.9919, 0.9923, 0.9923, 0.9925, 0.9923, 0.9922, 0.9921, 0.9920, 0.9921,\n",
            "        0.9921, 0.9923, 0.9923, 0.9920, 0.9922, 0.9921, 0.9920, 0.9923, 0.9922,\n",
            "        0.9922, 0.9923, 0.9922, 0.9921, 0.9916, 0.9924, 0.9923, 0.9925, 0.9920,\n",
            "        0.9925, 0.9921, 0.9921, 0.9928, 0.9924, 0.9921, 0.9921, 0.9925, 0.9919,\n",
            "        0.9923, 0.9926, 0.9925, 0.9922, 0.9924, 0.9925, 0.9924, 0.9924, 0.9926,\n",
            "        0.9921, 0.9921, 0.9925, 0.9923, 0.9925, 0.9923, 0.9925, 0.9924, 0.9921,\n",
            "        0.9922, 0.9918, 0.9923, 0.9923, 0.9924, 0.9921, 0.9923, 0.9918, 0.9920,\n",
            "        0.9926, 0.9919, 0.9922, 0.9920, 0.9924, 0.9925, 0.9921, 0.9922, 0.9919,\n",
            "        0.9927, 0.9924, 0.9923, 0.9921, 0.9915, 0.9923, 0.9922, 0.9931, 0.9920,\n",
            "        0.9925, 0.9925, 0.9925, 0.9925, 0.9922, 0.9920, 0.9924, 0.9928, 0.9919,\n",
            "        0.9922, 0.9923, 0.9923, 0.9925, 0.9918, 0.9927, 0.9921, 0.9917, 0.9919,\n",
            "        0.9925, 0.9922, 0.9919, 0.9925, 0.9924, 0.9923, 0.9929, 0.9920, 0.9921,\n",
            "        0.9922, 0.9919, 0.9924, 0.9922, 0.9922, 0.9923, 0.9924, 0.9921, 0.9920,\n",
            "        0.9926, 0.9922, 0.9918, 0.9921, 0.9923, 0.9924, 0.9922, 0.9927, 0.9923,\n",
            "        0.9923, 0.9922, 0.9922, 0.9923, 0.9921, 0.9919, 0.9925, 0.9920, 0.9926,\n",
            "        0.9923, 0.9921, 0.9922, 0.9923, 0.9926, 0.9920, 0.9924, 0.9919, 0.9927,\n",
            "        0.9924, 0.9921, 0.9922, 0.9921, 0.9920, 0.9921, 0.9921, 0.9931, 0.9924,\n",
            "        0.9925, 0.9920, 0.9924, 0.9921, 0.9924, 0.9922, 0.9922, 0.9915, 0.9924,\n",
            "        0.9925, 0.9922, 0.9921, 0.9921, 0.9920, 0.9921, 0.9921, 0.9928, 0.9921,\n",
            "        0.9922, 0.9923, 0.9917, 0.9925, 0.9921, 0.9924, 0.9922, 0.9924, 0.9918,\n",
            "        0.9921, 0.9924, 0.9928, 0.9921, 0.9917, 0.9924, 0.9922, 0.9925, 0.9921,\n",
            "        0.9924, 0.9921, 0.9923, 0.9921, 0.9922, 0.9922, 0.9922, 0.9920, 0.9916,\n",
            "        0.9921, 0.9921, 0.9918, 0.9921, 0.9923, 0.9920, 0.9925, 0.9928, 0.9928,\n",
            "        0.9923, 0.9922, 0.9920, 0.9927, 0.9918, 0.9917, 0.9933, 0.9923, 0.9922,\n",
            "        0.9921, 0.9923, 0.9922, 0.9924, 0.9922, 0.9922, 0.9923, 0.9923, 0.9922,\n",
            "        0.9920, 0.9921, 0.9918, 0.9923, 0.9925, 0.9923, 0.9928, 0.9922, 0.9919,\n",
            "        0.9918, 0.9915, 0.9929, 0.9926, 0.9918, 0.9920, 0.9925, 0.9923, 0.9925,\n",
            "        0.9924, 0.9923, 0.9924, 0.9926, 0.9923, 0.9921, 0.9924, 0.9924, 0.9927,\n",
            "        0.9921, 0.9924, 0.9926, 0.9924, 0.9925, 0.9924, 0.9923, 0.9923, 0.9920,\n",
            "        0.9924, 0.9923, 0.9924, 0.9922, 0.9926, 0.9923, 0.9924, 0.9928, 0.9924,\n",
            "        0.9917, 0.9922, 0.9921, 0.9925, 0.9922, 0.9925, 0.9928, 0.9924, 0.9923,\n",
            "        0.9928, 0.9920, 0.9928, 0.9919, 0.9927, 0.9924, 0.9922, 0.9924, 0.9920,\n",
            "        0.9921, 0.9925, 0.9921, 0.9923, 0.9922, 0.9921, 0.9921, 0.9923, 0.9921,\n",
            "        0.9925, 0.9921, 0.9924, 0.9921, 0.9922, 0.9924, 0.9922, 0.9923, 0.9919,\n",
            "        0.9924, 0.9918, 0.9921, 0.9922, 0.9922, 0.9921, 0.9923, 0.9923, 0.9922,\n",
            "        0.9922, 0.9926, 0.9920, 0.9920, 0.9921, 0.9923, 0.9923, 0.9919, 0.9927,\n",
            "        0.9918, 0.9925, 0.9925, 0.9922, 0.9924, 0.9922, 0.9921, 0.9924, 0.9918,\n",
            "        0.9922, 0.9928, 0.9924, 0.9922, 0.9925, 0.9926, 0.9920, 0.9926, 0.9920,\n",
            "        0.9922, 0.9920, 0.9919, 0.9923, 0.9925, 0.9920, 0.9925, 0.9926, 0.9928,\n",
            "        0.9924, 0.9925, 0.9921, 0.9930, 0.9926, 0.9921, 0.9923, 0.9925, 0.9923,\n",
            "        0.9925, 0.9918, 0.9920, 0.9923, 0.9923, 0.9920, 0.9921, 0.9921, 0.9923,\n",
            "        0.9919, 0.9922, 0.9927, 0.9921, 0.9925, 0.9922, 0.9923, 0.9920, 0.9925,\n",
            "        0.9927, 0.9922, 0.9922, 0.9919, 0.9922, 0.9925, 0.9923, 0.9922, 0.9918,\n",
            "        0.9924, 0.9928, 0.9920, 0.9922, 0.9923, 0.9925, 0.9920, 0.9924, 0.9923,\n",
            "        0.9922, 0.9926, 0.9924, 0.9922, 0.9920, 0.9923, 0.9926, 0.9922, 0.9922,\n",
            "        0.9918, 0.9921, 0.9918, 0.9919, 0.9923, 0.9922, 0.9922, 0.9922, 0.9927,\n",
            "        0.9922, 0.9919, 0.9922, 0.9925, 0.9924, 0.9922, 0.9918, 0.9921, 0.9925,\n",
            "        0.9924, 0.9923, 0.9921, 0.9927, 0.9922, 0.9920, 0.9922, 0.9922, 0.9925,\n",
            "        0.9922, 0.9923, 0.9923, 0.9921, 0.9922, 0.9923, 0.9933, 0.9925, 0.9921,\n",
            "        0.9923, 0.9920, 0.9919, 0.9919, 0.9925, 0.9921, 0.9923, 0.9921, 0.9922,\n",
            "        0.9928, 0.9921, 0.9918, 0.9923, 0.9930, 0.9922, 0.9926, 0.9922, 0.9921,\n",
            "        0.9927, 0.9919, 0.9920, 0.9923, 0.9921, 0.9920, 0.9922, 0.9921, 0.9922,\n",
            "        0.9920, 0.9922, 0.9921, 0.9921, 0.9921, 0.9918, 0.9923, 0.9922, 0.9928,\n",
            "        0.9925, 0.9924, 0.9924, 0.9924, 0.9932, 0.9921, 0.9921, 0.9925, 0.9924,\n",
            "        0.9923, 0.9919, 0.9923, 0.9920, 0.9919, 0.9930, 0.9921, 0.9917])), ('module.encoder_q.layer4.1.bn1.bias', tensor([-2.1458e-05, -1.5162e-04,  1.3314e-04,  5.1509e-04,  1.6148e-05,\n",
            "        -6.4934e-05,  1.3230e-04, -1.9507e-04,  9.9457e-05,  5.1055e-05,\n",
            "        -5.8805e-04,  1.3838e-03, -3.9118e-04, -9.3738e-05,  1.7408e-04,\n",
            "         1.5925e-04, -2.2249e-04,  4.9195e-04, -2.9144e-04,  5.1709e-04,\n",
            "        -1.5145e-04, -1.1024e-04,  7.0227e-05,  5.1246e-06, -7.1605e-05,\n",
            "        -2.3149e-04, -1.9777e-06, -4.6732e-05,  1.2113e-04,  1.0455e-04,\n",
            "        -3.2505e-04, -3.7458e-04, -2.1008e-04, -4.4024e-04, -1.2378e-04,\n",
            "         1.9006e-04, -4.1589e-04, -2.8895e-04, -1.2135e-04, -8.4135e-05,\n",
            "        -7.3196e-04, -1.4395e-04,  5.1215e-05,  2.6017e-04, -2.2035e-04,\n",
            "         1.4388e-04, -1.1334e-04, -3.8242e-04,  3.1700e-04,  3.5073e-04,\n",
            "         1.1567e-04, -1.1782e-04,  1.9495e-04, -3.8881e-04,  1.3531e-04,\n",
            "         1.7414e-04,  3.4018e-04, -2.2580e-04, -1.1335e-04,  1.6144e-04,\n",
            "         5.9651e-04,  1.0738e-04, -7.3646e-05, -5.2282e-05, -1.8714e-04,\n",
            "         9.7321e-05,  6.6943e-05,  1.7452e-04,  6.2692e-05,  1.4149e-04,\n",
            "        -9.8066e-05, -4.3647e-04, -5.0220e-05,  5.5651e-05,  2.6847e-04,\n",
            "         3.1211e-04,  1.6448e-04, -2.4644e-04,  1.1212e-04, -4.6657e-04,\n",
            "        -3.7667e-04,  2.6556e-04, -5.2385e-05, -7.7736e-05,  4.1316e-04,\n",
            "        -2.0924e-05,  2.0638e-04, -2.4850e-04,  1.0389e-04, -4.7672e-04,\n",
            "         1.8298e-04,  3.1867e-04,  3.5044e-04, -6.5536e-05, -4.5922e-04,\n",
            "         7.1979e-05, -1.3412e-04,  7.5620e-04, -3.8276e-04,  6.5680e-05,\n",
            "         1.7460e-04,  6.1455e-05, -6.8729e-05,  2.6103e-04, -3.0744e-04,\n",
            "         1.2578e-04,  3.3370e-04, -9.8191e-06,  1.5736e-04, -1.5634e-04,\n",
            "        -9.4767e-05,  1.1909e-04, -3.4843e-04,  2.1055e-04,  1.5906e-04,\n",
            "        -6.9461e-04, -2.3018e-04, -1.3651e-04, -1.6443e-04, -1.2253e-04,\n",
            "         1.5992e-04,  2.0903e-04, -1.5398e-04,  6.0103e-04, -4.4048e-04,\n",
            "        -1.4632e-04,  3.2690e-05, -2.7889e-04,  2.4770e-04,  1.9078e-04,\n",
            "        -3.3114e-04,  1.7064e-04,  2.3591e-04, -5.7525e-05, -3.7499e-05,\n",
            "         1.5589e-04,  7.0536e-05, -3.2491e-04, -9.1154e-05,  1.6033e-06,\n",
            "         2.3724e-04,  2.0930e-04,  4.2229e-04,  5.2685e-05, -2.4094e-04,\n",
            "        -3.2764e-04, -2.8427e-04,  2.5951e-04,  4.8458e-06, -4.0344e-05,\n",
            "         5.5753e-04, -3.3577e-04,  1.9331e-05,  1.1364e-04, -5.5938e-05,\n",
            "        -4.2509e-05,  4.0205e-04,  4.3511e-05, -3.8314e-04,  3.3316e-04,\n",
            "        -1.2651e-04, -1.9385e-05,  8.8392e-05, -4.0726e-04, -4.9584e-05,\n",
            "        -8.7060e-05, -3.3018e-04,  9.8756e-06, -1.7497e-04,  2.4491e-04,\n",
            "         3.0926e-04,  5.8036e-05, -2.4650e-04,  3.3069e-04,  7.4851e-06,\n",
            "         3.9086e-04, -9.3361e-05,  1.3334e-04, -4.2043e-04, -2.5471e-04,\n",
            "         3.3503e-04, -2.4108e-04, -1.6855e-06,  1.8479e-05, -3.1218e-04,\n",
            "        -1.0021e-04,  1.4167e-04,  4.3245e-04, -1.1820e-04,  8.4449e-05,\n",
            "         8.4201e-05, -2.1768e-04,  3.6108e-04, -3.7665e-05,  3.5275e-04,\n",
            "         4.0098e-04,  2.1585e-04, -3.1731e-04, -5.8447e-05,  1.2177e-04,\n",
            "         1.6039e-04, -4.0557e-04, -1.1484e-04,  5.7128e-05, -2.1684e-04,\n",
            "         5.5396e-05, -1.7739e-04,  2.7769e-04, -2.8764e-04,  9.8608e-06,\n",
            "         1.0409e-04, -4.7179e-05,  1.3208e-05, -2.5130e-04, -3.4266e-04,\n",
            "        -2.5833e-04, -1.7565e-04, -1.0148e-04, -3.1494e-04,  1.3747e-04,\n",
            "         2.7164e-04, -1.3061e-04,  2.0536e-04,  4.2691e-04,  3.5335e-04,\n",
            "        -2.3795e-04,  1.6087e-04, -2.4069e-04,  5.0496e-04,  1.0220e-04,\n",
            "        -3.2562e-04,  1.4028e-03, -6.3698e-05,  1.7676e-04, -5.5460e-05,\n",
            "        -1.4475e-04,  8.7911e-05,  1.8756e-04,  1.9405e-04,  4.5581e-04,\n",
            "        -2.9305e-05, -1.4128e-04, -2.5878e-04, -2.4325e-04, -1.3181e-05,\n",
            "        -1.7895e-04, -2.0306e-04,  4.5799e-04,  3.4655e-04,  3.9190e-04,\n",
            "        -1.2540e-04, -3.3400e-04,  1.2195e-04, -4.0435e-04,  3.0596e-04,\n",
            "         2.3522e-04, -8.5405e-05,  4.8702e-05,  1.2546e-04,  3.6666e-04,\n",
            "         5.4841e-07,  6.7352e-05,  1.4756e-04,  2.0345e-04,  3.5006e-04,\n",
            "        -8.0030e-05,  2.6287e-04, -9.2342e-05,  6.9732e-05,  1.6457e-04,\n",
            "        -9.8097e-06,  2.9538e-04,  5.6436e-06,  1.7530e-04, -2.2123e-04,\n",
            "         1.8432e-04, -1.1195e-04, -1.5559e-04, -2.5619e-04, -1.2404e-04,\n",
            "        -3.6031e-06,  8.1927e-05, -3.9466e-05,  2.0567e-04,  2.6550e-04,\n",
            "        -2.0847e-04,  3.9897e-04,  2.3873e-05, -8.1190e-05,  3.3747e-05,\n",
            "         1.3349e-04, -3.6736e-05, -1.9587e-04,  4.1309e-04,  5.0983e-04,\n",
            "         2.5335e-04, -1.9562e-04, -8.5503e-05, -2.5951e-04,  3.2737e-04,\n",
            "        -1.4908e-04,  9.2461e-05,  3.7629e-04, -1.1753e-05,  3.2627e-04,\n",
            "        -1.0756e-04, -1.4917e-04,  1.0267e-04, -1.5125e-04, -4.4763e-05,\n",
            "         4.4660e-05,  1.2509e-04,  2.4155e-05,  1.1791e-04, -2.7200e-04,\n",
            "        -1.2269e-05, -5.2078e-05,  2.6234e-04, -1.1611e-04,  2.6957e-04,\n",
            "        -6.8628e-05, -3.4139e-05, -8.3091e-06, -2.0823e-04,  3.0364e-06,\n",
            "         8.7372e-05, -6.3066e-05, -1.1808e-04, -1.0077e-04, -1.2942e-05,\n",
            "         3.2393e-04,  5.9109e-04, -7.7415e-05,  2.8233e-05,  2.3699e-04,\n",
            "        -7.6603e-05, -1.4292e-04,  1.0944e-04, -6.3544e-05,  1.7720e-04,\n",
            "        -4.1692e-04,  3.5946e-04, -4.3842e-04,  2.6162e-04, -2.1281e-04,\n",
            "        -1.1480e-04,  3.6556e-04,  1.6878e-04,  6.5044e-05,  1.0934e-04,\n",
            "        -3.3476e-04, -3.7125e-05,  2.5580e-04,  2.9412e-04, -1.2065e-04,\n",
            "         1.6552e-04,  3.1855e-04, -4.2101e-04,  9.8223e-05, -4.8137e-04,\n",
            "         2.2776e-04, -1.2064e-04,  4.2298e-05, -2.9311e-04, -1.8114e-04,\n",
            "        -4.0247e-04, -1.1709e-04,  2.0128e-04,  6.4322e-04,  2.1605e-05,\n",
            "        -1.2963e-04,  1.4722e-04,  5.5459e-04,  4.1231e-04, -2.3830e-04,\n",
            "        -7.7807e-05,  2.5355e-04,  1.2486e-04,  3.6908e-04,  7.1263e-05,\n",
            "        -4.2420e-04,  2.1168e-04, -1.4949e-04, -8.8819e-05, -2.2128e-04,\n",
            "        -4.6594e-05, -2.0913e-04, -1.6414e-04, -1.7959e-04,  1.9816e-04,\n",
            "         1.3371e-05,  1.7344e-04,  6.7712e-05, -3.3185e-05, -2.6317e-04,\n",
            "        -3.6706e-07,  5.5393e-04, -1.2737e-04, -1.0837e-05, -1.9473e-04,\n",
            "        -1.3159e-04,  3.1865e-04,  5.3171e-06,  5.9023e-05, -4.4776e-04,\n",
            "         2.2505e-04,  4.4696e-04, -3.2753e-04, -7.7854e-05, -6.0913e-06,\n",
            "         3.2532e-04, -2.0771e-04, -2.7503e-05,  7.6199e-05, -1.3913e-04,\n",
            "        -7.8612e-05, -9.4363e-06,  4.4727e-08, -2.8513e-04,  6.5777e-05,\n",
            "         2.7102e-04,  3.6501e-04,  8.4419e-05,  5.3356e-05,  1.5003e-04,\n",
            "        -3.1206e-04, -1.0588e-04,  1.2834e-04,  3.8937e-04,  1.2705e-04,\n",
            "        -5.0525e-05,  2.7212e-04, -1.4339e-04, -4.3532e-04, -2.9877e-04,\n",
            "        -2.4856e-05,  2.6528e-04, -1.0448e-04, -1.7776e-04, -2.0156e-04,\n",
            "         1.0884e-04, -1.2524e-04,  4.9844e-04, -2.8320e-04,  4.2675e-04,\n",
            "         2.3524e-05, -1.7968e-05,  1.8170e-04, -5.3164e-05,  2.3476e-04,\n",
            "        -7.1167e-05,  9.8605e-05,  3.2785e-05, -1.0650e-04, -7.9061e-05,\n",
            "         8.1715e-05,  1.5667e-03,  4.7327e-04, -1.3184e-04, -4.1115e-05,\n",
            "         9.8192e-05,  1.8727e-04, -5.7477e-04,  7.3539e-05, -1.1354e-04,\n",
            "        -2.3345e-04, -9.5496e-05,  7.8384e-05,  6.3719e-04, -3.3801e-04,\n",
            "        -1.1141e-04,  6.2181e-05,  3.0385e-04, -2.2579e-04,  2.4987e-04,\n",
            "         2.3260e-05, -2.2374e-04,  2.8145e-04, -2.1409e-04, -3.5971e-04,\n",
            "         5.7744e-05, -1.3553e-04, -2.3983e-04,  1.3227e-04, -3.4988e-04,\n",
            "         3.2195e-05,  6.3240e-05,  2.6792e-06, -3.9311e-04, -4.8487e-05,\n",
            "         3.3186e-05, -2.5533e-04, -3.3752e-05,  3.0235e-04,  7.6384e-04,\n",
            "        -1.3972e-04,  1.0128e-04, -9.4300e-05, -3.4659e-05,  1.0925e-03,\n",
            "        -3.1302e-04,  7.1858e-05,  9.3263e-05, -5.1542e-05,  5.1256e-04,\n",
            "        -5.9754e-05,  2.2925e-04,  3.4363e-05, -5.0026e-04,  4.8141e-04,\n",
            "        -1.0648e-04, -1.7429e-04])), ('module.encoder_q.layer4.1.bn1.running_mean', tensor([-0.9065, -0.6164, -2.1193,  0.7533, -1.1642,  0.3853,  0.7337, -1.3379,\n",
            "         0.8924,  0.3391,  1.3310,  1.2884,  2.5176, -0.7031,  0.3419,  0.9203,\n",
            "         2.0157,  2.4659,  0.1054, -3.2865, -2.9082, -0.5215, -1.1068,  0.6910,\n",
            "        -1.2861, -0.7001,  0.0359, -1.3254,  0.1501, -0.2389,  3.4316, -1.0282,\n",
            "        -0.7924, -1.6637,  1.2604, -0.4540, -0.1738,  0.8436,  1.3908,  0.2860,\n",
            "        -0.3073,  2.2491, -1.0506, -0.1055,  2.2938, -0.0653, -0.3571, -1.0772,\n",
            "        -0.9194,  0.1137, -0.2145,  1.3953,  1.4122,  0.5380,  2.8271,  2.7825,\n",
            "        -0.2206, -0.4007,  0.7367,  0.5680, -0.1982,  0.6253,  1.5401, -2.7878,\n",
            "         0.2733, -0.1648, -0.8172,  0.9478, -1.5920,  1.3498, -0.9768, -0.9085,\n",
            "         0.5876, -0.5894, -0.2514, -0.1116, -1.8637,  0.0751,  3.7751, -1.1436,\n",
            "         1.5672,  1.9991, -1.1029,  0.9186,  0.5119,  1.7094,  1.6425, -0.1261,\n",
            "        -1.8718,  1.4956,  1.1559, -2.1697, -1.1540, -0.5062,  1.0615,  0.4460,\n",
            "        -1.6431,  0.9973,  2.2232, -0.4646,  0.3439,  0.6222,  1.5556,  0.4398,\n",
            "        -1.5614,  0.3144,  0.5580, -1.0376, -2.6688, -1.9511, -1.0722, -0.8894,\n",
            "        -1.0202,  2.0793, -1.1689, -3.0238, -0.9905, -0.1081,  2.8371, -0.8176,\n",
            "        -0.1552, -2.1549,  0.3434, -0.5112,  0.3031, -2.1705, -1.2319, -0.8246,\n",
            "         0.7572, -0.5183, -0.3465, -0.1868,  1.1746,  0.8373,  0.1530,  1.3378,\n",
            "        -0.9623, -0.6948, -2.7806,  0.4027,  0.3816, -2.4739,  0.3401, -0.4744,\n",
            "         0.8516, -0.3294,  1.9950, -1.1716, -1.4416, -2.9305, -1.7142, -0.8045,\n",
            "         2.0181, -0.4380, -0.8160, -1.3235, -1.1117,  0.5640, -1.3176, -0.8065,\n",
            "        -0.2534,  0.2917, -0.6543, -0.7683, -1.9693,  0.8038, -1.8776, -1.6242,\n",
            "        -1.9821,  2.4474,  0.0761, -2.0658, -0.7955,  2.7360,  2.3929, -0.0293,\n",
            "        -1.1405, -1.9223, -0.8267, -3.0919,  0.8680,  1.2888, -2.3434,  0.0902,\n",
            "        -1.3380,  1.9104,  0.1209,  0.7154,  1.1907,  1.4010, -1.0522, -0.9694,\n",
            "        -2.1883, -0.3453, -0.0170, -1.2122, -0.0904,  0.6019, -0.6745,  0.0783,\n",
            "        -0.4042,  0.1672,  1.0544, -0.7281, -0.0041,  2.0502, -3.7702,  0.2814,\n",
            "        -0.2749,  1.3670, -1.1688,  1.5477,  0.1648, -0.2858,  1.9602,  2.0854,\n",
            "        -0.8754,  0.6594,  0.9386,  0.9086,  2.1137,  0.1796,  0.0081, -0.9911,\n",
            "        -0.7881,  2.5014,  0.7644,  0.0854,  0.1065, -0.0610,  0.3928,  0.0693,\n",
            "         0.7454,  0.8064, -0.5911,  1.3500,  0.1267, -1.4183, -1.3103,  2.3100,\n",
            "        -0.9991, -0.3884,  1.8205, -1.8343, -1.5290,  0.4322, -0.0550,  1.4093,\n",
            "         0.6400,  1.9912, -1.5899, -0.1562,  0.9395,  1.3231,  0.3413, -0.3534,\n",
            "        -1.2210, -0.3242, -0.6420, -0.8879,  0.0145,  1.7587,  0.9973, -1.5015,\n",
            "        -0.9269, -0.5233, -0.2063,  1.2183,  1.2647,  0.2600, -0.8796,  2.9550,\n",
            "        -0.1506,  0.1980,  1.0693, -2.3412, -0.2777,  2.6397,  0.2026,  0.1910,\n",
            "        -0.3150, -1.2463, -0.2201,  0.5480, -2.7396, -0.4217, -1.3843, -1.4515,\n",
            "        -0.7614,  1.3053,  1.1215,  0.9975,  0.8219, -1.3264, -0.8399,  1.0036,\n",
            "         0.3536,  1.2572,  1.2001,  0.4537,  0.4462, -0.4709,  1.1860,  0.2326,\n",
            "        -2.1208,  1.0723, -0.9944, -0.3791, -2.4745,  0.3637,  1.5013,  0.1967,\n",
            "         0.4229, -1.3758, -0.0501, -0.9954,  0.5135, -2.0951, -0.8689, -0.2257,\n",
            "         1.2760,  0.5169, -0.5898,  1.6087, -2.1510,  2.4595, -0.0486, -0.4020,\n",
            "        -1.0139,  3.3927,  1.1576,  0.7231, -1.9144, -1.3363, -1.6152, -0.9228,\n",
            "        -0.9036, -0.4190,  0.5814, -1.0480,  3.3726,  0.6567,  2.9914, -0.4628,\n",
            "         2.3709, -2.3758,  2.5070,  0.6402, -0.0091,  0.6542,  0.1591, -1.4228,\n",
            "         1.5962,  0.0723, -2.4686, -1.0295,  0.7549,  1.5161, -0.9280, -2.3907,\n",
            "        -0.0178,  0.1517,  0.6902,  0.8887,  0.4760,  1.1779, -1.4930, -0.7580,\n",
            "         0.3728,  1.0304,  0.4916,  0.2832,  1.4814,  0.3229, -0.5053, -0.2624,\n",
            "         1.9594, -1.2877,  0.9388,  1.6806, -1.4738, -0.9946,  1.4670, -1.9464,\n",
            "        -1.2076, -0.1413, -1.5671,  1.3365, -2.6347,  0.4140,  0.5281,  0.7678,\n",
            "         0.1632,  0.6332, -0.5587, -0.8442,  0.2085,  0.7563, -0.4223, -0.1281,\n",
            "        -3.2795,  0.4747, -0.7060, -1.3637, -1.6106,  1.1098,  1.1186, -1.4332,\n",
            "        -2.4361, -0.4906, -0.6856,  0.1184, -0.1676, -0.1690,  0.2772,  0.0736,\n",
            "         0.2473,  1.1872,  0.4590,  0.3442,  1.2890,  0.3887,  0.2495,  0.3627,\n",
            "        -1.9686, -0.2999,  0.0045,  1.9099,  0.9827,  2.2067,  2.9168, -2.1144,\n",
            "        -0.2799, -0.0107, -1.4393, -0.1029,  2.3917, -1.9971,  1.0917,  0.2036,\n",
            "         0.3315,  1.1525, -0.1902, -0.5130, -2.1401, -0.8342,  1.9764,  0.0866,\n",
            "        -0.9605,  1.6817, -1.6465,  1.2341, -0.2812,  0.3691, -0.4804, -0.8043,\n",
            "         1.8592, -3.4132, -0.5247, -1.7433, -0.1719,  1.1645, -1.8707, -2.5205,\n",
            "        -0.5666,  1.9443, -0.3048,  1.2565, -0.9662, -1.4263,  3.3071, -2.7402,\n",
            "        -0.9768, -0.6360, -0.1495, -3.7966, -1.1751,  3.1617, -0.3767,  0.7493,\n",
            "         0.4670,  0.5323, -0.5353,  0.7799, -1.5533,  0.4370, -0.6104,  1.6544,\n",
            "         1.1899, -0.1382,  0.9030, -0.4425, -1.0558, -0.9406,  0.9251,  1.4076,\n",
            "         2.0591,  0.7141, -0.2086, -0.7766,  0.6044, -0.6743,  0.1480, -2.0495,\n",
            "         1.2685,  2.0244,  0.3737,  2.7306, -0.1204, -0.2709,  1.7939,  2.0018])), ('module.encoder_q.layer4.1.bn1.running_var', tensor([ 4.5080,  4.8217,  6.6198,  6.2524,  5.0119,  5.4192,  6.3863,  8.4521,\n",
            "         4.9536,  4.7694,  7.7610,  5.2128, 12.0202,  5.7283,  4.8496,  3.8735,\n",
            "         5.3883,  7.9432,  8.0410, 12.1133,  7.2777,  5.2401, 10.2058,  4.5839,\n",
            "         4.3459,  6.6454,  5.0200,  4.1351,  4.6782,  5.0307,  6.2960,  5.4864,\n",
            "         8.0235,  5.0936,  4.2536,  4.1997,  4.9245,  5.3524,  9.1355,  4.4083,\n",
            "         4.5252,  5.8412, 14.0843,  4.1090,  4.9511,  4.6573,  4.3808,  4.7828,\n",
            "         4.2552,  5.7329,  4.1857,  5.8964,  4.7256,  5.3490, 10.6784,  8.5024,\n",
            "         4.6912,  5.2695,  5.0831,  4.2236,  5.4761,  4.6318,  8.0776,  5.2730,\n",
            "         5.6072,  4.8112,  4.5696,  6.2934,  7.1696,  4.4434,  4.9455,  4.3936,\n",
            "         4.3428,  4.4337,  4.7016,  7.9849,  4.3405,  4.1490,  9.7341,  5.1983,\n",
            "         6.2765,  8.3255,  7.0217,  5.4752,  4.4137,  4.6840,  7.4702,  7.8891,\n",
            "         8.0020,  8.8372,  4.1808, 11.2476,  5.1927,  5.8969,  4.2339,  5.9207,\n",
            "         4.2768,  6.4165,  5.5429,  4.0587,  4.3910,  8.8958,  9.2070,  5.7242,\n",
            "         5.3426,  4.8915,  4.3810,  4.2527,  7.5408,  8.4979,  4.1345,  4.1442,\n",
            "         7.2905,  4.2524,  4.3197,  7.0319,  4.5219,  4.5171,  8.1299,  4.8623,\n",
            "         5.0062, 10.4880,  9.1245,  4.5928,  5.9008,  8.6315,  4.5355,  6.1315,\n",
            "        14.0676,  5.9225,  5.2296, 11.4023,  7.7008, 11.1023,  5.1395,  5.4517,\n",
            "         8.1201,  4.8942, 11.3954,  5.5017,  7.9840,  6.0148,  6.3168,  4.7830,\n",
            "         4.6855,  4.3845,  8.0774,  6.1461, 13.5284,  4.5711, 10.0692,  6.1729,\n",
            "         6.8967,  7.6001,  9.1388,  5.7239,  8.4932,  4.3051,  5.0415,  4.2143,\n",
            "         9.5948,  4.8694,  5.9187,  4.6008,  6.9068,  6.9622, 11.6362,  8.4379,\n",
            "         5.6807, 12.1275,  6.5181,  6.3920,  5.1080, 16.6546,  6.6092,  5.9830,\n",
            "         5.8109,  8.0811,  5.3789,  5.7376,  5.3523,  6.0812, 18.6867,  3.9544,\n",
            "         6.1133,  5.6117,  4.6802,  8.0632, 12.5608,  5.6557,  6.3401,  5.0161,\n",
            "        12.9973,  4.4871,  4.2691,  6.6376,  4.2319,  4.0770, 15.1500,  5.6805,\n",
            "         4.1101,  4.3802, 13.0759,  4.8443,  4.4305,  4.0392, 17.2490,  7.1744,\n",
            "         4.6162,  5.1505,  8.5926,  6.1480,  3.8121,  4.4319,  6.4832, 10.7971,\n",
            "         5.1480,  5.8929,  6.8473,  6.2254, 15.4377,  7.7932,  6.4798,  4.9176,\n",
            "         4.1928, 19.0489,  4.1120,  3.9374,  4.9334,  8.0616,  4.3758,  6.4065,\n",
            "         5.3007,  5.8949,  4.8744,  4.6460,  6.4123,  4.3965,  5.2530,  7.4159,\n",
            "         4.5031,  5.5370,  5.8278,  7.9900,  4.1311,  8.3905,  4.2722,  7.3639,\n",
            "        12.4113, 17.3490,  9.9877,  4.4103,  4.9646,  4.3999,  6.4223,  5.4074,\n",
            "         4.4690,  4.7470,  4.8977,  9.4351,  4.0458,  4.8956,  4.3870,  9.9220,\n",
            "         3.9636,  4.5229,  8.0732,  4.6421, 10.9011,  5.8484,  6.0571,  6.8149,\n",
            "         6.7004,  5.9473,  7.3630, 10.0957,  4.3370, 13.9470,  5.0991,  5.3654,\n",
            "         9.2282, 10.1966,  4.4647,  4.1761, 13.8778,  4.1650,  5.2995,  4.6200,\n",
            "         4.6678,  4.8202,  3.6761,  6.3549, 10.8562,  6.8946,  5.5577,  8.0553,\n",
            "         4.3353,  8.6425,  4.0262,  6.5551,  4.0499,  5.1743,  4.5614,  4.5540,\n",
            "        10.0867,  4.6301,  9.8489,  4.3017,  7.9786,  4.5004,  7.1927,  5.5458,\n",
            "         4.3970,  5.0671,  4.5534,  4.2775,  4.1131, 12.2964,  4.6086,  4.8222,\n",
            "         4.4133,  4.7138,  4.1470,  4.9040,  4.5830,  7.6412,  4.6341,  5.5875,\n",
            "         4.3451, 10.8204,  5.1834,  4.7693,  7.0202,  4.9817,  5.0641,  6.1749,\n",
            "         6.6308,  4.0767,  4.0954,  5.9140,  9.9471,  6.9538, 14.2697,  5.3232,\n",
            "         8.5877, 10.7812,  7.5630,  5.0393,  4.1987, 11.8390,  4.3029,  4.9302,\n",
            "        14.8256,  5.3209,  4.7155,  5.2471,  4.6436,  8.8203,  5.0531,  5.2617,\n",
            "         4.9955,  5.5755,  4.3712,  6.7073,  4.0126,  3.5777,  4.8289,  4.7500,\n",
            "         7.8177,  9.9148,  7.5013,  5.2393,  7.4610,  6.1376,  4.0964,  4.0182,\n",
            "         5.3172,  8.3039,  5.2868,  5.2862,  4.8675, 12.5925,  5.9532,  4.8321,\n",
            "         4.9884,  4.7011,  4.4364,  6.5277,  7.1417,  5.1579,  4.8345,  4.9698,\n",
            "         6.8964,  8.1760,  5.1556,  4.9218,  4.7193,  6.8555,  4.6946,  4.8027,\n",
            "         9.7991,  4.3325, 10.3563,  6.0157,  5.2728,  5.0638,  6.4196,  6.6498,\n",
            "         9.8945,  4.6063,  5.4550,  4.5378,  4.3113,  4.8611,  6.8151,  4.2796,\n",
            "         4.3114,  5.5183,  4.6656,  6.1644,  5.1931,  5.8066,  5.1694,  5.0438,\n",
            "         8.9256,  4.2513,  3.8656,  8.2657,  5.2389,  7.4721, 14.8362,  4.4805,\n",
            "         5.9550,  4.3799,  7.3334,  5.3697,  8.4267,  4.2950,  3.7866,  5.3890,\n",
            "         9.0524,  4.3709,  4.8564,  5.6854,  5.0394,  4.8591,  9.4442,  5.1603,\n",
            "         5.6941, 17.3340,  6.4622,  4.0795,  4.4604,  4.4983,  4.3233,  4.0046,\n",
            "         7.4585,  6.6177, 13.3484,  4.4856,  5.4206,  4.4116,  4.3763,  7.0853,\n",
            "         4.8372,  7.0245,  5.3272,  4.7783,  4.8016,  8.3381,  7.5099, 15.4144,\n",
            "         4.3296,  9.4640,  4.4545, 12.6425,  4.0347,  6.6175,  7.1753,  3.8425,\n",
            "         4.4948,  5.2127, 10.9656,  5.3479,  6.0286,  4.1530,  6.1990,  5.0807,\n",
            "         3.7733,  5.0484, 10.6600,  4.9051,  5.1238,  5.4597,  9.9611,  4.6823,\n",
            "         7.9452,  8.6518,  5.6035,  5.0261,  4.1349,  5.3488,  3.9726,  4.5691,\n",
            "         6.0494,  5.2303,  4.1262,  6.8430,  4.5936,  6.4829,  8.9704,  5.4914])), ('module.encoder_q.layer4.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.1.conv2.weight', tensor([[[[-1.5562e-02, -1.1523e-02,  1.6716e-02],\n",
            "          [ 5.7698e-03,  5.5419e-03, -1.7550e-02],\n",
            "          [-1.3172e-02, -2.9783e-03,  8.7974e-03]],\n",
            "\n",
            "         [[-2.6296e-03,  7.9376e-03, -8.2434e-03],\n",
            "          [ 1.9977e-02,  1.4572e-02,  5.9086e-03],\n",
            "          [ 2.0194e-02, -2.3953e-02,  1.2383e-02]],\n",
            "\n",
            "         [[-2.8836e-03,  8.9386e-03, -7.0804e-03],\n",
            "          [ 2.1837e-02,  1.7083e-02, -9.2621e-03],\n",
            "          [ 1.6313e-02,  1.8963e-02,  1.0223e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7924e-02, -1.7650e-02,  7.3280e-04],\n",
            "          [ 5.5356e-03,  1.2868e-02, -1.4935e-02],\n",
            "          [-3.2372e-02,  2.0978e-02,  1.4327e-02]],\n",
            "\n",
            "         [[ 1.9415e-02, -3.7722e-02, -3.4158e-04],\n",
            "          [-3.9490e-02, -4.6945e-03, -2.2609e-02],\n",
            "          [-5.0701e-02, -9.1425e-03,  9.9978e-05]],\n",
            "\n",
            "         [[-5.9179e-02,  4.0196e-03, -1.4279e-03],\n",
            "          [ 1.6680e-02,  3.0559e-02,  2.2839e-02],\n",
            "          [-2.1149e-02,  1.2316e-02, -4.3391e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.5038e-03, -7.0323e-03, -6.4110e-03],\n",
            "          [-4.8324e-03, -1.2354e-03,  1.0545e-02],\n",
            "          [-3.1059e-02, -9.9574e-03,  9.8137e-03]],\n",
            "\n",
            "         [[-2.3181e-02, -1.2307e-02, -2.4995e-02],\n",
            "          [-3.7258e-03, -2.3581e-02,  1.2875e-02],\n",
            "          [-3.3125e-02, -2.4430e-02, -5.5322e-02]],\n",
            "\n",
            "         [[ 5.4659e-03, -2.9082e-03,  1.2819e-02],\n",
            "          [-8.7362e-03, -4.8982e-03,  9.6034e-03],\n",
            "          [-3.1814e-02, -4.8609e-03,  1.5544e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9774e-02,  1.9114e-03, -1.5736e-02],\n",
            "          [-4.4755e-03,  1.2377e-02,  2.1923e-02],\n",
            "          [-1.4514e-02,  1.2702e-02,  8.9986e-03]],\n",
            "\n",
            "         [[-4.2053e-04, -8.6248e-04, -6.1885e-03],\n",
            "          [-5.7166e-03, -2.4279e-02, -6.6679e-03],\n",
            "          [ 2.5137e-02,  8.5854e-03, -1.3517e-02]],\n",
            "\n",
            "         [[ 8.8604e-03,  2.5774e-02, -2.2091e-02],\n",
            "          [ 2.6345e-02, -3.3017e-02, -1.0270e-03],\n",
            "          [ 4.2220e-02,  1.0850e-03,  1.0625e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4560e-02,  1.5919e-02,  3.2820e-02],\n",
            "          [-1.1912e-03,  2.2615e-02,  2.3899e-02],\n",
            "          [ 6.1505e-03,  8.6349e-03, -2.1920e-02]],\n",
            "\n",
            "         [[ 2.5549e-02,  2.1358e-02,  2.8688e-02],\n",
            "          [-1.4210e-02, -4.6187e-03,  1.1737e-02],\n",
            "          [ 2.7921e-02, -9.7171e-03,  2.1576e-02]],\n",
            "\n",
            "         [[-1.1574e-02,  2.6067e-02, -1.1531e-02],\n",
            "          [ 2.4309e-02, -1.4603e-02, -1.5498e-03],\n",
            "          [-8.6629e-03, -3.0219e-03,  2.8175e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.0839e-03,  5.9234e-03,  2.5949e-02],\n",
            "          [ 1.7999e-02, -2.1847e-02, -8.4369e-03],\n",
            "          [-1.4593e-03,  1.4791e-02,  3.6506e-02]],\n",
            "\n",
            "         [[ 1.5879e-02,  2.6201e-02,  9.5855e-04],\n",
            "          [ 4.7115e-04,  2.4311e-02,  1.7557e-02],\n",
            "          [ 3.4691e-04, -1.9712e-02, -2.9371e-02]],\n",
            "\n",
            "         [[ 1.0458e-02,  2.3388e-02,  8.6684e-03],\n",
            "          [-1.9967e-02,  2.9909e-02,  1.1551e-02],\n",
            "          [ 1.0940e-02,  3.5791e-02,  3.5011e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.0437e-03, -6.0368e-03, -2.6949e-02],\n",
            "          [-6.4803e-03,  2.0809e-02,  5.6489e-03],\n",
            "          [ 5.6727e-03, -3.7960e-02, -9.6092e-03]],\n",
            "\n",
            "         [[-9.1025e-03, -4.5416e-03, -6.9334e-03],\n",
            "          [ 2.8336e-02, -1.9166e-02,  1.3349e-02],\n",
            "          [-1.3181e-02,  3.3177e-02,  1.2970e-02]],\n",
            "\n",
            "         [[ 1.1917e-02,  8.4305e-03, -2.2254e-02],\n",
            "          [-1.9405e-02, -8.4214e-03, -3.0499e-02],\n",
            "          [-4.0359e-03, -1.0531e-02,  4.3503e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4964e-02, -2.8949e-02, -8.6743e-04],\n",
            "          [ 1.3443e-02,  4.8049e-03,  7.4067e-03],\n",
            "          [-2.7698e-02, -3.7136e-02, -2.3054e-02]],\n",
            "\n",
            "         [[-3.2347e-02, -3.2990e-02, -1.1979e-02],\n",
            "          [-3.3536e-03, -3.9399e-02, -1.1717e-02],\n",
            "          [ 5.2098e-02,  1.8085e-02, -1.2910e-02]],\n",
            "\n",
            "         [[ 6.3926e-02,  5.8021e-03, -3.1149e-02],\n",
            "          [-9.1797e-03, -3.9877e-02, -1.9799e-02],\n",
            "          [-4.8271e-03,  1.5748e-02,  2.2875e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4454e-02, -1.4595e-02, -2.6298e-02],\n",
            "          [-1.9396e-02,  9.2003e-04, -2.6707e-02],\n",
            "          [ 1.8216e-02,  1.2754e-02,  1.3482e-02]],\n",
            "\n",
            "         [[-4.9253e-02,  3.8151e-02, -2.4489e-02],\n",
            "          [ 2.5238e-02,  1.0163e-02, -3.0881e-03],\n",
            "          [ 1.4160e-02,  3.2184e-02, -2.5566e-02]],\n",
            "\n",
            "         [[-9.4869e-03,  2.4390e-02,  2.4717e-02],\n",
            "          [-3.3736e-03, -4.7084e-03, -1.3719e-02],\n",
            "          [ 2.4650e-02, -1.2035e-02, -2.6103e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1967e-02, -1.4040e-02, -2.2832e-02],\n",
            "          [-3.4936e-03,  2.1163e-03,  1.4041e-02],\n",
            "          [ 7.8316e-03,  5.4553e-03,  1.3661e-02]],\n",
            "\n",
            "         [[ 2.6772e-02, -1.2390e-02,  2.2676e-02],\n",
            "          [-4.3530e-02, -8.9422e-03,  1.1068e-02],\n",
            "          [-4.2319e-03,  9.1874e-03, -8.4916e-03]],\n",
            "\n",
            "         [[-1.2875e-03,  3.1343e-02,  1.8009e-02],\n",
            "          [ 4.8785e-03,  1.5259e-02, -2.5452e-02],\n",
            "          [-5.2144e-03,  9.2853e-03,  1.2105e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4678e-02, -3.0938e-02, -1.2660e-02],\n",
            "          [-3.8445e-02, -2.6476e-02, -3.5104e-02],\n",
            "          [-9.5877e-03, -5.0727e-03,  5.0113e-03]],\n",
            "\n",
            "         [[-1.5972e-02,  1.1374e-02,  3.1696e-03],\n",
            "          [ 6.6089e-04,  3.7826e-02,  1.4680e-02],\n",
            "          [-2.7664e-02, -1.9099e-02, -6.5397e-04]],\n",
            "\n",
            "         [[ 1.2224e-02, -1.1421e-02, -3.2556e-02],\n",
            "          [ 2.2957e-02, -2.4003e-02,  3.3604e-02],\n",
            "          [ 2.4660e-02, -3.2972e-02, -6.4492e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6481e-02,  1.9588e-02, -3.1349e-02],\n",
            "          [-1.5436e-02, -2.1537e-02, -5.5020e-03],\n",
            "          [-1.0004e-02, -1.2208e-02,  1.2893e-02]],\n",
            "\n",
            "         [[-2.6050e-02, -1.9881e-02, -1.3485e-03],\n",
            "          [ 3.9395e-03, -2.9774e-02,  5.4548e-03],\n",
            "          [-1.1194e-02, -8.3182e-03, -1.1262e-02]],\n",
            "\n",
            "         [[ 3.6645e-02,  2.6840e-02, -3.3316e-02],\n",
            "          [ 7.6267e-03, -2.8311e-03, -1.9107e-02],\n",
            "          [ 2.9176e-02, -1.4562e-02, -1.7949e-02]]]])), ('module.encoder_q.layer4.1.bn2.weight', tensor([0.9924, 0.9925, 0.9919, 0.9924, 0.9923, 0.9924, 0.9920, 0.9923, 0.9919,\n",
            "        0.9920, 0.9922, 0.9921, 0.9920, 0.9920, 0.9924, 0.9922, 0.9922, 0.9919,\n",
            "        0.9922, 0.9921, 0.9921, 0.9920, 0.9923, 0.9923, 0.9924, 0.9920, 0.9920,\n",
            "        0.9923, 0.9923, 0.9924, 0.9921, 0.9922, 0.9925, 0.9920, 0.9921, 0.9924,\n",
            "        0.9924, 0.9924, 0.9929, 0.9924, 0.9922, 0.9920, 0.9922, 0.9924, 0.9921,\n",
            "        0.9921, 0.9923, 0.9926, 0.9921, 0.9921, 0.9921, 0.9920, 0.9923, 0.9922,\n",
            "        0.9919, 0.9930, 0.9926, 0.9923, 0.9925, 0.9919, 0.9923, 0.9925, 0.9920,\n",
            "        0.9923, 0.9924, 0.9925, 0.9924, 0.9922, 0.9929, 0.9922, 0.9924, 0.9921,\n",
            "        0.9923, 0.9922, 0.9920, 0.9928, 0.9922, 0.9926, 0.9929, 0.9930, 0.9922,\n",
            "        0.9917, 0.9924, 0.9922, 0.9922, 0.9921, 0.9921, 0.9929, 0.9920, 0.9922,\n",
            "        0.9926, 0.9924, 0.9924, 0.9919, 0.9926, 0.9923, 0.9921, 0.9924, 0.9920,\n",
            "        0.9926, 0.9925, 0.9921, 0.9922, 0.9920, 0.9922, 0.9916, 0.9924, 0.9922,\n",
            "        0.9922, 0.9925, 0.9921, 0.9925, 0.9929, 0.9920, 0.9924, 0.9922, 0.9922,\n",
            "        0.9926, 0.9925, 0.9921, 0.9919, 0.9921, 0.9920, 0.9921, 0.9929, 0.9919,\n",
            "        0.9920, 0.9926, 0.9921, 0.9929, 0.9922, 0.9923, 0.9926, 0.9919, 0.9923,\n",
            "        0.9917, 0.9919, 0.9927, 0.9922, 0.9928, 0.9921, 0.9921, 0.9920, 0.9919,\n",
            "        0.9921, 0.9921, 0.9918, 0.9928, 0.9923, 0.9921, 0.9923, 0.9926, 0.9923,\n",
            "        0.9922, 0.9920, 0.9918, 0.9920, 0.9922, 0.9919, 0.9921, 0.9921, 0.9925,\n",
            "        0.9928, 0.9917, 0.9918, 0.9921, 0.9921, 0.9921, 0.9925, 0.9918, 0.9923,\n",
            "        0.9920, 0.9920, 0.9923, 0.9919, 0.9919, 0.9920, 0.9924, 0.9923, 0.9924,\n",
            "        0.9919, 0.9919, 0.9921, 0.9922, 0.9922, 0.9923, 0.9921, 0.9924, 0.9922,\n",
            "        0.9916, 0.9923, 0.9921, 0.9925, 0.9923, 0.9922, 0.9921, 0.9931, 0.9920,\n",
            "        0.9920, 0.9920, 0.9922, 0.9919, 0.9920, 0.9921, 0.9923, 0.9926, 0.9924,\n",
            "        0.9923, 0.9923, 0.9928, 0.9920, 0.9923, 0.9922, 0.9925, 0.9920, 0.9921,\n",
            "        0.9919, 0.9927, 0.9919, 0.9924, 0.9922, 0.9920, 0.9924, 0.9922, 0.9921,\n",
            "        0.9925, 0.9923, 0.9922, 0.9921, 0.9921, 0.9924, 0.9922, 0.9924, 0.9926,\n",
            "        0.9922, 0.9918, 0.9924, 0.9922, 0.9919, 0.9925, 0.9923, 0.9922, 0.9922,\n",
            "        0.9924, 0.9922, 0.9918, 0.9921, 0.9924, 0.9922, 0.9925, 0.9915, 0.9922,\n",
            "        0.9919, 0.9927, 0.9921, 0.9926, 0.9923, 0.9922, 0.9926, 0.9928, 0.9925,\n",
            "        0.9923, 0.9926, 0.9918, 0.9923, 0.9925, 0.9920, 0.9927, 0.9922, 0.9922,\n",
            "        0.9925, 0.9926, 0.9921, 0.9924, 0.9922, 0.9930, 0.9925, 0.9930, 0.9928,\n",
            "        0.9919, 0.9918, 0.9925, 0.9919, 0.9931, 0.9920, 0.9923, 0.9922, 0.9924,\n",
            "        0.9926, 0.9925, 0.9924, 0.9919, 0.9922, 0.9920, 0.9928, 0.9926, 0.9925,\n",
            "        0.9927, 0.9928, 0.9920, 0.9922, 0.9921, 0.9924, 0.9922, 0.9923, 0.9924,\n",
            "        0.9918, 0.9924, 0.9918, 0.9916, 0.9918, 0.9925, 0.9923, 0.9923, 0.9926,\n",
            "        0.9924, 0.9920, 0.9919, 0.9923, 0.9929, 0.9925, 0.9921, 0.9922, 0.9924,\n",
            "        0.9921, 0.9921, 0.9926, 0.9922, 0.9914, 0.9923, 0.9922, 0.9929, 0.9921,\n",
            "        0.9924, 0.9920, 0.9924, 0.9928, 0.9924, 0.9922, 0.9925, 0.9928, 0.9919,\n",
            "        0.9922, 0.9921, 0.9923, 0.9915, 0.9922, 0.9934, 0.9926, 0.9920, 0.9925,\n",
            "        0.9922, 0.9920, 0.9925, 0.9922, 0.9922, 0.9924, 0.9921, 0.9921, 0.9923,\n",
            "        0.9923, 0.9921, 0.9921, 0.9926, 0.9927, 0.9921, 0.9926, 0.9916, 0.9920,\n",
            "        0.9921, 0.9921, 0.9921, 0.9921, 0.9920, 0.9923, 0.9922, 0.9923, 0.9927,\n",
            "        0.9925, 0.9925, 0.9921, 0.9925, 0.9921, 0.9920, 0.9919, 0.9920, 0.9924,\n",
            "        0.9928, 0.9922, 0.9925, 0.9927, 0.9924, 0.9924, 0.9923, 0.9923, 0.9921,\n",
            "        0.9922, 0.9925, 0.9920, 0.9922, 0.9920, 0.9929, 0.9922, 0.9921, 0.9921,\n",
            "        0.9923, 0.9921, 0.9923, 0.9927, 0.9925, 0.9928, 0.9920, 0.9922, 0.9923,\n",
            "        0.9922, 0.9928, 0.9923, 0.9920, 0.9921, 0.9921, 0.9924, 0.9919, 0.9926,\n",
            "        0.9923, 0.9920, 0.9921, 0.9921, 0.9921, 0.9922, 0.9920, 0.9924, 0.9927,\n",
            "        0.9923, 0.9920, 0.9921, 0.9928, 0.9923, 0.9923, 0.9923, 0.9922, 0.9923,\n",
            "        0.9923, 0.9921, 0.9919, 0.9920, 0.9923, 0.9929, 0.9922, 0.9922, 0.9920,\n",
            "        0.9923, 0.9918, 0.9917, 0.9921, 0.9920, 0.9923, 0.9926, 0.9923, 0.9922,\n",
            "        0.9923, 0.9929, 0.9925, 0.9921, 0.9919, 0.9923, 0.9922, 0.9922, 0.9921,\n",
            "        0.9920, 0.9923, 0.9924, 0.9922, 0.9921, 0.9921, 0.9919, 0.9922, 0.9921,\n",
            "        0.9924, 0.9924, 0.9927, 0.9923, 0.9923, 0.9920, 0.9922, 0.9925, 0.9929,\n",
            "        0.9923, 0.9921, 0.9921, 0.9918, 0.9924, 0.9931, 0.9922, 0.9922, 0.9920,\n",
            "        0.9920, 0.9920, 0.9925, 0.9920, 0.9924, 0.9923, 0.9928, 0.9928, 0.9924,\n",
            "        0.9926, 0.9920, 0.9922, 0.9924, 0.9926, 0.9920, 0.9920, 0.9920])), ('module.encoder_q.layer4.1.bn2.bias', tensor([-1.6049e-04,  1.4348e-04, -5.1331e-04, -3.3163e-04,  2.0025e-04,\n",
            "        -3.0400e-05,  1.7623e-04,  1.2169e-04, -1.7404e-04,  3.3233e-05,\n",
            "         1.2262e-04, -1.5620e-04, -7.4058e-06, -2.5871e-04,  1.6624e-05,\n",
            "        -2.5628e-04,  3.2068e-05, -1.6150e-04,  3.6743e-05, -1.4778e-04,\n",
            "         7.5079e-05,  2.2669e-05,  1.5563e-04,  4.9773e-04,  2.1978e-04,\n",
            "        -7.6548e-05, -1.2887e-04,  4.2938e-05,  2.0804e-04,  7.3826e-05,\n",
            "        -1.9963e-04,  4.3856e-04,  6.4141e-05, -1.6322e-04, -5.8161e-05,\n",
            "         1.1235e-05,  3.2924e-04,  1.8305e-06,  1.5070e-03,  3.7842e-04,\n",
            "         1.5470e-04, -1.1529e-04,  3.0889e-04,  1.1098e-04, -3.7494e-04,\n",
            "        -9.1536e-06,  3.4536e-04,  9.1416e-04, -3.4265e-06, -2.9494e-05,\n",
            "        -1.2497e-04,  2.6926e-04, -7.2612e-05, -1.0680e-04,  2.4512e-05,\n",
            "         4.7058e-04, -5.0535e-05,  3.1335e-05,  8.9314e-05, -1.8662e-04,\n",
            "         1.7069e-04, -2.6705e-04, -5.5836e-05,  1.7342e-04,  2.7674e-04,\n",
            "        -1.8744e-05,  7.1931e-05, -7.9280e-05,  2.2539e-04, -2.6379e-04,\n",
            "         3.9917e-04, -1.8490e-04, -4.0037e-05, -3.2297e-05, -8.6062e-05,\n",
            "         1.0570e-03, -1.6151e-04,  1.3213e-04,  4.0302e-04,  6.4796e-04,\n",
            "        -6.2892e-05, -2.9776e-04,  4.1500e-04, -2.4366e-04,  1.5574e-04,\n",
            "        -1.0768e-04,  1.0423e-04,  4.0038e-04, -9.2861e-05,  1.5059e-04,\n",
            "         5.4744e-04,  2.9642e-04, -1.7544e-04, -2.0457e-04,  4.9141e-04,\n",
            "         6.5324e-05, -2.7133e-04, -6.6078e-05, -2.5026e-04, -2.0141e-04,\n",
            "         6.0905e-05,  1.7686e-04, -1.1812e-04, -6.8641e-05, -1.1788e-04,\n",
            "        -4.1665e-04,  6.5438e-05,  1.5138e-04, -7.4320e-06,  7.3910e-04,\n",
            "         1.7266e-04,  2.5450e-04,  6.6211e-04, -1.2050e-04,  1.0423e-04,\n",
            "        -9.7054e-05, -7.6718e-05,  1.2057e-04,  1.8221e-04, -1.4398e-04,\n",
            "        -8.0186e-04, -3.9624e-04, -4.5325e-05,  1.4906e-04,  1.2172e-04,\n",
            "        -2.0183e-04, -1.5750e-04,  2.7682e-04, -3.6263e-04,  1.0646e-03,\n",
            "        -2.1704e-05,  5.7909e-05,  5.3254e-04, -4.0695e-04, -2.7118e-05,\n",
            "        -5.3523e-04, -2.8662e-05,  1.1101e-04,  1.6264e-05,  6.4759e-05,\n",
            "        -1.8052e-04, -3.2898e-04, -6.2176e-05, -3.9515e-04, -6.0637e-05,\n",
            "         4.5320e-05, -1.3867e-04,  2.4575e-04,  2.0174e-05, -8.7745e-05,\n",
            "        -6.0680e-05,  7.0171e-04, -1.6932e-04, -3.1505e-05, -1.0180e-04,\n",
            "        -4.3678e-04, -1.9636e-04, -1.6468e-04, -1.5034e-04, -1.2358e-04,\n",
            "         4.8422e-06,  2.5541e-04,  5.0659e-04, -4.3727e-04, -1.5248e-04,\n",
            "        -2.8366e-04, -2.3249e-04, -3.3891e-04,  7.5258e-05, -3.0519e-04,\n",
            "        -2.1963e-05, -2.5527e-05, -1.9318e-04, -8.2247e-05, -1.2289e-04,\n",
            "        -5.0082e-04, -1.1909e-04,  1.6396e-04, -2.1581e-04,  3.1291e-04,\n",
            "        -4.2739e-06, -2.7168e-04, -2.4982e-04,  1.6150e-04, -1.7170e-04,\n",
            "        -1.8852e-04,  1.8141e-04,  5.1405e-04,  7.4091e-06, -5.4764e-04,\n",
            "         1.1591e-04, -2.9850e-04,  4.7087e-04,  6.2469e-05, -1.7667e-05,\n",
            "        -8.2521e-05,  4.1741e-04, -2.3947e-04, -9.8492e-05, -2.7370e-04,\n",
            "        -6.0740e-05, -1.6386e-04, -2.3448e-04, -1.3888e-04,  2.2257e-04,\n",
            "        -2.5206e-05, -4.6716e-05, -4.3994e-05, -1.0858e-04,  1.7076e-05,\n",
            "        -2.0141e-04, -1.1251e-04,  4.0220e-05,  3.8108e-04, -3.4016e-04,\n",
            "        -4.6298e-05, -1.1424e-04,  3.4578e-04, -1.9740e-04, -2.8978e-04,\n",
            "         8.8711e-05, -1.5238e-04, -2.4296e-04, -4.2605e-05, -4.6667e-05,\n",
            "         5.2843e-04, -6.2416e-05,  1.0092e-04,  2.0953e-04, -3.0582e-04,\n",
            "         7.0128e-07,  1.0057e-04,  2.6089e-04,  2.8296e-04, -6.4003e-05,\n",
            "        -3.2224e-04, -8.5449e-05,  3.0757e-05, -2.1586e-04,  5.2187e-05,\n",
            "         1.0468e-05,  1.2392e-05,  1.5474e-05, -2.0527e-05,  3.2103e-05,\n",
            "        -3.6754e-04, -2.7185e-04,  2.0153e-05,  2.5420e-04,  4.6018e-05,\n",
            "        -5.9946e-04,  8.0654e-05, -2.8110e-04,  3.4600e-04, -5.4082e-05,\n",
            "         5.6790e-05,  2.0842e-04,  1.9202e-04,  3.5168e-04,  5.6922e-04,\n",
            "         6.0855e-05, -1.3398e-04,  7.7306e-05, -2.8406e-04,  3.6512e-04,\n",
            "         2.6651e-04, -1.3492e-04,  3.9959e-04, -2.3376e-05,  5.8841e-05,\n",
            "         2.6357e-04,  6.1099e-04, -1.7172e-04,  4.3093e-05, -8.7942e-05,\n",
            "         1.5219e-04,  4.8099e-05,  5.6030e-04,  7.7163e-04, -2.9189e-04,\n",
            "        -2.4571e-04,  7.8208e-05, -2.2981e-04,  1.3447e-03, -2.0295e-04,\n",
            "         4.0994e-05, -1.1200e-04, -5.9202e-05,  2.6939e-04,  6.4759e-05,\n",
            "         2.4535e-04, -3.6886e-05, -1.3376e-04, -3.8530e-04,  1.8981e-04,\n",
            "         5.3109e-04, -5.1762e-05,  1.6704e-04,  5.8434e-04,  1.3685e-04,\n",
            "         1.5267e-04, -3.5467e-05,  3.6235e-04,  1.8465e-04,  3.7013e-04,\n",
            "        -1.0376e-04, -1.7687e-04,  2.1649e-04, -2.1760e-04,  3.7514e-06,\n",
            "        -3.3120e-04, -1.8897e-05,  2.1503e-04,  1.3192e-04,  1.8634e-04,\n",
            "         1.8599e-04, -2.4935e-04,  7.2150e-05, -2.0113e-04,  4.5100e-04,\n",
            "         5.8815e-05, -9.2878e-05,  1.2255e-04, -2.3125e-06, -8.4163e-06,\n",
            "        -1.2768e-04,  4.9744e-04, -2.2011e-04, -4.5737e-04, -1.0286e-04,\n",
            "        -1.0630e-04,  5.7314e-04, -7.4526e-05,  2.9886e-04, -6.1921e-05,\n",
            "         1.8508e-04,  2.3381e-04,  7.7722e-05, -2.1475e-05, -7.7552e-05,\n",
            "         5.3911e-04, -2.4139e-04, -1.5083e-04, -1.3352e-04,  2.7879e-04,\n",
            "        -4.0212e-04, -6.6729e-05,  1.2839e-03,  1.8996e-04, -7.6076e-05,\n",
            "         1.4258e-04,  1.4827e-04, -2.8873e-04,  3.8287e-05, -1.1186e-04,\n",
            "        -2.0671e-04,  1.4170e-04, -2.8823e-04,  1.7349e-04,  1.4952e-04,\n",
            "         1.4899e-05,  9.0140e-05, -1.4562e-04,  6.1885e-06,  9.0334e-04,\n",
            "        -8.3182e-05,  2.7977e-04, -2.4813e-04,  1.2145e-04,  6.2523e-07,\n",
            "        -1.6392e-04,  2.2248e-06, -6.3531e-06, -4.5509e-05,  3.0044e-05,\n",
            "         6.7514e-05, -7.0744e-05,  8.7675e-04,  1.8963e-04,  7.5588e-05,\n",
            "        -1.9652e-04,  2.3189e-04, -2.2213e-04, -1.2163e-04, -2.9860e-04,\n",
            "        -1.6236e-04,  2.4349e-04,  2.6519e-04, -3.7640e-05,  4.2465e-04,\n",
            "         9.4075e-05,  8.9837e-05, -3.0122e-05,  1.9349e-04,  6.2915e-04,\n",
            "         9.6969e-05, -1.9634e-05,  8.6154e-05, -1.1709e-04,  5.5334e-05,\n",
            "        -4.0998e-04,  2.8160e-04, -9.3604e-05, -2.0041e-04,  3.0832e-05,\n",
            "        -1.2816e-04, -1.3688e-04,  1.4868e-04,  1.1100e-04,  7.5354e-05,\n",
            "         8.4301e-04, -4.1767e-04,  1.7513e-04, -9.3189e-05, -1.8242e-04,\n",
            "         2.4898e-04, -1.6220e-04, -3.1919e-04, -1.7004e-04,  2.7092e-06,\n",
            "         1.8045e-04, -6.5855e-05,  9.4981e-05, -9.9024e-05, -3.6379e-04,\n",
            "        -1.0381e-04, -2.6107e-05, -2.4852e-04, -1.3018e-04, -3.3741e-04,\n",
            "         1.1377e-04,  1.9689e-04,  1.6112e-04, -1.6501e-04,  1.4092e-04,\n",
            "         6.1740e-04,  3.4455e-05, -2.7664e-05, -4.8583e-05, -1.3477e-04,\n",
            "        -2.2344e-04, -2.7685e-04,  1.3783e-04, -1.4014e-04,  9.6073e-05,\n",
            "         2.3442e-04,  8.0997e-04,  1.8273e-04, -1.9728e-04, -3.6517e-05,\n",
            "         2.2712e-04, -4.5602e-04, -4.3743e-04, -1.0830e-04, -8.5232e-05,\n",
            "        -4.3007e-05,  6.1453e-04, -1.2461e-04, -2.2144e-05,  4.0133e-04,\n",
            "         3.9607e-04,  4.4378e-04, -2.0001e-04, -5.0255e-04,  2.1029e-04,\n",
            "        -1.8217e-04,  1.1751e-04, -2.7775e-05, -2.5881e-04, -3.8553e-06,\n",
            "        -1.0482e-05, -1.5257e-05, -1.9468e-04,  1.5367e-04, -1.0956e-04,\n",
            "         4.9699e-05, -2.4948e-04,  4.0910e-04,  3.1156e-05,  2.9557e-04,\n",
            "         3.0609e-04, -4.8715e-05, -3.7688e-04, -1.6382e-04, -3.3259e-05,\n",
            "         2.0244e-04,  7.4651e-05, -7.6649e-05,  2.6795e-04, -2.3936e-04,\n",
            "         6.4330e-04,  5.4077e-04, -4.0303e-05,  1.1703e-04,  1.4207e-04,\n",
            "        -1.8983e-04,  3.9112e-05,  1.6612e-04, -2.5545e-04,  4.4012e-04,\n",
            "        -5.7562e-05,  3.9972e-04,  3.3440e-04, -2.0251e-04,  4.0119e-04,\n",
            "         3.8356e-05,  8.2078e-05, -1.9296e-04,  1.8615e-04,  5.5178e-05,\n",
            "        -1.6486e-04, -3.8065e-04])), ('module.encoder_q.layer4.1.bn2.running_mean', tensor([ 2.5796e-01,  3.9465e-01, -6.3220e-01,  3.9942e-01, -6.4253e-01,\n",
            "        -4.3903e-02, -1.6731e-01, -1.8259e-01,  8.7458e-02,  3.0172e-01,\n",
            "         5.0603e-01, -1.5862e-01,  2.8860e-01,  1.5923e-01,  7.4200e-01,\n",
            "         2.1039e-01,  4.0352e-01,  9.8380e-02, -3.7547e-01,  5.4248e-02,\n",
            "         1.8323e-01,  1.7739e-01, -2.7589e-02, -2.9341e-01,  1.1602e-01,\n",
            "         6.6049e-02, -1.9060e-01,  9.2739e-01, -4.9471e-02, -2.4048e-01,\n",
            "         9.4824e-02,  2.0672e-01,  3.8654e-01, -6.9457e-02,  8.9279e-02,\n",
            "        -2.9648e-01,  1.3356e-01,  6.6560e-01, -8.5930e-03,  9.1857e-01,\n",
            "         6.4181e-01, -5.2160e-01, -3.4421e-01,  3.3522e-01, -1.1497e-01,\n",
            "         4.3423e-02, -2.0324e-01, -6.2832e-01, -2.8904e-01, -5.9550e-02,\n",
            "         3.2062e-01,  7.9945e-01,  1.0957e-01,  5.7979e-01, -1.1622e-01,\n",
            "         4.4829e-01,  3.9672e-01, -4.6384e-01, -2.5909e-01,  7.2018e-03,\n",
            "        -1.1465e-01, -4.5731e-02, -3.4167e-01,  2.9774e-01, -3.5044e-01,\n",
            "        -1.7259e-01, -1.5744e-02,  8.7604e-01,  3.5525e-01,  6.8160e-01,\n",
            "        -1.4257e-01,  2.3972e-01,  6.1972e-01, -6.4278e-01, -4.0593e-01,\n",
            "        -5.3033e-01,  7.0161e-01,  1.4200e-01, -3.2073e-01, -2.3886e-01,\n",
            "         1.7114e-01,  8.9665e-01,  1.7977e-01,  2.8501e-01, -8.4383e-02,\n",
            "         1.6321e-01,  8.5945e-02, -3.6837e-01, -8.9176e-01, -1.9277e-02,\n",
            "        -4.2990e-02, -8.6398e-01,  1.1354e-01, -1.4863e-01, -3.8661e-03,\n",
            "        -7.1595e-02,  6.6272e-01, -1.2533e-01, -8.6500e-02, -3.6355e-02,\n",
            "         2.0474e-01, -4.0435e-01, -1.1982e-01, -7.0210e-01,  1.4530e-01,\n",
            "        -1.9176e-01,  6.8024e-02, -4.2436e-02,  2.1923e-01, -7.3251e-01,\n",
            "        -3.2151e-03, -1.1881e-01,  6.5561e-01,  4.3635e-01, -5.0813e-01,\n",
            "         1.0639e-01, -3.8318e-02,  1.3714e-01,  1.0240e-01, -8.1064e-01,\n",
            "        -4.1855e-01, -6.3046e-01,  1.1538e-01, -1.2923e-01,  1.5005e-01,\n",
            "         1.4621e-01, -4.5267e-01,  6.0609e-01, -2.9640e-01, -8.5283e-01,\n",
            "         4.8133e-01,  4.4909e-01, -5.9678e-01,  4.7692e-01,  1.7980e-01,\n",
            "         2.8761e-01, -3.0394e-01,  7.9657e-02,  8.8068e-03,  5.4440e-01,\n",
            "        -5.4269e-01,  2.6997e-02, -4.8472e-01,  1.5657e-01,  3.4484e-01,\n",
            "        -2.4405e-01, -2.6524e-01,  2.2680e-01,  3.0129e-01, -6.2779e-01,\n",
            "         1.5682e-01, -2.7587e-01,  2.0178e-01,  1.0568e-01,  5.9801e-01,\n",
            "         2.0378e-01, -4.5075e-01, -8.0068e-02, -1.5344e-01, -3.2995e-01,\n",
            "        -4.4104e-01,  3.6014e-01,  1.6828e-01,  1.4859e-03, -3.4053e-01,\n",
            "        -1.5383e-01,  3.5453e-01, -5.9518e-01,  3.1276e-01,  5.6450e-01,\n",
            "         2.1701e-01,  5.8562e-01,  3.8521e-01,  9.3994e-04,  6.7663e-02,\n",
            "        -2.5757e-01, -2.3265e-01, -2.6780e-01,  1.3081e-01,  1.1442e+00,\n",
            "        -2.8705e-01,  6.9215e-02,  1.4427e-01, -5.4448e-01,  2.6524e-01,\n",
            "         7.2056e-01, -3.6348e-01,  2.2153e-01,  2.8007e-01,  3.0089e-01,\n",
            "        -2.4854e-02,  3.9469e-01, -1.2481e+00,  1.1218e-02, -5.3853e-02,\n",
            "        -5.2409e-01,  2.6222e-01, -5.8277e-01, -1.0959e-01,  7.9437e-02,\n",
            "        -9.1086e-02,  4.5304e-01,  1.7910e-01, -8.7844e-02,  1.6653e-01,\n",
            "        -9.5047e-03,  5.9090e-02,  1.3329e-01,  4.9619e-02, -3.6916e-01,\n",
            "        -1.0188e-01, -4.9052e-01,  2.7756e-02,  2.7107e-01, -2.4275e-01,\n",
            "         6.3426e-01,  2.0762e-01, -1.4448e-01,  1.0651e-01,  7.2917e-01,\n",
            "        -1.1004e+00,  2.7845e-01,  8.6061e-01,  3.6613e-02,  2.1681e-01,\n",
            "         9.7231e-03, -7.5471e-02, -7.9094e-02,  6.2306e-03, -2.8560e-01,\n",
            "         2.7183e-01,  1.9745e-01, -3.6719e-01,  1.1187e-01,  1.4527e-01,\n",
            "        -1.3134e-02, -5.5718e-01, -3.9980e-01,  6.9253e-01,  7.0903e-01,\n",
            "        -6.5981e-01, -4.1465e-01, -1.5657e-01,  2.0623e-01,  2.6296e-02,\n",
            "        -4.8869e-02, -9.9916e-02,  1.0145e-01, -3.1062e-03,  6.0025e-01,\n",
            "         8.9438e-01, -3.7355e-02, -4.9809e-01,  2.8931e-01, -2.3880e-01,\n",
            "         5.4324e-01, -4.7786e-01, -6.0556e-01,  1.7540e-01, -1.9566e-01,\n",
            "         5.1894e-01,  2.3701e-01, -1.2305e-01, -6.1680e-02, -4.4755e-01,\n",
            "         3.7385e-01,  4.1637e-01,  7.5891e-01, -1.0774e-01,  1.4058e-01,\n",
            "         3.2895e-01, -9.4175e-01,  1.3908e-01, -2.4289e-01,  3.8104e-01,\n",
            "         3.9024e-01, -2.8825e-01,  4.2361e-02,  3.2103e-01,  5.0271e-01,\n",
            "        -3.0145e-01,  6.5687e-01,  2.2068e-01, -3.7718e-01,  8.2265e-01,\n",
            "        -3.8859e-01,  4.7430e-01, -1.7335e-01,  5.3813e-01, -8.6674e-02,\n",
            "        -3.0104e-01, -7.7170e-02, -7.0204e-01, -1.0118e-01,  3.1905e-01,\n",
            "        -4.2003e-01,  5.8616e-02,  1.5590e-01,  1.9076e-01,  2.4441e-01,\n",
            "         6.3455e-01,  5.4933e-01, -2.0245e-01, -1.1995e-01, -2.2611e-01,\n",
            "        -1.8454e-01, -9.7233e-02,  5.7353e-02,  5.2645e-02,  9.3683e-01,\n",
            "        -2.2923e-01,  4.9393e-02, -4.2796e-01,  3.8326e-03,  3.9405e-01,\n",
            "        -2.3345e-01,  7.4065e-02, -3.1481e-01, -5.6258e-01,  3.1189e-01,\n",
            "         3.4307e-02,  2.7129e-01,  1.0073e-01, -3.6252e-01,  1.7052e-02,\n",
            "         3.7328e-02,  3.3801e-01, -5.0709e-01,  6.6669e-01, -3.2303e-01,\n",
            "        -1.6437e-01,  7.6365e-01,  8.5063e-02, -3.0950e-01, -1.6394e-01,\n",
            "        -1.0166e-01,  3.3407e-01,  3.6078e-01, -3.0281e-01,  1.1383e-01,\n",
            "         1.7340e-01,  5.8702e-01, -5.4002e-01, -3.5786e-01, -4.2063e-01,\n",
            "        -9.2656e-02, -1.1731e-01,  2.6330e-01, -1.8038e-01,  5.5552e-01,\n",
            "        -5.0011e-02,  9.0016e-02, -7.0122e-01, -3.9239e-01,  2.7933e-01,\n",
            "        -3.9782e-01, -3.4252e-01, -8.9389e-01, -1.1216e-01, -4.1392e-01,\n",
            "        -5.1870e-01, -8.9341e-01,  4.3665e-02,  1.4037e-01, -3.6935e-01,\n",
            "        -1.9632e-01, -1.1521e-01,  3.2253e-01, -4.6765e-01,  1.3229e-01,\n",
            "         2.4283e-01,  5.7698e-01, -9.1289e-02, -3.9478e-01, -2.8653e-01,\n",
            "         5.5789e-02,  5.7013e-01, -3.5620e-01, -1.3147e-01, -3.1569e-01,\n",
            "         2.3773e-01, -9.9090e-02,  4.1711e-01, -3.4060e-01, -1.4520e-01,\n",
            "        -5.8269e-02,  6.4306e-01, -7.7724e-02, -1.1970e-01, -1.6794e-01,\n",
            "        -1.2672e-01,  1.0955e-01,  6.1941e-01, -5.7852e-01, -9.2759e-02,\n",
            "         1.4958e-01, -4.5818e-01, -3.0145e-01, -6.1800e-01,  2.0940e-01,\n",
            "         2.1675e-01,  4.0665e-01,  2.0890e-01, -3.3992e-01, -1.2639e-01,\n",
            "         6.2560e-01,  4.3314e-01,  3.8936e-01, -8.7097e-03,  3.0093e-01,\n",
            "         2.5596e-01,  1.5733e-01,  5.6430e-01,  7.5624e-01, -2.9927e-01,\n",
            "         7.1269e-01, -4.8331e-02, -1.7057e-01, -5.3393e-01, -1.6016e-01,\n",
            "        -8.0820e-02, -9.9424e-02, -4.9308e-02,  6.3138e-01,  3.8178e-01,\n",
            "         1.6680e-01, -1.4846e-02,  3.9303e-01,  3.4262e-01, -7.8410e-01,\n",
            "         4.5960e-01, -3.6804e-01,  7.0280e-02,  4.7504e-01, -5.3425e-01,\n",
            "         3.2108e-02,  1.8850e-01, -2.2118e-01,  2.7465e-01, -7.1519e-01,\n",
            "        -3.1176e-01,  7.3528e-02,  2.7948e-01, -2.3173e-01,  6.5190e-01,\n",
            "        -4.3566e-01, -4.7053e-01, -2.1736e-01, -7.6829e-02, -4.0426e-01,\n",
            "        -6.4577e-01,  1.5569e-01,  6.6927e-01,  5.4177e-02, -8.8350e-01,\n",
            "         8.5913e-02, -9.1918e-01, -1.5414e-01, -3.5616e-01, -1.0435e+00,\n",
            "         1.7741e-01,  6.4463e-02,  2.7964e-01, -1.5888e-01,  3.7747e-02,\n",
            "        -7.9627e-02, -3.4243e-01, -2.9703e-01,  8.6547e-02,  3.1969e-01,\n",
            "        -3.6383e-01, -6.8906e-02,  1.4543e-02,  6.9567e-01, -1.6162e-01,\n",
            "         3.6716e-01,  1.6527e-01,  7.6220e-02,  3.6354e-01, -2.5485e-01,\n",
            "         1.3148e-01, -2.6313e-01,  1.1446e-01, -5.9970e-02,  1.7177e-01,\n",
            "         3.1494e-01,  4.0242e-01,  5.3398e-01,  2.3466e-01,  1.7110e-01,\n",
            "        -2.6279e-01,  5.3733e-01,  2.9284e-01, -4.7000e-01, -5.2435e-01,\n",
            "        -3.5029e-01, -4.4548e-01,  7.9586e-01, -1.2670e-01,  3.3087e-01,\n",
            "        -2.9682e-01,  3.1994e-01,  7.5546e-02,  2.1429e-01,  1.3591e-01,\n",
            "        -4.6672e-02, -3.5601e-01, -2.1955e-01,  3.8542e-01, -4.9863e-01,\n",
            "        -4.5355e-01, -6.3675e-01])), ('module.encoder_q.layer4.1.bn2.running_var', tensor([0.7284, 0.8703, 0.5716, 0.6991, 1.9673, 0.5764, 0.5896, 0.8405, 0.7326,\n",
            "        0.6423, 0.6354, 0.6383, 0.6216, 0.6803, 1.0006, 0.5830, 0.5423, 0.9643,\n",
            "        1.0423, 0.6548, 0.5599, 0.5846, 0.5330, 0.5897, 0.5056, 0.6476, 0.8514,\n",
            "        0.9027, 0.5480, 0.7220, 0.6773, 0.6816, 0.7667, 0.4760, 1.0921, 0.5420,\n",
            "        0.5097, 0.8814, 0.9629, 1.4282, 0.6065, 0.8771, 0.9562, 0.5603, 0.5665,\n",
            "        0.7842, 0.6162, 1.2214, 0.5340, 0.6415, 1.2760, 0.9333, 0.6580, 0.6359,\n",
            "        0.5683, 0.7099, 0.5945, 0.9607, 0.5699, 0.6135, 1.1013, 0.5018, 0.9944,\n",
            "        0.7437, 0.5417, 0.6067, 0.8561, 1.3227, 1.4391, 0.8861, 0.9452, 0.5185,\n",
            "        0.8586, 0.9554, 0.6401, 1.0838, 0.6633, 0.8119, 0.5516, 0.6896, 0.5867,\n",
            "        0.7666, 0.6088, 0.7923, 0.5104, 0.5203, 0.5005, 0.7305, 0.9693, 0.6857,\n",
            "        0.9674, 1.5785, 0.8646, 0.7250, 0.5916, 0.5867, 1.0248, 0.6522, 0.5908,\n",
            "        0.6810, 0.5233, 0.8497, 0.6098, 1.2295, 0.6407, 0.5754, 0.6652, 0.6089,\n",
            "        0.5971, 1.3045, 0.9742, 0.7177, 0.7036, 1.0809, 1.1608, 1.0462, 0.6368,\n",
            "        0.5737, 0.6525, 1.3726, 0.9367, 0.5776, 0.5380, 0.5860, 0.7509, 0.6915,\n",
            "        0.8642, 0.7062, 0.5265, 1.4340, 0.6814, 0.5206, 1.1591, 0.8600, 0.7007,\n",
            "        0.5996, 0.7032, 0.5719, 0.7355, 1.0690, 0.9033, 0.5973, 0.6084, 0.5570,\n",
            "        0.6138, 0.6437, 0.5451, 0.8287, 0.8969, 1.2150, 0.7061, 0.9256, 0.6297,\n",
            "        0.7044, 0.7297, 0.6927, 0.6723, 0.6910, 0.6779, 0.8678, 0.5543, 0.6130,\n",
            "        0.6644, 0.8756, 0.5619, 0.5930, 0.7174, 0.5942, 0.9694, 0.4920, 0.7240,\n",
            "        1.1109, 0.8134, 0.5686, 0.6292, 0.7462, 0.5362, 0.5162, 0.6710, 1.6915,\n",
            "        0.8455, 0.5343, 0.5352, 0.8709, 0.5664, 1.0874, 0.9374, 1.0084, 0.5979,\n",
            "        0.6344, 0.7846, 0.6874, 2.1771, 0.6790, 0.6290, 1.0532, 0.6881, 2.3617,\n",
            "        0.4749, 0.5032, 0.6020, 0.8133, 0.5358, 0.5154, 0.7272, 0.5140, 0.5776,\n",
            "        0.7433, 0.5928, 0.7390, 0.6933, 0.6966, 0.8158, 0.8314, 0.6164, 1.1901,\n",
            "        0.4580, 0.5953, 0.6954, 0.6972, 1.7825, 0.6129, 0.8904, 0.4886, 0.6501,\n",
            "        0.8248, 0.6135, 0.5316, 0.6918, 0.7163, 0.6042, 0.5558, 0.6709, 0.5324,\n",
            "        0.6435, 0.8751, 0.5587, 1.2327, 1.0147, 0.9533, 0.8776, 0.5912, 0.6546,\n",
            "        0.6614, 0.5325, 0.6331, 0.6601, 0.5162, 0.7145, 1.1133, 1.2692, 0.5723,\n",
            "        0.7756, 0.5845, 0.5388, 0.7962, 1.3614, 1.1757, 0.7094, 0.5238, 0.7293,\n",
            "        0.9270, 0.5503, 0.5766, 0.7468, 0.5899, 1.0476, 1.3128, 0.5170, 0.7212,\n",
            "        0.7699, 1.7306, 0.5860, 0.5096, 0.9242, 1.1250, 0.5654, 0.6420, 1.0325,\n",
            "        0.7974, 0.4819, 0.8884, 0.5375, 1.2687, 0.9518, 0.5678, 0.7069, 0.5893,\n",
            "        0.7593, 0.9637, 0.5668, 0.8151, 0.8173, 0.6490, 0.5456, 0.6264, 0.8819,\n",
            "        0.7031, 0.6487, 0.6485, 0.9710, 0.8314, 0.6150, 1.0702, 0.8380, 0.6630,\n",
            "        0.6170, 0.6000, 0.5013, 1.1919, 0.5312, 0.6594, 0.9658, 0.8885, 0.6594,\n",
            "        0.7210, 0.6548, 0.9861, 0.6327, 0.6132, 0.9405, 0.5345, 0.4729, 0.9331,\n",
            "        0.5119, 0.5186, 1.0972, 0.7739, 1.1226, 0.5329, 0.5246, 1.0477, 0.7120,\n",
            "        1.1749, 0.6010, 0.5740, 0.6440, 1.0068, 0.7012, 0.7643, 0.6507, 0.4958,\n",
            "        0.8146, 0.6203, 1.2181, 0.5082, 0.6107, 0.7364, 0.8736, 0.5607, 0.7825,\n",
            "        0.5571, 0.6902, 1.0187, 0.9714, 0.6248, 0.4976, 0.9233, 0.5964, 0.5506,\n",
            "        1.0618, 1.1993, 0.6113, 0.5613, 0.9813, 0.5572, 0.6149, 0.7247, 0.6698,\n",
            "        0.7347, 0.5344, 0.5740, 0.7443, 0.7916, 0.9607, 0.5793, 0.6009, 1.1631,\n",
            "        0.5463, 0.6078, 0.6476, 0.7626, 1.1296, 0.5658, 0.6074, 0.7179, 0.8135,\n",
            "        0.9851, 0.6692, 0.7296, 0.6815, 0.6506, 1.2259, 0.7204, 0.5903, 0.4947,\n",
            "        0.6434, 0.4775, 0.7309, 0.5832, 0.6727, 0.7851, 0.8370, 0.5899, 0.7359,\n",
            "        0.8599, 0.5816, 0.9989, 0.7191, 0.6595, 0.6228, 0.8948, 0.8269, 0.6889,\n",
            "        0.6289, 0.7686, 0.8550, 0.7670, 0.9376, 1.1196, 0.6098, 0.5065, 0.5673,\n",
            "        0.8418, 0.8417, 0.4897, 0.5400, 0.8427, 0.7958, 1.1213, 0.8717, 0.6372,\n",
            "        0.6395, 1.0731, 0.9107, 0.5620, 0.6924, 1.2521, 0.5937, 0.7814, 0.6785,\n",
            "        0.5680, 0.5077, 0.5648, 1.0949, 1.0166, 0.6569, 0.6063, 0.6567, 0.7111,\n",
            "        0.6700, 0.4963, 1.0300, 0.5698, 0.9656, 0.5695, 1.4955, 0.5486, 0.5912,\n",
            "        1.1646, 0.7109, 0.7389, 0.6203, 0.6162, 0.6690, 0.5741, 0.7780, 0.5839,\n",
            "        0.6605, 0.5888, 0.5500, 0.5614, 0.6946, 1.4171, 0.6535, 0.5595, 0.5402,\n",
            "        0.9275, 0.5445, 0.5838, 0.8339, 0.5748, 0.5126, 0.6186, 0.7781, 0.7429,\n",
            "        0.6009, 0.7828, 0.5854, 0.6358, 1.2548, 0.8407, 0.5197, 0.9576, 0.9968,\n",
            "        0.8138, 0.5646, 1.1031, 0.5417, 0.9454, 0.5358, 1.2149, 0.6577, 0.8371,\n",
            "        0.9874, 0.8042, 0.5000, 0.7489, 0.7775, 0.9254, 0.4795, 0.8835])), ('module.encoder_q.layer4.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.1.conv3.weight', tensor([[[[ 0.0011]],\n",
            "\n",
            "         [[-0.0518]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0217]],\n",
            "\n",
            "         [[-0.0015]],\n",
            "\n",
            "         [[ 0.0264]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0162]],\n",
            "\n",
            "         [[-0.0105]],\n",
            "\n",
            "         [[-0.0166]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0009]],\n",
            "\n",
            "         [[ 0.0872]],\n",
            "\n",
            "         [[ 0.0111]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0318]],\n",
            "\n",
            "         [[-0.0441]],\n",
            "\n",
            "         [[-0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0322]],\n",
            "\n",
            "         [[-0.0021]],\n",
            "\n",
            "         [[-0.0249]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0187]],\n",
            "\n",
            "         [[ 0.0145]],\n",
            "\n",
            "         [[-0.0305]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         [[ 0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0188]],\n",
            "\n",
            "         [[ 0.0175]],\n",
            "\n",
            "         [[ 0.0726]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0056]],\n",
            "\n",
            "         [[-0.0282]],\n",
            "\n",
            "         [[ 0.0052]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0372]],\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         [[-0.0013]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0120]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[ 0.0052]]]])), ('module.encoder_q.layer4.1.bn3.weight', tensor([0.9923, 0.9922, 0.9923,  ..., 0.9917, 0.9923, 0.9921])), ('module.encoder_q.layer4.1.bn3.bias', tensor([ 3.7984e-04,  1.3336e-04,  2.3976e-04,  ..., -9.9724e-04,\n",
            "        -1.5207e-04,  7.0402e-05])), ('module.encoder_q.layer4.1.bn3.running_mean', tensor([ 0.1222, -0.2011,  0.2886,  ..., -0.4900, -0.0187,  0.2167])), ('module.encoder_q.layer4.1.bn3.running_var', tensor([0.1707, 0.1842, 0.1644,  ..., 0.2437, 0.1552, 0.1839])), ('module.encoder_q.layer4.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.2.conv1.weight', tensor([[[[ 0.0236]],\n",
            "\n",
            "         [[ 0.0244]],\n",
            "\n",
            "         [[-0.0344]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0532]],\n",
            "\n",
            "         [[ 0.0830]],\n",
            "\n",
            "         [[ 0.0515]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0475]],\n",
            "\n",
            "         [[ 0.0897]],\n",
            "\n",
            "         [[-0.0201]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0244]],\n",
            "\n",
            "         [[-0.0503]],\n",
            "\n",
            "         [[-0.0983]]],\n",
            "\n",
            "\n",
            "        [[[-0.0008]],\n",
            "\n",
            "         [[ 0.0586]],\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0086]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[ 0.0202]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0530]],\n",
            "\n",
            "         [[-0.0688]],\n",
            "\n",
            "         [[ 0.0147]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0059]],\n",
            "\n",
            "         [[-0.0287]],\n",
            "\n",
            "         [[-0.0611]]],\n",
            "\n",
            "\n",
            "        [[[-0.0596]],\n",
            "\n",
            "         [[-0.0524]],\n",
            "\n",
            "         [[ 0.0966]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0730]],\n",
            "\n",
            "         [[-0.0466]],\n",
            "\n",
            "         [[ 0.0125]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0304]],\n",
            "\n",
            "         [[ 0.0909]],\n",
            "\n",
            "         [[ 0.0010]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         [[ 0.0157]],\n",
            "\n",
            "         [[ 0.0341]]]])), ('module.encoder_q.layer4.2.bn1.weight', tensor([0.9923, 0.9922, 0.9919, 0.9922, 0.9922, 0.9924, 0.9922, 0.9920, 0.9922,\n",
            "        0.9921, 0.9924, 0.9924, 0.9924, 0.9923, 0.9924, 0.9924, 0.9924, 0.9921,\n",
            "        0.9920, 0.9922, 0.9920, 0.9920, 0.9923, 0.9916, 0.9923, 0.9922, 0.9922,\n",
            "        0.9922, 0.9928, 0.9921, 0.9921, 0.9921, 0.9923, 0.9922, 0.9931, 0.9922,\n",
            "        0.9927, 0.9920, 0.9927, 0.9921, 0.9920, 0.9919, 0.9924, 0.9924, 0.9927,\n",
            "        0.9921, 0.9919, 0.9925, 0.9918, 0.9924, 0.9926, 0.9922, 0.9921, 0.9921,\n",
            "        0.9922, 0.9926, 0.9929, 0.9923, 0.9923, 0.9921, 0.9921, 0.9928, 0.9924,\n",
            "        0.9922, 0.9923, 0.9924, 0.9923, 0.9923, 0.9923, 0.9926, 0.9920, 0.9920,\n",
            "        0.9921, 0.9921, 0.9925, 0.9921, 0.9921, 0.9921, 0.9921, 0.9919, 0.9924,\n",
            "        0.9926, 0.9925, 0.9920, 0.9922, 0.9924, 0.9923, 0.9921, 0.9924, 0.9925,\n",
            "        0.9920, 0.9922, 0.9923, 0.9935, 0.9921, 0.9923, 0.9919, 0.9920, 0.9922,\n",
            "        0.9922, 0.9921, 0.9926, 0.9922, 0.9920, 0.9919, 0.9922, 0.9918, 0.9920,\n",
            "        0.9923, 0.9926, 0.9924, 0.9917, 0.9921, 0.9922, 0.9924, 0.9922, 0.9921,\n",
            "        0.9922, 0.9922, 0.9921, 0.9918, 0.9920, 0.9918, 0.9923, 0.9919, 0.9922,\n",
            "        0.9923, 0.9919, 0.9924, 0.9926, 0.9922, 0.9921, 0.9922, 0.9920, 0.9923,\n",
            "        0.9920, 0.9922, 0.9919, 0.9927, 0.9923, 0.9918, 0.9923, 0.9923, 0.9922,\n",
            "        0.9919, 0.9920, 0.9926, 0.9921, 0.9925, 0.9921, 0.9930, 0.9921, 0.9923,\n",
            "        0.9925, 0.9923, 0.9922, 0.9921, 0.9919, 0.9922, 0.9927, 0.9923, 0.9920,\n",
            "        0.9922, 0.9922, 0.9923, 0.9924, 0.9929, 0.9922, 0.9919, 0.9930, 0.9920,\n",
            "        0.9921, 0.9920, 0.9919, 0.9918, 0.9919, 0.9921, 0.9923, 0.9923, 0.9924,\n",
            "        0.9922, 0.9924, 0.9921, 0.9924, 0.9922, 0.9919, 0.9927, 0.9921, 0.9921,\n",
            "        0.9920, 0.9921, 0.9918, 0.9920, 0.9928, 0.9918, 0.9920, 0.9921, 0.9922,\n",
            "        0.9924, 0.9922, 0.9923, 0.9923, 0.9922, 0.9923, 0.9923, 0.9922, 0.9924,\n",
            "        0.9920, 0.9922, 0.9925, 0.9922, 0.9922, 0.9924, 0.9924, 0.9919, 0.9919,\n",
            "        0.9923, 0.9922, 0.9924, 0.9924, 0.9926, 0.9922, 0.9921, 0.9924, 0.9925,\n",
            "        0.9927, 0.9922, 0.9928, 0.9922, 0.9926, 0.9924, 0.9923, 0.9921, 0.9919,\n",
            "        0.9935, 0.9924, 0.9925, 0.9924, 0.9921, 0.9922, 0.9921, 0.9918, 0.9925,\n",
            "        0.9920, 0.9926, 0.9921, 0.9924, 0.9924, 0.9928, 0.9924, 0.9923, 0.9922,\n",
            "        0.9924, 0.9922, 0.9919, 0.9924, 0.9920, 0.9920, 0.9923, 0.9921, 0.9923,\n",
            "        0.9922, 0.9920, 0.9921, 0.9920, 0.9925, 0.9922, 0.9936, 0.9923, 0.9922,\n",
            "        0.9923, 0.9920, 0.9919, 0.9924, 0.9924, 0.9923, 0.9922, 0.9924, 0.9923,\n",
            "        0.9921, 0.9925, 0.9920, 0.9922, 0.9922, 0.9920, 0.9919, 0.9921, 0.9919,\n",
            "        0.9922, 0.9924, 0.9929, 0.9919, 0.9922, 0.9925, 0.9922, 0.9919, 0.9922,\n",
            "        0.9926, 0.9922, 0.9922, 0.9922, 0.9925, 0.9922, 0.9921, 0.9917, 0.9923,\n",
            "        0.9920, 0.9922, 0.9924, 0.9923, 0.9922, 0.9923, 0.9921, 0.9920, 0.9923,\n",
            "        0.9920, 0.9924, 0.9923, 0.9922, 0.9923, 0.9922, 0.9923, 0.9922, 0.9925,\n",
            "        0.9920, 0.9921, 0.9922, 0.9918, 0.9920, 0.9923, 0.9922, 0.9922, 0.9918,\n",
            "        0.9923, 0.9922, 0.9921, 0.9924, 0.9920, 0.9924, 0.9927, 0.9922, 0.9918,\n",
            "        0.9923, 0.9919, 0.9921, 0.9923, 0.9921, 0.9919, 0.9921, 0.9926, 0.9925,\n",
            "        0.9920, 0.9922, 0.9926, 0.9918, 0.9923, 0.9917, 0.9922, 0.9930, 0.9926,\n",
            "        0.9924, 0.9925, 0.9918, 0.9922, 0.9930, 0.9922, 0.9922, 0.9923, 0.9923,\n",
            "        0.9927, 0.9923, 0.9925, 0.9925, 0.9922, 0.9924, 0.9921, 0.9923, 0.9921,\n",
            "        0.9923, 0.9917, 0.9927, 0.9925, 0.9921, 0.9920, 0.9921, 0.9927, 0.9926,\n",
            "        0.9922, 0.9924, 0.9929, 0.9925, 0.9922, 0.9928, 0.9928, 0.9921, 0.9924,\n",
            "        0.9920, 0.9922, 0.9921, 0.9924, 0.9920, 0.9922, 0.9922, 0.9922, 0.9920,\n",
            "        0.9924, 0.9925, 0.9921, 0.9921, 0.9925, 0.9924, 0.9921, 0.9921, 0.9921,\n",
            "        0.9924, 0.9922, 0.9922, 0.9923, 0.9923, 0.9927, 0.9923, 0.9923, 0.9921,\n",
            "        0.9923, 0.9915, 0.9923, 0.9929, 0.9920, 0.9922, 0.9924, 0.9922, 0.9923,\n",
            "        0.9932, 0.9927, 0.9921, 0.9930, 0.9936, 0.9925, 0.9925, 0.9927, 0.9921,\n",
            "        0.9921, 0.9925, 0.9921, 0.9920, 0.9923, 0.9932, 0.9925, 0.9925, 0.9922,\n",
            "        0.9925, 0.9921, 0.9921, 0.9924, 0.9929, 0.9922, 0.9924, 0.9922, 0.9922,\n",
            "        0.9923, 0.9924, 0.9921, 0.9922, 0.9923, 0.9926, 0.9922, 0.9922, 0.9923,\n",
            "        0.9919, 0.9922, 0.9925, 0.9922, 0.9921, 0.9922, 0.9922, 0.9921, 0.9922,\n",
            "        0.9921, 0.9929, 0.9921, 0.9926, 0.9921, 0.9926, 0.9920, 0.9920, 0.9920,\n",
            "        0.9920, 0.9924, 0.9922, 0.9921, 0.9925, 0.9922, 0.9923, 0.9918, 0.9922,\n",
            "        0.9920, 0.9923, 0.9923, 0.9918, 0.9925, 0.9921, 0.9921, 0.9929, 0.9923,\n",
            "        0.9926, 0.9925, 0.9920, 0.9920, 0.9925, 0.9923, 0.9922, 0.9923])), ('module.encoder_q.layer4.2.bn1.bias', tensor([ 2.0129e-04, -1.9266e-04, -1.9911e-04, -9.9388e-05, -2.1352e-04,\n",
            "         1.3782e-04,  7.5354e-05, -2.3706e-04, -9.1854e-05, -5.7024e-05,\n",
            "         3.1048e-04,  1.9642e-04,  3.3084e-04, -4.8744e-05,  1.2619e-05,\n",
            "         3.1868e-04,  1.6737e-04, -6.4030e-05, -2.8403e-04, -1.0299e-05,\n",
            "        -2.0450e-04, -4.5084e-04, -9.3622e-05, -2.7121e-04,  1.0248e-04,\n",
            "         2.0439e-05, -5.2179e-05, -1.4345e-04,  2.2232e-04,  1.7912e-04,\n",
            "        -5.1266e-05,  1.4761e-04,  3.5126e-04,  7.6399e-05,  5.3308e-04,\n",
            "        -5.2555e-04,  4.8998e-04, -2.9835e-05,  1.6565e-04, -1.1931e-04,\n",
            "        -1.8319e-04, -3.5188e-04,  7.4662e-05, -1.7315e-04,  2.7077e-04,\n",
            "        -3.2492e-04,  1.0052e-04,  1.7029e-04, -1.4773e-04,  2.9585e-05,\n",
            "         3.0046e-04, -1.1464e-04,  3.7824e-05, -4.9151e-04,  1.0462e-04,\n",
            "         7.0303e-05,  4.3504e-04, -1.0259e-04,  2.4486e-04, -1.4149e-04,\n",
            "        -2.4696e-05,  1.2067e-04,  2.4008e-04,  2.0054e-04,  1.3420e-06,\n",
            "         5.2925e-05, -2.6810e-04, -4.8381e-05,  1.2068e-04, -5.4348e-05,\n",
            "        -3.0324e-04, -4.6791e-04, -1.4965e-04, -2.6088e-04, -3.6617e-05,\n",
            "         1.6914e-05, -1.4213e-04,  8.8928e-05, -1.6691e-04, -9.9075e-05,\n",
            "         1.7387e-04,  9.5500e-04,  4.6688e-04, -3.1648e-04,  2.9089e-06,\n",
            "         5.1586e-04,  1.2273e-04, -5.8191e-06, -4.6867e-06,  1.6771e-04,\n",
            "        -1.2374e-04,  4.2965e-06,  1.3440e-04,  1.0151e-03, -1.7404e-04,\n",
            "         2.5810e-04, -1.2359e-04, -6.4991e-05,  1.4979e-04,  6.2532e-05,\n",
            "        -2.6089e-04,  6.5108e-04,  2.1766e-06, -2.7913e-04, -2.1107e-04,\n",
            "        -7.1846e-06,  2.0790e-04, -3.9878e-04,  9.6395e-05, -9.1843e-06,\n",
            "         2.3462e-04, -4.7379e-04, -3.3407e-04,  2.2116e-04, -3.8890e-05,\n",
            "        -1.0579e-04,  6.7396e-05,  3.8221e-05, -1.5552e-04, -1.1938e-04,\n",
            "        -5.6889e-04, -2.7544e-04, -3.3404e-04, -2.4616e-05, -1.3938e-04,\n",
            "         1.9353e-04,  2.8990e-04, -4.5840e-04, -1.0115e-04,  2.4784e-04,\n",
            "         1.6934e-04, -3.4124e-04, -1.3850e-05, -1.0835e-04, -2.8424e-04,\n",
            "        -8.0250e-05, -7.1313e-06, -4.2697e-04,  4.3381e-04, -1.0924e-04,\n",
            "        -2.0660e-04,  2.0864e-04,  1.8955e-04, -1.2642e-05,  3.4111e-05,\n",
            "        -5.4636e-05,  2.0048e-04,  2.2818e-05,  1.1692e-04, -6.9179e-05,\n",
            "         5.7412e-04, -1.1193e-04,  4.7240e-05,  2.3819e-04,  3.5074e-05,\n",
            "         1.2419e-04, -4.1799e-05, -2.7705e-04,  1.0524e-04,  7.7282e-04,\n",
            "        -1.8557e-05, -4.0725e-05, -5.1878e-05, -1.0499e-04, -3.0048e-05,\n",
            "         2.2471e-04,  4.6338e-04,  1.9712e-05, -1.7781e-04,  3.3710e-04,\n",
            "        -7.3816e-05, -9.7019e-05, -3.6395e-04,  1.8550e-06, -3.1542e-04,\n",
            "        -7.1778e-05, -1.8977e-04, -2.0977e-05, -1.1682e-04,  3.2816e-04,\n",
            "        -2.2578e-04,  8.9505e-05,  1.3322e-04, -2.0515e-04,  7.4006e-05,\n",
            "         5.0046e-05,  5.2385e-04, -8.1988e-05, -1.5370e-04, -3.4929e-04,\n",
            "        -8.9133e-05, -4.1609e-05,  1.2998e-04,  6.4288e-04, -4.9202e-04,\n",
            "        -2.5930e-04, -7.6117e-05, -9.8238e-05, -2.6464e-04, -1.1721e-04,\n",
            "        -1.5342e-04,  4.2216e-05,  1.3881e-04, -2.0474e-04, -1.7811e-04,\n",
            "         8.9271e-05, -4.8967e-05, -1.7074e-04,  1.7360e-04, -9.1512e-05,\n",
            "         5.1454e-06, -4.2181e-04, -3.1581e-06,  1.1551e-04, -2.3237e-04,\n",
            "        -1.5559e-04,  2.3627e-04, -6.7776e-05,  3.6930e-04,  1.8053e-04,\n",
            "         2.0308e-04, -1.4842e-04, -1.3922e-04,  1.5550e-04,  2.6899e-04,\n",
            "         4.4336e-04,  9.0619e-05,  2.9163e-05, -4.0598e-05, -4.6495e-05,\n",
            "         9.5140e-05,  1.9464e-04, -4.4964e-05, -3.2860e-04,  1.2077e-03,\n",
            "         4.8644e-04,  4.1856e-04,  2.5537e-04, -2.7560e-04,  3.6599e-05,\n",
            "        -1.8084e-04, -3.5059e-04, -1.2664e-04, -1.5447e-04,  2.1889e-04,\n",
            "        -1.3548e-04, -5.6723e-05,  4.2291e-05,  3.2257e-04,  4.0921e-04,\n",
            "        -3.4444e-05,  1.8405e-06,  3.3057e-04, -5.5173e-05, -2.0258e-04,\n",
            "         3.1146e-04,  2.2177e-05, -1.1553e-04, -1.2369e-04, -3.2660e-04,\n",
            "        -9.8458e-05, -3.3028e-04, -1.7825e-04,  1.4829e-04, -8.4417e-06,\n",
            "         6.3508e-05, -1.3931e-04,  1.0117e-03,  1.2370e-04, -9.6096e-05,\n",
            "         2.5974e-05, -1.7516e-04, -1.4202e-04,  2.7105e-04, -2.8341e-05,\n",
            "        -5.2008e-05, -1.7548e-04,  4.4808e-05,  6.9322e-05, -2.7475e-04,\n",
            "        -5.6265e-05, -1.3246e-04,  2.4116e-04,  3.3899e-05, -1.2776e-04,\n",
            "        -3.5161e-04,  5.8171e-05, -5.7503e-04,  4.0026e-05,  3.1747e-04,\n",
            "         6.4336e-04, -2.6797e-04, -2.4056e-05,  1.3785e-04, -7.0378e-05,\n",
            "        -2.0841e-04, -1.1700e-04,  2.2414e-04,  2.7868e-04,  9.8582e-05,\n",
            "         6.0686e-05,  3.0473e-04, -9.2637e-05,  2.3878e-05, -3.8656e-04,\n",
            "        -1.4251e-04, -1.5332e-04, -1.7326e-04,  3.5265e-05, -1.1080e-04,\n",
            "        -1.4693e-04,  1.9438e-04, -8.4962e-05, -4.0289e-04,  2.2816e-04,\n",
            "        -2.0292e-04,  1.3988e-05,  1.0400e-04, -2.1060e-04, -7.7949e-05,\n",
            "        -1.3896e-05,  9.1436e-05, -1.0535e-04,  2.6088e-04, -1.4828e-04,\n",
            "        -3.8790e-05, -2.4186e-04, -1.6528e-04, -1.3235e-04,  7.2571e-05,\n",
            "         4.4514e-04,  2.0312e-04, -4.5560e-05, -1.0697e-04,  1.5079e-04,\n",
            "        -1.1850e-04, -4.0124e-05, -6.6405e-05,  1.3188e-04,  1.3870e-04,\n",
            "         2.3887e-04, -4.2546e-05,  4.9465e-04, -2.9311e-04, -2.7530e-04,\n",
            "        -8.4318e-05, -1.1880e-04, -4.9125e-04, -1.7950e-04,  6.5346e-04,\n",
            "         2.4204e-05, -1.3806e-04, -4.8467e-05,  7.0109e-04, -2.0820e-04,\n",
            "         2.2753e-04, -5.9868e-04, -7.6978e-05,  1.0179e-03,  5.0106e-04,\n",
            "         5.7696e-04,  1.3348e-04, -2.8804e-04, -4.1304e-05,  9.0242e-04,\n",
            "        -5.2857e-05, -1.5766e-04, -4.9267e-05, -1.3996e-04,  1.1267e-04,\n",
            "         3.0964e-04,  2.2235e-05,  9.3881e-06,  9.2108e-05, -9.1351e-05,\n",
            "        -1.4845e-04,  8.2148e-05, -8.1636e-05, -1.0541e-04, -6.0357e-04,\n",
            "         4.3647e-04,  6.3186e-05, -3.4399e-04, -3.7190e-04, -2.8907e-04,\n",
            "        -9.9190e-05,  2.1000e-04,  4.5028e-05,  6.5928e-07,  5.9258e-04,\n",
            "         1.2823e-05,  7.0517e-05,  4.0276e-04,  5.2056e-04,  2.2462e-05,\n",
            "        -7.6216e-06, -1.0252e-04, -1.0528e-04, -2.3849e-04,  5.4536e-04,\n",
            "        -3.1017e-04,  2.6118e-05, -1.7024e-04,  4.9651e-04, -1.4955e-04,\n",
            "         7.0952e-05,  4.4821e-04,  5.1565e-05,  3.1941e-04,  1.4635e-04,\n",
            "        -8.6094e-06, -2.0385e-04, -3.7171e-04, -7.0513e-05,  5.0653e-05,\n",
            "        -3.3993e-04, -1.0777e-04, -5.7631e-05,  7.9527e-05,  6.1585e-04,\n",
            "        -8.0290e-07,  2.0718e-04,  5.1406e-05,  2.0128e-04, -3.3986e-04,\n",
            "        -5.9615e-06,  2.2659e-04, -1.1666e-04, -1.9311e-04,  5.7991e-05,\n",
            "         5.5740e-06, -5.2793e-05,  7.7133e-04,  2.0497e-04, -1.6820e-05,\n",
            "         7.1342e-04,  1.2428e-03,  3.0502e-04, -3.9729e-05,  4.5244e-04,\n",
            "        -2.1478e-04,  1.0705e-04, -7.2978e-06, -2.0119e-04, -1.0496e-04,\n",
            "        -1.0949e-04,  1.0040e-03,  1.2355e-04,  4.2010e-04, -5.7419e-05,\n",
            "         5.4229e-04,  4.1140e-05, -1.9059e-04,  2.0644e-04,  8.2610e-04,\n",
            "         3.0977e-05,  1.3968e-04, -9.2708e-06,  8.9038e-05, -5.5044e-05,\n",
            "         1.1173e-04, -1.0560e-04, -3.4548e-04,  2.0993e-05,  1.8101e-04,\n",
            "        -1.0096e-04, -9.7271e-05, -1.0645e-05, -1.8532e-04,  9.7531e-05,\n",
            "         3.3681e-07, -6.8495e-06, -3.0324e-04, -8.3316e-05, -2.9688e-05,\n",
            "        -1.2314e-04, -1.0048e-04,  1.7191e-04,  6.0149e-04,  1.9448e-04,\n",
            "         2.2319e-04, -2.1585e-04,  5.8657e-05, -1.3083e-04, -6.8198e-05,\n",
            "        -3.0996e-04,  2.8105e-05,  1.8349e-04, -1.9715e-05,  3.3506e-05,\n",
            "         2.3227e-04, -9.2120e-05,  1.4221e-04, -8.1226e-05,  1.9434e-04,\n",
            "        -3.0391e-04,  6.1059e-07,  1.0690e-04, -4.7117e-04,  3.9096e-05,\n",
            "        -1.7919e-05, -3.6132e-04,  3.7888e-04,  7.3059e-05,  4.2202e-04,\n",
            "         1.6355e-05, -1.2025e-04, -2.1548e-05,  3.2265e-04,  4.2388e-05,\n",
            "        -1.5008e-04,  2.4275e-05])), ('module.encoder_q.layer4.2.bn1.running_mean', tensor([-2.7665e-01, -1.0639e+00, -1.4043e+00,  1.8439e+00,  3.2544e+00,\n",
            "         3.8121e-01,  1.0116e+00, -2.8016e+00,  1.2846e+00,  2.7120e+00,\n",
            "         6.4721e-01, -2.3028e+00,  9.4120e-01,  3.7850e+00, -1.2715e+00,\n",
            "         5.6468e-01, -7.3922e-01, -1.7048e+00,  8.2632e-01, -9.7548e-01,\n",
            "         1.6980e+00, -3.2310e+00,  9.2324e-01,  2.7112e+00, -7.0497e-01,\n",
            "        -2.6458e+00, -4.6770e+00,  1.7797e+00, -2.0598e-01, -1.5931e+00,\n",
            "        -1.6838e+00,  2.1821e-01,  3.4833e+00, -3.5423e+00, -9.3866e-01,\n",
            "         2.4798e+00,  7.1772e-02,  2.7426e+00, -3.0762e+00, -2.6963e+00,\n",
            "         3.7440e+00, -5.6603e-01,  3.3466e-02,  2.0690e+00,  9.1919e-01,\n",
            "        -3.8351e-01, -1.8546e+00, -1.6960e+00, -1.0180e-02, -2.4661e-01,\n",
            "        -3.6187e-01,  2.2480e+00, -2.2689e-01, -3.0872e+00, -1.7507e+00,\n",
            "        -8.5097e-01,  4.2823e+00,  2.2083e+00, -1.1393e-01,  2.6137e+00,\n",
            "        -4.9741e-01, -4.4233e-01, -2.1282e+00, -4.7966e-02,  1.0151e+00,\n",
            "         8.5996e-01, -1.3863e+00,  1.4560e+00, -1.2201e+00, -1.7843e+00,\n",
            "         2.1433e-01, -3.1696e+00, -2.5499e+00, -3.8693e+00,  8.4529e-02,\n",
            "         1.0707e+00, -1.8830e+00,  2.8442e-01,  2.4707e-01,  3.0598e+00,\n",
            "         1.3490e+00,  2.1525e+00, -8.1231e-01, -3.0684e+00,  3.8914e-01,\n",
            "        -2.0166e-01,  4.3425e+00,  2.5281e-02, -2.8418e+00, -7.1654e-01,\n",
            "         2.0871e+00, -3.1726e-01, -1.5978e+00, -1.2154e-01,  2.1396e+00,\n",
            "        -1.3762e+00,  2.2113e+00,  3.6764e+00,  6.7848e-01,  1.0441e+00,\n",
            "        -5.2037e-01, -1.4122e+00, -5.4081e-01, -1.4562e+00,  1.0953e+00,\n",
            "         4.0744e-01,  4.6149e+00,  1.2886e+00,  2.2830e-01, -2.8066e+00,\n",
            "         4.3784e+00, -7.7347e-01, -2.2387e+00,  1.9602e+00, -5.3763e-02,\n",
            "        -7.2252e-01,  4.6184e-01, -1.1512e+00,  1.9378e+00,  4.8320e-01,\n",
            "        -3.1749e-01, -7.7280e-01,  5.0710e-01, -7.2140e-01,  3.8687e+00,\n",
            "        -3.6189e+00, -2.4784e-01, -7.4743e-02,  1.4857e-01, -2.3804e-01,\n",
            "        -5.3698e-01,  3.1860e+00, -1.9119e+00, -8.1864e-01,  2.3948e-01,\n",
            "         5.5680e-01, -9.6258e-01, -9.1746e-01,  1.3546e+00, -1.0054e+00,\n",
            "         1.4556e+00, -2.0680e+00,  2.0143e+00,  2.4166e+00,  8.2428e-01,\n",
            "         1.5585e+00, -2.2868e+00,  1.5070e+00,  3.0919e+00,  6.2830e-01,\n",
            "        -1.0827e+00,  1.2312e+00, -2.8633e+00,  5.0315e-01,  1.1903e+00,\n",
            "         4.2502e+00, -2.0478e-02,  1.6065e+00,  9.2609e-01,  2.7518e+00,\n",
            "         1.6954e+00, -6.0867e-02,  4.2693e-01, -5.5877e-01, -8.8189e-01,\n",
            "        -3.1733e+00,  1.6401e+00,  5.8538e-01,  1.3055e+00,  1.3711e+00,\n",
            "         3.3409e+00,  1.9745e+00,  3.0781e+00,  1.8740e+00,  1.1577e+00,\n",
            "         3.2606e+00, -1.2274e+00,  5.0640e-01,  2.9834e+00,  1.0262e+00,\n",
            "         7.9126e-01,  3.4973e+00,  2.8130e+00,  5.6435e+00, -3.1534e+00,\n",
            "         2.7105e+00,  7.2077e-01,  1.9966e-01, -2.8632e+00, -2.3127e+00,\n",
            "         2.3277e+00, -8.3222e-01,  1.2221e+00, -1.6414e-01, -3.0158e-01,\n",
            "         2.1652e+00,  5.7198e-01, -3.2384e+00,  9.9024e-01,  2.2422e+00,\n",
            "        -4.4585e-01,  1.1912e+00, -2.1083e+00, -2.1206e+00, -3.6092e-01,\n",
            "        -2.2276e+00,  2.4343e+00, -3.1439e+00, -7.3777e-01,  1.5374e+00,\n",
            "         8.6195e-01,  1.4275e+00,  2.3448e+00, -7.4972e-01, -5.3789e-01,\n",
            "         8.7379e-01, -2.8669e+00,  1.2574e+00, -2.2278e+00,  8.4994e-01,\n",
            "         1.1132e+00, -4.6140e-01, -1.8966e+00, -6.0533e+00,  3.7346e+00,\n",
            "        -2.9578e+00,  2.1955e+00,  2.0183e+00, -4.7130e+00,  8.5249e-01,\n",
            "        -2.1411e+00, -2.9960e+00, -9.7550e-02, -1.2967e+00,  1.9008e+00,\n",
            "        -2.5935e+00, -2.5723e+00,  3.1815e+00, -1.3294e+00, -5.1663e-01,\n",
            "        -5.4471e-01,  1.8701e+00,  8.7947e-01, -8.6462e-01, -6.9199e-01,\n",
            "         1.3572e+00,  1.6997e+00,  3.9245e-02, -1.2533e+00,  2.0448e+00,\n",
            "        -6.7534e-01,  9.7768e-01, -9.0983e-01, -3.3581e-01,  3.2519e-01,\n",
            "        -4.3397e+00,  5.2466e-01, -2.0416e+00, -1.3502e+00, -7.0094e-01,\n",
            "         4.3922e-01, -1.0060e+00,  3.8679e-01, -7.9460e-02,  1.2720e+00,\n",
            "        -3.4167e+00, -7.3402e-01,  2.4927e+00,  1.6845e+00,  1.5114e-01,\n",
            "         2.2465e+00,  1.6012e+00,  3.1639e+00, -3.3293e-01, -1.5380e+00,\n",
            "        -2.2527e+00, -1.5361e-01, -2.3066e-01,  2.6187e+00,  2.0787e+00,\n",
            "         2.4959e+00,  1.0477e+00, -1.3526e+00,  1.4968e+00,  3.5325e-01,\n",
            "         4.4542e-01,  2.7729e+00,  4.7141e+00, -6.2487e-01, -5.0173e+00,\n",
            "        -3.0339e-01, -1.4648e+00,  5.9708e-01, -9.4626e-01,  1.8698e+00,\n",
            "         5.3720e-01,  4.2957e-01,  1.3204e+00,  3.4013e+00, -1.1686e+00,\n",
            "        -2.3249e-01, -2.2642e+00,  7.5052e-01,  4.3195e+00,  3.2732e+00,\n",
            "        -4.1611e-01,  1.7966e+00,  4.5796e-01,  8.8418e-01, -1.3853e-01,\n",
            "         6.5533e-01, -1.3278e+00, -3.0089e+00,  6.7768e-01,  5.4365e-01,\n",
            "        -2.2788e+00, -4.1096e-02, -2.7943e+00, -2.8752e+00, -3.2837e+00,\n",
            "        -1.0080e+00, -2.9450e+00, -1.2847e+00, -1.7652e+00,  8.3879e-01,\n",
            "        -1.7026e+00, -2.1480e+00,  9.6647e-01, -3.0714e+00,  4.1044e+00,\n",
            "        -3.2828e+00,  1.5089e+00, -3.7941e-01, -7.2738e-01, -1.2586e+00,\n",
            "        -1.1574e+00, -1.2126e+00,  4.1477e-01,  8.7411e-01, -2.1055e+00,\n",
            "        -1.2394e+00,  1.3970e+00,  5.6449e+00,  1.2229e+00, -1.5140e+00,\n",
            "         2.8497e+00,  1.4915e-01, -1.5334e+00, -2.4487e+00, -6.9903e-01,\n",
            "         9.7557e-02, -3.9558e-01, -2.3980e+00, -3.7182e+00,  2.0163e+00,\n",
            "        -4.4798e+00,  2.0809e+00,  1.2082e+00, -1.5664e-01, -7.1695e-01,\n",
            "        -1.9349e+00, -4.8175e-01, -8.0299e-01,  1.2269e+00,  8.7520e-02,\n",
            "        -8.3647e-01,  9.3233e-01,  9.0648e-02, -8.3015e-01, -2.8338e-01,\n",
            "        -3.8396e-01, -6.8564e-01,  1.5160e+00, -1.6525e+00,  6.4898e-02,\n",
            "        -1.3744e-01, -1.1870e+00,  2.8261e+00, -6.9312e-01,  2.2458e+00,\n",
            "         3.6200e+00,  1.4083e+00,  5.0002e-01, -4.1868e-01,  3.5002e-01,\n",
            "         1.5326e+00, -2.1675e+00, -2.7001e+00, -1.8349e+00,  2.7265e+00,\n",
            "        -5.6330e-01, -1.8130e+00, -1.8550e-01,  2.7334e+00, -2.0449e+00,\n",
            "        -4.4321e-01, -4.7962e-01, -1.6855e+00, -1.6559e+00, -1.1960e+00,\n",
            "         4.3746e-01, -3.4033e+00, -1.3187e+00,  3.9078e-01, -1.3580e+00,\n",
            "         1.3445e+00, -2.2162e+00,  2.0112e-03,  1.4939e+00,  5.4474e-01,\n",
            "         7.5287e-01, -1.8117e+00, -3.0145e+00, -6.7450e-01, -7.4741e-01,\n",
            "        -3.2196e+00, -2.1817e-02,  6.0627e-01,  2.2794e+00,  3.8374e-01,\n",
            "        -2.6114e-01, -8.0070e-01,  2.8314e+00,  1.5091e+00,  4.2014e+00,\n",
            "         5.9909e-01,  7.0409e-01, -3.9582e-01,  2.2824e-01,  1.9707e+00,\n",
            "        -1.7578e+00, -1.6041e+00,  2.3044e+00,  2.7042e+00,  9.3412e-01,\n",
            "         4.6207e-01,  3.6244e-01,  9.9633e-01,  3.8853e-01,  2.4162e+00,\n",
            "        -1.4059e+00,  1.8699e+00,  6.7968e-01,  7.0296e-01,  1.1673e+00,\n",
            "        -1.1737e+00,  2.5200e+00,  6.6468e-01,  1.8984e+00, -6.8436e-01,\n",
            "        -8.9306e-01,  6.5112e-01, -5.5220e+00,  6.7510e-01, -1.9058e+00,\n",
            "        -8.0238e-01, -1.1727e+00,  1.9096e+00,  1.2901e+00,  1.7103e+00,\n",
            "        -1.6692e+00, -2.9715e+00, -1.4557e+00, -1.0677e+00, -3.2306e+00,\n",
            "         1.9845e+00,  1.0069e-01, -2.0097e+00,  7.7439e-01,  1.1939e+00,\n",
            "        -1.3119e+00, -9.7960e-01,  5.2535e-02, -1.9315e+00,  2.4158e-01,\n",
            "        -9.3523e-01, -1.3726e+00,  9.3305e-02, -9.2803e-03, -5.4374e-01,\n",
            "        -9.9216e-01, -3.5630e-01,  2.1061e+00,  8.3385e-01, -1.5681e-01,\n",
            "         1.0356e-01,  6.0662e-02,  2.3803e-01, -1.3215e+00, -3.9987e-01,\n",
            "        -1.0301e+00,  2.7916e+00,  1.5335e+00,  3.4709e+00, -4.2842e-01,\n",
            "        -1.5504e+00,  5.7254e-01,  1.0399e+00,  1.6365e-01, -5.5126e-01,\n",
            "        -1.4594e+00,  3.6063e+00,  1.6821e-01, -7.5213e-01, -6.9202e+00,\n",
            "         1.6243e+00, -2.9653e+00,  1.8707e+00, -8.6406e-01, -1.1657e+00,\n",
            "        -1.9310e+00,  3.3496e+00])), ('module.encoder_q.layer4.2.bn1.running_var', tensor([ 9.4259,  6.7769,  7.2231,  8.4920, 46.6181,  6.5052,  6.7698,  8.9710,\n",
            "         5.6788,  6.6907,  9.3059,  8.5957,  7.2571, 15.1400,  7.4789,  8.6742,\n",
            "         8.0150,  8.1589,  6.7753,  6.7778,  6.4307,  9.5143,  7.1157, 10.0646,\n",
            "         9.9903, 11.6764,  7.2540,  8.8913,  7.9707, 12.4140,  7.0694,  8.2274,\n",
            "        17.1134, 15.8368,  7.7725,  5.9943,  6.4649,  6.8100,  6.6442, 11.3284,\n",
            "        20.1432,  6.5052,  5.7488,  8.7992,  7.1372,  7.1894,  6.1117,  6.2575,\n",
            "         7.5081,  6.8024,  6.7327, 10.1791,  7.0562, 10.9723,  7.6241,  7.7257,\n",
            "        18.9463,  7.6087,  7.3275, 18.4512,  8.2257, 13.9872, 21.8324, 11.9190,\n",
            "        12.5838,  7.0157,  7.8111,  5.7164, 11.5298,  6.8456, 15.7795, 11.9339,\n",
            "        12.0059,  6.7541, 10.8133,  9.1709,  7.9163,  8.1011, 10.1077, 17.1905,\n",
            "        14.2005, 11.2840, 10.8781,  8.6754,  7.8813, 12.3884, 16.7917,  8.1083,\n",
            "        10.7865, 10.9483, 10.3310,  7.1077, 11.5226,  7.5514,  6.2506,  7.0545,\n",
            "         6.2431, 23.0465,  6.3201, 10.1482,  7.9616, 13.8907,  8.3855,  7.2509,\n",
            "         7.4159,  7.3947, 24.8191,  8.8609,  8.4826,  9.3333, 17.5831,  9.7247,\n",
            "        12.9314, 17.4170,  6.8375,  6.3857,  6.3398,  9.3787,  8.6915,  7.1289,\n",
            "        11.3142,  6.8126,  7.4573,  7.3342, 24.9281, 14.1024, 11.1496,  5.6433,\n",
            "         7.2723,  7.1770, 11.4124,  7.0035, 11.4433,  6.3892,  7.9998,  7.7953,\n",
            "         6.9413,  7.0925,  9.1053,  6.9875,  8.2897, 13.0282, 11.4257,  9.6136,\n",
            "         8.0156,  5.8565,  7.6967,  7.1125, 11.9488,  6.5188,  9.2255,  6.8337,\n",
            "         9.6965,  8.8612,  5.8221, 20.4967,  5.8842,  6.1111,  6.3386, 10.2252,\n",
            "         6.4641,  6.6896,  7.3835,  8.1569,  9.0116, 15.5031, 15.7760,  7.8242,\n",
            "         9.1117, 10.2966, 10.9311,  5.8705, 21.8168,  6.8932,  6.3797, 14.8772,\n",
            "         7.2805,  8.6934, 23.5590,  9.6562,  8.1189,  7.3303, 11.7091, 33.7853,\n",
            "         9.5852, 10.6138,  8.6729,  8.8420, 15.2540, 10.5292,  7.1537,  9.0390,\n",
            "         9.1389,  7.3101,  8.8015,  7.1752,  7.7525, 12.4982, 15.0216,  7.3518,\n",
            "         5.7554, 12.7861, 14.2124,  6.3005,  8.6713,  9.7108, 19.4261,  6.5166,\n",
            "         8.3295, 16.8857, 10.4285,  5.9691, 11.1553,  6.2663,  6.7642, 10.1406,\n",
            "        12.0418,  6.6022, 12.7846,  6.5336, 11.4484,  6.1284,  7.8850, 45.7452,\n",
            "        19.4161,  7.0661, 11.5097,  7.3214,  8.0856, 19.5282,  6.0617, 14.1835,\n",
            "         6.4724,  6.5976,  7.0461, 14.3269, 12.0463,  7.6740,  6.3789,  7.1975,\n",
            "         5.7464, 16.0164,  9.6728,  7.5056,  7.2087, 16.6599,  6.2239,  5.6245,\n",
            "         7.6421,  7.8934,  8.8164,  7.0596, 10.8758, 11.2387,  8.2850, 11.8764,\n",
            "         6.4869,  7.3550,  7.5238, 10.4851,  6.2663,  7.4125,  6.2817,  7.3779,\n",
            "         8.4349,  7.4829, 15.8804,  7.6377, 13.9849,  8.6951, 11.7739,  6.7646,\n",
            "        12.4967,  6.6138,  6.8749, 24.3498,  7.0219,  7.7292,  8.1617, 15.1092,\n",
            "         7.3816, 10.0239, 15.9066,  7.9159,  7.9446,  8.1759,  8.3103, 19.9820,\n",
            "         7.9647, 28.5864,  7.3930,  6.2644,  8.9940,  6.7058, 13.0738,  5.9133,\n",
            "         9.3388,  6.8425, 15.2717,  6.5466,  6.0841, 19.8319,  6.7462, 17.3778,\n",
            "        12.9364,  7.6167,  6.5299,  7.1224,  8.1969,  7.3753, 10.2568,  6.7601,\n",
            "        13.0990,  7.7393,  9.8375,  6.3958,  9.2705,  6.5923, 12.2176,  9.9803,\n",
            "         8.6178, 15.8224,  6.2799,  5.6122,  8.2706, 17.0656,  8.3287,  6.3020,\n",
            "         8.5596,  8.6649,  8.8401,  6.9629,  7.5413,  9.6578, 11.0234,  8.2688,\n",
            "         7.6017,  7.8802,  5.8978,  7.3457,  8.9513,  6.6615, 23.0514, 15.3399,\n",
            "         8.1630,  8.7576,  6.4545,  6.0251, 15.7868, 10.4296,  7.0172,  6.2635,\n",
            "         7.9409, 16.7581, 18.2031, 18.4136, 23.2774,  6.8436, 11.8074, 12.6420,\n",
            "        14.9491,  6.6851,  6.3737,  6.4449, 14.1843,  8.4069,  7.7751,  8.9251,\n",
            "         8.1268,  6.6241,  7.8376,  7.7572, 17.7095,  8.6610, 13.1938,  8.7245,\n",
            "         7.0760,  6.2984,  6.8957, 17.9778, 20.5190,  5.7870,  6.5085, 15.0714,\n",
            "         7.2105, 10.5890,  7.4763, 13.7791,  7.9247, 17.7406,  6.7754,  7.4453,\n",
            "         6.1188,  8.5429,  6.8722,  9.6706,  7.3145,  6.5435,  6.6475, 12.5231,\n",
            "         8.8302, 15.9101,  7.3568, 11.4006,  6.8627, 15.6623, 14.6707,  8.5442,\n",
            "         9.2233, 10.4014,  6.4106, 11.5092, 11.2120,  8.1056,  9.0914, 10.7244,\n",
            "         6.1599,  7.3180,  6.1265,  6.4715,  8.0082,  8.9866, 15.1300,  7.7713,\n",
            "         6.9258, 11.6376, 10.2480,  7.4225,  7.0045, 13.6250,  9.1592,  7.4250,\n",
            "         7.6588, 12.0685,  8.4408,  7.4953,  8.5485, 11.3696,  8.2453,  8.1910,\n",
            "        15.0010,  7.2712, 10.7840,  6.0573,  6.6357,  7.2876, 17.9202,  7.4751,\n",
            "         8.2567,  8.1509, 13.2120, 11.0512, 31.1853,  5.8661, 21.5511,  6.4044,\n",
            "         6.7890, 12.0017,  6.5860,  7.3349,  6.5316, 12.8094,  6.4710,  6.0557,\n",
            "         6.4506,  6.3998,  7.9726,  6.4293,  6.0668,  6.6016,  7.0944, 11.7671,\n",
            "         9.1122,  6.2807,  7.1424, 13.9558,  7.1033,  8.0332,  8.3905,  6.9596,\n",
            "         9.7880,  7.9598, 12.8208,  8.3315,  6.6898,  8.4730,  7.2696,  5.8848,\n",
            "        12.0662,  9.1973,  6.3812, 12.7200,  6.9375, 15.4800,  7.5719,  7.6268,\n",
            "         7.9849, 12.7698,  6.9171, 10.2048, 14.1368, 18.3074,  7.6805, 14.6239,\n",
            "        37.8989,  8.8565, 10.6964, 14.8496,  9.5644, 10.9041, 10.4380, 21.8092])), ('module.encoder_q.layer4.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.2.conv2.weight', tensor([[[[-0.0105,  0.0049, -0.0310],\n",
            "          [ 0.0046,  0.0007, -0.0046],\n",
            "          [-0.0171,  0.0189,  0.0117]],\n",
            "\n",
            "         [[-0.0247,  0.0149,  0.0088],\n",
            "          [-0.0263, -0.0240, -0.0008],\n",
            "          [ 0.0145, -0.0084, -0.0149]],\n",
            "\n",
            "         [[ 0.0185,  0.0093, -0.0025],\n",
            "          [ 0.0176,  0.0036,  0.0125],\n",
            "          [-0.0321,  0.0116, -0.0296]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0061, -0.0127,  0.0142],\n",
            "          [ 0.0482,  0.0199, -0.0084],\n",
            "          [ 0.0124, -0.0192, -0.0255]],\n",
            "\n",
            "         [[-0.0195,  0.0106, -0.0014],\n",
            "          [-0.0215, -0.0104, -0.0392],\n",
            "          [-0.0149,  0.0101, -0.0176]],\n",
            "\n",
            "         [[ 0.0177,  0.0048, -0.0163],\n",
            "          [-0.0287, -0.0102,  0.0572],\n",
            "          [ 0.0191, -0.0171, -0.0182]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0233,  0.0110, -0.0192],\n",
            "          [-0.0040,  0.0118,  0.0137],\n",
            "          [ 0.0469,  0.0332,  0.0182]],\n",
            "\n",
            "         [[-0.0025, -0.0121, -0.0005],\n",
            "          [-0.0002, -0.0353,  0.0132],\n",
            "          [-0.0185, -0.0182, -0.0464]],\n",
            "\n",
            "         [[-0.0180,  0.0298, -0.0082],\n",
            "          [-0.0184,  0.0064,  0.0058],\n",
            "          [ 0.0190, -0.0068, -0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0276, -0.0455,  0.0432],\n",
            "          [-0.0200, -0.0224, -0.0237],\n",
            "          [-0.0328, -0.0147,  0.0018]],\n",
            "\n",
            "         [[ 0.0066,  0.0359,  0.0160],\n",
            "          [-0.0026, -0.0009, -0.0359],\n",
            "          [ 0.0203, -0.0020, -0.0193]],\n",
            "\n",
            "         [[ 0.0284, -0.0068, -0.0124],\n",
            "          [-0.0166, -0.0131,  0.0092],\n",
            "          [ 0.0353, -0.0199, -0.0032]]],\n",
            "\n",
            "\n",
            "        [[[-0.0207, -0.0163,  0.0165],\n",
            "          [ 0.0058, -0.0141, -0.0236],\n",
            "          [-0.0142, -0.0440,  0.0232]],\n",
            "\n",
            "         [[ 0.0356,  0.0182, -0.0055],\n",
            "          [-0.0235, -0.0274,  0.0100],\n",
            "          [-0.0136,  0.0049, -0.0352]],\n",
            "\n",
            "         [[ 0.0038,  0.0072,  0.0070],\n",
            "          [-0.0254, -0.0078, -0.0292],\n",
            "          [-0.0046, -0.0158,  0.0107]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0425, -0.0103,  0.0012],\n",
            "          [-0.0013,  0.0045,  0.0042],\n",
            "          [ 0.0220,  0.0097,  0.0304]],\n",
            "\n",
            "         [[ 0.0095, -0.0054,  0.0440],\n",
            "          [ 0.0017, -0.0004,  0.0227],\n",
            "          [ 0.0072, -0.0503,  0.0057]],\n",
            "\n",
            "         [[-0.0123, -0.0229,  0.0256],\n",
            "          [-0.0041, -0.0203, -0.0335],\n",
            "          [-0.0102, -0.0474,  0.0193]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0278, -0.0133,  0.0089],\n",
            "          [ 0.0042, -0.0242,  0.0136],\n",
            "          [-0.0231, -0.0368,  0.0021]],\n",
            "\n",
            "         [[-0.0194,  0.0029,  0.0005],\n",
            "          [-0.0058, -0.0074,  0.0165],\n",
            "          [ 0.0106, -0.0167,  0.0076]],\n",
            "\n",
            "         [[-0.0083,  0.0138, -0.0074],\n",
            "          [-0.0045, -0.0071,  0.0161],\n",
            "          [-0.0090, -0.0243,  0.0179]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0110, -0.0007,  0.0200],\n",
            "          [-0.0026, -0.0034,  0.0082],\n",
            "          [-0.0104, -0.0073, -0.0108]],\n",
            "\n",
            "         [[-0.0047, -0.0183,  0.0431],\n",
            "          [ 0.0151, -0.0021, -0.0257],\n",
            "          [ 0.0458,  0.0319,  0.0016]],\n",
            "\n",
            "         [[-0.0093, -0.0065, -0.0324],\n",
            "          [-0.0111, -0.0129, -0.0118],\n",
            "          [-0.0194,  0.0087, -0.0227]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0173,  0.0268,  0.0067],\n",
            "          [-0.0032, -0.0196,  0.0166],\n",
            "          [-0.0003, -0.0319, -0.0112]],\n",
            "\n",
            "         [[ 0.0154,  0.0118,  0.0381],\n",
            "          [-0.0054, -0.0241,  0.0501],\n",
            "          [ 0.0018,  0.0408, -0.0268]],\n",
            "\n",
            "         [[ 0.0156, -0.0162, -0.0025],\n",
            "          [-0.0037, -0.0107,  0.0145],\n",
            "          [-0.0525, -0.0049,  0.0293]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0097, -0.0183,  0.0018],\n",
            "          [ 0.0154, -0.0206, -0.0239],\n",
            "          [-0.0178, -0.0101,  0.0077]],\n",
            "\n",
            "         [[-0.0172,  0.0032, -0.0221],\n",
            "          [ 0.0238,  0.0141,  0.0107],\n",
            "          [ 0.0159,  0.0113, -0.0177]],\n",
            "\n",
            "         [[ 0.0349,  0.0034, -0.0017],\n",
            "          [-0.0091, -0.0038,  0.0053],\n",
            "          [-0.0067,  0.0178, -0.0209]]],\n",
            "\n",
            "\n",
            "        [[[-0.0232, -0.0142, -0.0134],\n",
            "          [ 0.0415,  0.0307, -0.0111],\n",
            "          [ 0.0106, -0.0091,  0.0191]],\n",
            "\n",
            "         [[-0.0106,  0.0039, -0.0130],\n",
            "          [-0.0443, -0.0030,  0.0123],\n",
            "          [ 0.0193,  0.0469, -0.0044]],\n",
            "\n",
            "         [[-0.0356,  0.0025, -0.0243],\n",
            "          [ 0.0032,  0.0222, -0.0159],\n",
            "          [-0.0431, -0.0202, -0.0263]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0010, -0.0131,  0.0282],\n",
            "          [-0.0102, -0.0151,  0.0127],\n",
            "          [ 0.0285, -0.0109,  0.0281]],\n",
            "\n",
            "         [[ 0.0067, -0.0134, -0.0018],\n",
            "          [ 0.0047, -0.0047, -0.0148],\n",
            "          [ 0.0146,  0.0037, -0.0283]],\n",
            "\n",
            "         [[ 0.0041, -0.0134, -0.0349],\n",
            "          [-0.0200, -0.0059,  0.0094],\n",
            "          [-0.0105,  0.0456,  0.0350]]]])), ('module.encoder_q.layer4.2.bn2.weight', tensor([0.9921, 0.9920, 0.9925, 0.9933, 0.9925, 0.9922, 0.9920, 0.9921, 0.9921,\n",
            "        0.9928, 0.9921, 0.9922, 0.9923, 0.9920, 0.9925, 0.9921, 0.9922, 0.9921,\n",
            "        0.9922, 0.9923, 0.9925, 0.9920, 0.9920, 0.9921, 0.9921, 0.9922, 0.9923,\n",
            "        0.9923, 0.9921, 0.9923, 0.9924, 0.9924, 0.9925, 0.9923, 0.9919, 0.9921,\n",
            "        0.9921, 0.9917, 0.9922, 0.9922, 0.9929, 0.9928, 0.9921, 0.9921, 0.9924,\n",
            "        0.9922, 0.9920, 0.9929, 0.9924, 0.9920, 0.9923, 0.9923, 0.9929, 0.9924,\n",
            "        0.9922, 0.9923, 0.9931, 0.9923, 0.9922, 0.9921, 0.9919, 0.9923, 0.9923,\n",
            "        0.9921, 0.9919, 0.9922, 0.9923, 0.9921, 0.9936, 0.9923, 0.9918, 0.9924,\n",
            "        0.9921, 0.9923, 0.9921, 0.9925, 0.9921, 0.9935, 0.9925, 0.9921, 0.9923,\n",
            "        0.9924, 0.9920, 0.9920, 0.9924, 0.9922, 0.9918, 0.9921, 0.9919, 0.9916,\n",
            "        0.9921, 0.9929, 0.9925, 0.9926, 0.9925, 0.9921, 0.9924, 0.9922, 0.9922,\n",
            "        0.9921, 0.9922, 0.9932, 0.9922, 0.9922, 0.9925, 0.9925, 0.9921, 0.9927,\n",
            "        0.9921, 0.9920, 0.9919, 0.9921, 0.9925, 0.9923, 0.9921, 0.9922, 0.9925,\n",
            "        0.9918, 0.9922, 0.9923, 0.9923, 0.9918, 0.9923, 0.9924, 0.9922, 0.9921,\n",
            "        0.9920, 0.9927, 0.9925, 0.9921, 0.9924, 0.9923, 0.9919, 0.9924, 0.9931,\n",
            "        0.9924, 0.9917, 0.9922, 0.9922, 0.9924, 0.9919, 0.9926, 0.9926, 0.9919,\n",
            "        0.9921, 0.9921, 0.9923, 0.9925, 0.9928, 0.9923, 0.9921, 0.9921, 0.9922,\n",
            "        0.9921, 0.9924, 0.9920, 0.9921, 0.9922, 0.9926, 0.9925, 0.9925, 0.9922,\n",
            "        0.9925, 0.9920, 0.9923, 0.9923, 0.9921, 0.9919, 0.9920, 0.9936, 0.9920,\n",
            "        0.9921, 0.9924, 0.9923, 0.9920, 0.9920, 0.9921, 0.9922, 0.9918, 0.9920,\n",
            "        0.9926, 0.9919, 0.9918, 0.9923, 0.9922, 0.9922, 0.9917, 0.9918, 0.9923,\n",
            "        0.9922, 0.9921, 0.9925, 0.9924, 0.9921, 0.9921, 0.9923, 0.9926, 0.9920,\n",
            "        0.9918, 0.9923, 0.9920, 0.9923, 0.9922, 0.9924, 0.9921, 0.9926, 0.9921,\n",
            "        0.9922, 0.9926, 0.9919, 0.9920, 0.9930, 0.9925, 0.9925, 0.9924, 0.9918,\n",
            "        0.9924, 0.9921, 0.9920, 0.9917, 0.9921, 0.9919, 0.9922, 0.9919, 0.9921,\n",
            "        0.9919, 0.9927, 0.9919, 0.9921, 0.9922, 0.9921, 0.9919, 0.9921, 0.9922,\n",
            "        0.9919, 0.9925, 0.9925, 0.9924, 0.9921, 0.9922, 0.9924, 0.9925, 0.9921,\n",
            "        0.9924, 0.9926, 0.9926, 0.9921, 0.9922, 0.9921, 0.9922, 0.9923, 0.9923,\n",
            "        0.9923, 0.9920, 0.9923, 0.9920, 0.9920, 0.9921, 0.9923, 0.9921, 0.9919,\n",
            "        0.9927, 0.9920, 0.9924, 0.9926, 0.9923, 0.9922, 0.9923, 0.9924, 0.9919,\n",
            "        0.9926, 0.9923, 0.9918, 0.9923, 0.9920, 0.9926, 0.9921, 0.9919, 0.9922,\n",
            "        0.9915, 0.9921, 0.9922, 0.9919, 0.9923, 0.9924, 0.9922, 0.9922, 0.9923,\n",
            "        0.9923, 0.9921, 0.9929, 0.9924, 0.9920, 0.9926, 0.9925, 0.9921, 0.9922,\n",
            "        0.9923, 0.9923, 0.9921, 0.9922, 0.9924, 0.9929, 0.9923, 0.9922, 0.9921,\n",
            "        0.9924, 0.9925, 0.9924, 0.9923, 0.9920, 0.9926, 0.9925, 0.9922, 0.9921,\n",
            "        0.9924, 0.9919, 0.9925, 0.9920, 0.9922, 0.9919, 0.9919, 0.9921, 0.9921,\n",
            "        0.9920, 0.9926, 0.9921, 0.9918, 0.9920, 0.9925, 0.9921, 0.9925, 0.9924,\n",
            "        0.9922, 0.9924, 0.9917, 0.9922, 0.9923, 0.9920, 0.9919, 0.9918, 0.9924,\n",
            "        0.9923, 0.9925, 0.9922, 0.9922, 0.9927, 0.9921, 0.9919, 0.9920, 0.9919,\n",
            "        0.9928, 0.9922, 0.9924, 0.9920, 0.9922, 0.9923, 0.9922, 0.9922, 0.9923,\n",
            "        0.9924, 0.9923, 0.9924, 0.9922, 0.9922, 0.9922, 0.9922, 0.9923, 0.9926,\n",
            "        0.9923, 0.9929, 0.9919, 0.9922, 0.9921, 0.9921, 0.9923, 0.9923, 0.9922,\n",
            "        0.9920, 0.9923, 0.9932, 0.9929, 0.9921, 0.9918, 0.9928, 0.9921, 0.9922,\n",
            "        0.9921, 0.9925, 0.9928, 0.9924, 0.9921, 0.9923, 0.9923, 0.9929, 0.9920,\n",
            "        0.9927, 0.9923, 0.9924, 0.9918, 0.9919, 0.9923, 0.9920, 0.9921, 0.9920,\n",
            "        0.9928, 0.9922, 0.9922, 0.9924, 0.9924, 0.9921, 0.9923, 0.9923, 0.9921,\n",
            "        0.9919, 0.9921, 0.9928, 0.9925, 0.9919, 0.9929, 0.9923, 0.9931, 0.9925,\n",
            "        0.9923, 0.9922, 0.9925, 0.9922, 0.9923, 0.9927, 0.9925, 0.9924, 0.9921,\n",
            "        0.9921, 0.9920, 0.9922, 0.9919, 0.9918, 0.9921, 0.9920, 0.9926, 0.9926,\n",
            "        0.9919, 0.9921, 0.9923, 0.9921, 0.9930, 0.9921, 0.9923, 0.9923, 0.9924,\n",
            "        0.9927, 0.9921, 0.9921, 0.9923, 0.9921, 0.9921, 0.9931, 0.9926, 0.9921,\n",
            "        0.9924, 0.9922, 0.9910, 0.9920, 0.9920, 0.9921, 0.9920, 0.9921, 0.9925,\n",
            "        0.9920, 0.9924, 0.9925, 0.9925, 0.9919, 0.9922, 0.9919, 0.9932, 0.9921,\n",
            "        0.9922, 0.9921, 0.9924, 0.9919, 0.9924, 0.9926, 0.9922, 0.9922, 0.9921,\n",
            "        0.9932, 0.9924, 0.9924, 0.9925, 0.9920, 0.9920, 0.9927, 0.9920, 0.9922,\n",
            "        0.9922, 0.9924, 0.9929, 0.9924, 0.9927, 0.9923, 0.9918, 0.9922, 0.9922,\n",
            "        0.9924, 0.9926, 0.9921, 0.9925, 0.9926, 0.9919, 0.9921, 0.9923])), ('module.encoder_q.layer4.2.bn2.bias', tensor([ 9.2807e-05, -3.5649e-04,  3.2092e-04,  9.7878e-04, -1.1831e-05,\n",
            "         3.0837e-04, -1.0279e-04, -7.0843e-05, -7.0355e-05,  7.0548e-04,\n",
            "        -5.4897e-05, -1.8554e-04, -1.0324e-04, -2.4911e-04,  4.2429e-05,\n",
            "        -3.8275e-04, -8.3636e-05,  9.6276e-06, -1.3262e-04, -1.1663e-05,\n",
            "         1.2396e-04, -2.5223e-05, -3.8687e-05, -1.9762e-04, -1.1658e-04,\n",
            "        -1.6895e-04, -2.9006e-05, -2.1499e-04, -2.1699e-04,  2.3341e-04,\n",
            "        -1.5288e-04,  9.1718e-06,  1.9718e-04, -1.1019e-04, -1.1096e-04,\n",
            "        -2.7363e-05, -1.5763e-04, -2.8016e-04, -6.6170e-05,  3.3036e-04,\n",
            "         1.0463e-04,  8.7137e-04, -2.4183e-04,  1.1192e-04,  6.6277e-04,\n",
            "         9.4649e-05, -3.0822e-04,  8.3756e-04,  1.6963e-05, -9.8747e-05,\n",
            "         2.9074e-04, -1.9523e-05,  3.8555e-04,  9.2764e-05, -2.2243e-05,\n",
            "         6.5776e-05,  5.8798e-04,  2.4943e-04, -3.1143e-04, -3.8099e-04,\n",
            "        -4.2797e-04,  1.8465e-05,  4.2711e-04, -4.4823e-04, -2.7808e-04,\n",
            "        -5.6292e-05, -5.7666e-05, -1.1214e-04,  1.0208e-03,  1.2854e-04,\n",
            "        -2.3624e-04,  5.2078e-04, -1.8306e-04,  1.5635e-05, -2.8172e-04,\n",
            "         9.4839e-05, -1.5299e-04,  1.3970e-03,  3.9480e-05, -1.2754e-04,\n",
            "         2.8347e-04,  4.0611e-04, -3.2029e-04, -4.7198e-04, -2.9468e-05,\n",
            "         2.0543e-05, -2.4573e-04, -6.0851e-05, -5.1882e-04, -1.7603e-04,\n",
            "        -6.6701e-05,  6.1395e-04,  5.8728e-04,  5.1503e-04,  1.3314e-05,\n",
            "        -2.1440e-04,  5.7471e-04,  3.6404e-05, -9.9467e-06,  2.6430e-05,\n",
            "         1.5694e-04,  7.1506e-04, -1.7957e-04,  4.6340e-05,  1.6908e-04,\n",
            "         1.6197e-05, -1.5539e-04,  8.4021e-04, -1.2009e-04, -1.6357e-04,\n",
            "        -2.4000e-04, -1.1192e-04,  1.4798e-05, -1.7483e-04,  3.0020e-05,\n",
            "         2.4293e-06,  6.3811e-05, -3.9699e-04,  3.9844e-05, -1.0369e-05,\n",
            "        -4.5761e-05, -2.3596e-04, -1.4748e-04,  4.0319e-04,  2.5393e-05,\n",
            "        -3.0125e-04, -5.7696e-05,  4.5092e-04,  9.3655e-05,  1.0826e-04,\n",
            "         3.8907e-04, -2.1810e-04, -1.9734e-04,  2.3599e-04,  9.1853e-04,\n",
            "         2.0227e-04, -2.0846e-04,  8.4124e-05, -6.3230e-05, -4.0609e-05,\n",
            "         1.9337e-04, -8.1660e-05,  4.0779e-04,  1.7183e-04, -1.3778e-04,\n",
            "        -3.3200e-04,  1.4243e-04,  2.7510e-04,  3.5350e-04,  1.9876e-04,\n",
            "         3.8531e-05,  3.8476e-05, -5.3028e-05, -2.0375e-04,  3.5241e-04,\n",
            "        -1.8128e-04, -3.1838e-04, -1.6721e-04, -1.0060e-04,  4.6364e-04,\n",
            "         2.6636e-04, -3.0937e-05,  1.8677e-04, -3.4714e-04,  5.6725e-04,\n",
            "         1.7138e-04, -2.0865e-04, -4.1709e-04, -8.1463e-05,  7.3132e-04,\n",
            "        -1.1207e-04, -1.0801e-04, -2.3667e-04,  1.4531e-04, -3.8766e-05,\n",
            "         1.2769e-04,  1.9305e-05,  1.2803e-04, -4.5619e-04, -2.2132e-04,\n",
            "         4.8850e-04, -1.8783e-04, -3.0542e-04, -2.7756e-05, -1.2141e-04,\n",
            "         1.8331e-05, -1.4989e-04, -1.2594e-04, -1.4533e-05,  3.5787e-05,\n",
            "        -3.3593e-04,  2.8301e-04,  5.5756e-04, -1.5395e-04, -2.2445e-04,\n",
            "         1.3584e-04, -5.0049e-05, -1.7107e-04,  4.6571e-05, -8.5545e-05,\n",
            "        -1.1191e-04,  3.7848e-05,  9.8716e-06, -5.6808e-05,  1.7851e-04,\n",
            "         4.6593e-04, -1.9289e-04, -9.6424e-05,  6.4635e-04, -2.0737e-04,\n",
            "        -2.1581e-04,  3.6460e-04,  1.3190e-04,  2.0142e-04, -3.8207e-06,\n",
            "        -3.9543e-04,  3.9098e-04, -3.8300e-04, -1.1195e-04, -2.3414e-04,\n",
            "        -1.9749e-04, -1.4718e-04, -7.6656e-05, -6.5841e-05, -1.0457e-05,\n",
            "        -3.3489e-04,  4.2779e-04, -5.6561e-04, -1.8790e-04, -5.9366e-05,\n",
            "         1.2315e-04, -2.2380e-04, -2.1576e-04, -7.3021e-06, -2.4153e-04,\n",
            "         3.8133e-04, -3.3355e-05, -7.5370e-05, -5.3702e-05,  1.6695e-04,\n",
            "         4.3190e-06,  2.5743e-04, -3.8571e-05,  2.9249e-05,  5.1451e-04,\n",
            "         9.1081e-05, -2.1994e-04, -1.1133e-04, -5.9819e-05,  4.4042e-05,\n",
            "         1.1121e-04, -5.3046e-05,  1.0046e-04, -1.0405e-04,  7.9218e-05,\n",
            "         8.5462e-05, -1.8309e-04, -1.8010e-04,  1.9497e-04, -2.3424e-05,\n",
            "        -2.4781e-04,  3.9883e-04, -1.1683e-04,  1.9784e-04,  6.8032e-04,\n",
            "         2.1692e-04, -5.7952e-05,  4.0468e-05,  1.2320e-04, -2.3510e-04,\n",
            "         7.8842e-06, -1.7251e-04, -1.7479e-04,  1.5832e-04,  8.1986e-05,\n",
            "         2.9782e-04, -1.7158e-04,  2.8857e-05, -1.0668e-04, -3.9333e-04,\n",
            "        -1.2397e-04, -5.3243e-04, -7.9571e-05, -9.7646e-05, -1.7613e-04,\n",
            "         5.7796e-05,  1.1043e-04,  8.9474e-05,  2.0447e-05, -1.9208e-04,\n",
            "         2.8142e-04, -1.1106e-04, -1.6588e-04,  6.3446e-04,  3.1880e-04,\n",
            "        -1.7831e-04, -2.1525e-04,  6.6283e-05,  7.5968e-05, -1.2038e-04,\n",
            "         1.8743e-04,  8.3285e-05,  5.3350e-04, -1.1704e-04,  9.8365e-05,\n",
            "         5.0513e-05,  3.3245e-04,  5.8811e-05,  1.6441e-04,  1.9340e-04,\n",
            "        -1.7999e-04,  2.3803e-04,  6.5541e-05, -8.3899e-05,  1.2824e-04,\n",
            "         4.0743e-05, -5.1107e-05, -1.2364e-05,  1.1160e-04,  3.5603e-05,\n",
            "         1.0436e-04, -2.2523e-04, -1.5218e-04, -1.3220e-04, -1.0847e-04,\n",
            "         4.9869e-04,  3.1090e-05, -1.3277e-04, -2.2258e-04,  1.8624e-04,\n",
            "         5.2620e-05, -5.9393e-05,  3.2910e-04, -1.9248e-05, -3.7508e-05,\n",
            "         9.7098e-05, -4.3255e-04,  8.7741e-05, -2.3697e-04, -1.3769e-04,\n",
            "        -1.0631e-04,  3.6364e-05,  5.3824e-04,  1.6484e-04,  1.6838e-04,\n",
            "         2.6691e-05,  4.1916e-04,  2.0566e-04, -2.0199e-04, -2.8595e-04,\n",
            "        -1.0233e-05,  2.2361e-04,  1.0422e-04,  7.2792e-04, -1.2555e-04,\n",
            "        -9.0504e-05,  1.8574e-04,  1.4765e-04, -7.2181e-06,  3.8111e-04,\n",
            "        -1.6438e-04,  3.6129e-04, -5.0322e-05, -1.3669e-04, -8.4186e-07,\n",
            "        -1.2043e-04,  4.2434e-05, -2.0789e-04,  5.8089e-04,  2.5350e-05,\n",
            "         4.7274e-04,  4.8688e-05,  5.8892e-05, -7.1765e-05, -5.3401e-05,\n",
            "         4.2687e-04,  8.4033e-05, -1.2909e-04, -2.4170e-04, -7.4953e-05,\n",
            "         1.0054e-03,  4.6767e-04, -1.1094e-04, -1.8041e-04,  3.1797e-04,\n",
            "        -2.0093e-04, -8.5012e-05,  1.0222e-04,  1.9875e-04,  2.5449e-04,\n",
            "         6.8731e-05, -1.7019e-04, -2.5553e-05, -1.5034e-04,  5.1073e-04,\n",
            "         2.0087e-04,  5.0737e-04,  4.9120e-04,  6.5136e-04, -6.4662e-04,\n",
            "        -2.8532e-04, -8.6274e-05, -9.4219e-05, -1.3252e-04, -8.9865e-06,\n",
            "         3.8678e-04, -8.9157e-05, -2.5077e-04,  3.6142e-04,  2.2950e-05,\n",
            "        -2.9322e-05, -1.5829e-04, -3.1982e-05, -1.9568e-04, -8.3232e-05,\n",
            "        -2.8128e-04,  5.1118e-04,  3.2860e-04, -1.5564e-04,  3.5565e-04,\n",
            "        -1.2369e-05,  9.6480e-04,  3.2112e-05, -4.2643e-09, -1.7643e-04,\n",
            "         4.7596e-04,  8.6522e-05, -1.0772e-04,  7.0707e-05,  1.2908e-04,\n",
            "         3.1408e-05, -1.7207e-04, -1.6534e-04, -1.2737e-05, -6.6585e-05,\n",
            "        -3.8896e-04, -1.8100e-04, -1.2794e-04,  2.3741e-05,  3.7628e-04,\n",
            "         2.4773e-04, -2.8102e-04, -4.9242e-05,  7.4711e-05, -9.3158e-05,\n",
            "         1.8994e-04, -2.1370e-04,  4.9815e-05,  4.9426e-04,  3.8017e-04,\n",
            "         1.0652e-04, -3.4952e-05, -8.3101e-05,  1.3099e-04, -1.2207e-04,\n",
            "         2.5750e-04,  5.7831e-04,  2.0548e-04,  2.4158e-04,  2.6529e-04,\n",
            "        -1.6448e-04, -9.4532e-04, -2.0260e-04, -2.5893e-04, -2.6730e-04,\n",
            "        -3.0054e-04, -7.0079e-05,  7.4229e-04, -2.9894e-04,  1.3171e-04,\n",
            "         8.1682e-04,  5.7025e-04, -5.6828e-04,  1.9615e-04, -4.3933e-04,\n",
            "         9.0437e-04, -4.3462e-05, -1.0562e-05, -4.7587e-06,  8.0706e-04,\n",
            "        -2.0270e-04,  2.8722e-04,  2.7373e-04,  4.7475e-04, -1.1255e-04,\n",
            "        -2.5790e-04,  8.8835e-04,  4.5970e-04,  2.7518e-04,  2.5582e-04,\n",
            "        -2.4983e-04, -1.8289e-04,  7.6359e-04, -1.1752e-04, -4.0004e-04,\n",
            "        -2.1261e-04,  2.4177e-04,  6.0475e-04, -2.9573e-05,  1.9118e-04,\n",
            "         5.0667e-05, -3.9623e-04, -2.2393e-04,  2.4050e-04, -1.5412e-04,\n",
            "         1.9603e-04,  5.4517e-04,  5.8313e-04,  1.9394e-04, -3.6851e-04,\n",
            "        -1.4018e-04,  1.8742e-04])), ('module.encoder_q.layer4.2.bn2.running_mean', tensor([ 1.0860e+00,  2.8953e-01,  1.4318e-01, -1.2372e-01,  2.3388e-01,\n",
            "        -2.7758e-01,  2.0136e-01,  7.7522e-02,  4.0647e-01, -5.4848e-01,\n",
            "        -4.1677e-01,  2.7951e-01, -1.1003e-01, -2.9010e-01, -3.1154e-02,\n",
            "        -5.3780e-01, -1.7313e-01,  1.3509e-01,  9.9514e-02,  2.7572e-02,\n",
            "         6.6338e-01,  1.6398e-01, -2.7484e-01, -7.6185e-02, -8.1922e-01,\n",
            "        -4.6849e-03,  5.2484e-01, -2.1618e-01, -2.6473e-01, -5.2442e-01,\n",
            "         1.9634e-01, -5.5212e-03, -3.1660e-01,  4.4410e-01, -4.9948e-02,\n",
            "        -1.7937e-01, -2.8085e-01,  6.8655e-01,  2.6283e-01, -5.9970e-01,\n",
            "        -6.2011e-02,  2.7788e-01, -3.2886e-01, -4.2513e-01, -7.7858e-01,\n",
            "        -2.4124e-01, -6.7931e-01,  2.4305e-02,  1.8933e-01, -2.7845e-01,\n",
            "        -5.7949e-01, -5.3657e-01, -1.1081e-01, -3.3618e-01, -4.7718e-01,\n",
            "        -6.4104e-01,  4.7076e-01, -7.4416e-01,  1.7478e-01,  4.1458e-01,\n",
            "         7.3164e-02,  3.6647e-01, -4.2067e-01,  1.0720e-01,  5.8992e-01,\n",
            "         3.8478e-01,  7.2933e-02, -3.1865e-01, -1.6622e-02, -5.6398e-01,\n",
            "         7.9432e-02, -2.6693e-01,  4.4931e-01, -7.5815e-01,  2.2925e-01,\n",
            "         8.9044e-02, -3.7374e-01,  8.7157e-01, -3.6202e-01,  4.2585e-02,\n",
            "        -1.8934e-01,  7.8962e-01, -2.1985e-01, -1.6292e-01,  1.6789e-01,\n",
            "        -6.2732e-01,  1.3925e-01,  9.8936e-01, -3.3912e-01,  9.0873e-01,\n",
            "        -1.9798e-01,  7.6893e-02,  3.9755e-01,  1.8364e-01,  7.3514e-01,\n",
            "         2.6840e-01, -6.4778e-01,  4.6131e-01, -1.1376e-01, -3.9288e-01,\n",
            "        -2.6517e-01,  2.7042e-01,  2.9125e-02, -8.0134e-03,  5.0260e-01,\n",
            "         3.2145e-01, -2.7114e-01, -1.7229e-01,  4.0200e-01,  2.6464e-01,\n",
            "         1.5786e-01,  2.6959e-02, -1.4604e-01,  3.0802e-01, -1.3568e-01,\n",
            "         1.3972e-02, -1.4272e-01,  4.4302e-01, -5.0416e-01,  2.8019e-01,\n",
            "        -5.3501e-02,  4.5774e-01,  1.5108e-02,  2.9755e-01, -1.0211e-03,\n",
            "        -5.2742e-01,  3.4616e-02,  2.7260e-01,  4.0743e-02, -2.5320e-01,\n",
            "        -6.1146e-01,  1.2910e-01, -5.9189e-01, -7.6808e-01,  7.0965e-01,\n",
            "         5.8716e-01, -2.0587e-01,  3.0392e-01,  1.6972e-01,  5.2139e-01,\n",
            "        -4.7887e-02,  4.0009e-02,  4.8299e-01,  3.9576e-01,  2.1959e-01,\n",
            "         4.3349e-01, -6.6380e-01,  1.0175e-01, -3.0042e-01,  7.9957e-01,\n",
            "        -3.2926e-01, -1.8530e-02, -2.2176e-01, -1.6291e-01, -6.4639e-01,\n",
            "        -1.1903e-01,  4.0969e-01, -3.8502e-01, -1.4206e-01,  2.5420e-01,\n",
            "         3.8424e-01, -3.5082e-01,  2.0768e-01,  1.0682e-01,  8.2729e-02,\n",
            "        -2.9766e-01,  3.2400e-01, -3.9728e-01, -3.1128e-01,  1.1590e+00,\n",
            "        -1.8045e-02, -7.7160e-01,  9.6617e-04,  9.9128e-02, -3.1061e-02,\n",
            "        -2.3359e-01, -2.9945e-01, -2.7825e-01, -3.9363e-01, -2.3994e-01,\n",
            "        -4.6407e-01,  5.7464e-01,  1.8825e-01, -7.4896e-04,  3.9809e-01,\n",
            "         2.6064e-01,  2.8273e-02,  1.7852e-01,  2.3720e-01, -9.6177e-01,\n",
            "        -1.5025e-01,  1.9777e-01, -2.4289e-01, -5.2305e-01, -7.4928e-02,\n",
            "         3.9515e-01,  2.6988e-01, -1.4655e-01,  2.5405e-01, -5.3881e-02,\n",
            "         3.8527e-01,  3.4796e-01, -1.3293e-01,  2.5499e-01,  1.5316e-01,\n",
            "        -5.4871e-01, -2.9668e-01,  3.2438e-02, -4.1432e-01,  2.3492e-01,\n",
            "         1.6716e-01,  3.0975e-02,  3.0982e-01,  9.3245e-02, -4.1997e-01,\n",
            "         4.9361e-01, -4.8258e-01,  1.2966e-01, -2.7349e-01,  1.8325e-01,\n",
            "        -6.7206e-01, -2.5315e-01, -6.9347e-02, -6.1631e-01,  2.3083e-01,\n",
            "        -2.4669e-02,  1.1686e-01,  1.0033e+00,  4.9886e-01, -7.9795e-01,\n",
            "         9.8700e-03,  6.6475e-01,  7.4877e-02, -4.9395e-01,  6.9653e-01,\n",
            "         7.1003e-01,  3.4843e-01, -1.6253e-01,  2.3630e-02,  2.0569e-01,\n",
            "        -2.7997e-01,  7.6968e-01,  2.2823e-01, -6.9723e-01, -5.2587e-01,\n",
            "         5.4435e-03, -9.0903e-01, -5.7229e-01,  2.2659e-01, -5.1976e-01,\n",
            "         2.2865e-01,  2.9095e-01, -1.6277e-01,  3.5071e-01,  3.6394e-01,\n",
            "         1.2716e-01, -3.5568e-01, -1.4798e-01, -2.3523e-02, -4.2039e-01,\n",
            "         1.3982e-01,  5.4136e-01,  3.1449e-02,  6.3349e-02, -6.4162e-01,\n",
            "         3.8501e-01, -2.0987e-01,  2.4076e-01, -2.5571e-01, -2.7524e-01,\n",
            "         3.6039e-01,  2.3439e-01,  2.7168e-02, -5.8496e-01, -8.5602e-03,\n",
            "         1.9572e-02,  4.4122e-02, -4.6195e-01,  1.6887e-01,  4.6923e-02,\n",
            "         1.1546e-01, -1.8792e-01, -3.3116e-01, -2.1398e-01,  3.7449e-01,\n",
            "        -4.1147e-01, -5.6567e-01,  2.7591e-01, -1.8175e-01, -3.5311e-02,\n",
            "         1.4435e-01,  1.5969e-01, -1.3229e-01, -3.1562e-01,  5.4828e-01,\n",
            "        -3.7140e-01, -2.2011e-01,  1.7253e-01, -3.8075e-01, -3.0895e-01,\n",
            "        -3.2271e-01, -1.1356e-01,  3.6133e-01,  6.2455e-01, -1.8421e-01,\n",
            "         3.6824e-01, -6.3631e-01,  9.2955e-01, -4.1125e-01, -7.0129e-01,\n",
            "         7.5812e-02, -1.6459e-02,  1.3424e-01,  3.0391e-01,  3.1174e-01,\n",
            "         4.9567e-01, -3.0015e-02,  9.1208e-01, -1.5417e-01, -1.3687e-02,\n",
            "        -1.2238e-01,  4.1036e-01,  4.9602e-02, -2.1522e-01, -6.6972e-01,\n",
            "         1.9476e-01, -2.0297e-01,  6.2635e-01, -2.1921e-01,  2.3582e-01,\n",
            "        -2.9731e-01,  6.8957e-02, -4.5758e-01, -2.2641e-01,  1.6936e-01,\n",
            "         7.9441e-01,  2.8575e-01,  9.2148e-01,  2.3822e-02,  4.0437e-01,\n",
            "        -1.9571e-01, -6.2547e-01, -1.7802e-01,  6.4697e-02,  4.0864e-01,\n",
            "        -2.8197e-01, -1.0993e-01,  7.8653e-02,  1.9910e-01,  3.2873e-01,\n",
            "         3.4074e-01,  1.1016e+00, -5.2062e-01, -3.3624e-01, -1.1120e-01,\n",
            "        -4.4273e-01,  2.3068e-01, -4.0042e-01,  9.9283e-02, -1.0539e+00,\n",
            "         7.0067e-01,  2.0501e-01,  2.1081e-01,  1.9618e-01, -9.4243e-01,\n",
            "         1.3694e-01,  3.8758e-01, -6.2582e-01, -4.2440e-01,  5.3799e-01,\n",
            "        -1.0268e-01,  2.7656e-01,  1.6579e-01, -4.2496e-01, -5.6536e-01,\n",
            "        -5.7800e-01,  7.9992e-02, -1.9697e-01, -6.0943e-02, -2.5589e-01,\n",
            "         1.5990e-01,  5.6002e-01,  9.1917e-01,  3.5905e-01,  3.2375e-02,\n",
            "         3.6757e-02, -2.8387e-01, -7.2415e-01,  2.9517e-01,  3.2731e-01,\n",
            "        -6.3623e-02, -5.1832e-01, -6.6113e-02, -4.6506e-01,  4.2831e-01,\n",
            "        -3.0238e-01,  5.4232e-02, -7.8216e-01, -2.6278e-01,  6.2076e-01,\n",
            "         1.4435e-02,  8.9619e-02,  1.1200e-01, -3.7999e-01,  4.1137e-01,\n",
            "         2.4997e-01,  4.0285e-01, -5.4083e-02,  2.2996e-01,  5.2497e-03,\n",
            "        -1.1732e-01,  2.4455e-01, -2.5119e-01, -3.8096e-01, -1.1853e-01,\n",
            "        -4.2358e-02, -3.5695e-01,  2.1013e-01, -1.1750e-01,  5.2440e-01,\n",
            "        -1.9100e-02, -7.1693e-01, -3.7023e-02,  2.5313e-01, -1.3913e-01,\n",
            "         2.8794e-01, -7.5611e-02,  2.7160e-02,  3.8152e-01,  6.1321e-01,\n",
            "         1.6099e-01, -4.9183e-01, -4.9738e-01,  7.0123e-01,  2.0746e-01,\n",
            "         9.9566e-01,  2.5562e-01,  4.3904e-01,  3.6217e-01,  2.3062e-01,\n",
            "         9.5275e-02,  4.8107e-01,  2.8427e-01, -8.0973e-01,  1.7880e-01,\n",
            "         3.2200e-01,  4.1020e-01, -5.6141e-02,  2.8911e-01,  1.9745e-01,\n",
            "         2.4358e-01,  2.6145e-01, -3.1297e-01, -9.1183e-01, -2.5487e-02,\n",
            "         1.6934e-01,  5.4233e-01, -7.3731e-02, -4.0182e-01, -3.2545e-01,\n",
            "         4.7566e-02,  4.1136e-01,  2.0810e-01,  2.9135e-01, -5.1259e-01,\n",
            "         1.1767e-01,  1.1807e-01, -4.2480e-01, -7.1498e-02, -4.4778e-01,\n",
            "         2.8025e-01, -4.9258e-01,  1.3658e-02, -1.0238e+00,  9.0505e-01,\n",
            "        -3.4648e-01, -7.6756e-02, -5.2104e-02, -4.4716e-01,  3.7129e-01,\n",
            "         9.7088e-01,  2.7488e-01,  6.4802e-01, -3.5836e-01,  8.7348e-02,\n",
            "         1.4259e-01,  6.3105e-01,  6.0923e-02, -4.1058e-01,  3.7619e-01,\n",
            "         1.0861e-01,  2.8438e-02,  1.4572e-01, -3.4371e-01, -3.1853e-01,\n",
            "         4.7581e-01, -6.7251e-01,  2.9397e-01, -2.0458e-01,  4.4937e-01,\n",
            "         1.7658e-01,  7.5884e-02, -3.1307e-01, -3.3946e-01,  4.2918e-01,\n",
            "        -3.1971e-03, -6.5061e-01, -8.5287e-01,  2.6221e-01, -8.5731e-02,\n",
            "         1.1927e-01,  1.0996e-01])), ('module.encoder_q.layer4.2.bn2.running_var', tensor([1.1751, 0.8811, 0.5035, 0.5791, 1.1133, 0.8450, 0.7272, 0.5394, 0.7696,\n",
            "        1.7227, 0.6902, 0.5376, 0.6013, 0.5584, 0.5229, 0.6651, 0.6491, 0.5651,\n",
            "        0.5566, 0.7073, 0.9162, 0.6094, 0.5401, 0.8264, 0.7686, 0.7650, 0.7768,\n",
            "        0.6108, 0.5450, 0.7512, 0.6236, 0.7485, 0.7328, 0.6560, 0.5623, 0.6750,\n",
            "        0.8500, 0.7169, 0.5034, 0.9169, 0.6253, 0.8094, 1.0575, 0.5811, 1.3062,\n",
            "        0.7136, 1.1127, 0.7750, 0.5699, 0.5018, 0.7242, 1.1263, 0.5355, 0.5373,\n",
            "        1.1080, 0.8903, 0.7472, 1.0438, 0.4516, 1.0113, 0.5282, 0.8804, 0.7429,\n",
            "        1.2809, 0.8184, 0.7458, 0.4356, 0.6135, 0.6376, 1.1520, 0.6128, 1.1915,\n",
            "        0.6290, 0.8355, 0.7169, 1.0384, 0.9163, 1.1837, 0.7824, 0.5923, 0.5766,\n",
            "        0.6645, 0.8053, 0.5602, 0.6155, 1.1073, 0.6287, 0.8663, 0.6764, 0.8412,\n",
            "        0.8825, 0.5699, 0.9773, 0.5860, 1.3966, 0.5188, 1.3386, 0.5665, 0.5132,\n",
            "        0.5616, 0.6135, 0.8961, 0.6084, 0.7608, 0.5914, 0.7578, 0.5366, 1.3070,\n",
            "        0.7891, 0.4740, 0.4662, 0.5214, 0.5934, 0.5367, 0.5838, 0.7505, 0.5758,\n",
            "        1.1643, 0.6667, 0.4866, 0.5221, 0.8362, 0.5309, 0.7599, 0.7498, 0.7176,\n",
            "        0.5362, 0.5817, 0.5704, 0.7082, 1.0415, 0.4819, 1.0961, 1.5057, 1.2015,\n",
            "        1.4287, 0.5461, 0.5465, 0.5422, 1.1343, 0.7824, 0.6799, 0.7360, 1.0091,\n",
            "        0.7550, 1.4787, 0.8667, 0.5543, 0.6173, 0.8657, 1.0490, 0.5653, 0.6092,\n",
            "        0.4655, 0.8746, 0.5473, 0.7887, 0.7833, 0.6369, 0.5566, 0.5491, 0.7801,\n",
            "        0.5584, 0.5752, 0.8224, 0.8450, 0.7267, 0.6274, 0.5709, 1.1567, 0.6271,\n",
            "        0.7710, 0.7442, 0.7022, 0.6658, 0.9541, 0.6722, 0.7691, 1.4905, 0.6060,\n",
            "        0.8808, 0.5112, 0.5916, 0.6238, 0.7430, 0.5592, 0.9342, 0.7067, 0.6802,\n",
            "        0.8288, 0.9654, 0.5588, 0.9386, 0.7317, 0.5150, 0.6067, 1.1271, 0.5688,\n",
            "        0.6180, 0.5683, 0.6427, 0.7655, 0.5178, 0.9074, 0.6173, 0.8399, 0.5282,\n",
            "        0.5152, 1.0018, 0.5517, 0.5168, 0.8261, 0.5006, 0.5880, 0.5127, 1.2040,\n",
            "        0.6747, 1.0696, 0.5054, 0.8356, 0.7309, 0.4881, 0.7259, 0.5935, 0.5516,\n",
            "        0.5348, 0.5486, 0.8140, 0.8303, 0.7537, 0.7155, 0.6091, 0.5384, 0.5171,\n",
            "        0.4955, 1.1461, 1.0802, 0.5131, 0.5796, 0.6192, 0.6109, 1.3217, 0.5669,\n",
            "        0.6233, 1.1088, 0.6065, 0.9751, 0.7510, 0.8694, 0.6332, 0.5751, 0.6976,\n",
            "        0.5356, 0.8859, 0.6492, 0.7265, 0.7471, 0.5191, 0.6131, 0.7052, 0.5093,\n",
            "        0.8103, 0.5977, 0.5329, 0.9590, 0.8888, 0.5146, 0.8437, 0.6074, 0.5300,\n",
            "        1.0020, 0.4709, 0.7998, 1.1935, 0.6151, 0.5167, 0.5114, 0.6180, 0.5882,\n",
            "        0.6399, 0.5768, 0.6740, 0.4911, 0.7565, 0.7007, 0.9457, 0.8421, 0.5467,\n",
            "        1.1334, 0.5307, 1.1314, 0.5850, 0.6081, 1.0744, 1.2394, 0.9042, 0.6022,\n",
            "        0.7349, 0.6586, 0.5539, 0.7538, 0.5951, 0.7700, 0.5639, 0.8505, 0.5373,\n",
            "        1.4291, 1.1162, 1.2897, 1.4854, 0.5328, 0.5308, 0.5321, 0.4866, 0.5723,\n",
            "        0.7868, 0.5489, 0.9232, 0.5264, 0.8838, 0.6568, 0.6669, 0.5437, 0.4644,\n",
            "        0.6794, 0.5733, 0.5283, 0.4793, 0.5852, 0.5683, 0.6254, 0.6184, 0.8926,\n",
            "        0.8305, 0.6352, 1.1289, 0.7639, 0.7736, 0.6685, 0.6512, 0.5122, 1.0850,\n",
            "        0.8191, 0.5651, 0.8901, 0.5065, 0.5513, 0.9271, 0.6445, 0.5631, 0.5500,\n",
            "        2.1739, 1.6337, 0.9661, 0.6354, 1.1430, 0.6739, 0.5567, 0.7901, 1.6021,\n",
            "        1.3433, 0.8551, 1.2880, 0.5502, 1.8681, 0.7320, 0.7113, 0.9703, 1.5207,\n",
            "        0.6103, 0.4950, 0.6183, 0.5610, 1.3217, 0.7366, 1.1448, 0.5394, 0.6193,\n",
            "        0.5093, 0.5440, 0.6270, 1.0021, 0.8300, 0.5295, 0.6532, 0.6996, 0.4924,\n",
            "        0.7060, 0.5292, 0.7655, 0.6215, 0.5384, 0.7029, 0.6884, 0.5795, 0.5753,\n",
            "        0.5135, 1.2346, 1.1235, 1.2468, 0.6062, 0.5886, 0.5705, 0.8049, 0.5636,\n",
            "        0.7466, 0.8100, 0.7294, 0.9899, 0.6952, 0.8362, 0.5492, 0.5671, 0.6589,\n",
            "        0.7163, 0.5631, 0.7629, 0.7186, 0.6723, 0.9542, 0.8818, 1.7736, 0.5290,\n",
            "        0.5250, 0.4865, 0.7149, 1.1089, 0.4890, 0.9447, 1.1911, 0.5269, 0.7410,\n",
            "        0.8587, 1.6921, 0.5165, 1.2369, 0.5253, 0.7030, 0.5027, 0.9288, 0.5090,\n",
            "        0.5371, 0.4910, 0.7464, 0.6258, 1.0733, 0.5485, 0.5832, 1.1228, 1.2121,\n",
            "        0.6040, 0.6136, 0.6631, 1.2355, 0.5204, 0.8984, 0.9078, 0.5475, 0.9953,\n",
            "        1.3773, 0.6327, 0.7836, 0.8524, 0.4928, 0.6305, 0.4806, 0.6137, 1.2605,\n",
            "        0.5120, 1.5088, 0.5443, 1.0835, 0.5588, 1.7311, 0.9126, 0.5761, 0.6243,\n",
            "        0.4800, 1.0941, 1.0136, 0.9876, 0.8101, 0.8693, 1.0962, 0.5407, 0.6008,\n",
            "        0.9239, 0.8583, 0.5766, 1.0493, 0.7240, 0.4888, 0.8887, 0.6720, 0.7605,\n",
            "        0.4878, 0.8481, 0.9313, 0.8719, 0.7924, 0.5565, 0.7271, 0.7939, 0.8228,\n",
            "        0.7754, 0.8355, 1.9534, 1.8371, 1.0448, 0.5068, 0.5821, 0.6704])), ('module.encoder_q.layer4.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_q.layer4.2.conv3.weight', tensor([[[[-0.0247]],\n",
            "\n",
            "         [[ 0.0010]],\n",
            "\n",
            "         [[-0.0740]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         [[-0.0450]],\n",
            "\n",
            "         [[ 0.0487]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0631]],\n",
            "\n",
            "         [[-0.0264]],\n",
            "\n",
            "         [[-0.0074]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0511]],\n",
            "\n",
            "         [[-0.0134]],\n",
            "\n",
            "         [[-0.0433]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0548]],\n",
            "\n",
            "         [[ 0.0170]],\n",
            "\n",
            "         [[-0.0089]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         [[ 0.0056]],\n",
            "\n",
            "         [[-0.0159]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0288]],\n",
            "\n",
            "         [[ 0.0160]],\n",
            "\n",
            "         [[ 0.0510]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         [[-0.0148]],\n",
            "\n",
            "         [[ 0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0311]],\n",
            "\n",
            "         [[-0.0256]],\n",
            "\n",
            "         [[-0.0493]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0383]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         [[ 0.0187]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0203]],\n",
            "\n",
            "         [[-0.0312]],\n",
            "\n",
            "         [[ 0.0018]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0213]],\n",
            "\n",
            "         [[ 0.0094]],\n",
            "\n",
            "         [[ 0.0399]]]])), ('module.encoder_q.layer4.2.bn3.weight', tensor([0.9925, 0.9922, 0.9919,  ..., 0.9921, 0.9925, 0.9925])), ('module.encoder_q.layer4.2.bn3.bias', tensor([ 0.0009,  0.0001, -0.0001,  ..., -0.0011, -0.0001,  0.0002])), ('module.encoder_q.layer4.2.bn3.running_mean', tensor([-0.3315, -0.1342,  0.1669,  ..., -0.4838,  0.4967,  0.4036])), ('module.encoder_q.layer4.2.bn3.running_var', tensor([0.2018, 0.1532, 0.1893,  ..., 0.1661, 0.1781, 0.2686])), ('module.encoder_q.layer4.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_q.fc.weight', tensor([[ 0.0153,  0.0007,  0.0007,  ..., -0.0093,  0.0170, -0.0107],\n",
            "        [-0.0072,  0.0020,  0.0161,  ...,  0.0053, -0.0132,  0.0077],\n",
            "        [ 0.0110, -0.0090, -0.0168,  ..., -0.0198, -0.0126,  0.0135],\n",
            "        ...,\n",
            "        [-0.0193, -0.0010,  0.0111,  ..., -0.0164,  0.0078, -0.0091],\n",
            "        [ 0.0033, -0.0089, -0.0216,  ...,  0.0152,  0.0005,  0.0087],\n",
            "        [-0.0197,  0.0038,  0.0084,  ...,  0.0117,  0.0152,  0.0001]])), ('module.encoder_q.fc.bias', tensor([ 0.0110, -0.0122, -0.0019, -0.0083,  0.0008,  0.0131,  0.0179, -0.0202,\n",
            "         0.0156,  0.0069, -0.0223,  0.0013, -0.0215, -0.0126, -0.0211, -0.0118,\n",
            "         0.0132,  0.0231,  0.0017, -0.0058, -0.0120,  0.0008,  0.0073,  0.0168,\n",
            "        -0.0152,  0.0131,  0.0053,  0.0094,  0.0162, -0.0063, -0.0197,  0.0112,\n",
            "        -0.0010, -0.0045, -0.0151, -0.0071,  0.0138, -0.0145,  0.0243,  0.0091,\n",
            "         0.0216, -0.0024,  0.0190, -0.0063, -0.0005,  0.0174, -0.0166, -0.0150,\n",
            "         0.0074, -0.0219,  0.0084, -0.0169,  0.0107, -0.0013,  0.0226, -0.0196,\n",
            "        -0.0037,  0.0117, -0.0063, -0.0095, -0.0143, -0.0195,  0.0140, -0.0020,\n",
            "        -0.0051, -0.0073, -0.0118,  0.0192, -0.0042, -0.0088,  0.0082, -0.0184,\n",
            "        -0.0240,  0.0003, -0.0081, -0.0203, -0.0017,  0.0082,  0.0023, -0.0156,\n",
            "        -0.0046,  0.0228, -0.0067, -0.0012,  0.0006,  0.0033, -0.0126, -0.0116,\n",
            "         0.0033,  0.0102, -0.0028,  0.0192,  0.0065, -0.0252,  0.0014,  0.0199,\n",
            "         0.0111,  0.0093, -0.0179, -0.0062,  0.0123, -0.0155, -0.0123, -0.0235,\n",
            "        -0.0181, -0.0139, -0.0084, -0.0064, -0.0141,  0.0044,  0.0055, -0.0054,\n",
            "         0.0146, -0.0040,  0.0144, -0.0160,  0.0035,  0.0108,  0.0184,  0.0213,\n",
            "        -0.0209, -0.0095, -0.0300, -0.0032,  0.0117, -0.0074, -0.0221,  0.0122])), ('module.encoder_k.conv1.weight', tensor([[[[-2.3822e-02,  2.0272e-02,  4.5412e-02,  ...,  2.6610e-03,\n",
            "           -8.5051e-03,  2.7393e-02],\n",
            "          [ 5.3267e-02,  7.6691e-03,  9.0444e-03,  ...,  3.0639e-02,\n",
            "           -6.5786e-04,  3.9461e-02],\n",
            "          [ 2.3390e-02,  1.8066e-02,  2.2151e-02,  ...,  1.3872e-02,\n",
            "            2.9309e-02, -2.3002e-02],\n",
            "          ...,\n",
            "          [ 7.3761e-03,  2.3967e-02, -7.3209e-03,  ...,  3.3089e-02,\n",
            "           -4.1222e-02,  1.2591e-02],\n",
            "          [-1.5109e-02,  5.5249e-02,  4.8684e-02,  ..., -1.0132e-02,\n",
            "            2.4371e-02,  2.8756e-02],\n",
            "          [ 2.9313e-03,  1.7480e-02, -6.1428e-03,  ..., -4.5294e-03,\n",
            "           -1.9212e-02, -2.0991e-02]],\n",
            "\n",
            "         [[ 7.5187e-02, -5.3382e-03,  4.2944e-02,  ...,  2.8294e-02,\n",
            "           -2.3198e-02,  1.2445e-02],\n",
            "          [ 6.5991e-02,  7.7779e-03,  4.8622e-02,  ...,  7.0514e-02,\n",
            "            5.5582e-02,  2.2070e-02],\n",
            "          [ 2.1261e-02,  7.7224e-02,  5.3213e-02,  ..., -1.3843e-02,\n",
            "            2.4797e-02,  5.5084e-02],\n",
            "          ...,\n",
            "          [-1.9718e-04,  3.3690e-02, -7.9294e-03,  ...,  1.9184e-02,\n",
            "            2.0264e-02, -6.1055e-02],\n",
            "          [ 4.8505e-02,  3.8088e-02,  1.5038e-02,  ...,  5.6877e-04,\n",
            "            1.2662e-03, -1.6441e-02],\n",
            "          [ 3.2274e-02,  2.2943e-02,  3.3364e-02,  ...,  4.4766e-02,\n",
            "           -3.7557e-02,  3.0476e-02]],\n",
            "\n",
            "         [[ 4.9322e-02,  1.6634e-02, -2.5396e-02,  ..., -1.0894e-02,\n",
            "            4.7334e-02,  4.2247e-02],\n",
            "          [ 1.3231e-02, -5.3767e-03,  5.2549e-04,  ..., -8.5303e-04,\n",
            "            3.6370e-02,  6.6642e-03],\n",
            "          [ 7.8663e-02,  3.0396e-02, -2.6336e-02,  ...,  1.1583e-02,\n",
            "            5.4666e-03,  2.5932e-02],\n",
            "          ...,\n",
            "          [ 4.3903e-03,  5.4543e-02, -3.9242e-03,  ...,  3.0200e-02,\n",
            "            1.6359e-02,  6.3063e-02],\n",
            "          [ 1.4583e-02,  4.2978e-02,  3.8711e-02,  ...,  6.5271e-03,\n",
            "            1.8903e-02,  5.2791e-02],\n",
            "          [ 3.8707e-02,  5.0494e-02,  6.2053e-03,  ..., -2.6370e-02,\n",
            "            3.9950e-02,  4.3621e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.8597e-03, -4.9850e-03, -1.3927e-02,  ...,  3.3952e-02,\n",
            "           -2.0834e-02, -1.0341e-02],\n",
            "          [ 4.0396e-02, -1.8385e-02,  4.0479e-02,  ..., -1.2165e-02,\n",
            "           -4.2987e-02, -5.1635e-02],\n",
            "          [ 1.8804e-02, -7.5629e-03,  9.3274e-03,  ..., -6.6014e-03,\n",
            "            1.5021e-02,  5.5538e-03],\n",
            "          ...,\n",
            "          [-5.7994e-02,  1.2041e-02,  2.9080e-03,  ..., -2.1883e-02,\n",
            "            2.0744e-02,  2.7391e-02],\n",
            "          [ 7.3913e-03, -5.7482e-03, -1.9110e-02,  ..., -2.6416e-02,\n",
            "           -2.9186e-03, -3.9362e-02],\n",
            "          [ 1.1957e-02, -2.6034e-02,  7.0782e-03,  ...,  2.3503e-02,\n",
            "           -7.6673e-03, -1.3047e-02]],\n",
            "\n",
            "         [[ 6.2162e-03,  2.0655e-02,  1.9193e-02,  ...,  7.3183e-03,\n",
            "           -7.8523e-03,  4.5027e-02],\n",
            "          [-3.6905e-02, -2.1033e-02, -7.7926e-05,  ..., -2.5394e-03,\n",
            "            5.0514e-02,  2.3080e-02],\n",
            "          [ 5.0307e-02,  1.1749e-02, -3.6924e-03,  ...,  2.4897e-02,\n",
            "           -1.4686e-02,  2.9266e-02],\n",
            "          ...,\n",
            "          [-7.9007e-03,  5.3656e-02, -5.0698e-02,  ...,  3.3451e-02,\n",
            "            1.5966e-02, -1.2628e-02],\n",
            "          [-2.0174e-02,  3.5587e-02,  2.0533e-03,  ..., -5.1934e-03,\n",
            "            1.1107e-02,  5.3944e-02],\n",
            "          [-4.5388e-02,  1.3344e-04, -4.1703e-03,  ..., -1.8806e-02,\n",
            "           -1.3215e-02,  8.1589e-03]],\n",
            "\n",
            "         [[-1.8166e-02, -7.4474e-04,  4.2817e-02,  ...,  3.8774e-02,\n",
            "           -1.5331e-02,  2.4924e-02],\n",
            "          [-1.6984e-03,  3.0642e-02,  5.7855e-02,  ..., -1.6612e-02,\n",
            "           -7.5591e-03,  2.6091e-02],\n",
            "          [ 8.1852e-03,  9.4645e-03,  8.5436e-02,  ...,  5.8743e-02,\n",
            "           -6.3789e-03, -7.3462e-03],\n",
            "          ...,\n",
            "          [-1.1482e-02,  2.6935e-02, -5.5997e-03,  ...,  4.3517e-02,\n",
            "           -1.8485e-02,  4.4887e-02],\n",
            "          [ 2.4600e-02,  1.1217e-02,  2.5384e-02,  ..., -2.8988e-02,\n",
            "            2.3393e-02, -2.9676e-02],\n",
            "          [ 1.4972e-02, -1.8370e-02,  3.4970e-02,  ...,  2.4622e-02,\n",
            "           -1.7682e-02, -7.8140e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.3054e-03,  4.7228e-02,  2.5232e-02,  ..., -3.4458e-03,\n",
            "            1.3513e-03,  2.9354e-02],\n",
            "          [-3.7777e-03,  1.3293e-02,  2.3139e-02,  ...,  4.1417e-04,\n",
            "           -4.9705e-04,  5.7632e-02],\n",
            "          [ 2.2183e-02, -1.5047e-02, -2.6590e-03,  ...,  7.7196e-03,\n",
            "            3.9061e-02,  3.3527e-03],\n",
            "          ...,\n",
            "          [ 2.2202e-02,  1.4391e-03, -3.8826e-02,  ..., -1.7827e-02,\n",
            "            2.8409e-02,  5.2669e-02],\n",
            "          [ 7.1264e-03, -1.0668e-02, -6.3057e-03,  ...,  3.9642e-02,\n",
            "            5.9455e-03, -1.5510e-02],\n",
            "          [ 2.7008e-02, -1.1921e-02,  1.9746e-02,  ...,  4.6858e-02,\n",
            "            1.7241e-02, -1.3335e-02]],\n",
            "\n",
            "         [[-2.6515e-03, -2.6069e-02,  1.8451e-02,  ..., -5.8490e-03,\n",
            "           -4.3023e-02,  6.1055e-02],\n",
            "          [ 4.3032e-02,  1.5279e-02,  8.8961e-04,  ...,  4.9452e-03,\n",
            "            6.2379e-02,  7.0806e-03],\n",
            "          [ 1.0125e-02, -1.2782e-03,  8.5832e-03,  ...,  8.7761e-03,\n",
            "            1.2748e-02,  6.1025e-02],\n",
            "          ...,\n",
            "          [ 6.2659e-03,  3.0839e-02, -2.2841e-02,  ...,  2.0373e-02,\n",
            "           -4.6318e-03,  1.9216e-02],\n",
            "          [ 5.0581e-02,  2.4748e-02, -4.3353e-02,  ...,  2.3075e-02,\n",
            "           -6.1350e-03,  4.6470e-02],\n",
            "          [ 1.7785e-02,  9.0170e-04,  2.7258e-02,  ..., -3.1938e-02,\n",
            "           -1.7586e-02,  2.6172e-02]],\n",
            "\n",
            "         [[ 3.2092e-02, -3.3494e-02,  3.8976e-03,  ..., -4.8845e-03,\n",
            "           -8.4910e-03, -8.6496e-03],\n",
            "          [-6.6981e-02, -2.8055e-03, -3.5671e-02,  ..., -3.9616e-03,\n",
            "           -3.6491e-02, -2.7480e-02],\n",
            "          [ 4.7331e-04,  5.7828e-02,  3.3880e-03,  ..., -4.9162e-02,\n",
            "            1.7325e-02,  5.0549e-03],\n",
            "          ...,\n",
            "          [ 1.4681e-02,  4.8563e-02, -1.3649e-02,  ...,  3.7257e-04,\n",
            "           -1.9977e-02,  1.2872e-02],\n",
            "          [ 3.8718e-02, -3.1494e-02, -1.3602e-02,  ..., -1.9082e-02,\n",
            "            1.6446e-02, -2.5988e-02],\n",
            "          [-4.4170e-02, -1.1695e-02,  2.4912e-02,  ...,  9.0002e-03,\n",
            "           -6.4089e-03,  8.9147e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5074e-03,  3.9613e-02,  2.8526e-02,  ...,  1.1106e-02,\n",
            "           -4.4030e-02,  4.4524e-02],\n",
            "          [-7.1016e-03, -3.2787e-02, -1.0296e-02,  ..., -2.5531e-03,\n",
            "            3.7215e-02,  2.5618e-03],\n",
            "          [ 3.1815e-02,  8.9395e-03, -4.8937e-02,  ..., -2.1405e-03,\n",
            "           -5.5548e-03,  2.5626e-02],\n",
            "          ...,\n",
            "          [-8.1377e-03,  2.6816e-03,  4.1724e-03,  ...,  2.8283e-02,\n",
            "            1.3274e-03,  6.2408e-02],\n",
            "          [ 1.6807e-02,  4.9718e-02, -2.6405e-03,  ...,  7.8931e-03,\n",
            "            1.0961e-02,  3.2408e-02],\n",
            "          [ 4.7423e-02, -3.2118e-03,  1.5802e-02,  ...,  1.8866e-02,\n",
            "            9.9085e-03,  1.5363e-02]],\n",
            "\n",
            "         [[-1.3020e-02,  1.3864e-02, -3.7825e-03,  ..., -8.3178e-03,\n",
            "            1.1752e-02, -1.4703e-02],\n",
            "          [-2.8528e-02,  3.5890e-03,  6.3435e-03,  ..., -3.9487e-02,\n",
            "           -4.7782e-03, -4.1945e-02],\n",
            "          [ 2.8718e-02, -4.0022e-02, -4.9873e-03,  ...,  8.0290e-03,\n",
            "           -4.1788e-03, -1.9099e-02],\n",
            "          ...,\n",
            "          [-4.2548e-02, -1.6004e-02, -3.3076e-03,  ...,  1.5981e-02,\n",
            "           -4.3660e-02, -1.0582e-02],\n",
            "          [-4.1486e-02,  2.8314e-02, -5.1436e-02,  ...,  2.1765e-02,\n",
            "            4.1774e-02,  1.3522e-02],\n",
            "          [ 1.3493e-02, -4.7428e-02, -1.2387e-02,  ...,  4.3600e-02,\n",
            "           -5.2692e-02,  3.3044e-02]],\n",
            "\n",
            "         [[-4.6805e-02, -2.8611e-02,  3.3372e-02,  ...,  1.4817e-03,\n",
            "           -1.9902e-02,  2.3050e-02],\n",
            "          [ 5.1958e-03,  1.2374e-02, -3.9466e-03,  ...,  3.8161e-02,\n",
            "           -1.0803e-01,  6.8323e-03],\n",
            "          [-2.0018e-02,  9.4219e-03, -4.7732e-03,  ..., -2.0634e-02,\n",
            "            1.8595e-02, -5.3983e-02],\n",
            "          ...,\n",
            "          [-1.3674e-02,  1.7175e-02, -3.6077e-02,  ...,  3.1702e-03,\n",
            "            8.6158e-03, -5.1626e-03],\n",
            "          [-4.5703e-03,  1.7105e-02,  4.7075e-03,  ..., -8.8571e-03,\n",
            "           -2.4781e-02, -3.1811e-02],\n",
            "          [ 3.2875e-02,  1.8490e-02,  1.9354e-02,  ..., -3.9430e-02,\n",
            "            1.8494e-02, -2.5873e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5254e-02, -1.5333e-02,  3.3787e-02,  ...,  2.9283e-02,\n",
            "            1.4084e-02,  4.6106e-02],\n",
            "          [ 4.2589e-04, -1.7639e-02, -1.0709e-02,  ...,  4.8704e-02,\n",
            "           -1.9952e-02,  2.7975e-02],\n",
            "          [-8.4425e-03, -3.3773e-02,  1.9277e-02,  ...,  2.6642e-03,\n",
            "            1.6541e-02, -4.5816e-02],\n",
            "          ...,\n",
            "          [-8.4524e-03, -1.7044e-02,  1.2592e-02,  ...,  2.1660e-02,\n",
            "            1.6925e-02,  9.8282e-03],\n",
            "          [ 8.5427e-03, -3.3724e-02, -9.8593e-03,  ...,  2.3789e-02,\n",
            "            1.1203e-02,  3.6571e-02],\n",
            "          [-3.1560e-02, -2.6831e-02,  1.5351e-02,  ...,  1.2456e-02,\n",
            "           -1.9500e-03,  1.9938e-02]],\n",
            "\n",
            "         [[ 1.7627e-02, -2.4966e-02, -7.7794e-03,  ...,  3.5146e-02,\n",
            "           -2.0607e-02, -1.4695e-02],\n",
            "          [-1.5532e-02, -4.8610e-02,  3.1493e-03,  ..., -2.2717e-02,\n",
            "           -1.4626e-03,  5.6087e-03],\n",
            "          [-3.0213e-02, -2.5478e-03,  1.9970e-03,  ..., -7.6733e-03,\n",
            "            9.2259e-05, -2.0690e-02],\n",
            "          ...,\n",
            "          [-9.4386e-03, -4.3935e-03,  6.5405e-03,  ..., -3.2841e-02,\n",
            "           -3.8565e-02,  2.9722e-03],\n",
            "          [-1.6292e-03, -5.1118e-03, -2.4184e-02,  ...,  4.5641e-03,\n",
            "           -3.6125e-03, -8.1225e-03],\n",
            "          [-3.3022e-02, -2.7061e-02, -1.7726e-02,  ...,  3.0010e-02,\n",
            "           -3.2767e-02, -5.5720e-02]],\n",
            "\n",
            "         [[ 7.3963e-02,  1.9193e-02,  8.9803e-03,  ..., -3.9853e-02,\n",
            "            8.6731e-03,  2.7103e-02],\n",
            "          [ 7.9466e-04,  2.4915e-02, -3.6557e-02,  ...,  1.4347e-02,\n",
            "            1.4232e-02, -3.0471e-02],\n",
            "          [ 1.2174e-02, -1.5037e-02, -1.3362e-02,  ...,  1.8020e-02,\n",
            "            3.7210e-02,  1.8085e-02],\n",
            "          ...,\n",
            "          [ 9.4386e-03,  1.0925e-02, -7.7489e-03,  ..., -1.0250e-03,\n",
            "           -2.5212e-02, -1.2537e-03],\n",
            "          [ 4.1607e-02,  1.7612e-02, -1.7529e-02,  ..., -1.6796e-02,\n",
            "           -3.5885e-02, -6.0569e-03],\n",
            "          [-4.0116e-02,  1.5770e-03,  3.8885e-02,  ...,  1.5646e-02,\n",
            "           -2.4358e-02,  2.8997e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5485e-03,  5.5589e-03, -6.1536e-02,  ..., -1.7778e-02,\n",
            "            1.4378e-03, -2.8174e-02],\n",
            "          [-3.1507e-02,  2.6306e-02, -1.8783e-03,  ..., -2.3312e-02,\n",
            "            6.9694e-02, -2.5328e-03],\n",
            "          [-2.0137e-03,  1.1659e-02, -1.8670e-02,  ..., -1.5516e-02,\n",
            "            1.5358e-02, -2.4034e-03],\n",
            "          ...,\n",
            "          [-3.6204e-02, -1.9381e-02,  5.8680e-02,  ..., -1.6756e-02,\n",
            "            3.2390e-02, -7.4925e-03],\n",
            "          [ 2.1148e-02, -1.2134e-02,  2.4225e-03,  ..., -1.4859e-02,\n",
            "           -1.1315e-02,  1.9809e-02],\n",
            "          [-2.1230e-02,  1.5105e-02, -3.3449e-02,  ..., -3.1869e-02,\n",
            "           -4.0556e-02, -1.6133e-02]],\n",
            "\n",
            "         [[ 1.4885e-02, -1.1979e-02, -1.1706e-02,  ...,  2.1262e-02,\n",
            "           -8.6123e-03, -3.8806e-02],\n",
            "          [ 8.1521e-03, -1.6034e-02,  1.0231e-02,  ...,  1.8040e-02,\n",
            "           -1.0461e-02, -9.2206e-03],\n",
            "          [ 4.0941e-03, -6.7987e-03,  2.6071e-02,  ...,  2.5959e-02,\n",
            "            3.8038e-02, -1.4177e-02],\n",
            "          ...,\n",
            "          [ 1.1521e-02,  3.0472e-03, -2.5752e-03,  ..., -5.0077e-02,\n",
            "            1.6407e-03, -1.4398e-03],\n",
            "          [-6.2957e-03, -1.1158e-02,  1.0556e-03,  ...,  1.6989e-02,\n",
            "            1.1272e-02,  2.3614e-02],\n",
            "          [ 6.4377e-03, -1.6931e-03,  1.3246e-02,  ...,  3.8024e-03,\n",
            "            9.4782e-03,  1.8112e-02]],\n",
            "\n",
            "         [[-4.4561e-02, -5.3444e-02,  4.5548e-02,  ..., -5.1311e-02,\n",
            "           -1.2964e-02, -1.4200e-02],\n",
            "          [-3.4756e-02, -2.3098e-02,  1.4184e-02,  ..., -3.0238e-02,\n",
            "            1.6427e-02, -5.2620e-03],\n",
            "          [-5.0827e-02, -9.5189e-03, -3.3295e-03,  ...,  4.2241e-03,\n",
            "            4.8510e-03, -1.6138e-02],\n",
            "          ...,\n",
            "          [-5.9906e-02, -7.7977e-02, -4.9989e-03,  ..., -1.5712e-02,\n",
            "            6.0973e-03, -4.2380e-02],\n",
            "          [ 9.2904e-03, -4.3045e-03,  8.5873e-03,  ..., -4.6940e-02,\n",
            "           -6.1339e-02, -1.1693e-02],\n",
            "          [-1.4498e-02, -4.7086e-02, -3.6473e-02,  ..., -1.8106e-02,\n",
            "           -4.3248e-03,  4.9623e-02]]]])), ('module.encoder_k.bn1.weight', tensor([0.9953, 0.9954, 1.0042, 0.9987, 0.9939, 0.9982, 0.9919, 1.0047, 0.9979,\n",
            "        0.9985, 1.0001, 0.9977, 1.0003, 1.0020, 1.0017, 1.0000, 0.9992, 0.9998,\n",
            "        0.9988, 0.9936, 0.9945, 1.0006, 1.0043, 1.0043, 0.9971, 0.9966, 0.9966,\n",
            "        0.9991, 0.9960, 0.9958, 0.9996, 1.0001, 0.9985, 1.0024, 0.9961, 1.0036,\n",
            "        0.9999, 0.9981, 0.9978, 1.0034, 1.0014, 0.9994, 1.0047, 0.9963, 1.0035,\n",
            "        0.9938, 0.9983, 1.0045, 0.9987, 0.9975, 0.9962, 0.9971, 0.9947, 1.0001,\n",
            "        1.0028, 1.0047, 0.9989, 1.0071, 0.9964, 1.0059, 0.9918, 0.9942, 0.9978,\n",
            "        0.9993])), ('module.encoder_k.bn1.bias', tensor([-0.0022,  0.0066,  0.0043,  0.0020, -0.0042,  0.0009, -0.0066,  0.0076,\n",
            "        -0.0032,  0.0036, -0.0006, -0.0023, -0.0026,  0.0027,  0.0075, -0.0024,\n",
            "        -0.0002,  0.0072, -0.0040, -0.0073, -0.0090,  0.0026, -0.0044,  0.0028,\n",
            "         0.0008,  0.0010,  0.0016,  0.0024,  0.0004,  0.0003, -0.0003, -0.0039,\n",
            "        -0.0029,  0.0021, -0.0027, -0.0002,  0.0004,  0.0008, -0.0022,  0.0008,\n",
            "         0.0014, -0.0050, -0.0041,  0.0032, -0.0043, -0.0013, -0.0008, -0.0013,\n",
            "        -0.0059, -0.0015,  0.0028, -0.0067,  0.0047,  0.0034, -0.0036,  0.0095,\n",
            "         0.0018,  0.0066,  0.0001,  0.0083, -0.0066, -0.0128,  0.0078, -0.0011])), ('module.encoder_k.bn1.running_mean', tensor([ 0.6221,  0.2598,  0.1486, -0.2445, -0.2679, -0.1751, -0.1192, -0.1681,\n",
            "        -0.0184,  0.0270,  0.1441,  0.1599, -0.2263, -0.0817,  0.3135,  0.1270,\n",
            "         0.2417,  0.0951, -0.2987, -0.3263,  0.3025,  0.0361,  0.1141,  0.0351,\n",
            "        -0.2371,  0.2178, -0.1458, -0.1585,  0.1912, -0.2902, -0.2232, -0.0732,\n",
            "        -0.0501,  0.3103,  0.4037, -0.3363, -0.1450, -0.2796, -0.2605, -0.0148,\n",
            "         0.0270,  0.1129,  0.3755, -0.0451, -0.6113,  0.2193,  0.2546,  0.0729,\n",
            "        -0.2506,  0.2978,  0.3284,  0.2240, -0.1809,  0.4019, -0.3240,  0.3885,\n",
            "        -0.0354, -0.1937, -0.1001, -0.2806,  0.2353, -0.0454,  0.0518, -0.2578])), ('module.encoder_k.bn1.running_var', tensor([0.0760, 0.0159, 0.0066, 0.0123, 0.0117, 0.0108, 0.0102, 0.0044, 0.0129,\n",
            "        0.0094, 0.0072, 0.0133, 0.0094, 0.0115, 0.0253, 0.0205, 0.0092, 0.0051,\n",
            "        0.0136, 0.0179, 0.0220, 0.0048, 0.0116, 0.0020, 0.0178, 0.0084, 0.0047,\n",
            "        0.0106, 0.0112, 0.0189, 0.0097, 0.0041, 0.0041, 0.0226, 0.0266, 0.0176,\n",
            "        0.0038, 0.0160, 0.0127, 0.0058, 0.0088, 0.0056, 0.0279, 0.0149, 0.0620,\n",
            "        0.0106, 0.0105, 0.0034, 0.0106, 0.0148, 0.0239, 0.0090, 0.0076, 0.0254,\n",
            "        0.0170, 0.0259, 0.0052, 0.0116, 0.0063, 0.0125, 0.0089, 0.0068, 0.0038,\n",
            "        0.0124])), ('module.encoder_k.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.0.conv1.weight', tensor([[[[-0.0842]],\n",
            "\n",
            "         [[ 0.2026]],\n",
            "\n",
            "         [[ 0.0519]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0655]],\n",
            "\n",
            "         [[ 0.0831]],\n",
            "\n",
            "         [[-0.1159]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0659]],\n",
            "\n",
            "         [[-0.2134]],\n",
            "\n",
            "         [[ 0.1789]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1035]],\n",
            "\n",
            "         [[-0.0996]],\n",
            "\n",
            "         [[-0.1206]]],\n",
            "\n",
            "\n",
            "        [[[-0.0627]],\n",
            "\n",
            "         [[-0.0211]],\n",
            "\n",
            "         [[ 0.0580]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0705]],\n",
            "\n",
            "         [[-0.3218]],\n",
            "\n",
            "         [[-0.0612]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0628]],\n",
            "\n",
            "         [[ 0.0325]],\n",
            "\n",
            "         [[ 0.1774]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3292]],\n",
            "\n",
            "         [[ 0.2110]],\n",
            "\n",
            "         [[-0.1888]]],\n",
            "\n",
            "\n",
            "        [[[-0.0169]],\n",
            "\n",
            "         [[ 0.0223]],\n",
            "\n",
            "         [[ 0.0929]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2426]],\n",
            "\n",
            "         [[ 0.0132]],\n",
            "\n",
            "         [[-0.1215]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0009]],\n",
            "\n",
            "         [[-0.2284]],\n",
            "\n",
            "         [[-0.1288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1301]],\n",
            "\n",
            "         [[ 0.2146]],\n",
            "\n",
            "         [[-0.1631]]]])), ('module.encoder_k.layer1.0.bn1.weight', tensor([0.9994, 1.0004, 0.9987, 0.9983, 0.9988, 1.0002, 0.9960, 0.9976, 0.9988,\n",
            "        0.9963, 1.0012, 1.0003, 0.9956, 1.0014, 0.9999, 0.9971, 1.0021, 1.0005,\n",
            "        1.0014, 0.9997, 1.0012, 0.9998, 1.0019, 1.0027, 0.9992, 1.0002, 0.9989,\n",
            "        0.9986, 0.9982, 0.9976, 0.9988, 0.9970, 0.9975, 0.9997, 1.0013, 0.9994,\n",
            "        0.9977, 0.9987, 0.9992, 0.9986, 0.9990, 0.9981, 0.9957, 0.9978, 0.9985,\n",
            "        0.9975, 0.9988, 0.9977, 0.9961, 0.9979, 0.9972, 0.9988, 0.9992, 1.0014,\n",
            "        1.0012, 1.0035, 1.0000, 0.9982, 1.0009, 0.9970, 1.0026, 0.9927, 1.0053,\n",
            "        0.9966])), ('module.encoder_k.layer1.0.bn1.bias', tensor([ 2.7526e-03,  2.4494e-03, -1.5517e-03, -2.7350e-03, -1.7346e-03,\n",
            "        -2.0078e-04,  5.7965e-04, -5.5984e-03, -3.2099e-03, -3.6724e-05,\n",
            "         5.9045e-03, -1.1819e-03, -7.7804e-03,  1.6647e-03,  1.5500e-03,\n",
            "         1.7221e-03,  3.0672e-03, -1.0002e-03,  1.7182e-03,  1.2521e-03,\n",
            "         2.7255e-03, -2.2217e-03,  2.7272e-03,  2.1564e-03,  2.4195e-03,\n",
            "         1.5841e-03,  3.0161e-03, -1.5560e-03,  1.4805e-03, -1.1270e-03,\n",
            "         2.7744e-04,  1.9232e-03, -1.6739e-03, -7.1026e-04, -6.4355e-04,\n",
            "        -3.2849e-03, -2.2559e-04,  1.9056e-03,  5.1591e-03,  1.2022e-04,\n",
            "        -9.5580e-04, -3.0537e-03, -1.6996e-03,  7.0655e-04,  1.8541e-03,\n",
            "        -1.7921e-04,  1.1195e-03, -4.3565e-04, -2.5272e-03,  6.4490e-04,\n",
            "        -2.0293e-03,  2.5622e-03,  4.3931e-03,  1.8924e-03,  1.9748e-03,\n",
            "         1.3949e-03,  1.0957e-03, -2.9105e-03,  1.2467e-04, -1.2207e-04,\n",
            "         3.5514e-03, -4.2501e-03,  1.8050e-03, -3.0019e-03])), ('module.encoder_k.layer1.0.bn1.running_mean', tensor([-0.2472,  0.2110,  0.7205,  0.1826,  0.2746, -0.5136,  0.1793,  1.3008,\n",
            "        -0.1746, -0.1122,  0.0652, -0.1624, -0.0147,  0.1888,  0.2351,  0.3351,\n",
            "        -0.5563, -0.9386, -0.0050,  0.0705, -0.3651, -0.2236,  0.0443,  1.4778,\n",
            "         0.0878,  0.3840,  0.0848,  0.5588, -1.7650,  0.3957, -0.0292,  0.1046,\n",
            "         0.1153, -0.4809, -0.1333,  0.9012, -0.6037,  0.6552, -0.6713,  0.0332,\n",
            "         0.5246, -0.0738,  0.2769, -0.0755, -0.8939, -1.3870,  0.2435, -0.4223,\n",
            "         0.4162,  0.1876,  0.1550, -1.2873, -0.9330,  0.1045, -0.4020, -0.0507,\n",
            "        -0.2175,  1.1494,  0.2241,  0.6428, -0.2416,  0.2700, -0.7025, -0.0458])), ('module.encoder_k.layer1.0.bn1.running_var', tensor([0.7080, 0.3555, 0.6998, 1.8263, 0.2248, 1.2585, 0.2980, 0.3929, 1.9753,\n",
            "        1.1340, 1.9475, 0.2867, 2.5268, 0.1773, 0.5836, 0.4713, 1.0304, 0.7738,\n",
            "        1.3197, 2.0335, 1.3917, 2.3725, 1.3979, 0.6499, 0.3264, 0.3903, 0.3060,\n",
            "        2.5272, 1.7298, 0.2099, 0.5332, 0.3281, 1.3132, 0.1640, 0.5320, 0.5239,\n",
            "        1.3558, 2.2634, 2.2850, 0.2990, 0.2623, 2.0463, 0.5337, 1.4472, 3.1986,\n",
            "        4.5644, 0.9579, 0.8899, 0.2266, 0.1869, 0.7676, 1.6559, 0.7136, 0.8481,\n",
            "        1.1189, 0.3697, 1.0020, 0.4282, 0.6957, 2.8611, 0.3639, 0.1768, 1.9838,\n",
            "        0.0869])), ('module.encoder_k.layer1.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.0.conv2.weight', tensor([[[[-5.2530e-02, -4.3228e-02, -5.3504e-02],\n",
            "          [ 6.2915e-02,  1.1664e-01,  7.7043e-02],\n",
            "          [-8.3414e-02, -1.9135e-01, -5.3417e-02]],\n",
            "\n",
            "         [[ 8.2273e-03, -3.6577e-02,  8.5302e-02],\n",
            "          [-7.8756e-02, -3.8059e-02,  1.5094e-02],\n",
            "          [-3.7214e-02, -6.1185e-03, -1.6990e-02]],\n",
            "\n",
            "         [[ 1.8216e-02,  1.3074e-02,  8.9895e-02],\n",
            "          [-5.4592e-03,  1.0634e-03,  1.0821e-01],\n",
            "          [-1.8511e-02,  3.1029e-02, -7.2774e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9666e-02,  3.6367e-02,  2.8555e-02],\n",
            "          [-9.9980e-02,  9.5842e-03,  5.0941e-02],\n",
            "          [-8.0638e-02, -1.6128e-02,  5.7026e-02]],\n",
            "\n",
            "         [[ 2.6191e-02, -4.7639e-02, -9.2262e-03],\n",
            "          [-1.0250e-02, -5.0616e-02,  5.1098e-02],\n",
            "          [ 6.0797e-02,  8.8264e-03, -9.3846e-02]],\n",
            "\n",
            "         [[ 1.4010e-01,  8.0471e-02,  8.1850e-02],\n",
            "          [ 7.2511e-02,  1.2952e-03, -5.2625e-02],\n",
            "          [-6.3221e-02,  9.5809e-02,  1.1868e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.4143e-02,  1.5202e-02,  9.6360e-02],\n",
            "          [-3.2843e-03, -6.5498e-02, -6.4518e-02],\n",
            "          [ 5.4339e-02,  5.0956e-02,  2.9372e-03]],\n",
            "\n",
            "         [[-8.4681e-03,  3.6994e-02,  7.8190e-02],\n",
            "          [ 2.3694e-02,  1.3766e-02, -7.5888e-02],\n",
            "          [-8.5870e-02,  2.0954e-02,  8.7308e-02]],\n",
            "\n",
            "         [[ 3.1115e-02, -1.5614e-02,  5.8194e-02],\n",
            "          [ 1.9849e-02, -3.3236e-02,  2.3830e-02],\n",
            "          [ 6.8045e-02, -3.4997e-02, -2.3987e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3874e-03, -6.5520e-02, -4.0776e-02],\n",
            "          [ 4.4124e-02,  2.7402e-02,  4.4196e-02],\n",
            "          [ 8.6942e-03,  6.9031e-02,  1.5109e-02]],\n",
            "\n",
            "         [[ 4.0271e-03, -1.7826e-03,  4.7036e-02],\n",
            "          [-4.2563e-04,  5.2807e-02, -3.2243e-02],\n",
            "          [-7.4176e-02, -1.8817e-02,  5.6255e-02]],\n",
            "\n",
            "         [[-5.1555e-03,  8.6382e-03, -2.2153e-03],\n",
            "          [ 7.0335e-02, -4.0034e-02, -1.9548e-03],\n",
            "          [ 1.1186e-01,  6.0220e-02, -3.8697e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6910e-02, -1.5255e-01,  3.6632e-02],\n",
            "          [-5.7220e-02, -1.7174e-01, -6.2505e-02],\n",
            "          [ 9.0737e-02, -3.8542e-02,  1.0751e-02]],\n",
            "\n",
            "         [[-4.7822e-02, -1.8287e-02, -1.8079e-02],\n",
            "          [ 7.3694e-02, -7.4320e-03,  7.9090e-02],\n",
            "          [ 3.1018e-02,  1.2587e-01,  9.5674e-02]],\n",
            "\n",
            "         [[-3.1694e-02, -5.0067e-02, -3.6065e-02],\n",
            "          [ 2.1289e-02,  2.5528e-03,  7.4992e-03],\n",
            "          [-8.6504e-02, -1.0768e-01,  4.5201e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5367e-02,  1.3333e-01,  2.2351e-02],\n",
            "          [ 7.6285e-02,  2.0689e-02,  6.7918e-02],\n",
            "          [-7.1290e-02,  4.4680e-02,  1.6033e-02]],\n",
            "\n",
            "         [[ 5.4016e-02, -1.1661e-03, -6.8364e-03],\n",
            "          [-8.9480e-02, -6.6556e-02,  7.2358e-03],\n",
            "          [ 5.1168e-02, -2.2362e-02, -1.5711e-04]],\n",
            "\n",
            "         [[ 6.6953e-02, -8.7338e-02,  7.0312e-02],\n",
            "          [ 8.0502e-02, -4.9904e-02, -1.6512e-02],\n",
            "          [-6.3493e-02, -5.0194e-02,  1.5747e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9071e-02,  9.6944e-03, -9.1647e-02],\n",
            "          [-2.3951e-02, -2.0357e-02,  1.8921e-02],\n",
            "          [ 2.1873e-02,  4.3538e-02,  5.8034e-02]],\n",
            "\n",
            "         [[ 5.3750e-02, -9.4183e-02,  2.3331e-02],\n",
            "          [-1.2446e-02, -1.0848e-02,  7.2224e-02],\n",
            "          [-5.7711e-03,  9.5715e-02, -5.4641e-02]],\n",
            "\n",
            "         [[-1.7873e-02,  3.8189e-02,  7.1227e-02],\n",
            "          [-2.6093e-02, -5.4173e-02, -8.4613e-03],\n",
            "          [-8.2621e-02,  8.7298e-03,  3.9516e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2362e-02,  6.5070e-02,  5.7728e-02],\n",
            "          [-1.0628e-01,  7.9430e-02, -6.9892e-03],\n",
            "          [ 1.5503e-01, -5.6406e-02, -4.2455e-02]],\n",
            "\n",
            "         [[ 2.8023e-02, -5.6480e-03,  1.6135e-01],\n",
            "          [-7.3176e-03, -2.5691e-02, -1.0249e-01],\n",
            "          [ 7.9448e-02,  3.6055e-02,  2.9810e-02]],\n",
            "\n",
            "         [[-4.1706e-02,  1.8089e-05, -3.8592e-02],\n",
            "          [ 9.2458e-02, -2.5987e-03, -5.3318e-02],\n",
            "          [ 5.0870e-02, -6.5804e-02,  2.9420e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5202e-02,  1.0027e-02, -3.0449e-02],\n",
            "          [-2.4793e-02, -4.6257e-02, -2.5393e-02],\n",
            "          [ 3.0205e-02, -5.9910e-02, -6.5456e-02]],\n",
            "\n",
            "         [[-1.0000e-01, -1.4720e-02, -4.6246e-02],\n",
            "          [ 4.1180e-03, -2.5999e-02, -8.8310e-03],\n",
            "          [ 7.2055e-02, -3.8726e-02, -1.6366e-02]],\n",
            "\n",
            "         [[-4.8354e-04, -4.1695e-02, -1.2855e-02],\n",
            "          [ 6.5245e-03, -1.1347e-01, -2.3720e-02],\n",
            "          [ 9.8822e-02, -8.1102e-02, -4.0788e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4482e-02, -3.0811e-02,  4.3774e-02],\n",
            "          [-3.3788e-02, -2.2310e-02,  2.0912e-03],\n",
            "          [ 1.1300e-01,  4.3707e-02,  3.6496e-02]],\n",
            "\n",
            "         [[ 1.6328e-01,  5.8961e-02,  2.6978e-02],\n",
            "          [-7.9921e-02, -2.6591e-02, -2.3026e-02],\n",
            "          [-3.7970e-02,  1.5315e-01,  3.7077e-02]],\n",
            "\n",
            "         [[ 2.3358e-02,  4.9069e-02, -5.8522e-02],\n",
            "          [-3.2534e-02,  5.7444e-02,  1.4049e-01],\n",
            "          [ 3.0562e-02, -4.8852e-02,  4.8902e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2318e-02, -7.4505e-02, -2.5152e-02],\n",
            "          [-1.1044e-01,  6.0966e-02,  9.5788e-02],\n",
            "          [-1.0848e-02,  6.3111e-02,  5.6150e-02]],\n",
            "\n",
            "         [[ 1.1226e-02,  7.2991e-02, -8.8752e-02],\n",
            "          [ 2.0405e-02,  1.0732e-01, -4.0205e-02],\n",
            "          [-4.4105e-02,  3.6063e-02,  2.0666e-02]],\n",
            "\n",
            "         [[ 5.0632e-02,  1.1479e-01, -1.1754e-01],\n",
            "          [ 1.2010e-02, -1.3038e-02,  6.6835e-02],\n",
            "          [ 2.6292e-02,  2.4990e-02,  6.1513e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2373e-02, -2.2979e-02,  5.5795e-02],\n",
            "          [ 1.0250e-01,  2.6258e-03, -2.1823e-02],\n",
            "          [-9.5226e-04,  3.8974e-02, -1.5823e-02]],\n",
            "\n",
            "         [[-3.9123e-02, -3.9645e-02,  1.4191e-02],\n",
            "          [ 3.1903e-02, -8.7444e-02, -5.6403e-03],\n",
            "          [ 9.7741e-02,  3.1797e-03, -4.1147e-03]],\n",
            "\n",
            "         [[-6.3214e-02,  4.8448e-02,  2.6035e-02],\n",
            "          [ 7.7557e-02,  5.7521e-02, -5.0642e-02],\n",
            "          [-7.1796e-02,  2.6729e-03, -9.5166e-02]]]])), ('module.encoder_k.layer1.0.bn2.weight', tensor([1.0006, 0.9926, 1.0002, 0.9966, 0.9970, 0.9970, 0.9980, 1.0016, 0.9983,\n",
            "        1.0006, 0.9990, 1.0024, 1.0020, 0.9998, 0.9989, 0.9985, 1.0026, 0.9963,\n",
            "        1.0045, 0.9940, 0.9994, 0.9989, 0.9991, 1.0010, 1.0000, 0.9992, 1.0022,\n",
            "        1.0014, 0.9947, 1.0004, 0.9994, 0.9985, 1.0029, 1.0025, 0.9923, 0.9975,\n",
            "        0.9973, 0.9983, 0.9990, 0.9990, 0.9985, 0.9965, 0.9989, 1.0002, 0.9976,\n",
            "        1.0037, 0.9939, 0.9987, 1.0005, 0.9987, 1.0026, 1.0016, 0.9996, 0.9985,\n",
            "        0.9981, 0.9980, 0.9985, 0.9966, 0.9989, 0.9995, 1.0044, 0.9944, 1.0013,\n",
            "        0.9982])), ('module.encoder_k.layer1.0.bn2.bias', tensor([ 2.0249e-03, -5.5635e-03, -8.1871e-04, -7.3707e-04, -1.4310e-03,\n",
            "         6.0007e-04, -8.6659e-04,  1.4434e-03, -1.8691e-03, -1.8302e-03,\n",
            "        -2.5052e-03,  1.6054e-03,  8.3513e-04,  8.1200e-04, -2.7706e-04,\n",
            "        -2.6372e-03,  4.6234e-03, -1.8694e-03,  2.4689e-03, -2.9904e-03,\n",
            "         1.1041e-03,  7.6034e-04,  1.4785e-03,  1.9198e-03,  2.4025e-04,\n",
            "         1.7076e-03,  5.2461e-03,  4.1879e-03, -3.6388e-03,  1.6963e-03,\n",
            "        -2.3098e-03, -9.6550e-04,  1.1984e-03,  7.1816e-04, -6.7194e-04,\n",
            "        -7.3010e-04,  2.0056e-03,  2.3305e-03,  3.7930e-04, -1.3131e-03,\n",
            "        -2.5218e-03, -1.9928e-04,  1.1720e-03, -2.6603e-03, -4.9129e-04,\n",
            "         1.6328e-03, -2.5049e-03,  1.4803e-03, -1.1886e-03, -3.0973e-04,\n",
            "         1.2408e-03, -7.1280e-05,  3.1964e-03,  5.4807e-04, -1.9545e-03,\n",
            "        -3.1174e-03,  7.9921e-04, -1.3074e-03,  7.4284e-04,  2.0029e-03,\n",
            "         2.9588e-03, -4.1542e-03,  8.0405e-04, -1.5064e-03])), ('module.encoder_k.layer1.0.bn2.running_mean', tensor([-0.7982,  0.3127,  0.0917,  0.2256,  0.3509, -0.2427,  0.3396, -0.1862,\n",
            "         0.1799, -0.7100, -0.4761, -0.7319, -0.3487,  1.0561,  0.7370,  0.4347,\n",
            "        -0.0499,  0.2836,  0.1858,  0.2962, -0.3762, -0.1532, -0.0842, -0.6112,\n",
            "        -0.6152,  0.7281, -0.6384, -0.5299, -0.8768, -0.0461, -0.7126,  0.1589,\n",
            "         0.6045,  0.5493, -0.2280,  0.9068,  0.4360, -0.5619, -0.1028, -0.0262,\n",
            "         0.2353,  0.2417, -0.3053,  0.1363, -0.8343, -0.1379, -0.6056, -0.2748,\n",
            "         0.2777, -0.6195,  0.3745,  0.0032, -0.1957,  0.6654, -0.0427, -0.3638,\n",
            "         0.1499, -0.8386, -0.3533, -0.1681,  0.6740, -0.3139,  0.7644,  0.2709])), ('module.encoder_k.layer1.0.bn2.running_var', tensor([0.3865, 0.9309, 0.9488, 1.4206, 0.4914, 0.8558, 1.8917, 0.4594, 0.9985,\n",
            "        2.3551, 0.3757, 0.5911, 0.8895, 1.4047, 0.7182, 0.3933, 0.6405, 0.8761,\n",
            "        1.1266, 0.5085, 0.4354, 0.3386, 0.7697, 0.7578, 0.4465, 0.5538, 0.4291,\n",
            "        0.6564, 0.6482, 0.7627, 0.4773, 0.6272, 0.5835, 0.7447, 1.2158, 1.0324,\n",
            "        0.2897, 0.4246, 0.9424, 0.6207, 0.5932, 0.5138, 0.4292, 1.8597, 3.7274,\n",
            "        0.8021, 1.2709, 1.2332, 0.7109, 0.2708, 0.9036, 0.7615, 0.6391, 0.9444,\n",
            "        0.4056, 0.4212, 0.9622, 0.8682, 0.3512, 0.8577, 1.3565, 0.7442, 0.6749,\n",
            "        0.3718])), ('module.encoder_k.layer1.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.0.conv3.weight', tensor([[[[-0.0493]],\n",
            "\n",
            "         [[-0.1103]],\n",
            "\n",
            "         [[ 0.0371]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0158]],\n",
            "\n",
            "         [[-0.0313]],\n",
            "\n",
            "         [[ 0.1325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0064]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[ 0.0541]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0561]],\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[ 0.1714]]],\n",
            "\n",
            "\n",
            "        [[[-0.1057]],\n",
            "\n",
            "         [[ 0.0780]],\n",
            "\n",
            "         [[-0.0724]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1983]],\n",
            "\n",
            "         [[ 0.0362]],\n",
            "\n",
            "         [[-0.1606]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1398]],\n",
            "\n",
            "         [[-0.0277]],\n",
            "\n",
            "         [[ 0.2261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0483]],\n",
            "\n",
            "         [[ 0.0733]],\n",
            "\n",
            "         [[-0.0579]]],\n",
            "\n",
            "\n",
            "        [[[-0.0383]],\n",
            "\n",
            "         [[ 0.0319]],\n",
            "\n",
            "         [[-0.0211]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0349]],\n",
            "\n",
            "         [[ 0.0761]],\n",
            "\n",
            "         [[-0.0173]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0332]],\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         [[ 0.0770]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.1226]],\n",
            "\n",
            "         [[-0.0015]]]])), ('module.encoder_k.layer1.0.bn3.weight', tensor([1.0008, 0.9989, 0.9980, 0.9998, 0.9994, 0.9997, 0.9979, 0.9979, 0.9989,\n",
            "        0.9967, 0.9989, 1.0003, 0.9985, 0.9992, 0.9991, 0.9976, 0.9995, 0.9984,\n",
            "        0.9996, 0.9974, 0.9995, 0.9986, 0.9979, 0.9972, 0.9988, 0.9992, 0.9970,\n",
            "        0.9994, 0.9994, 0.9989, 0.9976, 0.9994, 0.9990, 1.0000, 0.9978, 0.9980,\n",
            "        0.9976, 0.9981, 0.9993, 1.0025, 1.0001, 0.9976, 1.0004, 0.9991, 0.9975,\n",
            "        0.9991, 0.9987, 1.0014, 0.9978, 0.9978, 0.9981, 0.9992, 0.9987, 1.0003,\n",
            "        0.9990, 0.9998, 0.9997, 1.0006, 0.9995, 0.9986, 1.0004, 0.9983, 0.9983,\n",
            "        0.9992, 0.9971, 0.9998, 0.9996, 0.9996, 1.0001, 1.0003, 0.9974, 0.9994,\n",
            "        1.0009, 0.9983, 0.9997, 0.9992, 0.9963, 0.9993, 1.0004, 0.9995, 0.9992,\n",
            "        0.9970, 0.9994, 0.9959, 0.9972, 0.9991, 0.9985, 1.0006, 1.0001, 1.0015,\n",
            "        0.9983, 1.0002, 1.0006, 0.9999, 0.9998, 0.9995, 1.0011, 0.9997, 0.9989,\n",
            "        0.9984, 0.9979, 0.9983, 1.0008, 0.9994, 0.9997, 0.9991, 1.0005, 0.9989,\n",
            "        0.9994, 0.9990, 0.9979, 0.9979, 0.9969, 0.9985, 0.9985, 0.9988, 0.9992,\n",
            "        0.9989, 0.9995, 0.9988, 0.9992, 0.9980, 0.9975, 0.9984, 1.0009, 0.9980,\n",
            "        0.9995, 0.9995, 1.0016, 0.9991, 0.9989, 1.0006, 0.9980, 0.9998, 0.9983,\n",
            "        0.9996, 0.9966, 0.9974, 0.9986, 1.0017, 1.0004, 0.9995, 0.9999, 1.0008,\n",
            "        0.9999, 0.9991, 0.9988, 0.9984, 0.9981, 0.9991, 0.9988, 1.0006, 0.9998,\n",
            "        0.9986, 1.0010, 1.0000, 0.9975, 0.9995, 1.0003, 0.9980, 0.9996, 0.9978,\n",
            "        0.9987, 0.9977, 0.9983, 0.9981, 1.0001, 0.9977, 0.9979, 0.9990, 0.9998,\n",
            "        0.9982, 1.0012, 0.9995, 0.9978, 0.9986, 0.9993, 0.9978, 0.9987, 0.9996,\n",
            "        0.9984, 0.9990, 0.9999, 0.9991, 0.9978, 0.9981, 0.9992, 0.9988, 1.0007,\n",
            "        0.9985, 0.9984, 0.9992, 0.9981, 0.9995, 0.9973, 1.0003, 0.9991, 0.9983,\n",
            "        0.9990, 0.9993, 0.9984, 1.0000, 1.0009, 0.9982, 0.9983, 0.9969, 0.9995,\n",
            "        1.0000, 0.9988, 0.9991, 0.9985, 0.9996, 0.9979, 0.9990, 1.0007, 0.9983,\n",
            "        0.9992, 0.9995, 0.9989, 0.9978, 0.9962, 0.9984, 0.9973, 1.0007, 0.9987,\n",
            "        0.9987, 0.9996, 0.9999, 0.9993, 1.0010, 1.0011, 0.9987, 0.9981, 0.9993,\n",
            "        1.0008, 1.0003, 1.0000, 0.9983, 0.9984, 0.9969, 0.9982, 0.9971, 0.9984,\n",
            "        1.0006, 0.9997, 0.9982, 0.9982, 1.0007, 0.9998, 1.0016, 0.9977, 1.0011,\n",
            "        0.9984, 0.9988, 0.9982, 0.9995])), ('module.encoder_k.layer1.0.bn3.bias', tensor([ 1.8825e-03, -2.5636e-04,  2.3058e-04,  6.1536e-04, -2.4665e-04,\n",
            "         1.8648e-03, -6.5061e-04, -1.0284e-03, -1.7575e-04, -2.7672e-04,\n",
            "         1.4647e-03,  4.2379e-04,  2.2541e-04, -2.3544e-04, -1.0728e-03,\n",
            "        -1.4628e-04, -1.5347e-03, -2.3080e-03, -3.1559e-04, -1.2106e-04,\n",
            "        -7.4980e-04, -4.2625e-04, -6.0088e-04, -9.2326e-04, -4.5714e-04,\n",
            "        -1.6825e-04, -1.8367e-03,  2.1035e-04, -2.8318e-04, -4.6462e-04,\n",
            "        -1.8060e-04,  1.9015e-04, -1.6283e-04,  1.1824e-03, -1.2544e-03,\n",
            "        -1.0473e-03, -1.0465e-03,  5.4165e-04, -1.1569e-03,  1.7947e-03,\n",
            "        -9.3323e-04, -1.8648e-04,  7.7268e-05,  1.5070e-03,  6.7744e-04,\n",
            "        -1.1682e-03, -9.4614e-04,  9.6019e-04, -8.4583e-04, -1.6092e-03,\n",
            "        -1.3081e-03,  1.0232e-05,  6.2345e-04,  7.0282e-04,  1.3333e-03,\n",
            "         2.1466e-03,  6.1835e-04,  1.4490e-03,  2.4542e-04,  4.0598e-04,\n",
            "         9.2572e-05, -1.1318e-03, -4.1128e-05,  1.7084e-03, -4.3629e-04,\n",
            "         9.8186e-05, -1.4773e-03,  1.9950e-03,  4.4904e-04,  7.2284e-04,\n",
            "         4.2732e-04,  2.6971e-05, -3.5142e-04,  9.2027e-05,  1.8452e-03,\n",
            "         6.2995e-04, -1.8119e-03,  1.8685e-04,  1.4977e-03,  7.0531e-05,\n",
            "        -1.2803e-04, -8.2005e-04, -3.8147e-04, -8.6663e-04,  8.6261e-04,\n",
            "        -2.8469e-04, -1.8267e-04,  1.6596e-03, -9.6989e-04,  3.6550e-04,\n",
            "         7.4902e-04, -5.7288e-04, -1.0843e-03,  1.1276e-04, -3.1031e-04,\n",
            "         7.2098e-04,  8.4306e-05,  1.1448e-03, -5.8829e-04, -9.1522e-04,\n",
            "        -1.1554e-03,  7.5968e-04,  1.1376e-04,  2.7231e-04, -7.9273e-05,\n",
            "        -4.6458e-05,  2.6652e-04,  9.3896e-04,  7.6470e-04,  1.5134e-03,\n",
            "        -2.9041e-04, -7.1079e-04, -1.6824e-03, -4.7534e-04,  2.3715e-03,\n",
            "        -3.0041e-04, -4.5458e-04,  3.5071e-04,  7.8482e-04, -9.6851e-04,\n",
            "         4.6035e-04,  8.1430e-04, -1.0291e-03, -1.6785e-03, -2.0492e-04,\n",
            "        -4.3140e-04,  1.6443e-04,  2.2139e-03,  1.7763e-03, -1.0328e-03,\n",
            "        -1.6548e-03, -2.9355e-04, -9.2706e-04, -5.5210e-04, -5.1561e-04,\n",
            "         1.2793e-03, -2.3957e-03, -2.0060e-03,  2.3705e-04, -5.9726e-04,\n",
            "         6.3170e-04,  5.3059e-05, -5.0381e-04,  9.8448e-05,  1.5135e-03,\n",
            "         4.7572e-04, -1.8789e-04, -2.0959e-04, -1.0308e-03,  1.1859e-03,\n",
            "         1.0147e-03, -9.0360e-05, -3.3232e-04,  7.1845e-04,  6.4087e-04,\n",
            "        -2.3217e-04,  1.1755e-04,  2.0632e-04,  9.6386e-06, -7.1340e-04,\n",
            "        -1.3607e-04, -1.3336e-03, -1.2542e-03, -8.0969e-05,  6.8155e-04,\n",
            "         3.0448e-05,  2.3170e-04, -3.8720e-04,  3.9080e-04, -1.5905e-03,\n",
            "        -4.0721e-04,  2.5530e-04,  3.1012e-04, -8.2038e-04,  9.0187e-04,\n",
            "        -3.9302e-04,  7.9873e-04, -1.1068e-03,  1.2232e-03,  1.3316e-03,\n",
            "         3.5157e-04, -6.9229e-04,  1.8442e-03,  6.6319e-05,  2.1493e-04,\n",
            "         1.6064e-04,  2.7481e-04,  1.5498e-04,  8.3012e-04, -7.1942e-04,\n",
            "        -2.8059e-04,  5.0541e-04, -2.2602e-04, -2.7439e-04,  8.1758e-04,\n",
            "         7.4742e-04, -9.2281e-04, -1.5191e-03,  1.8471e-04, -4.6586e-04,\n",
            "         8.7690e-04,  1.7381e-04,  7.8544e-04,  4.8118e-05,  3.3746e-04,\n",
            "         6.2125e-04, -4.6575e-04,  1.6160e-03,  1.9133e-03, -3.1273e-04,\n",
            "        -1.8867e-04,  1.2637e-03,  2.7094e-04, -3.1524e-04,  2.3888e-03,\n",
            "        -5.9999e-04, -1.3370e-03,  2.3087e-04,  3.0793e-04, -2.7065e-04,\n",
            "        -9.2102e-04, -5.3149e-04, -1.2391e-03,  7.9034e-04, -7.3097e-05,\n",
            "        -5.2154e-04,  1.8873e-03,  6.1886e-04, -4.0362e-04,  5.5627e-04,\n",
            "         5.7626e-05,  1.1334e-03,  5.3259e-04,  5.3988e-04, -3.5718e-05,\n",
            "        -1.4658e-04,  7.1034e-04, -1.9175e-03,  7.7053e-04, -2.9156e-03,\n",
            "         6.0585e-04, -8.0003e-04, -1.6079e-03,  7.4531e-04, -1.6352e-03,\n",
            "        -1.2819e-03, -2.6544e-03,  7.9967e-04,  7.9872e-04,  2.9313e-03,\n",
            "        -2.0231e-03,  1.0843e-03,  3.8685e-04,  1.0173e-03,  7.1978e-04,\n",
            "        -9.1372e-04])), ('module.encoder_k.layer1.0.bn3.running_mean', tensor([-4.5001e-01,  7.7416e-01, -2.8137e-01, -6.3061e-01,  9.9890e-02,\n",
            "         5.9144e-02,  2.8355e-01,  5.8658e-01,  3.2618e-01, -1.0344e-01,\n",
            "        -8.7430e-02, -7.6189e-01,  3.7216e-01, -2.5273e-01,  3.6370e-01,\n",
            "        -2.6175e-01, -9.3327e-02, -4.1852e-02,  4.8368e-02,  3.4583e-01,\n",
            "        -4.2593e-01, -1.5416e-02,  3.1035e-01,  4.9076e-01,  6.6658e-02,\n",
            "         2.2933e-01, -1.3587e-01, -1.3364e-02,  1.0379e-01, -8.1448e-02,\n",
            "        -6.6578e-02, -4.7714e-02,  9.7672e-02, -4.7118e-01, -4.0398e-01,\n",
            "         2.4441e-01,  2.2301e-02,  2.9008e-01,  1.2064e-02, -2.0466e-01,\n",
            "        -8.0379e-02,  2.1947e-01, -1.9270e-01,  3.2486e-01,  2.1974e-02,\n",
            "        -2.6721e-01,  2.1967e-01, -1.4313e-01,  3.5973e-01,  3.5741e-02,\n",
            "         3.2613e-01,  6.1152e-02, -4.3642e-01, -6.8976e-01, -3.2555e-01,\n",
            "         2.9117e-01,  2.7838e-01,  2.1135e-01, -1.1247e-01,  3.8664e-01,\n",
            "         2.4914e-01,  6.7512e-01, -1.8879e-01, -3.1905e-01,  1.6832e-01,\n",
            "        -7.1536e-02, -5.6681e-02,  1.7038e-01,  2.7690e-02,  1.0429e-01,\n",
            "        -1.1364e-01,  1.5694e-01, -3.1199e-01,  4.8801e-02,  1.3538e-01,\n",
            "        -4.7786e-01,  4.6121e-02, -2.2332e-01,  2.8383e-01, -3.2844e-01,\n",
            "        -3.0606e-01,  1.1224e-01,  6.1759e-01,  9.7590e-02,  1.7144e-01,\n",
            "         2.4939e-02,  6.2432e-02,  3.4501e-01,  6.6824e-02, -3.3127e-01,\n",
            "         2.4616e-01,  1.8755e-02,  5.3946e-01, -5.9942e-01,  1.3491e-01,\n",
            "        -4.4521e-01, -4.7351e-01,  8.3000e-02, -2.9569e-01, -3.0195e-02,\n",
            "         4.9706e-02,  4.3789e-01,  2.6559e-01, -1.3740e-01,  1.3090e-01,\n",
            "         3.2576e-01, -7.2791e-02,  1.5811e-01, -2.5085e-01,  3.0494e-01,\n",
            "         1.1593e-01,  9.8684e-03, -3.7169e-01,  1.0175e-01, -4.8704e-01,\n",
            "         3.4451e-01, -3.8953e-01,  1.3159e-01,  2.0320e-01,  5.0666e-01,\n",
            "        -2.2808e-01,  2.7811e-01,  1.2615e-01,  4.4247e-01,  3.8774e-02,\n",
            "        -1.4620e-01,  4.2169e-01,  1.4916e-02, -1.7942e-01,  1.1266e-01,\n",
            "         3.3732e-01, -9.3025e-02,  1.2068e-01, -4.5051e-02,  2.2795e-01,\n",
            "        -3.3517e-02,  2.7957e-01, -8.6506e-03,  4.9046e-02,  1.5814e-01,\n",
            "        -3.0854e-02, -4.1413e-01, -9.9595e-02,  1.5224e-01, -2.7133e-01,\n",
            "         1.1060e-01,  1.5830e-01, -2.9073e-01, -1.2724e-01,  3.9996e-02,\n",
            "         2.9362e-01, -5.6541e-01,  2.4157e-01, -1.2777e-01,  1.4854e-02,\n",
            "         5.9056e-01,  9.8894e-03,  4.1545e-01, -2.7213e-01, -1.4979e-01,\n",
            "        -3.7024e-01,  7.7750e-02,  4.3389e-01,  1.2650e-01,  5.1092e-01,\n",
            "        -4.6295e-02,  4.6008e-01, -1.2968e-01,  3.8050e-01,  1.0964e-01,\n",
            "        -2.0221e-04,  2.5687e-01, -3.6597e-01, -8.1191e-02, -5.0832e-01,\n",
            "        -2.1249e-01, -4.5620e-01, -1.7500e-01,  4.9613e-01, -1.1388e-01,\n",
            "        -3.4175e-01,  2.5810e-01, -5.0300e-02, -9.8455e-02, -2.3457e-01,\n",
            "         6.3654e-02,  3.6799e-01,  5.7244e-02, -5.5912e-02,  1.8114e-01,\n",
            "         2.4794e-01,  3.0584e-01,  2.4514e-02, -3.2803e-01,  5.2735e-02,\n",
            "        -2.4590e-01, -7.0854e-02,  9.6081e-02,  2.1101e-01,  9.5333e-02,\n",
            "         3.4232e-01, -2.2343e-01,  8.4648e-02, -4.3241e-01, -4.5140e-02,\n",
            "         5.0221e-01,  1.0951e-01,  3.4456e-01, -5.0705e-02, -1.6851e-01,\n",
            "         1.3663e-02,  2.8326e-01,  1.0932e-01, -1.7256e-01, -2.9200e-01,\n",
            "        -1.8895e-01, -1.1594e-01,  3.6272e-02,  1.6284e-01, -2.3010e-01,\n",
            "         8.7161e-02, -1.1174e-01, -4.9158e-01,  1.8387e-01, -6.1698e-02,\n",
            "         6.4035e-02, -2.7958e-01, -8.4218e-02,  1.8540e-01,  3.8382e-01,\n",
            "         1.0459e-01,  6.1188e-02,  2.9060e-01, -7.4883e-02, -5.0197e-01,\n",
            "        -1.8280e-01, -4.3703e-01, -1.0010e-02, -9.8621e-02,  3.6970e-01,\n",
            "         2.4855e-01,  1.9356e-01, -2.8879e-01, -2.6004e-01,  1.4192e-02,\n",
            "        -2.0272e-01,  4.2212e-02,  9.8946e-02,  2.7761e-02, -1.9041e-01,\n",
            "         3.8264e-01, -3.3828e-01, -4.2355e-01,  6.3203e-01, -2.1562e-01,\n",
            "        -2.4430e-02])), ('module.encoder_k.layer1.0.bn3.running_var', tensor([0.1644, 0.2668, 0.1402, 0.1531, 0.2734, 0.0843, 0.2685, 0.2299, 0.1734,\n",
            "        0.1685, 0.1576, 0.1890, 0.1247, 0.1117, 0.2231, 0.1057, 0.2283, 0.1208,\n",
            "        0.2769, 0.2567, 0.1815, 0.3386, 0.2450, 0.0989, 0.1516, 0.1896, 0.2490,\n",
            "        0.1374, 0.3103, 0.1483, 0.2855, 0.0921, 0.0983, 0.3330, 0.5432, 0.1209,\n",
            "        0.2139, 0.1007, 0.1524, 0.1476, 0.1119, 0.0962, 0.1132, 0.1484, 0.5222,\n",
            "        0.1133, 0.2501, 0.1178, 0.1061, 0.1356, 0.1498, 0.0789, 0.2039, 0.1699,\n",
            "        0.1330, 0.1761, 0.1330, 0.1967, 0.1369, 0.1863, 0.1885, 0.0903, 0.5402,\n",
            "        0.1230, 0.1435, 0.0692, 0.3122, 0.1017, 0.2698, 0.4360, 0.1002, 0.2348,\n",
            "        0.1957, 0.1462, 0.1456, 0.2275, 0.1233, 0.1011, 0.1679, 0.2339, 0.1584,\n",
            "        0.1068, 0.2494, 0.1196, 0.2571, 0.0903, 0.1264, 0.2137, 0.2886, 0.2208,\n",
            "        0.1976, 0.1116, 0.1162, 0.2552, 0.0603, 0.3437, 0.1010, 0.1841, 0.1254,\n",
            "        0.1757, 0.2896, 0.1202, 0.1040, 0.1071, 0.1796, 0.2300, 0.0952, 0.3728,\n",
            "        0.3947, 0.1396, 0.0895, 0.2690, 0.1601, 0.1106, 0.3948, 0.2136, 0.1652,\n",
            "        0.3975, 0.1795, 0.1647, 0.1466, 0.2206, 0.1220, 0.1334, 0.1972, 0.1910,\n",
            "        0.2104, 0.0690, 0.1284, 0.2152, 0.1824, 0.1098, 0.0865, 0.1206, 0.2020,\n",
            "        0.2695, 0.3113, 0.1540, 0.2055, 0.1720, 0.2038, 0.1893, 0.1428, 0.1470,\n",
            "        0.1043, 0.0880, 0.2025, 0.0726, 0.1364, 0.1278, 0.1366, 0.1473, 0.2532,\n",
            "        0.1401, 0.1029, 0.2545, 0.0900, 0.1444, 0.3900, 0.1344, 0.1316, 0.2230,\n",
            "        0.3249, 0.0784, 0.1997, 0.1604, 0.2172, 0.0799, 0.1309, 0.0792, 0.0818,\n",
            "        0.1811, 0.2927, 0.2512, 0.3711, 0.1949, 0.1700, 0.1875, 0.3032, 0.3434,\n",
            "        0.1448, 0.4281, 0.3502, 0.1241, 0.1382, 0.3162, 0.3237, 0.1431, 0.3314,\n",
            "        0.1385, 0.2055, 0.1257, 0.1307, 0.2539, 0.1006, 0.1956, 0.1011, 0.1659,\n",
            "        0.2044, 0.3751, 0.2039, 0.0923, 0.1176, 0.2704, 0.1152, 0.1442, 0.4520,\n",
            "        0.1439, 0.2434, 0.1441, 0.0604, 0.2149, 0.1021, 0.0955, 0.1559, 0.2531,\n",
            "        0.2013, 0.0968, 0.2342, 0.3607, 0.2835, 0.0926, 0.0928, 0.0744, 0.0783,\n",
            "        0.3024, 0.1235, 0.1103, 0.1252, 0.1726, 0.1854, 0.4374, 0.1242, 0.1688,\n",
            "        0.1789, 0.1094, 0.2385, 0.2439, 0.1856, 0.2119, 0.0881, 0.1492, 0.1904,\n",
            "        0.1644, 0.1002, 0.1301, 0.1184, 0.4489, 0.1007, 0.2180, 0.2872, 0.1513,\n",
            "        0.2497, 0.5087, 0.1820, 0.1494])), ('module.encoder_k.layer1.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.0.downsample.0.weight', tensor([[[[-0.0031]],\n",
            "\n",
            "         [[-0.0386]],\n",
            "\n",
            "         [[ 0.0758]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1419]],\n",
            "\n",
            "         [[ 0.0144]],\n",
            "\n",
            "         [[-0.0481]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0562]],\n",
            "\n",
            "         [[-0.1577]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0892]],\n",
            "\n",
            "         [[-0.0406]],\n",
            "\n",
            "         [[ 0.0100]]],\n",
            "\n",
            "\n",
            "        [[[-0.0731]],\n",
            "\n",
            "         [[ 0.0813]],\n",
            "\n",
            "         [[-0.0287]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0393]],\n",
            "\n",
            "         [[ 0.1573]],\n",
            "\n",
            "         [[ 0.0759]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0211]],\n",
            "\n",
            "         [[ 0.1063]],\n",
            "\n",
            "         [[ 0.0479]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0869]],\n",
            "\n",
            "         [[ 0.0154]],\n",
            "\n",
            "         [[-0.0743]]],\n",
            "\n",
            "\n",
            "        [[[-0.0136]],\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         [[-0.0969]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0262]],\n",
            "\n",
            "         [[-0.0756]],\n",
            "\n",
            "         [[-0.0256]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0598]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         [[-0.1288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0877]],\n",
            "\n",
            "         [[ 0.0713]],\n",
            "\n",
            "         [[ 0.2315]]]])), ('module.encoder_k.layer1.0.downsample.1.weight', tensor([0.9979, 1.0003, 1.0001, 0.9997, 0.9985, 1.0019, 0.9993, 0.9988, 0.9984,\n",
            "        0.9986, 0.9991, 1.0005, 1.0008, 0.9993, 0.9989, 0.9994, 0.9984, 0.9985,\n",
            "        0.9997, 1.0007, 0.9986, 0.9984, 0.9996, 0.9981, 1.0001, 0.9982, 0.9972,\n",
            "        0.9993, 0.9989, 0.9982, 0.9981, 0.9972, 0.9985, 0.9987, 0.9990, 0.9992,\n",
            "        0.9982, 0.9989, 0.9980, 0.9996, 0.9990, 1.0019, 0.9991, 0.9993, 0.9997,\n",
            "        0.9977, 0.9974, 1.0007, 0.9996, 0.9971, 0.9984, 0.9986, 1.0009, 0.9998,\n",
            "        0.9991, 0.9998, 0.9990, 0.9992, 1.0000, 1.0009, 0.9967, 0.9992, 0.9992,\n",
            "        0.9992, 0.9996, 0.9972, 0.9988, 1.0007, 0.9992, 0.9980, 1.0011, 0.9996,\n",
            "        1.0009, 0.9971, 0.9997, 0.9980, 0.9993, 0.9997, 0.9983, 0.9972, 0.9984,\n",
            "        0.9991, 0.9977, 0.9992, 1.0005, 0.9993, 0.9980, 0.9998, 0.9978, 0.9981,\n",
            "        0.9997, 0.9986, 0.9975, 1.0000, 0.9985, 0.9995, 0.9995, 0.9989, 1.0005,\n",
            "        0.9984, 0.9987, 1.0005, 0.9988, 0.9993, 0.9989, 0.9984, 0.9988, 0.9991,\n",
            "        0.9987, 1.0013, 0.9995, 0.9999, 0.9984, 1.0001, 1.0016, 1.0000, 0.9978,\n",
            "        1.0011, 0.9992, 0.9985, 0.9993, 0.9992, 0.9997, 0.9977, 0.9993, 0.9997,\n",
            "        0.9990, 1.0004, 0.9995, 0.9988, 0.9989, 0.9981, 0.9987, 0.9976, 0.9988,\n",
            "        1.0004, 0.9972, 0.9988, 0.9989, 0.9978, 0.9964, 1.0008, 0.9990, 1.0001,\n",
            "        1.0012, 0.9982, 0.9993, 0.9985, 0.9991, 0.9988, 0.9996, 0.9983, 0.9995,\n",
            "        1.0008, 0.9979, 0.9973, 0.9989, 0.9990, 0.9983, 0.9994, 1.0009, 0.9982,\n",
            "        0.9980, 0.9988, 1.0004, 0.9991, 0.9986, 1.0008, 0.9995, 0.9973, 0.9999,\n",
            "        0.9990, 0.9978, 0.9971, 1.0000, 0.9989, 0.9990, 1.0000, 1.0011, 1.0002,\n",
            "        1.0015, 0.9997, 0.9994, 0.9999, 1.0004, 0.9989, 0.9987, 1.0003, 0.9977,\n",
            "        0.9997, 0.9971, 0.9989, 0.9993, 0.9987, 1.0005, 0.9989, 0.9979, 0.9976,\n",
            "        0.9985, 0.9975, 0.9998, 1.0012, 1.0005, 1.0004, 1.0002, 1.0001, 0.9973,\n",
            "        1.0015, 0.9985, 0.9995, 1.0001, 1.0009, 1.0003, 0.9981, 1.0001, 0.9985,\n",
            "        0.9969, 1.0002, 0.9990, 0.9987, 0.9993, 0.9971, 0.9991, 0.9992, 0.9986,\n",
            "        0.9992, 1.0005, 0.9995, 0.9984, 0.9998, 1.0010, 0.9998, 1.0001, 1.0007,\n",
            "        0.9983, 0.9988, 1.0009, 0.9973, 0.9992, 0.9977, 1.0001, 0.9996, 0.9986,\n",
            "        0.9987, 0.9987, 0.9992, 0.9978, 0.9986, 0.9998, 1.0002, 0.9976, 1.0007,\n",
            "        1.0014, 0.9993, 0.9986, 0.9984])), ('module.encoder_k.layer1.0.downsample.1.bias', tensor([ 1.8825e-03, -2.5636e-04,  2.3058e-04,  6.1536e-04, -2.4665e-04,\n",
            "         1.8648e-03, -6.5061e-04, -1.0284e-03, -1.7575e-04, -2.7672e-04,\n",
            "         1.4647e-03,  4.2379e-04,  2.2541e-04, -2.3544e-04, -1.0728e-03,\n",
            "        -1.4628e-04, -1.5347e-03, -2.3080e-03, -3.1559e-04, -1.2106e-04,\n",
            "        -7.4980e-04, -4.2625e-04, -6.0088e-04, -9.2326e-04, -4.5714e-04,\n",
            "        -1.6825e-04, -1.8367e-03,  2.1035e-04, -2.8318e-04, -4.6462e-04,\n",
            "        -1.8060e-04,  1.9015e-04, -1.6283e-04,  1.1824e-03, -1.2544e-03,\n",
            "        -1.0473e-03, -1.0465e-03,  5.4165e-04, -1.1569e-03,  1.7947e-03,\n",
            "        -9.3323e-04, -1.8648e-04,  7.7268e-05,  1.5070e-03,  6.7744e-04,\n",
            "        -1.1682e-03, -9.4614e-04,  9.6019e-04, -8.4583e-04, -1.6092e-03,\n",
            "        -1.3081e-03,  1.0232e-05,  6.2345e-04,  7.0282e-04,  1.3333e-03,\n",
            "         2.1466e-03,  6.1835e-04,  1.4490e-03,  2.4542e-04,  4.0598e-04,\n",
            "         9.2572e-05, -1.1318e-03, -4.1128e-05,  1.7084e-03, -4.3629e-04,\n",
            "         9.8186e-05, -1.4773e-03,  1.9950e-03,  4.4904e-04,  7.2284e-04,\n",
            "         4.2732e-04,  2.6971e-05, -3.5142e-04,  9.2027e-05,  1.8452e-03,\n",
            "         6.2995e-04, -1.8119e-03,  1.8685e-04,  1.4977e-03,  7.0531e-05,\n",
            "        -1.2803e-04, -8.2005e-04, -3.8147e-04, -8.6663e-04,  8.6261e-04,\n",
            "        -2.8469e-04, -1.8267e-04,  1.6596e-03, -9.6989e-04,  3.6550e-04,\n",
            "         7.4902e-04, -5.7288e-04, -1.0843e-03,  1.1276e-04, -3.1031e-04,\n",
            "         7.2098e-04,  8.4306e-05,  1.1448e-03, -5.8829e-04, -9.1522e-04,\n",
            "        -1.1554e-03,  7.5968e-04,  1.1376e-04,  2.7231e-04, -7.9273e-05,\n",
            "        -4.6458e-05,  2.6652e-04,  9.3896e-04,  7.6470e-04,  1.5134e-03,\n",
            "        -2.9041e-04, -7.1079e-04, -1.6824e-03, -4.7534e-04,  2.3715e-03,\n",
            "        -3.0041e-04, -4.5458e-04,  3.5071e-04,  7.8482e-04, -9.6851e-04,\n",
            "         4.6035e-04,  8.1430e-04, -1.0291e-03, -1.6785e-03, -2.0492e-04,\n",
            "        -4.3140e-04,  1.6443e-04,  2.2139e-03,  1.7763e-03, -1.0328e-03,\n",
            "        -1.6548e-03, -2.9355e-04, -9.2706e-04, -5.5210e-04, -5.1561e-04,\n",
            "         1.2793e-03, -2.3957e-03, -2.0060e-03,  2.3705e-04, -5.9726e-04,\n",
            "         6.3170e-04,  5.3059e-05, -5.0381e-04,  9.8448e-05,  1.5135e-03,\n",
            "         4.7572e-04, -1.8789e-04, -2.0959e-04, -1.0308e-03,  1.1859e-03,\n",
            "         1.0147e-03, -9.0360e-05, -3.3232e-04,  7.1845e-04,  6.4087e-04,\n",
            "        -2.3217e-04,  1.1755e-04,  2.0632e-04,  9.6386e-06, -7.1340e-04,\n",
            "        -1.3607e-04, -1.3336e-03, -1.2542e-03, -8.0969e-05,  6.8155e-04,\n",
            "         3.0448e-05,  2.3170e-04, -3.8720e-04,  3.9080e-04, -1.5905e-03,\n",
            "        -4.0721e-04,  2.5530e-04,  3.1012e-04, -8.2038e-04,  9.0187e-04,\n",
            "        -3.9302e-04,  7.9873e-04, -1.1068e-03,  1.2232e-03,  1.3316e-03,\n",
            "         3.5157e-04, -6.9229e-04,  1.8442e-03,  6.6319e-05,  2.1493e-04,\n",
            "         1.6064e-04,  2.7481e-04,  1.5498e-04,  8.3012e-04, -7.1942e-04,\n",
            "        -2.8059e-04,  5.0541e-04, -2.2602e-04, -2.7439e-04,  8.1758e-04,\n",
            "         7.4742e-04, -9.2281e-04, -1.5191e-03,  1.8471e-04, -4.6586e-04,\n",
            "         8.7690e-04,  1.7381e-04,  7.8544e-04,  4.8118e-05,  3.3746e-04,\n",
            "         6.2125e-04, -4.6575e-04,  1.6160e-03,  1.9133e-03, -3.1273e-04,\n",
            "        -1.8867e-04,  1.2637e-03,  2.7094e-04, -3.1524e-04,  2.3888e-03,\n",
            "        -5.9999e-04, -1.3370e-03,  2.3087e-04,  3.0793e-04, -2.7065e-04,\n",
            "        -9.2102e-04, -5.3149e-04, -1.2391e-03,  7.9034e-04, -7.3097e-05,\n",
            "        -5.2154e-04,  1.8873e-03,  6.1886e-04, -4.0362e-04,  5.5627e-04,\n",
            "         5.7626e-05,  1.1334e-03,  5.3259e-04,  5.3988e-04, -3.5718e-05,\n",
            "        -1.4658e-04,  7.1034e-04, -1.9175e-03,  7.7053e-04, -2.9156e-03,\n",
            "         6.0585e-04, -8.0003e-04, -1.6079e-03,  7.4531e-04, -1.6352e-03,\n",
            "        -1.2819e-03, -2.6544e-03,  7.9967e-04,  7.9872e-04,  2.9313e-03,\n",
            "        -2.0231e-03,  1.0843e-03,  3.8685e-04,  1.0173e-03,  7.1978e-04,\n",
            "        -9.1372e-04])), ('module.encoder_k.layer1.0.downsample.1.running_mean', tensor([ 4.0499e-01,  1.8836e-01,  2.1427e-01,  1.7477e-01,  4.0271e-01,\n",
            "         1.8807e-01, -4.1204e-01,  4.8349e-02,  3.5126e-01,  3.8950e-01,\n",
            "        -6.2772e-01, -4.3771e-01,  1.6002e-01,  1.8097e-01,  2.6885e-02,\n",
            "        -6.1992e-01,  7.9863e-02,  1.1242e-01,  9.8266e-02, -6.3789e-01,\n",
            "         1.2022e-02,  2.6834e-01,  1.4730e-01,  3.0862e-01,  5.8446e-01,\n",
            "        -2.0344e-01,  8.6287e-03,  3.3137e-01, -1.8845e-01, -1.1047e-03,\n",
            "        -4.6975e-02,  4.4747e-01,  4.2395e-01, -3.5973e-01,  6.1204e-01,\n",
            "        -2.3917e-01, -2.7761e-01, -3.0206e-01,  2.2188e-01, -3.5781e-01,\n",
            "         6.6392e-01, -2.7836e-02, -1.0900e-01,  1.9344e-01, -3.1166e-01,\n",
            "        -1.8841e-01,  4.0541e-01, -1.9647e-01,  7.5002e-02, -9.5600e-02,\n",
            "        -6.9027e-01, -3.9385e-01,  9.8443e-01, -6.6122e-01,  2.7795e-01,\n",
            "         1.4474e-01,  4.3008e-01,  2.2741e-01,  3.8125e-01, -8.6046e-03,\n",
            "        -6.7040e-03, -1.9390e-01,  1.8410e-01, -7.7471e-02, -1.2754e-01,\n",
            "         1.1491e+00,  2.2848e-01, -1.1841e-01,  2.4222e-01,  2.0015e-02,\n",
            "        -1.1648e-01, -6.0579e-01, -2.4571e-01, -1.1313e-01,  2.7952e-01,\n",
            "         5.9836e-02,  3.3077e-01,  2.0319e-01,  1.0842e-02,  1.5619e-01,\n",
            "        -2.1546e-01,  4.0212e-02, -4.2074e-01, -3.6179e-01, -2.3717e-01,\n",
            "        -1.9786e-01,  2.2407e-02,  1.4448e-02, -3.4489e-01, -9.8006e-02,\n",
            "        -1.2142e-01,  5.5945e-01, -5.1419e-01, -3.2956e-01, -3.4357e-01,\n",
            "         1.6635e-01, -2.7312e-01, -9.5369e-02,  9.3006e-01,  4.0731e-01,\n",
            "        -7.0912e-02, -4.2207e-01, -5.7210e-01,  1.4317e-01, -2.8208e-01,\n",
            "        -5.8114e-01,  9.8664e-02, -5.3319e-02,  6.9718e-02, -2.4827e-01,\n",
            "         1.2177e-01,  9.3206e-02, -1.7131e-01, -1.0269e-01,  3.8355e-01,\n",
            "         1.3529e-01, -5.2041e-03, -3.6877e-01,  8.2756e-01,  2.2025e-01,\n",
            "         2.5597e-02, -2.5232e-01, -4.4197e-01, -6.3249e-02,  1.8327e-01,\n",
            "         3.1333e-01,  5.8251e-01, -1.4167e-01,  7.9895e-02, -2.2045e-02,\n",
            "        -1.2166e-01,  3.1251e-01,  1.2829e-01, -1.7599e-02, -1.0749e-01,\n",
            "        -1.1945e-01,  1.6105e-01, -4.6622e-01, -2.3278e-01, -1.0152e-01,\n",
            "         8.6766e-02,  3.6517e-02, -4.5723e-01, -4.1173e-02, -6.0536e-02,\n",
            "         5.8885e-01,  1.3971e-01, -1.8539e-01, -5.7892e-01, -5.5688e-01,\n",
            "        -5.2008e-01, -3.1944e-02,  4.6409e-01, -5.1402e-01,  4.7091e-01,\n",
            "        -6.4477e-01, -4.1008e-01, -6.2063e-02,  3.5711e-02,  4.8469e-01,\n",
            "        -2.6088e-01,  2.1575e-01, -1.6693e-01, -5.4150e-01,  2.8118e-01,\n",
            "         3.1944e-01,  2.8922e-01,  2.1019e-01, -3.9495e-01, -5.0876e-02,\n",
            "         1.0248e-01, -8.3378e-01,  5.5840e-01,  1.9058e-01, -1.4732e-01,\n",
            "         9.8621e-02, -1.4774e-01,  6.9247e-01, -1.2040e-01,  1.8599e-01,\n",
            "        -5.7582e-01,  2.8045e-01, -2.7022e-01,  1.5779e-01,  7.3088e-02,\n",
            "        -2.8523e-01, -2.7581e-01,  1.9573e-01, -9.6393e-02,  1.4021e-01,\n",
            "         3.6117e-01, -2.0057e-01,  2.1833e-01,  4.6725e-01, -1.4352e-02,\n",
            "         1.4419e-01,  2.9970e-01, -2.6773e-01, -2.8917e-01, -2.4026e-01,\n",
            "        -1.6698e-01,  2.2271e-02, -3.4169e-01,  2.2063e-01,  4.9578e-03,\n",
            "         7.3643e-02, -2.1121e-01, -2.7548e-01, -5.7188e-01, -2.7050e-01,\n",
            "        -3.6811e-01,  5.1441e-01, -1.4413e-01, -5.9971e-01, -3.6480e-01,\n",
            "        -2.2902e-01, -2.8107e-01, -1.2857e-01, -9.4478e-02,  2.5428e-01,\n",
            "        -2.2644e-02,  4.8708e-02,  1.6235e-04,  1.2223e-01,  2.2202e-01,\n",
            "         5.3782e-01, -3.2654e-01, -3.6895e-01, -5.0247e-02, -2.7608e-01,\n",
            "         7.1322e-01,  4.5099e-01,  2.3163e-01,  1.1918e-01,  3.6112e-01,\n",
            "         5.7912e-02,  1.4576e-01,  3.9143e-02, -4.3801e-01,  5.6925e-01,\n",
            "        -3.1472e-01, -2.1286e-01,  2.1560e-01,  4.3301e-01, -3.2150e-01,\n",
            "        -2.0248e-01, -1.9306e-01,  5.3168e-01, -4.1792e-01, -2.2666e-01,\n",
            "        -7.4776e-01,  2.4887e-01,  5.1129e-02, -2.9980e-01, -2.4619e-01,\n",
            "         7.0548e-01])), ('module.encoder_k.layer1.0.downsample.1.running_var', tensor([0.3497, 0.3332, 0.1780, 0.1869, 0.1409, 0.1435, 0.0773, 0.0249, 0.5543,\n",
            "        0.0800, 0.2111, 0.1516, 0.1792, 0.1374, 0.1294, 0.2137, 0.0613, 0.1268,\n",
            "        0.1187, 0.1025, 0.2344, 0.0912, 0.1344, 0.1092, 0.1159, 0.0831, 0.1114,\n",
            "        0.9053, 0.2178, 0.5080, 0.2321, 0.1866, 0.1315, 0.4359, 0.4853, 0.1288,\n",
            "        0.3327, 0.0779, 0.1487, 0.1096, 0.3782, 0.1325, 0.0644, 0.2588, 0.0897,\n",
            "        0.0968, 0.0602, 0.0827, 0.2893, 0.3217, 0.2014, 0.3415, 0.4818, 0.2513,\n",
            "        0.5104, 0.0375, 0.1077, 0.1038, 0.5107, 0.1710, 0.1150, 0.2148, 0.7108,\n",
            "        0.2049, 0.1711, 0.3627, 0.1853, 0.1717, 0.1303, 0.0710, 0.2486, 0.2407,\n",
            "        0.1708, 0.1874, 0.0612, 0.0636, 0.1249, 0.3168, 0.5465, 0.0830, 0.2436,\n",
            "        0.0932, 0.1789, 0.0617, 0.0782, 0.0912, 0.2704, 0.3557, 0.1240, 0.6603,\n",
            "        0.1872, 0.2145, 0.4134, 0.1535, 0.2126, 0.0700, 0.1580, 0.0601, 0.2302,\n",
            "        0.1285, 0.1257, 0.4920, 0.3458, 0.0402, 0.1911, 0.2302, 0.1663, 0.1042,\n",
            "        0.2739, 0.2291, 0.2040, 0.3092, 0.1038, 0.1884, 0.1135, 0.5074, 0.1459,\n",
            "        0.1678, 0.1616, 0.2024, 0.1763, 0.1355, 0.1695, 0.1144, 0.0405, 0.3953,\n",
            "        0.1109, 0.1590, 0.0833, 0.0569, 0.0411, 0.3952, 0.1024, 0.3288, 0.1345,\n",
            "        0.4063, 0.3067, 0.3911, 0.2152, 0.1490, 0.3081, 0.1500, 0.0890, 0.0620,\n",
            "        0.2933, 0.1586, 0.2233, 0.2269, 0.2388, 0.1705, 0.1716, 0.0738, 0.4928,\n",
            "        0.1190, 0.0838, 0.1971, 0.4215, 0.1541, 0.1507, 0.1245, 0.0623, 0.6656,\n",
            "        0.0483, 0.0999, 0.2681, 0.0894, 0.7376, 0.3431, 0.0979, 0.0773, 0.1559,\n",
            "        0.6102, 0.2514, 0.0991, 0.1290, 0.3298, 0.0771, 0.2273, 0.0895, 0.1593,\n",
            "        0.0906, 0.1554, 0.1828, 0.0407, 0.0626, 0.1750, 0.4085, 0.0467, 0.3054,\n",
            "        0.3815, 0.0476, 0.1637, 0.1302, 0.3812, 0.2674, 0.1652, 0.0927, 0.1056,\n",
            "        0.0758, 0.0392, 0.2773, 0.0341, 0.2133, 0.1234, 0.1111, 0.1644, 0.0466,\n",
            "        0.0922, 0.1312, 0.1561, 0.3748, 0.1645, 0.4623, 0.1219, 0.2087, 0.0946,\n",
            "        0.3670, 0.0736, 0.2328, 0.1907, 0.3256, 0.0573, 0.1986, 0.0338, 0.0640,\n",
            "        0.6337, 0.1129, 0.1602, 0.4174, 0.2624, 0.4984, 0.3104, 0.5617, 0.1473,\n",
            "        0.3411, 0.0308, 0.1223, 0.1904, 0.1335, 0.1921, 0.2509, 0.2520, 0.2747,\n",
            "        0.2787, 0.0632, 0.2437, 0.1401, 0.3143, 0.1480, 0.0500, 0.3006, 0.8653,\n",
            "        0.1721, 0.2086, 0.0740, 0.1918])), ('module.encoder_k.layer1.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.1.conv1.weight', tensor([[[[ 0.0854]],\n",
            "\n",
            "         [[ 0.0864]],\n",
            "\n",
            "         [[ 0.1412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0110]],\n",
            "\n",
            "         [[ 0.1225]],\n",
            "\n",
            "         [[ 0.0371]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0857]],\n",
            "\n",
            "         [[-0.0896]],\n",
            "\n",
            "         [[ 0.1641]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0252]],\n",
            "\n",
            "         [[ 0.1058]],\n",
            "\n",
            "         [[-0.0931]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1521]],\n",
            "\n",
            "         [[ 0.0417]],\n",
            "\n",
            "         [[ 0.3219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0815]],\n",
            "\n",
            "         [[ 0.1295]],\n",
            "\n",
            "         [[-0.0656]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0052]],\n",
            "\n",
            "         [[-0.0455]],\n",
            "\n",
            "         [[ 0.0709]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0024]],\n",
            "\n",
            "         [[-0.0514]],\n",
            "\n",
            "         [[-0.0695]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1317]],\n",
            "\n",
            "         [[-0.2026]],\n",
            "\n",
            "         [[-0.0408]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1482]],\n",
            "\n",
            "         [[ 0.2303]],\n",
            "\n",
            "         [[-0.0976]]],\n",
            "\n",
            "\n",
            "        [[[-0.0541]],\n",
            "\n",
            "         [[-0.0561]],\n",
            "\n",
            "         [[ 0.0566]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0571]],\n",
            "\n",
            "         [[-0.3167]],\n",
            "\n",
            "         [[ 0.0072]]]])), ('module.encoder_k.layer1.1.bn1.weight', tensor([0.9997, 0.9968, 0.9984, 0.9986, 0.9984, 0.9970, 1.0022, 1.0026, 0.9980,\n",
            "        0.9972, 0.9987, 0.9987, 1.0010, 0.9975, 1.0003, 0.9992, 1.0005, 0.9997,\n",
            "        1.0014, 0.9969, 1.0024, 0.9994, 1.0013, 1.0018, 0.9967, 1.0045, 0.9986,\n",
            "        1.0006, 0.9983, 0.9980, 0.9974, 0.9997, 1.0003, 1.0012, 0.9983, 0.9978,\n",
            "        1.0004, 0.9989, 0.9988, 0.9969, 1.0001, 0.9990, 0.9975, 0.9989, 0.9946,\n",
            "        0.9987, 1.0010, 0.9992, 1.0003, 0.9962, 1.0014, 0.9978, 1.0018, 1.0014,\n",
            "        0.9987, 0.9953, 0.9968, 0.9976, 0.9983, 0.9977, 0.9979, 0.9998, 0.9976,\n",
            "        0.9995])), ('module.encoder_k.layer1.1.bn1.bias', tensor([ 6.3876e-04, -6.5087e-05, -1.2795e-03,  3.5253e-04,  4.4127e-04,\n",
            "        -1.0293e-03,  2.1889e-03,  4.9898e-03,  2.1109e-03,  3.2147e-03,\n",
            "        -9.7181e-04, -1.6718e-03, -1.8703e-03, -3.2129e-03,  1.0364e-03,\n",
            "         8.3533e-04,  2.0586e-03,  7.5386e-04,  5.0649e-04, -5.2318e-03,\n",
            "         1.7962e-03,  2.0960e-03, -1.0085e-03, -4.5177e-04, -3.7860e-03,\n",
            "         3.7830e-03, -1.3915e-03,  1.3540e-03, -1.2910e-03, -2.0337e-03,\n",
            "        -7.2161e-04,  3.0304e-03,  3.7821e-03,  3.0628e-03, -5.0785e-04,\n",
            "        -1.9974e-03,  2.4145e-03, -4.9798e-03, -3.4870e-04, -1.4837e-03,\n",
            "         2.1418e-04,  9.8944e-05, -7.2703e-04,  3.5906e-04, -3.8618e-03,\n",
            "         5.3295e-04, -7.9390e-04, -4.4137e-04,  8.5621e-04, -1.9143e-03,\n",
            "        -3.0709e-03, -6.3533e-04,  3.6741e-03, -9.5207e-05, -1.4721e-03,\n",
            "        -4.9903e-03, -3.6729e-03, -1.2222e-03, -8.3412e-04, -1.8699e-03,\n",
            "        -2.3954e-03,  3.3951e-03, -6.8433e-04,  6.9732e-04])), ('module.encoder_k.layer1.1.bn1.running_mean', tensor([-0.9011, -0.1159,  1.0586, -1.1425, -2.0930,  0.3734,  2.9555, -1.8251,\n",
            "         1.1572,  0.7489,  1.1059,  0.5173, -2.0602,  1.4245,  1.1974, -4.9032,\n",
            "        -0.8542,  0.6444, -0.1639,  0.7411, -0.2470,  2.1617,  1.3950,  1.9999,\n",
            "         0.3701, -0.9823,  0.9414, -0.3132,  1.3247, -1.8622, -0.4422,  2.0654,\n",
            "        -0.4783, -0.4161, -1.0963,  1.1427,  1.0048,  1.2286,  1.3835,  3.2068,\n",
            "        -0.6571, -0.8918,  0.3320, -2.9579,  0.1990, -2.3763,  1.5137, -1.8055,\n",
            "         0.6905,  0.9411,  1.0642,  0.9279,  1.2564, -1.3992, -1.9704, -1.2417,\n",
            "         1.0340,  0.6693, -1.1251,  1.2017, -3.2490,  0.0512, -0.2774, -0.5448])), ('module.encoder_k.layer1.1.bn1.running_var', tensor([ 7.5339,  5.5858,  5.1694,  3.7101,  6.2577,  3.7498,  8.4600,  3.3952,\n",
            "         3.5253,  3.6564,  5.9035,  3.9152,  4.8169,  9.3450,  6.5498,  4.0029,\n",
            "         3.2696,  4.4114,  5.0269,  3.4454,  4.5944,  5.4375,  6.3132,  4.0585,\n",
            "         3.0005,  7.3246,  5.1486,  4.1135, 11.2427,  4.3418,  4.5886, 12.1246,\n",
            "         2.9868,  2.3080,  9.3580,  7.2986,  4.4395,  6.6709,  3.7883, 11.8403,\n",
            "         7.0487,  4.3711,  6.6330,  7.8747,  7.8152,  7.7000,  7.1059,  4.0906,\n",
            "         4.9183, 17.5794,  3.4643,  4.4352,  4.0178,  2.2994,  9.7547,  5.3098,\n",
            "         6.0979,  6.6682,  6.1851,  9.2419,  3.5231,  3.9882,  8.8127,  3.2135])), ('module.encoder_k.layer1.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.1.conv2.weight', tensor([[[[-0.0293,  0.0396,  0.1015],\n",
            "          [ 0.0290,  0.0143,  0.0580],\n",
            "          [ 0.0671,  0.1217, -0.0752]],\n",
            "\n",
            "         [[ 0.0205,  0.0160, -0.0253],\n",
            "          [ 0.0485, -0.0523, -0.0772],\n",
            "          [ 0.0832,  0.0339,  0.0004]],\n",
            "\n",
            "         [[ 0.0533, -0.0265, -0.0013],\n",
            "          [ 0.1017,  0.0576,  0.0955],\n",
            "          [ 0.0047, -0.0314, -0.0332]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1126, -0.0579,  0.0271],\n",
            "          [ 0.1446, -0.0171,  0.0290],\n",
            "          [-0.1547, -0.0637,  0.0825]],\n",
            "\n",
            "         [[ 0.0282, -0.0801, -0.0724],\n",
            "          [ 0.0578, -0.0762, -0.0920],\n",
            "          [ 0.0763,  0.0930,  0.0638]],\n",
            "\n",
            "         [[ 0.0522, -0.0615,  0.0446],\n",
            "          [ 0.0474,  0.0304,  0.0092],\n",
            "          [-0.0387, -0.0406, -0.1186]]],\n",
            "\n",
            "\n",
            "        [[[-0.0481, -0.1912, -0.0272],\n",
            "          [-0.0060, -0.0457, -0.0135],\n",
            "          [-0.0665,  0.0901, -0.0759]],\n",
            "\n",
            "         [[ 0.0213,  0.0253,  0.0514],\n",
            "          [-0.0105,  0.0397, -0.0547],\n",
            "          [ 0.0351, -0.0778,  0.0191]],\n",
            "\n",
            "         [[-0.0422,  0.0114,  0.0953],\n",
            "          [-0.0109,  0.0342, -0.0051],\n",
            "          [-0.0534,  0.0101, -0.1570]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0503, -0.0074,  0.0137],\n",
            "          [-0.0291, -0.0499, -0.0021],\n",
            "          [-0.0175,  0.0979,  0.0828]],\n",
            "\n",
            "         [[ 0.0589,  0.0356,  0.1038],\n",
            "          [-0.0899,  0.1051,  0.0191],\n",
            "          [ 0.0021, -0.0694,  0.0135]],\n",
            "\n",
            "         [[ 0.0219, -0.0545, -0.0181],\n",
            "          [ 0.0284, -0.0226, -0.0122],\n",
            "          [ 0.0906,  0.0178, -0.0007]]],\n",
            "\n",
            "\n",
            "        [[[-0.0726, -0.0321,  0.1157],\n",
            "          [ 0.0676, -0.0443, -0.0103],\n",
            "          [ 0.0427,  0.0566,  0.0105]],\n",
            "\n",
            "         [[-0.0112,  0.0224,  0.0094],\n",
            "          [ 0.1410,  0.0317,  0.0192],\n",
            "          [ 0.0015,  0.0240, -0.0090]],\n",
            "\n",
            "         [[ 0.0416,  0.0434,  0.0213],\n",
            "          [ 0.0940,  0.0372,  0.0025],\n",
            "          [-0.0179, -0.1127,  0.0215]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0606, -0.0849,  0.0178],\n",
            "          [ 0.0183, -0.0603, -0.0189],\n",
            "          [ 0.0524,  0.0277,  0.0112]],\n",
            "\n",
            "         [[-0.0303,  0.0794,  0.0448],\n",
            "          [-0.0174,  0.0559, -0.0611],\n",
            "          [ 0.0067, -0.0871,  0.0868]],\n",
            "\n",
            "         [[-0.0316, -0.0836,  0.0087],\n",
            "          [-0.0614,  0.0534,  0.0715],\n",
            "          [-0.0277,  0.0456,  0.0186]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0941,  0.0758, -0.0628],\n",
            "          [ 0.0010,  0.0177, -0.0394],\n",
            "          [ 0.0277,  0.0112, -0.0195]],\n",
            "\n",
            "         [[ 0.0774, -0.0234,  0.0055],\n",
            "          [-0.0200, -0.0346,  0.1296],\n",
            "          [-0.1493,  0.0157, -0.0054]],\n",
            "\n",
            "         [[-0.0935,  0.0089,  0.0007],\n",
            "          [ 0.0264, -0.0348,  0.0820],\n",
            "          [-0.0744, -0.0800,  0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0568, -0.0476, -0.0952],\n",
            "          [-0.0453,  0.0380,  0.0823],\n",
            "          [-0.0439, -0.0477, -0.0403]],\n",
            "\n",
            "         [[-0.0230, -0.0538, -0.0293],\n",
            "          [ 0.0201,  0.1143, -0.0175],\n",
            "          [ 0.0949, -0.0742,  0.0287]],\n",
            "\n",
            "         [[-0.0312,  0.0231,  0.0207],\n",
            "          [-0.0073, -0.0413,  0.0496],\n",
            "          [-0.0064,  0.0254, -0.0202]]],\n",
            "\n",
            "\n",
            "        [[[-0.0570, -0.0368,  0.0203],\n",
            "          [-0.0838, -0.0476,  0.0145],\n",
            "          [-0.0803,  0.1002,  0.0337]],\n",
            "\n",
            "         [[ 0.0692,  0.0398, -0.0235],\n",
            "          [ 0.0815, -0.0652,  0.0787],\n",
            "          [ 0.0394, -0.0691,  0.1222]],\n",
            "\n",
            "         [[-0.0256, -0.0551,  0.0195],\n",
            "          [ 0.0131, -0.1123,  0.0713],\n",
            "          [-0.0906, -0.0598,  0.0434]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0204, -0.0775, -0.0490],\n",
            "          [-0.0161,  0.0379,  0.0688],\n",
            "          [-0.0139,  0.0095,  0.1327]],\n",
            "\n",
            "         [[ 0.0192, -0.0866,  0.0564],\n",
            "          [-0.0842, -0.0358,  0.0525],\n",
            "          [-0.0341, -0.1706, -0.0892]],\n",
            "\n",
            "         [[-0.0323, -0.1167, -0.0677],\n",
            "          [ 0.0362, -0.0927,  0.0875],\n",
            "          [ 0.1259,  0.0558,  0.0098]]],\n",
            "\n",
            "\n",
            "        [[[-0.0207,  0.0333,  0.0452],\n",
            "          [ 0.0266,  0.0324,  0.0752],\n",
            "          [-0.0716, -0.0573, -0.0293]],\n",
            "\n",
            "         [[-0.0119, -0.0754, -0.0400],\n",
            "          [ 0.0027, -0.0150,  0.0123],\n",
            "          [-0.0627,  0.0400, -0.0522]],\n",
            "\n",
            "         [[-0.0522,  0.0351, -0.0219],\n",
            "          [-0.1158,  0.0317,  0.1013],\n",
            "          [ 0.0119,  0.1029,  0.0361]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0670,  0.0082,  0.0570],\n",
            "          [-0.0106, -0.0144,  0.0196],\n",
            "          [ 0.0170,  0.0246, -0.0398]],\n",
            "\n",
            "         [[ 0.1111, -0.0502,  0.1437],\n",
            "          [ 0.0228, -0.0911,  0.0874],\n",
            "          [-0.0416,  0.0943, -0.0328]],\n",
            "\n",
            "         [[-0.0100,  0.0364, -0.0466],\n",
            "          [ 0.1756, -0.1478, -0.1096],\n",
            "          [-0.0489, -0.0636, -0.0343]]]])), ('module.encoder_k.layer1.1.bn2.weight', tensor([0.9991, 0.9963, 0.9968, 0.9978, 0.9963, 1.0006, 0.9984, 0.9969, 1.0009,\n",
            "        1.0021, 0.9981, 0.9990, 0.9983, 0.9977, 0.9994, 1.0015, 1.0008, 0.9957,\n",
            "        1.0015, 1.0040, 0.9989, 0.9963, 0.9996, 0.9992, 0.9991, 1.0002, 1.0002,\n",
            "        1.0006, 0.9961, 0.9978, 0.9986, 0.9999, 0.9989, 0.9982, 0.9982, 0.9970,\n",
            "        1.0002, 1.0004, 1.0005, 1.0021, 1.0008, 1.0034, 1.0004, 1.0002, 1.0005,\n",
            "        1.0018, 1.0001, 0.9959, 0.9965, 0.9966, 0.9992, 0.9969, 0.9996, 1.0001,\n",
            "        1.0007, 0.9991, 0.9988, 0.9986, 0.9999, 0.9982, 0.9977, 0.9972, 0.9982,\n",
            "        0.9975])), ('module.encoder_k.layer1.1.bn2.bias', tensor([-7.7160e-05, -4.1933e-03, -1.4587e-04, -5.6147e-04, -1.7403e-03,\n",
            "         6.4467e-04, -6.6421e-04,  5.3990e-04,  2.7496e-03,  1.6862e-03,\n",
            "        -3.2512e-03, -1.2172e-03, -4.8708e-05, -1.5532e-03,  3.2914e-04,\n",
            "         1.9449e-03, -3.4179e-05, -2.6418e-03, -4.0592e-04,  5.0494e-03,\n",
            "        -2.2641e-03, -3.9008e-04, -1.3719e-03,  1.3790e-03,  5.4773e-04,\n",
            "         4.5753e-03,  5.1415e-04,  3.2990e-03, -1.8826e-03, -1.0275e-04,\n",
            "        -3.8089e-05,  9.1605e-04,  1.2931e-03, -3.2282e-04, -2.3333e-03,\n",
            "        -1.2701e-03,  6.2770e-04,  8.3002e-04, -9.8538e-05,  6.0390e-04,\n",
            "         1.2398e-03,  2.2429e-03,  8.5337e-04, -7.0410e-04,  2.3977e-03,\n",
            "         1.2838e-03,  6.9779e-04, -1.3251e-03, -2.7177e-03, -9.8211e-04,\n",
            "        -1.4948e-03, -6.0437e-04, -4.0901e-03,  1.7081e-03,  2.6648e-03,\n",
            "        -1.0520e-05, -1.2995e-03, -2.0261e-03,  1.7496e-03, -1.5807e-03,\n",
            "        -9.5530e-04, -1.0825e-03, -1.2870e-03, -7.6299e-04])), ('module.encoder_k.layer1.1.bn2.running_mean', tensor([-0.3377,  0.4247, -0.2662,  0.0211, -0.1835,  0.2177,  0.0161, -0.3653,\n",
            "         0.4077,  0.7752,  0.0292, -0.2314,  0.6053,  0.7910, -0.1373,  0.0832,\n",
            "        -0.0986, -0.1816, -0.6912, -0.6851,  0.5360, -0.6785, -0.5591, -0.0152,\n",
            "         0.1508, -0.0900,  0.0509, -0.3340,  1.1008,  0.3951, -0.4486, -0.3412,\n",
            "         0.6875,  0.2615, -0.4938, -0.6673, -0.3112,  1.1056,  0.7799, -0.1527,\n",
            "        -0.3216,  0.0232,  0.4294,  0.4514, -0.1710,  0.2681, -0.0958,  0.1323,\n",
            "         0.5810,  0.8117,  0.1847, -0.8316,  0.6896,  0.0987,  0.2356,  0.1668,\n",
            "         1.0311,  0.1814, -0.1899,  0.0548, -0.3590, -0.4669, -0.2286,  0.2344])), ('module.encoder_k.layer1.1.bn2.running_var', tensor([0.8492, 0.7069, 0.8307, 0.8648, 0.8207, 0.4807, 0.7233, 0.5060, 0.3974,\n",
            "        0.6538, 0.2449, 0.7496, 0.5137, 0.3960, 1.0052, 0.8326, 0.6482, 0.5070,\n",
            "        0.5834, 1.2572, 1.4833, 0.6432, 0.3399, 0.5548, 0.8582, 0.7527, 0.5683,\n",
            "        1.1780, 1.1294, 0.6135, 0.5063, 0.3749, 1.2342, 0.5087, 0.6116, 0.7640,\n",
            "        0.2905, 1.4639, 0.3274, 0.6866, 0.9546, 0.6282, 1.4839, 0.5414, 0.6507,\n",
            "        1.0335, 0.6975, 0.7886, 0.7043, 0.8785, 0.4663, 0.4617, 0.6913, 0.8748,\n",
            "        0.5661, 0.3717, 0.9907, 1.1636, 0.5734, 0.6197, 1.5306, 0.9275, 0.6275,\n",
            "        0.3983])), ('module.encoder_k.layer1.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.1.conv3.weight', tensor([[[[-0.1376]],\n",
            "\n",
            "         [[ 0.0219]],\n",
            "\n",
            "         [[-0.0161]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0425]],\n",
            "\n",
            "         [[-0.0024]],\n",
            "\n",
            "         [[-0.1306]]],\n",
            "\n",
            "\n",
            "        [[[-0.0176]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.1996]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0910]],\n",
            "\n",
            "         [[-0.0239]],\n",
            "\n",
            "         [[-0.0413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0425]],\n",
            "\n",
            "         [[-0.1251]],\n",
            "\n",
            "         [[-0.0570]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1381]],\n",
            "\n",
            "         [[-0.0005]],\n",
            "\n",
            "         [[-0.0953]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0256]],\n",
            "\n",
            "         [[ 0.0895]],\n",
            "\n",
            "         [[-0.1773]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1554]],\n",
            "\n",
            "         [[-0.0974]],\n",
            "\n",
            "         [[ 0.0966]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0436]],\n",
            "\n",
            "         [[ 0.0072]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0333]],\n",
            "\n",
            "         [[-0.0487]],\n",
            "\n",
            "         [[-0.0741]]],\n",
            "\n",
            "\n",
            "        [[[-0.0554]],\n",
            "\n",
            "         [[ 0.0840]],\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1226]],\n",
            "\n",
            "         [[-0.1221]],\n",
            "\n",
            "         [[-0.1308]]]])), ('module.encoder_k.layer1.1.bn3.weight', tensor([0.9995, 0.9986, 1.0005, 1.0002, 0.9992, 0.9997, 0.9980, 0.9981, 1.0001,\n",
            "        0.9993, 0.9993, 0.9997, 0.9996, 0.9993, 0.9985, 0.9998, 0.9992, 0.9983,\n",
            "        1.0003, 0.9986, 0.9990, 1.0000, 0.9991, 0.9987, 1.0003, 0.9988, 0.9995,\n",
            "        0.9991, 0.9991, 1.0001, 0.9997, 0.9973, 0.9999, 0.9992, 0.9988, 0.9981,\n",
            "        0.9979, 0.9992, 0.9978, 0.9988, 0.9981, 0.9985, 0.9985, 0.9987, 0.9988,\n",
            "        0.9998, 0.9987, 0.9994, 0.9990, 0.9983, 0.9991, 0.9982, 0.9986, 0.9996,\n",
            "        0.9991, 0.9983, 1.0001, 0.9992, 0.9980, 0.9996, 1.0002, 0.9989, 0.9995,\n",
            "        0.9996, 0.9992, 0.9983, 0.9991, 0.9982, 0.9983, 0.9984, 0.9980, 0.9979,\n",
            "        1.0001, 0.9989, 1.0004, 0.9989, 1.0018, 0.9984, 0.9997, 0.9995, 1.0001,\n",
            "        0.9994, 0.9986, 0.9979, 0.9990, 0.9986, 0.9986, 0.9975, 0.9986, 0.9998,\n",
            "        0.9996, 0.9992, 0.9981, 0.9999, 0.9997, 0.9985, 0.9995, 0.9986, 0.9983,\n",
            "        0.9992, 0.9991, 0.9997, 1.0001, 0.9974, 1.0002, 0.9996, 0.9981, 0.9974,\n",
            "        0.9994, 0.9999, 0.9993, 0.9991, 0.9987, 0.9987, 0.9990, 0.9993, 1.0000,\n",
            "        0.9990, 1.0001, 0.9984, 0.9996, 0.9995, 0.9979, 0.9991, 0.9985, 0.9978,\n",
            "        0.9986, 0.9997, 0.9988, 0.9979, 0.9987, 1.0002, 0.9987, 0.9990, 1.0005,\n",
            "        0.9976, 0.9994, 0.9996, 0.9986, 0.9993, 1.0003, 0.9986, 0.9992, 0.9992,\n",
            "        0.9977, 0.9991, 0.9992, 0.9993, 0.9988, 0.9989, 0.9984, 0.9982, 0.9989,\n",
            "        0.9989, 0.9994, 0.9993, 0.9987, 0.9994, 0.9987, 0.9995, 0.9988, 0.9986,\n",
            "        0.9984, 0.9991, 0.9986, 0.9994, 0.9987, 0.9985, 0.9999, 0.9996, 0.9984,\n",
            "        0.9987, 1.0000, 0.9973, 0.9990, 0.9989, 0.9987, 0.9977, 0.9993, 0.9994,\n",
            "        0.9990, 0.9976, 0.9991, 0.9992, 0.9997, 0.9999, 0.9980, 0.9988, 0.9990,\n",
            "        1.0000, 1.0005, 0.9995, 0.9992, 0.9997, 0.9999, 0.9978, 0.9987, 0.9999,\n",
            "        0.9996, 0.9986, 0.9981, 0.9991, 0.9995, 1.0000, 0.9996, 0.9988, 0.9992,\n",
            "        0.9995, 0.9996, 0.9988, 0.9985, 0.9984, 1.0002, 0.9992, 0.9978, 0.9977,\n",
            "        0.9988, 0.9993, 0.9995, 0.9982, 0.9992, 0.9991, 0.9989, 0.9992, 0.9980,\n",
            "        0.9992, 0.9989, 0.9988, 0.9983, 0.9978, 0.9997, 0.9987, 0.9997, 0.9983,\n",
            "        0.9983, 0.9994, 0.9997, 0.9995, 0.9995, 0.9988, 0.9981, 0.9986, 0.9989,\n",
            "        0.9994, 0.9994, 0.9990, 0.9990, 0.9983, 0.9985, 1.0001, 1.0002, 1.0006,\n",
            "        0.9983, 0.9995, 0.9995, 0.9995])), ('module.encoder_k.layer1.1.bn3.bias', tensor([ 7.8269e-04, -5.9084e-04,  3.6145e-04,  6.4345e-04,  6.1859e-05,\n",
            "         1.0131e-03,  5.8886e-05, -2.1218e-04,  1.0666e-03, -7.0026e-04,\n",
            "         6.6318e-04,  6.4205e-05,  5.3288e-04, -7.6042e-04, -3.8979e-04,\n",
            "         9.4871e-04, -4.5731e-04, -8.0572e-04,  1.0161e-03, -1.2818e-03,\n",
            "        -1.6235e-04,  9.4430e-04, -4.9403e-04,  4.1581e-04, -1.4128e-04,\n",
            "         7.2838e-06, -1.0527e-03,  2.5982e-04,  8.6903e-04, -3.2855e-04,\n",
            "         8.4074e-05, -3.6283e-04,  5.8964e-04, -4.7979e-04, -5.1551e-04,\n",
            "        -8.0339e-04, -8.4148e-04,  1.8725e-04, -2.2356e-05,  8.2725e-04,\n",
            "         4.6894e-04, -1.1554e-03, -2.5481e-04, -1.3196e-03, -2.5559e-04,\n",
            "        -1.7635e-04, -1.1276e-04,  7.3342e-05, -7.7785e-04, -3.7169e-04,\n",
            "        -1.8483e-03,  8.3950e-05, -4.3193e-05,  6.3624e-04,  8.9855e-04,\n",
            "         1.8048e-04,  8.5872e-04,  1.0902e-03, -1.1595e-04,  8.3844e-05,\n",
            "         1.1103e-03, -6.7739e-04,  7.6548e-04,  1.4463e-04,  2.7130e-04,\n",
            "         4.8619e-04, -5.0306e-04,  6.4594e-04,  8.4544e-05,  4.6089e-04,\n",
            "         3.7463e-04, -1.8017e-04, -4.0849e-04,  9.9782e-04,  1.3468e-03,\n",
            "         3.4753e-04,  3.6872e-04, -6.2575e-04,  1.0139e-03,  3.2725e-04,\n",
            "         2.3832e-04, -1.4145e-04, -4.6024e-04, -4.8124e-04,  1.7371e-05,\n",
            "        -6.7434e-04,  5.5565e-04,  7.3769e-04, -9.2248e-04,  9.0617e-04,\n",
            "         3.9229e-04,  1.5626e-04, -1.6740e-03,  8.2374e-04,  1.4873e-04,\n",
            "        -1.1046e-03,  1.0765e-03, -2.1706e-04, -4.1978e-04, -5.3039e-05,\n",
            "        -7.2312e-04, -1.8038e-04, -6.3387e-04, -5.2965e-04,  8.7724e-05,\n",
            "        -9.6756e-05, -3.5861e-04, -4.5715e-04, -1.9396e-04, -2.0350e-04,\n",
            "        -8.0119e-04, -4.6347e-04, -4.1528e-04,  3.5620e-04, -4.8081e-04,\n",
            "        -2.4837e-04, -3.2633e-04,  6.2130e-04,  4.1035e-04, -5.8435e-04,\n",
            "         1.4990e-04, -6.6109e-06, -7.3447e-04, -5.2896e-04, -1.1235e-03,\n",
            "        -5.3788e-05, -3.1580e-04,  1.1301e-03,  1.1524e-03, -9.6834e-04,\n",
            "        -7.4676e-04,  2.1605e-04, -4.7846e-04, -6.3129e-04,  7.5758e-04,\n",
            "        -1.9039e-04, -6.1427e-04, -4.6569e-04, -8.5894e-06,  9.2150e-04,\n",
            "         8.8350e-04, -2.8347e-04,  1.7494e-05,  6.9585e-05,  9.5178e-05,\n",
            "         1.1608e-03,  3.3437e-04,  5.2897e-04,  2.8412e-04,  1.1894e-03,\n",
            "         7.1796e-04,  1.4133e-04,  6.2189e-04, -5.3462e-04,  2.7231e-04,\n",
            "        -7.9788e-04, -3.3116e-04,  1.5546e-04, -9.0396e-04, -5.6643e-04,\n",
            "         1.7179e-04, -4.9728e-04, -6.7008e-04, -1.0929e-04, -7.9430e-04,\n",
            "         1.3873e-03, -3.3130e-04, -7.3025e-04,  2.6254e-04, -4.2160e-04,\n",
            "         6.3503e-04, -7.6320e-04, -1.0048e-04, -6.8395e-04,  1.7666e-05,\n",
            "        -6.4161e-04, -6.5919e-05, -1.0038e-03,  1.8602e-04, -2.3907e-04,\n",
            "        -5.1027e-04, -7.2951e-04, -5.6519e-05,  1.5459e-04,  4.1770e-04,\n",
            "        -1.4388e-04, -4.7408e-04,  1.0747e-03, -7.9474e-04, -2.0519e-04,\n",
            "         1.3071e-03,  2.7074e-04, -5.0519e-04, -5.9890e-04, -1.3853e-04,\n",
            "        -9.8581e-04, -6.7091e-04, -8.9950e-05, -1.3738e-05, -1.5379e-04,\n",
            "        -7.8226e-04,  4.9120e-05,  7.8745e-04,  1.4306e-03,  3.8374e-04,\n",
            "         2.2541e-04,  2.0613e-04,  1.0430e-03,  5.3445e-04, -1.0095e-04,\n",
            "        -6.4761e-04,  3.0834e-05,  1.4896e-05,  4.9873e-04, -4.4011e-04,\n",
            "        -5.0049e-04, -8.2049e-04, -7.5400e-04, -5.7295e-05, -1.8329e-04,\n",
            "        -7.1053e-04, -4.9223e-04, -1.3353e-04, -3.3759e-04, -1.1750e-03,\n",
            "         6.4940e-04, -2.6299e-04, -1.4497e-04,  7.0160e-04,  8.5713e-04,\n",
            "         4.7577e-04, -3.6654e-05,  4.0674e-04,  8.9244e-04, -3.0639e-04,\n",
            "         1.6655e-04,  1.2154e-03, -7.0690e-04,  4.3584e-04, -1.4443e-03,\n",
            "         4.0037e-04, -2.1293e-05, -1.1122e-03,  6.7632e-04,  1.0975e-03,\n",
            "        -1.6607e-03, -1.4923e-03,  8.7390e-05,  6.4202e-04,  8.5804e-04,\n",
            "        -2.6214e-04,  5.3835e-04,  8.1303e-04,  7.4180e-04,  1.4256e-03,\n",
            "        -8.4147e-04])), ('module.encoder_k.layer1.1.bn3.running_mean', tensor([-3.4862e-01, -4.9225e-01, -3.1183e-01,  9.5164e-02, -1.4805e-01,\n",
            "        -1.1409e-01, -4.5812e-01,  8.0860e-02,  9.9449e-03, -2.7089e-01,\n",
            "        -1.6112e-01, -1.5482e-01, -4.7569e-01,  1.2435e-01,  1.9125e-01,\n",
            "         1.0370e-01, -3.1831e-01, -1.3545e-02,  5.4963e-02,  2.0563e-02,\n",
            "        -2.3008e-01, -2.7831e-01, -1.6890e-01, -2.6761e-01,  1.8182e-01,\n",
            "        -2.4473e-01,  2.6508e-01, -1.6428e-01, -8.6364e-02,  2.5358e-01,\n",
            "        -2.6833e-01,  2.1834e-01,  1.0573e-01,  8.3836e-02,  4.9346e-03,\n",
            "        -9.4055e-02, -8.0258e-02, -7.8314e-02,  2.9208e-02,  2.2481e-01,\n",
            "         2.9458e-01, -6.2160e-01,  7.4041e-03,  1.8964e-01, -4.5396e-01,\n",
            "         4.2946e-01,  1.4582e-01,  1.3122e-01, -3.2847e-01, -1.8797e-01,\n",
            "        -5.3800e-07, -1.2502e-01, -3.9073e-02,  5.9676e-01,  3.2613e-01,\n",
            "        -2.6977e-01,  2.4018e-01, -1.0465e-02, -2.1016e-01,  2.7623e-01,\n",
            "        -6.0754e-01, -2.5638e-01,  3.7805e-01,  1.3058e-01,  2.9824e-02,\n",
            "         2.0191e-01, -4.4477e-01,  2.5591e-01,  1.1820e-01,  7.7787e-02,\n",
            "         1.1337e-01,  9.2696e-02, -1.2896e-01,  2.7613e-01, -1.8553e-01,\n",
            "        -1.7086e-02, -1.0446e-01,  5.6637e-02, -1.0729e-01, -5.2675e-01,\n",
            "         3.7335e-02,  1.4247e-01,  3.7399e-01, -2.5655e-01,  4.4583e-02,\n",
            "         5.6637e-01, -3.6189e-01, -5.4117e-02, -1.3238e-02, -1.1268e-01,\n",
            "         5.3386e-02, -1.2791e-02, -3.8984e-01, -2.5116e-02,  1.9430e-01,\n",
            "        -3.2232e-02,  3.6288e-01,  8.0564e-02,  1.0049e-01, -2.5934e-01,\n",
            "        -8.3415e-02, -3.8737e-01, -2.2939e-01, -1.9884e-01, -2.3035e-02,\n",
            "        -7.5145e-02, -1.8843e-01,  9.7033e-02,  1.2820e-01, -1.6546e-01,\n",
            "         1.2743e-02,  3.1147e-01,  4.3819e-01,  6.4022e-02, -3.1061e-02,\n",
            "        -6.9200e-02,  2.1040e-01,  6.8774e-03,  1.6156e-01,  7.7278e-02,\n",
            "         4.2409e-02,  4.1015e-02,  4.8410e-02, -1.7622e-01, -3.0506e-02,\n",
            "        -1.9857e-01,  3.6962e-01,  2.7889e-01,  1.5751e-01, -4.4767e-02,\n",
            "        -3.4646e-01, -2.4719e-01,  4.0532e-02, -6.6789e-02,  5.3997e-01,\n",
            "         3.5489e-01, -3.9475e-01,  3.3335e-01, -2.6445e-01, -6.3788e-02,\n",
            "         3.7638e-01,  2.4819e-02,  3.2617e-01,  4.1053e-01, -6.6817e-01,\n",
            "        -9.2383e-02,  3.0301e-01,  1.9041e-01, -3.3113e-02,  1.7336e-01,\n",
            "         1.0137e-01,  2.7457e-02,  4.1318e-01, -3.9344e-02, -2.1631e-01,\n",
            "        -2.6384e-01,  2.6028e-03,  2.8214e-01,  5.7301e-01, -2.5095e-01,\n",
            "         1.1635e-01, -1.4051e-01,  3.5451e-01,  1.5437e-01, -2.6967e-01,\n",
            "        -7.7368e-02,  9.8733e-02,  4.6620e-01,  2.5140e-01, -1.5226e-01,\n",
            "        -2.8220e-01, -1.2715e-01,  1.8348e-01,  1.1497e-01, -4.1845e-02,\n",
            "        -2.1288e-02, -1.3809e-01,  7.0682e-02,  3.5512e-01,  1.1891e-01,\n",
            "        -1.6941e-01,  1.1026e-01, -1.2728e-01, -2.7814e-01, -4.4454e-01,\n",
            "        -1.2735e-01,  8.0050e-02,  2.2323e-01, -4.1007e-02,  4.2207e-01,\n",
            "         5.7423e-03, -1.8667e-01, -9.3350e-02,  5.6010e-02,  1.3767e-01,\n",
            "         1.1400e-01,  5.6765e-01, -2.3587e-01, -1.7092e-01, -9.8378e-02,\n",
            "         6.6320e-02,  2.8548e-01,  4.5423e-02, -1.8256e-01,  6.1690e-03,\n",
            "        -1.8128e-01, -1.2397e-01,  3.3600e-01, -4.5047e-01, -5.3379e-03,\n",
            "         1.1499e-02, -1.4171e-01, -3.4923e-02, -3.5536e-03,  1.6200e-01,\n",
            "         2.1937e-01,  1.0467e-01, -1.8983e-01,  1.6175e-01,  5.8034e-01,\n",
            "        -4.5302e-01, -2.2394e-01,  2.5737e-02, -1.6870e-01, -4.7738e-01,\n",
            "         1.8151e-01, -4.2470e-01,  1.4875e-01,  2.0161e-01,  2.9684e-01,\n",
            "         7.1438e-02, -3.8733e-01, -4.0252e-02,  4.1344e-01, -3.4060e-01,\n",
            "         1.1786e-01, -3.0812e-01, -2.5724e-02,  2.4418e-01,  5.3673e-02,\n",
            "         9.0949e-02,  6.2337e-03, -9.3059e-02,  1.1649e-01, -1.9845e-01,\n",
            "         4.5195e-02,  1.9941e-01,  1.2904e-02, -2.0175e-01,  3.3299e-02,\n",
            "         5.6220e-02,  3.3533e-01,  4.3706e-02,  1.2318e-01,  1.1505e-01,\n",
            "        -3.9611e-01])), ('module.encoder_k.layer1.1.bn3.running_var', tensor([0.2788, 0.1816, 0.1431, 0.1442, 0.1438, 0.2338, 0.1349, 0.1289, 0.2904,\n",
            "        0.1526, 0.1143, 0.1760, 0.1247, 0.1152, 0.1256, 0.1359, 0.3172, 0.1647,\n",
            "        0.2402, 0.1164, 0.1452, 0.1753, 0.3032, 0.1306, 0.0668, 0.0920, 0.2196,\n",
            "        0.1261, 0.4205, 0.1403, 0.1735, 0.2237, 0.1118, 0.2338, 0.1151, 0.0891,\n",
            "        0.1456, 0.2297, 0.0725, 0.1248, 0.1784, 0.3176, 0.3123, 0.1823, 0.1289,\n",
            "        0.3072, 0.1838, 0.3118, 0.0962, 0.2032, 0.1130, 0.0966, 0.1418, 0.3578,\n",
            "        0.3648, 0.0982, 0.1269, 0.1880, 0.2083, 0.1655, 0.3233, 0.1192, 0.1976,\n",
            "        0.2479, 0.1265, 0.1344, 0.1794, 0.1396, 0.1247, 0.0930, 0.1135, 0.1362,\n",
            "        0.1564, 0.2271, 0.1877, 0.1122, 0.1272, 0.1380, 0.1280, 0.1396, 0.1085,\n",
            "        0.2536, 0.5458, 0.1244, 0.1223, 0.1618, 0.2111, 0.1387, 0.2431, 0.0804,\n",
            "        0.1174, 0.0867, 0.2503, 0.1419, 0.1756, 0.1279, 0.1932, 0.1181, 0.2324,\n",
            "        0.4965, 0.1267, 0.2652, 0.0907, 0.1859, 0.1130, 0.1279, 0.2285, 0.1478,\n",
            "        0.3155, 0.2410, 0.1476, 0.2676, 0.1849, 0.1964, 0.1511, 0.3083, 0.0650,\n",
            "        0.1506, 0.1817, 0.2107, 0.2955, 0.1145, 0.1596, 0.1895, 0.2547, 0.1302,\n",
            "        0.3354, 0.1441, 0.1171, 0.1390, 0.1891, 0.1351, 0.0784, 0.0917, 0.1833,\n",
            "        0.4535, 0.1009, 0.4134, 0.1813, 0.2106, 0.1917, 0.1519, 0.1701, 0.2355,\n",
            "        0.3102, 0.1294, 0.1422, 0.1347, 0.1227, 0.1787, 0.2504, 0.1123, 0.3670,\n",
            "        0.1634, 0.2549, 0.1665, 0.2305, 0.1866, 0.1674, 0.0793, 0.2053, 0.1116,\n",
            "        0.1244, 0.2160, 0.1994, 0.1067, 0.1462, 0.3058, 0.0933, 0.1770, 0.2208,\n",
            "        0.3815, 0.0855, 0.1433, 0.1245, 0.1237, 0.1302, 0.1170, 0.2259, 0.1339,\n",
            "        0.1290, 0.0748, 0.1149, 0.2113, 0.2019, 0.1436, 0.2052, 0.0964, 0.1603,\n",
            "        0.3356, 0.1606, 0.1613, 0.1518, 0.1939, 0.2065, 0.1229, 0.3127, 0.1544,\n",
            "        0.0990, 0.2217, 0.1899, 0.1585, 0.1667, 0.0882, 0.1154, 0.1409, 0.4364,\n",
            "        0.0905, 0.3136, 0.1599, 0.1166, 0.2016, 0.1483, 0.1486, 0.1486, 0.2667,\n",
            "        0.1710, 0.1015, 0.2253, 0.4304, 0.2773, 0.1968, 0.1646, 0.1126, 0.1819,\n",
            "        0.3948, 0.1272, 0.3127, 0.1836, 0.2669, 0.1685, 0.1300, 0.1350, 0.2322,\n",
            "        0.1137, 0.1586, 0.1083, 0.1079, 0.3329, 0.1933, 0.1836, 0.2133, 0.1554,\n",
            "        0.2992, 0.1479, 0.1258, 0.1582, 0.1332, 0.1848, 0.1549, 0.0718, 0.2113,\n",
            "        0.2076, 0.1788, 0.1657, 0.1179])), ('module.encoder_k.layer1.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.2.conv1.weight', tensor([[[[-0.1268]],\n",
            "\n",
            "         [[-0.1345]],\n",
            "\n",
            "         [[ 0.0591]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0403]],\n",
            "\n",
            "         [[ 0.1351]],\n",
            "\n",
            "         [[-0.1163]]],\n",
            "\n",
            "\n",
            "        [[[ 0.4111]],\n",
            "\n",
            "         [[ 0.0477]],\n",
            "\n",
            "         [[ 0.0154]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1724]],\n",
            "\n",
            "         [[ 0.3491]],\n",
            "\n",
            "         [[-0.1348]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1032]],\n",
            "\n",
            "         [[-0.2147]],\n",
            "\n",
            "         [[-0.1866]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1150]],\n",
            "\n",
            "         [[-0.3053]],\n",
            "\n",
            "         [[ 0.1756]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0877]],\n",
            "\n",
            "         [[-0.0316]],\n",
            "\n",
            "         [[-0.2087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1408]],\n",
            "\n",
            "         [[-0.1660]],\n",
            "\n",
            "         [[ 0.1308]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0535]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         [[ 0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1469]],\n",
            "\n",
            "         [[-0.0713]],\n",
            "\n",
            "         [[-0.0619]]],\n",
            "\n",
            "\n",
            "        [[[-0.1534]],\n",
            "\n",
            "         [[ 0.0756]],\n",
            "\n",
            "         [[ 0.0900]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2363]],\n",
            "\n",
            "         [[-0.3263]],\n",
            "\n",
            "         [[ 0.2777]]]])), ('module.encoder_k.layer1.2.bn1.weight', tensor([0.9987, 0.9988, 0.9994, 0.9978, 0.9985, 1.0001, 0.9988, 0.9999, 0.9981,\n",
            "        0.9980, 0.9990, 0.9992, 0.9990, 0.9994, 0.9998, 1.0005, 0.9966, 0.9984,\n",
            "        0.9968, 1.0012, 0.9960, 0.9987, 0.9989, 0.9972, 0.9986, 0.9995, 1.0016,\n",
            "        0.9975, 0.9998, 0.9978, 1.0013, 0.9993, 0.9974, 0.9978, 0.9996, 0.9993,\n",
            "        0.9992, 0.9999, 0.9971, 1.0001, 0.9992, 0.9996, 1.0001, 0.9986, 1.0015,\n",
            "        0.9997, 0.9998, 0.9985, 0.9991, 0.9985, 0.9988, 0.9980, 0.9981, 0.9985,\n",
            "        0.9993, 1.0003, 1.0000, 1.0004, 0.9993, 1.0015, 1.0001, 1.0004, 0.9975,\n",
            "        0.9997])), ('module.encoder_k.layer1.2.bn1.bias', tensor([-1.1926e-03,  2.8089e-04,  4.2819e-04, -1.0531e-03, -1.6029e-03,\n",
            "         8.4310e-04, -3.1590e-04,  1.5506e-03, -8.5252e-04, -5.8392e-04,\n",
            "         6.7228e-04,  7.9314e-04, -1.0421e-03,  1.0301e-03,  2.0076e-04,\n",
            "         8.9164e-04, -9.9705e-04, -7.3879e-05, -4.9161e-04,  8.1442e-04,\n",
            "        -1.7454e-03,  1.2693e-03, -1.3299e-04, -1.7619e-03, -7.3329e-04,\n",
            "         1.9352e-04,  1.6856e-03, -1.4390e-04,  1.3690e-04, -1.2842e-03,\n",
            "        -3.1641e-04,  1.2238e-03, -7.9390e-04, -1.3705e-03, -3.8790e-04,\n",
            "         2.6726e-03,  1.0246e-03,  1.9444e-03, -2.2346e-03,  6.1830e-04,\n",
            "        -3.3575e-04, -1.5831e-03,  6.3955e-04,  2.0946e-03, -1.2623e-03,\n",
            "         1.1455e-03,  7.0616e-04, -1.1151e-03, -7.1346e-04, -1.9763e-03,\n",
            "        -4.2946e-04,  7.8715e-04, -1.6253e-04,  1.5109e-04,  4.0167e-04,\n",
            "         1.6032e-03,  8.8331e-04,  2.2006e-03, -1.6949e-04,  3.5349e-03,\n",
            "         1.6992e-03,  1.1708e-03, -1.4866e-03, -5.7275e-04])), ('module.encoder_k.layer1.2.bn1.running_mean', tensor([ 0.9180, -1.6270, -0.3213,  1.6207,  0.4873, -0.8513,  1.2049,  0.6278,\n",
            "         0.2609, -1.0949, -0.6676, -1.1194,  0.4017, -0.1727, -2.4775, -5.6778,\n",
            "        -1.0820, -2.9688, -1.6564,  0.4046,  0.6178, -3.5927, -0.8377,  2.5422,\n",
            "         1.5175, -2.3457,  0.3785, -0.6285, -3.7298,  1.3007,  1.6154,  0.1303,\n",
            "         0.8980,  1.6771,  0.8865,  1.7439, -0.1294, -3.0993,  2.2164, -2.9060,\n",
            "        -2.8337,  0.1189,  1.6307,  2.8919, -1.8179,  2.0823,  2.2551,  0.9276,\n",
            "        -0.5107, -0.1614, -3.6747, -0.9334,  0.4240,  0.5966, -0.3533,  1.6279,\n",
            "        -2.6095, -0.4774, -0.4818, -3.3740, -1.5483,  2.8030, -0.1907,  0.2395])), ('module.encoder_k.layer1.2.bn1.running_var', tensor([11.4056,  9.6733,  6.8736, 13.6000, 13.3677,  4.7079,  7.3562,  6.9287,\n",
            "         7.5426, 11.0145,  8.1570,  6.8830,  7.6730,  8.9123,  3.8085,  7.5717,\n",
            "         5.2362, 10.6759,  8.6690,  7.7148,  8.3974,  5.6551, 10.3304,  9.3113,\n",
            "         4.4185,  8.1951,  8.9504,  7.6529, 11.7614,  9.1601,  9.1207,  7.6422,\n",
            "         7.5933,  5.8871,  7.8165,  9.0762,  5.2043,  9.4949,  5.1038, 10.6566,\n",
            "        19.8924,  5.5641,  7.1064, 10.2065,  4.5996,  7.5586,  8.7197,  8.8891,\n",
            "         4.7328, 11.9679, 28.9647,  8.4575,  9.5817,  7.6324,  8.0750,  4.6919,\n",
            "         6.3331,  5.6762, 10.9507,  7.6920,  9.0617,  3.8301,  9.7461, 10.3050])), ('module.encoder_k.layer1.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.2.conv2.weight', tensor([[[[ 9.8076e-02, -1.1069e-01,  5.7146e-02],\n",
            "          [ 2.5739e-02, -1.7556e-02,  1.3347e-01],\n",
            "          [ 9.4914e-02,  6.3752e-02, -5.0016e-02]],\n",
            "\n",
            "         [[-6.8609e-02, -8.6146e-02, -1.1366e-01],\n",
            "          [ 2.7814e-02, -1.0995e-01, -3.0661e-02],\n",
            "          [ 5.9561e-02,  6.2802e-02, -6.0389e-02]],\n",
            "\n",
            "         [[ 5.9106e-02, -4.3970e-02,  2.1841e-02],\n",
            "          [ 7.9578e-02, -7.0610e-02,  8.2363e-03],\n",
            "          [-3.7222e-02, -4.4415e-02, -3.2616e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0888e-02, -2.7952e-02, -8.3659e-02],\n",
            "          [-1.0134e-01,  4.4428e-02,  1.3934e-01],\n",
            "          [ 8.6817e-02,  2.5075e-02, -1.3038e-03]],\n",
            "\n",
            "         [[-9.1994e-02,  6.3108e-02,  4.3375e-03],\n",
            "          [-3.8804e-02,  1.0988e-02,  1.1317e-03],\n",
            "          [ 5.7721e-02, -4.2502e-02,  4.9881e-04]],\n",
            "\n",
            "         [[-1.5437e-02, -6.6427e-02,  1.1329e-01],\n",
            "          [ 1.6349e-02,  2.1276e-02,  4.8647e-02],\n",
            "          [ 5.1359e-02, -6.3421e-02, -9.3806e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.6315e-02,  3.7025e-02, -2.7962e-02],\n",
            "          [-2.5935e-02,  8.8598e-02,  3.0367e-02],\n",
            "          [-4.3370e-02, -9.2730e-02, -2.4882e-02]],\n",
            "\n",
            "         [[-2.5613e-02, -2.0002e-02, -5.7507e-02],\n",
            "          [-4.1786e-02, -1.8797e-02,  2.5122e-02],\n",
            "          [-1.3224e-02, -1.7938e-02,  1.3369e-02]],\n",
            "\n",
            "         [[ 6.6942e-03,  1.3993e-02, -1.2102e-02],\n",
            "          [-7.1579e-02, -8.2667e-02,  5.3104e-02],\n",
            "          [ 1.6843e-02, -2.1323e-02, -4.5424e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.1827e-02, -2.5672e-02, -6.5542e-02],\n",
            "          [ 6.7588e-03, -3.7019e-03, -2.1305e-04],\n",
            "          [-8.0260e-02, -1.4294e-02, -4.6111e-02]],\n",
            "\n",
            "         [[-3.8882e-02, -9.1744e-02,  5.2846e-02],\n",
            "          [-7.2034e-02,  1.0058e-01, -9.2992e-02],\n",
            "          [-7.6099e-02, -4.5278e-02,  9.1688e-02]],\n",
            "\n",
            "         [[ 2.5432e-02,  5.3759e-02,  1.1844e-02],\n",
            "          [ 1.5449e-02,  4.1986e-03,  9.9130e-02],\n",
            "          [-6.5514e-02,  3.9980e-02, -1.3896e-01]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3465e-01,  8.7931e-03, -1.2344e-02],\n",
            "          [ 2.3962e-02, -1.4492e-02, -8.4702e-02],\n",
            "          [-5.4711e-02, -2.8946e-02, -6.5761e-02]],\n",
            "\n",
            "         [[ 6.3643e-02,  1.1611e-01,  5.6273e-02],\n",
            "          [ 4.0412e-02, -6.9373e-02,  1.3940e-02],\n",
            "          [ 4.6324e-02,  9.4383e-02,  5.0575e-02]],\n",
            "\n",
            "         [[ 5.9960e-03,  3.5456e-02,  7.2562e-02],\n",
            "          [-1.0317e-01, -3.7162e-02, -2.2354e-02],\n",
            "          [ 2.7452e-02,  4.7378e-02, -1.6484e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2496e-02, -1.8127e-02, -3.1640e-02],\n",
            "          [ 2.8532e-02, -1.7604e-02, -3.8568e-02],\n",
            "          [-5.3294e-02, -1.1829e-01,  3.9589e-03]],\n",
            "\n",
            "         [[ 1.2296e-01, -3.8253e-02,  4.3310e-02],\n",
            "          [ 4.9585e-02, -1.8257e-02, -6.1508e-02],\n",
            "          [-6.0507e-02, -7.6966e-02,  4.4459e-02]],\n",
            "\n",
            "         [[-4.0424e-02,  3.3021e-02,  6.3896e-02],\n",
            "          [-2.9547e-02, -2.1664e-02, -8.4264e-02],\n",
            "          [ 8.7497e-03,  3.5951e-02, -5.8700e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.7778e-03, -6.5106e-02, -2.8948e-02],\n",
            "          [-1.0378e-01,  4.0227e-02, -1.1457e-02],\n",
            "          [-1.4180e-02, -2.5737e-02,  7.6164e-03]],\n",
            "\n",
            "         [[-5.8995e-02,  2.3803e-02, -3.5032e-02],\n",
            "          [ 4.2368e-02, -9.1306e-02, -3.4742e-02],\n",
            "          [-8.6354e-02,  2.9202e-04,  5.6059e-02]],\n",
            "\n",
            "         [[-3.7945e-02, -1.3866e-02,  5.0207e-02],\n",
            "          [ 2.9867e-02, -7.5457e-02, -2.7776e-03],\n",
            "          [ 3.4706e-02, -8.6611e-02,  1.1468e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4907e-02, -3.3797e-02, -3.0632e-02],\n",
            "          [-1.5928e-02,  1.2421e-02,  1.2114e-01],\n",
            "          [ 1.2835e-01, -3.9272e-02,  6.5457e-02]],\n",
            "\n",
            "         [[-5.6319e-02, -9.4594e-02,  1.0823e-02],\n",
            "          [-1.0440e-01,  1.2927e-02, -7.0788e-02],\n",
            "          [ 8.4450e-02, -7.4835e-02, -1.3395e-02]],\n",
            "\n",
            "         [[-4.4210e-02, -3.6338e-03, -2.9587e-03],\n",
            "          [-3.1925e-03, -1.1460e-01,  1.3013e-02],\n",
            "          [-7.6948e-02, -6.5217e-02, -9.5186e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.3616e-03, -6.8522e-02,  6.9923e-03],\n",
            "          [-3.1361e-03, -4.5423e-02, -4.8382e-02],\n",
            "          [-8.9691e-02, -5.7905e-02,  1.9669e-02]],\n",
            "\n",
            "         [[-4.5798e-02,  1.1638e-01,  1.6169e-01],\n",
            "          [ 1.3462e-02,  1.2603e-02, -9.0835e-02],\n",
            "          [ 1.4255e-02,  5.8880e-02,  4.1306e-02]],\n",
            "\n",
            "         [[-6.7028e-02, -8.4269e-03,  4.4240e-02],\n",
            "          [-4.7199e-02,  5.4717e-02,  1.0628e-01],\n",
            "          [-3.9388e-04,  2.7795e-02,  2.4846e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7879e-02, -2.2826e-03, -4.1199e-02],\n",
            "          [-5.3115e-02, -4.7973e-02,  8.2087e-02],\n",
            "          [-2.7611e-02,  1.2941e-01,  4.4576e-02]],\n",
            "\n",
            "         [[ 1.4612e-01, -1.5525e-02, -3.5093e-02],\n",
            "          [-2.4013e-02,  5.3694e-02,  6.9111e-02],\n",
            "          [ 5.0843e-02, -3.0408e-02,  2.6520e-02]],\n",
            "\n",
            "         [[-8.6013e-02,  4.3928e-02,  1.1606e-01],\n",
            "          [ 5.4425e-02,  4.9302e-02,  1.6829e-02],\n",
            "          [-4.7892e-02,  2.4350e-02, -2.5741e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9276e-02, -7.0058e-02, -1.5274e-02],\n",
            "          [ 5.3175e-03, -1.4084e-02, -4.8340e-02],\n",
            "          [-2.3574e-02,  2.9298e-02, -1.2431e-01]],\n",
            "\n",
            "         [[-3.6987e-02,  3.7284e-02, -1.4661e-01],\n",
            "          [ 4.9875e-02,  5.3276e-02,  7.6233e-02],\n",
            "          [-2.9335e-02, -3.9026e-02, -5.6466e-02]],\n",
            "\n",
            "         [[-9.2436e-04, -3.0453e-02,  4.0042e-02],\n",
            "          [ 9.1992e-02, -3.8871e-02, -6.7077e-02],\n",
            "          [ 1.6969e-01,  1.3032e-02,  1.0340e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.1517e-02,  4.0436e-02,  2.6729e-02],\n",
            "          [ 8.4477e-03, -4.1648e-02, -4.2209e-02],\n",
            "          [-6.3316e-02, -9.1207e-02,  7.3664e-02]],\n",
            "\n",
            "         [[ 2.3809e-02, -1.2720e-01, -1.4210e-04],\n",
            "          [-2.3660e-02, -2.1783e-02,  9.2694e-02],\n",
            "          [ 8.6472e-02, -3.9366e-02, -7.7136e-02]],\n",
            "\n",
            "         [[-1.3586e-01,  5.0227e-02, -6.6078e-02],\n",
            "          [-1.0725e-01, -4.6212e-02, -3.3507e-02],\n",
            "          [ 5.2965e-02,  1.3305e-02, -8.2823e-03]]]])), ('module.encoder_k.layer1.2.bn2.weight', tensor([0.9998, 0.9984, 0.9988, 1.0001, 0.9968, 0.9977, 0.9998, 0.9995, 0.9985,\n",
            "        1.0008, 1.0010, 0.9986, 0.9971, 0.9989, 1.0026, 0.9985, 0.9978, 0.9975,\n",
            "        0.9994, 0.9973, 0.9973, 0.9990, 0.9978, 0.9998, 0.9982, 1.0009, 0.9985,\n",
            "        0.9985, 0.9991, 1.0003, 0.9987, 0.9992, 0.9976, 0.9995, 0.9975, 0.9991,\n",
            "        1.0007, 0.9992, 1.0001, 0.9981, 1.0009, 1.0007, 0.9997, 0.9984, 0.9989,\n",
            "        0.9988, 0.9983, 0.9980, 1.0003, 0.9988, 0.9997, 0.9990, 1.0017, 0.9977,\n",
            "        0.9995, 0.9978, 1.0002, 0.9984, 0.9991, 0.9995, 0.9995, 0.9987, 0.9987,\n",
            "        1.0012])), ('module.encoder_k.layer1.2.bn2.bias', tensor([ 3.4382e-04, -1.0275e-03, -2.7886e-04,  7.7299e-04, -1.9330e-03,\n",
            "        -7.7369e-04,  1.6614e-03,  2.1341e-03, -1.1654e-03,  1.7701e-04,\n",
            "         1.4268e-03,  7.9668e-05, -1.8886e-03,  4.0459e-04,  3.2202e-03,\n",
            "        -3.6513e-04,  2.8223e-04, -8.0341e-04,  7.6842e-04, -8.0953e-04,\n",
            "        -1.2668e-03, -8.4252e-04,  2.7686e-04,  9.1584e-04, -1.4991e-03,\n",
            "         1.2269e-03,  5.4004e-05, -3.0683e-04,  1.3213e-03,  7.3640e-04,\n",
            "        -1.3946e-03, -3.2707e-05, -6.6807e-04, -1.3516e-05, -7.5188e-04,\n",
            "        -1.6494e-04, -1.5120e-04,  9.8947e-04, -5.4435e-04,  4.6246e-04,\n",
            "         9.7159e-04,  1.8229e-03,  2.2378e-03,  3.1673e-04, -2.5648e-04,\n",
            "        -6.1589e-04, -1.4165e-03, -6.5572e-04, -1.5192e-04, -4.5429e-04,\n",
            "         1.2527e-03, -2.9706e-04,  3.0542e-03, -1.0296e-03, -6.0605e-04,\n",
            "         8.2219e-05,  3.7780e-04,  4.2886e-04, -1.6511e-03,  5.3141e-04,\n",
            "        -5.5107e-04,  4.5024e-04,  1.5015e-04,  1.9574e-03])), ('module.encoder_k.layer1.2.bn2.running_mean', tensor([-0.3372,  0.0701, -0.0969, -0.2699, -0.8366, -0.0385, -0.4038,  0.0519,\n",
            "         0.3451, -0.4025,  0.3387, -0.9643, -0.1203,  0.6780,  0.3039,  0.4947,\n",
            "         0.2471, -0.8516, -1.0359,  0.2702,  0.6155,  1.5601, -0.2926,  0.0323,\n",
            "        -0.0765,  0.3687, -0.3399,  0.1935,  0.1355,  0.1652, -0.7706, -0.6939,\n",
            "         1.1470, -0.9412, -0.5026, -0.5352,  0.3340,  0.0528,  0.0731, -0.0703,\n",
            "        -0.5817,  0.3200,  0.3357, -0.1137,  0.0122,  0.3808, -0.0776,  0.1266,\n",
            "         0.5467,  0.9174,  0.4812,  1.0653,  0.6527,  0.7968, -0.2092, -0.0421,\n",
            "         0.4382, -0.0684,  0.2212, -0.0833, -0.2435,  0.2582, -0.3101, -0.4002])), ('module.encoder_k.layer1.2.bn2.running_var', tensor([0.8709, 0.4756, 0.7310, 0.6752, 1.3386, 0.3221, 0.6763, 0.4970, 0.4611,\n",
            "        0.7153, 0.7813, 0.9299, 0.4458, 1.4389, 0.9928, 0.5013, 0.9581, 0.6397,\n",
            "        1.4827, 0.9083, 0.8052, 0.9242, 0.7044, 0.6285, 0.8301, 0.5004, 0.4699,\n",
            "        0.6399, 0.6226, 0.8635, 0.8645, 0.7555, 1.0993, 0.4595, 0.9448, 0.5158,\n",
            "        0.8630, 0.5041, 0.7417, 0.8816, 0.9256, 0.6456, 0.7164, 0.7220, 0.4918,\n",
            "        1.0666, 0.3324, 0.4763, 0.7758, 0.3654, 0.9197, 0.9324, 0.7233, 0.5355,\n",
            "        0.8016, 0.5915, 0.3470, 0.9916, 0.6105, 0.4091, 0.6157, 0.5635, 0.9104,\n",
            "        0.5534])), ('module.encoder_k.layer1.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer1.2.conv3.weight', tensor([[[[-0.1540]],\n",
            "\n",
            "         [[ 0.0046]],\n",
            "\n",
            "         [[ 0.0475]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0644]],\n",
            "\n",
            "         [[ 0.0528]],\n",
            "\n",
            "         [[ 0.0393]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0118]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0273]],\n",
            "\n",
            "         [[-0.1240]],\n",
            "\n",
            "         [[-0.1724]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1522]],\n",
            "\n",
            "         [[-0.0523]],\n",
            "\n",
            "         [[-0.1732]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0108]],\n",
            "\n",
            "         [[ 0.1289]],\n",
            "\n",
            "         [[-0.0410]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1419]],\n",
            "\n",
            "         [[ 0.0873]],\n",
            "\n",
            "         [[ 0.1142]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0854]],\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         [[ 0.1641]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1175]],\n",
            "\n",
            "         [[-0.0527]],\n",
            "\n",
            "         [[-0.0305]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0065]],\n",
            "\n",
            "         [[-0.0790]],\n",
            "\n",
            "         [[-0.0337]]],\n",
            "\n",
            "\n",
            "        [[[-0.0411]],\n",
            "\n",
            "         [[ 0.0611]],\n",
            "\n",
            "         [[-0.1290]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0935]],\n",
            "\n",
            "         [[ 0.0138]],\n",
            "\n",
            "         [[-0.0684]]]])), ('module.encoder_k.layer1.2.bn3.weight', tensor([0.9989, 0.9984, 0.9996, 0.9993, 0.9997, 0.9994, 1.0000, 1.0001, 0.9988,\n",
            "        0.9986, 0.9989, 0.9995, 0.9986, 0.9989, 0.9990, 0.9994, 0.9997, 0.9986,\n",
            "        0.9994, 0.9995, 0.9993, 0.9989, 0.9989, 0.9994, 0.9990, 0.9989, 1.0005,\n",
            "        0.9987, 0.9986, 0.9994, 0.9990, 0.9999, 0.9987, 0.9996, 0.9991, 0.9982,\n",
            "        0.9999, 0.9992, 0.9983, 0.9992, 0.9995, 0.9998, 0.9994, 0.9995, 0.9996,\n",
            "        0.9991, 0.9991, 0.9997, 0.9995, 0.9993, 0.9995, 0.9990, 0.9989, 0.9990,\n",
            "        0.9998, 0.9980, 0.9988, 0.9992, 0.9991, 0.9996, 1.0000, 0.9983, 0.9996,\n",
            "        0.9980, 0.9997, 0.9986, 0.9990, 1.0000, 0.9991, 0.9986, 0.9987, 0.9990,\n",
            "        0.9996, 0.9994, 0.9987, 0.9993, 0.9989, 0.9992, 0.9988, 0.9998, 0.9991,\n",
            "        0.9999, 0.9992, 0.9985, 0.9991, 0.9993, 0.9994, 0.9990, 0.9992, 0.9995,\n",
            "        0.9996, 0.9988, 0.9984, 0.9984, 0.9986, 0.9986, 0.9988, 0.9990, 0.9998,\n",
            "        0.9996, 0.9995, 0.9991, 0.9990, 0.9985, 0.9983, 0.9987, 0.9992, 0.9984,\n",
            "        0.9995, 0.9997, 0.9994, 0.9991, 0.9993, 0.9981, 0.9993, 0.9991, 0.9986,\n",
            "        0.9990, 1.0000, 0.9994, 0.9998, 0.9992, 0.9992, 0.9980, 0.9993, 0.9989,\n",
            "        0.9983, 0.9996, 0.9987, 0.9994, 0.9996, 0.9992, 0.9994, 0.9986, 0.9988,\n",
            "        0.9983, 0.9988, 0.9982, 0.9988, 0.9996, 0.9985, 0.9982, 0.9996, 0.9995,\n",
            "        0.9995, 0.9993, 0.9996, 0.9988, 0.9996, 0.9986, 0.9988, 0.9990, 1.0000,\n",
            "        0.9995, 0.9995, 0.9989, 0.9990, 0.9990, 0.9989, 0.9986, 0.9988, 0.9992,\n",
            "        0.9987, 0.9989, 0.9981, 0.9997, 0.9981, 0.9989, 0.9992, 0.9991, 0.9990,\n",
            "        0.9982, 0.9987, 0.9981, 0.9996, 0.9998, 0.9992, 0.9998, 0.9992, 0.9991,\n",
            "        0.9992, 0.9987, 0.9990, 0.9996, 0.9991, 0.9992, 0.9998, 0.9992, 0.9987,\n",
            "        0.9997, 0.9992, 0.9989, 0.9993, 0.9994, 0.9989, 0.9992, 0.9988, 0.9993,\n",
            "        0.9999, 0.9991, 0.9989, 0.9987, 0.9982, 0.9995, 0.9998, 0.9988, 0.9982,\n",
            "        0.9989, 0.9992, 0.9995, 0.9994, 0.9986, 0.9984, 0.9985, 1.0003, 0.9998,\n",
            "        0.9995, 0.9991, 0.9987, 0.9981, 0.9989, 0.9987, 0.9994, 0.9998, 0.9993,\n",
            "        1.0005, 0.9994, 0.9991, 0.9996, 0.9996, 0.9993, 0.9988, 0.9993, 0.9992,\n",
            "        0.9988, 0.9990, 0.9985, 0.9988, 0.9990, 0.9985, 0.9987, 0.9994, 0.9993,\n",
            "        0.9993, 0.9995, 0.9991, 0.9995, 0.9990, 0.9985, 0.9988, 0.9996, 0.9989,\n",
            "        0.9996, 0.9993, 1.0000, 0.9985])), ('module.encoder_k.layer1.2.bn3.bias', tensor([-2.1442e-04, -1.4992e-04,  5.9081e-04, -2.6168e-04, -1.8166e-04,\n",
            "         7.4889e-04,  3.7086e-04,  6.4838e-04,  2.4378e-04,  2.0927e-04,\n",
            "         2.1510e-04,  1.9301e-04,  4.1117e-04, -4.3504e-05,  2.4514e-04,\n",
            "         4.8387e-04, -1.2566e-04, -7.1955e-04,  3.2364e-04, -3.7128e-04,\n",
            "        -3.0085e-04,  4.4387e-04,  1.3592e-04,  1.4170e-04,  1.8658e-04,\n",
            "         3.2154e-04,  3.3678e-04,  1.7944e-04,  1.0061e-04, -2.4878e-04,\n",
            "         1.8598e-04,  4.3575e-04, -2.5065e-04, -9.5179e-05, -7.2251e-04,\n",
            "        -5.2624e-04,  6.0187e-04,  4.4732e-04, -5.7030e-04, -1.9055e-04,\n",
            "         3.0624e-04, -1.0881e-04, -3.0706e-04, -1.2970e-04,  2.1034e-04,\n",
            "         4.3682e-04,  7.2336e-05, -3.3107e-04, -4.1624e-05, -2.4617e-04,\n",
            "        -2.8058e-04, -1.7678e-04, -1.4698e-04,  3.3461e-04, -2.0528e-04,\n",
            "         2.2260e-04,  1.0042e-03,  5.2707e-04, -2.5478e-04,  5.6778e-04,\n",
            "         1.8048e-04, -4.0436e-04,  6.2181e-04, -2.2269e-05,  2.7890e-04,\n",
            "        -3.8431e-04, -3.1397e-04,  3.0603e-04,  7.1403e-04, -1.1863e-04,\n",
            "        -1.1786e-04, -5.4465e-05,  2.0951e-04,  3.1746e-04,  8.3008e-05,\n",
            "         2.4965e-04, -1.5226e-04, -5.6692e-05,  3.1586e-04,  4.9330e-04,\n",
            "         5.1185e-04,  1.7511e-04,  3.3922e-04, -3.4603e-04,  9.9880e-05,\n",
            "        -4.5351e-04,  4.7273e-05,  6.7888e-05, -4.4139e-04,  8.9350e-04,\n",
            "         3.0409e-04, -1.3430e-05, -8.4899e-04,  2.4720e-04, -2.3114e-04,\n",
            "        -5.6006e-04,  2.6226e-04, -2.8340e-04,  2.4833e-04,  8.2767e-05,\n",
            "        -1.6384e-04,  1.3901e-04, -2.8232e-05, -6.9432e-06, -4.6144e-04,\n",
            "        -2.7326e-04, -1.5987e-04, -9.2316e-04,  3.7434e-04,  6.9417e-04,\n",
            "        -6.4282e-05, -4.0646e-04, -2.4141e-04, -4.3084e-04,  1.9275e-04,\n",
            "        -1.0720e-04,  2.1856e-04,  5.8590e-04,  7.0598e-04, -2.7012e-04,\n",
            "         1.5295e-04,  1.3103e-04, -3.9376e-04, -7.8898e-05, -2.9590e-05,\n",
            "        -5.2434e-04, -8.1213e-04,  7.7908e-04,  7.5559e-04,  3.1892e-04,\n",
            "        -6.8017e-04,  4.0729e-06,  5.1801e-04,  6.3664e-06, -1.2216e-04,\n",
            "        -4.8860e-05,  7.4741e-06,  3.6774e-05, -3.1187e-04,  2.4094e-04,\n",
            "         2.3604e-04, -2.1264e-04,  8.7273e-05,  9.7388e-06,  1.5884e-05,\n",
            "         5.7039e-04,  2.2524e-05,  3.8756e-04, -4.5525e-04, -2.6013e-04,\n",
            "         4.8013e-04, -3.0476e-04,  2.0903e-05, -7.8426e-05,  3.7373e-04,\n",
            "        -2.9424e-04, -4.2945e-04, -2.2818e-05,  5.1188e-04, -8.2642e-05,\n",
            "        -6.0445e-05, -2.4650e-04, -1.0987e-03, -2.5652e-08,  2.0260e-05,\n",
            "         3.7572e-04, -5.5631e-04,  1.4731e-04,  7.8337e-05, -2.7263e-04,\n",
            "         3.5918e-04, -2.9987e-04, -3.7606e-04, -5.5621e-04, -4.0964e-04,\n",
            "         2.1732e-04, -1.0349e-04,  2.3697e-04,  6.4223e-04,  3.1713e-04,\n",
            "        -1.5149e-04,  1.4238e-04, -4.9359e-04,  1.1461e-04, -1.4961e-04,\n",
            "         2.8053e-04, -4.8874e-04, -1.6966e-05, -3.1572e-04, -1.2680e-04,\n",
            "         5.4656e-04,  1.8586e-04, -1.1796e-04,  8.4598e-05,  1.2700e-04,\n",
            "         6.7096e-04, -2.1896e-05,  3.0196e-04,  7.2941e-04,  2.8570e-04,\n",
            "        -5.3007e-04, -2.2501e-06,  1.0269e-04, -1.2059e-04,  6.2130e-04,\n",
            "         2.3423e-05,  3.4085e-04,  1.6016e-04,  9.5836e-05,  3.5017e-04,\n",
            "        -2.7752e-04, -2.5237e-04,  2.0010e-04, -7.7542e-05,  5.3346e-05,\n",
            "         1.3833e-04,  1.4646e-04, -5.5363e-04, -4.0510e-04, -6.1943e-04,\n",
            "         5.0581e-05, -6.1383e-05, -1.5721e-04, -1.8179e-04, -4.6998e-04,\n",
            "        -3.7799e-04, -7.6433e-06, -2.4887e-04, -1.7619e-04, -1.9620e-04,\n",
            "         6.0699e-04, -2.2334e-04,  1.9582e-04, -9.8251e-05, -7.0201e-05,\n",
            "        -7.4050e-05,  2.2258e-04, -2.4573e-04, -5.5811e-04, -9.7733e-04,\n",
            "         1.1191e-04, -1.4890e-05, -6.4991e-05,  6.4015e-04,  1.1885e-04,\n",
            "        -5.5598e-04, -1.5173e-04, -1.3119e-04,  3.1040e-04, -2.3436e-04,\n",
            "         8.9148e-05, -2.4245e-04,  4.8642e-04,  8.7570e-05,  1.5604e-06,\n",
            "        -5.5253e-04])), ('module.encoder_k.layer1.2.bn3.running_mean', tensor([-1.2119e-01, -1.2949e-02,  4.2329e-02, -5.2530e-02,  4.5003e-01,\n",
            "         1.9223e-01,  2.0343e-01,  9.4949e-03,  3.2854e-01, -1.8771e-01,\n",
            "        -5.1610e-02,  4.0156e-01,  1.4085e-01,  1.0992e-01,  7.3352e-02,\n",
            "         3.2070e-01,  1.6758e-01,  3.2940e-01,  3.4595e-02,  1.9024e-01,\n",
            "        -2.5630e-01,  2.7887e-01,  1.3781e-02,  2.3914e-01,  3.4381e-01,\n",
            "        -2.1561e-01, -7.8785e-02,  2.7201e-01,  7.8369e-02, -3.5260e-01,\n",
            "         4.4251e-02, -2.7412e-02,  1.5212e-01, -2.8688e-01,  6.9846e-01,\n",
            "         1.3862e-02,  4.4678e-02, -1.5136e-02,  9.8184e-02,  9.9009e-02,\n",
            "        -2.7614e-01,  3.7065e-01,  2.5124e-01, -3.9872e-01,  2.4374e-01,\n",
            "        -3.7780e-01,  2.4500e-01, -2.7705e-01, -3.0351e-01, -4.6061e-02,\n",
            "         2.8552e-01, -9.6685e-02,  1.1863e-01,  9.8076e-02, -6.5869e-02,\n",
            "        -1.1488e-02,  1.2858e-01,  2.5628e-01,  8.9121e-02, -3.9412e-02,\n",
            "         1.3077e-01, -1.2324e-01, -1.5864e-01, -8.8940e-02, -3.9618e-01,\n",
            "         2.7200e-01, -2.3739e-01, -2.2968e-01, -2.8302e-02, -2.8555e-01,\n",
            "        -8.0779e-01, -2.6092e-01,  4.6704e-02,  2.3638e-01,  3.1658e-01,\n",
            "        -1.0238e-01,  4.5072e-01,  4.9243e-01, -1.2981e-02,  1.5994e-01,\n",
            "        -1.7939e-02, -3.5692e-01, -1.0979e-01,  1.4865e-01,  7.9735e-02,\n",
            "         2.3530e-01, -1.7927e-01, -2.1475e-01,  1.6904e-01,  4.6249e-02,\n",
            "         5.7363e-01, -1.2471e-01, -4.2011e-01, -1.9638e-01,  1.9015e-01,\n",
            "         1.2343e-01,  1.7390e-01, -8.2140e-02,  1.3622e-01,  1.6152e-01,\n",
            "         9.2543e-02,  3.9706e-01,  4.8892e-02,  5.6559e-01,  5.1302e-02,\n",
            "         5.4615e-02, -8.4125e-02,  1.6143e-01, -3.1303e-02, -7.7073e-02,\n",
            "        -5.5373e-02,  2.9639e-01,  3.1620e-01, -2.2067e-02, -3.9327e-03,\n",
            "         4.1692e-02, -2.3279e-01, -1.1967e-01,  2.9618e-01, -4.8242e-01,\n",
            "        -3.0388e-01, -7.5943e-02, -3.8080e-02, -3.4623e-01,  6.9293e-02,\n",
            "        -7.4728e-02, -1.2078e-01,  2.7597e-01,  3.6415e-06,  5.5761e-02,\n",
            "         7.8511e-02,  3.6430e-01, -8.1495e-02,  4.5794e-01, -1.5214e-01,\n",
            "         1.8017e-01,  3.5908e-01,  2.8802e-01, -1.5199e-01, -2.4043e-02,\n",
            "         1.6462e-02, -5.6762e-01, -2.5492e-01, -1.2748e-01,  1.6306e-01,\n",
            "         1.1426e-01, -1.7980e-01,  4.3150e-01, -3.2726e-01, -2.3998e-01,\n",
            "        -6.3191e-02, -3.8413e-01, -1.7799e-01,  1.5145e-01,  2.6103e-01,\n",
            "        -1.7081e-01, -1.8479e-01,  3.5207e-01, -2.3014e-01, -1.4062e-01,\n",
            "         1.8262e-01,  7.2643e-02,  1.8748e-01, -5.9641e-02,  3.3199e-01,\n",
            "        -2.0906e-01, -3.4934e-01, -2.9478e-01, -1.4148e-01, -1.5649e-01,\n",
            "        -4.8817e-01, -5.3519e-02, -4.3431e-02,  4.3155e-01,  1.6774e-03,\n",
            "        -2.1668e-01,  1.2166e-01, -3.4266e-03,  2.7439e-01,  4.2517e-01,\n",
            "         4.1385e-01, -5.5282e-02, -5.0393e-01, -1.0906e-01,  4.5640e-01,\n",
            "        -1.8014e-02,  1.9807e-01,  9.3657e-02, -1.5317e-01, -1.8308e-01,\n",
            "        -3.5480e-01,  1.1500e-01,  6.2574e-01,  1.5228e-01, -4.7174e-02,\n",
            "         3.5668e-01,  3.6434e-01,  4.5399e-02,  6.8462e-03, -1.3351e-01,\n",
            "        -5.6314e-02,  1.6067e-01, -1.4314e-01, -3.7733e-01, -1.7313e-01,\n",
            "         2.9143e-02, -2.0346e-01,  3.7039e-01, -4.6654e-01,  5.4582e-01,\n",
            "         1.2604e-01,  3.0424e-01, -1.8249e-01,  1.6162e-02,  4.5564e-02,\n",
            "        -1.3356e-02, -3.2246e-02, -2.7153e-04, -2.9073e-01, -4.8436e-02,\n",
            "         2.1765e-01,  3.4247e-02, -3.3409e-01,  3.1519e-02, -2.6597e-01,\n",
            "        -3.8083e-02, -3.4257e-01,  5.2412e-01, -1.4470e-02,  1.1177e-01,\n",
            "         4.5035e-02, -3.0063e-01, -2.3453e-01,  1.0362e-01, -1.1574e-01,\n",
            "        -6.1333e-02,  3.3900e-01, -1.1678e-01,  1.8971e-01, -1.8230e-01,\n",
            "         1.1717e-03,  5.4310e-01, -3.7228e-01,  5.4614e-02, -1.7318e-01,\n",
            "         2.4139e-01, -3.7283e-01,  6.6754e-02,  6.9525e-01, -5.3062e-01,\n",
            "         3.8811e-01, -7.4516e-01, -2.9171e-01, -2.9412e-01,  3.7372e-02,\n",
            "         1.8034e-02])), ('module.encoder_k.layer1.2.bn3.running_var', tensor([0.1405, 0.1409, 0.1844, 0.1002, 0.3242, 0.1273, 0.3801, 0.1352, 0.2091,\n",
            "        0.2353, 0.2041, 0.2051, 0.1685, 0.1197, 0.2621, 0.2752, 0.1425, 0.2713,\n",
            "        0.2821, 0.1028, 0.2886, 0.2470, 0.1784, 0.2214, 0.2000, 0.1048, 0.1612,\n",
            "        0.1029, 0.1775, 0.5725, 0.1562, 0.2620, 0.1315, 0.1137, 0.3416, 0.1971,\n",
            "        0.1530, 0.1772, 0.1379, 0.1721, 0.1724, 0.2884, 0.2011, 0.1594, 0.1673,\n",
            "        0.1661, 0.1846, 0.1739, 0.1604, 0.2187, 0.1072, 0.1285, 0.1882, 0.1792,\n",
            "        0.1808, 0.1707, 0.2096, 0.1567, 0.1804, 0.1547, 0.1359, 0.1871, 0.1118,\n",
            "        0.1555, 0.1738, 0.1050, 0.1547, 0.1511, 0.1771, 0.1853, 0.1747, 0.2402,\n",
            "        0.0748, 0.1700, 0.1847, 0.1815, 0.1591, 0.3004, 0.1050, 0.1814, 0.1479,\n",
            "        0.2274, 0.1760, 0.1164, 0.1156, 0.1949, 0.2981, 0.2836, 0.2293, 0.1188,\n",
            "        0.1653, 0.1546, 0.1421, 0.1359, 0.2388, 0.2090, 0.1255, 0.1271, 0.1497,\n",
            "        0.1388, 0.1629, 0.2198, 0.2035, 0.3712, 0.1595, 0.2099, 0.1517, 0.1058,\n",
            "        0.2188, 0.1169, 0.1274, 0.1866, 0.1614, 0.1254, 0.1417, 0.1759, 0.1590,\n",
            "        0.1362, 0.2434, 0.2113, 0.2292, 0.1469, 0.1297, 0.1424, 0.1759, 0.1465,\n",
            "        0.1531, 0.2722, 0.1797, 0.1301, 0.2035, 0.2833, 0.0806, 0.2762, 0.1684,\n",
            "        0.1991, 0.1471, 0.1985, 0.1987, 0.1762, 0.1029, 0.2089, 0.1292, 0.2084,\n",
            "        0.1624, 0.1812, 0.1542, 0.1965, 0.2144, 0.0829, 0.1987, 0.2826, 0.1530,\n",
            "        0.1741, 0.2259, 0.1926, 0.1474, 0.1272, 0.2836, 0.2389, 0.1413, 0.1174,\n",
            "        0.1281, 0.1733, 0.1171, 0.1337, 0.1206, 0.1463, 0.1488, 0.2219, 0.2490,\n",
            "        0.1790, 0.1599, 0.1190, 0.1161, 0.2610, 0.1594, 0.0998, 0.0759, 0.2882,\n",
            "        0.1669, 0.1731, 0.2952, 0.2061, 0.1565, 0.1124, 0.1981, 0.1309, 0.2897,\n",
            "        0.0974, 0.1242, 0.1127, 0.6240, 0.1591, 0.0938, 0.1964, 0.1225, 0.1270,\n",
            "        0.1641, 0.1868, 0.1212, 0.4241, 0.2415, 0.3717, 0.1360, 0.1180, 0.1102,\n",
            "        0.1896, 0.1909, 0.2708, 0.1319, 0.3139, 0.1229, 0.1313, 0.2370, 0.2494,\n",
            "        0.1414, 0.1533, 0.2087, 0.1693, 0.2548, 0.2023, 0.2325, 0.2110, 0.1458,\n",
            "        0.1451, 0.1902, 0.3026, 0.1274, 0.2200, 0.1684, 0.1185, 0.1702, 0.1926,\n",
            "        0.1255, 0.1918, 0.2651, 0.1672, 0.2229, 0.2041, 0.0956, 0.1359, 0.1240,\n",
            "        0.1404, 0.1320, 0.2893, 0.2571, 0.1853, 0.3129, 0.4625, 0.1623, 0.2066,\n",
            "        0.2246, 0.2364, 0.1733, 0.1648])), ('module.encoder_k.layer1.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.0.conv1.weight', tensor([[[[-1.1532e-04]],\n",
            "\n",
            "         [[ 9.1081e-02]],\n",
            "\n",
            "         [[ 5.9365e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9217e-02]],\n",
            "\n",
            "         [[ 6.5054e-02]],\n",
            "\n",
            "         [[ 8.0014e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9541e-01]],\n",
            "\n",
            "         [[ 2.8129e-01]],\n",
            "\n",
            "         [[-2.0197e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.4086e-02]],\n",
            "\n",
            "         [[-1.7781e-01]],\n",
            "\n",
            "         [[ 5.9563e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.5082e-02]],\n",
            "\n",
            "         [[-3.9150e-02]],\n",
            "\n",
            "         [[-7.8170e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0249e-01]],\n",
            "\n",
            "         [[-1.4514e-01]],\n",
            "\n",
            "         [[-1.3612e-01]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.6740e-01]],\n",
            "\n",
            "         [[-8.5804e-02]],\n",
            "\n",
            "         [[ 1.3663e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8288e-02]],\n",
            "\n",
            "         [[ 3.2698e-02]],\n",
            "\n",
            "         [[ 1.3862e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4394e-01]],\n",
            "\n",
            "         [[ 4.1334e-03]],\n",
            "\n",
            "         [[-1.3802e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9179e-01]],\n",
            "\n",
            "         [[-1.4119e-01]],\n",
            "\n",
            "         [[-3.7616e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.1890e-02]],\n",
            "\n",
            "         [[-1.1151e-01]],\n",
            "\n",
            "         [[ 6.4222e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0368e-02]],\n",
            "\n",
            "         [[-8.8796e-02]],\n",
            "\n",
            "         [[ 1.0915e-01]]]])), ('module.encoder_k.layer2.0.bn1.weight', tensor([0.9981, 0.9990, 0.9990, 0.9995, 0.9993, 0.9990, 1.0006, 1.0002, 0.9988,\n",
            "        1.0002, 0.9979, 0.9995, 0.9975, 0.9998, 0.9983, 0.9992, 1.0004, 0.9999,\n",
            "        0.9993, 0.9990, 0.9995, 0.9983, 0.9995, 1.0005, 0.9998, 0.9993, 0.9982,\n",
            "        0.9994, 0.9978, 0.9990, 0.9990, 0.9996, 0.9989, 0.9990, 0.9999, 0.9992,\n",
            "        1.0001, 0.9990, 0.9996, 0.9984, 0.9986, 0.9987, 0.9975, 0.9994, 0.9997,\n",
            "        0.9980, 0.9983, 0.9988, 0.9993, 0.9988, 0.9999, 0.9997, 0.9991, 0.9976,\n",
            "        0.9989, 0.9992, 0.9993, 0.9988, 1.0000, 0.9975, 0.9981, 1.0005, 1.0011,\n",
            "        0.9989, 0.9979, 0.9990, 0.9978, 0.9994, 0.9984, 1.0008, 0.9989, 0.9990,\n",
            "        0.9995, 1.0002, 1.0003, 0.9993, 0.9979, 0.9983, 0.9995, 0.9994, 1.0000,\n",
            "        0.9999, 0.9993, 0.9995, 0.9984, 0.9986, 1.0002, 0.9979, 0.9986, 0.9993,\n",
            "        1.0001, 0.9993, 0.9991, 0.9990, 0.9981, 0.9992, 0.9990, 0.9990, 1.0001,\n",
            "        0.9993, 0.9986, 0.9998, 0.9975, 0.9988, 0.9999, 0.9995, 0.9985, 0.9989,\n",
            "        0.9978, 0.9972, 0.9991, 0.9983, 0.9994, 0.9989, 1.0012, 0.9988, 0.9980,\n",
            "        0.9978, 0.9998, 0.9991, 0.9999, 0.9968, 0.9982, 0.9985, 0.9984, 1.0001,\n",
            "        1.0003, 0.9996])), ('module.encoder_k.layer2.0.bn1.bias', tensor([-4.5387e-04, -6.5111e-05,  4.6228e-04,  1.1391e-03, -8.7894e-05,\n",
            "         5.7800e-04,  3.1898e-04,  1.3081e-04,  4.2687e-04,  4.4437e-04,\n",
            "        -6.3703e-04,  8.0057e-04, -8.2421e-04,  5.1834e-04, -4.0066e-04,\n",
            "         1.2552e-03, -4.1203e-04, -3.5151e-04, -1.8983e-04,  1.4614e-03,\n",
            "         1.1905e-03, -1.2955e-03,  6.8375e-04,  4.9988e-04,  1.7708e-04,\n",
            "        -3.7149e-04, -1.6614e-03,  1.2439e-03,  1.4428e-04,  9.7780e-04,\n",
            "         5.9391e-04,  4.4759e-04,  5.7620e-04, -1.3739e-03,  1.0890e-03,\n",
            "         9.1240e-04,  1.1842e-03, -2.1287e-04,  5.9838e-04, -3.1862e-04,\n",
            "        -5.7780e-04,  4.0333e-04, -9.4587e-04, -7.7148e-04,  2.1920e-04,\n",
            "        -5.5638e-04, -1.0493e-04,  8.1135e-05,  9.6723e-04, -1.1422e-04,\n",
            "         1.1140e-03,  3.3909e-04, -2.2725e-04, -1.0619e-03, -1.1836e-04,\n",
            "         1.4679e-04, -5.9814e-04, -1.0951e-03,  8.0190e-04, -9.4801e-06,\n",
            "        -9.1035e-04,  8.9256e-04,  3.4581e-04, -2.6296e-04,  1.6089e-04,\n",
            "         6.3611e-04, -1.4805e-03,  3.6614e-04, -1.2854e-04,  6.5798e-04,\n",
            "         2.1957e-04,  1.0506e-04,  2.6224e-05,  1.0624e-03,  1.7948e-03,\n",
            "         8.4787e-04, -5.8144e-04,  6.9832e-04,  1.8035e-03, -2.3129e-04,\n",
            "         6.3139e-04,  3.3690e-04, -2.3247e-04,  5.3231e-04, -9.6884e-05,\n",
            "        -3.0893e-05,  7.2670e-04, -2.0634e-04, -6.3211e-04, -3.1192e-04,\n",
            "        -5.5514e-04,  1.7866e-04, -9.0086e-04, -3.7241e-04,  4.0563e-04,\n",
            "        -8.4008e-04, -6.2699e-04, -1.6538e-04,  1.0570e-03,  5.2910e-04,\n",
            "        -3.8921e-04,  2.6798e-04,  2.0132e-04,  6.8824e-04,  6.5353e-04,\n",
            "         9.0838e-04, -3.3111e-04,  3.9442e-05, -1.9018e-04, -1.6397e-03,\n",
            "         1.0460e-03, -4.9188e-04,  7.3636e-04, -1.9830e-03,  3.8366e-04,\n",
            "        -2.8313e-04, -8.1218e-04,  2.5426e-05,  5.3097e-04, -5.2947e-06,\n",
            "         5.6957e-04, -2.1736e-03, -1.4528e-03, -4.7308e-04, -3.0708e-05,\n",
            "         4.8196e-04,  6.6748e-04,  8.9368e-04])), ('module.encoder_k.layer2.0.bn1.running_mean', tensor([ 0.5386,  2.1314, -0.8859,  1.9044,  2.7636,  0.0848, -5.2277, -0.8717,\n",
            "         2.4128,  1.3501,  1.3715, -2.0272,  1.0449,  5.1872, -2.5441,  0.0272,\n",
            "         1.2143, -1.0258,  2.9085, -0.6401, -1.9844, -5.7268, -5.1657,  1.5394,\n",
            "        -0.0167,  2.1373, -1.6629,  3.6819, -1.8364, -1.3960,  2.8524,  2.3821,\n",
            "        -1.9777,  1.0969,  1.4894, -3.5675,  2.4508, -0.3528,  1.6618, -2.9476,\n",
            "        -1.0377,  0.8434,  1.7331, -3.2556, -1.7014,  0.8792,  1.3812,  1.8902,\n",
            "        -2.0073, -0.5425, -1.7844, -0.7881,  0.0574,  0.7478, -2.1687, -4.3020,\n",
            "        -2.8289,  2.6553, -3.3636,  5.4899,  3.6098,  2.7223,  3.5459,  4.3175,\n",
            "        -0.5967, -0.3816,  3.7552,  0.4724, -1.5560,  1.2998,  1.2931,  1.7573,\n",
            "         1.3782,  0.4905, -0.5817, -0.9358,  2.5107,  2.6349,  1.6692, -1.0326,\n",
            "        -1.7544, -1.6267,  1.3471, -0.4045, -0.9835, -1.6583,  0.9362,  1.4652,\n",
            "        -1.5199,  1.9703, -0.2507, -0.1265,  0.9957, -1.3223,  1.1052, -2.0374,\n",
            "         1.2641,  1.1974,  0.8308, -2.3802, -2.0387, -1.7371, -0.0571,  0.8169,\n",
            "         2.5467, -0.1725, -3.9119,  0.2099,  1.8148,  1.4521, -3.5020, -1.0338,\n",
            "         1.1836, -2.7266,  2.3809, -0.5021,  0.6102, -0.1421, -2.0826, -1.9511,\n",
            "        -3.3518,  1.2980,  1.2194,  2.6979, -1.1224,  0.1118,  0.0879,  2.4938])), ('module.encoder_k.layer2.0.bn1.running_var', tensor([ 6.2760,  5.1932,  4.1064,  5.2593,  7.4697,  6.2140,  5.6691,  4.5416,\n",
            "         5.7158,  7.2814,  6.4113,  4.9360,  5.3596,  7.2754,  6.1085,  3.7717,\n",
            "         7.9715,  4.8297,  4.8798,  5.9123,  4.0314, 11.1280, 13.0985,  9.4058,\n",
            "         3.0993,  3.5217,  5.1495,  5.2718, 10.1557, 10.5446,  4.0042,  7.1406,\n",
            "         4.3057,  8.0182,  4.9555,  9.1899,  7.8881,  5.9420,  6.6911, 10.0193,\n",
            "         4.7287,  5.0117,  3.8779,  5.6461,  3.5221,  5.4250,  3.3895,  6.0385,\n",
            "         3.3074,  4.8741,  8.3312,  3.9397,  3.4219,  4.4284,  4.7456,  5.1671,\n",
            "         3.8190,  5.8122,  7.5053,  6.0239,  8.1819,  5.1989, 10.0979, 11.3046,\n",
            "         5.3415,  3.1853,  7.0909,  4.5059,  4.9891,  7.6804,  3.9843,  6.4808,\n",
            "         4.9215,  8.8146,  6.1614,  4.2979,  7.8087,  5.2139,  3.2979,  5.3372,\n",
            "         3.8093,  9.2485,  8.1261,  4.4333,  4.0806,  4.8246,  4.1655,  4.9500,\n",
            "         5.5718,  6.2176,  6.4413,  4.3589,  4.6265,  5.4838,  4.1138,  3.9178,\n",
            "         7.5204,  6.6401,  5.1727,  3.7762,  5.2446,  4.6795,  5.8077,  3.3443,\n",
            "         8.5762,  6.2639,  5.5874,  7.1059,  4.1680,  5.6024,  9.3876,  4.4760,\n",
            "         4.4857,  7.9153,  6.3784,  4.7684,  7.3531,  7.6565,  4.5933,  3.3442,\n",
            "         6.7502,  5.7568,  4.7729,  4.8778,  4.8985,  5.2217,  2.8803,  7.0675])), ('module.encoder_k.layer2.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.0.conv2.weight', tensor([[[[-8.1397e-02,  2.3223e-02,  6.8851e-02],\n",
            "          [ 4.0279e-03, -2.4842e-02,  5.3125e-02],\n",
            "          [-9.5822e-02,  9.4556e-03, -3.1575e-03]],\n",
            "\n",
            "         [[ 4.1594e-05, -3.4648e-02,  3.3816e-02],\n",
            "          [ 4.1379e-02, -3.9269e-02, -2.2071e-02],\n",
            "          [ 5.3030e-02, -2.0298e-02, -1.7974e-02]],\n",
            "\n",
            "         [[ 2.1890e-02, -2.4642e-02, -4.6205e-02],\n",
            "          [-3.9164e-02,  2.6628e-02, -3.8123e-03],\n",
            "          [ 1.3366e-02, -4.8955e-02,  2.9350e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0230e-02,  6.1561e-03, -1.4782e-02],\n",
            "          [ 2.3001e-02, -6.6551e-02,  3.6473e-02],\n",
            "          [ 6.3455e-03,  5.1916e-02, -8.5644e-02]],\n",
            "\n",
            "         [[-8.1240e-03, -3.6979e-02, -1.2403e-02],\n",
            "          [-2.5428e-02, -4.6943e-02, -3.6320e-02],\n",
            "          [ 1.9475e-02, -3.1132e-03, -6.1108e-02]],\n",
            "\n",
            "         [[-5.1815e-02,  5.0495e-03,  4.3569e-02],\n",
            "          [ 4.2360e-02,  2.8518e-03, -3.2301e-03],\n",
            "          [ 4.3679e-02,  1.6179e-02,  7.8602e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2647e-02, -2.0522e-02,  3.5533e-02],\n",
            "          [ 2.1156e-03,  3.1585e-02,  2.1443e-02],\n",
            "          [ 3.3036e-02,  6.8701e-02,  3.2235e-02]],\n",
            "\n",
            "         [[ 2.3328e-02, -1.1946e-01, -4.0221e-02],\n",
            "          [ 6.7039e-02,  5.4212e-02, -2.5004e-02],\n",
            "          [ 5.1282e-02, -2.7998e-02, -6.1735e-03]],\n",
            "\n",
            "         [[ 4.8215e-02, -2.3126e-02, -2.0640e-02],\n",
            "          [ 6.3783e-02,  6.2033e-02, -5.8243e-03],\n",
            "          [ 9.8903e-03, -3.6593e-02, -2.9086e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6559e-02,  8.5699e-03,  3.4160e-02],\n",
            "          [-4.8111e-02, -3.2917e-02,  4.9220e-02],\n",
            "          [ 5.4799e-02,  1.0628e-01,  8.4229e-03]],\n",
            "\n",
            "         [[-2.8256e-03, -1.1431e-02, -4.5250e-02],\n",
            "          [ 2.2418e-02, -3.6469e-02,  1.2415e-01],\n",
            "          [ 5.9636e-02,  5.8572e-02, -5.9275e-02]],\n",
            "\n",
            "         [[-4.0635e-02,  4.2008e-03,  2.4783e-02],\n",
            "          [-5.9035e-02, -2.9985e-02,  5.5193e-03],\n",
            "          [ 4.7045e-02,  5.4829e-02,  8.5867e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4454e-02,  8.5737e-03,  6.3537e-02],\n",
            "          [-5.2721e-02, -1.1211e-02, -2.6201e-02],\n",
            "          [ 1.5074e-02,  9.9851e-03,  3.9015e-02]],\n",
            "\n",
            "         [[-8.0264e-04, -6.7426e-02, -1.6602e-02],\n",
            "          [-1.6415e-02, -3.4744e-02,  6.6333e-02],\n",
            "          [-1.8948e-02, -1.8516e-02,  1.7324e-02]],\n",
            "\n",
            "         [[-5.2826e-02, -5.1209e-02, -6.3181e-03],\n",
            "          [ 4.3787e-02, -2.8304e-02, -6.5425e-02],\n",
            "          [ 1.1328e-01,  2.4784e-02, -2.0826e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2118e-03,  3.4981e-02,  1.6491e-02],\n",
            "          [-6.4199e-03, -4.9807e-02, -1.9136e-02],\n",
            "          [ 1.0972e-02,  2.7202e-02, -2.0383e-02]],\n",
            "\n",
            "         [[ 1.9783e-02, -5.9143e-02,  2.0027e-02],\n",
            "          [-2.6820e-02,  2.7414e-02, -3.4286e-02],\n",
            "          [-5.8268e-02, -2.6449e-02, -4.1209e-02]],\n",
            "\n",
            "         [[ 2.8019e-02, -2.8465e-02, -2.4151e-02],\n",
            "          [ 2.2814e-02, -2.8927e-02,  2.4043e-02],\n",
            "          [-2.1969e-02,  1.9831e-03, -1.0550e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.5227e-02,  3.2066e-02, -4.6485e-02],\n",
            "          [-1.6076e-02,  3.1741e-02,  1.6473e-02],\n",
            "          [ 4.1150e-02, -4.8430e-03, -2.2405e-02]],\n",
            "\n",
            "         [[ 3.5972e-03,  1.0720e-02,  1.5458e-02],\n",
            "          [-3.0666e-02, -3.1574e-02, -5.3201e-03],\n",
            "          [-3.3129e-03, -1.0910e-02,  8.8121e-02]],\n",
            "\n",
            "         [[-2.8951e-02, -5.2793e-02, -9.2277e-03],\n",
            "          [-6.7019e-02,  3.1348e-02,  5.9412e-02],\n",
            "          [ 1.4817e-02, -4.5629e-02, -5.4711e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.6390e-03, -5.5132e-02, -1.4447e-02],\n",
            "          [ 3.4306e-02,  1.5342e-02, -3.8200e-02],\n",
            "          [ 6.0132e-03,  1.6799e-02, -2.5785e-02]],\n",
            "\n",
            "         [[-2.1607e-02, -2.0663e-02,  1.9175e-02],\n",
            "          [-6.0053e-02,  9.3464e-02,  1.9019e-02],\n",
            "          [ 1.0867e-02,  1.0616e-01,  4.6704e-03]],\n",
            "\n",
            "         [[ 1.2554e-02,  3.5051e-02,  5.1709e-02],\n",
            "          [ 3.7413e-02,  6.7220e-02,  3.4678e-02],\n",
            "          [ 1.2121e-02, -4.9755e-02,  4.7429e-02]]],\n",
            "\n",
            "\n",
            "        [[[-6.5203e-02, -1.2537e-02, -6.6159e-04],\n",
            "          [-4.3935e-02,  1.3543e-02, -5.7962e-02],\n",
            "          [-3.1067e-02,  3.2175e-02, -4.1747e-02]],\n",
            "\n",
            "         [[-6.3328e-03, -5.5376e-02, -1.1876e-02],\n",
            "          [-2.0850e-03,  1.6235e-02, -6.0153e-03],\n",
            "          [ 7.3505e-02, -2.2053e-02,  2.7768e-03]],\n",
            "\n",
            "         [[-2.5892e-02,  2.4055e-03,  3.2688e-02],\n",
            "          [-6.4951e-03,  3.5676e-02, -2.9950e-02],\n",
            "          [-3.0342e-02,  2.6209e-02,  5.0338e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5908e-02, -3.5697e-02,  9.4797e-03],\n",
            "          [ 1.5913e-02,  3.0476e-02,  3.6636e-02],\n",
            "          [-6.0223e-02, -1.1370e-02,  1.7056e-02]],\n",
            "\n",
            "         [[ 5.1649e-02,  2.1346e-02, -1.1133e-02],\n",
            "          [-3.9388e-03, -4.1446e-03,  7.4195e-02],\n",
            "          [-4.6228e-02,  5.3628e-03,  9.5047e-03]],\n",
            "\n",
            "         [[-1.1623e-02,  8.9048e-02, -3.5217e-02],\n",
            "          [ 1.8847e-02,  2.4585e-02, -6.1150e-02],\n",
            "          [ 9.1339e-02,  6.9128e-02, -7.7384e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.6211e-04, -7.3165e-02, -5.5970e-02],\n",
            "          [ 1.2645e-02, -1.8816e-02,  3.9749e-02],\n",
            "          [-6.3697e-02, -3.6023e-03, -1.0465e-01]],\n",
            "\n",
            "         [[-2.6762e-03, -4.0625e-03,  1.6586e-02],\n",
            "          [ 4.2506e-02, -6.1113e-02,  4.0387e-02],\n",
            "          [ 2.1257e-02,  4.5573e-02, -3.0305e-02]],\n",
            "\n",
            "         [[-6.4283e-03, -4.0810e-02, -4.8835e-02],\n",
            "          [-8.2525e-02,  5.1029e-02,  2.3048e-02],\n",
            "          [-2.9121e-02,  2.3344e-02,  8.1801e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6088e-02, -5.7137e-02, -3.5964e-02],\n",
            "          [ 7.5887e-03, -2.8475e-02,  3.3232e-02],\n",
            "          [ 4.4119e-03,  1.0758e-01,  4.5122e-02]],\n",
            "\n",
            "         [[ 3.5319e-02, -6.9629e-03, -6.3430e-02],\n",
            "          [-4.5029e-02, -3.6196e-02,  3.1693e-02],\n",
            "          [-1.4122e-02, -1.2199e-02, -8.5395e-02]],\n",
            "\n",
            "         [[ 4.6075e-02,  2.8979e-02,  2.1167e-02],\n",
            "          [-2.4950e-03,  7.9890e-02, -5.1760e-02],\n",
            "          [-4.9387e-02, -1.2104e-03,  1.8039e-02]]]])), ('module.encoder_k.layer2.0.bn2.weight', tensor([0.9992, 0.9996, 0.9980, 0.9977, 0.9981, 0.9989, 0.9984, 0.9995, 0.9999,\n",
            "        0.9984, 0.9991, 0.9989, 0.9981, 0.9991, 0.9993, 1.0001, 0.9998, 0.9978,\n",
            "        0.9987, 0.9982, 0.9987, 0.9997, 0.9980, 0.9996, 1.0001, 0.9993, 1.0008,\n",
            "        1.0000, 0.9997, 0.9995, 0.9991, 0.9985, 0.9980, 0.9996, 0.9991, 0.9994,\n",
            "        1.0002, 0.9992, 0.9986, 0.9994, 1.0002, 0.9990, 0.9992, 0.9995, 0.9977,\n",
            "        0.9986, 0.9985, 0.9998, 0.9994, 0.9996, 0.9992, 0.9986, 0.9994, 0.9990,\n",
            "        0.9993, 0.9982, 0.9987, 1.0003, 0.9995, 0.9984, 0.9990, 0.9992, 0.9986,\n",
            "        0.9984, 0.9985, 0.9996, 0.9995, 0.9975, 0.9990, 0.9976, 1.0003, 0.9997,\n",
            "        0.9981, 1.0000, 0.9988, 0.9989, 0.9987, 0.9989, 0.9999, 0.9996, 0.9986,\n",
            "        0.9993, 0.9987, 0.9991, 0.9988, 0.9979, 1.0010, 0.9983, 0.9992, 0.9987,\n",
            "        0.9988, 0.9985, 1.0006, 0.9978, 0.9997, 0.9989, 0.9994, 0.9996, 0.9995,\n",
            "        0.9995, 0.9996, 0.9992, 0.9987, 0.9984, 0.9992, 0.9984, 0.9990, 0.9998,\n",
            "        0.9984, 0.9997, 0.9996, 1.0002, 0.9992, 0.9986, 0.9990, 0.9991, 0.9993,\n",
            "        0.9988, 0.9984, 1.0001, 0.9985, 0.9984, 0.9985, 1.0004, 0.9989, 0.9997,\n",
            "        1.0004, 0.9980])), ('module.encoder_k.layer2.0.bn2.bias', tensor([ 1.2363e-03,  5.6066e-04, -6.7046e-04, -9.0854e-04, -1.7567e-04,\n",
            "        -1.0510e-03, -2.0180e-05, -1.1223e-04,  1.2155e-04, -6.4316e-04,\n",
            "         1.0615e-03,  2.1344e-04,  7.9490e-04,  5.4427e-05, -2.9973e-04,\n",
            "        -1.0780e-04, -1.2706e-04, -7.0970e-04, -2.6880e-04, -4.5206e-04,\n",
            "         2.4669e-04,  4.0216e-04, -1.1360e-03, -5.6643e-04,  6.0599e-04,\n",
            "        -3.7066e-04,  1.0647e-03,  4.8854e-04,  5.2509e-04,  7.0244e-04,\n",
            "        -1.3974e-05, -9.1641e-04, -2.3646e-04,  9.9808e-04,  3.3045e-04,\n",
            "         3.0568e-06,  1.7192e-03, -1.6667e-04, -3.6256e-04,  5.0253e-04,\n",
            "         4.2448e-04,  8.0274e-04,  1.0761e-03,  7.4503e-04, -1.3660e-03,\n",
            "        -7.4264e-04, -1.0939e-04,  2.3982e-04,  3.3647e-04, -6.9505e-04,\n",
            "         3.7744e-04,  3.7839e-04,  8.6773e-04,  8.3956e-04,  5.2589e-04,\n",
            "         3.5535e-04, -1.1882e-03,  9.9558e-04,  9.9702e-04, -9.6702e-04,\n",
            "         2.2180e-04, -8.8684e-04,  2.4848e-04, -4.3243e-04, -4.3275e-04,\n",
            "         1.2650e-04,  1.9552e-04, -8.4638e-04,  1.0327e-03, -1.7004e-03,\n",
            "         1.1182e-03,  1.7438e-04, -2.2189e-04,  1.1913e-03, -1.4624e-04,\n",
            "        -9.1832e-04,  1.6340e-04, -3.3573e-04, -7.6221e-05,  4.3366e-04,\n",
            "         1.8409e-04, -3.0600e-04, -2.0840e-04, -8.7882e-04, -5.7986e-04,\n",
            "        -4.6252e-04,  1.3672e-03, -5.0303e-04, -7.2860e-04, -2.9408e-04,\n",
            "        -1.0200e-03, -3.4288e-04,  7.5465e-04, -6.7741e-04,  8.3725e-04,\n",
            "         2.7026e-04,  5.4817e-04,  6.3617e-04, -8.5700e-05, -3.6876e-05,\n",
            "        -8.2310e-05,  5.6555e-04, -6.6312e-04, -5.0322e-04,  1.6573e-04,\n",
            "        -5.9174e-05, -2.1539e-05,  9.9571e-04, -8.3132e-04,  6.4227e-04,\n",
            "         8.3197e-04,  1.1308e-03,  1.0568e-05, -1.0943e-04,  1.4320e-04,\n",
            "         7.2543e-04, -3.9394e-05, -7.0044e-04, -8.8325e-04,  7.2199e-04,\n",
            "        -4.7694e-04, -5.3959e-04, -1.4966e-04,  6.4578e-04, -1.5179e-04,\n",
            "        -5.6932e-06,  9.5563e-04, -8.7277e-04])), ('module.encoder_k.layer2.0.bn2.running_mean', tensor([-0.5213, -0.4944, -0.2716,  0.7743, -0.3422, -0.5824,  0.0621,  0.3376,\n",
            "         0.6752, -0.2210, -0.0865,  0.3672, -0.2691, -0.2057, -0.5282, -0.2205,\n",
            "         0.3552,  0.3478, -0.4464,  0.0980, -0.1555, -1.1723,  0.7378, -0.5962,\n",
            "        -0.2012,  0.2295, -0.0691, -0.1379, -0.3628, -0.0699, -0.6509,  0.1195,\n",
            "        -0.3698, -0.1989, -0.4600, -1.1536,  0.1109, -0.1457,  0.5467, -1.0246,\n",
            "         0.1778, -0.8739,  0.1768,  0.1974, -0.2840,  0.7860,  0.0648, -0.2573,\n",
            "        -1.0643, -0.4071,  0.7202, -0.0927,  0.3695,  0.1178,  0.0163, -0.5213,\n",
            "         0.0343,  0.1720, -0.3020, -0.7049,  0.7497,  0.2283,  0.0890, -0.0246,\n",
            "        -0.6494, -1.2914,  0.8324, -0.0696,  0.0438, -0.2380, -0.0825,  0.0547,\n",
            "        -0.6496,  0.3562, -0.3067,  0.5592, -0.1214,  0.1666, -0.4239,  0.4136,\n",
            "         0.9486,  0.0849,  0.5252, -0.6121,  0.1576, -0.1621, -0.0422,  0.0017,\n",
            "         1.0716, -0.7105,  0.3247, -0.3226,  0.3949,  0.2125, -0.4920, -0.2441,\n",
            "        -0.8754,  0.8551,  0.4408, -0.1564, -0.3162,  0.4703,  0.3110, -0.3150,\n",
            "        -0.3668,  0.8179, -0.9855, -0.6096,  0.4684, -0.5829,  0.0612, -0.2574,\n",
            "         0.5002,  1.1457,  1.3069,  0.1985, -0.2370, -0.2526,  0.6747, -0.0297,\n",
            "         0.1130, -0.0305,  0.7902,  0.9609, -0.3285, -0.0578,  0.3015,  0.5378])), ('module.encoder_k.layer2.0.bn2.running_var', tensor([0.6946, 0.6418, 0.6641, 0.8254, 0.4932, 0.6381, 0.6474, 0.6356, 1.2220,\n",
            "        1.1046, 0.8233, 0.9733, 0.8809, 0.5620, 0.9668, 0.7031, 1.9219, 0.5778,\n",
            "        0.5539, 0.5862, 0.5804, 2.0747, 0.6398, 0.7166, 0.5792, 0.6861, 0.6517,\n",
            "        0.4717, 0.4335, 0.5717, 0.4550, 0.8237, 1.0168, 0.5057, 0.8151, 0.8721,\n",
            "        0.8868, 0.6635, 0.6050, 1.8166, 0.7545, 0.8931, 0.6226, 0.8753, 0.7312,\n",
            "        0.8773, 0.4788, 0.6034, 2.2173, 0.9190, 1.2398, 0.5810, 0.9111, 0.4711,\n",
            "        0.6219, 0.4865, 0.6744, 0.7293, 0.7484, 0.8381, 0.9321, 0.9195, 0.5863,\n",
            "        0.7123, 0.5380, 2.4382, 0.6671, 0.6997, 0.6735, 0.6001, 0.8209, 0.5764,\n",
            "        0.5464, 0.6489, 0.6077, 0.6325, 1.2733, 0.7167, 0.4801, 0.8916, 0.6604,\n",
            "        0.4579, 1.1885, 0.6696, 0.8672, 0.8011, 0.7711, 0.9804, 1.0231, 0.4669,\n",
            "        0.5209, 0.5917, 0.7472, 0.5643, 1.0212, 0.7931, 1.5732, 1.2966, 0.8329,\n",
            "        0.9478, 0.9306, 1.0207, 0.8256, 0.5455, 0.4807, 0.8323, 1.1457, 0.6186,\n",
            "        0.6384, 0.7769, 0.7152, 0.7914, 0.5990, 1.1232, 1.2337, 0.6624, 0.4266,\n",
            "        0.4933, 0.4994, 0.5264, 0.5938, 0.4802, 1.1430, 0.8690, 0.5834, 0.6566,\n",
            "        1.2009, 1.3765])), ('module.encoder_k.layer2.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.0.conv3.weight', tensor([[[[ 0.0275]],\n",
            "\n",
            "         [[-0.0549]],\n",
            "\n",
            "         [[ 0.1078]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0186]],\n",
            "\n",
            "         [[ 0.0090]],\n",
            "\n",
            "         [[-0.0191]]],\n",
            "\n",
            "\n",
            "        [[[-0.0224]],\n",
            "\n",
            "         [[-0.0071]],\n",
            "\n",
            "         [[ 0.1028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0155]],\n",
            "\n",
            "         [[ 0.0348]],\n",
            "\n",
            "         [[ 0.1017]]],\n",
            "\n",
            "\n",
            "        [[[-0.0759]],\n",
            "\n",
            "         [[-0.0110]],\n",
            "\n",
            "         [[ 0.1200]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0931]],\n",
            "\n",
            "         [[-0.0655]],\n",
            "\n",
            "         [[ 0.0232]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1027]],\n",
            "\n",
            "         [[ 0.0222]],\n",
            "\n",
            "         [[ 0.0237]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0635]],\n",
            "\n",
            "         [[ 0.0516]],\n",
            "\n",
            "         [[ 0.0503]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0321]],\n",
            "\n",
            "         [[-0.0516]],\n",
            "\n",
            "         [[-0.0135]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0849]],\n",
            "\n",
            "         [[ 0.1559]],\n",
            "\n",
            "         [[ 0.0281]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0233]],\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[ 0.1082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0544]],\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         [[ 0.0020]]]])), ('module.encoder_k.layer2.0.bn3.weight', tensor([0.9995, 0.9994, 0.9996, 0.9993, 0.9989, 0.9991, 0.9992, 0.9989, 0.9992,\n",
            "        0.9990, 0.9992, 0.9992, 0.9996, 0.9990, 0.9995, 0.9991, 0.9990, 0.9993,\n",
            "        0.9993, 0.9990, 0.9989, 0.9992, 0.9986, 0.9990, 0.9990, 0.9992, 0.9995,\n",
            "        0.9990, 0.9991, 0.9991, 0.9993, 0.9989, 0.9993, 0.9992, 0.9995, 0.9993,\n",
            "        0.9991, 0.9990, 0.9990, 0.9992, 0.9992, 0.9993, 0.9986, 0.9991, 0.9994,\n",
            "        0.9991, 0.9993, 0.9987, 0.9992, 0.9991, 0.9992, 0.9989, 0.9991, 0.9992,\n",
            "        0.9991, 0.9996, 0.9991, 0.9987, 0.9993, 0.9992, 0.9984, 0.9994, 0.9987,\n",
            "        0.9991, 0.9989, 0.9994, 0.9989, 0.9988, 0.9994, 0.9994, 0.9985, 0.9990,\n",
            "        0.9993, 0.9989, 0.9994, 0.9989, 0.9990, 0.9996, 0.9987, 0.9995, 0.9992,\n",
            "        0.9989, 0.9996, 0.9991, 0.9994, 0.9991, 0.9999, 0.9992, 0.9998, 0.9988,\n",
            "        0.9989, 0.9991, 0.9992, 0.9987, 0.9985, 0.9990, 0.9987, 0.9992, 0.9988,\n",
            "        0.9990, 0.9986, 0.9981, 0.9992, 0.9994, 0.9988, 0.9993, 0.9988, 0.9985,\n",
            "        0.9993, 0.9988, 0.9991, 0.9990, 0.9991, 0.9986, 0.9991, 0.9988, 0.9991,\n",
            "        0.9991, 0.9993, 0.9988, 0.9987, 0.9994, 0.9989, 0.9993, 0.9991, 0.9997,\n",
            "        0.9995, 0.9992, 0.9987, 0.9990, 0.9994, 0.9990, 0.9990, 0.9992, 0.9992,\n",
            "        0.9986, 0.9992, 0.9989, 0.9993, 1.0000, 0.9992, 0.9993, 0.9984, 0.9994,\n",
            "        0.9987, 0.9991, 0.9989, 0.9993, 0.9990, 0.9990, 0.9983, 0.9992, 0.9989,\n",
            "        0.9985, 0.9991, 0.9994, 0.9991, 0.9996, 0.9989, 0.9985, 0.9991, 0.9995,\n",
            "        0.9992, 0.9994, 0.9991, 0.9989, 0.9989, 0.9991, 0.9985, 0.9993, 0.9987,\n",
            "        0.9988, 0.9990, 0.9994, 0.9993, 0.9994, 0.9991, 0.9996, 0.9991, 0.9991,\n",
            "        0.9994, 0.9989, 0.9995, 0.9995, 0.9988, 0.9989, 0.9990, 0.9987, 0.9995,\n",
            "        0.9992, 0.9987, 0.9988, 0.9992, 0.9991, 0.9993, 0.9989, 0.9985, 0.9986,\n",
            "        0.9986, 0.9991, 0.9988, 0.9986, 0.9992, 0.9987, 0.9995, 0.9993, 0.9984,\n",
            "        0.9993, 0.9987, 0.9989, 0.9990, 0.9993, 0.9991, 0.9994, 0.9998, 0.9995,\n",
            "        0.9989, 0.9990, 0.9988, 0.9991, 0.9996, 0.9995, 0.9996, 0.9988, 0.9988,\n",
            "        0.9991, 0.9990, 0.9988, 0.9989, 0.9995, 0.9994, 0.9994, 0.9986, 0.9990,\n",
            "        0.9989, 0.9989, 0.9987, 0.9997, 0.9992, 0.9996, 0.9993, 0.9990, 0.9989,\n",
            "        0.9993, 0.9992, 0.9994, 0.9991, 0.9988, 0.9988, 0.9992, 0.9990, 0.9991,\n",
            "        0.9995, 0.9994, 0.9987, 0.9989, 0.9993, 0.9991, 0.9991, 0.9992, 0.9988,\n",
            "        0.9992, 0.9988, 0.9988, 0.9994, 0.9989, 0.9989, 0.9993, 1.0000, 0.9991,\n",
            "        0.9993, 0.9995, 0.9992, 0.9994, 0.9992, 0.9990, 0.9988, 0.9992, 0.9988,\n",
            "        0.9988, 0.9990, 0.9984, 0.9985, 0.9991, 0.9989, 0.9993, 0.9986, 0.9987,\n",
            "        0.9988, 0.9994, 0.9984, 0.9995, 0.9989, 0.9992, 0.9986, 0.9992, 0.9993,\n",
            "        0.9987, 0.9994, 0.9984, 0.9991, 0.9993, 1.0001, 0.9993, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9989, 0.9984, 0.9987, 0.9990, 0.9986, 0.9992, 0.9991,\n",
            "        0.9988, 0.9989, 0.9993, 0.9988, 0.9997, 0.9989, 0.9986, 0.9989, 0.9995,\n",
            "        0.9991, 0.9988, 0.9993, 0.9990, 0.9986, 0.9993, 0.9987, 0.9989, 0.9986,\n",
            "        0.9988, 0.9998, 0.9987, 0.9991, 0.9991, 0.9993, 0.9995, 0.9988, 0.9990,\n",
            "        0.9992, 0.9988, 0.9989, 0.9986, 0.9991, 0.9990, 0.9986, 0.9993, 0.9993,\n",
            "        0.9988, 0.9990, 0.9994, 0.9987, 0.9996, 0.9991, 0.9995, 0.9995, 0.9985,\n",
            "        0.9988, 0.9992, 0.9989, 0.9988, 0.9997, 0.9997, 0.9989, 0.9995, 0.9986,\n",
            "        0.9989, 0.9991, 0.9994, 0.9990, 0.9989, 0.9992, 0.9988, 0.9990, 0.9992,\n",
            "        0.9994, 0.9988, 0.9992, 0.9991, 0.9991, 0.9993, 0.9991, 0.9992, 0.9992,\n",
            "        0.9989, 0.9986, 0.9985, 0.9991, 0.9983, 0.9990, 0.9990, 0.9992, 0.9987,\n",
            "        0.9985, 0.9987, 0.9990, 0.9987, 0.9993, 0.9993, 0.9989, 0.9990, 0.9990,\n",
            "        0.9994, 0.9991, 0.9991, 0.9991, 0.9992, 0.9986, 0.9983, 0.9992, 0.9993,\n",
            "        0.9991, 0.9994, 0.9986, 0.9984, 0.9994, 0.9987, 0.9995, 0.9994, 0.9994,\n",
            "        0.9994, 0.9997, 0.9993, 0.9989, 0.9987, 0.9993, 0.9992, 0.9994, 0.9986,\n",
            "        0.9995, 0.9991, 0.9996, 0.9991, 0.9989, 0.9989, 0.9986, 0.9989, 0.9994,\n",
            "        0.9991, 1.0001, 0.9989, 0.9989, 0.9994, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9989, 0.9993, 0.9987, 0.9995, 0.9993, 0.9984, 0.9992,\n",
            "        0.9997, 0.9990, 0.9987, 0.9987, 0.9991, 0.9992, 0.9989, 0.9983, 0.9986,\n",
            "        0.9988, 0.9989, 0.9986, 0.9994, 0.9994, 0.9992, 0.9988, 0.9987, 0.9992,\n",
            "        0.9988, 0.9986, 0.9992, 0.9995, 0.9993, 0.9992, 0.9990, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9997, 0.9994, 0.9989, 0.9992, 0.9989, 0.9989, 0.9987,\n",
            "        0.9990, 0.9994, 0.9988, 0.9988, 0.9987, 0.9989, 0.9993, 0.9988, 0.9989,\n",
            "        0.9984, 0.9989, 0.9989, 0.9993, 0.9988, 0.9990, 0.9994, 0.9989])), ('module.encoder_k.layer2.0.bn3.bias', tensor([ 1.2415e-04,  1.1416e-05,  6.1311e-04, -2.8327e-04, -2.9144e-05,\n",
            "         9.7328e-05,  1.4811e-04,  5.7856e-05,  5.1448e-04,  2.4658e-04,\n",
            "         4.0801e-04,  3.5806e-05,  2.2731e-04,  2.0703e-04,  1.2907e-04,\n",
            "         4.9898e-05,  5.7348e-04, -2.8312e-04,  9.1265e-05,  5.2232e-04,\n",
            "        -2.2375e-05,  1.3308e-04, -1.0289e-04, -8.8629e-04, -4.2682e-04,\n",
            "         6.2120e-04,  4.4314e-05, -1.2847e-04,  5.1154e-05,  6.0389e-05,\n",
            "         2.4148e-04, -2.5931e-04, -9.6830e-05,  6.3541e-05,  1.3635e-04,\n",
            "         2.7351e-04,  2.3395e-04, -1.4666e-05, -2.9267e-04,  3.2970e-04,\n",
            "        -1.1640e-04,  2.1598e-04, -2.5892e-04, -3.1431e-04,  5.3554e-04,\n",
            "         1.8067e-04, -2.2044e-04,  3.4226e-05, -4.2999e-04, -3.0653e-04,\n",
            "         1.6290e-05, -2.0577e-04,  6.4170e-04,  2.4075e-04, -6.8216e-05,\n",
            "        -4.0454e-04, -1.7309e-04, -2.4039e-04, -6.8933e-05,  5.5128e-05,\n",
            "        -1.0104e-04,  6.6936e-04, -8.4169e-05,  4.1427e-04, -1.7437e-04,\n",
            "        -7.0772e-05,  3.2867e-04, -3.6636e-04,  2.2351e-04,  7.6255e-05,\n",
            "        -1.7099e-04,  3.5639e-04,  3.1265e-04,  3.2165e-04, -1.7258e-04,\n",
            "         1.9345e-04, -6.2624e-04,  4.9982e-04,  5.7485e-05,  1.6385e-04,\n",
            "         2.0402e-04,  3.6069e-05, -4.2438e-04,  1.9925e-04,  2.1502e-04,\n",
            "        -9.8239e-05,  7.5384e-04, -5.0607e-04,  3.7941e-04, -2.4687e-04,\n",
            "         5.0446e-05, -9.0793e-05,  7.1176e-05, -3.9081e-04, -5.7289e-04,\n",
            "        -4.7716e-04,  1.2072e-05, -1.2615e-04, -1.2836e-04, -4.6585e-04,\n",
            "         7.5111e-05, -1.7747e-04, -2.6002e-04,  5.6059e-04,  3.0474e-04,\n",
            "         7.9377e-06, -6.1705e-05, -5.8645e-04, -8.2443e-05, -3.7355e-04,\n",
            "         1.5336e-06, -2.5325e-04,  1.7672e-04, -6.1631e-04,  2.3896e-04,\n",
            "         3.5343e-04,  4.5139e-04, -3.7059e-05,  2.0473e-04, -1.3958e-04,\n",
            "         8.5704e-05,  7.7711e-05,  5.6703e-05,  1.4440e-04, -2.1780e-04,\n",
            "         2.3462e-04,  4.1228e-04, -1.2716e-05, -1.5260e-04,  1.3996e-04,\n",
            "         6.9329e-05, -1.8254e-04,  3.4178e-04,  9.8128e-05,  7.8933e-05,\n",
            "         9.6185e-05,  5.3710e-04, -2.2004e-04, -2.2110e-04,  4.9741e-04,\n",
            "        -3.2234e-04,  3.3551e-05, -3.7238e-04,  1.9070e-04, -6.1269e-04,\n",
            "        -1.6511e-04, -4.8685e-04, -2.0884e-04, -1.3379e-04,  3.1307e-04,\n",
            "        -7.7249e-05,  6.3038e-05, -1.4219e-04,  3.5079e-04,  8.1777e-05,\n",
            "         1.9238e-04,  1.6339e-05,  4.5761e-04,  1.4812e-04, -5.2544e-04,\n",
            "         2.2520e-04,  4.9837e-04,  1.0933e-04,  2.8671e-04, -5.7444e-05,\n",
            "         3.7515e-04,  3.5898e-05,  2.7948e-04, -1.8986e-04, -4.2907e-04,\n",
            "        -2.4913e-05,  1.1443e-04, -7.2307e-04,  1.3245e-04, -6.0921e-06,\n",
            "         2.4864e-04, -3.1212e-04,  6.1181e-04,  1.1427e-04, -9.3010e-05,\n",
            "         8.9605e-05, -7.0531e-05,  3.6321e-04, -4.6080e-05, -1.4850e-04,\n",
            "         3.8131e-04, -2.5167e-04, -3.0700e-04,  1.8727e-04, -3.0101e-04,\n",
            "        -4.8365e-04, -1.7582e-04, -1.0758e-05,  4.4924e-04,  4.8317e-04,\n",
            "        -3.5058e-04, -3.0923e-04, -2.9760e-04,  1.0726e-04,  2.4603e-04,\n",
            "         3.2793e-05,  4.9249e-04, -1.6901e-04, -7.0245e-04, -2.1274e-04,\n",
            "         6.7376e-05, -2.4885e-04,  3.1083e-04, -1.3790e-04, -1.6372e-04,\n",
            "         3.3391e-04, -1.6753e-04, -2.8878e-04,  1.2322e-04,  3.1527e-04,\n",
            "         1.7327e-04, -2.2378e-04,  2.5649e-04, -1.9732e-04,  2.7950e-05,\n",
            "         1.9245e-04,  2.0086e-04,  8.0008e-04,  3.6273e-05, -3.9829e-04,\n",
            "         3.2153e-04,  2.7175e-04,  5.0015e-05, -1.2484e-04,  3.7014e-04,\n",
            "         4.7514e-04,  3.7910e-04, -7.6432e-05,  1.9519e-04, -1.8125e-04,\n",
            "        -1.5294e-04,  2.1036e-05,  4.9002e-04, -1.7030e-05,  2.0915e-04,\n",
            "        -5.2804e-04, -4.6903e-05, -4.3259e-04, -5.2106e-05, -4.6514e-04,\n",
            "        -1.1811e-04, -2.4649e-04,  1.7998e-04, -2.4086e-05, -2.3106e-04,\n",
            "        -4.6177e-04,  3.1373e-04,  1.6188e-04,  1.5570e-04, -7.4327e-04,\n",
            "        -1.8654e-04, -2.2438e-05,  3.3304e-04, -3.5225e-05,  1.3434e-04,\n",
            "        -2.7524e-04,  2.8327e-04,  1.3293e-04, -1.2631e-04,  4.9445e-04,\n",
            "        -3.0725e-04,  1.3085e-04,  5.0241e-04,  3.4980e-04,  2.9930e-04,\n",
            "         6.5445e-04, -7.4614e-05,  1.0863e-04,  5.7680e-05, -2.3136e-04,\n",
            "        -2.1481e-05,  1.4319e-04, -1.2775e-04, -6.4530e-04, -6.6915e-05,\n",
            "        -1.4767e-04, -3.2272e-04, -7.9424e-05, -8.8185e-05, -1.9353e-04,\n",
            "         2.7408e-04, -4.3375e-04, -4.1846e-04,  3.8382e-04,  3.6218e-04,\n",
            "        -3.0813e-04,  3.8102e-04, -6.1553e-05, -1.1594e-04, -3.0546e-04,\n",
            "        -7.5133e-05,  3.7233e-04, -3.9138e-04, -3.2303e-04, -3.0976e-04,\n",
            "         3.1619e-05,  6.4562e-05,  3.4450e-04,  1.6489e-04, -7.6834e-06,\n",
            "         2.2425e-05, -2.8904e-04, -2.6297e-04, -8.4961e-06, -2.1925e-04,\n",
            "        -3.9701e-05,  3.3207e-04, -2.7061e-04,  3.2627e-05,  2.2373e-04,\n",
            "         6.3776e-04, -1.9452e-04,  1.9717e-04, -1.1952e-04, -4.4414e-05,\n",
            "        -7.5057e-05, -5.1755e-04, -9.4944e-05,  8.1293e-06,  1.5344e-04,\n",
            "        -2.1390e-04,  4.4463e-04,  1.1542e-04,  6.1730e-04, -2.0559e-05,\n",
            "        -2.4498e-04,  9.6365e-05, -5.2600e-04, -3.3786e-04,  1.0406e-03,\n",
            "        -3.2709e-04,  7.8333e-05,  8.3210e-05,  1.2734e-04,  4.5478e-04,\n",
            "         5.5354e-07, -6.7015e-07,  2.6020e-04,  1.2541e-04, -2.2791e-05,\n",
            "         2.5046e-05,  4.9726e-04, -1.1449e-04, -4.2316e-04,  7.2103e-05,\n",
            "        -2.4137e-04,  2.6710e-04, -3.6985e-04,  4.2692e-04, -3.0560e-04,\n",
            "         2.3364e-04,  2.6621e-04, -4.2067e-05,  2.8130e-04, -5.8450e-04,\n",
            "         1.8488e-04,  2.7752e-04, -6.3698e-05, -3.5744e-05,  8.0053e-04,\n",
            "         2.7319e-04, -4.9969e-06,  2.0011e-04,  2.1923e-04, -3.4864e-04,\n",
            "         8.5352e-06,  7.2094e-06,  9.2352e-05, -2.0469e-04,  2.3911e-04,\n",
            "        -5.2762e-04,  1.8747e-05, -4.8021e-05,  1.3627e-04,  1.4528e-04,\n",
            "        -1.5379e-04, -4.6435e-06,  7.7782e-06,  7.2019e-04,  3.9728e-04,\n",
            "         4.3431e-04,  4.7211e-04,  2.8127e-04,  1.4733e-04, -2.7895e-04,\n",
            "         1.6366e-04, -4.5877e-05, -1.8018e-04,  1.0239e-05,  6.6984e-05,\n",
            "        -2.8065e-04,  1.9256e-04, -5.8224e-04, -3.9822e-04, -4.4824e-04,\n",
            "        -3.4704e-04,  2.4464e-05,  2.9961e-04, -5.5987e-04, -3.9315e-05,\n",
            "         3.1231e-05, -1.5299e-04,  4.0391e-04, -1.4884e-04,  1.8017e-04,\n",
            "        -2.2419e-04, -2.4618e-04,  5.3776e-04,  2.5630e-04, -1.9081e-04,\n",
            "         3.6652e-04, -4.4598e-04, -2.3429e-04,  1.1982e-04, -1.1419e-04,\n",
            "        -2.9450e-05,  6.7510e-05, -1.0898e-04,  3.6360e-05,  1.7675e-04,\n",
            "         3.9464e-05,  1.8612e-04,  1.0437e-04,  3.4679e-04, -2.0830e-04,\n",
            "         2.5909e-05, -4.3018e-05,  3.0290e-05, -4.8006e-04,  8.0406e-05,\n",
            "        -1.8301e-04, -2.2000e-04, -2.5251e-04, -2.1423e-04,  1.0874e-04,\n",
            "         2.8379e-04, -9.7723e-05,  2.9183e-04, -2.7608e-04, -4.2442e-04,\n",
            "         1.2227e-04, -4.6224e-04,  1.5574e-04,  1.0513e-04, -2.7735e-04,\n",
            "        -4.3762e-06,  2.3889e-04, -2.7088e-04,  1.1767e-04,  6.1608e-05,\n",
            "        -2.3875e-04, -2.5063e-04, -8.7411e-05,  2.6762e-05,  1.8709e-04,\n",
            "         2.6669e-04, -5.5820e-05,  9.0990e-05,  1.2931e-04,  6.8310e-05,\n",
            "         1.6827e-04, -5.7149e-04, -1.1184e-04,  2.7963e-04, -5.3831e-04,\n",
            "        -4.3123e-04,  1.4847e-04, -4.2052e-05, -1.3308e-04, -2.2494e-04,\n",
            "         7.6343e-05, -1.3631e-04, -4.2756e-05, -3.9586e-04, -1.7161e-05,\n",
            "        -1.3310e-04, -2.6424e-04,  3.8975e-04, -3.2559e-04,  1.5926e-04,\n",
            "         6.9561e-05, -1.1939e-05,  3.7265e-05,  3.7495e-04,  4.4486e-05,\n",
            "         2.3450e-04,  4.7455e-04, -1.8759e-04, -2.8185e-05,  9.1871e-07,\n",
            "         3.4696e-04,  1.6608e-04, -1.6487e-04, -2.0377e-04,  5.1502e-04,\n",
            "        -1.7947e-04,  1.3452e-04,  1.4189e-04, -1.8595e-04,  8.6106e-06,\n",
            "        -6.6240e-05,  4.1878e-05, -2.3366e-07, -1.9717e-04, -2.0211e-04,\n",
            "        -6.7047e-04,  3.0836e-05])), ('module.encoder_k.layer2.0.bn3.running_mean', tensor([-2.2881e-01,  7.8437e-03,  1.3132e-01,  5.1949e-02,  9.5152e-03,\n",
            "        -3.3846e-01, -1.7706e-01,  4.4038e-02,  1.5778e-02,  8.6190e-02,\n",
            "         2.9996e-01,  1.8401e-01,  7.2405e-02,  7.5682e-02, -2.0525e-01,\n",
            "         1.6558e-01, -3.9885e-01, -1.2894e-01, -3.9974e-02,  1.2458e-01,\n",
            "        -2.0916e-01, -7.3564e-02, -7.3701e-02,  1.3941e-01, -3.8379e-01,\n",
            "         4.0157e-01,  1.8606e-02,  1.2224e-01, -2.2230e-01,  9.2698e-02,\n",
            "         3.2795e-01, -2.0525e-01,  2.7930e-01, -3.0978e-03,  6.1565e-01,\n",
            "         3.6623e-01,  1.9986e-01,  1.2076e-01,  4.5253e-01, -3.6720e-02,\n",
            "        -2.0587e-01, -3.4655e-01,  1.1486e-01,  7.4441e-02, -6.3781e-02,\n",
            "         3.0875e-01,  2.1879e-03,  3.0375e-01,  2.0522e-01, -7.7528e-02,\n",
            "        -2.0266e-01,  5.6081e-01,  4.5408e-01,  1.5241e-01, -1.1555e-01,\n",
            "         4.4204e-01,  2.6315e-01, -1.3496e-01,  1.0254e-01,  5.0358e-01,\n",
            "        -4.3790e-03, -4.8180e-02, -6.1027e-01,  4.7498e-02, -9.3889e-03,\n",
            "        -9.1083e-02, -1.5455e-02,  8.3469e-02,  1.2261e-01,  1.3349e-01,\n",
            "        -5.9383e-01,  1.0705e-02,  4.8806e-01,  5.6462e-01,  2.9151e-02,\n",
            "        -2.0561e-01,  2.1029e-01, -9.9264e-02,  2.5489e-01, -5.7230e-03,\n",
            "        -2.8903e-02, -9.7388e-02,  1.1894e-01, -4.3031e-01, -4.7046e-01,\n",
            "        -2.0069e-01,  1.0437e-01,  3.5709e-01, -5.1204e-01,  3.0358e-01,\n",
            "        -3.3995e-01, -2.8180e-01,  6.2913e-02, -1.6422e-01,  3.4357e-01,\n",
            "        -3.7973e-02,  1.8602e-01, -3.7034e-01,  4.0380e-01, -2.8442e-01,\n",
            "         2.3523e-01, -9.7803e-02,  3.4060e-01,  2.8082e-01,  5.5476e-01,\n",
            "        -2.0679e-01,  3.7592e-01, -7.3519e-02,  3.8322e-03,  2.0025e-01,\n",
            "         1.8010e-01, -1.8255e-01, -3.1691e-01,  2.2077e-01,  3.5605e-01,\n",
            "        -1.0896e-01, -4.0925e-01, -2.6758e-01,  1.2400e-01,  6.4287e-03,\n",
            "         2.4523e-01,  1.3553e-01,  2.0044e-02, -1.0689e-01, -3.7445e-01,\n",
            "        -5.5859e-03,  2.4239e-01,  2.4450e-01, -1.7180e-01,  1.2960e-01,\n",
            "         6.2577e-01, -4.4271e-01,  1.9904e-01,  2.0029e-01,  1.0989e-01,\n",
            "        -1.0593e-01,  4.0637e-05,  5.2410e-02,  2.5038e-02,  2.5096e-01,\n",
            "        -4.8074e-01,  2.4359e-01,  3.4237e-02, -6.9053e-02,  4.2594e-02,\n",
            "         7.9880e-02, -1.2291e-01, -2.8176e-01,  1.7094e-01,  7.2786e-02,\n",
            "         9.0043e-02, -1.9614e-01, -3.3029e-01,  2.4881e-01,  6.3775e-03,\n",
            "         2.2218e-01, -1.0239e-01,  1.4289e-01,  1.1898e-01,  1.2305e-02,\n",
            "         1.4216e-01, -3.2016e-03,  2.6474e-02, -1.7366e-01, -9.5934e-03,\n",
            "        -7.0470e-03, -3.3709e-01, -4.3186e-01, -6.2346e-02,  2.6292e-01,\n",
            "        -8.9591e-02,  1.2015e-01, -3.1083e-01,  2.6256e-01,  2.8556e-01,\n",
            "         7.6163e-02, -1.1964e-01,  3.8064e-01,  5.2763e-01, -1.8199e-01,\n",
            "         3.7257e-01, -6.4501e-02, -1.6955e-01,  7.1508e-01, -2.7626e-01,\n",
            "         1.5461e-01,  2.8343e-01,  3.1271e-01,  2.1395e-01,  4.1038e-01,\n",
            "        -2.3293e-01,  1.9353e-02,  1.0957e-01,  9.7596e-02, -1.5413e-01,\n",
            "         2.1290e-01,  4.8003e-01, -3.5386e-01,  1.3557e-01, -1.6157e-01,\n",
            "         4.0668e-01,  8.3848e-02,  3.0766e-02, -1.8063e-02,  1.6179e-01,\n",
            "         3.5166e-01,  3.3405e-02,  2.5982e-02,  8.0410e-02,  3.2656e-02,\n",
            "         1.0590e-01,  6.1109e-01, -1.1322e-01,  2.1613e-01,  2.6703e-01,\n",
            "         1.7539e-01,  7.2300e-03,  4.9600e-01, -6.9747e-03,  6.9588e-03,\n",
            "         8.5769e-02,  1.5389e-01,  3.3364e-01, -2.7746e-01, -3.6871e-02,\n",
            "        -2.9621e-01,  3.9540e-01,  4.6808e-01, -6.3269e-02, -6.9759e-02,\n",
            "         1.3394e-01, -2.1356e-01, -4.7034e-01, -6.4179e-01, -1.4035e-01,\n",
            "        -4.1825e-01,  2.3605e-01, -5.8273e-02,  1.3998e-01, -1.7595e-01,\n",
            "        -3.3149e-01,  5.4871e-02,  2.4822e-01,  2.6363e-01, -2.9350e-02,\n",
            "        -4.3304e-01, -5.2860e-02, -2.6346e-01, -4.3302e-01, -1.3686e-03,\n",
            "        -2.6389e-01, -1.4772e-02, -1.4221e-01, -2.2879e-02,  2.4493e-03,\n",
            "         2.3005e-01, -1.6219e-01,  5.0229e-02,  5.9436e-01,  1.1779e-01,\n",
            "         3.0534e-01, -2.9029e-01, -7.5512e-02, -3.8599e-01, -1.3523e-01,\n",
            "         3.8480e-01,  3.0530e-01, -2.4336e-01, -4.8234e-01, -6.0643e-01,\n",
            "         2.8230e-01,  1.8010e-01,  2.2442e-01, -4.6141e-01, -3.4758e-01,\n",
            "         1.7929e-01,  4.4022e-02, -4.7263e-02,  5.9344e-02, -1.8934e-01,\n",
            "        -3.2223e-01, -2.7407e-02, -3.2980e-01,  1.5005e-02, -1.8588e-01,\n",
            "         1.4800e-01, -1.0478e-01, -1.6458e-01,  4.7977e-02,  9.8785e-02,\n",
            "        -2.3402e-01, -1.9897e-01, -4.9673e-01, -2.8661e-01,  1.0262e-01,\n",
            "         3.1320e-01,  2.5919e-01,  1.1135e-01,  3.2963e-01,  1.9156e-01,\n",
            "        -1.5104e-01,  2.7936e-01, -1.5022e-01, -6.6973e-02,  5.1046e-01,\n",
            "         4.1111e-01,  2.5101e-01, -2.8803e-01, -1.1572e-02,  3.0407e-01,\n",
            "         4.7501e-02, -1.0086e-01, -1.8727e-01,  1.1205e-02, -2.3203e-01,\n",
            "         2.2269e-01,  4.6742e-02,  9.1411e-02,  4.1931e-01,  1.6183e-01,\n",
            "        -5.4430e-01, -1.4914e-01, -4.0831e-01, -7.4902e-02,  6.6520e-01,\n",
            "        -5.8410e-01, -3.8761e-01, -2.3658e-01, -2.2426e-01, -1.1292e-01,\n",
            "         4.0713e-01,  4.8959e-02, -4.1241e-02, -1.8139e-03,  1.8420e-01,\n",
            "         7.8335e-03, -2.6188e-02, -4.1142e-03, -1.6119e-01,  5.2187e-01,\n",
            "        -1.6935e-01, -1.4199e-01, -2.6290e-01,  1.8275e-01, -6.0337e-01,\n",
            "         2.7124e-01, -8.0221e-02,  5.8867e-01, -2.6989e-01, -5.3512e-02,\n",
            "         3.4607e-01, -2.1441e-02,  4.6918e-01, -6.0495e-02,  6.1131e-01,\n",
            "         2.6819e-02, -2.6298e-01, -2.0363e-01, -1.3083e-01,  9.6734e-02,\n",
            "         2.8207e-01, -9.4974e-02,  3.7490e-01, -2.4396e-02,  2.5079e-02,\n",
            "         5.1059e-02, -2.3744e-02, -7.2307e-03,  1.2406e-01,  3.1772e-02,\n",
            "         2.2066e-01, -3.9877e-01, -3.0260e-01, -9.4637e-02, -1.3708e-03,\n",
            "        -4.0940e-01, -3.2687e-01,  1.7757e-01, -2.0404e-01,  5.9166e-02,\n",
            "         1.0106e-01, -1.7678e-01, -4.2603e-01,  1.4693e-01,  3.0999e-01,\n",
            "        -4.7921e-01, -2.2272e-02, -1.8542e-01, -2.1762e-01, -3.2130e-02,\n",
            "         2.6622e-01, -2.4274e-02,  1.1382e-01, -5.1339e-01, -3.5023e-01,\n",
            "         1.9959e-01,  3.1924e-01, -1.6723e-01, -5.7888e-01, -4.1877e-01,\n",
            "         1.1760e-01,  4.3290e-01, -4.6999e-02,  2.1040e-03, -7.7239e-02,\n",
            "         2.7772e-01, -4.6632e-01, -1.5025e-01, -2.6272e-01, -3.2616e-01,\n",
            "        -4.1730e-01,  1.8310e-01,  1.3873e-01,  3.2982e-01, -1.0223e-01,\n",
            "         1.7304e-02, -2.3063e-01, -3.9713e-01, -2.1810e-03, -1.2023e-01,\n",
            "        -1.5321e-01, -9.5055e-04,  2.1300e-01,  3.9517e-01, -1.6446e-01,\n",
            "         1.4710e-01, -4.6707e-01, -4.5628e-02,  9.1015e-03,  3.2122e-01,\n",
            "         2.1239e-01, -3.0067e-01, -3.0165e-01,  3.2406e-01, -3.6846e-01,\n",
            "        -2.0721e-01,  2.4435e-01, -2.3268e-01,  2.0592e-01, -8.2838e-03,\n",
            "         3.3004e-01, -4.1702e-01, -4.6190e-01, -2.9614e-01,  1.6581e-01,\n",
            "        -2.5683e-01, -1.8576e-01, -1.6875e-01,  1.7562e-01,  7.4591e-02,\n",
            "         5.0354e-01,  4.9668e-02,  5.1883e-01, -1.5553e-01,  4.8003e-01,\n",
            "        -3.9479e-02,  2.0875e-01, -1.4382e-01, -2.7640e-01, -3.9947e-02,\n",
            "        -3.1356e-01,  2.8056e-02, -2.3871e-01, -8.5808e-02,  7.8550e-02,\n",
            "         2.3990e-01, -2.1932e-01, -1.0707e-01, -1.2475e-01,  1.0682e-01,\n",
            "        -5.3612e-01, -2.9234e-01,  2.5325e-01, -3.0787e-01, -2.1734e-01,\n",
            "        -9.2471e-03,  1.8417e-01,  1.2370e-01, -6.4481e-01, -3.1653e-02,\n",
            "        -2.8132e-01, -4.3147e-01, -5.2673e-01,  2.8285e-01, -2.7534e-01,\n",
            "         1.8794e-01,  2.3314e-01, -2.1577e-01,  1.9024e-02, -7.5456e-01,\n",
            "         1.2919e-01, -1.7614e-01,  1.9402e-01,  2.2450e-01,  2.9581e-01,\n",
            "         2.0057e-02, -1.2138e-01, -1.7369e-01, -7.7952e-02,  1.8517e-01,\n",
            "        -2.6319e-01, -5.7148e-01, -2.7894e-01, -3.4906e-01,  2.5099e-02,\n",
            "         1.4162e-01,  2.8595e-01,  2.2222e-01, -2.6959e-01, -2.2542e-02,\n",
            "        -8.3109e-02,  2.0158e-01])), ('module.encoder_k.layer2.0.bn3.running_var', tensor([0.2148, 0.2366, 0.1311, 0.1227, 0.1877, 0.1617, 0.2119, 0.1417, 0.2519,\n",
            "        0.1746, 0.1701, 0.1411, 0.1263, 0.1884, 0.1563, 0.2020, 0.2799, 0.1397,\n",
            "        0.1955, 0.1561, 0.1207, 0.2061, 0.1569, 0.1272, 0.2825, 0.1869, 0.1632,\n",
            "        0.1861, 0.1556, 0.1484, 0.1611, 0.1561, 0.1341, 0.1752, 0.3260, 0.2500,\n",
            "        0.1924, 0.1327, 0.2096, 0.1347, 0.1742, 0.1775, 0.1083, 0.2130, 0.1469,\n",
            "        0.1501, 0.1973, 0.1421, 0.1192, 0.3110, 0.1333, 0.3263, 0.2052, 0.3660,\n",
            "        0.1615, 0.2935, 0.1943, 0.1619, 0.1460, 0.4109, 0.1476, 0.1460, 0.1699,\n",
            "        0.1381, 0.1524, 0.1345, 0.3462, 0.1870, 0.1680, 0.1550, 0.2721, 0.1708,\n",
            "        0.1746, 0.2869, 0.1626, 0.2726, 0.1478, 0.1500, 0.1925, 0.1578, 0.1294,\n",
            "        0.2055, 0.1612, 0.2226, 0.2385, 0.2930, 0.1524, 0.2390, 0.1995, 0.2163,\n",
            "        0.2198, 0.1475, 0.1772, 0.1246, 0.2345, 0.1223, 0.3057, 0.1408, 0.1800,\n",
            "        0.0890, 0.1110, 0.2137, 0.2451, 0.2382, 0.2002, 0.1938, 0.3145, 0.1887,\n",
            "        0.1866, 0.1494, 0.1838, 0.1711, 0.2225, 0.0869, 0.2189, 0.1304, 0.2885,\n",
            "        0.1967, 0.1680, 0.1215, 0.2078, 0.1481, 0.2136, 0.1339, 0.1061, 0.1542,\n",
            "        0.1407, 0.3317, 0.1449, 0.1370, 0.1489, 0.3875, 0.1800, 0.1850, 0.1718,\n",
            "        0.1739, 0.2065, 0.2314, 0.1542, 0.1659, 0.2194, 0.1375, 0.1086, 0.1377,\n",
            "        0.1353, 0.1584, 0.1639, 0.1193, 0.1516, 0.1351, 0.2465, 0.2009, 0.1596,\n",
            "        0.1468, 0.2707, 0.1391, 0.1664, 0.2194, 0.1185, 0.1011, 0.1802, 0.1448,\n",
            "        0.1633, 0.1368, 0.1072, 0.1422, 0.1647, 0.1833, 0.2095, 0.2519, 0.1522,\n",
            "        0.1233, 0.1700, 0.2937, 0.2437, 0.2081, 0.1329, 0.1592, 0.2472, 0.2305,\n",
            "        0.1921, 0.1473, 0.1478, 0.6676, 0.1739, 0.1527, 0.2164, 0.1527, 0.1095,\n",
            "        0.2157, 0.1875, 0.1224, 0.2376, 0.1543, 0.2476, 0.1361, 0.1796, 0.2033,\n",
            "        0.1513, 0.2436, 0.1461, 0.1608, 0.1455, 0.1808, 0.1121, 0.1513, 0.2866,\n",
            "        0.1302, 0.2475, 0.1878, 0.1248, 0.1636, 0.1027, 0.1850, 0.1481, 0.1430,\n",
            "        0.1837, 0.2116, 0.1793, 0.2648, 0.2594, 0.1818, 0.1325, 0.1434, 0.1493,\n",
            "        0.1136, 0.1159, 0.1587, 0.1147, 0.1066, 0.1716, 0.1941, 0.3720, 0.4966,\n",
            "        0.0949, 0.1384, 0.2155, 0.1474, 0.1766, 0.2075, 0.3984, 0.1614, 0.1682,\n",
            "        0.2170, 0.2539, 0.1537, 0.1472, 0.1328, 0.1599, 0.1582, 0.1350, 0.1429,\n",
            "        0.0749, 0.1237, 0.2481, 0.1333, 0.2436, 0.1107, 0.2199, 0.1864, 0.1321,\n",
            "        0.2045, 0.1881, 0.2805, 0.2513, 0.1800, 0.1468, 0.1445, 0.1625, 0.2494,\n",
            "        0.1277, 0.1722, 0.1019, 0.2390, 0.1162, 0.1765, 0.1114, 0.2023, 0.2144,\n",
            "        0.2309, 0.2251, 0.1248, 0.1857, 0.1267, 0.1319, 0.1074, 0.1537, 0.2423,\n",
            "        0.1463, 0.1488, 0.1296, 0.1412, 0.2430, 0.1979, 0.1685, 0.1575, 0.1711,\n",
            "        0.1137, 0.1186, 0.1189, 0.1353, 0.1624, 0.1277, 0.1592, 0.3217, 0.1448,\n",
            "        0.4823, 0.1756, 0.1351, 0.1886, 0.1161, 0.1408, 0.1440, 0.1924, 0.1214,\n",
            "        0.2643, 0.1418, 0.1524, 0.3853, 0.1742, 0.1889, 0.1510, 0.1638, 0.1407,\n",
            "        0.2836, 0.2122, 0.3379, 0.1633, 0.1650, 0.1137, 0.0977, 0.1718, 0.1856,\n",
            "        0.1307, 0.1313, 0.1707, 0.1198, 0.2206, 0.1498, 0.1715, 0.1067, 0.1468,\n",
            "        0.1238, 0.1363, 0.2163, 0.1648, 0.1099, 0.2378, 0.1081, 0.1574, 0.2903,\n",
            "        0.1400, 0.1247, 0.2196, 0.2890, 0.1836, 0.1165, 0.3714, 0.1696, 0.1080,\n",
            "        0.1697, 0.1619, 0.2292, 0.1345, 0.1926, 0.1144, 0.1094, 0.1563, 0.1164,\n",
            "        0.1856, 0.2363, 0.1133, 0.1693, 0.1381, 0.1688, 0.3115, 0.1681, 0.2669,\n",
            "        0.1934, 0.1085, 0.2965, 0.1145, 0.4163, 0.1752, 0.1506, 0.5640, 0.1576,\n",
            "        0.3988, 0.1175, 0.1842, 0.0943, 0.1286, 0.1561, 0.5663, 0.1549, 0.0999,\n",
            "        0.1336, 0.1702, 0.4291, 1.0231, 0.1809, 0.1714, 0.1460, 0.1250, 0.1331,\n",
            "        0.1467, 0.2275, 0.1316, 0.2077, 0.2168, 0.1424, 0.1090, 0.1884, 0.1290,\n",
            "        0.1377, 0.1636, 0.1259, 0.1756, 0.1308, 0.2018, 0.2055, 0.2038, 0.2246,\n",
            "        0.1439, 0.1840, 0.1454, 0.1648, 0.1608, 0.1304, 0.2157, 0.2247, 0.2272,\n",
            "        0.1637, 0.2558, 0.1488, 0.1738, 0.2171, 0.1661, 0.1447, 0.1431, 0.1285,\n",
            "        0.1264, 0.2517, 0.1488, 0.2947, 0.2405, 0.0945, 0.1690, 0.2080, 0.2252,\n",
            "        0.3184, 0.1543, 0.2046, 0.1151, 0.2087, 0.1836, 0.1615, 0.1340, 0.2480,\n",
            "        0.1226, 0.1315, 0.1521, 0.2670, 0.1386, 0.1393, 0.1451, 0.1268, 0.2436,\n",
            "        0.1302, 0.1269, 0.1742, 0.1688, 0.1488, 0.1578, 0.3118, 0.1284, 0.1474,\n",
            "        0.1737, 0.2019, 0.2197, 0.3261, 0.1881, 0.1581, 0.2015, 0.1105, 0.1683,\n",
            "        0.1573, 0.3192, 0.2059, 0.1547, 0.2331, 0.1665, 0.1427, 0.2533, 0.3894,\n",
            "        0.1419, 0.3071, 0.1203, 0.1915, 0.1542, 0.1684, 0.4215, 0.2088, 0.1770,\n",
            "        0.1182, 0.1365, 0.2053, 0.1879, 0.1430, 0.1532, 0.1503, 0.1428])), ('module.encoder_k.layer2.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.0.downsample.0.weight', tensor([[[[ 0.0352]],\n",
            "\n",
            "         [[-0.1188]],\n",
            "\n",
            "         [[ 0.0241]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221]],\n",
            "\n",
            "         [[-0.0588]],\n",
            "\n",
            "         [[-0.1063]]],\n",
            "\n",
            "\n",
            "        [[[-0.1123]],\n",
            "\n",
            "         [[ 0.0044]],\n",
            "\n",
            "         [[ 0.0104]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0099]],\n",
            "\n",
            "         [[ 0.0349]],\n",
            "\n",
            "         [[ 0.1328]]],\n",
            "\n",
            "\n",
            "        [[[-0.0126]],\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.1170]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0195]],\n",
            "\n",
            "         [[-0.0082]],\n",
            "\n",
            "         [[ 0.0606]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0327]],\n",
            "\n",
            "         [[ 0.0362]],\n",
            "\n",
            "         [[ 0.0186]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0217]],\n",
            "\n",
            "         [[-0.0262]],\n",
            "\n",
            "         [[-0.0565]]],\n",
            "\n",
            "\n",
            "        [[[-0.0542]],\n",
            "\n",
            "         [[-0.0693]],\n",
            "\n",
            "         [[ 0.0500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0395]],\n",
            "\n",
            "         [[ 0.0187]],\n",
            "\n",
            "         [[ 0.1015]]],\n",
            "\n",
            "\n",
            "        [[[-0.0799]],\n",
            "\n",
            "         [[ 0.0882]],\n",
            "\n",
            "         [[ 0.0601]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0539]],\n",
            "\n",
            "         [[ 0.0529]],\n",
            "\n",
            "         [[-0.1176]]]])), ('module.encoder_k.layer2.0.downsample.1.weight', tensor([0.9991, 0.9994, 0.9994, 0.9990, 0.9992, 0.9996, 0.9992, 0.9994, 0.9995,\n",
            "        0.9995, 0.9994, 0.9984, 0.9992, 0.9995, 0.9990, 0.9985, 0.9994, 0.9992,\n",
            "        0.9993, 0.9994, 0.9992, 0.9994, 0.9992, 0.9985, 0.9984, 0.9996, 0.9991,\n",
            "        0.9994, 0.9993, 0.9992, 0.9995, 0.9992, 0.9989, 0.9989, 0.9988, 0.9990,\n",
            "        0.9995, 0.9990, 0.9989, 0.9992, 0.9995, 0.9990, 0.9989, 0.9990, 0.9995,\n",
            "        0.9991, 0.9987, 0.9993, 0.9990, 0.9991, 0.9992, 0.9987, 0.9996, 0.9989,\n",
            "        0.9994, 0.9994, 0.9987, 0.9993, 0.9990, 0.9990, 0.9994, 0.9996, 0.9989,\n",
            "        0.9996, 0.9991, 0.9986, 0.9989, 0.9987, 0.9994, 0.9990, 0.9991, 0.9995,\n",
            "        0.9994, 0.9994, 0.9995, 0.9986, 0.9986, 0.9996, 0.9994, 0.9990, 0.9990,\n",
            "        0.9995, 0.9984, 0.9992, 0.9991, 0.9992, 0.9992, 0.9989, 0.9992, 0.9992,\n",
            "        0.9992, 0.9992, 0.9994, 0.9989, 0.9991, 0.9993, 0.9995, 0.9986, 0.9984,\n",
            "        0.9985, 0.9990, 0.9995, 0.9990, 0.9993, 0.9993, 0.9987, 0.9990, 0.9991,\n",
            "        0.9992, 0.9993, 0.9990, 0.9989, 0.9992, 0.9988, 0.9998, 0.9994, 0.9999,\n",
            "        0.9995, 0.9990, 0.9992, 0.9990, 0.9990, 0.9994, 0.9992, 0.9984, 0.9986,\n",
            "        0.9991, 0.9993, 0.9992, 0.9990, 0.9993, 0.9987, 0.9993, 0.9989, 0.9988,\n",
            "        0.9995, 0.9997, 0.9992, 0.9988, 0.9997, 0.9993, 0.9985, 0.9992, 0.9987,\n",
            "        0.9988, 0.9989, 0.9990, 0.9992, 0.9997, 0.9990, 0.9995, 0.9986, 0.9996,\n",
            "        0.9997, 0.9996, 0.9988, 0.9990, 0.9993, 0.9995, 0.9990, 0.9989, 0.9993,\n",
            "        0.9996, 0.9989, 0.9988, 0.9988, 0.9990, 0.9996, 0.9990, 0.9983, 0.9993,\n",
            "        0.9997, 0.9984, 0.9990, 0.9993, 0.9994, 0.9988, 0.9991, 0.9987, 0.9994,\n",
            "        0.9989, 0.9993, 0.9990, 0.9994, 0.9988, 0.9997, 0.9984, 0.9993, 0.9991,\n",
            "        0.9983, 0.9990, 0.9992, 0.9989, 0.9993, 0.9993, 0.9986, 0.9991, 0.9987,\n",
            "        0.9988, 0.9995, 0.9996, 0.9996, 0.9989, 0.9986, 0.9988, 0.9996, 0.9993,\n",
            "        0.9994, 0.9989, 0.9987, 0.9993, 0.9989, 0.9987, 0.9993, 0.9991, 0.9989,\n",
            "        0.9989, 0.9993, 0.9994, 0.9996, 0.9985, 0.9988, 0.9992, 0.9993, 0.9988,\n",
            "        0.9992, 0.9993, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9997, 0.9994,\n",
            "        0.9989, 0.9989, 0.9995, 0.9988, 0.9990, 0.9986, 0.9986, 0.9995, 0.9990,\n",
            "        0.9989, 0.9985, 0.9985, 0.9995, 0.9995, 0.9992, 0.9994, 0.9991, 0.9992,\n",
            "        0.9995, 0.9988, 0.9988, 0.9990, 0.9990, 0.9997, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9995, 0.9992, 0.9992, 0.9990, 0.9992, 0.9999, 0.9992, 0.9994,\n",
            "        0.9992, 0.9983, 0.9991, 0.9989, 0.9986, 0.9992, 0.9994, 0.9989, 0.9988,\n",
            "        0.9990, 0.9986, 0.9990, 0.9995, 0.9991, 0.9990, 0.9989, 0.9992, 0.9987,\n",
            "        0.9998, 0.9992, 0.9995, 0.9991, 0.9989, 0.9987, 0.9991, 0.9990, 0.9990,\n",
            "        0.9993, 0.9983, 0.9991, 0.9990, 0.9990, 0.9993, 0.9996, 0.9990, 0.9992,\n",
            "        0.9985, 0.9987, 0.9994, 0.9995, 0.9987, 0.9997, 0.9995, 0.9991, 0.9989,\n",
            "        0.9993, 0.9989, 0.9989, 0.9987, 0.9985, 0.9994, 0.9991, 0.9992, 0.9990,\n",
            "        0.9992, 0.9990, 0.9988, 0.9993, 0.9999, 0.9985, 0.9992, 0.9995, 0.9988,\n",
            "        0.9992, 0.9998, 0.9993, 0.9990, 0.9991, 0.9991, 0.9988, 0.9994, 0.9991,\n",
            "        0.9992, 0.9993, 0.9991, 0.9994, 0.9994, 0.9988, 0.9985, 0.9989, 0.9989,\n",
            "        0.9995, 0.9984, 0.9995, 0.9991, 0.9991, 0.9991, 0.9987, 0.9987, 0.9985,\n",
            "        0.9992, 0.9989, 0.9988, 0.9996, 0.9998, 0.9994, 0.9990, 0.9986, 0.9994,\n",
            "        0.9992, 0.9993, 0.9990, 0.9992, 0.9986, 0.9989, 0.9989, 0.9992, 0.9992,\n",
            "        0.9986, 0.9993, 0.9988, 0.9992, 0.9991, 0.9996, 0.9992, 0.9993, 0.9989,\n",
            "        0.9994, 0.9998, 0.9986, 0.9993, 0.9992, 0.9994, 0.9991, 0.9991, 0.9993,\n",
            "        0.9997, 0.9989, 0.9990, 0.9982, 0.9988, 0.9992, 0.9991, 0.9984, 0.9995,\n",
            "        0.9992, 0.9986, 0.9999, 0.9988, 0.9993, 0.9989, 0.9993, 0.9990, 0.9990,\n",
            "        0.9993, 0.9995, 0.9987, 0.9991, 0.9990, 0.9990, 0.9990, 0.9992, 0.9992,\n",
            "        0.9984, 0.9990, 0.9988, 0.9993, 0.9993, 0.9993, 0.9987, 0.9989, 0.9990,\n",
            "        0.9988, 0.9985, 0.9990, 0.9987, 0.9991, 0.9993, 0.9993, 0.9989, 0.9993,\n",
            "        0.9992, 0.9993, 0.9990, 0.9990, 0.9989, 0.9990, 0.9993, 0.9991, 0.9986,\n",
            "        0.9983, 0.9992, 0.9987, 0.9989, 0.9992, 0.9990, 0.9986, 0.9994, 0.9991,\n",
            "        0.9988, 0.9996, 0.9991, 0.9991, 0.9992, 0.9985, 0.9994, 0.9988, 0.9993,\n",
            "        0.9991, 0.9987, 0.9995, 0.9998, 0.9989, 0.9991, 0.9992, 0.9992, 0.9993,\n",
            "        0.9992, 0.9991, 0.9987, 0.9985, 0.9991, 0.9995, 0.9988, 0.9996, 0.9991,\n",
            "        0.9990, 0.9990, 0.9996, 0.9988, 0.9989, 0.9996, 0.9989, 0.9994, 0.9989,\n",
            "        0.9990, 0.9990, 0.9993, 0.9988, 0.9993, 0.9987, 0.9995, 0.9992, 0.9993,\n",
            "        0.9991, 0.9996, 0.9990, 0.9990, 0.9993, 0.9991, 0.9985, 0.9986])), ('module.encoder_k.layer2.0.downsample.1.bias', tensor([ 1.2415e-04,  1.1416e-05,  6.1311e-04, -2.8327e-04, -2.9144e-05,\n",
            "         9.7328e-05,  1.4811e-04,  5.7856e-05,  5.1448e-04,  2.4658e-04,\n",
            "         4.0801e-04,  3.5806e-05,  2.2731e-04,  2.0703e-04,  1.2907e-04,\n",
            "         4.9898e-05,  5.7348e-04, -2.8312e-04,  9.1265e-05,  5.2232e-04,\n",
            "        -2.2375e-05,  1.3308e-04, -1.0289e-04, -8.8629e-04, -4.2682e-04,\n",
            "         6.2120e-04,  4.4314e-05, -1.2847e-04,  5.1154e-05,  6.0389e-05,\n",
            "         2.4148e-04, -2.5931e-04, -9.6830e-05,  6.3541e-05,  1.3635e-04,\n",
            "         2.7351e-04,  2.3395e-04, -1.4666e-05, -2.9267e-04,  3.2970e-04,\n",
            "        -1.1640e-04,  2.1598e-04, -2.5892e-04, -3.1431e-04,  5.3554e-04,\n",
            "         1.8067e-04, -2.2044e-04,  3.4226e-05, -4.2999e-04, -3.0653e-04,\n",
            "         1.6290e-05, -2.0577e-04,  6.4170e-04,  2.4075e-04, -6.8216e-05,\n",
            "        -4.0454e-04, -1.7309e-04, -2.4039e-04, -6.8933e-05,  5.5128e-05,\n",
            "        -1.0104e-04,  6.6936e-04, -8.4169e-05,  4.1427e-04, -1.7437e-04,\n",
            "        -7.0772e-05,  3.2867e-04, -3.6636e-04,  2.2351e-04,  7.6255e-05,\n",
            "        -1.7099e-04,  3.5639e-04,  3.1265e-04,  3.2165e-04, -1.7258e-04,\n",
            "         1.9345e-04, -6.2624e-04,  4.9982e-04,  5.7485e-05,  1.6385e-04,\n",
            "         2.0402e-04,  3.6069e-05, -4.2438e-04,  1.9925e-04,  2.1502e-04,\n",
            "        -9.8239e-05,  7.5384e-04, -5.0607e-04,  3.7941e-04, -2.4687e-04,\n",
            "         5.0446e-05, -9.0793e-05,  7.1176e-05, -3.9081e-04, -5.7289e-04,\n",
            "        -4.7716e-04,  1.2072e-05, -1.2615e-04, -1.2836e-04, -4.6585e-04,\n",
            "         7.5111e-05, -1.7747e-04, -2.6002e-04,  5.6059e-04,  3.0474e-04,\n",
            "         7.9377e-06, -6.1705e-05, -5.8645e-04, -8.2443e-05, -3.7355e-04,\n",
            "         1.5336e-06, -2.5325e-04,  1.7672e-04, -6.1631e-04,  2.3896e-04,\n",
            "         3.5343e-04,  4.5139e-04, -3.7059e-05,  2.0473e-04, -1.3958e-04,\n",
            "         8.5704e-05,  7.7711e-05,  5.6703e-05,  1.4440e-04, -2.1780e-04,\n",
            "         2.3462e-04,  4.1228e-04, -1.2716e-05, -1.5260e-04,  1.3996e-04,\n",
            "         6.9329e-05, -1.8254e-04,  3.4178e-04,  9.8128e-05,  7.8933e-05,\n",
            "         9.6185e-05,  5.3710e-04, -2.2004e-04, -2.2110e-04,  4.9741e-04,\n",
            "        -3.2234e-04,  3.3551e-05, -3.7238e-04,  1.9070e-04, -6.1269e-04,\n",
            "        -1.6511e-04, -4.8685e-04, -2.0884e-04, -1.3379e-04,  3.1307e-04,\n",
            "        -7.7249e-05,  6.3038e-05, -1.4219e-04,  3.5079e-04,  8.1777e-05,\n",
            "         1.9238e-04,  1.6339e-05,  4.5761e-04,  1.4812e-04, -5.2544e-04,\n",
            "         2.2520e-04,  4.9837e-04,  1.0933e-04,  2.8671e-04, -5.7444e-05,\n",
            "         3.7515e-04,  3.5898e-05,  2.7948e-04, -1.8986e-04, -4.2907e-04,\n",
            "        -2.4913e-05,  1.1443e-04, -7.2307e-04,  1.3245e-04, -6.0921e-06,\n",
            "         2.4864e-04, -3.1212e-04,  6.1181e-04,  1.1427e-04, -9.3010e-05,\n",
            "         8.9605e-05, -7.0531e-05,  3.6321e-04, -4.6080e-05, -1.4850e-04,\n",
            "         3.8131e-04, -2.5167e-04, -3.0700e-04,  1.8727e-04, -3.0101e-04,\n",
            "        -4.8365e-04, -1.7582e-04, -1.0758e-05,  4.4924e-04,  4.8317e-04,\n",
            "        -3.5058e-04, -3.0923e-04, -2.9760e-04,  1.0726e-04,  2.4603e-04,\n",
            "         3.2793e-05,  4.9249e-04, -1.6901e-04, -7.0245e-04, -2.1274e-04,\n",
            "         6.7376e-05, -2.4885e-04,  3.1083e-04, -1.3790e-04, -1.6372e-04,\n",
            "         3.3391e-04, -1.6753e-04, -2.8878e-04,  1.2322e-04,  3.1527e-04,\n",
            "         1.7327e-04, -2.2378e-04,  2.5649e-04, -1.9732e-04,  2.7950e-05,\n",
            "         1.9245e-04,  2.0086e-04,  8.0008e-04,  3.6273e-05, -3.9829e-04,\n",
            "         3.2153e-04,  2.7175e-04,  5.0015e-05, -1.2484e-04,  3.7014e-04,\n",
            "         4.7514e-04,  3.7910e-04, -7.6432e-05,  1.9519e-04, -1.8125e-04,\n",
            "        -1.5294e-04,  2.1036e-05,  4.9002e-04, -1.7030e-05,  2.0915e-04,\n",
            "        -5.2804e-04, -4.6903e-05, -4.3259e-04, -5.2106e-05, -4.6514e-04,\n",
            "        -1.1811e-04, -2.4649e-04,  1.7998e-04, -2.4086e-05, -2.3106e-04,\n",
            "        -4.6177e-04,  3.1373e-04,  1.6188e-04,  1.5570e-04, -7.4327e-04,\n",
            "        -1.8654e-04, -2.2438e-05,  3.3304e-04, -3.5225e-05,  1.3434e-04,\n",
            "        -2.7524e-04,  2.8327e-04,  1.3293e-04, -1.2631e-04,  4.9445e-04,\n",
            "        -3.0725e-04,  1.3085e-04,  5.0241e-04,  3.4980e-04,  2.9930e-04,\n",
            "         6.5445e-04, -7.4614e-05,  1.0863e-04,  5.7680e-05, -2.3136e-04,\n",
            "        -2.1481e-05,  1.4319e-04, -1.2775e-04, -6.4530e-04, -6.6915e-05,\n",
            "        -1.4767e-04, -3.2272e-04, -7.9424e-05, -8.8185e-05, -1.9353e-04,\n",
            "         2.7408e-04, -4.3375e-04, -4.1846e-04,  3.8382e-04,  3.6218e-04,\n",
            "        -3.0813e-04,  3.8102e-04, -6.1553e-05, -1.1594e-04, -3.0546e-04,\n",
            "        -7.5133e-05,  3.7233e-04, -3.9138e-04, -3.2303e-04, -3.0976e-04,\n",
            "         3.1619e-05,  6.4562e-05,  3.4450e-04,  1.6489e-04, -7.6834e-06,\n",
            "         2.2425e-05, -2.8904e-04, -2.6297e-04, -8.4961e-06, -2.1925e-04,\n",
            "        -3.9701e-05,  3.3207e-04, -2.7061e-04,  3.2627e-05,  2.2373e-04,\n",
            "         6.3776e-04, -1.9452e-04,  1.9717e-04, -1.1952e-04, -4.4414e-05,\n",
            "        -7.5057e-05, -5.1755e-04, -9.4944e-05,  8.1293e-06,  1.5344e-04,\n",
            "        -2.1390e-04,  4.4463e-04,  1.1542e-04,  6.1730e-04, -2.0559e-05,\n",
            "        -2.4498e-04,  9.6365e-05, -5.2600e-04, -3.3786e-04,  1.0406e-03,\n",
            "        -3.2709e-04,  7.8333e-05,  8.3210e-05,  1.2734e-04,  4.5478e-04,\n",
            "         5.5354e-07, -6.7015e-07,  2.6020e-04,  1.2541e-04, -2.2791e-05,\n",
            "         2.5046e-05,  4.9726e-04, -1.1449e-04, -4.2316e-04,  7.2103e-05,\n",
            "        -2.4137e-04,  2.6710e-04, -3.6985e-04,  4.2692e-04, -3.0560e-04,\n",
            "         2.3364e-04,  2.6621e-04, -4.2067e-05,  2.8130e-04, -5.8450e-04,\n",
            "         1.8488e-04,  2.7752e-04, -6.3698e-05, -3.5744e-05,  8.0053e-04,\n",
            "         2.7319e-04, -4.9969e-06,  2.0011e-04,  2.1923e-04, -3.4864e-04,\n",
            "         8.5352e-06,  7.2094e-06,  9.2352e-05, -2.0469e-04,  2.3911e-04,\n",
            "        -5.2762e-04,  1.8747e-05, -4.8021e-05,  1.3627e-04,  1.4528e-04,\n",
            "        -1.5379e-04, -4.6435e-06,  7.7782e-06,  7.2019e-04,  3.9728e-04,\n",
            "         4.3431e-04,  4.7211e-04,  2.8127e-04,  1.4733e-04, -2.7895e-04,\n",
            "         1.6366e-04, -4.5877e-05, -1.8018e-04,  1.0239e-05,  6.6984e-05,\n",
            "        -2.8065e-04,  1.9256e-04, -5.8224e-04, -3.9822e-04, -4.4824e-04,\n",
            "        -3.4704e-04,  2.4464e-05,  2.9961e-04, -5.5987e-04, -3.9315e-05,\n",
            "         3.1231e-05, -1.5299e-04,  4.0391e-04, -1.4884e-04,  1.8017e-04,\n",
            "        -2.2419e-04, -2.4618e-04,  5.3776e-04,  2.5630e-04, -1.9081e-04,\n",
            "         3.6652e-04, -4.4598e-04, -2.3429e-04,  1.1982e-04, -1.1419e-04,\n",
            "        -2.9450e-05,  6.7510e-05, -1.0898e-04,  3.6360e-05,  1.7675e-04,\n",
            "         3.9464e-05,  1.8612e-04,  1.0437e-04,  3.4679e-04, -2.0830e-04,\n",
            "         2.5909e-05, -4.3018e-05,  3.0290e-05, -4.8006e-04,  8.0406e-05,\n",
            "        -1.8301e-04, -2.2000e-04, -2.5251e-04, -2.1423e-04,  1.0874e-04,\n",
            "         2.8379e-04, -9.7723e-05,  2.9183e-04, -2.7608e-04, -4.2442e-04,\n",
            "         1.2227e-04, -4.6224e-04,  1.5574e-04,  1.0513e-04, -2.7735e-04,\n",
            "        -4.3762e-06,  2.3889e-04, -2.7088e-04,  1.1767e-04,  6.1608e-05,\n",
            "        -2.3875e-04, -2.5063e-04, -8.7411e-05,  2.6762e-05,  1.8709e-04,\n",
            "         2.6669e-04, -5.5820e-05,  9.0990e-05,  1.2931e-04,  6.8310e-05,\n",
            "         1.6827e-04, -5.7149e-04, -1.1184e-04,  2.7963e-04, -5.3831e-04,\n",
            "        -4.3123e-04,  1.4847e-04, -4.2052e-05, -1.3308e-04, -2.2494e-04,\n",
            "         7.6343e-05, -1.3631e-04, -4.2756e-05, -3.9586e-04, -1.7161e-05,\n",
            "        -1.3310e-04, -2.6424e-04,  3.8975e-04, -3.2559e-04,  1.5926e-04,\n",
            "         6.9561e-05, -1.1939e-05,  3.7265e-05,  3.7495e-04,  4.4486e-05,\n",
            "         2.3450e-04,  4.7455e-04, -1.8759e-04, -2.8185e-05,  9.1871e-07,\n",
            "         3.4696e-04,  1.6608e-04, -1.6487e-04, -2.0377e-04,  5.1502e-04,\n",
            "        -1.7947e-04,  1.3452e-04,  1.4189e-04, -1.8595e-04,  8.6106e-06,\n",
            "        -6.6240e-05,  4.1878e-05, -2.3366e-07, -1.9717e-04, -2.0211e-04,\n",
            "        -6.7047e-04,  3.0836e-05])), ('module.encoder_k.layer2.0.downsample.1.running_mean', tensor([-0.3205, -0.6278, -0.9885, -0.3459,  0.5408, -1.1599,  1.1537,  1.1109,\n",
            "        -1.5025, -0.8112,  0.8636,  0.2889,  1.6635, -1.2781, -0.4618,  1.4031,\n",
            "        -0.4234, -0.0436,  1.1357,  2.3429,  2.6925,  0.6478, -0.4751, -0.3725,\n",
            "        -0.5728, -1.4902, -0.5180,  1.3556, -0.5488, -1.8146, -0.0485, -0.5635,\n",
            "         2.4525,  1.0579, -1.0943,  0.1773,  0.6898,  0.5691, -1.0525, -0.1842,\n",
            "         0.3941, -0.8719, -1.0907, -1.0693,  0.8155,  1.0207, -1.2130,  1.0342,\n",
            "         2.3485, -0.4301,  0.2617, -1.1309, -0.6930, -0.5207, -0.1057,  2.1832,\n",
            "         0.2231, -0.3221, -1.3424,  1.4737,  0.2326, -0.0981,  0.0795, -0.6891,\n",
            "         0.8549,  0.5792, -0.3088, -0.4187,  1.1252, -0.6653, -0.6792,  1.1226,\n",
            "         1.0321,  0.0201, -0.5980, -0.2074, -1.2396,  0.0931,  0.1816, -0.7772,\n",
            "        -1.1942,  0.8102,  0.6769, -1.0538, -0.6248, -0.4445,  1.0494,  0.4990,\n",
            "        -0.0347, -1.6091,  0.1680, -0.7448, -0.5215, -1.4402,  0.1713,  0.4043,\n",
            "        -1.2311,  1.4384,  1.1078,  0.9302,  1.0455,  0.0985,  0.0147, -0.6124,\n",
            "         1.5971,  0.8973, -0.1881, -0.1127, -0.4152,  1.0190,  1.5017, -0.4507,\n",
            "         0.6829,  0.1515, -0.1291, -0.9434,  0.0963, -1.6997, -0.1640, -0.3871,\n",
            "         0.5899, -0.8239,  0.3882, -0.7421, -0.5232,  1.6460, -1.8619, -0.5234,\n",
            "         0.7184, -0.8060, -1.7545, -0.0180,  0.6713, -1.3903, -0.2328,  0.2203,\n",
            "         0.7075,  0.5805, -0.9049,  0.5643,  0.5318, -0.3264, -0.7518,  0.0149,\n",
            "         0.2403,  0.4074, -0.6918, -0.3512,  0.5500,  0.9815,  0.1047,  0.0467,\n",
            "        -1.6524, -0.0690,  0.9478,  1.5180,  0.0561, -1.0626, -0.4738,  0.1750,\n",
            "         0.0229,  0.1240,  0.3625,  0.4692,  0.0975,  1.0486, -0.0311, -1.4775,\n",
            "        -0.2869, -0.6213, -0.7752, -0.7466, -0.8209, -0.8722, -1.0056,  1.2064,\n",
            "        -0.8538, -0.0653,  1.4988, -0.3858, -0.0698, -0.4985, -0.4756,  0.1293,\n",
            "        -1.5749, -0.3626,  0.7565,  0.1332, -0.4305, -0.6749,  0.9761,  0.3965,\n",
            "        -0.2133, -0.4931,  0.3514, -1.4437, -0.1706,  1.3216, -0.3494, -0.3627,\n",
            "        -1.7652, -0.3544, -1.0077, -0.8180, -0.0367,  0.9882,  1.1938,  1.8126,\n",
            "         1.7755,  0.6490,  1.2934, -0.3571,  1.0765, -0.4109,  1.3851, -1.6585,\n",
            "         1.1773,  0.7360, -0.3436, -0.4560,  0.0467,  0.9367, -0.2211, -0.9551,\n",
            "        -1.5310,  0.2183,  0.4967,  2.3241,  0.3376,  1.4511, -1.2477,  1.5973,\n",
            "        -0.6657,  0.1034, -0.4156,  0.5398, -0.0322,  0.3954,  0.1854,  0.5444,\n",
            "         1.9420,  0.7490, -0.1269,  1.1349,  1.2413,  0.3819,  0.6784,  0.3313,\n",
            "         0.7071,  0.2232,  0.4337, -0.0425, -0.5241, -0.5843, -0.6362, -1.1336,\n",
            "        -0.5459,  0.0091, -0.7088, -0.5649, -0.3605, -0.6785,  1.1613,  1.0452,\n",
            "        -0.9147,  0.0412, -0.6610, -0.5077,  0.0619,  0.1141,  0.1476, -0.6028,\n",
            "        -1.6337, -0.0796,  1.4315,  1.9137, -0.4709,  0.7990,  0.3114, -0.0342,\n",
            "         0.3529,  1.1963, -1.5058,  0.2912, -2.0711,  0.2115, -0.3855, -0.8882,\n",
            "         0.7060,  0.0553, -0.2019, -0.2739, -1.7687,  1.7697, -1.1939, -0.1365,\n",
            "        -0.5098,  0.1199, -0.4016, -0.0978, -0.1684, -1.7238,  0.2391, -1.5592,\n",
            "         0.6798,  0.7703,  1.7196,  0.3672, -0.5056, -1.1057,  0.2923, -0.7007,\n",
            "         1.5254, -0.3296,  0.5587, -0.5904, -0.1069,  0.4688, -0.2930,  0.7582,\n",
            "        -0.0631, -0.2599, -0.2416, -1.9072,  1.4506,  0.6150,  1.6824,  0.3019,\n",
            "        -0.3587,  2.1578, -1.8339, -1.2914,  0.4033, -0.1287, -0.6580,  0.6200,\n",
            "        -1.9684, -2.1175,  0.3252, -0.2925, -0.9626, -0.1664,  0.8324,  0.4018,\n",
            "         0.3522,  0.1793,  0.2168, -1.1762,  0.4891, -0.0658,  0.3819,  0.2241,\n",
            "         0.6150, -1.5470,  0.5560, -0.4589, -0.5533,  0.8869,  1.7182, -1.7731,\n",
            "         0.1476,  0.4494, -0.3158,  0.8367,  0.5400,  0.0245,  0.1015, -0.2403,\n",
            "         1.5212, -1.8333, -1.0401,  0.6823,  1.2844,  0.1065,  0.4283, -1.5001,\n",
            "        -0.2022,  0.2062,  0.2084, -0.7125,  0.3194, -0.3382,  0.0718, -0.0886,\n",
            "         0.1050,  0.3045,  1.0236,  2.0717,  0.3987, -1.1472,  0.6240, -0.6331,\n",
            "        -0.9449, -0.8112,  1.1852, -1.1880, -0.0738,  0.7169, -1.3168, -0.3324,\n",
            "        -0.8857,  1.2737,  0.4842,  0.8068, -0.9870, -0.8287, -0.2656, -1.0629,\n",
            "         0.1867,  1.1384,  0.4189, -0.5994, -0.4261,  0.2843,  0.4169,  0.8004,\n",
            "        -0.0551, -0.4361, -0.7154,  0.8359, -0.4925, -0.5454,  1.7273,  0.2140,\n",
            "         1.0562,  1.0495, -0.2250, -0.0162, -0.0662, -0.4939, -0.9905,  0.3581,\n",
            "         0.6853, -1.1386,  0.3074,  0.6583,  0.1455, -0.4866,  0.3149,  0.3158,\n",
            "        -0.5550, -0.1796,  0.7125, -0.4143, -0.4545, -0.2413,  0.6287,  1.1098,\n",
            "        -0.4905, -1.4669,  1.6401, -0.5412, -0.5264, -0.3264,  0.4605,  0.2146,\n",
            "        -1.2739, -0.0378,  0.2861, -1.5304, -0.2818,  0.1877, -0.3431,  2.0440,\n",
            "        -0.7000, -0.2817,  0.5538, -0.6804, -0.4049, -0.5874,  0.3149, -1.7258,\n",
            "         0.7515, -0.4116, -1.1688, -2.1946, -0.5032, -1.6811,  1.0420,  1.0239,\n",
            "        -0.4613,  0.4832,  1.8929, -0.4323, -0.4332, -0.5426, -1.6899, -0.1460,\n",
            "         0.0455,  1.8020,  1.4704, -0.4251,  0.2460,  0.0767,  1.4920,  1.4131,\n",
            "         1.0653,  0.0185,  0.8794, -0.4381,  0.7908, -0.4175, -0.1599,  0.6791,\n",
            "        -0.2741,  0.4403,  1.7200,  0.3254,  1.0477, -0.3548, -0.3094,  0.9014])), ('module.encoder_k.layer2.0.downsample.1.running_var', tensor([1.1481, 1.1844, 1.6126, 1.7434, 1.2594, 2.5985, 2.0453, 1.2761, 2.3659,\n",
            "        0.9166, 1.3754, 2.7579, 1.3967, 1.0802, 1.4086, 1.0230, 1.3022, 1.2319,\n",
            "        0.7251, 1.7752, 8.0471, 1.2297, 1.0526, 1.7934, 1.1621, 1.5470, 1.2124,\n",
            "        1.5504, 1.4045, 2.5014, 1.9268, 1.3750, 2.2507, 1.6791, 1.9378, 1.4459,\n",
            "        1.2766, 1.4351, 0.8929, 1.1865, 0.9515, 1.3626, 3.1614, 1.1798, 1.2271,\n",
            "        1.7313, 1.2420, 1.4146, 1.4469, 1.1757, 1.2838, 1.3438, 2.0439, 1.3222,\n",
            "        1.2322, 2.2267, 0.9237, 1.1375, 1.3003, 1.4791, 1.2772, 0.9157, 1.3565,\n",
            "        3.0484, 1.6155, 1.2801, 1.2049, 1.7608, 1.3679, 1.4350, 1.7596, 1.0534,\n",
            "        1.7787, 1.1079, 1.0184, 1.2042, 2.3913, 1.0341, 1.2609, 0.9357, 2.2064,\n",
            "        1.3920, 1.3439, 0.7926, 0.7840, 0.8277, 1.0960, 1.0426, 1.0618, 2.4428,\n",
            "        2.5095, 1.1736, 1.4613, 1.7170, 1.5854, 0.9292, 2.4619, 2.2338, 1.2279,\n",
            "        1.1820, 0.7718, 0.9969, 0.9956, 1.0354, 1.0623, 1.1079, 2.5043, 1.4494,\n",
            "        1.0825, 1.4943, 0.8741, 1.5253, 1.0665, 1.6574, 1.2627, 1.2867, 3.1989,\n",
            "        3.5292, 1.8463, 1.4308, 1.1629, 2.4937, 0.9834, 0.8729, 0.8425, 3.3899,\n",
            "        1.6423, 1.9772, 0.8470, 1.3132, 1.0661, 1.1197, 1.2158, 2.9675, 2.1243,\n",
            "        1.0730, 1.1599, 2.0653, 1.3164, 1.3669, 0.9920, 1.1048, 1.0145, 0.8192,\n",
            "        1.3901, 1.7614, 2.1064, 1.0193, 2.6005, 0.7806, 1.6344, 1.0471, 0.8524,\n",
            "        1.8131, 1.3094, 1.7323, 1.3382, 1.6065, 1.6654, 1.1174, 1.0135, 0.7919,\n",
            "        1.9981, 1.0000, 0.9681, 2.3276, 1.3342, 1.5969, 1.7491, 1.4923, 0.9023,\n",
            "        1.2616, 1.1847, 1.3097, 1.0836, 1.6057, 2.2230, 1.6669, 1.8335, 1.7279,\n",
            "        1.1268, 1.3090, 1.4834, 1.5222, 1.5664, 1.1288, 2.0194, 1.4340, 1.7584,\n",
            "        1.2369, 1.6448, 1.9924, 1.6139, 1.8358, 1.9355, 1.1603, 2.7072, 1.3856,\n",
            "        1.6961, 1.8226, 1.5073, 1.0682, 1.5242, 1.9114, 0.9173, 1.0256, 1.4903,\n",
            "        2.3132, 2.8409, 0.8209, 1.5909, 0.7860, 0.8741, 1.3216, 2.2034, 1.1123,\n",
            "        1.2610, 1.1045, 1.3138, 1.9862, 1.1597, 1.8846, 0.8881, 0.8862, 1.7176,\n",
            "        0.6030, 3.1756, 1.2473, 1.0209, 1.4777, 0.8628, 4.5053, 0.7671, 0.9856,\n",
            "        1.2050, 1.0057, 1.4033, 1.1212, 1.2408, 0.9776, 1.4731, 1.7828, 0.8823,\n",
            "        1.0611, 1.4725, 1.0135, 2.4971, 1.4869, 1.6110, 1.6036, 1.3290, 2.1139,\n",
            "        1.3070, 1.5925, 1.8225, 0.9127, 1.8100, 1.0743, 2.3587, 0.9639, 1.9333,\n",
            "        1.7801, 2.1262, 1.7849, 2.1522, 1.5223, 1.8504, 1.1935, 1.2157, 1.2840,\n",
            "        1.1792, 1.4824, 2.1739, 1.0967, 2.0581, 1.9651, 1.0225, 1.3664, 0.9506,\n",
            "        1.3367, 1.0699, 1.1177, 0.7597, 0.7692, 2.2112, 1.7289, 0.9078, 1.4125,\n",
            "        1.0592, 1.3989, 1.0492, 1.1733, 2.8500, 2.4718, 1.8201, 1.1894, 1.2585,\n",
            "        0.9698, 1.2424, 1.0698, 1.0291, 2.3147, 1.9495, 1.4187, 2.5385, 0.8698,\n",
            "        1.9332, 1.9774, 1.0993, 1.0721, 1.2034, 1.1116, 1.4567, 0.6463, 1.5541,\n",
            "        1.2820, 1.2695, 1.4417, 1.1147, 2.0973, 0.9828, 0.8836, 1.0340, 2.3630,\n",
            "        1.5091, 1.3216, 2.0796, 1.3698, 1.4031, 1.4397, 2.2322, 2.1050, 1.8211,\n",
            "        1.4483, 2.2235, 1.0655, 1.5828, 2.4818, 1.0363, 1.0997, 1.5187, 1.2094,\n",
            "        1.0594, 0.8885, 0.9463, 1.5355, 1.6427, 0.8397, 1.9383, 1.7579, 1.2585,\n",
            "        1.2036, 1.2624, 2.3437, 0.9256, 1.2587, 1.1016, 1.4957, 1.9770, 3.1673,\n",
            "        1.3025, 0.9959, 0.9327, 1.6320, 1.1693, 1.8356, 1.2846, 1.0459, 1.1097,\n",
            "        3.5077, 1.3556, 2.2363, 1.0314, 1.6267, 1.1051, 1.2391, 1.4113, 1.5425,\n",
            "        1.9855, 1.0588, 2.1111, 1.3448, 2.1940, 2.2139, 1.4512, 1.7317, 1.1953,\n",
            "        1.2848, 1.1892, 0.8726, 0.7652, 1.2699, 1.0482, 1.7991, 1.1033, 1.1792,\n",
            "        1.6263, 0.9568, 1.6604, 1.8650, 1.0902, 1.0512, 1.0958, 1.6326, 1.2630,\n",
            "        1.2337, 0.9841, 1.6114, 1.4865, 1.0073, 0.8210, 2.0319, 1.0836, 1.6136,\n",
            "        2.4950, 2.0274, 1.6794, 1.0294, 1.2449, 1.8849, 0.8333, 1.3835, 1.6368,\n",
            "        0.9842, 3.1799, 1.3646, 1.0811, 1.4655, 1.5302, 1.6726, 1.9243, 1.4434,\n",
            "        0.8108, 1.1799, 0.8447, 0.9641, 1.7623, 1.6792, 3.7226, 2.3990, 1.8511,\n",
            "        1.8527, 1.2139, 1.4609, 0.6922, 0.7637, 1.1214, 2.1639, 1.4709, 1.7518,\n",
            "        1.5318, 1.0660, 1.2571, 1.4864, 1.1182, 1.9115, 1.3259, 1.8718, 1.1873,\n",
            "        1.8512, 0.9491, 1.1922, 0.9280, 2.8501, 1.1139, 0.9602, 1.3567, 1.2274,\n",
            "        2.5348, 1.0960, 1.8712, 1.9573, 1.5489, 1.6223, 1.2203, 2.4354, 1.6069,\n",
            "        1.4859, 1.3732, 1.6309, 1.6366, 0.7130, 1.7367, 1.3327, 1.2626, 3.0530,\n",
            "        1.0683, 1.1316, 1.4530, 1.5842, 1.8928, 0.9847, 1.4843, 1.7245, 1.6517,\n",
            "        1.2316, 0.9951, 1.1597, 1.0628, 1.4864, 1.3280, 1.2226, 2.0579, 1.3836,\n",
            "        0.9320, 1.1738, 1.7898, 1.3278, 0.9963, 1.1629, 1.8515, 1.0451])), ('module.encoder_k.layer2.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.1.conv1.weight', tensor([[[[-0.0608]],\n",
            "\n",
            "         [[-0.0004]],\n",
            "\n",
            "         [[-0.0195]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0496]],\n",
            "\n",
            "         [[-0.2510]],\n",
            "\n",
            "         [[ 0.2002]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0474]],\n",
            "\n",
            "         [[-0.1438]],\n",
            "\n",
            "         [[-0.1138]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2023]],\n",
            "\n",
            "         [[-0.1830]],\n",
            "\n",
            "         [[ 0.1695]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0428]],\n",
            "\n",
            "         [[ 0.0642]],\n",
            "\n",
            "         [[-0.0347]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1122]],\n",
            "\n",
            "         [[ 0.1655]],\n",
            "\n",
            "         [[ 0.0708]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0546]],\n",
            "\n",
            "         [[-0.0759]],\n",
            "\n",
            "         [[-0.0009]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1712]],\n",
            "\n",
            "         [[ 0.1760]],\n",
            "\n",
            "         [[ 0.0655]]],\n",
            "\n",
            "\n",
            "        [[[-0.1922]],\n",
            "\n",
            "         [[-0.0785]],\n",
            "\n",
            "         [[-0.0660]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1236]],\n",
            "\n",
            "         [[ 0.1638]],\n",
            "\n",
            "         [[ 0.0282]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0297]],\n",
            "\n",
            "         [[ 0.0353]],\n",
            "\n",
            "         [[-0.0069]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         [[ 0.0610]],\n",
            "\n",
            "         [[ 0.1592]]]])), ('module.encoder_k.layer2.1.bn1.weight', tensor([0.9991, 0.9993, 0.9987, 0.9980, 0.9994, 0.9990, 0.9988, 1.0000, 0.9982,\n",
            "        0.9994, 1.0004, 0.9985, 0.9990, 0.9989, 0.9998, 0.9983, 0.9994, 1.0003,\n",
            "        1.0003, 0.9990, 0.9990, 0.9992, 0.9987, 0.9984, 1.0000, 0.9987, 0.9992,\n",
            "        0.9998, 1.0004, 0.9991, 0.9991, 0.9993, 0.9994, 0.9992, 0.9996, 0.9979,\n",
            "        0.9994, 0.9991, 0.9988, 0.9990, 0.9989, 0.9988, 1.0001, 0.9995, 0.9985,\n",
            "        0.9995, 0.9996, 1.0001, 0.9986, 0.9986, 0.9998, 0.9990, 1.0002, 0.9988,\n",
            "        0.9992, 0.9990, 0.9995, 0.9983, 0.9998, 1.0004, 0.9991, 0.9990, 0.9989,\n",
            "        0.9988, 0.9999, 0.9993, 0.9984, 0.9985, 0.9992, 0.9992, 0.9984, 0.9984,\n",
            "        0.9988, 0.9991, 0.9986, 0.9997, 0.9982, 0.9982, 0.9994, 0.9992, 0.9985,\n",
            "        0.9986, 0.9980, 0.9985, 0.9982, 1.0001, 0.9989, 0.9990, 0.9991, 0.9994,\n",
            "        0.9989, 0.9999, 0.9998, 0.9988, 0.9990, 0.9987, 0.9985, 0.9991, 0.9999,\n",
            "        0.9990, 0.9980, 0.9985, 0.9994, 0.9988, 0.9986, 0.9997, 0.9985, 0.9988,\n",
            "        0.9993, 0.9993, 0.9987, 0.9978, 0.9985, 1.0006, 0.9989, 0.9989, 0.9987,\n",
            "        1.0006, 0.9987, 0.9989, 0.9997, 0.9990, 0.9995, 0.9987, 0.9987, 0.9991,\n",
            "        0.9988, 0.9985])), ('module.encoder_k.layer2.1.bn1.bias', tensor([ 1.6144e-05, -4.4510e-05, -7.8083e-04, -7.3051e-04,  2.5945e-04,\n",
            "        -1.4813e-04, -3.1430e-04,  7.0670e-04, -6.6798e-04, -4.1769e-04,\n",
            "         5.0534e-04,  7.3122e-05, -6.4339e-07,  2.1465e-04,  7.7949e-04,\n",
            "        -7.2631e-04, -3.5834e-04,  1.4929e-03,  9.8840e-04, -3.7562e-04,\n",
            "         3.3724e-04, -2.9383e-04, -3.6226e-04, -4.5916e-04,  9.4469e-04,\n",
            "        -1.9586e-04,  5.9033e-06,  7.8003e-05,  1.6597e-04, -1.5289e-05,\n",
            "         2.3796e-04,  5.6392e-04,  7.5125e-04, -2.7586e-04, -1.2626e-04,\n",
            "        -3.5642e-04,  1.1860e-03,  1.0415e-04,  1.7913e-04,  3.4818e-04,\n",
            "         7.0395e-04, -1.0023e-03,  4.9244e-04,  5.3169e-04, -7.6153e-04,\n",
            "         5.5555e-04,  6.5348e-04,  1.2267e-04,  4.7728e-04,  3.9136e-04,\n",
            "         7.2843e-04,  7.5638e-04,  4.7602e-04, -6.2380e-04,  4.4394e-04,\n",
            "         9.2561e-06, -9.2956e-05, -1.1622e-03,  3.5517e-04,  7.4740e-04,\n",
            "        -4.2063e-05, -5.1582e-04,  1.3643e-04, -1.6985e-05,  7.3750e-04,\n",
            "        -2.9773e-04, -3.9849e-05, -5.3295e-04,  5.1056e-04,  6.3441e-04,\n",
            "        -7.9316e-04, -8.9114e-04, -4.7439e-04, -9.3900e-04,  1.9734e-04,\n",
            "         2.4542e-04, -1.0361e-04, -1.4629e-03,  3.1836e-04, -1.1728e-04,\n",
            "         7.3885e-05, -6.5160e-04, -6.8701e-04, -2.5953e-04,  1.0742e-05,\n",
            "         5.3709e-04, -5.9234e-04, -1.9043e-04, -4.6627e-05,  5.9392e-04,\n",
            "         1.7213e-04,  8.6795e-04,  1.7508e-04,  1.5642e-04,  8.4241e-05,\n",
            "         3.4570e-04, -1.0033e-03,  4.0038e-04, -8.8304e-05, -2.5377e-04,\n",
            "        -5.2036e-04, -3.5410e-04, -5.7512e-06, -8.1614e-05, -5.9172e-05,\n",
            "        -4.4165e-04, -7.9162e-04,  3.4461e-05,  3.9125e-04,  3.3561e-04,\n",
            "        -3.2599e-04, -1.0897e-03, -7.2583e-04,  7.5405e-04,  1.2120e-04,\n",
            "        -8.3630e-04, -4.5839e-04,  7.9312e-04, -6.4822e-04,  1.8283e-04,\n",
            "         2.9314e-04,  1.6363e-04,  4.8959e-04, -7.5267e-04, -7.5892e-04,\n",
            "        -3.5108e-04,  4.0288e-05, -6.3744e-04])), ('module.encoder_k.layer2.1.bn1.running_mean', tensor([ 9.8403e-01, -1.3264e+00, -2.0864e+00,  2.0505e+00, -1.6782e-04,\n",
            "        -6.7336e-01,  5.5594e-01, -1.1712e+00, -2.5863e+00,  8.4176e-01,\n",
            "         2.8024e-01,  9.8626e-01,  3.2843e-01, -1.6335e+00, -6.6031e-01,\n",
            "        -7.7689e-01, -1.6969e+00,  7.1044e-01, -1.7547e+00, -1.7426e+00,\n",
            "        -1.3195e+00, -1.8001e+00,  1.1811e-01,  5.7226e-01,  1.4925e+00,\n",
            "         1.8804e+00,  6.5555e-01,  1.8332e-02,  8.0876e-01,  7.5732e-01,\n",
            "        -1.6007e+00,  1.6736e+00, -4.6442e-01,  1.2906e+00, -3.1678e-01,\n",
            "         1.1758e+00, -8.1715e-01,  4.2091e-01,  1.0192e+00, -2.0344e+00,\n",
            "         1.3591e+00, -2.4720e+00,  2.0939e+00,  5.1735e-01,  2.2206e+00,\n",
            "        -1.7730e+00,  1.8321e+00,  9.0368e-01, -8.0926e-01, -1.0386e+00,\n",
            "         1.4635e+00,  6.9677e-01,  2.4717e-01, -2.9588e-01, -1.7001e+00,\n",
            "         2.0711e+00,  7.2495e-01, -2.0794e+00,  3.0796e+00, -8.5134e-01,\n",
            "         2.8610e-01,  1.4568e+00,  1.9648e+00, -1.3281e+00,  2.2931e+00,\n",
            "         8.0012e-01, -1.4331e+00, -5.4888e-01,  1.0106e+00,  2.5100e+00,\n",
            "        -2.4216e+00, -1.4260e+00,  2.6145e-01,  1.2007e+00, -3.2406e-01,\n",
            "         2.1068e+00,  1.5378e-01,  1.6563e+00, -2.5868e+00, -1.9392e+00,\n",
            "        -1.2218e+00, -6.7858e-02,  3.8903e-01, -2.1695e+00,  8.8451e-01,\n",
            "        -1.3323e-02,  2.5438e+00,  1.4478e+00, -2.4411e-01,  1.3251e+00,\n",
            "         3.9162e-01,  2.2340e+00, -2.5555e+00,  1.5506e+00,  1.2958e+00,\n",
            "         8.7645e-01, -2.8286e+00, -1.7554e+00,  2.3271e+00,  1.4142e+00,\n",
            "         2.9426e+00, -7.6625e-01, -1.6472e+00,  1.6089e+00,  3.5921e-01,\n",
            "         9.3659e-01,  9.3516e-01,  4.1466e-01,  4.3219e-01,  1.6933e+00,\n",
            "        -3.0951e-01, -1.6048e-01,  1.6045e+00, -8.3943e-01,  1.4626e+00,\n",
            "         8.7590e-01, -1.7747e+00,  7.8792e-01, -2.1589e+00,  8.3118e-01,\n",
            "         2.2160e+00,  1.5627e+00,  1.1799e+00,  8.9613e-02, -1.3673e+00,\n",
            "         3.4298e-01,  1.5352e+00,  1.4407e+00])), ('module.encoder_k.layer2.1.bn1.running_var', tensor([ 5.9388,  3.6601,  8.2774,  4.8710,  6.8389,  3.9121,  5.0162,  4.2908,\n",
            "         8.0695,  8.6992,  7.6572,  4.5732,  7.6375,  4.1642,  5.0877,  5.2131,\n",
            "         5.1085,  4.7489,  4.2006,  8.8179,  4.7973,  4.8587,  4.4518,  4.9229,\n",
            "         4.4727,  9.7619,  6.2139,  4.5144,  4.0898,  5.0269,  4.3564,  4.7322,\n",
            "         4.6565,  4.1507,  6.2667,  4.0657,  4.5413,  3.6131,  6.9426,  4.5954,\n",
            "         4.4013,  6.2254,  8.9988,  4.6373,  6.5207,  5.7977,  4.1662,  4.7495,\n",
            "         7.2586,  5.0326,  5.9140,  5.2048,  5.1466,  5.0189,  6.0761,  4.3005,\n",
            "         5.6007,  6.7709,  9.6931,  7.1650,  3.8251,  8.1205, 12.2231,  5.1161,\n",
            "         7.1800,  5.2812,  4.7376,  5.1402,  4.1432,  9.9851,  8.2378,  6.8048,\n",
            "         6.4670,  5.4432,  6.5117,  7.7047,  3.7881,  7.0810,  7.6995, 10.0789,\n",
            "         5.7980,  7.6459,  5.6913,  6.4078,  5.1703,  5.0338,  6.6251,  4.6917,\n",
            "         6.1697,  4.6757,  9.5409,  5.7858,  7.1627,  4.9043,  5.5665,  7.5394,\n",
            "         4.6183,  5.0352,  7.8615,  7.5382, 12.9876,  7.3187,  8.7110,  4.6912,\n",
            "         4.5549,  5.7828,  3.9698,  3.8553,  4.3982,  5.5045,  4.1303,  6.1215,\n",
            "         5.1646,  4.4788,  9.9465,  7.7798,  7.1920,  8.3781,  4.0048,  5.4397,\n",
            "         4.3334,  6.6988,  5.5441,  5.3194,  3.9700,  3.5472,  5.5775,  7.5859])), ('module.encoder_k.layer2.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.1.conv2.weight', tensor([[[[-1.4426e-02,  7.1078e-02,  7.2232e-03],\n",
            "          [ 1.1013e-01, -5.1361e-02, -6.0730e-02],\n",
            "          [-3.9117e-02, -9.4755e-02,  1.5209e-02]],\n",
            "\n",
            "         [[-2.8975e-02,  4.7870e-02,  1.1947e-02],\n",
            "          [-3.2201e-02, -7.9037e-02,  5.5324e-03],\n",
            "          [ 6.3436e-02,  5.5016e-03, -2.3966e-02]],\n",
            "\n",
            "         [[-3.5953e-02,  7.4077e-03,  3.8281e-02],\n",
            "          [ 1.4777e-02,  7.1158e-02, -1.0057e-01],\n",
            "          [ 4.6945e-02, -4.3437e-03, -3.7082e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3102e-02, -2.1326e-02,  4.2975e-02],\n",
            "          [ 3.8641e-02, -6.4899e-03,  2.9843e-03],\n",
            "          [-5.0173e-02,  2.4051e-02, -5.4743e-02]],\n",
            "\n",
            "         [[ 1.2890e-02, -1.2978e-02, -3.6998e-02],\n",
            "          [ 5.2214e-03,  1.5122e-02,  5.3351e-02],\n",
            "          [-3.3473e-02,  5.3574e-03,  5.3762e-02]],\n",
            "\n",
            "         [[-1.2098e-01,  9.0533e-03, -6.2904e-02],\n",
            "          [ 6.7972e-02,  6.3507e-02, -3.7756e-02],\n",
            "          [ 6.7115e-02, -1.6429e-02,  3.6442e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.5198e-03, -1.4342e-02, -1.0550e-01],\n",
            "          [ 4.2232e-02,  4.9314e-02,  3.6554e-02],\n",
            "          [ 3.9728e-03,  1.0903e-02,  1.7879e-03]],\n",
            "\n",
            "         [[ 1.8985e-02, -9.5916e-02,  2.1380e-02],\n",
            "          [ 6.3914e-02, -2.8152e-02, -2.9750e-02],\n",
            "          [-4.4042e-02, -1.0463e-01,  7.1520e-02]],\n",
            "\n",
            "         [[-2.2863e-02, -9.7789e-03, -1.1410e-01],\n",
            "          [-7.2134e-03, -1.5967e-02, -2.7993e-02],\n",
            "          [-6.4242e-02, -9.0683e-05, -9.9157e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2781e-02, -6.2875e-03, -8.4004e-04],\n",
            "          [ 1.0270e-02,  2.8472e-02,  3.2530e-02],\n",
            "          [ 9.9789e-03,  6.2354e-02, -4.1011e-03]],\n",
            "\n",
            "         [[ 2.5065e-02,  1.5952e-02, -5.8796e-02],\n",
            "          [-6.8536e-03,  9.4138e-02, -1.1603e-02],\n",
            "          [-8.1980e-03, -3.3448e-02,  3.1003e-02]],\n",
            "\n",
            "         [[ 1.6447e-02,  1.9751e-03, -2.1515e-02],\n",
            "          [-2.6232e-02,  3.4795e-02,  9.2301e-02],\n",
            "          [ 1.8284e-02,  7.9201e-02, -6.8573e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.6948e-03,  3.0204e-03,  1.5580e-02],\n",
            "          [ 2.1881e-02, -2.6636e-02, -4.4077e-02],\n",
            "          [ 3.7273e-02,  2.7292e-02,  7.5807e-02]],\n",
            "\n",
            "         [[-7.2702e-03, -1.8701e-02,  3.6639e-02],\n",
            "          [ 2.0795e-02,  2.5844e-02, -1.6716e-02],\n",
            "          [-2.4180e-02,  3.1847e-02,  8.0050e-02]],\n",
            "\n",
            "         [[-2.5145e-02, -2.3232e-03, -3.4546e-02],\n",
            "          [-8.1901e-03, -1.7188e-02,  5.1251e-02],\n",
            "          [-5.9721e-02, -6.3273e-02, -2.3762e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4589e-02, -5.0393e-02, -4.4852e-02],\n",
            "          [ 2.2910e-02, -3.9686e-02,  1.1301e-01],\n",
            "          [ 5.3014e-02,  2.4171e-02,  2.0488e-05]],\n",
            "\n",
            "         [[-3.2561e-02, -8.3705e-02, -1.8151e-02],\n",
            "          [-6.4661e-02, -4.7916e-03, -1.0700e-02],\n",
            "          [ 1.0129e-02, -3.2841e-02, -2.6401e-02]],\n",
            "\n",
            "         [[ 1.1227e-02, -8.3413e-03,  5.8335e-03],\n",
            "          [-2.0505e-02,  6.8730e-03,  1.0044e-02],\n",
            "          [-1.6635e-02, -2.3719e-02,  7.7384e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3304e-02, -5.4729e-02,  4.1140e-02],\n",
            "          [ 1.9075e-02,  4.1267e-02,  4.8495e-02],\n",
            "          [-6.1848e-02,  5.0263e-02, -1.2702e-02]],\n",
            "\n",
            "         [[-3.7490e-02, -3.8938e-02, -9.1843e-02],\n",
            "          [ 2.7509e-02,  5.4944e-02, -2.6914e-02],\n",
            "          [-1.8944e-02,  3.4626e-02,  5.0629e-02]],\n",
            "\n",
            "         [[ 6.9310e-02,  5.2083e-02,  3.6266e-02],\n",
            "          [ 1.6679e-02, -4.9410e-02, -1.8699e-02],\n",
            "          [ 1.6777e-03, -3.2366e-02, -8.4683e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.2908e-02,  4.8011e-02, -2.4326e-02],\n",
            "          [-7.4565e-02, -1.7219e-02, -4.5107e-02],\n",
            "          [ 2.2900e-02, -3.9057e-02, -2.2366e-02]],\n",
            "\n",
            "         [[-3.6718e-02, -1.3023e-02, -2.0146e-02],\n",
            "          [ 5.2348e-03,  4.9156e-02,  4.4493e-02],\n",
            "          [-3.9884e-02,  4.7048e-02, -3.2346e-02]],\n",
            "\n",
            "         [[ 2.2073e-02, -8.3635e-02, -1.2878e-02],\n",
            "          [ 8.5325e-03, -3.7308e-02, -6.7902e-02],\n",
            "          [-9.1129e-02,  1.0188e-02, -2.1437e-02]]],\n",
            "\n",
            "\n",
            "        [[[-5.1487e-02, -1.5312e-02, -2.4208e-02],\n",
            "          [ 4.0247e-02,  3.0459e-02,  6.4766e-02],\n",
            "          [-3.8264e-02,  4.3485e-02,  4.5588e-02]],\n",
            "\n",
            "         [[-2.3061e-02, -6.8898e-02, -1.2286e-02],\n",
            "          [ 1.2815e-02, -9.2237e-03,  2.4565e-02],\n",
            "          [ 7.6982e-02,  2.1474e-02,  2.6943e-02]],\n",
            "\n",
            "         [[ 7.9089e-02,  1.4992e-02, -5.1374e-02],\n",
            "          [ 4.3842e-02, -4.8884e-02,  1.1333e-02],\n",
            "          [-7.7847e-02, -5.4046e-02,  3.0272e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.8123e-04, -1.5536e-02, -9.0375e-03],\n",
            "          [ 5.9327e-02, -2.7763e-02,  3.8561e-02],\n",
            "          [-6.6114e-03,  1.4515e-02, -2.6084e-02]],\n",
            "\n",
            "         [[-6.6003e-02,  5.5592e-02, -1.3719e-02],\n",
            "          [-2.7886e-02, -3.7720e-02, -5.4202e-02],\n",
            "          [ 3.1946e-02, -5.1622e-02, -1.5625e-02]],\n",
            "\n",
            "         [[ 7.3626e-02,  1.5679e-02, -1.3183e-02],\n",
            "          [ 1.4020e-02, -1.1944e-03, -1.0755e-02],\n",
            "          [-2.6683e-02,  1.7730e-02, -3.1929e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1770e-02, -9.2448e-03, -5.7686e-03],\n",
            "          [ 8.3691e-02,  2.9957e-02, -4.6699e-03],\n",
            "          [ 2.9269e-02,  8.3152e-03,  1.4515e-02]],\n",
            "\n",
            "         [[-2.6920e-02, -7.2565e-02,  5.0352e-02],\n",
            "          [ 1.4277e-02, -3.5907e-02, -1.5226e-02],\n",
            "          [-4.6619e-02,  7.4380e-02,  1.3148e-02]],\n",
            "\n",
            "         [[ 1.0313e-01, -2.6401e-03,  2.9990e-02],\n",
            "          [ 9.9629e-03, -5.1211e-02,  6.1635e-02],\n",
            "          [ 2.1752e-02, -6.4119e-02,  4.8777e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1722e-02,  3.6546e-03, -2.1080e-02],\n",
            "          [ 3.5399e-02,  1.1037e-02, -3.8488e-03],\n",
            "          [ 9.0221e-02,  1.6701e-02, -2.9331e-02]],\n",
            "\n",
            "         [[-4.3111e-02, -4.6485e-03, -4.7966e-02],\n",
            "          [ 9.6561e-03,  6.1711e-02,  1.0569e-01],\n",
            "          [-5.2106e-02, -2.8757e-03, -1.7606e-02]],\n",
            "\n",
            "         [[ 5.6164e-04,  6.5602e-02,  1.9461e-02],\n",
            "          [ 3.6161e-02, -3.2352e-02, -5.7425e-02],\n",
            "          [-2.1816e-02,  7.8548e-02, -3.9316e-02]]]])), ('module.encoder_k.layer2.1.bn2.weight', tensor([0.9995, 0.9999, 0.9997, 0.9991, 0.9996, 0.9992, 0.9992, 0.9989, 0.9991,\n",
            "        0.9992, 0.9995, 0.9988, 0.9996, 0.9999, 0.9995, 0.9991, 1.0001, 0.9987,\n",
            "        0.9991, 0.9985, 0.9993, 0.9985, 0.9999, 1.0002, 0.9992, 0.9988, 0.9992,\n",
            "        0.9992, 0.9984, 0.9990, 0.9992, 0.9996, 0.9984, 0.9995, 0.9981, 0.9987,\n",
            "        0.9987, 0.9983, 0.9996, 0.9987, 0.9986, 0.9983, 0.9992, 0.9983, 0.9993,\n",
            "        0.9988, 0.9994, 0.9994, 0.9992, 0.9991, 0.9992, 0.9990, 0.9996, 0.9991,\n",
            "        0.9993, 0.9990, 0.9991, 0.9987, 0.9991, 0.9995, 0.9987, 0.9987, 0.9990,\n",
            "        0.9990, 0.9998, 0.9988, 0.9994, 0.9991, 0.9986, 0.9993, 0.9991, 0.9993,\n",
            "        0.9992, 0.9985, 0.9989, 0.9990, 0.9990, 0.9989, 0.9987, 0.9996, 0.9993,\n",
            "        0.9981, 0.9986, 0.9996, 0.9991, 0.9990, 0.9986, 0.9990, 1.0008, 0.9989,\n",
            "        0.9991, 0.9983, 0.9990, 0.9985, 0.9992, 0.9993, 0.9992, 0.9989, 0.9992,\n",
            "        0.9987, 0.9990, 0.9994, 0.9991, 0.9984, 0.9980, 0.9999, 0.9991, 0.9992,\n",
            "        1.0000, 0.9984, 0.9992, 0.9992, 0.9989, 0.9989, 0.9990, 0.9991, 0.9991,\n",
            "        0.9989, 0.9990, 0.9985, 0.9993, 0.9991, 0.9990, 0.9992, 0.9989, 0.9998,\n",
            "        0.9988, 0.9990])), ('module.encoder_k.layer2.1.bn2.bias', tensor([ 7.5892e-04,  5.1571e-04,  2.9383e-04, -3.6561e-04, -4.0629e-05,\n",
            "        -4.9158e-04, -1.9479e-04,  1.7362e-04,  5.0915e-04, -2.6556e-04,\n",
            "        -1.1608e-04,  2.7707e-04,  1.6705e-04,  9.0992e-04,  6.3491e-04,\n",
            "        -2.7414e-04,  3.3222e-04, -5.0662e-04, -2.6950e-05, -9.2769e-05,\n",
            "        -1.9843e-04, -3.6917e-04,  1.0581e-03,  1.0139e-03,  1.7559e-04,\n",
            "        -1.7548e-04, -3.1615e-07,  5.0346e-04, -8.0956e-04, -1.2283e-04,\n",
            "         7.6881e-04,  1.0544e-03,  2.5349e-04,  3.0643e-04, -4.0028e-04,\n",
            "        -6.2745e-04, -2.2314e-04, -9.4372e-04,  8.4318e-04, -7.0566e-05,\n",
            "        -5.7272e-04, -2.4766e-04, -7.5934e-05, -2.4797e-05,  4.7336e-04,\n",
            "        -8.6721e-04,  9.3824e-05,  8.6515e-05,  6.3588e-04, -1.8153e-04,\n",
            "        -8.4106e-06, -1.0194e-04, -1.9102e-04, -4.1781e-04,  3.9384e-04,\n",
            "         1.6435e-04, -7.7720e-05, -1.4132e-04, -3.7151e-04,  3.5159e-04,\n",
            "        -5.9053e-04, -3.0003e-04, -5.1115e-05, -9.3039e-05, -1.5589e-05,\n",
            "        -1.6692e-05,  4.6156e-04,  2.4724e-04, -3.0468e-04,  3.7776e-04,\n",
            "         1.3811e-04,  2.1931e-04,  6.2762e-04,  5.1015e-05, -4.0277e-04,\n",
            "        -1.5753e-05, -2.6264e-04,  6.8748e-04, -6.1990e-04, -2.3861e-05,\n",
            "        -3.3489e-04, -2.5987e-04, -6.9856e-04,  4.8682e-04, -2.1192e-04,\n",
            "        -3.2823e-04,  6.3312e-04,  3.3383e-05,  9.1593e-04, -2.9993e-04,\n",
            "        -3.1416e-04, -4.0728e-04,  5.2538e-04, -5.5032e-04, -3.1220e-05,\n",
            "         6.0755e-04, -8.5394e-04, -3.2054e-04,  3.1917e-04,  9.6977e-05,\n",
            "        -6.9916e-04,  2.7926e-04,  3.4304e-04, -4.4643e-04, -8.4908e-04,\n",
            "         1.2042e-03,  3.9064e-04,  3.6840e-04,  5.6656e-04, -1.6828e-04,\n",
            "         3.1438e-04, -2.9484e-04, -3.8544e-05, -4.4863e-04,  6.4794e-04,\n",
            "         8.9893e-05,  5.6986e-04,  5.3806e-04, -3.6766e-04, -5.8988e-05,\n",
            "         8.5023e-04,  5.7660e-04, -3.7219e-04, -5.0068e-04,  7.2632e-04,\n",
            "         3.5440e-05, -2.2724e-04, -4.4184e-05])), ('module.encoder_k.layer2.1.bn2.running_mean', tensor([ 2.9376e-01, -1.7524e-01,  7.9144e-02,  9.4329e-02,  3.3892e-01,\n",
            "        -2.4021e-01,  2.1663e-03, -7.3635e-01,  1.2398e-01, -1.1301e-01,\n",
            "         5.0476e-01, -2.2441e-01, -3.9693e-02, -2.9096e-01, -4.6354e-01,\n",
            "         2.0464e-01,  4.5700e-01,  6.2370e-01, -4.8310e-01,  7.3962e-01,\n",
            "        -3.0422e-01,  1.2628e+00,  1.8878e-01, -3.5403e-01,  3.0410e-02,\n",
            "         1.6637e-01,  6.7323e-01,  7.0194e-01,  2.0971e-01,  1.2652e-01,\n",
            "         3.6352e-01, -8.2316e-01,  9.9308e-01,  2.2980e-01,  2.2608e-01,\n",
            "        -7.5833e-01,  3.4336e-01,  3.7827e-01, -4.9153e-01,  6.2217e-01,\n",
            "         3.3150e-01, -2.8633e-01,  2.7772e-01,  4.0100e-01, -8.4348e-01,\n",
            "        -2.4071e-01,  2.4069e-01,  5.7566e-01,  9.9934e-01,  6.0044e-01,\n",
            "         3.3891e-01, -1.3172e+00,  1.5478e-01, -2.2848e-01,  6.8299e-01,\n",
            "        -5.0702e-01,  4.6850e-01,  5.7645e-01, -2.8932e-03, -2.8948e-01,\n",
            "         6.6587e-01, -8.6428e-02,  2.5004e-01, -4.1980e-01,  3.4001e-01,\n",
            "         2.6103e-02, -4.2693e-01, -3.3784e-01,  1.4173e-01,  3.9042e-01,\n",
            "        -1.7180e-01, -7.9326e-01, -7.6287e-02, -7.0365e-01, -1.0931e+00,\n",
            "         3.9512e-04, -3.9293e-01, -3.1387e-01,  3.1136e-01, -3.3819e-01,\n",
            "         6.9801e-01,  5.6692e-01, -2.4396e-01,  1.3726e-01, -1.7529e-01,\n",
            "        -5.4381e-02,  4.1537e-01, -7.3053e-01,  2.7830e-01,  2.7367e-01,\n",
            "        -2.8611e-01, -1.2711e-01,  3.0129e-01,  2.6323e-01, -4.4299e-02,\n",
            "         3.5760e-01,  2.8199e-01, -9.0884e-01, -8.7929e-01,  3.5640e-02,\n",
            "         8.8998e-01,  3.4074e-01, -1.6267e-02,  2.5188e-01,  2.5108e-01,\n",
            "        -5.9401e-01,  1.6182e-01, -5.2518e-01, -2.9983e-01, -1.2565e+00,\n",
            "        -3.6005e-01, -4.1908e-01, -7.7431e-01, -9.7998e-01, -1.0344e-01,\n",
            "         1.0634e+00,  3.4799e-01,  8.6255e-01, -9.0663e-03,  4.2866e-01,\n",
            "        -5.3662e-01,  2.8240e-01,  2.2389e-01,  5.3453e-01, -3.0154e-01,\n",
            "        -7.7009e-02,  6.7645e-01,  1.9665e-01])), ('module.encoder_k.layer2.1.bn2.running_var', tensor([0.5755, 0.5615, 0.8190, 0.5598, 0.7151, 0.8099, 0.5827, 0.9193, 1.1356,\n",
            "        0.5824, 0.6475, 0.4415, 0.5937, 0.8898, 0.6313, 0.6583, 0.6202, 0.6918,\n",
            "        0.7141, 1.0476, 0.6279, 1.7142, 0.6954, 0.6582, 0.6038, 0.5075, 0.6417,\n",
            "        1.0435, 0.7123, 0.9187, 0.5856, 0.6288, 1.3651, 0.5246, 0.4965, 0.7278,\n",
            "        0.5857, 0.5874, 0.8931, 1.1042, 0.6686, 0.5908, 0.6754, 0.6310, 0.6602,\n",
            "        0.5366, 0.6148, 0.6080, 1.0215, 0.6126, 0.5087, 0.6283, 0.5758, 0.5532,\n",
            "        0.6522, 0.5387, 0.5869, 0.6357, 0.6677, 0.7063, 0.7941, 0.6851, 0.6940,\n",
            "        0.8026, 0.4957, 0.6522, 0.5103, 0.7133, 0.8888, 0.6917, 0.6170, 1.2376,\n",
            "        0.7318, 0.9967, 0.8275, 0.6175, 0.6563, 0.9918, 0.8475, 0.9556, 0.9787,\n",
            "        0.7938, 0.5782, 0.5938, 0.6895, 0.5638, 0.6120, 0.9868, 0.5980, 0.8685,\n",
            "        0.7760, 0.5694, 0.7277, 0.8025, 0.6913, 0.7449, 0.7342, 0.8201, 0.7518,\n",
            "        0.6102, 0.7157, 0.8288, 0.5307, 0.5943, 0.5574, 0.5672, 0.6239, 1.2991,\n",
            "        0.6252, 0.6567, 0.7290, 0.7199, 0.6470, 0.5573, 1.0044, 1.2144, 0.6439,\n",
            "        0.5360, 0.7523, 0.5516, 0.6629, 0.6249, 0.8025, 0.8438, 0.6273, 0.5314,\n",
            "        0.6058, 0.8008])), ('module.encoder_k.layer2.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.1.conv3.weight', tensor([[[[ 0.0135]],\n",
            "\n",
            "         [[-0.0089]],\n",
            "\n",
            "         [[-0.0747]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0356]],\n",
            "\n",
            "         [[-0.0281]],\n",
            "\n",
            "         [[ 0.0148]]],\n",
            "\n",
            "\n",
            "        [[[-0.0497]],\n",
            "\n",
            "         [[-0.0970]],\n",
            "\n",
            "         [[-0.0183]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0399]],\n",
            "\n",
            "         [[ 0.0442]],\n",
            "\n",
            "         [[ 0.0137]]],\n",
            "\n",
            "\n",
            "        [[[-0.1227]],\n",
            "\n",
            "         [[ 0.1145]],\n",
            "\n",
            "         [[-0.0724]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0414]],\n",
            "\n",
            "         [[ 0.0626]],\n",
            "\n",
            "         [[ 0.0663]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0264]],\n",
            "\n",
            "         [[-0.0160]],\n",
            "\n",
            "         [[-0.0334]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0592]],\n",
            "\n",
            "         [[ 0.0766]],\n",
            "\n",
            "         [[ 0.0195]]],\n",
            "\n",
            "\n",
            "        [[[-0.0077]],\n",
            "\n",
            "         [[-0.0117]],\n",
            "\n",
            "         [[-0.1057]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0434]],\n",
            "\n",
            "         [[-0.0179]],\n",
            "\n",
            "         [[-0.1077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0206]],\n",
            "\n",
            "         [[ 0.0182]],\n",
            "\n",
            "         [[ 0.0357]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0133]],\n",
            "\n",
            "         [[-0.0040]],\n",
            "\n",
            "         [[ 0.0051]]]])), ('module.encoder_k.layer2.1.bn3.weight', tensor([0.9992, 0.9992, 0.9993, 0.9991, 0.9990, 0.9995, 0.9994, 0.9991, 0.9988,\n",
            "        0.9992, 0.9987, 0.9990, 0.9992, 0.9995, 0.9990, 0.9991, 0.9988, 0.9989,\n",
            "        0.9993, 0.9987, 0.9988, 0.9994, 0.9990, 0.9991, 0.9995, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9994, 0.9990, 0.9988, 0.9991, 0.9991, 0.9993, 0.9992,\n",
            "        0.9995, 0.9992, 0.9990, 0.9992, 0.9991, 0.9991, 0.9987, 0.9990, 0.9989,\n",
            "        0.9992, 0.9989, 0.9992, 0.9993, 0.9987, 0.9991, 0.9991, 0.9993, 0.9992,\n",
            "        0.9990, 0.9990, 0.9990, 0.9993, 0.9989, 0.9995, 0.9987, 0.9991, 0.9988,\n",
            "        0.9994, 0.9992, 0.9990, 0.9990, 0.9988, 0.9989, 0.9991, 0.9992, 0.9989,\n",
            "        0.9989, 0.9993, 0.9994, 0.9992, 0.9994, 0.9990, 0.9991, 0.9994, 0.9992,\n",
            "        0.9994, 0.9988, 0.9992, 0.9988, 0.9990, 0.9991, 0.9989, 0.9990, 0.9992,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9987, 0.9988, 0.9989, 0.9994,\n",
            "        0.9993, 0.9987, 0.9989, 0.9988, 0.9987, 0.9992, 0.9993, 0.9990, 0.9987,\n",
            "        0.9992, 0.9989, 0.9991, 0.9992, 0.9991, 0.9989, 0.9987, 0.9988, 0.9990,\n",
            "        0.9991, 0.9987, 0.9988, 0.9992, 0.9989, 0.9989, 0.9989, 0.9995, 0.9994,\n",
            "        0.9992, 0.9991, 0.9990, 0.9989, 0.9991, 0.9991, 0.9992, 0.9990, 0.9989,\n",
            "        0.9990, 0.9994, 0.9991, 0.9989, 0.9992, 0.9987, 0.9987, 0.9985, 0.9993,\n",
            "        0.9987, 0.9993, 0.9991, 0.9988, 0.9988, 0.9994, 0.9989, 0.9990, 0.9994,\n",
            "        0.9988, 0.9996, 0.9993, 0.9995, 0.9994, 0.9993, 0.9988, 0.9988, 0.9992,\n",
            "        0.9991, 0.9995, 0.9990, 0.9994, 0.9993, 0.9992, 0.9991, 0.9990, 0.9990,\n",
            "        0.9994, 0.9991, 0.9991, 0.9988, 0.9990, 0.9992, 0.9992, 0.9990, 0.9991,\n",
            "        0.9994, 0.9987, 0.9991, 0.9995, 0.9991, 0.9990, 0.9990, 0.9989, 0.9992,\n",
            "        0.9990, 0.9993, 0.9990, 0.9986, 0.9989, 0.9991, 0.9991, 0.9994, 0.9994,\n",
            "        0.9994, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9993, 0.9991,\n",
            "        0.9991, 0.9987, 0.9990, 0.9993, 0.9993, 0.9991, 0.9989, 0.9985, 0.9987,\n",
            "        0.9989, 0.9988, 0.9992, 0.9989, 0.9987, 0.9993, 0.9994, 0.9990, 0.9988,\n",
            "        0.9991, 0.9991, 0.9989, 0.9993, 0.9993, 0.9992, 0.9991, 0.9989, 0.9991,\n",
            "        0.9992, 0.9989, 0.9992, 0.9994, 0.9988, 0.9992, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9993, 0.9990, 0.9991, 0.9994, 0.9989, 0.9994, 0.9996, 0.9993,\n",
            "        0.9986, 0.9994, 0.9994, 0.9989, 0.9993, 0.9993, 0.9990, 0.9991, 0.9991,\n",
            "        0.9993, 0.9987, 0.9991, 0.9994, 0.9992, 0.9996, 0.9991, 0.9989, 0.9990,\n",
            "        0.9987, 0.9991, 0.9992, 0.9993, 0.9990, 0.9992, 0.9987, 0.9991, 0.9993,\n",
            "        0.9991, 0.9989, 0.9990, 0.9987, 0.9991, 0.9992, 0.9988, 0.9989, 0.9987,\n",
            "        0.9991, 0.9994, 0.9989, 0.9990, 0.9990, 0.9990, 0.9989, 0.9990, 0.9992,\n",
            "        0.9989, 0.9987, 0.9994, 0.9994, 0.9990, 0.9991, 0.9991, 0.9989, 0.9991,\n",
            "        0.9990, 0.9993, 0.9993, 0.9988, 0.9992, 0.9989, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9987, 0.9991, 0.9990, 0.9988, 0.9991, 0.9991, 0.9988, 0.9990,\n",
            "        0.9988, 0.9985, 0.9988, 0.9992, 0.9994, 0.9995, 0.9991, 0.9992, 0.9994,\n",
            "        0.9992, 0.9988, 0.9995, 0.9993, 0.9990, 0.9990, 0.9991, 0.9992, 0.9985,\n",
            "        0.9993, 0.9996, 0.9992, 0.9991, 0.9992, 0.9995, 0.9991, 0.9992, 0.9988,\n",
            "        0.9994, 0.9994, 0.9993, 0.9991, 0.9992, 0.9989, 0.9986, 0.9995, 0.9990,\n",
            "        0.9992, 0.9994, 0.9985, 0.9991, 0.9989, 0.9990, 0.9994, 0.9988, 0.9992,\n",
            "        0.9992, 0.9992, 0.9994, 0.9992, 0.9995, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9992, 0.9992, 0.9992, 0.9994, 0.9994, 0.9989, 0.9988, 0.9987, 0.9992,\n",
            "        0.9989, 0.9991, 0.9992, 0.9992, 0.9992, 0.9987, 0.9994, 0.9993, 0.9988,\n",
            "        0.9987, 0.9994, 0.9988, 0.9995, 0.9992, 0.9992, 0.9992, 0.9991, 0.9986,\n",
            "        0.9988, 0.9988, 0.9993, 0.9991, 0.9994, 0.9988, 0.9990, 0.9991, 0.9989,\n",
            "        0.9994, 0.9997, 0.9991, 0.9990, 0.9988, 0.9989, 0.9992, 0.9992, 0.9994,\n",
            "        0.9991, 0.9992, 0.9990, 0.9991, 0.9993, 0.9991, 0.9986, 0.9991, 0.9992,\n",
            "        0.9990, 0.9992, 0.9992, 0.9989, 0.9993, 0.9991, 0.9990, 0.9994, 0.9991,\n",
            "        0.9989, 0.9991, 0.9990, 0.9991, 0.9989, 0.9993, 0.9994, 0.9994, 0.9992,\n",
            "        0.9987, 0.9993, 0.9990, 0.9992, 0.9994, 0.9992, 0.9994, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9986, 0.9991, 0.9991, 0.9993, 0.9990, 0.9990, 0.9993,\n",
            "        0.9991, 0.9989, 0.9991, 0.9990, 0.9986, 0.9994, 0.9989, 0.9990, 0.9992,\n",
            "        0.9990, 0.9986, 0.9988, 0.9989, 0.9991, 0.9991, 0.9994, 0.9989, 0.9986,\n",
            "        0.9991, 0.9996, 0.9992, 0.9988, 0.9988, 0.9988, 0.9992, 0.9993, 0.9993,\n",
            "        0.9987, 0.9992, 0.9991, 0.9988, 0.9993, 0.9991, 0.9988, 0.9990, 0.9991,\n",
            "        0.9989, 0.9991, 0.9989, 0.9988, 0.9993, 0.9988, 0.9991, 0.9993])), ('module.encoder_k.layer2.1.bn3.bias', tensor([ 9.8544e-05, -1.6202e-05,  2.6264e-04, -1.9532e-04, -5.3289e-05,\n",
            "         3.4470e-04,  2.4886e-04, -1.4198e-04,  1.5800e-04,  1.5724e-04,\n",
            "        -2.9519e-04,  2.4727e-04,  2.0330e-04,  1.3586e-04,  5.5221e-06,\n",
            "        -2.1071e-04,  1.8371e-04, -2.3527e-04, -1.1348e-04, -2.4606e-04,\n",
            "        -1.8115e-05,  1.9909e-04, -1.0042e-04, -2.4898e-04,  1.1023e-04,\n",
            "         2.9313e-04, -5.2969e-05, -4.4414e-05,  1.0499e-04,  1.9445e-04,\n",
            "         9.0304e-05,  1.1830e-04, -1.0901e-04, -2.6327e-04,  1.6488e-04,\n",
            "        -6.7441e-05,  1.2431e-04,  5.1081e-05, -1.9797e-04,  5.8602e-04,\n",
            "         6.5161e-05,  3.0742e-05, -1.2979e-04, -2.9805e-05, -8.8963e-05,\n",
            "        -1.6127e-04, -2.0313e-04,  2.1138e-05, -2.4222e-04, -2.1530e-04,\n",
            "        -8.3898e-05, -3.0109e-04, -1.4019e-04,  1.1140e-04, -1.3822e-04,\n",
            "        -1.8556e-04, -1.1555e-04, -5.1677e-05,  2.1310e-05, -8.3363e-06,\n",
            "        -2.1986e-04,  3.2734e-04,  2.7820e-04,  1.8447e-04, -3.5465e-05,\n",
            "        -6.8641e-05,  1.9064e-04, -6.6480e-05,  8.3617e-06,  1.5922e-05,\n",
            "         1.1716e-05,  1.7628e-04, -4.3088e-06,  2.1353e-04,  3.2792e-04,\n",
            "         3.3454e-04,  1.8252e-04,  1.5264e-04,  2.7394e-04,  1.7379e-04,\n",
            "         1.0966e-04,  2.8716e-04,  5.4032e-05,  2.6351e-04, -2.2097e-05,\n",
            "        -7.2498e-05,  2.4324e-04, -1.6171e-04,  1.5361e-04, -1.7079e-04,\n",
            "        -1.0833e-04, -4.0489e-05,  1.7640e-04, -1.8190e-04, -1.2136e-04,\n",
            "        -2.8172e-05, -6.7875e-05, -2.8841e-04,  1.3442e-04, -1.3883e-04,\n",
            "        -1.1616e-05, -2.6067e-04, -1.7625e-04, -1.2303e-04,  1.5170e-04,\n",
            "        -2.4157e-04,  2.8480e-04,  4.4953e-05,  1.8901e-05, -2.5419e-04,\n",
            "         3.1087e-04,  4.0619e-05,  1.5214e-04, -4.9858e-04, -1.1935e-04,\n",
            "        -4.1576e-05,  1.7079e-04,  1.9065e-04, -1.5455e-04, -2.7787e-04,\n",
            "         3.6001e-05, -8.0260e-05, -3.1324e-04, -5.7204e-05, -6.9120e-05,\n",
            "         2.2713e-05,  3.9021e-04, -1.5045e-04, -6.6016e-05, -1.0872e-04,\n",
            "         3.3945e-04,  2.3207e-04,  3.4760e-04,  1.3391e-04,  2.0480e-04,\n",
            "        -7.2573e-06,  2.2714e-04, -4.5210e-05,  3.0440e-05,  1.3474e-04,\n",
            "        -2.1169e-04,  9.2681e-06, -3.2000e-04,  5.8489e-05, -2.3952e-04,\n",
            "         2.1439e-04,  6.3302e-05,  2.0647e-04, -1.6007e-04,  1.6272e-04,\n",
            "        -1.2206e-04,  1.1659e-04, -1.6388e-04, -1.2878e-04,  2.8390e-04,\n",
            "         1.7798e-04, -2.2803e-05,  3.1525e-04,  8.3266e-05, -2.5234e-04,\n",
            "         5.0949e-06, -3.6053e-05, -9.9090e-05,  6.8066e-05, -4.8442e-05,\n",
            "         1.6672e-04,  3.3436e-04,  1.4997e-07,  2.2830e-04, -1.0872e-04,\n",
            "         1.6903e-04,  1.6568e-04, -1.3794e-04, -1.0217e-04,  6.1375e-05,\n",
            "        -7.0546e-05,  2.6972e-05,  2.1570e-04,  6.6555e-05,  8.0420e-05,\n",
            "         3.2127e-04,  1.0664e-04,  8.7816e-05,  3.0269e-04,  2.0405e-04,\n",
            "         3.0007e-04,  4.7893e-05, -1.2619e-04,  2.6101e-04, -1.6684e-04,\n",
            "        -3.3069e-04, -4.4124e-06, -2.5437e-04, -1.9726e-04,  2.1960e-04,\n",
            "        -7.8152e-05, -3.7619e-05,  9.7046e-05,  3.4232e-04, -6.8822e-05,\n",
            "        -1.0522e-04,  1.1166e-06,  1.3671e-04, -1.3766e-04, -8.4663e-05,\n",
            "         3.9845e-04,  1.6139e-04,  1.2441e-04, -1.8455e-04,  2.7001e-06,\n",
            "         4.6922e-04,  9.7958e-05,  1.7635e-05, -3.5605e-04,  1.1307e-04,\n",
            "        -1.9868e-05, -3.7595e-05, -1.9165e-04,  2.1951e-05, -3.5495e-05,\n",
            "        -2.5180e-04,  2.2696e-04,  9.6685e-05, -3.7276e-05, -9.8073e-05,\n",
            "         2.3548e-04,  1.1834e-04, -9.2941e-05,  1.8787e-04,  2.1389e-05,\n",
            "         1.3545e-04,  2.6852e-04, -3.6345e-04,  7.3893e-05, -7.3863e-05,\n",
            "        -3.6520e-05,  1.4703e-04,  2.4464e-04,  5.9741e-06,  2.3808e-04,\n",
            "        -4.3801e-05,  8.9805e-05,  1.9500e-04,  1.9543e-04,  3.3845e-05,\n",
            "        -1.7346e-04, -3.4744e-05, -9.3043e-06, -1.5205e-04, -1.2932e-04,\n",
            "         3.8593e-04,  1.7185e-04, -1.3766e-04,  4.0725e-05, -9.1209e-05,\n",
            "        -1.3874e-04,  8.1507e-05, -1.8458e-04, -7.4818e-06,  1.1520e-04,\n",
            "        -2.7752e-05,  1.6594e-04,  4.5123e-05,  6.5857e-05,  5.1886e-05,\n",
            "        -9.5998e-05,  9.1974e-05,  1.7065e-04,  1.5302e-04,  2.3906e-04,\n",
            "        -6.2294e-05, -4.4255e-04,  6.2117e-05,  1.5675e-04, -1.5298e-04,\n",
            "         9.4342e-05, -1.6375e-04,  3.1698e-05, -5.2044e-04,  8.0060e-05,\n",
            "        -2.0801e-04, -1.0184e-04, -2.0353e-04, -9.7566e-05, -3.4220e-05,\n",
            "        -8.8766e-06, -4.5804e-04, -3.8163e-04,  3.4181e-05,  1.2406e-04,\n",
            "        -2.4080e-04,  2.6700e-04, -3.6458e-05,  1.1000e-04, -1.3977e-04,\n",
            "        -6.9186e-05,  9.9227e-05,  3.0039e-04, -4.2897e-05,  2.3330e-04,\n",
            "        -1.1356e-04,  4.3624e-05,  1.9845e-04,  2.3239e-04, -4.3537e-05,\n",
            "         3.8806e-04, -3.2427e-04, -1.8398e-04, -6.2455e-05, -2.5573e-04,\n",
            "         1.4179e-04, -3.5517e-05, -9.8313e-05, -1.5768e-04, -5.3944e-05,\n",
            "         1.6691e-04, -5.2574e-05,  1.7051e-04,  2.1360e-06, -5.5587e-05,\n",
            "         1.7538e-04, -1.5198e-04, -1.2422e-04,  1.2402e-04,  6.3771e-05,\n",
            "        -1.0271e-04,  2.3336e-04,  1.5776e-04,  2.6203e-04,  2.1791e-04,\n",
            "         5.1154e-05,  2.3901e-04,  9.6100e-05,  4.4263e-06,  1.9567e-04,\n",
            "        -8.6842e-05,  6.7248e-05, -1.8951e-04,  6.1567e-05,  2.0944e-04,\n",
            "         3.8289e-05, -2.2062e-04,  2.9563e-04,  2.9180e-04,  1.1395e-05,\n",
            "         1.8322e-04, -1.0513e-05, -2.5813e-04,  1.1124e-05,  2.3826e-04,\n",
            "        -4.5891e-06, -1.1629e-04, -9.2745e-05,  4.6177e-04,  2.6704e-04,\n",
            "         8.6943e-05, -2.5284e-05, -3.5186e-04,  2.9267e-04, -3.1991e-04,\n",
            "        -5.4772e-05,  2.8784e-04, -3.0774e-04, -1.8655e-05,  5.2083e-04,\n",
            "         1.8045e-04,  1.8498e-04, -1.3713e-04,  7.3425e-05, -2.6570e-04,\n",
            "        -1.1825e-04,  1.2082e-04,  1.8226e-04,  1.3256e-05,  1.7975e-04,\n",
            "        -2.8559e-04, -1.0749e-04,  1.6451e-05, -1.3892e-04,  1.7731e-04,\n",
            "         1.1328e-05,  1.0877e-04, -2.6692e-04,  6.5366e-05, -6.6594e-05,\n",
            "        -4.0395e-04,  1.6440e-04,  2.6472e-05,  3.3206e-04, -7.1464e-05,\n",
            "         1.0016e-04, -4.0647e-05, -1.6388e-04,  6.6360e-05, -3.5686e-06,\n",
            "        -3.1882e-05,  1.4975e-04, -4.4971e-05,  1.6922e-05, -1.3499e-04,\n",
            "        -8.0542e-05,  1.8679e-04, -2.4588e-04, -4.7238e-04, -1.5306e-04,\n",
            "        -2.6663e-05, -9.9177e-05,  1.1819e-04, -1.5818e-04,  9.8196e-05,\n",
            "         8.5984e-05, -2.7596e-04,  2.1940e-04,  6.6135e-05,  3.1200e-04,\n",
            "         3.1018e-04, -2.5297e-05, -4.0943e-04, -1.2161e-04, -1.6801e-04,\n",
            "        -1.8714e-04, -1.1341e-04, -1.8418e-04, -2.1342e-04,  4.2539e-05,\n",
            "         1.9423e-04,  1.4709e-04,  3.5237e-06,  1.6262e-04, -2.7210e-04,\n",
            "         8.7837e-06,  1.5571e-04,  2.0927e-04,  9.2779e-06,  3.3354e-04,\n",
            "         5.3764e-05, -1.2895e-04, -1.2373e-04, -1.0195e-04,  1.8129e-04,\n",
            "         1.7582e-04,  7.0621e-05,  2.7062e-04, -1.3591e-04, -1.8516e-04,\n",
            "        -7.0913e-05,  2.0069e-04,  5.9904e-06, -3.0944e-05, -1.6218e-04,\n",
            "        -8.6782e-05, -1.6068e-04,  1.8105e-05,  4.9139e-05,  1.6388e-04,\n",
            "         6.2411e-05,  6.2307e-05,  1.1992e-04, -1.4500e-04, -1.3991e-05,\n",
            "         4.9953e-05, -3.2863e-04,  1.8514e-04, -2.1480e-04,  1.1330e-04,\n",
            "         4.6505e-05,  4.2604e-05, -9.1957e-05,  4.4028e-04, -3.2167e-04,\n",
            "        -5.0928e-05,  1.2671e-04, -2.5769e-04,  1.5884e-04, -2.8808e-04,\n",
            "        -1.8950e-04, -6.8007e-05, -4.6564e-04, -1.0328e-04, -1.8278e-04,\n",
            "        -7.2414e-05,  9.8444e-05,  9.9457e-05, -8.0465e-05,  5.0124e-05,\n",
            "        -9.7703e-05, -2.5413e-05,  1.0859e-04,  1.6382e-04, -2.6968e-04,\n",
            "         6.2722e-05, -7.6461e-05,  6.1475e-05,  3.1385e-04, -1.0802e-04,\n",
            "        -1.5464e-04,  5.2687e-05,  2.0573e-05,  1.1727e-05,  3.0838e-04,\n",
            "        -1.4161e-04,  1.6693e-04, -1.3812e-04, -6.6886e-05, -2.3220e-05,\n",
            "        -9.4729e-05, -1.9797e-04,  1.9189e-04,  1.0904e-04, -1.2437e-04,\n",
            "        -2.4049e-04, -5.1945e-05])), ('module.encoder_k.layer2.1.bn3.running_mean', tensor([ 0.0076, -0.1334,  0.1019,  0.4477, -0.0446,  0.1529, -0.0290,  0.0249,\n",
            "         0.4331, -0.1169, -0.4103,  0.0458, -0.0623, -0.3896,  0.0359,  0.1224,\n",
            "         0.2738, -0.1830, -0.2924, -0.3998, -0.3265,  0.0961, -0.2723,  0.1339,\n",
            "        -0.1255, -0.0152,  0.2149,  0.0399, -0.0902, -0.3126,  0.0104,  0.5838,\n",
            "        -0.1401,  0.0847, -0.1756, -0.0398,  0.4211,  0.1878,  0.3210, -0.0056,\n",
            "        -0.6536, -0.1065,  0.1622, -0.0215,  0.0111,  0.0500,  0.0396,  0.0347,\n",
            "        -0.1907, -0.3216,  0.0422,  0.0624,  0.1296,  0.3128, -0.1678,  0.3538,\n",
            "         0.0385,  0.0308,  0.1912,  0.0702, -0.1818,  0.0886,  0.1305, -0.2002,\n",
            "        -0.0621,  0.0158, -0.2020,  0.0106, -0.0263,  0.4110,  0.0915, -0.1147,\n",
            "         0.2594,  0.1033, -0.1028,  0.0585,  0.1083, -0.3557,  0.0752,  0.1343,\n",
            "        -0.1769,  0.0426,  0.6539,  0.0393,  0.4374,  0.0360,  0.1137,  0.2113,\n",
            "         0.3357, -0.2047, -0.2437,  0.0452,  0.0552, -0.0961, -0.3848, -0.3449,\n",
            "         0.5362, -0.0680,  0.0942, -0.0460,  0.5346,  0.1484,  0.2290, -0.1083,\n",
            "         0.2883,  0.0874, -0.0035,  0.0077,  0.5536,  0.2684, -0.3481,  0.0959,\n",
            "        -0.3839, -0.2559, -0.0368,  0.1007,  0.4461,  0.2190,  0.1259,  0.4201,\n",
            "         0.0193,  0.1499,  0.1834, -0.3414,  0.0417,  0.3478, -0.3155, -0.3202,\n",
            "         0.1297,  0.3054, -0.0034, -0.0899,  0.0878,  0.2170,  0.3573,  0.1928,\n",
            "        -0.2974, -0.5812,  0.2098, -0.4233,  0.0816, -0.2985,  0.2300, -0.1542,\n",
            "         0.4365, -0.0861, -0.2365, -0.3066, -0.2139, -0.1344,  0.0856, -0.1434,\n",
            "         0.0108,  0.0085, -0.3725,  0.1910, -0.0279, -0.2338, -0.0251,  0.1788,\n",
            "        -0.2774,  0.0977, -0.3893,  0.1916,  0.0778, -0.4745,  0.3258, -0.1172,\n",
            "        -0.0806,  0.1301, -0.0845, -0.0783,  0.5077,  0.5187, -0.3217, -0.2138,\n",
            "         0.3920, -0.0694, -0.3830, -0.0933, -0.0470, -0.3155, -0.4428,  0.0252,\n",
            "         0.3281,  0.1433, -0.1183, -0.1239,  0.0252,  0.5600, -0.6873, -0.2783,\n",
            "         0.3781, -0.2690,  0.2675,  0.3728, -0.0771,  0.1118, -0.1370, -0.1431,\n",
            "        -0.4279,  0.0245, -0.4179, -0.0178, -0.0570,  0.2089,  0.1926, -0.2576,\n",
            "         0.1472, -0.6100, -0.0974,  0.1279, -0.2883, -0.1476,  0.0689, -0.1074,\n",
            "        -0.1075,  0.5952, -0.0833, -0.0246, -0.1415,  0.0456,  0.2930,  0.2399,\n",
            "         0.1024,  0.2676, -0.1259, -0.0808,  0.4342, -0.3113,  0.3258,  0.2259,\n",
            "        -0.1782, -0.3951, -0.0938, -0.3570,  0.2955, -0.4474,  0.0551, -0.0028,\n",
            "         0.3723,  0.1427, -0.0495,  0.1017,  0.2053,  0.4566, -0.1411,  0.0507,\n",
            "         0.3407, -0.0750,  0.3215, -0.1580, -0.0573,  0.0441, -0.1413,  0.1887,\n",
            "         0.4785, -0.0903,  0.1388, -0.3777,  0.1324,  0.1372, -0.1230, -0.1128,\n",
            "        -0.1401,  0.1451,  0.1116,  0.3555,  0.5447, -0.1473, -0.2623, -0.3473,\n",
            "        -0.0626,  0.2542, -0.4597,  0.1556,  0.0604,  0.2517,  0.1408, -0.0044,\n",
            "         0.0328, -0.2862,  0.1385, -0.0890,  0.1496, -0.2121,  0.3531, -0.0185,\n",
            "         0.2960, -0.1532, -0.1359,  0.2979, -0.2473,  0.0582, -0.2479, -0.0441,\n",
            "        -0.1731, -0.4616, -0.6910, -0.0894, -0.0149,  0.0986,  0.0466, -0.3383,\n",
            "         0.0084, -0.2310,  0.4224,  0.0019,  0.1113,  0.0045,  0.5449,  0.1543,\n",
            "        -0.3174, -0.6241,  0.0224, -0.6471, -0.1560, -0.1048,  0.1794, -0.1180,\n",
            "        -0.0257, -0.0919,  0.4348,  0.0341,  0.1669, -0.0750,  0.2930,  0.0073,\n",
            "        -0.2162, -0.0503, -0.5743,  0.1206,  0.0335,  0.1223, -0.0181, -0.2679,\n",
            "        -0.2243,  0.6190, -0.0805,  0.0525,  0.4731, -0.3118, -0.0509, -0.3376,\n",
            "        -0.2138, -0.1846,  0.0287, -0.2396, -0.1240,  0.0286,  0.2898, -0.1675,\n",
            "         0.1368,  0.0046, -0.0407, -0.0829, -0.1649,  0.0836,  0.2142, -0.1657,\n",
            "         0.1673,  0.3082, -0.6162,  0.0984, -0.0963,  0.0884, -0.2366,  0.5827,\n",
            "         0.1344, -0.2152, -0.6244, -0.0589, -0.0867, -0.2271, -0.0779, -0.2606,\n",
            "        -0.0571,  0.0266, -0.0058,  0.0416, -0.0410,  0.0034, -0.1563,  0.5219,\n",
            "        -0.1467, -0.4114,  0.1372,  0.2691, -0.3629,  0.0112, -0.4616,  0.0965,\n",
            "        -0.2426,  0.0605,  0.0785,  0.1057, -0.0057, -0.0647, -0.3079,  0.1306,\n",
            "        -0.1014, -0.6157, -0.0469, -0.0810, -0.2422,  0.1524, -0.4577,  0.2059,\n",
            "         0.0661, -0.0141,  0.1805, -0.1003,  0.5394, -0.1761,  0.0327,  0.2568,\n",
            "        -0.7251,  0.0951, -0.1712,  0.4657,  0.0032, -0.1462, -0.1275, -0.2982,\n",
            "         0.2152,  0.1433,  0.2714,  0.2047,  0.2645,  0.2944, -0.5392,  0.1640,\n",
            "        -0.1863,  0.0042,  0.2350,  0.1193, -0.2046,  0.4912,  0.1818,  0.2598,\n",
            "         0.1090, -0.3024,  0.2212, -0.1390, -0.1937,  0.2440,  0.1479, -0.4221,\n",
            "         0.0410, -0.1253,  0.2076,  0.1755, -0.0077,  0.0894,  0.0386, -0.0939,\n",
            "         0.1449,  0.0757, -0.2799,  0.2935,  0.2896,  0.1782,  0.0973,  0.1006,\n",
            "         0.3625,  0.1478,  0.0279,  0.0186,  0.0770, -0.1308,  0.3271, -0.1272,\n",
            "         0.1108, -0.0693,  0.2454,  0.1083,  0.2462, -0.0076, -0.0048,  0.1688,\n",
            "         0.0755, -0.0092, -0.1131, -0.2082, -0.6680, -0.0664,  0.1157, -0.0683,\n",
            "         0.0738,  0.1257, -0.1171, -0.1107, -0.0915,  0.1170, -0.0394, -0.3106,\n",
            "        -0.1540, -0.4634, -0.2643, -0.0615,  0.4873,  0.1557,  0.0311,  0.0590,\n",
            "        -0.1632,  0.0937, -0.3797,  0.3381,  0.1489,  0.3208,  0.1283, -0.1617])), ('module.encoder_k.layer2.1.bn3.running_var', tensor([0.1532, 0.1865, 0.1499, 0.2966, 0.2017, 0.1755, 0.2184, 0.1816, 0.1604,\n",
            "        0.1936, 0.1440, 0.1173, 0.1700, 0.1644, 0.1375, 0.1511, 0.1603, 0.2168,\n",
            "        0.1959, 0.2377, 0.1877, 0.1503, 0.1829, 0.1623, 0.1449, 0.2080, 0.1355,\n",
            "        0.1819, 0.2203, 0.1695, 0.1523, 0.1997, 0.1599, 0.1962, 0.1953, 0.1653,\n",
            "        0.2047, 0.2179, 0.2125, 0.1196, 0.3305, 0.2112, 0.1887, 0.1662, 0.1560,\n",
            "        0.2400, 0.1386, 0.1580, 0.1536, 0.2901, 0.1386, 0.2766, 0.1740, 0.1529,\n",
            "        0.2076, 0.1483, 0.1841, 0.1419, 0.1395, 0.1300, 0.1580, 0.1787, 0.1859,\n",
            "        0.1473, 0.1898, 0.1333, 0.2027, 0.1529, 0.1387, 0.2284, 0.1222, 0.1551,\n",
            "        0.1288, 0.2202, 0.1953, 0.1570, 0.1619, 0.2006, 0.1657, 0.1178, 0.1537,\n",
            "        0.1887, 0.2539, 0.1670, 0.1792, 0.1635, 0.2429, 0.1437, 0.1396, 0.1493,\n",
            "        0.3306, 0.1943, 0.1582, 0.1517, 0.3993, 0.1588, 0.2027, 0.1604, 0.1290,\n",
            "        0.1742, 0.3345, 0.1276, 0.1431, 0.1612, 0.2417, 0.1689, 0.1456, 0.1784,\n",
            "        0.3279, 0.1640, 0.1509, 0.1985, 0.1990, 0.1252, 0.1545, 0.1568, 0.2126,\n",
            "        0.3065, 0.1703, 0.1614, 0.1669, 0.1363, 0.2967, 0.1633, 0.2006, 0.2009,\n",
            "        0.1825, 0.1353, 0.1727, 0.1498, 0.1502, 0.2008, 0.1613, 0.2707, 0.1988,\n",
            "        0.1305, 0.2857, 0.2708, 0.1796, 0.1541, 0.1762, 0.1875, 0.1672, 0.1496,\n",
            "        0.1916, 0.1459, 0.1688, 0.1813, 0.1714, 0.1215, 0.1525, 0.1220, 0.1982,\n",
            "        0.1218, 0.1586, 0.1516, 0.1832, 0.1582, 0.1264, 0.2421, 0.1609, 0.1225,\n",
            "        0.1801, 0.1419, 0.2351, 0.1824, 0.1373, 0.1586, 0.2150, 0.2677, 0.1510,\n",
            "        0.1859, 0.1496, 0.1454, 0.2649, 0.2687, 0.1618, 0.1956, 0.3545, 0.1502,\n",
            "        0.1502, 0.1241, 0.1680, 0.1728, 0.1408, 0.1389, 0.1888, 0.1459, 0.2306,\n",
            "        0.3586, 0.3747, 0.1394, 0.1591, 0.2067, 0.4126, 0.1550, 0.1661, 0.1785,\n",
            "        0.1869, 0.1636, 0.1311, 0.1817, 0.1787, 0.2257, 0.1194, 0.2214, 0.1169,\n",
            "        0.2050, 0.1280, 0.2249, 0.2171, 0.2047, 0.2073, 0.1880, 0.1613, 0.1057,\n",
            "        0.1514, 0.1231, 0.1825, 0.1781, 0.1417, 0.1881, 0.1336, 0.1378, 0.2019,\n",
            "        0.1463, 0.1351, 0.2987, 0.1667, 0.2144, 0.1298, 0.1525, 0.1639, 0.1344,\n",
            "        0.1512, 0.2398, 0.2650, 0.1189, 0.1617, 0.1457, 0.1455, 0.2307, 0.1421,\n",
            "        0.1610, 0.2845, 0.2034, 0.1501, 0.1362, 0.2212, 0.1041, 0.1778, 0.1504,\n",
            "        0.1795, 0.1950, 0.1503, 0.1535, 0.1794, 0.1083, 0.1311, 0.1712, 0.2133,\n",
            "        0.1170, 0.1403, 0.1522, 0.1516, 0.1585, 0.1536, 0.1268, 0.1405, 0.1408,\n",
            "        0.1315, 0.1669, 0.1764, 0.1585, 0.3124, 0.1450, 0.1502, 0.3336, 0.2134,\n",
            "        0.1898, 0.1696, 0.1522, 0.1918, 0.1824, 0.2116, 0.1515, 0.1668, 0.1499,\n",
            "        0.1277, 0.1586, 0.1753, 0.2213, 0.1695, 0.2280, 0.2059, 0.2427, 0.1609,\n",
            "        0.1715, 0.1459, 0.1803, 0.1564, 0.1567, 0.1226, 0.1801, 0.1717, 0.1529,\n",
            "        0.3315, 0.1418, 0.1233, 0.1412, 0.2821, 0.1772, 0.1956, 0.2850, 0.1749,\n",
            "        0.3353, 0.2434, 0.1759, 0.2000, 0.2014, 0.1711, 0.1511, 0.2292, 0.1403,\n",
            "        0.1320, 0.2290, 0.1249, 0.1809, 0.1910, 0.1786, 0.1394, 0.1574, 0.1742,\n",
            "        0.1260, 0.1731, 0.1943, 0.2564, 0.2015, 0.1942, 0.2524, 0.2611, 0.2298,\n",
            "        0.2072, 0.1942, 0.1540, 0.4433, 0.1916, 0.2452, 0.1423, 0.1147, 0.3190,\n",
            "        0.1543, 0.1790, 0.1430, 0.2231, 0.1988, 0.1722, 0.1706, 0.2060, 0.1812,\n",
            "        0.1533, 0.1194, 0.1753, 0.1584, 0.2081, 0.2127, 0.1800, 0.2471, 0.1762,\n",
            "        0.1264, 0.3282, 0.2066, 0.1196, 0.2250, 0.2081, 0.1646, 0.1266, 0.2672,\n",
            "        0.2609, 0.1910, 0.2287, 0.1092, 0.1555, 0.1286, 0.1399, 0.1319, 0.1993,\n",
            "        0.1969, 0.2342, 0.2715, 0.1643, 0.1285, 0.2432, 0.1543, 0.1357, 0.1390,\n",
            "        0.1640, 0.1574, 0.2330, 0.1295, 0.1512, 0.2492, 0.1168, 0.2002, 0.1591,\n",
            "        0.1809, 0.2304, 0.1328, 0.1410, 0.1368, 0.2476, 0.1351, 0.1902, 0.1447,\n",
            "        0.2016, 0.1903, 0.6140, 0.2322, 0.2140, 0.1705, 0.1965, 0.1357, 0.1549,\n",
            "        0.1469, 0.1403, 0.1242, 0.1693, 0.1374, 0.1707, 0.1741, 0.2638, 0.1392,\n",
            "        0.2190, 0.1419, 0.2245, 0.1488, 0.1262, 0.2649, 0.2162, 0.1759, 0.1440,\n",
            "        0.1274, 0.1965, 0.1935, 0.1734, 0.1446, 0.1342, 0.1217, 0.1694, 0.1510,\n",
            "        0.1761, 0.1798, 0.1989, 0.1570, 0.1661, 0.1238, 0.1685, 0.1743, 0.2320,\n",
            "        0.1472, 0.1763, 0.2577, 0.1375, 0.1414, 0.3036, 0.1990, 0.1562, 0.1725,\n",
            "        0.1508, 0.2324, 0.1034, 0.1758, 0.1506, 0.1761, 0.1343, 0.1687, 0.1638,\n",
            "        0.1746, 0.1740, 0.1184, 0.1685, 0.1288, 0.2292, 0.1565, 0.3922, 0.2758,\n",
            "        0.1823, 0.1449, 0.1454, 0.1864, 0.1334, 0.1894, 0.1420, 0.1413, 0.1516,\n",
            "        0.2532, 0.1811, 0.3162, 0.1481, 0.1502, 0.2009, 0.1746, 0.1774, 0.1492,\n",
            "        0.1298, 0.1405, 0.1744, 0.1993, 0.2236, 0.2406, 0.2245, 0.2416])), ('module.encoder_k.layer2.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.2.conv1.weight', tensor([[[[ 0.1012]],\n",
            "\n",
            "         [[ 0.0664]],\n",
            "\n",
            "         [[ 0.2563]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0363]],\n",
            "\n",
            "         [[-0.0991]],\n",
            "\n",
            "         [[ 0.0037]]],\n",
            "\n",
            "\n",
            "        [[[-0.1986]],\n",
            "\n",
            "         [[-0.0042]],\n",
            "\n",
            "         [[ 0.0457]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0193]],\n",
            "\n",
            "         [[ 0.0846]],\n",
            "\n",
            "         [[-0.0344]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0807]],\n",
            "\n",
            "         [[-0.1240]],\n",
            "\n",
            "         [[ 0.1037]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0679]],\n",
            "\n",
            "         [[-0.1061]],\n",
            "\n",
            "         [[-0.2692]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.2215]],\n",
            "\n",
            "         [[-0.0298]],\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0380]],\n",
            "\n",
            "         [[ 0.1535]],\n",
            "\n",
            "         [[-0.0354]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1293]],\n",
            "\n",
            "         [[ 0.1525]],\n",
            "\n",
            "         [[-0.1575]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         [[ 0.0767]],\n",
            "\n",
            "         [[-0.0734]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0880]],\n",
            "\n",
            "         [[ 0.1227]],\n",
            "\n",
            "         [[-0.0737]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1953]],\n",
            "\n",
            "         [[ 0.0790]],\n",
            "\n",
            "         [[-0.1640]]]])), ('module.encoder_k.layer2.2.bn1.weight', tensor([0.9986, 0.9990, 0.9987, 0.9993, 1.0000, 0.9997, 0.9987, 0.9990, 0.9988,\n",
            "        0.9993, 0.9993, 0.9983, 1.0001, 0.9985, 0.9988, 0.9989, 0.9990, 0.9990,\n",
            "        0.9991, 0.9988, 0.9986, 0.9992, 0.9995, 0.9997, 0.9989, 0.9995, 0.9997,\n",
            "        1.0000, 0.9990, 0.9991, 0.9987, 0.9989, 0.9996, 0.9994, 0.9990, 0.9993,\n",
            "        0.9984, 0.9989, 0.9993, 0.9990, 0.9997, 0.9985, 0.9994, 0.9987, 0.9985,\n",
            "        0.9993, 0.9990, 0.9993, 0.9987, 0.9990, 0.9992, 0.9993, 0.9988, 0.9985,\n",
            "        0.9995, 0.9999, 0.9995, 0.9984, 0.9998, 0.9985, 0.9995, 0.9984, 0.9992,\n",
            "        0.9994, 0.9992, 0.9992, 0.9986, 0.9988, 0.9989, 0.9989, 0.9988, 0.9992,\n",
            "        0.9984, 1.0001, 0.9991, 0.9993, 0.9996, 0.9985, 0.9993, 0.9993, 0.9986,\n",
            "        0.9989, 0.9997, 0.9995, 0.9992, 0.9996, 0.9987, 0.9992, 0.9996, 0.9994,\n",
            "        0.9986, 0.9986, 0.9991, 0.9989, 0.9988, 0.9994, 0.9993, 0.9993, 0.9991,\n",
            "        0.9987, 0.9993, 0.9985, 1.0001, 0.9991, 0.9988, 0.9992, 0.9987, 0.9984,\n",
            "        0.9986, 0.9991, 0.9996, 0.9984, 0.9979, 0.9993, 0.9985, 0.9992, 0.9986,\n",
            "        0.9998, 0.9996, 0.9986, 0.9990, 0.9994, 0.9991, 0.9992, 0.9993, 0.9986,\n",
            "        0.9997, 0.9986])), ('module.encoder_k.layer2.2.bn1.bias', tensor([ 2.9771e-05,  1.3349e-04, -2.2215e-04, -8.6692e-05,  2.8312e-04,\n",
            "         8.4762e-05,  5.5327e-06,  2.0263e-04, -4.1636e-04,  4.3024e-04,\n",
            "         1.0292e-03, -4.9527e-04,  9.1630e-05,  1.7277e-04, -4.3649e-04,\n",
            "         6.0880e-04, -4.9051e-04, -3.0268e-04, -2.7564e-04, -5.1465e-05,\n",
            "         1.4672e-04,  5.3794e-05,  6.2279e-05, -1.0181e-04, -3.6686e-04,\n",
            "         4.7368e-05, -2.9117e-04,  7.2768e-04, -2.2478e-04,  4.1383e-04,\n",
            "        -6.9036e-04,  5.2742e-04,  7.6499e-04,  4.2709e-04,  2.8494e-04,\n",
            "        -3.3733e-04, -3.9961e-04,  9.9579e-05, -4.4025e-04,  3.1210e-04,\n",
            "         1.8810e-04, -1.9588e-05,  4.5593e-04, -1.7306e-04, -8.0101e-04,\n",
            "        -3.4992e-04, -6.7604e-04, -2.5792e-04, -4.0549e-04,  5.5101e-05,\n",
            "         2.6206e-04,  3.2008e-04, -3.0185e-04, -1.5274e-04,  4.4329e-04,\n",
            "         3.6615e-04,  5.2044e-04, -4.2979e-04,  4.2991e-04, -3.7125e-04,\n",
            "         1.8943e-05, -5.5892e-04,  1.4697e-04, -1.0212e-05,  5.8851e-04,\n",
            "         2.2182e-05, -5.1972e-04,  1.2868e-04, -1.0670e-04, -1.6274e-04,\n",
            "        -3.8050e-04,  3.1136e-04, -8.1086e-04,  9.2767e-04, -2.0965e-04,\n",
            "         6.1008e-04,  9.2560e-05, -1.2604e-05, -3.1574e-04, -1.7274e-04,\n",
            "        -5.9902e-05,  1.6892e-05,  7.4338e-04,  5.1825e-04, -3.1515e-04,\n",
            "         4.6159e-04, -4.1875e-04,  4.4333e-04, -8.6640e-05, -1.0971e-04,\n",
            "        -4.0432e-04, -4.7079e-04,  1.2764e-04,  3.2915e-04, -6.8452e-04,\n",
            "         1.6241e-04, -2.0732e-04,  9.4181e-05,  6.2671e-05, -2.5074e-04,\n",
            "         3.3785e-04,  1.3937e-04,  1.1306e-03,  1.0900e-04,  2.7027e-04,\n",
            "         3.3921e-04,  3.9536e-05, -4.1929e-04, -3.6265e-04,  3.1048e-04,\n",
            "         4.0389e-04, -6.0748e-04, -8.5090e-04, -4.3809e-05,  4.1559e-05,\n",
            "        -5.3606e-04,  4.5179e-05,  2.8510e-04,  2.5793e-04, -1.8011e-04,\n",
            "         7.9595e-05,  5.0629e-04, -8.7757e-06,  4.0194e-05, -3.0180e-04,\n",
            "        -7.1399e-05,  4.1049e-04, -2.0006e-04])), ('module.encoder_k.layer2.2.bn1.running_mean', tensor([ 0.6148,  1.6916, -0.8171,  1.3742, -1.5360,  4.2982,  3.8134,  4.1333,\n",
            "        -1.6728, -0.0977, -1.9360, -0.6024, -0.3156,  2.9565, -1.1192,  0.4873,\n",
            "         0.1290,  2.0861,  2.9000, -0.7849,  2.9924,  1.0049, -0.7367,  0.9882,\n",
            "        -2.5409,  0.5058,  1.1869, -0.4053, -0.5593, -0.7515, -1.5733,  3.2707,\n",
            "         2.0882,  1.5343,  1.7186, -1.2632,  1.8094, -1.1516,  0.8330,  2.7388,\n",
            "        -0.5501,  3.9273,  2.5830,  1.9357,  0.1513,  0.2382,  2.4743, -2.4327,\n",
            "        -0.4467,  0.0833, -0.8730,  2.4050,  1.1043,  4.2948,  4.8334, -4.7448,\n",
            "        -3.7237,  1.7167, -3.4531,  3.1329, -0.5342, -1.6793,  0.0879, -2.4586,\n",
            "         3.1886,  2.3745,  3.4076,  2.0348,  3.5797,  0.9006, -1.1278, -1.2251,\n",
            "         0.1776, -3.0732, -1.2610,  0.3307, -1.8673,  2.5607,  0.9499, -3.2914,\n",
            "         2.2595, -0.5423, -0.2501,  0.4810, -3.2585, -4.0722, -2.8229,  0.2329,\n",
            "         1.3874,  0.8555, -2.8414, -0.6500,  0.1246,  1.4108, -5.2965, -2.9796,\n",
            "         1.3043,  0.7424,  0.5108, -1.0009, -2.9546,  1.8292,  4.0311,  2.5396,\n",
            "         1.9403,  3.4348, -2.1970, -0.5791, -2.5447,  0.8929,  1.5158, -0.2683,\n",
            "        -3.5874, -0.7844,  3.4818, -0.2797,  0.8251,  1.4145,  2.3237, -1.7777,\n",
            "         3.2349, -4.3614,  1.1945,  1.5357,  3.0125,  0.2059, -0.5754, -4.0562])), ('module.encoder_k.layer2.2.bn1.running_var', tensor([ 8.7901,  6.5286,  6.5347,  8.4341,  8.8944,  8.8045, 13.1530, 10.9078,\n",
            "         7.3433,  6.1086,  7.7915,  7.4147,  8.8597,  7.8892, 11.5591,  6.6968,\n",
            "         6.2858,  8.4854, 12.8488,  8.3842,  7.8561,  8.8378,  6.3794, 12.5411,\n",
            "         7.0158,  7.5952, 10.5414,  8.0216,  9.4178,  8.3324,  6.6180,  7.2429,\n",
            "        12.4598,  8.6730, 12.0682,  9.2762, 10.4190,  7.2016,  6.9803, 14.5358,\n",
            "         8.9128, 12.8160,  5.8335,  8.6135,  9.5450,  7.3240, 11.6157,  9.8798,\n",
            "         6.9525,  9.0090,  6.1058,  7.9443,  9.4861, 13.9614, 17.8703, 12.2996,\n",
            "         6.0310,  7.7660,  7.1346,  7.6779,  6.9550,  8.0786,  6.1158, 12.7600,\n",
            "        10.3408,  6.1003, 10.6064,  8.6982, 12.0373,  7.5888,  7.3379,  7.9086,\n",
            "         5.5723,  7.8106,  7.7704,  6.0011,  8.7378,  8.1393,  5.7161,  6.4599,\n",
            "         8.5279,  8.9110, 10.2762,  6.4057, 11.2475,  6.9458,  7.5879,  7.4649,\n",
            "         8.0513,  9.3424,  6.1870,  8.7555,  8.1383,  7.4660,  8.7790,  5.4439,\n",
            "         6.2449,  6.5283,  7.0320, 12.1280,  7.7963,  4.9321,  7.8374,  9.5137,\n",
            "        11.3329,  8.0647,  9.3109, 11.2873, 13.7468,  7.5795,  7.0788,  8.4594,\n",
            "         8.3864,  7.0645,  9.5086, 12.4271,  9.6056,  8.1483,  7.0404,  8.0750,\n",
            "        12.6461, 13.2035,  9.5676,  8.7942,  8.6209,  8.1769,  5.1876,  9.2180])), ('module.encoder_k.layer2.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.2.conv2.weight', tensor([[[[-0.0008, -0.0736, -0.0114],\n",
            "          [ 0.0287, -0.0196, -0.0664],\n",
            "          [ 0.0191, -0.0261,  0.0586]],\n",
            "\n",
            "         [[ 0.1024, -0.0067,  0.0284],\n",
            "          [-0.0594, -0.0137,  0.0150],\n",
            "          [-0.0222,  0.0523, -0.0560]],\n",
            "\n",
            "         [[ 0.0336, -0.0133,  0.0679],\n",
            "          [ 0.0466, -0.1148,  0.0169],\n",
            "          [-0.0538,  0.0191, -0.0169]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0362, -0.0241, -0.0217],\n",
            "          [-0.0470,  0.0350, -0.0307],\n",
            "          [ 0.0400, -0.0085, -0.0717]],\n",
            "\n",
            "         [[ 0.0712, -0.0520,  0.0471],\n",
            "          [-0.0483,  0.0108,  0.0474],\n",
            "          [-0.0020, -0.0076, -0.0108]],\n",
            "\n",
            "         [[-0.0051, -0.0131,  0.0613],\n",
            "          [-0.0397,  0.0182, -0.0300],\n",
            "          [-0.0044, -0.0214,  0.0525]]],\n",
            "\n",
            "\n",
            "        [[[-0.0220,  0.0522, -0.0023],\n",
            "          [ 0.0508, -0.0768,  0.0199],\n",
            "          [-0.0233,  0.0071,  0.0464]],\n",
            "\n",
            "         [[ 0.0100, -0.0113, -0.0227],\n",
            "          [ 0.0358,  0.0771, -0.0055],\n",
            "          [-0.0118, -0.0194,  0.0097]],\n",
            "\n",
            "         [[-0.0048, -0.0254, -0.0046],\n",
            "          [-0.0487, -0.0319,  0.0693],\n",
            "          [ 0.0684, -0.0049, -0.0575]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0007,  0.1038,  0.0122],\n",
            "          [-0.0580,  0.0605, -0.0198],\n",
            "          [ 0.0264, -0.0681,  0.0706]],\n",
            "\n",
            "         [[ 0.0165, -0.0138, -0.0261],\n",
            "          [-0.0026, -0.0150, -0.0128],\n",
            "          [ 0.0595, -0.0017, -0.0155]],\n",
            "\n",
            "         [[ 0.0435,  0.0279, -0.0239],\n",
            "          [ 0.0151, -0.0184, -0.0162],\n",
            "          [ 0.0175,  0.0967,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0019,  0.0059, -0.0226],\n",
            "          [-0.0771,  0.0478, -0.0391],\n",
            "          [-0.0390, -0.0412, -0.0274]],\n",
            "\n",
            "         [[-0.0088, -0.0371, -0.0139],\n",
            "          [-0.0600, -0.0350,  0.0372],\n",
            "          [ 0.0027, -0.0654,  0.0160]],\n",
            "\n",
            "         [[-0.0448,  0.0892,  0.0442],\n",
            "          [-0.0875,  0.0396, -0.0700],\n",
            "          [-0.0504,  0.0255, -0.0078]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0160,  0.0047, -0.0279],\n",
            "          [-0.0259,  0.0175, -0.0409],\n",
            "          [-0.0353,  0.0024,  0.0336]],\n",
            "\n",
            "         [[-0.0386, -0.0325,  0.0198],\n",
            "          [ 0.0431,  0.0265, -0.0412],\n",
            "          [ 0.0346, -0.1294,  0.0195]],\n",
            "\n",
            "         [[ 0.0330, -0.0508,  0.0492],\n",
            "          [ 0.0059,  0.0114,  0.0413],\n",
            "          [ 0.0375,  0.0812,  0.0348]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0772, -0.0332, -0.0439],\n",
            "          [ 0.0363,  0.0087, -0.0547],\n",
            "          [ 0.0090,  0.0654, -0.0231]],\n",
            "\n",
            "         [[-0.0337,  0.0104,  0.0366],\n",
            "          [ 0.0595,  0.0371, -0.0035],\n",
            "          [-0.0086,  0.0585,  0.0345]],\n",
            "\n",
            "         [[-0.0015,  0.0428, -0.0483],\n",
            "          [-0.0675, -0.0096, -0.0474],\n",
            "          [ 0.0086,  0.0747,  0.0337]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0179, -0.0651,  0.0167],\n",
            "          [-0.0551,  0.0552,  0.0395],\n",
            "          [-0.0780,  0.0808, -0.0362]],\n",
            "\n",
            "         [[-0.0263, -0.0076, -0.0852],\n",
            "          [ 0.0304, -0.0303, -0.0306],\n",
            "          [ 0.0606,  0.0325, -0.0070]],\n",
            "\n",
            "         [[-0.0130,  0.0712, -0.0530],\n",
            "          [ 0.0215, -0.0058, -0.0222],\n",
            "          [-0.0174,  0.0241,  0.0048]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0339,  0.0149,  0.0371],\n",
            "          [-0.0466, -0.0518,  0.0487],\n",
            "          [-0.0024, -0.0125,  0.0657]],\n",
            "\n",
            "         [[-0.0359, -0.0229, -0.0157],\n",
            "          [-0.0382,  0.0110, -0.0471],\n",
            "          [ 0.0513, -0.0803,  0.0449]],\n",
            "\n",
            "         [[-0.0123, -0.0219, -0.0196],\n",
            "          [ 0.0412, -0.0022, -0.0250],\n",
            "          [-0.0112, -0.0285,  0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0176,  0.0228, -0.0677],\n",
            "          [ 0.0416, -0.0011,  0.0252],\n",
            "          [-0.0688, -0.0422, -0.0265]],\n",
            "\n",
            "         [[-0.0821, -0.0201, -0.0533],\n",
            "          [-0.0037,  0.0241, -0.0684],\n",
            "          [ 0.0151,  0.0026, -0.0130]],\n",
            "\n",
            "         [[-0.0113,  0.0531,  0.0686],\n",
            "          [-0.0408,  0.0258,  0.0459],\n",
            "          [-0.0481,  0.0676,  0.0113]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0404,  0.0022, -0.1215],\n",
            "          [-0.0684, -0.0090, -0.0113],\n",
            "          [-0.0810,  0.0176, -0.0055]],\n",
            "\n",
            "         [[ 0.0484, -0.0224, -0.0305],\n",
            "          [-0.0028,  0.0186,  0.0033],\n",
            "          [ 0.1007, -0.0687,  0.0803]],\n",
            "\n",
            "         [[ 0.0017, -0.0543,  0.0378],\n",
            "          [ 0.0646,  0.0655, -0.0087],\n",
            "          [ 0.0668, -0.0582,  0.0046]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0234, -0.0229,  0.0221],\n",
            "          [-0.0054,  0.0254,  0.0571],\n",
            "          [-0.0089,  0.0120,  0.0108]],\n",
            "\n",
            "         [[-0.0851, -0.0020,  0.0149],\n",
            "          [ 0.0155, -0.0230,  0.0504],\n",
            "          [-0.0344,  0.0393,  0.0489]],\n",
            "\n",
            "         [[-0.0186, -0.0226,  0.0079],\n",
            "          [ 0.0558,  0.0059, -0.0415],\n",
            "          [-0.0718,  0.0875, -0.0015]]]])), ('module.encoder_k.layer2.2.bn2.weight', tensor([0.9998, 0.9994, 0.9988, 0.9990, 0.9990, 0.9990, 0.9992, 0.9985, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9987, 0.9992, 0.9994, 1.0001, 0.9994,\n",
            "        0.9987, 0.9989, 0.9996, 0.9995, 0.9994, 0.9990, 0.9990, 0.9995, 0.9982,\n",
            "        0.9986, 0.9991, 0.9992, 0.9988, 0.9991, 0.9995, 0.9994, 0.9981, 0.9985,\n",
            "        0.9998, 0.9996, 0.9995, 0.9987, 0.9993, 0.9986, 0.9998, 0.9991, 0.9992,\n",
            "        0.9987, 0.9992, 0.9992, 0.9993, 0.9988, 0.9992, 0.9992, 0.9990, 0.9991,\n",
            "        0.9993, 0.9992, 0.9993, 0.9984, 0.9987, 0.9989, 0.9991, 0.9984, 0.9988,\n",
            "        0.9989, 0.9990, 0.9991, 0.9998, 0.9989, 1.0000, 0.9991, 0.9987, 0.9990,\n",
            "        0.9990, 0.9987, 0.9987, 0.9991, 0.9995, 0.9990, 0.9992, 0.9990, 0.9990,\n",
            "        0.9994, 0.9989, 0.9993, 0.9993, 0.9993, 0.9991, 0.9992, 0.9986, 0.9995,\n",
            "        0.9994, 0.9989, 0.9986, 0.9989, 0.9991, 0.9989, 0.9988, 0.9993, 0.9992,\n",
            "        0.9990, 0.9985, 0.9992, 0.9992, 0.9987, 0.9991, 0.9986, 0.9991, 0.9989,\n",
            "        0.9986, 0.9992, 0.9990, 0.9985, 0.9995, 0.9992, 0.9990, 0.9995, 0.9994,\n",
            "        0.9989, 0.9988, 0.9991, 0.9989, 0.9989, 0.9993, 0.9993, 0.9988, 0.9994,\n",
            "        0.9993, 0.9994])), ('module.encoder_k.layer2.2.bn2.bias', tensor([ 4.6324e-04,  3.6745e-04, -1.6366e-04,  2.7415e-04, -4.4301e-04,\n",
            "         7.4146e-05,  1.6603e-04, -4.4843e-04,  1.0405e-05,  1.5050e-05,\n",
            "        -1.4181e-04, -6.0131e-04,  1.6459e-04, -4.1694e-04, -6.8353e-05,\n",
            "         4.1236e-04,  5.4287e-04,  2.6394e-04, -2.2273e-04, -6.0660e-04,\n",
            "         9.6743e-04,  6.8540e-04,  5.9438e-04, -9.7570e-05, -5.6976e-04,\n",
            "         4.6076e-04, -5.4878e-04, -3.5206e-04,  4.3058e-04, -4.7209e-04,\n",
            "        -9.5694e-05, -1.6215e-04,  3.1080e-04,  3.4267e-04, -6.0193e-04,\n",
            "        -4.2542e-04,  7.2530e-04,  5.2373e-04,  7.9256e-05, -4.2490e-04,\n",
            "         1.3874e-04, -6.4865e-04,  3.5187e-04, -7.9505e-04, -2.5975e-05,\n",
            "        -5.0220e-04,  2.0950e-04,  1.6568e-05,  1.7857e-04, -1.8763e-04,\n",
            "        -4.1474e-04,  3.3849e-04, -1.7517e-04,  5.2978e-05,  4.2576e-04,\n",
            "         8.4698e-05,  4.0377e-04, -4.3460e-04, -1.8328e-04, -5.0439e-04,\n",
            "         1.1749e-04, -6.1153e-04, -1.2147e-04, -5.5333e-04, -8.8737e-06,\n",
            "         3.0220e-04,  1.3112e-04, -1.5797e-04,  3.5967e-04,  1.2766e-04,\n",
            "        -3.8780e-04,  3.0760e-04,  3.4662e-04,  1.2251e-05, -2.2531e-04,\n",
            "        -1.0958e-04,  4.0454e-04,  2.8641e-04,  3.6614e-04,  4.7586e-04,\n",
            "         1.1442e-04,  8.2125e-05,  2.8691e-04,  2.6508e-04, -6.9981e-05,\n",
            "        -1.2553e-04, -2.4988e-04, -7.6529e-05,  1.5264e-05,  1.5922e-04,\n",
            "         2.8307e-04, -1.9384e-06, -1.6185e-04, -3.5239e-05,  3.4036e-04,\n",
            "         1.3995e-05, -3.6744e-04,  2.4378e-04,  5.3084e-04,  2.3466e-04,\n",
            "        -3.9555e-04, -1.7562e-04, -3.4782e-04, -1.9358e-04, -7.3552e-05,\n",
            "        -3.4235e-04, -1.7121e-04, -6.6233e-04,  1.8011e-04,  1.1937e-04,\n",
            "        -1.9902e-05, -2.7147e-04,  4.6721e-04,  3.3483e-04, -2.1041e-04,\n",
            "         3.3047e-04,  6.6333e-04,  4.5829e-04, -3.5291e-04,  9.4200e-05,\n",
            "        -2.8873e-04, -1.6969e-04,  7.4386e-05,  1.7193e-04, -1.8165e-04,\n",
            "         3.7675e-04,  1.8478e-04, -1.8882e-05])), ('module.encoder_k.layer2.2.bn2.running_mean', tensor([ 0.3851, -0.5950, -0.3311, -0.3827,  0.3534, -0.5883, -0.1329, -0.0367,\n",
            "         0.3020,  0.2444, -0.7602, -0.4610, -0.1637,  0.1141,  0.9113, -0.0629,\n",
            "         0.3558, -0.9368,  0.5176,  0.0859, -0.2038,  1.4676,  0.1072, -0.9314,\n",
            "        -0.5353,  0.5262, -0.1299,  0.0180, -0.4649,  0.0753,  0.9059, -0.3776,\n",
            "        -0.1920, -0.4478,  0.0925, -0.1120, -0.6079, -0.5555,  0.0599,  0.0683,\n",
            "         0.0885,  0.1884, -0.1290,  0.7341, -0.4104,  0.9885,  0.6829,  1.4259,\n",
            "        -0.5388,  0.6717, -0.8358,  0.0527, -0.0035,  0.0185, -0.1177,  0.4342,\n",
            "        -0.3459,  0.6455, -0.2859, -0.5699, -0.8352, -0.3560, -0.4229,  0.1053,\n",
            "        -0.1596, -0.1980,  0.2341, -0.4358,  0.4128, -0.7951,  0.9399,  0.1350,\n",
            "         0.1929, -0.6718,  0.6509, -0.3614, -0.1128, -0.3395, -0.4512,  0.2359,\n",
            "         0.8206, -0.1632,  0.4320, -0.0681, -0.0575, -0.1033,  0.4459, -0.8742,\n",
            "         0.7589,  0.0945,  0.0423,  0.0847, -0.6379, -1.2312, -0.1565, -0.2743,\n",
            "        -1.5124, -0.0219,  0.5700,  0.4829,  0.9174, -0.4358,  0.3779, -0.4246,\n",
            "        -0.0379, -0.2871,  0.1641, -0.4269,  0.5734,  0.3476,  1.2329,  0.8432,\n",
            "         0.7191, -0.5936,  0.3677, -0.7899,  0.2176,  0.7832, -0.4907, -0.0835,\n",
            "        -0.0654, -0.5050, -0.3917,  0.5647,  0.0038,  0.0377,  0.4805,  0.0251])), ('module.encoder_k.layer2.2.bn2.running_var', tensor([0.8669, 1.4439, 0.6026, 0.6686, 0.5034, 0.6422, 0.6515, 0.9150, 0.5553,\n",
            "        0.6113, 0.5996, 0.9824, 0.7066, 0.5633, 0.9074, 0.5514, 0.5296, 1.1930,\n",
            "        0.6355, 0.7879, 0.6039, 1.6436, 0.5268, 0.9181, 0.6608, 0.6984, 0.8057,\n",
            "        0.6451, 0.5642, 0.6228, 0.5939, 0.5805, 0.6005, 1.1708, 0.5598, 0.9881,\n",
            "        0.6714, 0.7761, 0.6847, 0.5871, 0.5638, 0.8580, 0.6771, 1.3365, 0.7681,\n",
            "        1.1004, 1.0182, 1.7643, 0.8282, 0.7218, 0.6133, 0.8367, 0.6490, 0.5836,\n",
            "        0.6791, 0.6080, 0.9060, 0.6244, 0.6292, 0.7452, 1.0742, 0.9052, 0.6996,\n",
            "        0.6610, 0.6686, 0.6072, 0.7274, 0.6707, 0.5851, 0.7835, 0.8910, 0.5758,\n",
            "        0.7132, 0.8065, 0.5791, 0.5846, 0.6224, 0.6704, 0.4855, 0.9360, 1.0439,\n",
            "        0.6707, 0.9954, 0.6220, 0.7361, 0.6828, 0.9496, 0.9100, 1.0121, 0.5072,\n",
            "        0.6662, 0.6552, 0.6848, 0.7636, 0.5279, 0.6709, 1.3379, 0.7507, 1.0629,\n",
            "        0.5814, 0.6656, 0.5758, 0.6667, 0.6983, 0.5611, 0.7378, 0.9803, 0.7047,\n",
            "        0.5993, 0.7039, 1.8311, 0.7175, 0.6994, 0.6887, 0.5022, 0.7577, 0.6545,\n",
            "        1.3089, 0.7827, 0.5893, 0.7152, 0.6882, 0.5968, 1.1866, 0.7234, 0.5525,\n",
            "        0.7913, 0.5467])), ('module.encoder_k.layer2.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.2.conv3.weight', tensor([[[[ 0.0978]],\n",
            "\n",
            "         [[-0.1222]],\n",
            "\n",
            "         [[-0.0241]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0259]],\n",
            "\n",
            "         [[-0.0254]],\n",
            "\n",
            "         [[-0.1623]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0433]],\n",
            "\n",
            "         [[ 0.0091]],\n",
            "\n",
            "         [[-0.1112]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0039]],\n",
            "\n",
            "         [[ 0.0297]],\n",
            "\n",
            "         [[ 0.0828]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0074]],\n",
            "\n",
            "         [[-0.0622]],\n",
            "\n",
            "         [[ 0.0550]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0456]],\n",
            "\n",
            "         [[ 0.0533]],\n",
            "\n",
            "         [[-0.0983]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1225]],\n",
            "\n",
            "         [[-0.0376]],\n",
            "\n",
            "         [[ 0.0846]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0456]],\n",
            "\n",
            "         [[-0.0558]],\n",
            "\n",
            "         [[ 0.0368]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0690]],\n",
            "\n",
            "         [[ 0.0366]],\n",
            "\n",
            "         [[ 0.0331]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0670]],\n",
            "\n",
            "         [[-0.0253]],\n",
            "\n",
            "         [[-0.0917]]],\n",
            "\n",
            "\n",
            "        [[[-0.0376]],\n",
            "\n",
            "         [[-0.0169]],\n",
            "\n",
            "         [[ 0.0967]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1007]],\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[-0.0750]]]])), ('module.encoder_k.layer2.2.bn3.weight', tensor([0.9992, 0.9989, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9989, 0.9993, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9988, 0.9992,\n",
            "        0.9992, 0.9990, 0.9993, 0.9991, 0.9990, 0.9987, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9992, 0.9989, 0.9988, 0.9992, 0.9991, 0.9990, 0.9988,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9992, 0.9988, 0.9989, 0.9990,\n",
            "        0.9991, 0.9988, 0.9989, 0.9990, 0.9990, 0.9991, 0.9994, 0.9990, 0.9993,\n",
            "        0.9989, 0.9993, 0.9993, 0.9993, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9989, 0.9992, 0.9989, 0.9992, 0.9993, 0.9990, 0.9990, 0.9993, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9996, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990,\n",
            "        0.9993, 0.9989, 0.9990, 0.9991, 0.9991, 0.9990, 0.9993, 0.9991, 0.9989,\n",
            "        0.9991, 0.9992, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9989, 0.9991, 0.9993, 0.9991, 0.9994, 0.9992, 0.9990, 0.9992,\n",
            "        0.9989, 0.9990, 0.9989, 0.9992, 0.9992, 0.9990, 0.9991, 0.9993, 0.9990,\n",
            "        0.9992, 0.9992, 0.9992, 0.9991, 0.9993, 0.9994, 0.9994, 0.9989, 0.9989,\n",
            "        0.9990, 0.9992, 0.9991, 0.9989, 0.9989, 0.9989, 0.9993, 0.9991, 0.9990,\n",
            "        0.9992, 0.9992, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9988, 0.9988,\n",
            "        0.9990, 0.9992, 0.9992, 0.9991, 0.9992, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9989, 0.9995, 0.9991, 0.9993, 0.9990, 0.9991, 0.9989, 0.9991, 0.9988,\n",
            "        0.9992, 0.9991, 0.9989, 0.9991, 0.9991, 0.9989, 0.9992, 0.9988, 0.9991,\n",
            "        0.9992, 0.9995, 0.9993, 0.9989, 0.9989, 0.9990, 0.9991, 0.9991, 0.9988,\n",
            "        0.9990, 0.9994, 0.9990, 0.9990, 0.9991, 0.9990, 0.9992, 0.9989, 0.9988,\n",
            "        0.9989, 0.9989, 0.9990, 0.9993, 0.9990, 0.9992, 0.9992, 0.9989, 0.9989,\n",
            "        0.9992, 0.9990, 0.9993, 0.9992, 0.9990, 0.9990, 0.9989, 0.9992, 0.9995,\n",
            "        0.9991, 0.9989, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9989, 0.9990, 0.9991, 0.9992, 0.9990, 0.9991, 0.9990, 0.9989, 0.9992,\n",
            "        0.9994, 0.9990, 0.9990, 0.9987, 0.9991, 0.9989, 0.9991, 0.9991, 0.9992,\n",
            "        0.9993, 0.9991, 0.9988, 0.9990, 0.9991, 0.9990, 0.9990, 0.9992, 0.9992,\n",
            "        0.9992, 0.9992, 0.9988, 0.9989, 0.9990, 0.9991, 0.9990, 0.9991, 0.9987,\n",
            "        0.9987, 0.9990, 0.9991, 0.9989, 0.9991, 0.9989, 0.9989, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9993, 0.9990, 0.9990, 0.9991, 0.9993,\n",
            "        0.9992, 0.9991, 0.9992, 0.9995, 0.9990, 0.9993, 0.9990, 0.9987, 0.9991,\n",
            "        0.9991, 0.9993, 0.9990, 0.9991, 0.9989, 0.9990, 0.9992, 0.9990, 0.9989,\n",
            "        0.9994, 0.9990, 0.9992, 0.9989, 0.9993, 0.9990, 0.9991, 0.9992, 0.9994,\n",
            "        0.9991, 0.9990, 0.9992, 0.9990, 0.9990, 0.9993, 0.9990, 0.9994, 0.9990,\n",
            "        0.9992, 0.9992, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9992, 0.9990, 0.9994, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9992, 0.9990, 0.9991, 0.9992, 0.9991, 0.9993, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9992, 0.9986, 0.9989, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9993, 0.9991, 0.9991, 0.9992, 0.9990, 0.9993,\n",
            "        0.9991, 0.9989, 0.9992, 0.9992, 0.9990, 0.9993, 0.9989, 0.9989, 0.9992,\n",
            "        0.9991, 0.9991, 0.9992, 0.9989, 0.9989, 0.9989, 0.9990, 0.9992, 0.9992,\n",
            "        0.9987, 0.9994, 0.9992, 0.9990, 0.9991, 0.9991, 0.9994, 0.9992, 0.9992,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9989, 0.9991, 0.9989, 0.9990,\n",
            "        0.9990, 0.9992, 0.9993, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9988, 0.9988, 0.9988, 0.9991, 0.9992, 0.9992, 0.9991, 0.9990,\n",
            "        0.9989, 0.9991, 0.9988, 0.9992, 0.9992, 0.9992, 0.9993, 0.9992, 0.9992,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9992, 0.9988, 0.9989, 0.9993, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9989, 0.9992, 0.9991, 0.9990, 0.9989, 0.9990,\n",
            "        0.9990, 0.9991, 0.9992, 0.9992, 0.9988, 0.9995, 0.9991, 0.9991, 0.9992,\n",
            "        0.9992, 0.9989, 0.9990, 0.9991, 0.9992, 0.9988, 0.9991, 0.9993, 0.9989,\n",
            "        0.9992, 0.9992, 0.9990, 0.9989, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9988, 0.9989, 0.9991, 0.9989, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9989,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9993, 0.9990, 0.9989, 0.9990, 0.9991,\n",
            "        0.9993, 0.9988, 0.9993, 0.9993, 0.9992, 0.9994, 0.9991, 0.9989, 0.9990,\n",
            "        0.9990, 0.9992, 0.9990, 0.9992, 0.9990, 0.9991, 0.9993, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9995, 0.9993, 0.9990, 0.9991, 0.9992])), ('module.encoder_k.layer2.2.bn3.bias', tensor([ 1.4096e-04,  3.0026e-04,  1.5273e-04, -1.6439e-04,  4.7519e-06,\n",
            "         2.2317e-04,  6.1999e-05, -3.1773e-05, -2.1935e-05, -5.1847e-05,\n",
            "         5.6346e-05,  2.0618e-04,  1.5549e-04,  9.1671e-05, -2.2488e-05,\n",
            "        -3.2525e-05, -7.1699e-05, -1.3597e-04,  7.9930e-05, -3.7043e-05,\n",
            "         1.5948e-04, -2.8228e-05, -1.0344e-04, -4.2862e-05, -3.1468e-05,\n",
            "        -1.4067e-05, -6.4981e-05,  6.3536e-05, -6.6813e-05,  8.1193e-05,\n",
            "        -1.4982e-04,  2.2063e-05, -1.5743e-06, -4.1225e-05, -3.7518e-06,\n",
            "        -2.5089e-04,  4.2920e-05,  5.9337e-05,  1.4597e-04,  2.1971e-04,\n",
            "         1.7055e-04,  6.3079e-05,  4.3945e-05, -5.6916e-05,  1.5778e-04,\n",
            "        -4.9843e-05, -2.3382e-05,  3.4911e-05, -1.4739e-04, -4.6716e-05,\n",
            "         5.1576e-05, -3.1705e-04, -9.2514e-05, -7.9733e-05, -6.8156e-05,\n",
            "         4.4392e-06, -8.0234e-05,  1.5236e-04,  1.1183e-04, -4.0665e-05,\n",
            "        -1.7216e-04, -9.2847e-06, -5.6854e-06,  5.8277e-05, -1.8182e-06,\n",
            "        -1.1894e-04,  1.3804e-04, -1.8419e-05,  1.9838e-04, -1.2155e-04,\n",
            "         3.3951e-05,  9.3768e-05, -7.7559e-05, -2.5486e-05,  9.4988e-05,\n",
            "         2.8192e-04,  2.7148e-06,  1.5827e-04,  3.9744e-05,  1.0554e-04,\n",
            "        -2.7071e-04,  6.0575e-05,  1.4627e-05,  2.3388e-04, -7.8987e-05,\n",
            "        -8.2611e-05,  9.7912e-05, -3.2976e-06,  2.4772e-04, -1.1721e-05,\n",
            "        -1.4315e-04, -4.1372e-05, -1.0405e-04, -1.4827e-04, -7.4201e-05,\n",
            "         7.3764e-05, -4.1847e-05, -1.4060e-04,  9.1801e-05,  3.4154e-05,\n",
            "         5.8910e-05,  5.0444e-05, -1.4775e-04, -3.9766e-05,  8.2753e-05,\n",
            "        -7.6474e-05, -1.2044e-04, -1.1372e-06, -1.1550e-04,  9.7565e-06,\n",
            "        -2.0573e-05,  9.9371e-05,  3.2844e-04, -1.0703e-04,  8.5365e-05,\n",
            "         1.1802e-05,  4.7698e-05, -1.6565e-05, -1.4002e-04, -2.8904e-04,\n",
            "         4.1003e-05,  1.1164e-04,  8.6990e-05, -1.7762e-04,  8.0420e-05,\n",
            "        -1.4021e-04,  1.4072e-04, -1.1832e-05,  1.0145e-04,  1.1136e-05,\n",
            "         1.8516e-04,  2.8934e-05,  1.6047e-04, -9.3573e-05,  1.4927e-06,\n",
            "         8.0350e-05,  2.5743e-05, -2.3140e-05, -8.5568e-05,  1.1579e-04,\n",
            "        -1.9852e-04,  5.3577e-05, -1.4790e-04,  8.3302e-05, -3.6432e-04,\n",
            "        -1.7372e-04,  1.3492e-04,  5.8966e-05,  1.4393e-04, -9.1844e-05,\n",
            "         6.1862e-05,  1.7562e-04, -5.3658e-05, -1.7410e-04,  3.2453e-05,\n",
            "         7.4987e-05, -1.1838e-05,  3.0888e-05,  7.1135e-05, -5.1324e-05,\n",
            "         5.0772e-05,  5.3773e-05, -5.6766e-05, -6.1605e-05, -2.7418e-04,\n",
            "         2.0790e-04,  1.6187e-04,  3.9333e-06,  2.6211e-05, -3.3238e-04,\n",
            "         2.4907e-05,  3.3753e-04,  8.2150e-05, -9.1623e-05, -7.7348e-05,\n",
            "        -1.0850e-04, -2.6662e-05, -1.9254e-05, -3.0083e-06, -2.6230e-05,\n",
            "         4.6614e-05,  8.4829e-05,  6.7817e-05,  1.4348e-04,  9.9876e-05,\n",
            "         1.3707e-04,  1.0296e-04, -1.3902e-05, -9.5203e-05, -1.1707e-04,\n",
            "        -1.6096e-04,  4.0352e-05, -1.0467e-04, -1.3550e-04,  2.9004e-04,\n",
            "        -1.8089e-04, -1.2126e-04,  1.3734e-04,  1.2342e-04,  9.0230e-05,\n",
            "        -1.5866e-05, -1.2116e-04,  1.2491e-05, -2.6240e-04, -1.9790e-04,\n",
            "         1.9728e-04,  2.9577e-05, -4.6671e-05, -4.2197e-05,  5.2854e-05,\n",
            "         1.8466e-04,  6.0734e-05, -7.6134e-05, -3.6035e-04, -1.0685e-04,\n",
            "        -6.5353e-05, -7.4053e-05, -2.3723e-04,  6.5928e-05, -3.2725e-05,\n",
            "        -8.5584e-05,  1.4269e-04, -3.9642e-05, -5.9577e-06,  5.1138e-05,\n",
            "         1.5450e-04,  3.4214e-05, -1.5548e-04,  1.2837e-05,  3.4809e-05,\n",
            "        -1.1823e-04,  1.6169e-05, -2.2007e-04,  1.1907e-04, -1.1550e-04,\n",
            "        -9.2030e-05,  5.7082e-05,  7.9619e-05,  1.9403e-05,  1.9371e-04,\n",
            "         1.1734e-04,  7.2329e-05,  5.5909e-06,  7.6901e-05, -1.2350e-04,\n",
            "        -8.5190e-05, -1.5065e-04,  8.1320e-05,  8.9898e-06, -1.0160e-05,\n",
            "         2.0758e-04, -5.3178e-05, -2.5157e-04, -7.0808e-05, -6.9729e-05,\n",
            "        -1.7101e-04,  1.4736e-04,  1.5817e-04,  5.8996e-05, -7.4956e-05,\n",
            "         1.0334e-04,  3.0086e-05,  1.1873e-04, -8.1528e-06, -1.7031e-05,\n",
            "        -8.3859e-05, -1.0548e-04,  2.5915e-05,  2.2866e-04,  1.9215e-04,\n",
            "         2.9697e-05, -1.7246e-04,  6.3393e-05,  1.3040e-04, -6.4131e-05,\n",
            "         1.7292e-04, -8.2773e-05, -1.7737e-04, -1.6544e-04,  1.7869e-04,\n",
            "        -3.2052e-05, -6.5232e-05, -2.8118e-05,  1.3163e-04,  1.6066e-04,\n",
            "         1.3068e-04, -3.6138e-04, -3.8920e-04,  2.3724e-04,  1.1671e-04,\n",
            "        -1.6217e-04, -6.7505e-05, -9.1804e-05,  5.5505e-05,  5.2614e-05,\n",
            "        -3.5125e-05, -5.3621e-05,  1.1386e-04, -1.6678e-05,  1.4130e-04,\n",
            "        -6.3286e-05, -6.0856e-05,  7.9379e-06,  3.5878e-05,  1.8104e-04,\n",
            "         2.4595e-04,  1.4245e-05, -1.0195e-04,  3.1712e-06, -1.0046e-04,\n",
            "         6.9175e-05,  1.6019e-04,  1.6688e-05, -1.2528e-04, -3.4644e-05,\n",
            "         4.7826e-05, -1.6392e-05,  1.5668e-05,  5.0133e-05, -1.0769e-04,\n",
            "         8.7664e-05, -4.1503e-05, -6.3181e-05,  1.7366e-04,  2.5580e-04,\n",
            "        -1.1093e-04, -4.3667e-05,  6.2892e-05,  1.0158e-04,  1.2402e-04,\n",
            "        -6.8011e-05,  3.5123e-05, -7.8385e-05,  1.0098e-04,  1.4108e-04,\n",
            "        -1.1860e-05, -4.8983e-07, -2.7066e-04, -3.2885e-05,  9.6485e-05,\n",
            "         4.0144e-04, -7.5000e-05,  1.4697e-04,  1.2797e-04,  4.1615e-05,\n",
            "         7.0566e-05, -8.2042e-05,  3.3844e-05, -6.9354e-05, -1.4945e-06,\n",
            "         4.1449e-05, -1.8131e-06, -1.3269e-04,  1.7605e-04,  6.8182e-05,\n",
            "        -6.5690e-06,  7.1270e-05, -1.8506e-04,  2.4349e-04, -1.1705e-04,\n",
            "        -7.2599e-05,  2.0333e-04,  8.6467e-05, -6.1587e-05,  2.1157e-04,\n",
            "        -1.3471e-04,  1.1378e-04,  1.4308e-04,  9.9811e-05, -2.3351e-04,\n",
            "        -4.0803e-05,  2.5350e-04,  1.4793e-04,  2.1069e-05,  2.5577e-04,\n",
            "        -7.9915e-05,  1.1106e-04, -1.8387e-04,  1.8179e-04,  8.8709e-05,\n",
            "         1.2634e-04,  1.0176e-04, -6.8767e-05, -5.0550e-05,  9.9367e-05,\n",
            "        -1.6980e-04,  1.4388e-04,  1.1640e-04,  5.7987e-05, -4.3310e-06,\n",
            "        -3.4772e-06,  6.3630e-05, -1.7999e-05,  2.6380e-05,  1.0097e-04,\n",
            "        -1.8209e-04,  1.9226e-04, -4.1546e-07,  1.4989e-05, -3.1448e-05,\n",
            "        -1.7238e-04,  2.0359e-04, -6.4575e-05, -1.7578e-05, -1.3466e-04,\n",
            "        -1.2799e-04, -1.2506e-04, -6.5506e-05, -1.8743e-04,  1.8330e-04,\n",
            "         1.4695e-04, -3.4473e-04,  4.7344e-05,  1.1177e-05,  8.5164e-06,\n",
            "         2.4628e-05,  8.8484e-05, -1.0043e-04, -6.9753e-05, -9.4260e-05,\n",
            "         1.3195e-04,  2.2518e-05,  8.7857e-05, -7.3100e-05,  1.1564e-05,\n",
            "         1.6264e-04, -3.9077e-05,  7.8991e-05,  6.5922e-06, -3.8542e-05,\n",
            "         8.4705e-05,  7.8031e-05, -6.6206e-05, -2.3156e-05,  1.2753e-04,\n",
            "         8.0818e-05,  1.6084e-04,  1.2385e-04, -1.1231e-04,  5.7477e-05,\n",
            "         6.2795e-05,  4.6240e-05,  6.6681e-05, -3.3486e-05, -1.8843e-05,\n",
            "        -9.5823e-05,  1.0560e-04, -8.5015e-05,  2.5534e-04, -9.6458e-05,\n",
            "        -2.8491e-05, -2.3644e-04, -4.1821e-05, -2.9459e-04,  9.0729e-05,\n",
            "         3.1522e-05, -9.4844e-05,  1.2257e-04, -9.1242e-07,  1.4444e-05,\n",
            "         1.1242e-04, -1.0375e-04, -2.6897e-05,  2.6374e-06, -1.5264e-05,\n",
            "         1.0402e-04,  3.9218e-05,  1.0774e-04,  2.5314e-04, -2.3671e-04,\n",
            "         1.4409e-04,  2.1882e-05, -1.7878e-04, -1.2731e-05, -2.4305e-05,\n",
            "        -8.3060e-05, -4.8166e-06,  4.9440e-05, -2.1256e-04, -5.8112e-05,\n",
            "        -9.1518e-05,  1.0506e-04, -2.4619e-05,  6.3647e-05, -1.3582e-05,\n",
            "        -1.5783e-05,  1.4926e-05,  3.8552e-05,  1.7007e-04, -1.1683e-04,\n",
            "         1.0062e-04,  4.9239e-05, -3.8730e-06,  5.1184e-05, -1.0083e-04,\n",
            "        -1.6866e-04,  1.2163e-04, -3.7350e-05, -2.8649e-05,  6.7287e-06,\n",
            "         1.6928e-05, -4.3915e-05,  2.6003e-04, -3.6457e-05, -7.1162e-05,\n",
            "         1.2202e-05, -4.8500e-05, -4.6924e-06,  2.0277e-04, -1.5160e-04,\n",
            "        -4.0326e-05,  9.1426e-06])), ('module.encoder_k.layer2.2.bn3.running_mean', tensor([-1.1254e-01,  5.9662e-02,  2.7940e-01,  3.1402e-01, -2.9942e-01,\n",
            "         2.4742e-01,  4.0003e-02, -1.0660e-01,  2.8489e-01,  4.1547e-01,\n",
            "         9.8976e-02,  2.7860e-01,  3.4232e-01,  3.6640e-01,  3.8713e-01,\n",
            "        -9.3283e-03,  1.0621e-01, -1.3227e-01, -3.5692e-02, -8.3484e-02,\n",
            "         4.9181e-01,  2.0641e-01, -7.9629e-02,  1.4044e-01, -4.0496e-02,\n",
            "        -1.5060e-01, -1.5552e-01, -1.8428e-01,  3.2790e-01, -1.0239e-01,\n",
            "         1.0984e-01,  5.9951e-02,  3.0629e-01,  2.6244e-01, -7.1045e-02,\n",
            "         1.8074e-01,  1.3032e-01,  2.4540e-01,  5.8491e-02,  1.6425e-01,\n",
            "        -5.6361e-02,  8.9403e-02,  2.1554e-01,  1.3336e-01, -1.5997e-01,\n",
            "        -5.6098e-01, -6.7303e-02,  3.9543e-01,  2.8843e-01,  5.4190e-01,\n",
            "        -2.7474e-01, -2.4834e-01,  1.1314e-01, -1.4556e-01,  2.0583e-01,\n",
            "         2.9745e-01,  2.4159e-01, -5.2055e-01, -1.9761e-01,  2.9160e-01,\n",
            "         3.3632e-01,  2.3759e-01, -3.8753e-01,  4.2174e-02,  1.9173e-01,\n",
            "         1.3540e-01, -5.5625e-02,  6.5518e-03, -1.6660e-01, -1.8292e-01,\n",
            "         3.6682e-01, -2.2881e-02,  1.5241e-01,  4.8567e-01, -2.4925e-01,\n",
            "        -7.4345e-02, -4.3908e-01, -6.4041e-02,  4.7071e-02, -2.0315e-01,\n",
            "         2.8083e-01,  1.9877e-01, -2.2799e-01, -3.7388e-02, -1.3563e-01,\n",
            "         1.4523e-01,  1.0256e-01, -4.7585e-01,  3.8590e-01, -1.9341e-02,\n",
            "         5.2007e-02, -2.9892e-01, -1.0208e-01, -6.0989e-02, -3.0971e-02,\n",
            "        -5.0213e-01, -1.7722e-01,  1.9996e-01, -1.2669e-01, -2.0453e-03,\n",
            "         4.0605e-01,  2.3872e-01, -3.6622e-02, -1.6312e-01,  3.5796e-03,\n",
            "         6.8162e-02,  1.3956e-01,  5.4596e-02,  1.9569e-01,  1.0274e-01,\n",
            "         2.6469e-01,  6.2149e-01,  2.1325e-03,  3.4916e-01,  3.0477e-01,\n",
            "        -1.1698e-01, -3.6622e-01, -5.7734e-02, -5.6759e-01,  5.4788e-02,\n",
            "         1.4305e-01,  2.9137e-01,  4.8471e-04,  4.3940e-01, -3.8574e-01,\n",
            "         4.4946e-01, -9.7627e-02, -2.2922e-02, -5.4130e-01,  3.2698e-02,\n",
            "        -2.0165e-01,  4.0367e-01,  3.6199e-01,  7.3218e-02, -1.7848e-01,\n",
            "         2.6586e-02, -8.6465e-02, -1.0106e-01, -3.5116e-01, -3.8432e-01,\n",
            "        -3.8177e-01, -1.1140e-01,  2.4785e-01,  6.4965e-02,  3.1858e-01,\n",
            "         1.3134e-01, -3.0683e-01, -3.6360e-01,  2.1933e-01,  1.7690e-01,\n",
            "         8.0772e-02,  6.8046e-02,  2.6732e-01,  2.1318e-01, -3.8455e-02,\n",
            "        -1.3621e-01, -2.8340e-02,  2.1534e-01,  3.3434e-02, -6.7437e-02,\n",
            "         5.3714e-02,  3.2714e-01,  4.4895e-01,  3.7504e-01, -1.6558e-01,\n",
            "         2.9905e-01, -8.9412e-02, -2.8498e-02, -3.4726e-01,  2.5563e-01,\n",
            "        -2.9025e-01,  3.1500e-01, -1.8835e-01, -2.1987e-01, -9.8753e-02,\n",
            "        -4.2845e-01, -6.2799e-02,  4.2723e-01, -6.8338e-02, -2.8070e-01,\n",
            "         2.6736e-01,  2.5770e-01, -6.5310e-01,  1.3828e-01, -2.0207e-03,\n",
            "         2.4362e-01,  2.7086e-01,  7.5241e-02, -1.5857e-01, -3.3465e-01,\n",
            "        -5.8687e-01, -8.0268e-02, -1.9745e-01, -4.6283e-01, -4.1523e-01,\n",
            "         9.6880e-02, -2.4163e-01, -1.7479e-01,  1.6515e-01, -9.9210e-02,\n",
            "        -4.8265e-01, -7.3120e-01, -2.7322e-01,  2.7483e-02, -1.1949e-01,\n",
            "         3.0616e-02, -1.2887e-01,  3.6348e-01, -4.0283e-02, -3.0118e-01,\n",
            "         2.4351e-01, -5.0761e-02, -2.9926e-01,  1.1732e-01,  3.3987e-01,\n",
            "        -3.1554e-01,  9.3619e-02, -4.2961e-01,  3.3530e-01, -1.2982e-01,\n",
            "        -1.8809e-01,  1.7729e-01,  1.5292e-01, -1.4056e-01,  7.9836e-02,\n",
            "        -9.9937e-02,  8.7847e-02, -7.3550e-02,  7.6227e-02, -1.8899e-01,\n",
            "        -1.9505e-01, -9.2800e-02,  9.4167e-02,  4.3234e-01, -2.2009e-01,\n",
            "         8.2066e-02,  4.8678e-03,  1.8153e-01,  2.6902e-01, -7.8508e-02,\n",
            "        -2.7364e-01, -1.7573e-01, -3.1454e-01,  2.8139e-01,  2.6585e-01,\n",
            "         4.3775e-01,  1.0440e-01, -2.3030e-01,  2.3439e-01, -3.1725e-01,\n",
            "        -2.1841e-01, -2.3238e-01,  3.6829e-01,  2.9338e-02,  3.5335e-02,\n",
            "         3.3315e-02,  9.2014e-02,  1.2731e-01,  8.0957e-02,  4.1875e-01,\n",
            "        -2.1687e-01, -3.0679e-02, -1.7341e-01,  1.0607e-01,  2.1682e-02,\n",
            "         2.6329e-01, -2.5177e-01,  6.2074e-01, -2.1063e-01, -2.1082e-01,\n",
            "        -4.8139e-01, -2.8336e-01, -3.2496e-01,  2.5412e-02, -1.1109e-02,\n",
            "        -8.8567e-03, -6.6144e-02, -1.8699e-01, -9.0592e-02, -1.8859e-01,\n",
            "        -1.3538e-01, -1.7643e-01, -2.2368e-01,  2.8977e-01,  2.3312e-01,\n",
            "         2.1985e-01,  3.5404e-01, -1.9235e-01, -5.6287e-02,  5.5150e-01,\n",
            "         3.3253e-01,  3.2571e-01, -6.2414e-01, -1.0082e-01,  1.1970e-01,\n",
            "         5.8395e-01, -4.6741e-01,  5.3163e-01, -1.3659e-01,  1.4977e-01,\n",
            "        -4.2609e-01, -4.0811e-01, -6.4997e-02, -3.2386e-01, -4.8268e-02,\n",
            "        -4.2349e-01,  1.0199e-01,  1.4300e-01, -5.8198e-01, -9.0339e-02,\n",
            "        -1.7939e-01,  3.8429e-01,  6.1615e-01, -1.5159e-01, -2.0861e-01,\n",
            "        -2.1813e-01,  2.5165e-01, -1.3770e-02, -4.5282e-01,  5.8865e-02,\n",
            "        -1.3618e-01,  2.9450e-01,  1.6669e-01,  3.5544e-01,  1.3048e-01,\n",
            "         5.8547e-01,  3.2770e-02, -2.4754e-01,  1.7700e-02,  5.6595e-01,\n",
            "         5.9705e-02,  3.5238e-01, -9.2403e-02,  3.0722e-01,  5.3898e-01,\n",
            "        -3.3894e-02, -1.8821e-01,  3.1184e-02, -2.2014e-01,  1.4584e-01,\n",
            "        -2.2885e-01, -4.7023e-02,  7.3179e-02, -1.3436e-01, -2.2647e-01,\n",
            "        -3.9248e-01,  1.5722e-01, -7.8495e-02,  3.0321e-02, -2.3000e-01,\n",
            "        -1.3200e-01,  1.6402e-01,  8.0232e-02, -1.1808e-01, -1.2202e-01,\n",
            "         2.6035e-01,  8.0659e-02, -3.5356e-01,  1.7194e-01,  3.2383e-01,\n",
            "         9.9332e-03,  3.8488e-01, -1.7343e-01, -2.6453e-01,  1.4926e-01,\n",
            "        -2.3063e-01,  1.1479e-01, -3.8286e-01, -3.3182e-03,  1.5846e-02,\n",
            "        -1.8894e-01,  1.1101e-01, -5.5183e-02,  4.5792e-02,  1.5319e-01,\n",
            "        -2.3329e-01,  2.2590e-01,  2.1919e-01,  1.0218e-02,  2.8108e-01,\n",
            "        -2.1348e-01, -4.4216e-02, -5.5140e-01,  4.4851e-02,  4.1834e-02,\n",
            "         3.3466e-01, -2.7484e-03,  5.7036e-01, -1.2470e-01,  7.1362e-02,\n",
            "         2.0240e-01,  2.1086e-01,  1.7885e-01, -2.5992e-01, -4.8499e-02,\n",
            "         7.5968e-03,  1.7167e-01, -1.8826e-01, -1.7700e-01, -6.4061e-02,\n",
            "         6.0231e-02,  3.7601e-01, -8.4114e-03, -3.1736e-01,  3.7929e-02,\n",
            "         1.8388e-01,  3.0266e-01,  2.3143e-01, -6.8406e-02,  5.9166e-02,\n",
            "         4.9310e-01,  2.7220e-01, -1.0008e-01, -1.2639e-01,  2.7887e-01,\n",
            "         6.1907e-02, -3.3386e-01,  2.5154e-01,  2.3798e-01, -2.3467e-01,\n",
            "        -2.7937e-01, -4.9676e-02, -2.1951e-01, -1.5424e-02, -2.2413e-01,\n",
            "         1.5405e-03, -2.3323e-01, -2.3699e-01, -2.9738e-01, -9.5236e-02,\n",
            "        -1.8801e-01, -7.3208e-02, -5.9017e-02, -4.8234e-03, -4.2684e-01,\n",
            "        -1.1841e-01,  7.4878e-02, -8.0546e-02, -3.2938e-01,  2.9346e-01,\n",
            "        -3.2992e-01,  3.1661e-02, -1.3292e-01, -5.1426e-02, -3.5673e-01,\n",
            "        -5.6035e-02,  1.7963e-01,  3.3875e-02, -1.9484e-01, -1.7498e-01,\n",
            "         6.0319e-02, -3.5937e-01, -6.9297e-02, -2.2425e-01,  5.5422e-02,\n",
            "        -3.6811e-01,  2.4382e-01,  5.5376e-02, -5.2043e-02,  2.2889e-02,\n",
            "        -1.6848e-01,  1.7817e-01,  9.7720e-02, -2.9011e-02, -4.7605e-01,\n",
            "         1.5786e-02,  2.5935e-01,  2.7992e-02,  2.7271e-01, -9.0344e-02,\n",
            "         4.5410e-02, -1.3488e-01, -1.6332e-01, -8.7114e-02,  7.4870e-02,\n",
            "         7.0395e-02, -3.6284e-01, -1.6933e-01,  2.3758e-01, -3.2353e-01,\n",
            "        -2.9371e-01, -3.4719e-02,  2.8474e-01,  1.0375e-01,  3.5155e-01,\n",
            "         8.1099e-02,  4.1482e-01, -1.1662e-01,  3.0507e-01,  6.5968e-01,\n",
            "         3.6890e-01,  1.5799e-02,  2.6956e-01,  2.9194e-01,  1.4715e-01,\n",
            "        -7.3667e-02,  5.2741e-01, -4.8019e-02,  6.8602e-02,  6.2336e-02,\n",
            "        -9.3168e-02, -1.8093e-01,  1.2582e-01,  3.8769e-01,  1.2831e-01,\n",
            "         2.3780e-01,  2.1069e-01, -1.9578e-01,  2.3836e-02, -9.3969e-02,\n",
            "        -3.0495e-01, -7.2529e-02])), ('module.encoder_k.layer2.2.bn3.running_var', tensor([0.1933, 0.2464, 0.1314, 0.1616, 0.1430, 0.1468, 0.1441, 0.1369, 0.1116,\n",
            "        0.2243, 0.3149, 0.1845, 0.1724, 0.2898, 0.1014, 0.1406, 0.1018, 0.1344,\n",
            "        0.1456, 0.1585, 0.2220, 0.1344, 0.1905, 0.1374, 0.1656, 0.1727, 0.1755,\n",
            "        0.1317, 0.1868, 0.1411, 0.1434, 0.1494, 0.2326, 0.1522, 0.1555, 0.1705,\n",
            "        0.2087, 0.1407, 0.2482, 0.1556, 0.1412, 0.2232, 0.1363, 0.2213, 0.2272,\n",
            "        0.1731, 0.2427, 0.1581, 0.1129, 0.2398, 0.3610, 0.1584, 0.1274, 0.1695,\n",
            "        0.1974, 0.1539, 0.2767, 0.2153, 0.1536, 0.1469, 0.2522, 0.3717, 0.1429,\n",
            "        0.1595, 0.1811, 0.1642, 0.1725, 0.1456, 0.1448, 0.1323, 0.1493, 0.1531,\n",
            "        0.1686, 0.3639, 0.1870, 0.2034, 0.1654, 0.1919, 0.1392, 0.1936, 0.1444,\n",
            "        0.1522, 0.1677, 0.1460, 0.1814, 0.1603, 0.1420, 0.2836, 0.2590, 0.1242,\n",
            "        0.1509, 0.1684, 0.1777, 0.1226, 0.1493, 0.4730, 0.1214, 0.1236, 0.2252,\n",
            "        0.1942, 0.2713, 0.1066, 0.1335, 0.1325, 0.1274, 0.1975, 0.1802, 0.1344,\n",
            "        0.2310, 0.1665, 0.1802, 0.1893, 0.1739, 0.1960, 0.1583, 0.0942, 0.2061,\n",
            "        0.2018, 0.2810, 0.2458, 0.2423, 0.1747, 0.1742, 0.1744, 0.1394, 0.3318,\n",
            "        0.1459, 0.1471, 0.2093, 0.1203, 0.1586, 0.3098, 0.2486, 0.1262, 0.1796,\n",
            "        0.1611, 0.1176, 0.1211, 0.2657, 0.1428, 0.1582, 0.1259, 0.1216, 0.1469,\n",
            "        0.1240, 0.1532, 0.1403, 0.1663, 0.1280, 0.1980, 0.2000, 0.1760, 0.2612,\n",
            "        0.1541, 0.1667, 0.1618, 0.1384, 0.1558, 0.2574, 0.1650, 0.1492, 0.2185,\n",
            "        0.3536, 0.1383, 0.1491, 0.1427, 0.1444, 0.1103, 0.2043, 0.2439, 0.2293,\n",
            "        0.1647, 0.1275, 0.1588, 0.1348, 0.1581, 0.2755, 0.1748, 0.2124, 0.1333,\n",
            "        0.1932, 0.1552, 0.5464, 0.1671, 0.1856, 0.1692, 0.1831, 0.1713, 0.1558,\n",
            "        0.1869, 0.3433, 0.1325, 0.1362, 0.2681, 0.3435, 0.1681, 0.2403, 0.1826,\n",
            "        0.1599, 0.2030, 0.1418, 0.2767, 0.2942, 0.1341, 0.1509, 0.1840, 0.1432,\n",
            "        0.3177, 0.1546, 0.1437, 0.1544, 0.1612, 0.1823, 0.1298, 0.2050, 0.1812,\n",
            "        0.1576, 0.1613, 0.1488, 0.1192, 0.1503, 0.1392, 0.1883, 0.2014, 0.1950,\n",
            "        0.2140, 0.1147, 0.1496, 0.1631, 0.2530, 0.2173, 0.3918, 0.1668, 0.1199,\n",
            "        0.1069, 0.1446, 0.2249, 0.2221, 0.1841, 0.1584, 0.2155, 0.1386, 0.1839,\n",
            "        0.1406, 0.1578, 0.2929, 0.2007, 0.3512, 0.1128, 0.1102, 0.2335, 0.1619,\n",
            "        0.1693, 0.1733, 0.1874, 0.1499, 0.2104, 0.1950, 0.1396, 0.1145, 0.1726,\n",
            "        0.1190, 0.2340, 0.1848, 0.1523, 0.1673, 0.1525, 0.2679, 0.1893, 0.1627,\n",
            "        0.2253, 0.1142, 0.2278, 0.1370, 0.1090, 0.1644, 0.1627, 0.2300, 0.2024,\n",
            "        0.1274, 0.1440, 0.1581, 0.2754, 0.1437, 0.1655, 0.1759, 0.1825, 0.1340,\n",
            "        0.1019, 0.2595, 0.2300, 0.3687, 0.3346, 0.1848, 0.1697, 0.2533, 0.1431,\n",
            "        0.1527, 0.1574, 0.1073, 0.2310, 0.1590, 0.1943, 0.1148, 0.1041, 0.2457,\n",
            "        0.1782, 0.1514, 0.1714, 0.1907, 0.1504, 0.2226, 0.2183, 0.1559, 0.1751,\n",
            "        0.1573, 0.1898, 0.1822, 0.2250, 0.1837, 0.1245, 0.1427, 0.1565, 0.4431,\n",
            "        0.1809, 0.2105, 0.1210, 0.2650, 0.1285, 0.2234, 0.2319, 0.1354, 0.2206,\n",
            "        0.1966, 0.2296, 0.1600, 0.1654, 0.1400, 0.2115, 0.1757, 0.1552, 0.2567,\n",
            "        0.1507, 0.1653, 0.1601, 0.1788, 0.1659, 0.1423, 0.1558, 0.1455, 0.1103,\n",
            "        0.1317, 0.3588, 0.1444, 0.1478, 0.1349, 0.1385, 0.1601, 0.2730, 0.1269,\n",
            "        0.1488, 0.2836, 0.1741, 0.1179, 0.1472, 0.1819, 0.1527, 0.1655, 0.1857,\n",
            "        0.1346, 0.1581, 0.1220, 0.1417, 0.1458, 0.1560, 0.1464, 0.2318, 0.2350,\n",
            "        0.1500, 0.1450, 0.1792, 0.2882, 0.3471, 0.1310, 0.1775, 0.2553, 0.1589,\n",
            "        0.1751, 0.1675, 0.2016, 0.1357, 0.4205, 0.1853, 0.1643, 0.1274, 0.1988,\n",
            "        0.1788, 0.2193, 0.1947, 0.1716, 0.1547, 0.1245, 0.1840, 0.1883, 0.1864,\n",
            "        0.1769, 0.4124, 0.1348, 0.2112, 0.1682, 0.2558, 0.2017, 0.1705, 0.1626,\n",
            "        0.1176, 0.1674, 0.1719, 0.1557, 0.1377, 0.1556, 0.3233, 0.1189, 0.1469,\n",
            "        0.1793, 0.1640, 0.1340, 0.1455, 0.1360, 0.1901, 0.1476, 0.1642, 0.1328,\n",
            "        0.1208, 0.1454, 0.1617, 0.1428, 0.1703, 0.1191, 0.1417, 0.2436, 0.2498,\n",
            "        0.2311, 0.2369, 0.1544, 0.2233, 0.1345, 0.1755, 0.1218, 0.2176, 0.0982,\n",
            "        0.1208, 0.3198, 0.1844, 0.1381, 0.1626, 0.1639, 0.1492, 0.1346, 0.1400,\n",
            "        0.2168, 0.1237, 0.1704, 0.1384, 0.1503, 0.2073, 0.1482, 0.1849, 0.1458,\n",
            "        0.1353, 0.1635, 0.1408, 0.1534, 0.1818, 0.1980, 0.2105, 0.1742, 0.2187,\n",
            "        0.1795, 0.1315, 0.1220, 0.2248, 0.1644, 0.1494, 0.2959, 0.2027, 0.1505,\n",
            "        0.1632, 0.3498, 0.1306, 0.2526, 0.2852, 0.1257, 0.1587, 0.2662, 0.1658,\n",
            "        0.1645, 0.4346, 0.1636, 0.2516, 0.1621, 0.1489, 0.1818, 0.1686, 0.2221,\n",
            "        0.1517, 0.1559, 0.1994, 0.1890, 0.1621, 0.1920, 0.2859, 0.1625])), ('module.encoder_k.layer2.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.3.conv1.weight', tensor([[[[-0.0861]],\n",
            "\n",
            "         [[-0.0850]],\n",
            "\n",
            "         [[ 0.0775]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0843]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         [[-0.0783]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1165]],\n",
            "\n",
            "         [[ 0.1624]],\n",
            "\n",
            "         [[-0.0356]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0113]],\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[-0.1130]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0258]],\n",
            "\n",
            "         [[ 0.1591]],\n",
            "\n",
            "         [[ 0.1322]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1409]],\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         [[-0.0510]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1717]],\n",
            "\n",
            "         [[-0.1639]],\n",
            "\n",
            "         [[ 0.0536]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0372]],\n",
            "\n",
            "         [[ 0.0497]],\n",
            "\n",
            "         [[ 0.1308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0611]],\n",
            "\n",
            "         [[-0.0652]],\n",
            "\n",
            "         [[ 0.0642]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1904]],\n",
            "\n",
            "         [[-0.0701]],\n",
            "\n",
            "         [[-0.0189]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1255]],\n",
            "\n",
            "         [[ 0.0577]],\n",
            "\n",
            "         [[-0.1825]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1335]],\n",
            "\n",
            "         [[ 0.0603]],\n",
            "\n",
            "         [[ 0.1413]]]])), ('module.encoder_k.layer2.3.bn1.weight', tensor([0.9993, 0.9989, 0.9989, 0.9988, 0.9989, 0.9991, 0.9997, 0.9989, 0.9990,\n",
            "        0.9991, 0.9985, 0.9986, 0.9987, 0.9994, 0.9989, 0.9982, 0.9991, 0.9986,\n",
            "        0.9996, 0.9992, 0.9993, 0.9994, 0.9995, 0.9988, 0.9991, 0.9985, 0.9988,\n",
            "        0.9991, 0.9992, 0.9993, 0.9990, 0.9995, 0.9992, 0.9990, 0.9992, 0.9986,\n",
            "        0.9990, 0.9994, 0.9988, 0.9991, 0.9989, 0.9989, 0.9988, 0.9986, 0.9988,\n",
            "        0.9988, 0.9992, 0.9992, 0.9993, 0.9988, 0.9989, 0.9993, 0.9990, 0.9994,\n",
            "        0.9981, 0.9988, 0.9994, 0.9991, 0.9992, 0.9993, 0.9991, 0.9991, 1.0000,\n",
            "        0.9986, 0.9988, 0.9991, 0.9989, 0.9992, 0.9991, 0.9996, 0.9988, 0.9988,\n",
            "        0.9990, 0.9988, 0.9990, 0.9990, 0.9993, 0.9992, 0.9987, 0.9996, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9984, 0.9989, 0.9992, 0.9992, 0.9989, 0.9992,\n",
            "        0.9994, 0.9993, 0.9994, 0.9987, 0.9998, 0.9991, 0.9989, 0.9992, 0.9997,\n",
            "        0.9988, 0.9994, 0.9987, 0.9993, 0.9991, 0.9988, 0.9992, 0.9997, 0.9994,\n",
            "        0.9996, 0.9988, 0.9994, 0.9992, 0.9993, 0.9991, 0.9995, 0.9992, 0.9992,\n",
            "        0.9993, 0.9998, 0.9995, 0.9988, 0.9987, 0.9989, 0.9993, 0.9988, 0.9989,\n",
            "        0.9991, 0.9992])), ('module.encoder_k.layer2.3.bn1.bias', tensor([ 1.8699e-04, -3.8937e-05, -3.5466e-04, -1.4696e-04, -3.1714e-04,\n",
            "         1.0688e-04, -4.3127e-05,  7.0207e-05, -2.5719e-04,  7.6059e-05,\n",
            "        -2.0318e-04, -3.3162e-04, -4.2684e-04,  9.1456e-05, -2.0599e-04,\n",
            "        -8.4171e-04, -9.3963e-05, -2.1937e-04,  4.8688e-05, -4.2504e-05,\n",
            "         6.6877e-04,  5.4056e-04,  1.0836e-04, -2.7412e-05, -1.0657e-04,\n",
            "        -1.5706e-04, -9.0567e-05,  4.2277e-04, -4.6609e-05, -2.1720e-04,\n",
            "        -2.1590e-04,  4.2791e-04,  2.3143e-04,  3.7855e-04, -1.6768e-04,\n",
            "        -7.3267e-05, -7.3787e-05,  1.8569e-04, -2.5067e-04,  4.0057e-04,\n",
            "        -9.8195e-05, -1.1902e-04, -2.5336e-04, -2.0188e-04, -2.2965e-04,\n",
            "         1.8350e-04,  2.4343e-04, -2.5803e-04,  2.5668e-04, -3.1422e-04,\n",
            "         1.5732e-05, -7.9504e-06,  2.9214e-05,  2.7556e-04, -1.0073e-03,\n",
            "        -3.6061e-04,  3.0730e-04, -9.1919e-05,  2.8793e-04,  2.0590e-04,\n",
            "         2.3968e-05, -3.2087e-04,  9.3460e-04, -2.5441e-04, -4.6731e-04,\n",
            "        -6.9502e-05,  3.5362e-05, -1.0070e-04,  3.0518e-04,  4.5781e-04,\n",
            "         4.0202e-05,  2.1636e-04,  4.0057e-04, -2.5823e-04, -1.1545e-04,\n",
            "        -5.2020e-04, -1.9031e-05,  4.3302e-04,  1.4055e-04,  2.7196e-04,\n",
            "        -8.3348e-05, -2.0310e-05, -5.3911e-05,  4.2172e-05, -1.4411e-04,\n",
            "        -5.6248e-04,  7.7699e-05,  1.3697e-04, -2.8651e-04,  3.8872e-06,\n",
            "         6.2842e-04,  2.7874e-04, -1.6269e-04,  1.0189e-04,  6.9691e-04,\n",
            "         2.5184e-04,  7.1239e-05,  3.6611e-04,  1.3635e-04, -3.4634e-04,\n",
            "        -1.2663e-04,  8.9655e-05, -5.4334e-05,  3.0214e-06,  1.1116e-04,\n",
            "         1.1955e-04,  3.4713e-04,  3.1628e-04,  3.6312e-04,  1.0027e-04,\n",
            "         5.7022e-05, -1.5824e-04,  4.7966e-04, -1.3616e-04,  6.1584e-04,\n",
            "         7.1398e-05,  1.8950e-04,  4.9003e-04,  7.1806e-04,  5.6121e-05,\n",
            "         1.5944e-04, -3.5377e-04, -7.7180e-05,  3.1640e-04,  1.1581e-04,\n",
            "         6.3225e-05, -1.2572e-04, -3.9129e-04])), ('module.encoder_k.layer2.3.bn1.running_mean', tensor([ 1.1138,  2.7389,  1.6831,  0.2281, -2.0648,  1.0217,  2.3079, -1.8580,\n",
            "         4.7172, -1.2727,  0.9427, -1.0929,  1.8387, -2.2121, -1.2446,  2.3619,\n",
            "        -2.3312, -2.3997,  6.0381,  2.8887,  0.5633,  2.3307,  0.7153, -1.7289,\n",
            "         1.4530, -4.9366,  0.2359,  2.1373, -3.3192,  2.0249, -0.7037,  2.7192,\n",
            "         0.4431, -0.2992, -1.1357, -2.6220,  1.2823,  2.8805, -0.8272, -1.5459,\n",
            "         1.7307, -1.2487,  0.8170, -1.3324,  2.8549,  1.6334,  5.6767, -0.5401,\n",
            "         5.0026, -5.7002, -5.3864,  0.7856,  1.0412, -2.2587,  0.5799, -3.8743,\n",
            "        -1.7304, -2.6686,  0.6631,  0.6568,  1.2247, -2.5701, -2.8023, -4.0109,\n",
            "         0.1693, -0.9369, -3.2544,  2.8798, -4.9601, -0.5782,  0.2440, -0.8307,\n",
            "        -3.2907,  1.6202,  1.3106,  6.5097,  2.1125, -1.1771,  6.7834, -3.5115,\n",
            "        -0.3334,  2.7517, -3.1409, -2.6144,  0.9333, -6.0150,  2.0326, -0.4415,\n",
            "         8.0233,  2.1477,  1.7413,  1.5565,  1.0916,  2.2091, -2.6327, -2.2650,\n",
            "         0.4970,  0.6099,  2.2385,  0.0601,  0.6523,  3.6063, -0.9800, -1.8322,\n",
            "         5.7089,  0.1544, -0.2769,  0.5334, -1.4907, -1.6736, -0.6909,  2.2701,\n",
            "        -5.6529,  2.1026,  1.4264,  0.2759,  0.8130, -0.1432,  7.5949,  2.1744,\n",
            "         0.5752, -0.9566, -2.5210, -4.0096, -3.2900, -1.5907, -0.5662, -3.4788])), ('module.encoder_k.layer2.3.bn1.running_var', tensor([10.5449, 18.9202, 12.2572,  9.0905,  9.9255,  6.9855,  9.3243,  9.9980,\n",
            "        10.9137, 25.2612,  7.9625, 12.2741,  9.2777, 10.5580,  8.3973,  9.0156,\n",
            "         8.3296, 10.5538, 20.0718, 10.5907, 10.7399,  9.6625, 11.1645, 11.2854,\n",
            "        13.9071, 14.3610, 10.7027, 20.2584, 11.0912,  9.6911,  8.5838, 14.2694,\n",
            "        10.4771, 11.3445,  9.0106, 12.8117, 11.5545, 16.9316, 10.4574, 10.3968,\n",
            "         9.8516, 10.1738,  8.9652,  9.7196, 14.1622, 11.5043, 22.7514,  8.2030,\n",
            "        12.6265, 17.4456,  8.9698, 10.6536,  9.3474,  7.9539, 10.2830, 16.9902,\n",
            "         9.6268,  8.7888,  8.4999,  9.2076, 15.9986, 13.3547, 13.8783,  8.3451,\n",
            "        12.2216,  9.1965, 12.4573, 13.0618, 19.6616, 12.9264,  8.3879, 11.6693,\n",
            "         9.3805, 11.3792,  9.4309, 27.2441, 16.9321, 10.7445, 36.9400,  8.5719,\n",
            "         9.3625, 21.0225, 14.2094, 13.0223, 12.7932, 14.7979, 10.7701,  9.8273,\n",
            "        40.8333,  9.7194, 15.0563, 15.6716, 10.6934, 12.0779,  8.3988,  8.9606,\n",
            "        12.0806,  8.7999, 13.2381, 10.9087, 11.9277, 18.0200, 11.0785, 11.8690,\n",
            "        14.3350,  9.8697,  9.1082,  8.0444, 14.5903, 10.3560, 11.0433, 12.1791,\n",
            "        15.4793, 10.7463,  9.1855,  7.8848, 11.8543,  9.2320, 24.5854,  8.1405,\n",
            "         9.6551, 10.3743, 20.9188, 20.5902, 13.0946,  8.6171,  7.8098, 15.7708])), ('module.encoder_k.layer2.3.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.3.conv2.weight', tensor([[[[-3.1342e-02, -6.2473e-02, -4.0346e-02],\n",
            "          [-8.1534e-02, -2.2897e-02, -2.5463e-02],\n",
            "          [-8.7034e-02,  3.2219e-02, -4.0861e-02]],\n",
            "\n",
            "         [[ 1.7942e-02, -2.6195e-02, -2.0781e-02],\n",
            "          [-3.4594e-02,  4.7527e-03, -1.4739e-02],\n",
            "          [ 1.4569e-02, -2.2826e-02, -7.5673e-02]],\n",
            "\n",
            "         [[-8.1159e-02,  4.4418e-02, -1.1861e-01],\n",
            "          [ 6.3612e-02,  4.5632e-03, -3.3192e-02],\n",
            "          [ 2.6944e-02,  3.6341e-02,  3.2786e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7362e-02, -1.9842e-02, -1.5307e-02],\n",
            "          [ 1.8263e-02, -3.3511e-03,  1.8791e-02],\n",
            "          [ 1.8205e-02,  5.1782e-02, -4.3780e-05]],\n",
            "\n",
            "         [[-2.5728e-02, -2.6123e-02,  9.6935e-02],\n",
            "          [ 7.0030e-02,  1.1090e-01, -3.0461e-02],\n",
            "          [-8.2774e-03,  3.0678e-02,  1.9959e-02]],\n",
            "\n",
            "         [[ 1.1008e-02,  2.1390e-02,  1.4424e-01],\n",
            "          [ 8.1403e-02,  2.8736e-02,  3.6208e-02],\n",
            "          [ 4.7085e-02,  5.1446e-02, -3.9902e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3587e-02,  7.3678e-03, -1.2107e-02],\n",
            "          [-5.0136e-02,  8.3982e-02, -5.9751e-03],\n",
            "          [ 2.1391e-02,  4.8941e-02, -2.5107e-02]],\n",
            "\n",
            "         [[-1.2165e-02, -6.3993e-02,  3.9380e-02],\n",
            "          [ 3.4572e-02, -2.9658e-02, -1.1846e-02],\n",
            "          [-5.8020e-03, -1.6761e-03, -2.1383e-02]],\n",
            "\n",
            "         [[-4.6228e-02, -4.1510e-02,  2.6815e-02],\n",
            "          [ 1.3219e-02,  6.0372e-02, -6.8878e-03],\n",
            "          [-5.4142e-02, -2.2528e-02,  4.6489e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4644e-03,  2.2905e-02,  2.4754e-03],\n",
            "          [ 5.5485e-03,  6.9503e-02,  6.1953e-02],\n",
            "          [ 4.8254e-02, -6.1776e-02, -3.4724e-02]],\n",
            "\n",
            "         [[-6.8682e-02, -3.5149e-02, -2.1442e-02],\n",
            "          [-1.6727e-02,  6.9179e-03, -2.7606e-02],\n",
            "          [-2.0983e-02,  4.0996e-02,  4.8608e-03]],\n",
            "\n",
            "         [[ 4.5499e-02, -1.4552e-02,  7.0267e-02],\n",
            "          [-1.1213e-02, -1.3303e-02, -3.8344e-02],\n",
            "          [-1.3940e-02,  1.8977e-02,  7.7618e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8813e-02, -2.1930e-03,  3.9351e-02],\n",
            "          [-5.2971e-02, -1.1424e-02, -4.3202e-02],\n",
            "          [ 2.6798e-02, -2.4109e-02,  2.2057e-02]],\n",
            "\n",
            "         [[ 3.5512e-02,  9.3945e-04,  3.6482e-02],\n",
            "          [ 3.9398e-02,  5.1235e-02,  1.5531e-02],\n",
            "          [-7.6409e-03,  1.2706e-02, -4.7399e-02]],\n",
            "\n",
            "         [[-5.3127e-02,  8.7215e-03, -1.7144e-02],\n",
            "          [-7.1064e-03, -1.1935e-02, -1.7008e-03],\n",
            "          [-2.3785e-02, -2.6667e-02,  8.9037e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.5775e-02,  1.4374e-02,  1.7504e-02],\n",
            "          [-4.6887e-02,  4.9993e-02, -3.2934e-02],\n",
            "          [ 2.5538e-03,  1.1490e-02, -2.4825e-02]],\n",
            "\n",
            "         [[ 2.6692e-03, -4.1972e-02, -2.7278e-02],\n",
            "          [ 8.9090e-02, -2.2992e-02,  3.2596e-02],\n",
            "          [-3.0814e-02,  7.3915e-02, -6.6983e-02]],\n",
            "\n",
            "         [[-1.3970e-02,  2.6345e-02, -4.7437e-03],\n",
            "          [-1.8832e-02, -2.2681e-02,  2.8409e-02],\n",
            "          [-4.3086e-02, -2.4823e-02,  3.6923e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3655e-03,  8.3990e-02,  4.7274e-02],\n",
            "          [-9.1786e-02,  4.6033e-02,  1.4189e-02],\n",
            "          [ 2.0489e-02, -1.6480e-02, -5.0599e-02]],\n",
            "\n",
            "         [[-1.0808e-02,  4.1654e-02,  2.0382e-02],\n",
            "          [-3.3122e-02,  5.9032e-02,  9.1210e-02],\n",
            "          [ 1.8563e-02, -8.6029e-02,  6.7022e-03]],\n",
            "\n",
            "         [[-1.2680e-02, -1.9313e-02,  3.9500e-03],\n",
            "          [ 3.0610e-02,  1.6040e-02,  1.6860e-02],\n",
            "          [-1.0015e-02, -4.6462e-02,  1.2457e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.8034e-03, -1.0714e-01, -4.1164e-02],\n",
            "          [-2.5291e-02, -6.7996e-02,  1.9440e-03],\n",
            "          [-1.0562e-02, -9.3413e-02, -5.3675e-02]],\n",
            "\n",
            "         [[ 5.1369e-02,  2.3216e-03,  7.0179e-02],\n",
            "          [ 3.4359e-03,  6.2550e-03,  1.5705e-02],\n",
            "          [-1.5352e-02,  4.0978e-02, -3.0830e-02]],\n",
            "\n",
            "         [[-2.8887e-02, -3.4607e-02, -4.2289e-02],\n",
            "          [ 3.4686e-02, -7.6680e-02, -4.0863e-03],\n",
            "          [ 5.3430e-02,  7.8293e-02,  6.6912e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.9727e-02, -4.7073e-02,  6.2067e-02],\n",
            "          [ 9.1525e-02, -8.1446e-03,  2.0462e-02],\n",
            "          [ 8.2586e-03, -6.4488e-02,  1.2140e-01]],\n",
            "\n",
            "         [[-3.5685e-03, -5.3877e-02, -3.2812e-02],\n",
            "          [-2.7537e-02, -2.5038e-02, -9.3250e-04],\n",
            "          [ 2.5627e-03,  5.6325e-02,  8.3380e-03]],\n",
            "\n",
            "         [[-5.2430e-02,  1.4177e-02,  6.0349e-03],\n",
            "          [ 4.6444e-02,  1.4230e-02, -1.9028e-02],\n",
            "          [-3.5605e-02,  5.8786e-02, -3.2319e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3880e-02, -5.6607e-02, -3.8878e-02],\n",
            "          [ 3.8489e-02, -2.9741e-02, -5.9432e-02],\n",
            "          [ 2.1116e-02, -1.7227e-02,  1.0385e-01]],\n",
            "\n",
            "         [[-9.7281e-03,  3.0056e-02, -1.5048e-02],\n",
            "          [ 6.9531e-02,  2.3127e-02,  2.9866e-03],\n",
            "          [ 4.6428e-02,  3.5455e-02, -9.3440e-02]],\n",
            "\n",
            "         [[-1.2738e-02, -1.7677e-02, -5.7103e-02],\n",
            "          [-3.0397e-02,  1.8083e-02,  6.2882e-02],\n",
            "          [-8.1779e-03, -3.5742e-03,  2.0739e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4900e-04, -2.2436e-02, -1.1797e-02],\n",
            "          [ 8.3714e-03, -1.8038e-02, -3.5811e-02],\n",
            "          [ 2.6889e-02, -2.3529e-03, -1.2602e-02]],\n",
            "\n",
            "         [[ 3.1493e-02, -1.3460e-02, -2.6770e-02],\n",
            "          [-5.1330e-02,  1.4863e-02,  3.2412e-02],\n",
            "          [ 6.5517e-02, -2.3927e-02, -1.9445e-02]],\n",
            "\n",
            "         [[ 9.0075e-02, -2.5762e-02,  3.3519e-02],\n",
            "          [ 7.4558e-03,  1.5361e-02, -1.9824e-02],\n",
            "          [ 1.0534e-02,  4.1296e-02,  2.6747e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4390e-02,  2.4364e-02, -3.7841e-02],\n",
            "          [ 5.9416e-03,  1.0398e-02, -1.7766e-02],\n",
            "          [-4.5896e-02, -2.6561e-02, -1.7697e-02]],\n",
            "\n",
            "         [[ 5.7722e-02,  5.6017e-02, -6.1718e-02],\n",
            "          [ 2.4191e-02,  9.9158e-03,  5.9996e-02],\n",
            "          [-7.7993e-02, -2.5076e-02,  2.9586e-02]],\n",
            "\n",
            "         [[-3.7411e-02, -3.0441e-02, -5.6721e-02],\n",
            "          [-2.3783e-02, -1.2915e-02, -2.0090e-02],\n",
            "          [ 6.1386e-02, -2.8297e-03,  3.4691e-02]]]])), ('module.encoder_k.layer2.3.bn2.weight', tensor([0.9989, 0.9992, 0.9990, 0.9990, 0.9992, 0.9988, 0.9990, 0.9987, 0.9992,\n",
            "        0.9988, 0.9988, 0.9988, 0.9992, 0.9992, 0.9990, 0.9997, 0.9991, 0.9989,\n",
            "        0.9992, 0.9993, 0.9992, 0.9995, 0.9992, 0.9990, 0.9992, 0.9988, 0.9991,\n",
            "        0.9992, 0.9993, 0.9997, 0.9990, 0.9990, 0.9991, 0.9992, 0.9987, 0.9988,\n",
            "        0.9989, 0.9991, 0.9988, 0.9995, 0.9988, 0.9990, 0.9993, 0.9992, 0.9993,\n",
            "        0.9990, 0.9990, 0.9992, 0.9991, 0.9986, 0.9989, 0.9989, 0.9994, 0.9992,\n",
            "        0.9991, 0.9990, 0.9988, 0.9990, 0.9989, 0.9991, 0.9990, 0.9993, 0.9991,\n",
            "        0.9991, 0.9991, 0.9994, 0.9994, 0.9988, 0.9993, 0.9991, 0.9992, 0.9994,\n",
            "        0.9989, 0.9984, 0.9994, 0.9989, 0.9994, 0.9992, 0.9994, 0.9994, 0.9989,\n",
            "        0.9988, 0.9996, 0.9988, 0.9993, 0.9988, 0.9994, 0.9990, 0.9988, 0.9989,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9988, 0.9990, 0.9994, 0.9992, 0.9989,\n",
            "        0.9993, 0.9990, 0.9993, 0.9987, 0.9992, 0.9990, 0.9991, 0.9992, 0.9992,\n",
            "        0.9987, 0.9990, 0.9989, 0.9992, 0.9993, 0.9993, 0.9994, 0.9986, 0.9991,\n",
            "        0.9991, 0.9989, 0.9987, 0.9994, 0.9990, 0.9990, 0.9989, 0.9991, 0.9991,\n",
            "        0.9995, 0.9991])), ('module.encoder_k.layer2.3.bn2.bias', tensor([ 1.1967e-05,  1.8923e-04, -3.8548e-04, -1.5715e-05,  4.2419e-04,\n",
            "        -3.0891e-04, -8.7369e-05, -2.3579e-04,  1.5738e-04,  5.8401e-05,\n",
            "        -1.0976e-05, -1.2424e-04, -2.0434e-04, -1.8907e-04,  8.6962e-05,\n",
            "         3.1903e-04, -8.1799e-05, -3.4555e-04,  4.8969e-05,  1.5526e-04,\n",
            "         2.8204e-04,  3.6938e-04,  1.1857e-04,  2.0910e-04, -9.1763e-05,\n",
            "        -4.1409e-04,  2.6362e-04,  3.3310e-04,  1.0772e-04,  1.5581e-04,\n",
            "        -3.8966e-04, -8.4206e-05,  3.9688e-04,  1.9758e-04, -5.1422e-04,\n",
            "        -1.1332e-04, -3.8137e-04, -1.1358e-04, -9.8475e-05,  2.2490e-04,\n",
            "        -4.4000e-04, -1.8479e-04, -8.7831e-05, -7.6102e-05, -2.0905e-04,\n",
            "         6.7487e-05,  2.7192e-04,  3.5509e-04, -7.6979e-06, -1.6093e-04,\n",
            "        -3.9593e-04,  1.7877e-04,  4.5113e-05,  1.6179e-04, -8.5075e-05,\n",
            "         2.5223e-04, -3.1995e-04,  9.4175e-05, -3.8265e-05, -1.3603e-04,\n",
            "        -2.1429e-05,  2.8802e-04,  1.3305e-04,  2.9883e-05,  2.2069e-05,\n",
            "         5.1828e-04,  1.8067e-04, -5.3006e-04,  3.2574e-04,  1.4621e-04,\n",
            "         3.2052e-04,  3.7343e-04,  1.5693e-04, -3.6778e-04,  8.2742e-05,\n",
            "         2.1521e-04,  4.1550e-04,  3.8437e-04,  5.8470e-04,  1.4893e-04,\n",
            "        -3.7364e-04, -2.6570e-04,  4.1101e-04, -1.0461e-04, -1.7835e-04,\n",
            "        -1.9229e-04, -2.4341e-05, -1.7968e-04, -1.4131e-04, -3.3711e-04,\n",
            "        -3.9231e-04, -3.3248e-05, -8.6341e-05,  2.7117e-04, -9.9062e-05,\n",
            "        -1.1425e-04, -1.3384e-04,  2.6676e-04, -3.1534e-05, -2.7776e-04,\n",
            "         5.3232e-05,  1.9057e-04, -3.2504e-04,  3.3701e-04, -7.7833e-05,\n",
            "        -1.7504e-04, -3.4929e-04,  3.2812e-05, -3.3745e-05, -3.0157e-05,\n",
            "         2.2391e-05,  9.5691e-05,  3.3615e-04,  1.6187e-04,  6.6345e-04,\n",
            "        -3.0441e-04, -7.9028e-05,  3.8655e-04, -3.5186e-04, -2.1248e-04,\n",
            "         9.5187e-05,  4.4413e-06,  1.2333e-05,  3.0798e-04, -9.2482e-05,\n",
            "         2.1965e-04,  2.1659e-04,  1.2056e-04])), ('module.encoder_k.layer2.3.bn2.running_mean', tensor([ 0.6248,  0.3031,  1.3728, -0.0481,  0.6724, -0.4996,  0.5386,  0.3744,\n",
            "        -0.1541,  0.3811,  1.0925, -0.3489, -0.1345,  0.0165, -0.1175, -0.1675,\n",
            "         0.4379, -0.1906,  0.5566, -0.6838,  0.5962,  0.6168,  0.2006,  0.6635,\n",
            "         1.2800,  0.6714,  0.0903,  0.2347,  0.2506,  0.3243, -0.7714,  0.1498,\n",
            "        -0.1038, -0.6105, -0.3137, -0.0244, -0.9536,  0.5969, -1.0520,  0.7007,\n",
            "        -0.1775, -0.8797,  0.2912, -1.0681,  0.7399,  0.6418,  0.6814,  0.3250,\n",
            "        -0.4369,  0.0245, -0.0318,  0.2930, -0.2364, -0.8963,  0.6772,  1.3055,\n",
            "        -0.2066,  0.3053, -0.0516, -0.3768,  0.0579, -0.0993,  0.1064,  0.1437,\n",
            "        -0.0893, -0.1042,  0.4277,  0.8175,  0.4201, -0.5129,  0.0786,  0.4799,\n",
            "         0.3620, -0.5423,  0.2169, -0.1813,  0.2033, -0.2971, -0.1227, -0.2114,\n",
            "        -0.5085, -0.1433, -0.6391,  0.1142,  0.7123,  0.7123,  0.3207, -0.0805,\n",
            "         0.3481, -0.3451,  0.1887,  0.6442, -0.5059,  0.1304,  1.1041, -0.5513,\n",
            "        -1.2430,  0.1056,  0.2425,  0.4116,  0.3910, -0.4255, -0.1994, -0.3287,\n",
            "        -0.5935,  0.0824,  0.4163, -0.4313,  0.7981,  0.2666,  0.5265, -1.3173,\n",
            "         0.0187,  1.1943, -0.5768,  0.4973, -0.9860, -0.1031, -0.6592,  0.4390,\n",
            "         0.6721, -0.7673, -0.5199,  0.0322,  1.0595,  0.3551, -0.2161, -0.8201])), ('module.encoder_k.layer2.3.bn2.running_var', tensor([0.7238, 0.5971, 1.3692, 0.6362, 0.7557, 0.6898, 0.6368, 0.6033, 0.5331,\n",
            "        1.1617, 0.6525, 0.5438, 0.5472, 0.6061, 0.6235, 0.5979, 0.5791, 0.5983,\n",
            "        0.6945, 0.6125, 0.5769, 0.6520, 0.6417, 0.6246, 1.1736, 0.9600, 0.6280,\n",
            "        0.6171, 0.5703, 0.6597, 0.7914, 0.7626, 1.1909, 0.5335, 0.5733, 0.6860,\n",
            "        1.6936, 0.9387, 0.7163, 0.5885, 0.6246, 0.5936, 0.8345, 0.9901, 0.5262,\n",
            "        0.8310, 0.5745, 0.6042, 0.8032, 0.4653, 0.5495, 1.0059, 0.5497, 0.7425,\n",
            "        0.6519, 0.9617, 0.5245, 0.7320, 0.5534, 0.8792, 0.9412, 0.5704, 0.6024,\n",
            "        0.6081, 0.5706, 0.6303, 0.7092, 0.7701, 0.7025, 0.7008, 0.5541, 0.7099,\n",
            "        0.5513, 0.6045, 1.2671, 0.5841, 0.6295, 0.8565, 0.7803, 0.6686, 0.9508,\n",
            "        0.5320, 0.6930, 0.5556, 1.8361, 0.5515, 0.7008, 0.6239, 0.6549, 0.4851,\n",
            "        0.5353, 0.7269, 0.6192, 0.6167, 1.7542, 0.7236, 0.9363, 0.7106, 0.5257,\n",
            "        0.5793, 0.9394, 0.6947, 0.7840, 0.5606, 0.5618, 0.9956, 0.7429, 0.8042,\n",
            "        0.6281, 0.6460, 0.8618, 2.3136, 0.5706, 1.6510, 0.6466, 0.7732, 0.5409,\n",
            "        0.8603, 0.6929, 0.8558, 0.5834, 0.7319, 0.6585, 0.7535, 1.0286, 0.7053,\n",
            "        0.6366, 0.6698])), ('module.encoder_k.layer2.3.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer2.3.conv3.weight', tensor([[[[-0.0446]],\n",
            "\n",
            "         [[ 0.0195]],\n",
            "\n",
            "         [[ 0.0716]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1020]],\n",
            "\n",
            "         [[-0.0707]],\n",
            "\n",
            "         [[ 0.0592]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[ 0.0820]],\n",
            "\n",
            "         [[-0.1625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0095]],\n",
            "\n",
            "         [[-0.0992]],\n",
            "\n",
            "         [[-0.0047]]],\n",
            "\n",
            "\n",
            "        [[[-0.0949]],\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0289]],\n",
            "\n",
            "         [[ 0.0219]],\n",
            "\n",
            "         [[ 0.1135]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0666]],\n",
            "\n",
            "         [[-0.0285]],\n",
            "\n",
            "         [[ 0.0715]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0187]],\n",
            "\n",
            "         [[ 0.0426]],\n",
            "\n",
            "         [[ 0.0829]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0970]],\n",
            "\n",
            "         [[-0.0488]],\n",
            "\n",
            "         [[ 0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0449]],\n",
            "\n",
            "         [[ 0.0873]],\n",
            "\n",
            "         [[-0.0313]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0297]],\n",
            "\n",
            "         [[ 0.0214]],\n",
            "\n",
            "         [[ 0.0772]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1215]],\n",
            "\n",
            "         [[-0.0773]],\n",
            "\n",
            "         [[-0.0090]]]])), ('module.encoder_k.layer2.3.bn3.weight', tensor([0.9990, 0.9990, 0.9990, 0.9988, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9989, 0.9991, 0.9989, 0.9991, 0.9989, 0.9989,\n",
            "        0.9991, 0.9991, 0.9989, 0.9992, 0.9990, 0.9991, 0.9989, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9994, 0.9990, 0.9990,\n",
            "        0.9989, 0.9990, 0.9992, 0.9990, 0.9992, 0.9992, 0.9992, 0.9991, 0.9989,\n",
            "        0.9990, 0.9992, 0.9989, 0.9993, 0.9992, 0.9993, 0.9989, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9989, 0.9991, 0.9989, 0.9992, 0.9989, 0.9990, 0.9990, 0.9991,\n",
            "        0.9994, 0.9992, 0.9991, 0.9992, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990,\n",
            "        0.9991, 0.9989, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992, 0.9991, 0.9989, 0.9992,\n",
            "        0.9992, 0.9989, 0.9990, 0.9991, 0.9992, 0.9992, 0.9988, 0.9991, 0.9989,\n",
            "        0.9991, 0.9988, 0.9990, 0.9992, 0.9991, 0.9993, 0.9991, 0.9992, 0.9992,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9992, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9993,\n",
            "        0.9992, 0.9990, 0.9991, 0.9989, 0.9992, 0.9989, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9989,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9992, 0.9992,\n",
            "        0.9990, 0.9992, 0.9991, 0.9992, 0.9990, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9989, 0.9990, 0.9992, 0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9993, 0.9989, 0.9988, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9990, 0.9988, 0.9990, 0.9989, 0.9994, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9993, 0.9992, 0.9989, 0.9991, 0.9993, 0.9993, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9989, 0.9992, 0.9992, 0.9990, 0.9992, 0.9991, 0.9990,\n",
            "        0.9990, 0.9993, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9988, 0.9990, 0.9989, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9990, 0.9992, 0.9991, 0.9993,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9992, 0.9989, 0.9990,\n",
            "        0.9990, 0.9993, 0.9991, 0.9992, 0.9992, 0.9989, 0.9992, 0.9992, 0.9989,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991,\n",
            "        0.9988, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9989, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9989, 0.9992, 0.9990, 0.9990, 0.9990, 0.9992,\n",
            "        0.9989, 0.9989, 0.9992, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9989,\n",
            "        0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9992, 0.9992, 0.9992, 0.9990,\n",
            "        0.9991, 0.9993, 0.9990, 0.9991, 0.9992, 0.9990, 0.9990, 0.9990, 0.9992,\n",
            "        0.9990, 0.9991, 0.9993, 0.9993, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9989, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9989, 0.9990, 0.9990,\n",
            "        0.9992, 0.9990, 0.9991, 0.9992, 0.9991, 0.9989, 0.9992, 0.9992, 0.9990,\n",
            "        0.9992, 0.9992, 0.9993, 0.9993, 0.9992, 0.9989, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9993, 0.9990, 0.9991, 0.9993, 0.9990, 0.9991, 0.9991, 0.9989,\n",
            "        0.9990, 0.9989, 0.9991, 0.9989, 0.9991, 0.9991, 0.9991, 0.9992, 0.9994,\n",
            "        0.9991, 0.9991, 0.9990, 0.9989, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9993, 0.9990, 0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9989, 0.9989, 0.9990, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9990, 0.9990,\n",
            "        0.9992, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9992, 0.9990, 0.9990, 0.9990,\n",
            "        0.9989, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9988, 0.9993, 0.9990, 0.9992, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991,\n",
            "        0.9992, 0.9993, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9989, 0.9992, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9993, 0.9991, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9992, 0.9993, 0.9991, 0.9992, 0.9990, 0.9990, 0.9989,\n",
            "        0.9992, 0.9992, 0.9991, 0.9992, 0.9989, 0.9990, 0.9990, 0.9992])), ('module.encoder_k.layer2.3.bn3.bias', tensor([-1.2561e-05,  7.3782e-05,  1.8332e-05, -1.2713e-04,  8.3165e-06,\n",
            "         1.5323e-04, -2.2258e-05, -6.6849e-06,  2.6886e-06, -1.3085e-04,\n",
            "         7.4267e-05,  9.5314e-05, -2.7946e-05, -4.5696e-05, -1.6301e-04,\n",
            "         1.6415e-05, -3.3747e-05, -9.5520e-05, -2.1110e-05,  6.4038e-06,\n",
            "         1.6718e-05, -3.7683e-05, -1.1646e-04, -7.2281e-05, -3.3966e-05,\n",
            "         7.8291e-05, -5.6402e-05,  6.6951e-05, -1.2770e-05,  5.3511e-05,\n",
            "        -2.6835e-05,  9.7632e-06, -6.2983e-05, -5.6331e-05,  1.3176e-04,\n",
            "        -2.7725e-05,  2.3131e-05,  8.5673e-05,  2.8487e-05,  3.3673e-05,\n",
            "         8.8941e-05,  2.2371e-05,  2.2559e-05, -6.8847e-05,  9.4842e-05,\n",
            "        -5.0429e-05, -1.9536e-05,  1.1827e-04,  1.5969e-05, -4.9020e-05,\n",
            "         1.0592e-04, -2.0658e-04,  4.3557e-05, -1.4250e-04, -9.3963e-05,\n",
            "         6.1465e-05, -8.7887e-06, -1.0508e-04,  1.3157e-04, -1.9155e-05,\n",
            "        -4.2061e-05, -4.1383e-06,  1.4788e-04,  1.1989e-04, -7.9965e-05,\n",
            "        -4.3541e-05,  5.5515e-05, -1.3814e-05,  1.0704e-04, -6.0059e-05,\n",
            "         3.2026e-05, -5.5744e-05,  2.4566e-05, -8.5200e-05,  7.8471e-05,\n",
            "         8.1116e-05,  4.5150e-05, -1.7679e-05,  2.5062e-05,  1.5256e-04,\n",
            "        -1.7350e-06,  2.3272e-05, -1.0161e-04,  9.6750e-05, -5.9844e-05,\n",
            "         1.8972e-06, -2.9871e-05,  8.6987e-05,  2.2177e-04,  1.9670e-04,\n",
            "        -1.8214e-04, -6.5221e-05,  5.0994e-06, -8.2707e-05, -1.2552e-04,\n",
            "        -4.9264e-07,  7.3479e-05, -8.7779e-05,  1.2961e-04,  2.5344e-05,\n",
            "         1.3602e-04,  7.6083e-05,  4.6998e-05, -5.5770e-05,  1.2952e-04,\n",
            "        -5.1056e-05,  1.2689e-04, -4.6375e-05,  4.5622e-05,  3.4430e-05,\n",
            "        -3.0665e-05,  1.7355e-04,  5.8722e-05,  3.6736e-05,  9.0541e-05,\n",
            "        -1.7340e-05, -1.6921e-05, -5.5165e-05, -3.4876e-05, -1.1417e-04,\n",
            "         5.7726e-05, -6.1479e-05, -3.8951e-05, -1.0941e-04, -3.3164e-07,\n",
            "        -9.4624e-05,  5.5496e-05,  3.9014e-05,  1.0487e-06, -4.2108e-05,\n",
            "         1.0318e-04, -7.5996e-05,  3.6255e-05, -2.3348e-05,  3.4123e-05,\n",
            "         3.5028e-05, -1.3392e-04, -1.6924e-05, -5.1332e-05,  1.1029e-04,\n",
            "        -3.6566e-05, -2.6310e-05,  9.1051e-05,  1.7044e-05, -1.2279e-04,\n",
            "        -9.2275e-05, -5.5452e-05, -2.3559e-05,  1.4816e-04, -1.2811e-04,\n",
            "         6.6771e-05,  1.1292e-04,  1.7760e-05, -7.9471e-05,  4.1412e-06,\n",
            "         5.7625e-05, -4.3698e-05,  2.7703e-05, -9.8095e-05, -6.1011e-05,\n",
            "         2.0047e-05, -1.6975e-05, -5.8619e-06, -4.7351e-05, -1.9349e-05,\n",
            "         4.0544e-05,  1.0211e-04,  1.0948e-04,  7.7142e-05, -4.0972e-05,\n",
            "         1.0928e-04,  1.0249e-04, -2.0524e-05, -2.2156e-06, -6.0931e-05,\n",
            "        -1.6304e-04, -6.2472e-06,  8.5708e-05, -1.0454e-04, -1.8403e-06,\n",
            "        -5.9240e-05,  1.3464e-04, -4.7026e-05, -7.8749e-06,  7.5546e-05,\n",
            "        -3.1155e-05,  2.1253e-05,  8.1266e-06, -7.9207e-05, -1.1029e-04,\n",
            "        -1.2154e-04, -1.1556e-04, -5.9237e-05, -6.8193e-05,  1.9695e-04,\n",
            "        -1.0369e-04, -1.0768e-04,  7.5163e-05, -7.3318e-07, -3.7708e-06,\n",
            "        -3.8555e-05, -4.2179e-05,  6.6060e-05, -1.7524e-04, -2.2940e-05,\n",
            "        -1.6683e-06, -2.5237e-05,  4.0583e-05,  6.4918e-05, -1.5070e-05,\n",
            "         8.6787e-05,  8.8809e-05,  5.2252e-05, -1.7530e-04, -4.4637e-05,\n",
            "        -1.0142e-04, -8.9853e-09, -1.2188e-04,  1.8168e-05, -4.1175e-05,\n",
            "        -6.9356e-05,  6.6208e-05,  1.1182e-04,  4.4949e-05,  5.6071e-05,\n",
            "         9.1744e-06, -2.7876e-05,  1.3500e-05,  1.1283e-04, -3.9653e-05,\n",
            "        -9.5443e-06,  1.0014e-04, -8.9938e-05,  1.6807e-04, -6.3917e-05,\n",
            "         5.0051e-07, -4.0333e-05, -1.0370e-04, -4.8113e-05,  3.8634e-05,\n",
            "         4.4234e-05,  2.5651e-05,  5.1123e-05,  7.7610e-05,  5.1243e-05,\n",
            "        -1.0577e-04,  1.7352e-05,  1.0602e-05,  7.2837e-05, -7.0730e-05,\n",
            "         1.6327e-04, -7.4203e-05, -9.5142e-05,  9.0129e-05, -9.7621e-05,\n",
            "         3.8928e-05,  9.8057e-06, -7.4071e-05,  6.6224e-05,  2.6122e-05,\n",
            "         1.4392e-04,  1.0953e-04,  2.7971e-05,  8.2524e-05, -4.5410e-06,\n",
            "        -1.0250e-04, -5.0282e-05, -1.9281e-06,  1.0938e-05,  4.8462e-05,\n",
            "         6.9496e-05, -4.9314e-05,  2.1219e-05,  7.4193e-05,  1.2887e-04,\n",
            "        -3.3686e-05, -5.7802e-07, -2.4199e-05, -8.8127e-05,  1.2908e-04,\n",
            "        -9.3118e-05, -5.1395e-05, -4.7401e-05,  4.3110e-05,  4.6924e-05,\n",
            "        -8.2781e-07,  1.6962e-05, -2.6058e-04,  4.7441e-05,  7.5814e-05,\n",
            "        -1.0208e-04, -4.4874e-06, -1.2849e-05,  5.2973e-05,  5.2774e-05,\n",
            "        -5.1642e-05, -1.1059e-04, -3.0426e-05,  2.5340e-05,  7.6425e-05,\n",
            "         3.3836e-05,  1.8194e-05,  9.8431e-05, -1.6264e-05,  1.1455e-04,\n",
            "         5.5386e-05,  2.9445e-05, -1.2208e-04, -3.2280e-05, -5.7405e-05,\n",
            "         5.3972e-05,  1.5197e-04,  6.3148e-06, -2.1473e-05, -9.0063e-05,\n",
            "        -2.9378e-05, -3.2743e-05,  7.2217e-05,  3.9829e-05, -1.4995e-04,\n",
            "         1.1536e-04, -3.2587e-05, -1.3745e-04,  6.6978e-05,  1.2720e-04,\n",
            "         1.5032e-05, -3.2300e-05, -1.3957e-05,  6.0540e-05, -7.5259e-05,\n",
            "        -8.9941e-05, -1.0860e-05, -1.0028e-04,  1.1371e-04,  7.5729e-05,\n",
            "         9.5454e-05,  1.4289e-04, -9.9752e-05,  2.4301e-05,  1.1833e-04,\n",
            "         1.9618e-04, -6.8789e-05,  5.4593e-05,  4.6718e-05,  4.8833e-05,\n",
            "         1.6746e-05, -6.8766e-05, -1.0645e-04, -1.7463e-04,  3.0168e-05,\n",
            "        -7.2907e-05,  9.8535e-05,  7.6874e-05,  4.3704e-05,  2.5739e-05,\n",
            "         1.0348e-05,  5.5039e-05, -2.2118e-04, -1.6616e-07, -7.2475e-05,\n",
            "         3.8523e-06, -3.5738e-06, -6.2222e-05, -3.6096e-05,  5.0824e-05,\n",
            "        -9.1320e-05,  9.4913e-05, -5.4110e-05,  2.4322e-05, -1.2585e-04,\n",
            "        -1.3463e-06,  7.4601e-05, -5.9815e-05,  4.9023e-05,  6.6778e-06,\n",
            "        -7.1174e-05,  4.1753e-05,  2.4521e-05,  5.2391e-05, -3.9275e-05,\n",
            "         7.4766e-05,  7.1723e-05,  3.6545e-05,  1.6471e-05,  2.0145e-06,\n",
            "        -1.0957e-04,  8.8902e-05, -6.1572e-06,  1.1805e-04,  7.5294e-05,\n",
            "        -1.2756e-05, -6.5862e-05,  4.4808e-05, -6.7157e-05,  9.8066e-05,\n",
            "        -1.9016e-05,  4.0094e-05,  1.3106e-05,  1.7794e-06, -9.0785e-05,\n",
            "        -1.4657e-04,  3.1434e-05, -6.6223e-05,  3.3097e-05, -1.3323e-04,\n",
            "        -2.3677e-05, -2.3296e-05, -3.0414e-05, -1.1587e-04,  9.5470e-05,\n",
            "         6.8758e-05, -1.8474e-04,  2.6083e-05,  3.3861e-05,  6.5511e-05,\n",
            "        -1.1652e-05,  3.2241e-05, -2.9396e-05,  2.7933e-05, -1.5586e-04,\n",
            "         8.8858e-05,  2.6802e-05,  8.8399e-05, -6.8954e-05, -3.3022e-05,\n",
            "         9.0400e-05, -2.8682e-05,  1.9161e-05,  1.2427e-04, -1.3459e-04,\n",
            "        -1.9933e-06,  5.1713e-05, -1.4150e-04, -9.0511e-06,  2.8477e-04,\n",
            "        -5.4802e-05, -1.3312e-05,  9.2727e-05, -3.5656e-05, -7.7124e-05,\n",
            "         9.5164e-05,  3.2862e-05,  6.4275e-05, -7.5926e-05,  2.8251e-05,\n",
            "        -1.5875e-04,  8.6805e-05, -1.5911e-05,  9.5380e-05, -7.0572e-05,\n",
            "         8.3730e-05,  6.5325e-05, -8.0511e-05, -9.3120e-05,  1.4189e-04,\n",
            "        -4.1329e-06, -5.3574e-05, -1.9148e-05, -3.9523e-05, -6.0049e-06,\n",
            "         1.2283e-04, -5.4815e-06,  2.4917e-06,  1.6431e-05, -9.5444e-05,\n",
            "         6.8955e-06, -1.2823e-05,  7.2895e-05,  9.4616e-05, -9.0442e-05,\n",
            "         3.0259e-05,  5.0753e-05, -1.1714e-04, -3.6825e-05,  2.0979e-05,\n",
            "         6.1570e-05, -9.6461e-05,  1.7120e-05, -8.3609e-05, -6.2497e-05,\n",
            "         2.2120e-05,  1.4052e-06, -1.2533e-04,  4.8306e-05, -3.2982e-05,\n",
            "         1.2723e-04,  1.6728e-04,  2.8390e-05,  8.3536e-05, -1.1337e-04,\n",
            "         6.6827e-05,  9.7076e-05, -7.7370e-05, -7.6924e-05,  2.8106e-05,\n",
            "        -2.0601e-04, -3.0934e-05,  1.1449e-05,  7.1790e-05, -3.6240e-05,\n",
            "         8.8627e-05, -1.5465e-04,  5.8769e-05,  2.2084e-05, -2.9756e-05,\n",
            "        -1.8993e-06, -7.0029e-05,  2.1187e-06,  8.2227e-05, -1.1400e-04,\n",
            "         2.8489e-05,  8.4653e-05])), ('module.encoder_k.layer2.3.bn3.running_mean', tensor([ 4.8152e-02,  9.5913e-02, -1.8929e-01,  1.1280e-01, -3.0579e-01,\n",
            "        -2.1169e-01,  1.9438e-01, -3.2871e-02,  1.3397e-01,  6.4589e-02,\n",
            "         3.4737e-01, -6.3408e-02,  2.1757e-02, -2.2656e-01,  1.3538e-01,\n",
            "        -3.2152e-01, -4.5294e-01,  2.5109e-02,  3.2528e-01,  2.1147e-01,\n",
            "         1.9066e-01, -3.2452e-01,  4.0792e-01, -8.4605e-02, -2.0578e-02,\n",
            "         7.9023e-02, -1.3212e-01, -5.0022e-01,  4.4736e-01, -3.3373e-02,\n",
            "        -2.5448e-01, -2.1361e-01,  8.8440e-02,  1.5766e-01,  9.6504e-02,\n",
            "        -5.3197e-02, -1.0614e-01,  5.3164e-02, -1.4877e-01,  1.6352e-01,\n",
            "        -2.7412e-02, -6.2085e-02,  7.3884e-02, -2.6442e-01,  4.2731e-02,\n",
            "         5.0631e-02,  2.9283e-01,  1.9221e-01,  2.9196e-01,  3.8616e-02,\n",
            "         2.6839e-01, -2.0961e-01,  9.3861e-02,  2.6015e-01, -4.0705e-02,\n",
            "        -1.8650e-01,  1.0544e-01,  4.2109e-02,  9.3375e-02, -6.1547e-01,\n",
            "        -6.1224e-04,  5.2136e-02,  1.3704e-01,  6.8259e-03, -2.0500e-01,\n",
            "        -1.2934e-01, -2.6806e-01, -4.4738e-01,  2.9312e-02, -2.4626e-01,\n",
            "        -1.5467e-01,  2.9329e-02,  5.3913e-02,  5.3655e-02,  1.9239e-01,\n",
            "        -1.1393e-01,  2.6501e-02, -2.4428e-02,  5.7347e-01, -9.7786e-02,\n",
            "        -9.7530e-02,  1.8897e-01, -1.0591e-01,  1.2958e-01, -3.5016e-02,\n",
            "        -2.5346e-01, -6.3623e-02, -2.1070e-02,  2.7556e-01, -1.2856e-01,\n",
            "        -5.5452e-01, -6.6570e-02, -2.6428e-01,  1.5435e-01, -1.2017e-02,\n",
            "        -2.6504e-01,  4.6360e-02,  5.2070e-02,  1.1027e-01, -4.8459e-03,\n",
            "        -1.4338e-01, -9.8040e-03, -1.7342e-01,  1.3149e-02, -9.0899e-02,\n",
            "        -6.0527e-01, -3.1644e-01, -2.6565e-01,  4.6476e-02,  2.1763e-02,\n",
            "         2.2100e-02, -4.2279e-01, -6.6287e-02, -1.7932e-01,  2.5189e-01,\n",
            "        -6.0620e-02,  3.6694e-01,  1.9133e-02, -1.6559e-01, -3.4884e-01,\n",
            "        -5.8120e-02, -2.7305e-01, -1.9297e-02, -1.6406e-01,  1.9123e-01,\n",
            "         3.7649e-01,  1.2113e-01, -2.8490e-02,  4.2282e-01,  1.2945e-02,\n",
            "         1.6933e-01,  2.7561e-01,  3.4016e-03, -2.3294e-01,  1.4063e-01,\n",
            "        -2.5195e-01, -7.4462e-01, -1.4452e-01,  1.9663e-01, -1.0435e-01,\n",
            "        -3.4856e-01,  1.2674e-02, -5.2690e-01,  1.4483e-01, -1.4961e-01,\n",
            "         1.4711e-01,  2.7654e-01, -3.2484e-01,  1.9394e-01,  4.3727e-01,\n",
            "         2.2815e-01, -1.6775e-01,  5.4923e-01,  3.5746e-01,  4.6247e-02,\n",
            "        -2.0273e-01, -1.5457e-02, -3.2737e-01,  2.6074e-01, -1.0633e-01,\n",
            "        -1.6637e-01,  2.7050e-02,  1.8703e-01, -1.1544e-01, -4.1768e-01,\n",
            "        -2.3443e-01,  1.4796e-01, -3.3579e-01,  3.7707e-01,  1.6759e-01,\n",
            "         2.3631e-01, -3.4773e-01, -1.3703e-01, -4.6907e-02, -1.6278e-01,\n",
            "         1.6976e-01, -6.5829e-02,  1.0800e-01, -1.8803e-01, -1.6749e-01,\n",
            "        -1.2374e-01, -2.7243e-01,  5.3524e-01,  2.2291e-01, -9.9152e-02,\n",
            "        -2.6451e-01,  1.4841e-01,  1.7248e-01, -1.1565e-01,  8.3954e-02,\n",
            "        -3.2001e-02,  1.4183e-01,  3.4843e-01, -3.2999e-02, -5.2594e-01,\n",
            "        -1.4895e-01,  1.7952e-01,  5.1462e-02, -2.1536e-01,  1.4997e-01,\n",
            "        -1.8081e-02, -6.9210e-02,  1.2809e-01, -2.8159e-01,  1.4557e-01,\n",
            "         4.8084e-01, -9.2894e-02, -6.2212e-01, -1.6657e-01,  6.0462e-01,\n",
            "         2.1661e-01, -2.1992e-01, -1.5032e-01,  4.0682e-01, -1.8489e-01,\n",
            "        -7.4060e-02, -3.9218e-02,  3.3469e-01, -1.1572e-01,  4.2114e-01,\n",
            "        -5.4951e-01, -1.3072e-01,  2.4670e-01,  1.2902e-01,  2.2875e-01,\n",
            "         1.9592e-01, -1.5601e-01, -5.1167e-02,  1.1783e-01,  1.9424e-01,\n",
            "         2.6570e-01,  1.2934e-01, -4.2696e-01,  3.9169e-01,  7.9987e-03,\n",
            "         1.6719e-01, -5.7242e-01,  1.6562e-01,  9.2918e-02, -2.5837e-01,\n",
            "         1.5567e-02,  5.4924e-01, -1.3505e-02, -4.2836e-01,  1.8012e-01,\n",
            "        -3.1741e-01,  2.3285e-02,  4.8010e-01,  2.0111e-01,  1.0928e-01,\n",
            "         2.3785e-01,  3.0449e-01, -5.6118e-01, -2.8804e-01,  2.5658e-01,\n",
            "        -8.5397e-02, -7.8551e-02, -2.2118e-01, -1.0047e-01,  6.0127e-01,\n",
            "         2.4528e-01, -2.4221e-01,  1.8386e-01, -3.2494e-01,  5.3687e-01,\n",
            "        -1.2019e-01,  4.6988e-01, -2.0040e-01,  1.7875e-01,  4.7037e-03,\n",
            "        -6.1787e-02, -4.7547e-01, -1.7225e-01,  3.8249e-01, -2.0753e-01,\n",
            "         1.6281e-02, -2.2918e-01, -3.1460e-01,  4.9901e-02, -1.5438e-01,\n",
            "        -1.9945e-01, -2.8132e-01, -3.0924e-01,  3.4064e-01, -3.2471e-01,\n",
            "         3.2846e-01, -3.9673e-01,  1.8434e-01, -1.2343e-01, -1.5323e-01,\n",
            "        -1.7621e-01, -2.9462e-01, -1.9074e-01,  1.9982e-01,  1.5646e-01,\n",
            "         4.9147e-02, -1.8407e-01, -5.4694e-02,  3.6296e-03,  8.4348e-02,\n",
            "         3.2761e-01, -8.3775e-02,  3.6173e-01, -3.0455e-01, -1.6406e-01,\n",
            "        -3.3096e-01,  2.5865e-01, -1.0375e-01,  7.3095e-02, -3.1393e-01,\n",
            "        -3.1627e-01, -1.4134e-01, -1.4529e-01,  2.0847e-02, -1.1922e-01,\n",
            "         3.2337e-01, -4.3169e-01,  3.5775e-01, -2.2978e-01,  4.1021e-01,\n",
            "         2.2383e-01,  2.2943e-01, -4.2387e-01, -2.4714e-01,  5.9500e-02,\n",
            "         3.6023e-01,  8.1343e-02, -1.1636e-01, -6.9499e-02,  8.3606e-02,\n",
            "         1.0844e-01, -9.5649e-02, -1.0793e-01,  3.7719e-01,  3.1670e-01,\n",
            "         2.5521e-01, -2.2448e-02, -1.5272e-01,  1.5848e-01, -2.2990e-01,\n",
            "        -3.3572e-01, -4.3529e-01, -3.5661e-01,  2.9023e-01, -1.8715e-01,\n",
            "         6.0854e-02,  1.7746e-02, -1.7315e-01,  2.1984e-01,  4.2765e-02,\n",
            "        -8.0685e-02,  2.5505e-01, -1.0591e-01,  1.8548e-01, -1.4312e-01,\n",
            "        -2.7304e-01,  2.4686e-02, -1.5439e-01,  2.5937e-01, -8.2494e-02,\n",
            "        -3.0388e-01,  3.9609e-02,  8.1624e-02, -3.2570e-01,  6.3934e-01,\n",
            "        -2.9469e-01,  4.2156e-02,  2.0442e-01,  3.6548e-01,  3.2907e-01,\n",
            "        -1.9063e-01,  3.9931e-02, -4.7605e-02, -2.5221e-01,  3.8075e-01,\n",
            "        -3.2474e-02,  4.3127e-01,  6.9400e-02, -2.8976e-02, -1.2465e-01,\n",
            "        -2.8021e-01,  2.0325e-01, -6.7067e-02, -1.6989e-01,  3.8210e-02,\n",
            "         7.0456e-02,  2.5675e-01,  5.0193e-01,  6.9499e-02,  5.5536e-01,\n",
            "        -3.2763e-01, -1.8480e-01,  2.8071e-01, -2.7590e-01,  3.8616e-01,\n",
            "         5.1687e-01,  1.4304e-02, -3.4011e-02, -2.5539e-01, -3.4207e-01,\n",
            "         9.3716e-02, -3.3029e-01,  1.7830e-01,  1.7934e-02, -3.0968e-01,\n",
            "         2.9140e-01,  7.2754e-01, -5.9384e-02,  3.3000e-01,  3.3833e-01,\n",
            "        -1.3155e-01,  1.5391e-02, -3.2902e-01, -2.0327e-01,  1.1277e-01,\n",
            "        -1.9392e-01, -4.1961e-01,  6.4801e-02,  1.9834e-01,  8.4374e-02,\n",
            "         3.7884e-01,  1.4595e-01, -6.9957e-01,  1.2570e-01, -1.5622e-01,\n",
            "        -1.2492e-01, -1.5373e-01,  3.1433e-01, -3.8665e-02,  1.0281e-02,\n",
            "         3.4107e-01,  2.8222e-01,  2.7379e-01,  2.5292e-01, -1.2619e-01,\n",
            "        -3.5832e-01, -3.1293e-01,  2.6072e-02,  8.0202e-02, -3.6276e-02,\n",
            "         1.6669e-01, -1.8095e-01, -1.1230e-04,  2.3210e-01, -1.3710e-01,\n",
            "         1.1686e-01, -1.0498e-01,  7.8473e-02, -4.4682e-04,  4.2181e-01,\n",
            "         5.7244e-03, -1.6304e-01,  2.1214e-01,  7.8698e-02, -6.5594e-02,\n",
            "         1.1109e-01,  3.5677e-01,  1.5788e-01, -1.3059e-01,  7.9735e-02,\n",
            "         1.5895e-01,  3.0290e-01, -5.3467e-02,  1.6152e-01,  3.8494e-01,\n",
            "         5.8515e-02,  1.2398e-01,  1.1828e-01, -3.0722e-01,  2.7292e-01,\n",
            "        -3.2137e-01,  1.6160e-01,  3.0762e-01, -2.6539e-01, -2.2501e-01,\n",
            "        -2.5164e-01, -7.5519e-02,  8.3317e-02, -2.0190e-01,  1.0598e-01,\n",
            "         1.3347e-01,  4.3959e-02,  1.1931e-01,  2.9665e-01, -1.0041e-01,\n",
            "        -3.1389e-01, -3.7419e-02, -2.8293e-02, -1.8269e-01,  5.9780e-02,\n",
            "         1.1337e-01,  3.8761e-01,  2.9383e-01,  1.5280e-01, -6.8554e-02,\n",
            "         1.3721e-01,  4.4817e-02, -1.8570e-01,  1.9506e-01, -1.0654e-01,\n",
            "         1.4902e-01,  1.6013e-01, -3.3223e-02, -1.3279e-01,  6.2101e-02,\n",
            "         4.5778e-01, -4.8269e-01,  1.3828e-01,  1.0906e-01,  1.7354e-02,\n",
            "         1.6199e-02,  2.3914e-01])), ('module.encoder_k.layer2.3.bn3.running_var', tensor([0.1495, 0.1225, 0.1832, 0.1816, 0.1440, 0.2451, 0.1411, 0.1443, 0.2051,\n",
            "        0.1670, 0.1158, 0.1675, 0.1543, 0.1666, 0.1549, 0.1837, 0.2215, 0.1698,\n",
            "        0.2737, 0.1684, 0.1986, 0.1873, 0.2334, 0.1600, 0.1418, 0.1692, 0.1415,\n",
            "        0.2009, 0.1694, 0.1817, 0.3638, 0.1413, 0.1944, 0.1676, 0.1885, 0.1695,\n",
            "        0.2529, 0.1683, 0.1750, 0.1635, 0.1687, 0.1852, 0.1569, 0.2209, 0.3017,\n",
            "        0.1714, 0.1835, 0.1628, 0.1744, 0.1601, 0.2557, 0.1804, 0.1560, 0.1788,\n",
            "        0.1595, 0.1837, 0.1730, 0.1871, 0.1740, 0.6450, 0.1404, 0.1707, 0.2911,\n",
            "        0.1349, 0.1369, 0.1697, 0.1710, 0.3545, 0.1584, 0.1734, 0.1731, 0.1906,\n",
            "        0.1480, 0.1592, 0.1605, 0.1659, 0.2929, 0.1935, 0.1870, 0.1581, 0.1698,\n",
            "        0.1764, 0.1426, 0.1423, 0.1830, 0.1659, 0.1618, 0.1131, 0.2158, 0.1796,\n",
            "        0.4329, 0.1535, 0.2254, 0.1538, 0.1637, 0.1635, 0.2303, 0.2103, 0.1723,\n",
            "        0.1530, 0.1507, 0.1788, 0.1678, 0.1562, 0.2593, 0.1744, 0.3489, 0.1705,\n",
            "        0.1277, 0.1683, 0.2035, 0.2712, 0.1628, 0.1488, 0.1535, 0.1771, 0.3762,\n",
            "        0.1269, 0.1565, 0.1996, 0.1574, 0.1355, 0.1232, 0.1570, 0.1666, 0.1448,\n",
            "        0.1402, 0.1716, 0.2235, 0.1238, 0.1328, 0.1576, 0.1290, 0.1254, 0.2385,\n",
            "        0.1372, 0.3471, 0.1628, 0.2457, 0.2656, 0.2565, 0.1886, 0.2920, 0.2139,\n",
            "        0.2100, 0.2085, 0.1514, 0.1362, 0.1914, 0.3108, 0.1533, 0.2107, 0.1943,\n",
            "        0.1552, 0.1590, 0.1858, 0.4049, 0.1805, 0.1799, 0.1499, 0.2342, 0.1438,\n",
            "        0.1128, 0.1732, 0.2374, 0.2022, 0.1582, 0.1530, 0.2875, 0.1435, 0.1154,\n",
            "        0.1982, 0.2301, 0.1499, 0.1506, 0.1401, 0.2467, 0.1253, 0.1842, 0.1551,\n",
            "        0.1989, 0.2755, 0.2526, 0.1661, 0.1450, 0.1343, 0.1885, 0.1664, 0.2193,\n",
            "        0.1249, 0.1445, 0.1252, 0.1795, 0.1372, 0.1754, 0.2048, 0.1190, 0.1359,\n",
            "        0.2381, 0.3118, 0.1096, 0.1396, 0.1766, 0.3089, 0.1095, 0.2796, 0.1417,\n",
            "        0.3351, 0.1670, 0.2831, 0.1746, 0.3340, 0.1595, 0.2785, 0.1187, 0.2338,\n",
            "        0.1588, 0.4203, 0.1088, 0.3334, 0.2769, 0.1511, 0.1496, 0.1741, 0.2220,\n",
            "        0.2007, 0.1497, 0.2020, 0.1765, 0.2699, 0.1283, 0.1497, 0.1676, 0.3574,\n",
            "        0.1269, 0.1349, 0.4120, 0.1731, 0.2017, 0.2172, 0.2783, 0.1551, 0.1488,\n",
            "        0.3000, 0.1584, 0.1860, 0.1348, 0.2952, 0.1950, 0.1528, 0.2150, 0.1742,\n",
            "        0.2658, 0.1410, 0.1969, 0.1397, 0.1534, 0.2127, 0.1514, 0.4109, 0.1806,\n",
            "        0.1491, 0.1861, 0.1433, 0.4343, 0.1687, 0.6664, 0.1710, 0.1592, 0.1406,\n",
            "        0.1416, 0.1364, 0.2080, 0.2540, 0.2309, 0.1658, 0.2126, 0.3485, 0.1962,\n",
            "        0.2105, 0.1776, 0.1655, 0.3009, 0.2142, 0.1801, 0.2012, 0.4037, 0.4421,\n",
            "        0.1559, 0.1223, 0.1300, 0.1661, 0.1251, 0.1797, 0.3344, 0.1375, 0.1524,\n",
            "        0.1820, 0.1766, 0.1940, 0.2867, 0.1605, 0.1377, 0.1655, 0.2073, 0.1202,\n",
            "        0.2115, 0.1505, 0.1372, 0.2240, 0.3689, 0.1587, 0.1461, 0.1492, 0.1719,\n",
            "        0.2040, 0.3936, 0.1298, 0.1682, 0.2508, 0.1746, 0.3261, 0.2759, 0.1772,\n",
            "        0.1465, 0.1596, 0.1845, 0.1499, 0.1278, 0.3040, 0.2291, 0.1487, 0.1556,\n",
            "        0.1854, 0.2461, 0.1647, 0.1359, 0.1614, 0.1569, 0.1767, 0.1848, 0.2491,\n",
            "        0.2257, 0.1391, 0.1477, 0.1693, 0.1801, 0.1177, 0.1242, 0.1335, 0.1806,\n",
            "        0.1776, 0.1541, 0.1504, 0.1608, 0.1887, 0.1734, 0.2276, 0.1448, 0.1547,\n",
            "        0.1190, 0.2567, 0.1346, 0.2024, 0.2089, 0.1764, 0.1920, 0.1858, 0.1781,\n",
            "        0.2435, 0.2305, 0.1704, 0.1514, 0.1667, 0.1503, 0.1439, 0.2274, 0.1797,\n",
            "        0.1313, 0.1352, 0.1514, 0.1871, 0.1624, 0.1710, 0.1364, 0.1518, 0.1739,\n",
            "        0.3982, 0.1072, 0.2837, 0.1222, 0.1465, 0.1845, 0.1715, 0.4698, 0.1150,\n",
            "        0.1304, 0.1581, 0.1860, 0.1367, 0.1405, 0.1408, 0.1451, 0.2201, 0.1704,\n",
            "        0.1848, 0.2470, 0.1405, 0.1309, 0.1559, 0.1652, 0.1728, 0.2010, 0.1237,\n",
            "        0.2053, 0.2774, 0.3452, 0.1591, 0.1798, 0.2480, 0.1709, 0.1241, 0.2233,\n",
            "        0.1442, 0.1925, 0.1979, 0.1729, 0.2267, 0.1467, 0.1483, 0.2297, 0.2756,\n",
            "        0.2063, 0.1923, 0.1356, 0.2287, 0.1723, 0.1878, 0.1383, 0.1626, 0.1524,\n",
            "        0.1674, 0.1403, 0.1466, 0.1333, 0.1307, 0.1441, 0.1502, 0.1776, 0.1477,\n",
            "        0.1531, 0.1827, 0.1761, 0.2143, 0.1669, 0.1950, 0.3836, 0.1670, 0.1811,\n",
            "        0.1815, 0.1954, 0.1693, 0.1446, 0.1453, 0.1786, 0.1701, 0.2178, 0.1818,\n",
            "        0.1670, 0.1908, 0.1439, 0.1763, 0.1295, 0.1778, 0.1775, 0.1443, 0.1816,\n",
            "        0.1391, 0.1833, 0.1485, 0.1579, 0.1948, 0.1810, 0.1914, 0.1265, 0.3461,\n",
            "        0.1400, 0.1744, 0.1677, 0.1875, 0.1770, 0.1515, 0.1349, 0.2083, 0.1541,\n",
            "        0.2558, 0.2071, 0.1527, 0.1853, 0.1394, 0.1374, 0.1616, 0.1641, 0.1383,\n",
            "        0.2144, 0.5312, 0.1811, 0.1683, 0.1861, 0.1307, 0.1189, 0.1616])), ('module.encoder_k.layer2.3.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.0.conv1.weight', tensor([[[[ 0.0208]],\n",
            "\n",
            "         [[ 0.0173]],\n",
            "\n",
            "         [[-0.0272]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0363]],\n",
            "\n",
            "         [[ 0.1408]],\n",
            "\n",
            "         [[-0.0880]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0330]],\n",
            "\n",
            "         [[-0.1065]],\n",
            "\n",
            "         [[-0.1545]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1268]],\n",
            "\n",
            "         [[-0.0160]],\n",
            "\n",
            "         [[-0.0124]]],\n",
            "\n",
            "\n",
            "        [[[-0.0513]],\n",
            "\n",
            "         [[-0.1429]],\n",
            "\n",
            "         [[ 0.0447]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0530]],\n",
            "\n",
            "         [[-0.0655]],\n",
            "\n",
            "         [[-0.1854]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1546]],\n",
            "\n",
            "         [[-0.0533]],\n",
            "\n",
            "         [[ 0.0213]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0002]],\n",
            "\n",
            "         [[ 0.0046]],\n",
            "\n",
            "         [[ 0.1533]]],\n",
            "\n",
            "\n",
            "        [[[-0.1916]],\n",
            "\n",
            "         [[-0.0211]],\n",
            "\n",
            "         [[ 0.1156]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0727]],\n",
            "\n",
            "         [[ 0.0300]],\n",
            "\n",
            "         [[ 0.0668]]],\n",
            "\n",
            "\n",
            "        [[[-0.1330]],\n",
            "\n",
            "         [[ 0.1042]],\n",
            "\n",
            "         [[ 0.0934]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0667]],\n",
            "\n",
            "         [[-0.1707]],\n",
            "\n",
            "         [[ 0.0478]]]])), ('module.encoder_k.layer3.0.bn1.weight', tensor([0.9989, 0.9990, 0.9990, 0.9990, 0.9992, 0.9988, 0.9988, 0.9992, 0.9991,\n",
            "        0.9990, 0.9989, 0.9992, 0.9992, 0.9996, 0.9987, 0.9991, 0.9995, 0.9990,\n",
            "        0.9993, 0.9992, 0.9995, 0.9990, 0.9989, 0.9988, 0.9989, 0.9990, 0.9991,\n",
            "        0.9992, 0.9989, 0.9988, 0.9991, 0.9990, 0.9992, 0.9990, 0.9992, 0.9989,\n",
            "        0.9994, 0.9989, 0.9991, 0.9984, 0.9989, 0.9990, 0.9989, 0.9989, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9993, 0.9993, 0.9992, 0.9993, 0.9991,\n",
            "        0.9993, 0.9990, 0.9993, 0.9992, 0.9995, 0.9988, 0.9990, 0.9993, 0.9984,\n",
            "        0.9991, 0.9988, 0.9992, 0.9989, 0.9994, 0.9992, 0.9990, 0.9987, 0.9991,\n",
            "        0.9990, 0.9989, 0.9992, 0.9992, 0.9989, 0.9989, 0.9990, 0.9991, 0.9994,\n",
            "        0.9989, 0.9995, 0.9990, 0.9990, 0.9992, 0.9988, 0.9989, 0.9989, 0.9990,\n",
            "        0.9989, 0.9990, 0.9992, 0.9988, 0.9990, 0.9991, 0.9991, 0.9989, 0.9992,\n",
            "        0.9989, 0.9993, 0.9991, 0.9993, 0.9989, 0.9992, 0.9996, 0.9990, 0.9994,\n",
            "        0.9993, 0.9991, 0.9987, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9993,\n",
            "        0.9989, 0.9987, 0.9990, 0.9991, 0.9992, 0.9989, 0.9991, 0.9993, 0.9992,\n",
            "        0.9989, 0.9992, 0.9992, 0.9990, 0.9991, 0.9994, 0.9993, 0.9991, 0.9992,\n",
            "        0.9992, 0.9992, 0.9992, 0.9991, 0.9993, 0.9988, 0.9988, 0.9989, 0.9991,\n",
            "        0.9990, 0.9993, 0.9992, 0.9992, 0.9990, 0.9995, 0.9991, 0.9992, 0.9988,\n",
            "        0.9993, 0.9992, 0.9990, 0.9990, 0.9994, 0.9995, 0.9994, 0.9990, 0.9990,\n",
            "        0.9990, 0.9989, 0.9989, 0.9995, 0.9990, 0.9991, 0.9993, 0.9989, 0.9987,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9989, 0.9990, 0.9988, 0.9986,\n",
            "        0.9993, 0.9989, 0.9987, 0.9992, 0.9997, 0.9992, 0.9993, 0.9993, 0.9989,\n",
            "        0.9996, 0.9991, 0.9991, 0.9989, 0.9997, 0.9990, 0.9989, 0.9990, 0.9989,\n",
            "        0.9990, 0.9993, 0.9986, 0.9990, 0.9992, 0.9991, 0.9988, 0.9990, 0.9993,\n",
            "        0.9990, 0.9990, 0.9995, 0.9991, 0.9991, 0.9991, 0.9991, 0.9988, 0.9991,\n",
            "        0.9988, 0.9990, 0.9992, 0.9988, 0.9993, 0.9995, 0.9996, 0.9988, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9987, 0.9990, 0.9989, 0.9990,\n",
            "        0.9994, 0.9992, 0.9989, 0.9990, 0.9988, 0.9995, 0.9992, 0.9990, 0.9994,\n",
            "        0.9989, 0.9988, 0.9992, 0.9990, 0.9990, 0.9992, 0.9990, 0.9990, 0.9996,\n",
            "        0.9995, 0.9991, 0.9990, 0.9989])), ('module.encoder_k.layer3.0.bn1.bias', tensor([-1.4921e-04, -3.4114e-04,  4.5460e-05,  2.2460e-04,  2.0646e-04,\n",
            "        -3.2056e-04, -1.1550e-04,  3.3101e-04,  1.3904e-04,  4.9010e-05,\n",
            "        -1.9035e-04, -1.8815e-04,  1.0759e-04,  2.0221e-04, -6.0244e-05,\n",
            "         9.8349e-05,  2.6381e-04, -2.1762e-05,  2.2753e-04,  3.1887e-04,\n",
            "         2.0439e-04,  2.6308e-05, -4.5879e-04, -5.2603e-04, -6.4194e-05,\n",
            "        -5.2453e-05, -3.0304e-05, -2.9649e-06, -1.8112e-04,  1.8454e-04,\n",
            "        -2.7518e-04,  3.5553e-05,  2.1753e-04, -7.0064e-05,  1.7273e-04,\n",
            "         2.5964e-05,  4.6639e-04, -1.7541e-04, -7.5882e-05, -5.8288e-04,\n",
            "        -1.9294e-04, -3.8876e-05, -4.0728e-05, -1.5310e-04, -8.9257e-05,\n",
            "        -1.7740e-04, -7.4681e-05, -9.0650e-05,  4.5857e-06,  2.9018e-04,\n",
            "         2.2281e-04, -1.1063e-05, -3.1649e-05,  3.4203e-04,  2.2653e-04,\n",
            "        -3.3812e-04,  1.2716e-04, -1.5595e-04,  2.1205e-04, -1.9194e-04,\n",
            "         7.0063e-05,  1.7670e-04, -4.0966e-04,  5.4809e-05,  2.4185e-05,\n",
            "        -2.5136e-05, -2.5699e-04,  1.2580e-04,  9.9863e-05, -3.3191e-04,\n",
            "        -3.6269e-04, -1.1037e-04, -2.1138e-04, -2.7738e-04,  1.1336e-04,\n",
            "         1.3530e-04,  2.9727e-04, -2.5416e-04, -1.5405e-05, -2.2553e-04,\n",
            "         1.4323e-04,  2.0923e-04,  2.6998e-04, -2.0483e-04, -3.1634e-04,\n",
            "         1.2369e-05, -1.3736e-04, -3.6806e-04,  2.8758e-05,  1.1118e-04,\n",
            "        -1.3818e-04, -3.6163e-04, -1.7306e-05, -1.2867e-04, -6.0834e-05,\n",
            "        -6.5887e-05,  1.8490e-04, -1.3540e-04,  1.6859e-04, -9.5899e-05,\n",
            "         2.8937e-04, -8.2163e-05,  2.7654e-04, -1.4530e-04,  2.8977e-04,\n",
            "         3.7542e-04, -7.5175e-05,  4.1630e-04,  6.4528e-05,  1.7257e-04,\n",
            "        -1.7099e-04,  1.5091e-04, -2.4530e-04,  8.8233e-06,  3.6506e-04,\n",
            "        -2.8198e-04,  1.5642e-04, -1.6467e-04, -5.3160e-05, -1.5304e-04,\n",
            "        -8.5215e-05,  5.2617e-05,  3.1997e-05,  2.7546e-04,  2.8633e-06,\n",
            "         1.0114e-04,  1.0712e-04,  1.3484e-04,  5.6996e-05,  4.9345e-05,\n",
            "        -5.1976e-05,  1.5639e-04,  2.9670e-04,  2.2323e-04,  7.8223e-05,\n",
            "        -3.3406e-04, -1.4407e-04,  3.9210e-04, -1.3264e-04,  2.2918e-04,\n",
            "        -1.1181e-04,  2.1246e-04, -1.1779e-04, -3.2230e-04, -5.4825e-04,\n",
            "         1.2246e-04,  3.9980e-04,  1.9419e-04,  3.5593e-06,  4.2317e-04,\n",
            "        -1.4549e-04,  2.1198e-04, -6.4463e-05,  3.6513e-04,  4.6870e-04,\n",
            "        -1.9144e-05,  1.2585e-04,  2.0921e-04,  2.0463e-04,  1.9100e-04,\n",
            "        -1.9266e-04, -1.6740e-04, -1.3629e-04, -7.8716e-05, -3.3556e-06,\n",
            "         1.4733e-04,  8.3841e-05, -4.7102e-05,  2.1201e-04,  1.9635e-04,\n",
            "        -2.2541e-04,  3.5700e-04, -8.6391e-05,  2.4619e-04, -1.1433e-04,\n",
            "        -1.6677e-04, -2.1795e-05, -2.1092e-04, -3.8441e-04, -1.5191e-04,\n",
            "         8.7641e-05, -1.5325e-04, -2.5714e-04,  2.3084e-04,  4.5337e-04,\n",
            "         3.1203e-04,  2.3081e-04,  7.9260e-05, -1.0886e-04,  4.3668e-04,\n",
            "         6.3653e-05,  1.3713e-04,  4.8302e-06,  6.4863e-04, -3.4633e-05,\n",
            "         7.5175e-05,  9.1670e-05, -2.2340e-04,  3.7496e-05,  8.1968e-05,\n",
            "        -2.4785e-04, -5.3211e-05,  1.6496e-04, -1.9600e-04, -1.4816e-04,\n",
            "        -6.9458e-05,  3.4608e-04,  1.3231e-04, -3.1288e-05, -1.3482e-04,\n",
            "         2.9676e-05,  2.1706e-04,  1.4637e-04,  5.5367e-05, -1.3000e-04,\n",
            "         2.2377e-04, -7.7132e-04, -6.8741e-05,  1.7623e-04, -3.1873e-04,\n",
            "        -4.9826e-06,  1.4497e-04,  8.3582e-05,  1.6079e-05,  2.9811e-04,\n",
            "        -1.7297e-04, -4.9838e-05,  3.1277e-04, -1.7773e-04,  5.9009e-05,\n",
            "        -1.9070e-04, -2.6638e-04,  1.4886e-04, -4.2632e-05,  2.2099e-04,\n",
            "        -3.0409e-04, -1.2452e-04, -1.8401e-04, -2.2000e-04,  1.2447e-04,\n",
            "         1.0533e-04,  1.1940e-04,  1.6741e-04, -1.0906e-04, -1.4216e-04,\n",
            "         2.2562e-04,  2.9479e-04,  9.1628e-05,  1.7970e-04, -1.1774e-04,\n",
            "         3.8551e-04,  2.5107e-04, -1.2601e-05,  1.4722e-04, -1.9711e-04,\n",
            "        -1.4387e-04])), ('module.encoder_k.layer3.0.bn1.running_mean', tensor([-1.4999,  4.1818, -1.3971, -1.7579,  4.3491, -0.8932,  2.7224, -1.2859,\n",
            "         0.3708,  1.8760,  2.5015, -0.0706,  0.1273, -0.3976,  4.2596, -3.1817,\n",
            "         1.8565,  0.2062, -0.1425,  0.4500, -2.9394, -1.6782,  1.9768, -3.2951,\n",
            "         0.0590,  0.7444,  2.1878,  4.4788, -2.2216,  3.9030, -3.6277,  2.0688,\n",
            "         1.4451, -0.5387, -1.9526, -4.2679, -0.4656, -0.8702, -0.6028, -1.4388,\n",
            "        -2.2384,  1.4060, -2.3001, -2.6474,  0.4966,  1.8354, -0.5904, -4.3692,\n",
            "         0.2567, -3.0534,  4.3033,  1.4704, -0.8214, -5.9057, -1.2786, -2.8729,\n",
            "        -1.0997,  1.3754, -1.5281,  0.7977,  5.2405,  0.4266, -0.9821, -0.4581,\n",
            "        -1.5453, -3.1960,  0.7635,  2.6423,  0.4228,  2.1908, -0.7334,  5.3819,\n",
            "         0.7973, -1.3612,  0.8207,  3.5050,  0.7345,  0.1516,  0.1410,  0.6289,\n",
            "         3.7017, -0.7770,  1.0021, -1.3998, -2.6292,  1.0031, -0.0743,  1.4973,\n",
            "         2.8045,  3.0696, -0.6409,  0.1330,  1.2811, -1.4331,  1.1488, -0.6623,\n",
            "         2.9860,  2.8167, -0.1877,  5.3409, -1.7930, -1.3731, -2.1496,  2.2764,\n",
            "         1.1790, -1.4795, -0.8018, -0.7600, -0.3203,  1.3374, -2.5577, -0.2885,\n",
            "        -0.7970, -2.7981,  1.1461,  2.3712,  4.6741,  4.2037, -1.2772, -1.2561,\n",
            "         2.1674, -2.2727, -1.6435,  3.3289,  3.3978,  1.0639, -4.0684,  1.1950,\n",
            "         0.1992, -1.2340,  8.3943, -0.5707, -0.9336, -2.0593, -4.6274, -0.3783,\n",
            "         2.4349,  0.1464,  1.4707,  1.5697,  0.1025,  4.6079, -2.8786,  2.4715,\n",
            "         0.0228,  0.0212, -1.8499,  2.2522, -0.0587, -0.0346, -1.8792, -0.1512,\n",
            "         1.2383, -0.5818, -4.6920,  3.8304,  0.7215,  0.0785, -0.2383,  0.1945,\n",
            "        -0.7020,  0.4982, -4.3638, -0.4432, -0.5483,  1.4775,  0.4922,  2.5628,\n",
            "        -2.5512,  4.9576,  4.0111,  1.1888,  1.2846,  3.3100, -0.9667,  0.3612,\n",
            "         2.9014, -2.4310, -2.1185,  3.0421,  0.2239, -2.0318, -2.1202,  1.8913,\n",
            "         1.3103,  1.1079, -4.6777,  0.0640,  0.3121,  4.4168,  0.4028,  1.9941,\n",
            "        -3.2510, -2.1491,  2.7477, -1.2679, -0.1376, -2.7500,  0.0577,  0.1102,\n",
            "         3.4929,  3.5455, -3.1689,  1.1094,  2.5014, -1.5983, -1.4784, -0.1809,\n",
            "         0.4376, -1.6574, -1.9918,  1.3077,  2.2262, -0.9950,  5.5264, -0.6600,\n",
            "         3.7182,  0.0341,  1.9714,  3.1505,  0.2885,  1.0642,  0.2570, -0.1026,\n",
            "         0.1909, -0.3456, -2.7311,  2.1447, -4.0036, -0.0832, -2.6881,  0.2492,\n",
            "        -0.0561,  2.4564,  1.7330,  0.1428,  0.5474, -0.7864, -1.3980,  1.1856,\n",
            "         0.7937, -1.3315, -0.5686,  0.4876, -0.8704,  2.0167,  0.3996, -0.6687,\n",
            "        -2.5488,  0.8569, -0.0304,  2.4514, -1.0795, -2.6017, -0.1863, -1.9406])), ('module.encoder_k.layer3.0.bn1.running_var', tensor([ 7.2140,  5.6387,  7.6533,  6.9493,  9.9920,  5.5964,  5.9036,  5.7464,\n",
            "         5.9019,  6.3368,  5.6521, 11.4835,  5.9247,  7.2802, 11.5991, 15.4382,\n",
            "         6.4185,  6.8862,  5.5570,  5.8128,  5.6549,  6.5580,  9.0280,  6.2601,\n",
            "         5.8568,  7.8912,  5.3451, 13.0484,  6.3455,  8.9435,  8.4808,  7.6420,\n",
            "         5.3726,  5.6945,  6.1877, 13.7769,  5.0842,  6.0130,  6.5605,  7.0928,\n",
            "         6.3254,  6.2456, 10.9801,  5.4018,  7.6224,  8.1329,  7.2632, 14.4305,\n",
            "         5.8073,  9.0636, 10.0223, 10.5910,  6.7925, 22.5113,  6.1482,  9.7586,\n",
            "         5.4637,  5.8486,  5.6926,  5.7311, 12.6653,  7.0876,  5.3793,  6.8113,\n",
            "         5.1017,  7.2583,  8.9687,  8.1551,  7.4722,  8.9362,  5.2177, 23.2225,\n",
            "         5.4251,  7.5238,  5.9485,  7.9251,  6.5672,  6.0036,  5.8071,  8.2126,\n",
            "         6.7757,  4.9298,  5.7984, 10.0618,  6.1846,  8.4990,  6.7881,  6.8792,\n",
            "         6.4154,  5.8936,  7.0876,  8.2530,  8.8038,  7.3355,  5.8961,  7.7128,\n",
            "         6.0759, 20.5376,  8.1510, 13.5312, 10.4187,  6.2488, 15.8335,  9.0075,\n",
            "         6.4426,  9.5943,  7.4737,  6.6154,  5.7853,  9.0588,  5.6863,  5.9536,\n",
            "         5.9733, 15.7399,  6.3012,  6.9322,  9.8315, 13.1203,  8.4766,  8.4065,\n",
            "         8.8042,  7.0552,  5.0654,  8.6230,  9.5247,  5.1760, 13.9085,  6.0177,\n",
            "         6.1940,  7.6926, 43.5824,  9.4937,  7.7469,  6.8811, 16.0106,  8.3812,\n",
            "         8.3948,  9.5409, 15.3486,  6.5080,  5.6192, 16.5417,  8.9573, 10.7389,\n",
            "         6.0035,  5.8348,  8.3329,  7.1546,  6.4504,  5.4235,  7.1391,  8.2269,\n",
            "         7.3465,  5.1015, 11.1909,  8.2648,  6.4227,  7.3483,  6.7898,  7.1597,\n",
            "         8.1048,  5.8770, 11.6475,  5.2067,  7.4474, 14.4454,  6.7879, 12.0189,\n",
            "        13.9690, 10.6162,  7.7295,  5.5633,  4.7774,  8.0581,  9.5646,  6.9317,\n",
            "        21.7355,  8.2079,  6.8129,  7.7715,  6.3798,  7.8403, 12.9587,  5.9489,\n",
            "         5.9616,  7.5596,  8.1162,  9.2940,  5.4176, 10.1913,  5.8676,  6.2512,\n",
            "        13.3685,  6.9410, 11.1062,  6.7106,  5.5787,  6.3306,  5.5661,  8.2622,\n",
            "         9.5757, 18.3644,  7.5728,  5.8850,  4.9992,  9.9473, 18.7629,  7.1935,\n",
            "         7.7025,  5.5455,  6.6485,  7.8936,  5.7685, 11.9865, 17.1634,  9.8560,\n",
            "        10.5587,  7.1708,  6.4277,  5.8927,  8.3742,  7.5777,  9.4124,  5.8691,\n",
            "        13.6883,  6.3820,  6.9052,  6.7713,  6.4560,  6.3916,  7.7350,  4.7949,\n",
            "         6.8876,  9.0600,  6.0968,  6.1429,  5.8854,  6.2908,  7.2085,  5.3172,\n",
            "         5.9269,  7.0435,  9.3515,  5.6393,  5.3317,  6.6372,  8.4529,  6.6105,\n",
            "         5.8811,  5.9436,  6.9807, 10.1455,  5.8726,  6.5525, 10.2513,  9.3421])), ('module.encoder_k.layer3.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.0.conv2.weight', tensor([[[[ 5.4896e-03,  2.9160e-02,  3.9711e-03],\n",
            "          [ 5.5603e-02, -2.8885e-03,  4.8703e-02],\n",
            "          [ 2.8203e-02,  1.6619e-02,  2.1617e-02]],\n",
            "\n",
            "         [[ 3.8509e-02, -4.7255e-03, -2.7901e-02],\n",
            "          [ 3.4342e-02, -9.7773e-02,  1.6053e-02],\n",
            "          [ 2.9236e-02, -5.9345e-02,  6.1264e-02]],\n",
            "\n",
            "         [[-4.4631e-03,  2.3934e-02, -1.8358e-02],\n",
            "          [-3.7283e-02,  1.6296e-02,  1.0335e-02],\n",
            "          [ 4.3150e-03, -4.7834e-02,  5.8779e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2753e-02, -1.6110e-03,  1.7425e-02],\n",
            "          [-2.7927e-02,  6.8767e-02, -4.9213e-03],\n",
            "          [-2.7358e-02, -2.0989e-02,  3.7467e-02]],\n",
            "\n",
            "         [[ 1.9225e-02, -8.5151e-02, -5.3893e-02],\n",
            "          [-1.8477e-02,  1.2833e-02, -1.0981e-02],\n",
            "          [ 1.2020e-02,  8.1102e-03, -2.6509e-02]],\n",
            "\n",
            "         [[-6.8508e-03,  1.2832e-02,  2.7668e-02],\n",
            "          [-3.5577e-02,  9.1967e-03,  4.2664e-02],\n",
            "          [ 8.8541e-03, -3.1701e-02, -4.9604e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7167e-02,  3.8087e-02,  5.8618e-03],\n",
            "          [-3.6060e-02,  1.9829e-02, -7.9633e-03],\n",
            "          [-4.7601e-02, -1.4817e-02,  6.5723e-04]],\n",
            "\n",
            "         [[ 4.3751e-02,  1.7998e-02,  3.5216e-02],\n",
            "          [-3.3268e-02,  1.3086e-02,  3.0987e-03],\n",
            "          [ 8.3185e-03, -5.3892e-02, -1.1274e-02]],\n",
            "\n",
            "         [[-4.4711e-02,  3.6687e-02, -2.5854e-02],\n",
            "          [ 4.9908e-02, -8.7261e-03,  4.4004e-02],\n",
            "          [-6.2680e-03, -3.4532e-02,  4.1069e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6946e-02, -3.3537e-02,  5.3422e-02],\n",
            "          [ 9.5608e-03, -1.4107e-02,  2.4610e-02],\n",
            "          [ 1.0045e-02, -1.3729e-03,  2.5043e-02]],\n",
            "\n",
            "         [[-1.7425e-03, -1.3502e-02, -1.2304e-02],\n",
            "          [ 2.0737e-02,  1.0353e-03,  6.7334e-04],\n",
            "          [ 9.1755e-02,  2.3571e-02,  6.6297e-03]],\n",
            "\n",
            "         [[-1.0282e-02,  2.0743e-02,  2.0890e-02],\n",
            "          [-5.1610e-02,  7.4446e-03,  3.8852e-02],\n",
            "          [ 7.3162e-03,  1.0331e-02, -7.0078e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.4187e-02, -1.7181e-02,  4.0619e-03],\n",
            "          [ 2.9442e-02, -3.8764e-02, -3.5211e-03],\n",
            "          [-2.2154e-03, -4.0566e-02,  3.3564e-02]],\n",
            "\n",
            "         [[ 1.8199e-02,  2.3197e-02,  5.1779e-03],\n",
            "          [ 5.5296e-02, -1.0521e-02,  1.6755e-02],\n",
            "          [ 6.0825e-03, -5.7191e-02, -3.2814e-02]],\n",
            "\n",
            "         [[-2.8151e-02, -6.1232e-03,  2.5934e-02],\n",
            "          [ 4.2446e-02, -6.6266e-03,  3.5065e-03],\n",
            "          [-6.2963e-03,  2.8703e-02,  4.4982e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0394e-03,  1.8773e-02, -2.1824e-02],\n",
            "          [ 7.7236e-03,  5.5863e-02, -4.3201e-02],\n",
            "          [-6.9451e-03,  1.1394e-02, -6.9362e-03]],\n",
            "\n",
            "         [[ 1.5180e-02, -2.2741e-02, -4.0921e-02],\n",
            "          [-7.2364e-03, -3.8689e-02, -1.6057e-02],\n",
            "          [-2.5317e-02,  3.0741e-03, -3.8001e-02]],\n",
            "\n",
            "         [[-2.3330e-02,  6.8835e-02, -5.4580e-02],\n",
            "          [ 2.9865e-02,  2.8478e-02,  3.7693e-02],\n",
            "          [-2.9691e-02,  3.1145e-02,  2.2493e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1664e-02,  2.6755e-02,  7.3823e-03],\n",
            "          [ 3.9904e-02, -5.1710e-03,  4.1311e-02],\n",
            "          [-3.2143e-03, -4.6323e-02,  1.8733e-02]],\n",
            "\n",
            "         [[-4.0674e-02, -1.9678e-02,  2.9460e-02],\n",
            "          [-3.6571e-02, -1.4536e-02, -1.7511e-02],\n",
            "          [ 2.3863e-02,  1.2842e-02,  1.5734e-02]],\n",
            "\n",
            "         [[ 5.7812e-03, -1.2970e-02,  8.9653e-03],\n",
            "          [ 2.1875e-02,  2.2262e-02, -7.8857e-02],\n",
            "          [ 3.1077e-02,  1.7082e-02,  7.8151e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7208e-02, -1.2604e-02, -5.1648e-02],\n",
            "          [-3.7636e-03, -1.8063e-02,  4.8969e-03],\n",
            "          [ 2.5092e-02, -6.7053e-03, -3.5361e-02]],\n",
            "\n",
            "         [[ 1.4053e-02, -1.0827e-02,  1.7319e-02],\n",
            "          [ 1.2587e-02,  1.0967e-02,  5.1446e-02],\n",
            "          [-3.3688e-02,  4.0636e-02,  3.0170e-03]],\n",
            "\n",
            "         [[-9.1296e-03,  2.4847e-02, -2.7989e-03],\n",
            "          [ 1.6967e-02,  2.9956e-02, -3.2253e-02],\n",
            "          [-2.3866e-02, -1.1854e-03,  2.3374e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.0764e-03, -9.5095e-03,  4.6377e-02],\n",
            "          [ 2.1251e-02,  1.0785e-02,  1.5833e-02],\n",
            "          [ 4.5355e-02, -7.9176e-03, -5.2972e-02]],\n",
            "\n",
            "         [[ 1.3626e-02,  2.8069e-02, -2.4395e-02],\n",
            "          [ 2.0974e-02, -3.2303e-02, -4.1759e-02],\n",
            "          [-1.3132e-02,  5.2510e-02,  2.8753e-02]],\n",
            "\n",
            "         [[ 1.9218e-02,  8.3730e-02,  3.7454e-02],\n",
            "          [ 2.4740e-04,  2.1310e-02, -9.2129e-03],\n",
            "          [-6.4160e-02, -3.7813e-03, -3.4569e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4504e-02, -1.0184e-02, -2.5958e-02],\n",
            "          [-3.5332e-02,  5.8987e-03, -3.2254e-02],\n",
            "          [ 5.4959e-02, -7.1151e-02, -5.0148e-02]],\n",
            "\n",
            "         [[ 8.7651e-03,  6.2811e-03,  4.2683e-02],\n",
            "          [ 1.0528e-02, -4.1274e-02, -4.0683e-02],\n",
            "          [ 1.2258e-03, -3.0606e-02,  1.0435e-02]],\n",
            "\n",
            "         [[ 1.0304e-02,  5.7142e-03, -6.0858e-03],\n",
            "          [ 5.0215e-02, -1.1623e-02,  4.8485e-02],\n",
            "          [ 1.4722e-02,  6.3962e-02,  1.6772e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8017e-05, -3.7539e-02, -3.1678e-03],\n",
            "          [ 3.2515e-02, -2.0108e-02, -1.9620e-02],\n",
            "          [-3.2610e-02,  2.0427e-02,  2.2995e-02]],\n",
            "\n",
            "         [[-8.3941e-04,  3.0902e-02, -1.5240e-03],\n",
            "          [ 5.5688e-02,  3.6538e-02,  1.0479e-02],\n",
            "          [ 2.0953e-03,  1.9760e-02, -5.0461e-02]],\n",
            "\n",
            "         [[ 4.7727e-03, -1.8632e-02, -4.1078e-03],\n",
            "          [ 2.4383e-03, -2.5945e-02, -3.6096e-03],\n",
            "          [ 2.7540e-02,  1.2514e-02,  5.8069e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8614e-02,  1.7450e-02,  1.9694e-02],\n",
            "          [ 1.5427e-02, -5.4195e-02, -1.9113e-03],\n",
            "          [ 2.0494e-02,  1.5202e-02,  5.8540e-02]],\n",
            "\n",
            "         [[-1.4576e-02,  9.4580e-03, -3.2147e-02],\n",
            "          [ 3.7454e-03,  3.2331e-02, -4.5637e-02],\n",
            "          [ 3.6408e-02, -8.3745e-03, -4.1159e-02]],\n",
            "\n",
            "         [[ 1.5534e-02,  1.2572e-02, -6.1970e-03],\n",
            "          [ 4.5931e-03, -2.9335e-02, -4.1076e-02],\n",
            "          [-1.5705e-02, -4.3647e-02, -3.3481e-02]]]])), ('module.encoder_k.layer3.0.bn2.weight', tensor([0.9990, 0.9992, 0.9992, 0.9992, 0.9989, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9993, 0.9992, 0.9994,\n",
            "        0.9996, 0.9992, 0.9990, 0.9989, 0.9993, 0.9988, 0.9989, 0.9995, 0.9992,\n",
            "        0.9988, 0.9985, 0.9991, 0.9991, 0.9991, 0.9989, 0.9990, 0.9992, 0.9996,\n",
            "        0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9994, 0.9991,\n",
            "        0.9989, 0.9991, 0.9988, 0.9990, 0.9989, 0.9991, 0.9991, 0.9992, 0.9992,\n",
            "        0.9991, 0.9990, 0.9989, 0.9995, 0.9988, 0.9989, 0.9993, 0.9993, 0.9992,\n",
            "        0.9991, 0.9992, 0.9990, 0.9992, 0.9987, 0.9991, 0.9991, 0.9993, 0.9991,\n",
            "        0.9988, 0.9987, 0.9990, 0.9992, 0.9991, 0.9987, 0.9992, 0.9990, 0.9990,\n",
            "        0.9988, 0.9996, 0.9994, 0.9994, 0.9994, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9989, 0.9992, 0.9988, 0.9991, 0.9992, 0.9992, 0.9991, 0.9992, 0.9989,\n",
            "        0.9992, 0.9990, 0.9992, 0.9987, 0.9992, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9989, 0.9991, 0.9990, 0.9991, 0.9989, 0.9990, 0.9991, 0.9993, 0.9989,\n",
            "        0.9993, 0.9992, 0.9991, 0.9991, 0.9990, 0.9988, 0.9989, 0.9989, 0.9990,\n",
            "        0.9991, 0.9988, 0.9989, 0.9993, 0.9990, 0.9989, 0.9990, 0.9993, 0.9992,\n",
            "        0.9987, 0.9993, 0.9991, 0.9988, 0.9990, 0.9990, 0.9991, 0.9997, 0.9990,\n",
            "        0.9991, 0.9992, 0.9989, 0.9991, 0.9992, 0.9994, 0.9988, 0.9991, 0.9989,\n",
            "        0.9991, 0.9989, 0.9991, 0.9991, 0.9990, 0.9992, 0.9993, 0.9991, 0.9991,\n",
            "        0.9989, 0.9990, 0.9989, 0.9989, 0.9992, 0.9990, 0.9992, 0.9989, 0.9990,\n",
            "        0.9991, 0.9989, 0.9990, 0.9991, 0.9988, 0.9993, 0.9990, 0.9993, 0.9991,\n",
            "        0.9993, 0.9990, 0.9991, 0.9991, 0.9987, 0.9990, 0.9990, 0.9993, 0.9991,\n",
            "        0.9988, 0.9995, 0.9993, 0.9992, 0.9989, 0.9989, 0.9988, 0.9990, 0.9993,\n",
            "        0.9990, 0.9991, 0.9987, 0.9992, 0.9989, 0.9990, 0.9993, 0.9990, 0.9995,\n",
            "        0.9996, 0.9992, 0.9990, 0.9991, 0.9993, 0.9989, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9995, 0.9991, 0.9994, 0.9996, 0.9989, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9992, 0.9996, 0.9990, 0.9993, 0.9989, 0.9991,\n",
            "        0.9992, 0.9990, 0.9988, 0.9994, 0.9993, 0.9993, 0.9992, 0.9989, 0.9987,\n",
            "        0.9988, 0.9990, 0.9989, 0.9990, 0.9989, 0.9993, 0.9991, 0.9993, 0.9989,\n",
            "        0.9989, 0.9989, 0.9991, 0.9990])), ('module.encoder_k.layer3.0.bn2.bias', tensor([-4.5649e-05,  5.1026e-05, -5.1088e-05,  2.7402e-05, -9.2978e-05,\n",
            "        -2.5138e-05,  1.0535e-04,  7.0699e-05,  1.4268e-04, -2.2201e-04,\n",
            "         7.4028e-05,  7.3650e-05,  1.0608e-04, -2.2268e-05,  2.3380e-04,\n",
            "         2.5929e-04,  2.0145e-04,  2.3198e-04,  5.4491e-04,  2.6944e-05,\n",
            "        -5.7650e-05,  1.0616e-05,  1.3080e-04, -1.0640e-04, -1.4811e-05,\n",
            "         3.6086e-06, -1.5022e-05, -2.5358e-04, -1.8113e-04,  5.5419e-06,\n",
            "         3.1809e-04,  1.1335e-04, -2.6215e-04,  2.3939e-05,  1.3998e-04,\n",
            "         6.2021e-05, -3.3478e-04, -7.3309e-05, -1.8787e-04, -2.6644e-05,\n",
            "        -1.8297e-04,  8.7994e-05, -1.3895e-04, -1.9888e-05, -1.7164e-04,\n",
            "        -4.3359e-04,  2.0129e-05, -1.1117e-04, -2.3809e-05, -3.0190e-04,\n",
            "        -5.8820e-05,  1.3491e-04, -4.0383e-05,  2.0782e-05, -6.2679e-05,\n",
            "         1.3055e-04, -1.4768e-04,  5.0136e-04,  7.3797e-05, -1.2246e-04,\n",
            "        -1.1218e-05,  8.9571e-05,  6.7426e-05, -1.9239e-04, -5.1357e-04,\n",
            "        -3.9755e-05,  7.8971e-05, -3.9790e-05, -4.7412e-05,  1.4494e-04,\n",
            "         3.2794e-04,  5.4397e-05, -9.7480e-05, -5.1538e-05,  1.0132e-04,\n",
            "         1.6058e-04,  1.4573e-04, -1.1907e-04,  4.4659e-04, -1.5293e-04,\n",
            "        -8.3734e-05, -1.1864e-04,  3.1984e-04,  8.0334e-05,  4.1809e-05,\n",
            "         8.8474e-05, -2.3395e-04, -1.6603e-04,  1.5270e-04,  1.2656e-04,\n",
            "        -2.3110e-04,  7.9703e-05, -1.5000e-04, -2.4093e-05,  1.2833e-04,\n",
            "         2.9436e-04,  2.7232e-04,  2.6239e-04, -1.9148e-04,  6.1423e-05,\n",
            "         1.4289e-04,  1.9815e-04, -1.7644e-04, -5.4309e-05, -2.2102e-04,\n",
            "         1.2892e-04, -3.1859e-05,  6.1976e-05,  3.1454e-05, -5.3219e-05,\n",
            "        -1.5655e-04, -3.8939e-05, -1.3935e-04, -3.1446e-05,  1.7199e-04,\n",
            "        -6.6536e-05, -8.2519e-05,  3.1553e-04,  1.6456e-04, -1.5405e-04,\n",
            "         9.9153e-05,  6.1543e-05, -2.0768e-04, -6.3833e-05, -8.2357e-05,\n",
            "        -4.7856e-05, -2.0979e-04, -1.4079e-04, -1.0502e-04,  2.0074e-04,\n",
            "        -1.1360e-04, -2.1240e-04, -2.4795e-04,  2.3192e-04,  7.0177e-05,\n",
            "        -1.7726e-04,  1.8314e-04,  1.2164e-04, -4.4524e-05, -9.8846e-05,\n",
            "         3.7109e-05, -1.0602e-04,  2.9629e-04, -4.7613e-05, -3.8114e-05,\n",
            "         5.8151e-06, -1.8126e-04, -3.1717e-04,  1.6896e-04,  1.1465e-04,\n",
            "        -3.1104e-04,  2.1148e-04, -6.2352e-05, -1.5999e-04, -2.1819e-04,\n",
            "         1.3713e-04, -2.1467e-04, -9.2886e-06,  2.8398e-04,  4.4573e-04,\n",
            "        -3.2191e-05,  2.5602e-04, -1.6118e-05,  8.8299e-06, -2.3192e-04,\n",
            "        -5.3450e-05,  2.0108e-04, -1.7692e-04,  1.5312e-05, -1.9162e-04,\n",
            "         2.9469e-05,  3.1790e-04,  1.6728e-04,  1.6531e-04, -7.3767e-06,\n",
            "        -3.7805e-04,  5.2918e-05,  9.4911e-05,  2.6967e-04, -3.2390e-06,\n",
            "         1.2166e-04, -3.5454e-04,  2.2266e-05,  1.3541e-04, -2.3359e-04,\n",
            "        -2.5683e-04,  1.4500e-05,  7.3414e-06, -1.1566e-05,  6.1862e-05,\n",
            "         1.9250e-04,  2.0151e-04, -1.0499e-04,  6.6460e-05, -6.7500e-05,\n",
            "        -6.8630e-05, -1.8433e-04,  1.0819e-04,  9.6301e-05,  1.7171e-04,\n",
            "         3.8845e-05,  7.9594e-05, -2.4348e-04, -1.8769e-04,  2.9386e-04,\n",
            "        -6.1304e-05,  2.6013e-04,  4.9082e-04, -9.8470e-05,  7.7361e-05,\n",
            "        -1.9474e-04,  8.3405e-05, -3.3892e-05, -1.4909e-04,  2.0552e-05,\n",
            "         1.3486e-04, -9.3837e-05, -2.2577e-04,  2.3877e-04,  8.1425e-05,\n",
            "         1.0494e-04,  3.6627e-04,  1.3645e-05, -3.0768e-04,  9.5306e-05,\n",
            "        -1.9798e-04, -7.7163e-05,  5.9551e-05, -2.5004e-05,  2.9368e-04,\n",
            "        -1.8772e-04, -1.8412e-05, -2.8968e-04,  7.8116e-05, -5.1527e-05,\n",
            "        -6.5994e-05, -8.5366e-05,  4.7761e-04, -3.8030e-05,  1.7966e-04,\n",
            "        -1.4186e-04, -1.6777e-04, -2.2729e-04, -5.3660e-06, -2.2445e-04,\n",
            "        -5.0437e-06,  1.3149e-04, -5.8152e-05,  2.7161e-04,  3.6624e-04,\n",
            "         3.3319e-04, -1.9142e-04, -3.0076e-05, -1.0620e-04,  4.3063e-05,\n",
            "         4.4462e-05])), ('module.encoder_k.layer3.0.bn2.running_mean', tensor([-7.6967e-02, -2.5664e-02,  1.7223e-01, -3.5496e-01, -8.9468e-01,\n",
            "        -9.3167e-01, -8.2068e-01, -9.6770e-01, -5.8819e-01,  6.5132e-01,\n",
            "         2.5531e-01,  7.1707e-01, -4.1173e-01, -8.4322e-01, -2.9771e-01,\n",
            "        -2.7312e-01,  3.3783e-01,  5.7753e-01, -7.6095e-01,  7.6564e-01,\n",
            "        -6.3011e-01,  1.5907e+00, -4.3320e-01, -4.9212e-01, -3.6861e-02,\n",
            "        -1.3872e-01,  4.2858e-01,  1.0847e+00,  5.2676e-01,  2.5969e-01,\n",
            "        -1.9328e-01,  9.9791e-01,  6.9409e-01, -3.1744e-01,  1.2356e-01,\n",
            "         2.3897e-01,  1.0314e-01, -5.5796e-02,  5.4345e-01,  2.7702e-01,\n",
            "        -3.0443e-01,  1.5569e-01, -2.7299e-03, -2.9319e-01,  5.6755e-01,\n",
            "        -1.7345e-01, -6.1259e-01,  5.1996e-01,  1.9797e-02, -5.5442e-01,\n",
            "         7.8752e-01,  5.8185e-02,  1.0208e-01, -4.8384e-01, -7.9412e-01,\n",
            "         3.9150e-01, -3.3556e-01, -1.1507e-01, -1.1143e-01,  3.6861e-01,\n",
            "         3.4295e-01, -2.8398e-01,  3.3767e-01,  5.5547e-02,  3.7361e-01,\n",
            "        -1.5500e-01,  5.6383e-01,  1.8324e-01, -2.0908e-01, -4.5651e-01,\n",
            "         5.2387e-01, -5.2296e-01, -5.0250e-01, -1.5239e-01,  7.9217e-01,\n",
            "        -6.0929e-02,  3.3268e-01,  5.1471e-01,  1.3221e-01, -2.5375e-01,\n",
            "         6.1317e-01,  1.4888e-01, -7.1576e-02, -1.5502e-01,  4.7088e-01,\n",
            "        -1.4536e-01, -7.6963e-01, -1.2381e+00, -1.2334e-01, -1.5902e-01,\n",
            "        -2.1738e-01,  9.4068e-02,  1.1133e-01, -2.2102e-01, -1.9576e-01,\n",
            "         5.4624e-01,  1.3029e-01, -2.1205e-01,  7.2557e-01, -6.9267e-01,\n",
            "        -4.9430e-01,  9.3388e-02,  1.3501e+00, -2.8389e-01,  1.9263e-02,\n",
            "        -8.6583e-02, -1.0283e-01,  5.9590e-01,  8.0572e-01,  3.6602e-01,\n",
            "         8.2146e-02, -3.6145e-01, -4.4947e-01, -1.7825e-01,  6.0293e-02,\n",
            "         1.6114e-01, -2.0243e-01,  4.7793e-01,  6.0826e-01,  2.9438e-01,\n",
            "        -2.7765e-01, -4.1794e-02, -6.2434e-01,  2.2979e-01,  6.0158e-01,\n",
            "         1.0596e-01,  4.6304e-03,  8.9409e-01,  3.5626e-01,  6.2888e-01,\n",
            "        -3.6667e-01,  8.2082e-01, -7.6142e-01, -1.1773e-01,  1.2548e-01,\n",
            "        -6.9257e-01,  6.8311e-02, -9.8483e-01, -2.3400e-01,  5.0668e-02,\n",
            "         1.9239e-01, -7.1909e-01, -2.0281e-01, -3.5888e-01, -6.4409e-01,\n",
            "         6.3583e-02, -4.3115e-02,  4.4811e-01, -9.9376e-02,  5.1143e-02,\n",
            "        -1.9367e-01,  1.9401e-02,  3.1490e-01, -8.2004e-01,  1.0837e-02,\n",
            "        -1.0946e+00,  8.8629e-02, -6.7965e-02,  2.4781e-02, -1.9140e-02,\n",
            "        -2.0845e-01,  4.6922e-01,  4.6506e-01,  3.2232e-01,  6.7099e-01,\n",
            "         1.1938e+00,  2.2332e-01,  2.6458e-01,  2.6592e-01,  1.4504e-01,\n",
            "        -1.3539e-01, -2.7547e-02,  9.7046e-01, -2.5122e-01,  1.2926e-01,\n",
            "         1.7086e-01, -6.7696e-01,  6.9014e-01,  2.7195e-01, -1.3004e-01,\n",
            "        -2.9542e-01, -4.4190e-01,  3.9031e-01, -3.2327e-01, -1.0707e-01,\n",
            "        -5.9659e-01,  1.0236e+00, -2.7765e-02, -1.4533e-01,  3.4851e-01,\n",
            "        -5.6724e-02, -1.8763e-01, -5.7402e-01, -3.1844e-02, -1.5263e-01,\n",
            "         3.3367e-01, -4.8096e-01,  1.7206e-01,  9.3768e-03,  9.2696e-02,\n",
            "        -1.9777e-01,  4.9268e-02, -2.3883e-01,  2.1792e-01, -3.3109e-01,\n",
            "         4.7300e-01, -1.5258e-01, -2.7848e-01,  3.9251e-01, -7.9841e-01,\n",
            "         7.5470e-01,  3.0436e-01,  1.2088e+00, -2.1224e-01,  4.6132e-01,\n",
            "        -2.7781e-01,  5.3012e-02,  2.0251e-01,  1.5301e-01, -3.6461e-01,\n",
            "         4.1143e-01, -1.2957e-01, -5.9544e-01,  5.2099e-01, -4.5981e-01,\n",
            "         4.9685e-01, -1.5123e-01, -1.4413e-01, -5.7204e-01,  1.7998e-02,\n",
            "         5.3410e-01,  2.3483e-01, -2.0945e-01, -1.1233e-01, -3.6236e-01,\n",
            "         4.9537e-01, -1.0780e-01, -1.0197e-01,  2.4452e-01,  6.9445e-01,\n",
            "        -5.2984e-01, -7.1897e-01, -1.2867e-01,  8.7508e-04, -4.4819e-01,\n",
            "        -1.0314e+00, -3.0261e-01, -4.1576e-01, -3.8632e-01, -4.7759e-01,\n",
            "         4.2002e-01,  5.7384e-01,  4.5863e-01, -5.0464e-01, -1.4458e-01,\n",
            "         3.5512e-01])), ('module.encoder_k.layer3.0.bn2.running_var', tensor([0.5397, 0.5974, 0.5934, 0.6380, 0.5607, 0.5358, 1.0752, 0.9257, 0.6896,\n",
            "        0.8654, 0.6491, 0.6231, 0.5603, 0.6110, 0.5377, 0.5441, 0.6969, 0.5929,\n",
            "        0.5475, 0.8893, 0.6983, 1.0876, 0.6633, 0.7126, 0.6532, 0.5306, 0.8007,\n",
            "        1.4939, 0.7339, 0.6153, 0.6839, 0.7291, 0.7116, 0.5837, 0.7673, 0.7536,\n",
            "        0.7638, 0.6909, 0.6160, 1.6730, 0.5747, 0.5335, 0.5880, 0.6370, 1.0360,\n",
            "        0.5285, 0.5121, 0.5693, 0.8415, 0.8319, 0.9387, 0.6265, 0.7375, 0.8093,\n",
            "        0.6089, 0.6511, 0.6366, 0.5616, 0.5293, 1.0080, 0.6703, 0.7310, 0.8316,\n",
            "        0.6782, 0.5924, 0.6997, 0.6065, 0.5694, 0.6848, 0.7871, 0.6239, 0.8306,\n",
            "        0.6266, 0.5771, 0.9495, 0.6407, 0.6353, 0.8708, 0.5631, 0.5811, 0.6143,\n",
            "        0.6031, 0.5949, 0.6246, 0.8298, 0.6621, 0.9929, 1.4036, 0.7954, 0.7703,\n",
            "        1.0020, 0.5246, 0.6973, 0.6352, 0.4881, 0.9488, 0.6477, 0.5986, 0.7751,\n",
            "        0.6287, 0.7110, 0.6968, 3.0139, 0.4796, 0.6545, 0.7404, 0.6381, 0.8313,\n",
            "        0.6757, 0.4727, 0.5505, 0.5787, 0.9734, 0.5726, 0.4886, 0.5904, 0.5366,\n",
            "        0.5304, 1.1689, 0.5697, 0.5172, 0.5077, 1.0740, 1.0685, 0.9272, 0.5949,\n",
            "        0.5030, 0.5567, 0.6947, 0.6064, 0.5838, 1.0329, 0.9210, 0.8490, 0.5438,\n",
            "        0.5979, 0.5569, 0.8642, 0.6717, 0.8686, 0.5554, 1.1828, 0.5260, 0.6796,\n",
            "        0.8246, 0.5616, 0.5238, 0.7583, 0.7652, 0.7482, 0.5610, 0.6760, 1.1123,\n",
            "        1.0510, 0.5729, 1.1028, 0.5989, 0.5721, 0.6605, 0.5842, 1.0292, 0.7957,\n",
            "        0.9211, 0.6813, 0.5783, 2.7260, 0.6439, 0.7843, 0.5862, 0.6977, 0.6821,\n",
            "        0.7317, 0.5896, 0.6452, 0.5383, 0.7289, 0.6769, 1.2817, 0.6785, 0.5511,\n",
            "        0.6514, 0.7764, 0.5708, 0.6723, 0.5812, 0.8287, 0.9901, 0.5770, 0.6345,\n",
            "        0.5971, 0.8457, 0.6631, 0.6215, 0.6781, 0.5591, 0.6530, 0.7674, 0.6639,\n",
            "        0.6806, 0.5100, 0.6886, 0.8475, 0.6624, 0.6111, 0.5035, 0.7633, 0.7538,\n",
            "        0.6188, 0.9224, 0.6722, 0.5845, 0.6820, 1.5664, 0.5085, 0.5326, 0.5941,\n",
            "        0.6007, 0.6763, 0.5066, 0.7453, 0.7086, 0.5717, 0.6625, 0.9825, 0.6548,\n",
            "        0.5379, 0.9532, 0.6044, 1.1036, 0.5988, 0.5665, 0.5948, 0.5421, 0.9050,\n",
            "        0.8333, 1.1883, 0.5700, 0.6612, 0.7595, 0.5031, 0.5564, 0.6822, 0.5369,\n",
            "        0.6096, 0.5746, 0.7878, 0.5713, 0.7534, 0.5883, 0.7290, 0.8748, 0.7990,\n",
            "        1.0285, 1.3343, 0.5512, 0.5627])), ('module.encoder_k.layer3.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.0.conv3.weight', tensor([[[[-0.0624]],\n",
            "\n",
            "         [[-0.0849]],\n",
            "\n",
            "         [[ 0.0599]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0211]],\n",
            "\n",
            "         [[-0.0023]],\n",
            "\n",
            "         [[ 0.0562]]],\n",
            "\n",
            "\n",
            "        [[[-0.1057]],\n",
            "\n",
            "         [[ 0.0367]],\n",
            "\n",
            "         [[ 0.0683]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0237]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[-0.0503]]],\n",
            "\n",
            "\n",
            "        [[[-0.0330]],\n",
            "\n",
            "         [[ 0.0015]],\n",
            "\n",
            "         [[ 0.0549]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0305]],\n",
            "\n",
            "         [[-0.0244]],\n",
            "\n",
            "         [[ 0.0284]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0112]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[-0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0155]],\n",
            "\n",
            "         [[ 0.0032]],\n",
            "\n",
            "         [[-0.0869]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0397]],\n",
            "\n",
            "         [[ 0.0025]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0390]],\n",
            "\n",
            "         [[ 0.0063]],\n",
            "\n",
            "         [[ 0.0278]]],\n",
            "\n",
            "\n",
            "        [[[-0.0236]],\n",
            "\n",
            "         [[-0.0583]],\n",
            "\n",
            "         [[-0.0357]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0110]],\n",
            "\n",
            "         [[-0.0249]],\n",
            "\n",
            "         [[-0.0578]]]])), ('module.encoder_k.layer3.0.bn3.weight', tensor([0.9991, 0.9990, 0.9990,  ..., 0.9992, 0.9990, 0.9991])), ('module.encoder_k.layer3.0.bn3.bias', tensor([ 3.5825e-05,  5.0885e-05, -2.0473e-05,  ...,  3.2359e-05,\n",
            "        -1.3750e-04,  2.2162e-05])), ('module.encoder_k.layer3.0.bn3.running_mean', tensor([-0.4684,  0.0189, -0.1331,  ..., -0.0814, -0.2723,  0.3327])), ('module.encoder_k.layer3.0.bn3.running_var', tensor([0.1703, 0.1875, 0.1364,  ..., 0.1515, 0.1942, 0.2241])), ('module.encoder_k.layer3.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.0.downsample.0.weight', tensor([[[[ 0.0390]],\n",
            "\n",
            "         [[-0.0588]],\n",
            "\n",
            "         [[ 0.0378]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0682]],\n",
            "\n",
            "         [[ 0.0731]],\n",
            "\n",
            "         [[ 0.0513]]],\n",
            "\n",
            "\n",
            "        [[[-0.0453]],\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[ 0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0058]],\n",
            "\n",
            "         [[-0.0058]],\n",
            "\n",
            "         [[-0.0299]]],\n",
            "\n",
            "\n",
            "        [[[-0.0653]],\n",
            "\n",
            "         [[ 0.0137]],\n",
            "\n",
            "         [[ 0.0126]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0300]],\n",
            "\n",
            "         [[-0.0518]],\n",
            "\n",
            "         [[-0.0500]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0064]],\n",
            "\n",
            "         [[-0.0617]],\n",
            "\n",
            "         [[ 0.0289]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0245]],\n",
            "\n",
            "         [[-0.0306]],\n",
            "\n",
            "         [[-0.0084]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0026]],\n",
            "\n",
            "         [[ 0.0289]],\n",
            "\n",
            "         [[ 0.0063]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0107]],\n",
            "\n",
            "         [[-0.0249]],\n",
            "\n",
            "         [[-0.0032]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0638]],\n",
            "\n",
            "         [[ 0.0541]],\n",
            "\n",
            "         [[ 0.0120]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0891]],\n",
            "\n",
            "         [[ 0.0533]],\n",
            "\n",
            "         [[ 0.0181]]]])), ('module.encoder_k.layer3.0.downsample.1.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9991, 0.9990, 0.9992])), ('module.encoder_k.layer3.0.downsample.1.bias', tensor([ 3.5825e-05,  5.0885e-05, -2.0473e-05,  ...,  3.2359e-05,\n",
            "        -1.3750e-04,  2.2162e-05])), ('module.encoder_k.layer3.0.downsample.1.running_mean', tensor([ 0.2028, -0.2414, -1.1904,  ..., -0.4564, -0.3560,  0.2978])), ('module.encoder_k.layer3.0.downsample.1.running_var', tensor([1.3792, 2.4009, 1.1620,  ..., 1.3796, 1.6397, 1.5816])), ('module.encoder_k.layer3.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.1.conv1.weight', tensor([[[[-0.0207]],\n",
            "\n",
            "         [[-0.0132]],\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0037]],\n",
            "\n",
            "         [[-0.0871]],\n",
            "\n",
            "         [[ 0.0583]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0054]],\n",
            "\n",
            "         [[-0.1403]],\n",
            "\n",
            "         [[ 0.0944]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0480]],\n",
            "\n",
            "         [[ 0.1454]],\n",
            "\n",
            "         [[-0.0140]]],\n",
            "\n",
            "\n",
            "        [[[-0.0907]],\n",
            "\n",
            "         [[ 0.0244]],\n",
            "\n",
            "         [[-0.0508]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0459]],\n",
            "\n",
            "         [[-0.0526]],\n",
            "\n",
            "         [[ 0.0181]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0188]],\n",
            "\n",
            "         [[-0.1533]],\n",
            "\n",
            "         [[ 0.0057]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1098]],\n",
            "\n",
            "         [[-0.1314]],\n",
            "\n",
            "         [[ 0.0962]]],\n",
            "\n",
            "\n",
            "        [[[-0.2117]],\n",
            "\n",
            "         [[ 0.0618]],\n",
            "\n",
            "         [[ 0.0434]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1216]],\n",
            "\n",
            "         [[ 0.0572]],\n",
            "\n",
            "         [[-0.1100]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0322]],\n",
            "\n",
            "         [[ 0.0399]],\n",
            "\n",
            "         [[-0.0453]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1101]],\n",
            "\n",
            "         [[ 0.0041]],\n",
            "\n",
            "         [[ 0.0791]]]])), ('module.encoder_k.layer3.1.bn1.weight', tensor([0.9992, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990, 0.9991, 0.9993,\n",
            "        0.9992, 0.9990, 0.9991, 0.9991, 0.9989, 0.9992, 0.9991, 0.9991, 0.9993,\n",
            "        0.9991, 0.9989, 0.9992, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9993, 0.9992, 0.9992, 0.9988, 0.9991, 0.9991, 0.9991, 0.9989,\n",
            "        0.9991, 0.9991, 0.9990, 0.9989, 0.9989, 0.9992, 0.9990, 0.9988, 0.9991,\n",
            "        0.9991, 0.9991, 0.9993, 0.9989, 0.9992, 0.9989, 0.9989, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9993, 0.9991, 0.9990, 0.9990, 0.9989, 0.9993, 0.9987,\n",
            "        0.9994, 0.9988, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9990, 0.9992,\n",
            "        0.9988, 0.9992, 0.9989, 0.9994, 0.9992, 0.9992, 0.9989, 0.9990, 0.9993,\n",
            "        0.9991, 0.9988, 0.9991, 0.9991, 0.9989, 0.9992, 0.9991, 0.9988, 0.9990,\n",
            "        0.9991, 0.9989, 0.9991, 0.9991, 0.9993, 0.9991, 0.9989, 0.9994, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9989,\n",
            "        0.9991, 0.9992, 0.9993, 0.9992, 0.9991, 0.9991, 0.9991, 0.9994, 0.9992,\n",
            "        0.9990, 0.9992, 0.9991, 0.9989, 0.9989, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9989, 0.9992, 0.9987, 0.9991, 0.9991, 0.9990, 0.9989, 0.9990, 0.9988,\n",
            "        0.9991, 0.9991, 0.9989, 0.9993, 0.9990, 0.9990, 0.9991, 0.9996, 0.9992,\n",
            "        0.9991, 0.9990, 0.9992, 0.9991, 0.9989, 0.9992, 0.9991, 0.9992, 0.9992,\n",
            "        0.9991, 0.9989, 0.9992, 0.9988, 0.9990, 0.9994, 0.9990, 0.9990, 0.9993,\n",
            "        0.9994, 0.9993, 0.9990, 0.9994, 0.9987, 0.9993, 0.9990, 0.9993, 0.9990,\n",
            "        0.9989, 0.9993, 0.9992, 0.9989, 0.9991, 0.9993, 0.9990, 0.9994, 0.9991,\n",
            "        0.9989, 0.9990, 0.9987, 0.9992, 0.9990, 0.9992, 0.9992, 0.9991, 0.9991,\n",
            "        0.9989, 0.9992, 0.9990, 0.9992, 0.9990, 0.9988, 0.9992, 0.9993, 0.9991,\n",
            "        0.9991, 0.9991, 0.9993, 0.9988, 0.9991, 0.9991, 0.9988, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9989, 0.9990, 0.9989, 0.9991,\n",
            "        0.9992, 0.9992, 0.9991, 0.9988, 0.9993, 0.9992, 0.9989, 0.9990, 0.9989,\n",
            "        0.9991, 0.9990, 0.9992, 0.9993, 0.9993, 0.9991, 0.9991, 0.9992, 0.9989,\n",
            "        0.9992, 0.9992, 0.9992, 0.9989, 0.9990, 0.9990, 0.9990, 0.9992, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9995, 0.9991, 0.9989, 0.9991,\n",
            "        0.9990, 0.9989, 0.9991, 0.9993])), ('module.encoder_k.layer3.1.bn1.bias', tensor([-2.4482e-04, -4.3788e-05, -1.1968e-05,  1.9986e-04,  1.2661e-04,\n",
            "        -1.0731e-04, -8.4079e-05, -2.7200e-05,  2.3041e-04,  1.9587e-04,\n",
            "        -1.6500e-04, -1.4457e-04,  6.6893e-05,  3.1646e-05,  1.4615e-04,\n",
            "        -4.8755e-05, -3.4234e-05,  2.2848e-04,  2.2613e-05, -2.8479e-05,\n",
            "         7.3638e-05, -1.1727e-05, -6.0771e-05, -3.3962e-05,  1.0556e-04,\n",
            "        -2.8576e-05,  9.9800e-05, -1.0103e-04,  1.0538e-04,  1.1131e-04,\n",
            "         2.7213e-04, -2.9874e-04, -7.6142e-05, -1.1477e-04,  8.6540e-05,\n",
            "         2.1076e-04, -9.0951e-05,  7.7327e-05,  2.1423e-05, -1.3364e-05,\n",
            "        -1.5617e-04,  5.2335e-05, -1.0839e-04,  8.4755e-06, -1.5921e-04,\n",
            "         9.2393e-05,  6.7962e-05,  2.1112e-04,  1.4789e-05,  1.0649e-04,\n",
            "         4.0410e-05,  6.3388e-07, -1.7093e-04,  1.5107e-05,  8.0436e-05,\n",
            "        -4.8018e-05,  1.2204e-04, -9.3871e-05,  1.2355e-04, -1.0049e-04,\n",
            "        -9.9518e-05,  4.5849e-05, -2.9628e-04,  2.1923e-04, -7.1978e-05,\n",
            "        -7.5654e-05, -2.8488e-05,  4.2240e-05, -4.3726e-05,  2.8909e-05,\n",
            "        -4.2187e-05,  1.7419e-04, -1.3502e-04,  2.1011e-04, -2.8156e-04,\n",
            "         2.4823e-04,  2.1387e-04,  2.0662e-05, -1.6784e-04, -1.0693e-04,\n",
            "        -7.2117e-05, -1.4329e-04, -1.2117e-04,  9.0023e-05,  9.2508e-05,\n",
            "         1.1660e-04,  1.0011e-04, -8.0711e-05, -2.6597e-04, -1.6009e-04,\n",
            "         1.2906e-04, -1.0696e-04,  8.2084e-05, -2.2338e-05,  2.6294e-04,\n",
            "        -1.5869e-05, -6.3403e-05,  1.8669e-04,  6.8429e-05,  2.7430e-05,\n",
            "         3.1955e-05,  8.1890e-05, -1.3891e-04, -1.5199e-05,  1.9163e-05,\n",
            "        -1.1717e-05, -5.2925e-05, -5.5017e-05,  8.8053e-05, -4.6753e-05,\n",
            "         6.7567e-05, -2.3964e-05, -1.5547e-05, -1.3896e-04, -1.1524e-04,\n",
            "         2.4666e-04,  2.0371e-04,  4.8378e-05,  1.0177e-04, -1.5839e-04,\n",
            "        -2.8509e-04, -8.2218e-05, -8.0972e-05, -2.0562e-04,  1.8673e-04,\n",
            "         1.0103e-04, -1.0443e-04,  4.2822e-05, -1.0047e-04,  9.9091e-06,\n",
            "        -5.4159e-05, -1.7069e-04, -1.2677e-04, -3.8644e-04, -1.5271e-04,\n",
            "         6.4236e-05, -3.9949e-05, -1.2884e-04,  2.0632e-04, -1.3150e-04,\n",
            "         6.6856e-05,  1.3341e-05,  3.5234e-04,  9.8253e-05,  8.6253e-05,\n",
            "        -1.0737e-04, -5.5244e-05, -7.2242e-05, -9.8563e-05,  2.6520e-04,\n",
            "         1.0846e-04, -9.6126e-05,  6.7981e-05, -3.2732e-05, -8.9865e-05,\n",
            "         1.0012e-04,  1.4743e-04, -9.0922e-05,  1.6426e-04, -2.2953e-04,\n",
            "         8.3522e-05,  1.1576e-04,  2.9715e-04, -4.5489e-05, -1.1212e-04,\n",
            "         1.2404e-04, -2.0404e-04,  2.5665e-05, -6.2895e-05,  1.5834e-04,\n",
            "         1.9743e-04, -2.2270e-04,  2.0503e-04,  1.8695e-04, -7.5102e-05,\n",
            "        -7.3757e-05,  1.4042e-04, -1.4993e-05,  1.6444e-04, -5.3984e-05,\n",
            "        -1.3943e-04,  1.6496e-05, -2.4879e-04,  1.9871e-04, -1.2979e-05,\n",
            "        -3.7332e-05,  8.6769e-05,  1.1079e-04, -7.0010e-05, -2.2209e-04,\n",
            "         9.5577e-05, -1.5839e-04, -9.3293e-05, -2.2719e-04, -2.1579e-04,\n",
            "         1.1489e-04,  2.2045e-04, -4.2258e-05, -2.4298e-05,  8.2510e-05,\n",
            "         1.9576e-04, -2.6744e-05, -1.1185e-04,  2.2893e-05, -7.9099e-05,\n",
            "         5.3710e-05, -8.0215e-05,  8.7225e-05,  5.1574e-06, -7.4685e-05,\n",
            "        -1.0533e-04,  2.0118e-04, -1.7796e-04, -1.8326e-04, -1.1884e-04,\n",
            "         6.7544e-05,  1.2856e-04,  4.7392e-05,  1.2875e-04, -2.3429e-05,\n",
            "         1.3783e-04,  4.1332e-05, -6.3705e-05,  2.7990e-05, -4.2533e-05,\n",
            "         7.3263e-05, -1.1081e-04, -5.1080e-05,  6.6589e-05,  2.0778e-04,\n",
            "         4.5302e-05, -3.0644e-05,  8.9354e-06, -3.1697e-04, -3.1681e-06,\n",
            "         2.8610e-04,  2.3797e-04, -7.9194e-05,  1.4749e-04, -6.4382e-05,\n",
            "        -2.0032e-05,  2.1027e-05, -6.0148e-06, -5.6758e-05, -3.4013e-04,\n",
            "         8.4493e-05,  1.2222e-04,  1.0046e-04,  5.0352e-05,  1.2234e-04,\n",
            "        -8.9760e-05,  1.8345e-04, -4.9808e-05,  4.7212e-05,  1.3993e-04,\n",
            "         9.6744e-05])), ('module.encoder_k.layer3.1.bn1.running_mean', tensor([ 0.6325,  0.8196,  0.3636,  0.7416, -1.5948, -2.1541, -1.6092,  3.1910,\n",
            "        -2.5637, -0.3145, -1.1117,  0.1558, -0.3295,  0.4613, -5.4569,  0.6366,\n",
            "         1.1018,  0.0496, -0.1684, -1.7456, -0.0113, -0.0135,  0.9452, -1.9659,\n",
            "        -1.8259,  1.3874,  0.5508,  0.5931,  2.0048,  0.4602, -0.3839,  0.2885,\n",
            "        -5.2080,  0.6951, -0.2432,  1.1979,  0.6766,  1.1196,  1.8774,  0.2425,\n",
            "        -0.2571, -0.7208,  0.7336,  2.1646, -0.0219,  0.1678, -0.1046,  1.1033,\n",
            "         1.3357, -0.6170,  0.6430,  1.1178, -1.1601, -1.3326,  1.3974, -1.6422,\n",
            "        -0.3824, -1.1706, -1.1719, -0.6672,  0.6331, -1.5214,  0.9850, -0.7714,\n",
            "         0.9455,  0.0834,  1.4496, -0.6698, -1.9798, -0.7863,  1.1135, -2.9211,\n",
            "        -0.2364,  0.0533, -0.7303,  0.1188,  1.0485,  0.9039,  0.3590, -1.2695,\n",
            "        -0.3277, -0.4813,  2.7306, -0.2510, -0.9076,  0.9135,  1.3808,  0.1014,\n",
            "        -0.6756,  1.3458, -1.7133,  2.8478, -1.4629, -1.9183, -0.0660,  0.7628,\n",
            "         0.7615,  2.6234, -0.6754, -0.4860, -2.2923,  0.0735, -1.7893, -0.5288,\n",
            "        -1.2269,  1.6169,  2.3719,  0.3747, -2.8835,  0.1771, -2.3103,  0.0619,\n",
            "        -1.3118, -2.5575, -1.3518,  0.8233, -1.6655, -0.7819, -0.8994,  0.7365,\n",
            "        -2.2307, -0.9136,  0.9173, -0.7848,  1.2477, -0.0665,  0.9853,  0.5908,\n",
            "         0.6752,  0.6881, -0.3437,  0.4550,  0.7102, -0.0521,  1.4996,  0.9777,\n",
            "        -0.0361, -2.5798, -1.5736,  2.7233,  0.0397, -1.0085,  0.4826,  0.1489,\n",
            "        -1.2475,  0.9604,  1.4246,  0.2765, -2.3231,  0.3475,  1.2742,  0.9272,\n",
            "         0.1925, -1.6916, -0.3817,  0.4266, -1.4080, -0.1821, -1.3574, -0.1478,\n",
            "        -1.8910,  0.5467, -0.6376,  0.8593,  1.6814,  1.4461,  0.6189,  0.5688,\n",
            "        -0.3517, -1.6849, -0.6436,  0.3683,  0.6283,  0.7203,  2.5566,  2.7441,\n",
            "        -1.3135, -0.3180, -0.0757, -0.6123, -0.1942,  0.5043,  0.1233, -2.4176,\n",
            "        -0.7697, -0.1635, -3.1958,  1.4652,  2.2477, -0.4263,  1.4417,  0.6024,\n",
            "        -0.8159, -0.8411, -0.4682,  0.4407,  1.8999,  2.2213, -0.6183, -2.6469,\n",
            "        -1.5514, -0.4705,  0.3315,  1.0859,  1.7775, -1.4143, -3.0791, -2.1530,\n",
            "        -0.7761,  1.3386,  1.5391, -0.2106, -1.4116, -0.7413,  3.1635,  1.6969,\n",
            "        -1.7258, -1.5924,  1.0552,  1.3985,  1.1839, -2.0298,  0.4219,  0.6834,\n",
            "         1.5617, -2.4219,  1.4944, -0.7615,  1.2311, -1.5030,  2.8669, -2.6203,\n",
            "         0.2444,  1.1735, -1.6200, -0.3389, -2.2069,  2.6989, -0.9451, -0.3705,\n",
            "         0.3399, -2.3336, -0.6757, -1.0380,  0.2500,  0.6780,  2.0872,  0.8523,\n",
            "        -0.3298,  0.0217, -1.2574,  1.5879,  1.6276, -1.9862, -0.6103,  0.3612])), ('module.encoder_k.layer3.1.bn1.running_var', tensor([ 4.5931,  4.4988,  6.7220,  5.2451,  5.0092,  5.2832,  4.7651, 11.8278,\n",
            "         8.8070,  6.7903,  6.6299,  4.4561,  5.2211,  5.0607,  8.3830,  4.8600,\n",
            "         4.9341,  6.0617,  8.1374, 10.4163,  4.5313,  4.8987,  4.8870,  8.6321,\n",
            "         4.3347,  4.5793,  4.9156,  4.3381,  4.4221,  5.1902,  5.2980,  4.7802,\n",
            "        10.5664,  6.9546,  9.9000,  5.8973,  5.5758,  5.0576,  5.6160,  5.2748,\n",
            "         6.1725,  4.6072,  4.8732,  4.5990,  8.0891,  4.5405,  5.3110,  7.9621,\n",
            "         5.7308,  6.0559,  5.1310,  4.6451,  5.3474,  4.5099,  7.1517, 10.3957,\n",
            "         5.7331,  5.8013,  8.3600,  4.7906,  4.5646,  5.7194,  5.3499,  4.0386,\n",
            "         6.6299,  6.6200,  5.3491,  4.1964,  8.7516,  5.4410,  4.9629, 20.0766,\n",
            "         4.5737,  5.4546,  8.9294,  4.3895,  9.6884,  5.1889,  5.3315,  4.9818,\n",
            "         4.6694,  5.5297,  5.7475,  4.6756,  6.0793,  4.8211,  3.8662,  5.1764,\n",
            "         4.4589,  5.7111,  6.8555,  5.8058,  6.5047,  7.2186,  8.3677,  5.2025,\n",
            "         8.1117,  8.4843,  4.6405,  4.0487,  6.1055,  4.5787,  6.6200,  5.5860,\n",
            "         6.3155,  5.2179,  4.2736,  5.0048, 17.2914,  5.7098,  6.0010,  5.4686,\n",
            "         4.9289,  8.6653,  6.4208,  5.2879, 13.3724,  5.3536,  6.1290,  6.6119,\n",
            "         5.5161,  5.1928,  4.5004,  5.3772,  6.3275,  5.0635,  5.0313,  4.5701,\n",
            "         5.1381,  8.0563,  5.3390,  5.2423,  5.3597,  7.3528,  5.0235,  4.7310,\n",
            "         5.8759,  5.2354,  4.5468, 14.2050,  4.1906,  4.6002,  6.7090,  5.3146,\n",
            "         5.0550,  4.4036,  4.6122,  4.9893,  9.7832,  6.6187,  5.6539,  3.9551,\n",
            "         8.2495,  6.5476,  5.1785,  5.3180,  5.7557,  4.9975,  6.4599,  4.2921,\n",
            "         5.8834,  5.2065,  5.5617,  5.6875,  6.3387,  9.3587,  7.7681,  4.4345,\n",
            "         6.1139,  7.0207,  8.1157,  4.7442,  7.9095,  7.2611, 13.2321,  6.7427,\n",
            "         5.5840,  4.8475,  4.7201,  5.3003,  5.0665,  4.2242,  4.5511,  4.5748,\n",
            "         6.2795,  4.5689, 12.9749,  5.9208,  9.7056,  5.0620,  4.6106,  4.8284,\n",
            "         4.1706,  4.6535,  3.8660, 10.6242,  6.5315,  5.4771,  3.8895,  9.8870,\n",
            "         4.3986,  5.3594,  4.6060,  5.5851,  6.9632,  7.2482,  4.2224,  6.6977,\n",
            "         5.2617,  6.1110,  6.1348,  4.5005,  6.2834,  4.0471,  4.9201,  7.1834,\n",
            "         5.5230,  4.9956,  6.5812,  4.8333,  8.5123,  6.8945,  5.5769,  6.2967,\n",
            "         5.8243, 12.8852,  4.7119,  4.4909,  5.5636,  5.6348,  8.2986,  9.1099,\n",
            "         5.0584,  9.4456,  7.3129,  4.5394,  4.1550,  7.6157,  5.2651,  4.8330,\n",
            "         4.7674,  6.5937,  5.3369,  4.7382,  5.6309,  4.6903,  4.8823,  4.6692,\n",
            "         5.5321,  5.1313,  4.8622,  6.2000,  7.9401,  5.0411,  5.5122,  5.5515])), ('module.encoder_k.layer3.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.1.conv2.weight', tensor([[[[-0.0069, -0.0373,  0.0379],\n",
            "          [-0.0575,  0.0109, -0.0606],\n",
            "          [-0.0043, -0.0034, -0.0258]],\n",
            "\n",
            "         [[ 0.0401, -0.0340,  0.0064],\n",
            "          [ 0.0646,  0.0359,  0.0218],\n",
            "          [ 0.0397,  0.0204, -0.0301]],\n",
            "\n",
            "         [[ 0.0238,  0.0054, -0.0173],\n",
            "          [-0.0387,  0.0300,  0.0083],\n",
            "          [ 0.0460,  0.0096,  0.0700]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0238,  0.0524, -0.0178],\n",
            "          [ 0.0406,  0.0302, -0.0066],\n",
            "          [ 0.0090,  0.0161,  0.0118]],\n",
            "\n",
            "         [[-0.0316,  0.0161,  0.0129],\n",
            "          [ 0.0508,  0.0291,  0.0460],\n",
            "          [-0.0174, -0.0352, -0.0451]],\n",
            "\n",
            "         [[ 0.0175,  0.0501,  0.0702],\n",
            "          [-0.0148,  0.0406,  0.0169],\n",
            "          [ 0.0190,  0.0576, -0.0035]]],\n",
            "\n",
            "\n",
            "        [[[-0.0020, -0.0607,  0.0330],\n",
            "          [-0.0142, -0.0224,  0.0426],\n",
            "          [-0.0276, -0.0112, -0.0363]],\n",
            "\n",
            "         [[-0.0287,  0.0003,  0.0115],\n",
            "          [ 0.0135,  0.0356, -0.0181],\n",
            "          [-0.0016, -0.0283,  0.0409]],\n",
            "\n",
            "         [[-0.0155, -0.0383, -0.0274],\n",
            "          [ 0.0063, -0.0058,  0.0368],\n",
            "          [ 0.0555, -0.0099,  0.0068]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0239,  0.0004,  0.0296],\n",
            "          [-0.0111,  0.0220,  0.0205],\n",
            "          [ 0.0363, -0.0294,  0.0104]],\n",
            "\n",
            "         [[ 0.0450, -0.0243,  0.0578],\n",
            "          [-0.0407, -0.0058,  0.0252],\n",
            "          [-0.0842,  0.0245,  0.0045]],\n",
            "\n",
            "         [[ 0.0016,  0.0045,  0.0446],\n",
            "          [ 0.0410, -0.0316, -0.0148],\n",
            "          [ 0.0338,  0.0196,  0.0184]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0310,  0.0306, -0.0009],\n",
            "          [ 0.0043,  0.0229, -0.0003],\n",
            "          [-0.0159, -0.0006, -0.0551]],\n",
            "\n",
            "         [[ 0.0215, -0.0407,  0.0224],\n",
            "          [-0.0010, -0.0443, -0.0086],\n",
            "          [ 0.0295,  0.0304,  0.0316]],\n",
            "\n",
            "         [[-0.0036,  0.0360,  0.0088],\n",
            "          [ 0.0399, -0.0144, -0.0685],\n",
            "          [ 0.0214, -0.0045,  0.0147]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0065, -0.0655, -0.0015],\n",
            "          [ 0.0108,  0.0195,  0.0062],\n",
            "          [-0.0096, -0.0017,  0.0187]],\n",
            "\n",
            "         [[ 0.0387, -0.0291, -0.0081],\n",
            "          [-0.0294, -0.0289,  0.0700],\n",
            "          [ 0.0144,  0.0246, -0.0121]],\n",
            "\n",
            "         [[ 0.0353, -0.0124, -0.0603],\n",
            "          [ 0.0104,  0.0140, -0.0209],\n",
            "          [-0.0371,  0.0301, -0.0247]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0116,  0.0202,  0.0050],\n",
            "          [ 0.0515, -0.0002,  0.0095],\n",
            "          [-0.0215,  0.0015,  0.0208]],\n",
            "\n",
            "         [[-0.0131,  0.0087, -0.0254],\n",
            "          [ 0.0402,  0.0292,  0.0071],\n",
            "          [-0.0051, -0.0033, -0.0110]],\n",
            "\n",
            "         [[-0.0472, -0.0181,  0.0272],\n",
            "          [ 0.0310, -0.0066,  0.0381],\n",
            "          [ 0.0306, -0.0168,  0.0044]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0151, -0.0107, -0.0148],\n",
            "          [ 0.0101,  0.0043, -0.0611],\n",
            "          [-0.0261,  0.0384, -0.0622]],\n",
            "\n",
            "         [[ 0.0438, -0.0096, -0.0428],\n",
            "          [-0.0249, -0.0282, -0.0288],\n",
            "          [-0.0166,  0.0147, -0.0104]],\n",
            "\n",
            "         [[ 0.0614, -0.0242,  0.0256],\n",
            "          [-0.0288,  0.0023,  0.0008],\n",
            "          [-0.0230, -0.0157, -0.0205]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0521, -0.0035,  0.0285],\n",
            "          [-0.0164, -0.0128,  0.0059],\n",
            "          [ 0.0230, -0.0257,  0.0144]],\n",
            "\n",
            "         [[ 0.0324, -0.0306, -0.0270],\n",
            "          [-0.0351, -0.0215, -0.0142],\n",
            "          [ 0.0314,  0.0189,  0.0280]],\n",
            "\n",
            "         [[ 0.0297, -0.0756,  0.0272],\n",
            "          [ 0.0149,  0.0102,  0.0069],\n",
            "          [ 0.0143,  0.0290, -0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0005, -0.0262, -0.0052],\n",
            "          [ 0.0298,  0.0032, -0.0154],\n",
            "          [ 0.0259, -0.0211, -0.0014]],\n",
            "\n",
            "         [[-0.0215,  0.0217, -0.0064],\n",
            "          [ 0.0235, -0.0132, -0.0226],\n",
            "          [-0.0590,  0.0062,  0.0380]],\n",
            "\n",
            "         [[ 0.0138, -0.0166, -0.0102],\n",
            "          [-0.0376,  0.0230,  0.0177],\n",
            "          [-0.0183, -0.0576, -0.0074]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0256,  0.0336,  0.0676],\n",
            "          [-0.0284,  0.0264,  0.0238],\n",
            "          [ 0.0172, -0.0257,  0.0228]],\n",
            "\n",
            "         [[ 0.0171, -0.0013,  0.0187],\n",
            "          [ 0.0603,  0.0113, -0.0084],\n",
            "          [-0.0214,  0.0186,  0.0402]],\n",
            "\n",
            "         [[-0.0351, -0.0461,  0.0158],\n",
            "          [ 0.0181, -0.0233,  0.0666],\n",
            "          [ 0.0115,  0.0674,  0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0186,  0.0265,  0.0255],\n",
            "          [-0.0161, -0.0179,  0.0307],\n",
            "          [-0.0319,  0.0243,  0.0067]],\n",
            "\n",
            "         [[ 0.0518,  0.0234, -0.0165],\n",
            "          [ 0.0263, -0.0205,  0.0322],\n",
            "          [ 0.0416, -0.0070, -0.0275]],\n",
            "\n",
            "         [[ 0.0097, -0.0100,  0.0545],\n",
            "          [-0.0388, -0.0164, -0.0056],\n",
            "          [-0.0462,  0.0532, -0.0537]]]])), ('module.encoder_k.layer3.1.bn2.weight', tensor([0.9993, 0.9990, 0.9992, 0.9990, 0.9990, 0.9992, 0.9990, 0.9991, 0.9992,\n",
            "        0.9990, 0.9994, 0.9990, 0.9991, 0.9993, 0.9989, 0.9993, 0.9988, 0.9992,\n",
            "        0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9991, 0.9988, 0.9991, 0.9992,\n",
            "        0.9993, 0.9992, 0.9995, 0.9993, 0.9988, 0.9990, 0.9993, 0.9992, 0.9992,\n",
            "        0.9992, 0.9990, 0.9991, 0.9990, 0.9989, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9992, 0.9990, 0.9995, 0.9991, 0.9990, 0.9990,\n",
            "        0.9993, 0.9991, 0.9989, 0.9991, 0.9987, 0.9993, 0.9991, 0.9992, 0.9990,\n",
            "        0.9989, 0.9991, 0.9993, 0.9990, 0.9990, 0.9991, 0.9988, 0.9989, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9993, 0.9991,\n",
            "        0.9989, 0.9991, 0.9992, 0.9991, 0.9989, 0.9990, 0.9988, 0.9990, 0.9988,\n",
            "        0.9992, 0.9990, 0.9992, 0.9989, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9987, 0.9990, 0.9990, 0.9990, 0.9992, 0.9992, 0.9992,\n",
            "        0.9992, 0.9992, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9992, 0.9988,\n",
            "        0.9993, 0.9991, 0.9993, 0.9990, 0.9991, 0.9991, 0.9991, 0.9989, 0.9990,\n",
            "        0.9992, 0.9987, 0.9992, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9993, 0.9990, 0.9992, 0.9990, 0.9991, 0.9990, 0.9992,\n",
            "        0.9989, 0.9991, 0.9993, 0.9991, 0.9989, 0.9990, 0.9991, 0.9990, 0.9990,\n",
            "        0.9993, 0.9989, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9992, 0.9991, 0.9992, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9989, 0.9990, 0.9991, 0.9991, 0.9992, 0.9989, 0.9992, 0.9989,\n",
            "        0.9992, 0.9991, 0.9993, 0.9992, 0.9992, 0.9989, 0.9989, 0.9990, 0.9989,\n",
            "        0.9990, 0.9990, 0.9991, 0.9989, 0.9991, 0.9992, 0.9994, 0.9990, 0.9990,\n",
            "        0.9990, 0.9989, 0.9991, 0.9991, 0.9992, 0.9993, 0.9988, 0.9994, 0.9993,\n",
            "        0.9991, 0.9990, 0.9992, 0.9992, 0.9991, 0.9995, 0.9990, 0.9992, 0.9992,\n",
            "        0.9990, 0.9989, 0.9989, 0.9989, 0.9991, 0.9991, 0.9991, 0.9990, 0.9989,\n",
            "        0.9989, 0.9990, 0.9993, 0.9989, 0.9991, 0.9990, 0.9989, 0.9991, 0.9992,\n",
            "        0.9993, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9993,\n",
            "        0.9990, 0.9992, 0.9992, 0.9990, 0.9992, 0.9990, 0.9992, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9992, 0.9990])), ('module.encoder_k.layer3.1.bn2.bias', tensor([ 8.1653e-05,  1.3514e-04, -7.2326e-06, -9.7397e-05,  4.3152e-05,\n",
            "        -8.9886e-05,  5.1873e-05,  2.3578e-04,  1.0435e-04, -1.8580e-04,\n",
            "         2.0476e-04,  6.7734e-05,  5.7292e-05,  1.5206e-05, -6.9882e-05,\n",
            "        -1.7432e-05, -1.4144e-04,  1.4724e-04, -7.3946e-05,  2.1169e-04,\n",
            "         4.3544e-05, -3.9668e-05,  6.3605e-05,  5.3117e-07,  3.4977e-05,\n",
            "         6.0223e-05,  2.6896e-04, -3.1229e-05,  2.0291e-04,  2.2627e-05,\n",
            "         2.1144e-05,  2.4006e-05,  5.1763e-05,  1.1832e-04, -6.5607e-05,\n",
            "         1.8945e-04,  2.4557e-05, -1.5589e-04,  2.1812e-05,  6.7820e-05,\n",
            "        -1.1819e-05,  1.0693e-04, -7.3509e-05, -4.8638e-05,  1.3328e-04,\n",
            "         9.1434e-05,  6.0764e-05, -1.2812e-04, -5.5386e-06, -3.1259e-05,\n",
            "         2.4868e-04,  8.9409e-05, -7.5411e-07, -2.6942e-04,  1.2411e-04,\n",
            "        -3.3651e-06, -1.5967e-04, -3.2312e-05, -3.9063e-04,  3.2343e-04,\n",
            "         5.4225e-05, -5.9676e-05, -1.2932e-05, -8.8352e-05,  8.0853e-05,\n",
            "         1.3369e-04, -4.4569e-05, -4.0275e-05,  1.4080e-05, -1.9358e-05,\n",
            "        -8.2044e-06, -5.2611e-05,  1.9723e-05,  1.7081e-04,  1.6698e-04,\n",
            "        -6.6416e-05, -3.5471e-05, -6.1135e-05, -4.9309e-05,  3.5869e-04,\n",
            "        -6.3577e-05, -9.0749e-05,  2.7999e-05,  5.0985e-05, -2.5640e-08,\n",
            "        -1.2611e-04, -3.5728e-05, -1.3086e-04, -3.9210e-05, -1.6989e-04,\n",
            "         1.1884e-04, -1.8623e-04,  2.2203e-05,  7.4061e-05, -3.5040e-05,\n",
            "         1.7993e-05,  1.1710e-04,  9.0156e-05, -2.3000e-06, -1.7603e-04,\n",
            "        -2.8247e-07, -2.8954e-04, -5.5641e-05, -1.2297e-05,  1.2185e-04,\n",
            "         2.6477e-04,  2.7619e-05,  1.2321e-04,  5.3450e-05,  1.6908e-04,\n",
            "         6.7445e-05, -8.3353e-05, -1.2210e-05, -1.8832e-04,  4.5678e-05,\n",
            "        -4.8565e-05, -5.1184e-05,  2.1300e-04,  8.0836e-05, -8.8639e-05,\n",
            "         3.4279e-05,  1.0016e-04,  5.1548e-06, -9.5575e-05, -1.8266e-04,\n",
            "        -6.9685e-05,  1.9775e-04, -1.9493e-04,  7.2437e-05,  1.2261e-04,\n",
            "        -1.7340e-05, -1.2967e-05,  3.2204e-05,  3.7102e-05, -8.3517e-05,\n",
            "         5.2700e-05,  7.0679e-05,  1.4868e-04, -2.5801e-04,  1.9469e-04,\n",
            "        -6.9064e-05, -6.6215e-05, -1.7672e-04,  1.5459e-05, -2.3686e-04,\n",
            "        -9.0732e-05,  1.7552e-04, -9.1221e-05, -2.1178e-04, -3.1073e-05,\n",
            "        -2.3215e-05, -1.1942e-04, -3.6259e-05,  1.4301e-04,  7.2571e-05,\n",
            "         1.3327e-04,  5.3170e-05,  1.2143e-04, -8.8509e-05, -1.9600e-05,\n",
            "         3.1508e-05, -1.6624e-04, -1.7385e-04,  1.4465e-04, -1.7175e-04,\n",
            "         9.5781e-05,  6.0622e-05,  6.7998e-05, -4.3013e-05,  2.1043e-06,\n",
            "        -1.6688e-06, -1.4430e-04,  5.9629e-05, -3.5747e-05,  2.4032e-05,\n",
            "         1.5808e-04,  1.3165e-04, -6.4856e-05,  1.6122e-05, -1.7666e-04,\n",
            "         2.3752e-04,  7.0538e-05,  2.1236e-04,  3.9033e-05, -1.6080e-04,\n",
            "        -1.6826e-04, -1.6232e-04,  3.7814e-05, -1.1097e-04,  5.4477e-05,\n",
            "        -7.1222e-05, -1.0921e-04, -5.1552e-05,  1.2632e-04,  6.8603e-05,\n",
            "         1.5407e-04, -4.7662e-05, -1.4924e-04, -1.3455e-04, -5.4647e-05,\n",
            "        -1.9700e-05,  5.3246e-05,  2.5363e-04,  9.3451e-05, -9.9134e-05,\n",
            "         1.2513e-04,  1.2383e-04, -1.5105e-04, -5.7946e-06,  1.4221e-04,\n",
            "         9.7199e-06, -3.3093e-05,  1.4477e-04, -9.8653e-05, -6.8222e-05,\n",
            "         1.1702e-05,  8.0606e-07, -1.2446e-04,  2.6656e-05, -1.5696e-04,\n",
            "         5.5843e-05, -4.9833e-05,  7.3579e-05, -1.1799e-04, -8.1879e-05,\n",
            "        -1.9771e-04, -8.1687e-05,  2.1913e-04, -1.4077e-04,  7.2021e-05,\n",
            "        -1.2270e-04, -6.9957e-05,  4.4855e-05,  1.6463e-04,  1.2498e-04,\n",
            "         1.0078e-04,  7.1439e-05,  6.8059e-05, -1.9216e-05,  1.3940e-06,\n",
            "         1.0536e-04,  2.5819e-05,  1.4455e-05, -1.8007e-05,  1.7518e-04,\n",
            "         1.6389e-04, -7.6202e-05,  3.1917e-04, -1.7090e-04,  1.5785e-04,\n",
            "        -8.5719e-05, -1.9440e-04,  3.4097e-05,  1.7416e-04,  9.8830e-05,\n",
            "        -1.6173e-04])), ('module.encoder_k.layer3.1.bn2.running_mean', tensor([-1.1606e-01,  1.5646e-01,  8.6641e-03,  4.3582e-01,  5.4322e-01,\n",
            "        -2.7977e-01, -4.3873e-01, -3.2489e-01,  1.7888e-02, -5.5360e-01,\n",
            "         2.0602e-03, -5.8701e-01,  1.3463e-01,  1.3936e-01,  2.0042e-01,\n",
            "        -1.1815e-01,  6.4330e-01, -1.5817e-01, -8.4614e-02, -3.1963e-02,\n",
            "         6.3247e-01,  2.1299e-01,  6.2495e-01, -3.1563e-01, -3.9193e-02,\n",
            "        -3.7966e-02, -5.5581e-01,  3.5766e-01,  1.7100e-02, -1.4286e-01,\n",
            "        -2.0114e-01,  5.1642e-03,  2.0914e-02, -4.0098e-01,  4.5391e-03,\n",
            "         2.2678e-01,  3.0295e-02, -3.9884e-01,  4.3954e-02, -2.7697e-01,\n",
            "        -3.0292e-01,  2.4640e-01,  8.3304e-03, -2.2640e-01, -2.4431e-02,\n",
            "        -2.1037e-01,  1.6887e-01,  2.4764e-01,  9.1338e-01, -5.1570e-02,\n",
            "        -3.5344e-01, -1.1481e-01,  6.6170e-01,  5.3497e-01,  3.2106e-01,\n",
            "        -1.5075e-01,  2.1241e-02,  1.1616e-01,  3.2140e-01, -5.1650e-01,\n",
            "         1.3481e-03, -6.2058e-02,  2.6039e-01, -2.0838e-01, -6.9265e-01,\n",
            "         2.7749e-01, -4.1867e-01, -4.0045e-01, -3.4097e-01, -3.4741e-01,\n",
            "         2.6813e-01, -6.6899e-01,  9.8853e-01, -2.6203e-01, -5.6447e-01,\n",
            "        -2.7511e-01,  6.1851e-01, -4.9034e-01, -3.3489e-01,  4.3790e-01,\n",
            "        -3.7126e-01, -2.7341e-01,  1.3924e-01,  2.0162e-01, -8.8043e-01,\n",
            "         2.1159e-01, -3.9899e-01,  3.4187e-01, -8.5704e-02,  9.4814e-02,\n",
            "         2.6120e-01,  3.4119e-01, -7.9522e-01, -2.8513e-01, -2.8968e-01,\n",
            "         1.6618e-01,  6.8025e-01,  6.8139e-01,  1.4429e-01, -4.6858e-01,\n",
            "        -1.8120e-02,  1.4311e-01,  2.8187e-01,  1.2762e-01, -3.8019e-01,\n",
            "         1.1979e-01,  3.5718e-01, -3.5251e-01,  3.2146e-01, -2.5036e-01,\n",
            "        -6.3659e-01,  1.4116e-01,  6.8457e-01,  2.8573e-01,  1.4550e-01,\n",
            "         1.0115e-02,  1.1317e+00, -1.0169e-03,  8.2445e-01,  2.8742e-01,\n",
            "         6.2327e-02, -1.8480e-01, -6.1058e-01, -6.3082e-01,  4.7852e-01,\n",
            "        -6.7523e-01, -5.8479e-02, -5.6685e-01,  4.3036e-01,  3.9321e-02,\n",
            "         3.7990e-01,  7.5781e-01,  6.9968e-01,  4.1768e-01, -1.8231e-01,\n",
            "        -8.7665e-01, -3.2598e-01,  7.1738e-01,  1.1623e-01, -4.8694e-01,\n",
            "        -8.9415e-01, -3.4575e-01, -7.4295e-01, -5.8671e-01, -1.5912e-01,\n",
            "        -4.4023e-01,  3.4550e-01,  5.6890e-01, -6.0088e-01, -1.4064e-01,\n",
            "         1.4420e-02,  2.7648e-01, -4.0156e-01, -2.6183e-01, -1.0449e-02,\n",
            "         1.8197e-01, -8.3591e-01,  1.6568e-01, -3.3839e-01, -7.6485e-01,\n",
            "         1.4268e-01, -3.2805e-01,  1.1809e-02,  1.7238e-02, -1.9142e-01,\n",
            "         3.5491e-01, -8.9292e-02,  7.6521e-03, -5.0383e-02,  2.0899e-01,\n",
            "         8.4473e-01, -7.4829e-01,  5.6878e-02, -2.2208e-01,  2.3784e-01,\n",
            "        -5.2695e-01, -6.6002e-01,  7.2847e-01,  8.4903e-01,  3.3841e-01,\n",
            "        -3.1615e-01,  1.7295e-01,  1.2243e+00,  3.1339e-01,  5.1436e-02,\n",
            "        -7.1816e-01, -2.0743e-01, -3.2551e-01,  2.9161e-01,  1.2739e-01,\n",
            "         6.5131e-02,  3.3439e-01,  3.5901e-02,  2.2397e-02, -2.7030e-01,\n",
            "         3.5055e-01, -1.3361e-01,  6.1748e-01,  2.9154e-01,  1.8616e-01,\n",
            "        -1.4377e-01, -1.6681e-01, -6.1096e-02, -2.4755e-01, -3.7963e-01,\n",
            "         5.6244e-01, -6.5246e-01,  4.1348e-01, -2.5071e-01, -2.2250e-01,\n",
            "         4.5859e-01,  6.7792e-01,  5.5747e-02,  1.9633e-01,  3.0900e-01,\n",
            "        -9.3881e-02,  4.8321e-01, -4.8458e-01, -2.6253e-01,  4.5885e-01,\n",
            "        -2.7022e-01, -1.6631e-01,  1.6214e-01, -2.9892e-01,  1.4354e+00,\n",
            "         4.6028e-01,  6.0433e-01, -2.7338e-01,  1.5574e-01, -5.1799e-01,\n",
            "        -7.1233e-03, -2.4909e-02,  2.5712e-01,  1.8735e-01, -4.2764e-02,\n",
            "         2.0696e-01,  2.6647e-01,  3.5708e-01, -1.4135e-01,  1.1626e-01,\n",
            "         2.6898e-01,  5.3187e-01,  2.1856e-01, -2.7569e-01, -8.1906e-01,\n",
            "        -1.5448e-01, -1.4518e-02,  6.4627e-01, -2.4701e-01,  8.0986e-01,\n",
            "        -4.6725e-01,  3.9074e-01, -7.6238e-02, -7.3996e-01, -5.1533e-01,\n",
            "         1.2190e+00])), ('module.encoder_k.layer3.1.bn2.running_var', tensor([0.5519, 0.6134, 0.7978, 0.6687, 0.6114, 0.6571, 0.7244, 1.1961, 0.5669,\n",
            "        0.7323, 0.5471, 0.9527, 0.6343, 0.5590, 0.5614, 0.6124, 0.7292, 0.5660,\n",
            "        0.6037, 0.5587, 0.7210, 0.6375, 0.8053, 0.5768, 0.6501, 0.7420, 0.6253,\n",
            "        0.6579, 0.7165, 0.6549, 0.8709, 0.7909, 0.5779, 0.7624, 0.5828, 0.5584,\n",
            "        0.5770, 0.5758, 0.7640, 0.5924, 0.7915, 0.6952, 0.6125, 0.6230, 0.5850,\n",
            "        0.5703, 0.5652, 0.6827, 1.0717, 0.5308, 0.6421, 0.5267, 1.0925, 0.9883,\n",
            "        0.5979, 0.6305, 0.5993, 0.5800, 0.5783, 0.6269, 0.5900, 0.5353, 0.8259,\n",
            "        0.6597, 0.8727, 0.7865, 0.7084, 0.6182, 0.5807, 0.5783, 0.7541, 0.5788,\n",
            "        0.6261, 0.5828, 0.6336, 1.0229, 0.7265, 0.5813, 0.5751, 0.6289, 0.8125,\n",
            "        0.5297, 0.5228, 0.8437, 0.6666, 0.6284, 0.8472, 0.6047, 0.6386, 0.7343,\n",
            "        0.8898, 0.6075, 1.0596, 0.5027, 0.6995, 0.5426, 0.5629, 0.7843, 0.6189,\n",
            "        0.5858, 0.5121, 0.5489, 0.9087, 0.6717, 0.5568, 0.6100, 0.5954, 1.1519,\n",
            "        0.5347, 0.5570, 0.9855, 0.6871, 2.1830, 0.7309, 0.6885, 0.5538, 0.6663,\n",
            "        0.7603, 0.8987, 0.5733, 0.6980, 0.5435, 0.6941, 0.7980, 0.6192, 0.8457,\n",
            "        0.7276, 0.5928, 0.8125, 0.5280, 0.5453, 0.6490, 1.0429, 1.0663, 0.6832,\n",
            "        0.7396, 0.7242, 0.6323, 0.7440, 1.7818, 0.9974, 0.7985, 0.7481, 0.7960,\n",
            "        0.5947, 0.6964, 0.7672, 0.5362, 0.6481, 0.8217, 0.5570, 0.5574, 0.8705,\n",
            "        0.5456, 0.7903, 0.8618, 0.6611, 0.5613, 0.5532, 0.5555, 0.5491, 0.6495,\n",
            "        0.5932, 0.5417, 0.6462, 0.7122, 0.5593, 0.5501, 0.7969, 0.5502, 1.5063,\n",
            "        0.7187, 0.6380, 0.9387, 0.5698, 0.9010, 0.6201, 0.5564, 0.8238, 0.7180,\n",
            "        0.6528, 0.5722, 2.3622, 0.8218, 0.6988, 0.5989, 0.5498, 0.6168, 0.7425,\n",
            "        0.5984, 0.5118, 0.8566, 0.6522, 0.8679, 0.7478, 0.6073, 0.6596, 0.8614,\n",
            "        0.7469, 0.5835, 0.5406, 0.7006, 0.7144, 0.5837, 0.5234, 0.9038, 0.6397,\n",
            "        0.9360, 0.6318, 0.5192, 0.6213, 0.5948, 0.6348, 0.5995, 0.8750, 0.5189,\n",
            "        1.0015, 0.6489, 0.5921, 0.7028, 0.6382, 0.6302, 0.5887, 0.5847, 0.7186,\n",
            "        0.8301, 0.6753, 1.0712, 0.5676, 0.6027, 0.5820, 0.8840, 0.6463, 0.6332,\n",
            "        0.6495, 0.6536, 0.7175, 0.7140, 0.9938, 0.5436, 0.6893, 0.7216, 0.5976,\n",
            "        0.6216, 0.7086, 0.5336, 0.6233, 0.7252, 0.5608, 1.0080, 0.7465, 0.6922,\n",
            "        0.5609, 1.3659, 0.6542, 0.7957])), ('module.encoder_k.layer3.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.1.conv3.weight', tensor([[[[-0.0668]],\n",
            "\n",
            "         [[-0.0088]],\n",
            "\n",
            "         [[-0.0383]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0205]],\n",
            "\n",
            "         [[ 0.0600]],\n",
            "\n",
            "         [[-0.0253]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0032]],\n",
            "\n",
            "         [[ 0.0046]],\n",
            "\n",
            "         [[ 0.0342]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0405]],\n",
            "\n",
            "         [[-0.0514]],\n",
            "\n",
            "         [[ 0.0009]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0363]],\n",
            "\n",
            "         [[-0.0264]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0446]],\n",
            "\n",
            "         [[ 0.0066]],\n",
            "\n",
            "         [[-0.0890]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0325]],\n",
            "\n",
            "         [[-0.0052]],\n",
            "\n",
            "         [[-0.0686]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0266]],\n",
            "\n",
            "         [[-0.1042]],\n",
            "\n",
            "         [[-0.0385]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0382]],\n",
            "\n",
            "         [[ 0.0410]],\n",
            "\n",
            "         [[ 0.0466]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0511]],\n",
            "\n",
            "         [[ 0.0429]],\n",
            "\n",
            "         [[ 0.0233]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0066]],\n",
            "\n",
            "         [[ 0.0224]],\n",
            "\n",
            "         [[ 0.0241]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0636]],\n",
            "\n",
            "         [[-0.0698]],\n",
            "\n",
            "         [[-0.0828]]]])), ('module.encoder_k.layer3.1.bn3.weight', tensor([0.9991, 0.9992, 0.9992,  ..., 0.9992, 0.9990, 0.9991])), ('module.encoder_k.layer3.1.bn3.bias', tensor([-4.4946e-06,  1.3352e-05,  2.5039e-05,  ..., -1.1084e-05,\n",
            "        -6.3044e-05, -4.6263e-05])), ('module.encoder_k.layer3.1.bn3.running_mean', tensor([-0.1765, -0.2634, -0.0582,  ..., -0.3518, -0.1404, -0.2804])), ('module.encoder_k.layer3.1.bn3.running_var', tensor([0.1384, 0.2398, 0.1372,  ..., 0.1448, 0.1614, 0.1268])), ('module.encoder_k.layer3.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.2.conv1.weight', tensor([[[[ 0.1743]],\n",
            "\n",
            "         [[-0.0590]],\n",
            "\n",
            "         [[ 0.0247]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0343]],\n",
            "\n",
            "         [[-0.0194]],\n",
            "\n",
            "         [[ 0.0540]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1238]],\n",
            "\n",
            "         [[ 0.1049]],\n",
            "\n",
            "         [[ 0.0075]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0680]],\n",
            "\n",
            "         [[-0.1064]],\n",
            "\n",
            "         [[-0.0993]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0403]],\n",
            "\n",
            "         [[ 0.0041]],\n",
            "\n",
            "         [[ 0.0898]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0547]],\n",
            "\n",
            "         [[-0.0917]],\n",
            "\n",
            "         [[ 0.0301]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0237]],\n",
            "\n",
            "         [[-0.0644]],\n",
            "\n",
            "         [[ 0.0792]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0580]],\n",
            "\n",
            "         [[ 0.0286]],\n",
            "\n",
            "         [[ 0.0193]]],\n",
            "\n",
            "\n",
            "        [[[-0.1203]],\n",
            "\n",
            "         [[ 0.0971]],\n",
            "\n",
            "         [[ 0.1001]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0436]],\n",
            "\n",
            "         [[-0.0997]],\n",
            "\n",
            "         [[ 0.0059]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0114]],\n",
            "\n",
            "         [[-0.0995]],\n",
            "\n",
            "         [[-0.0439]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0677]],\n",
            "\n",
            "         [[ 0.0202]],\n",
            "\n",
            "         [[-0.0298]]]])), ('module.encoder_k.layer3.2.bn1.weight', tensor([0.9991, 0.9994, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9992, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9992,\n",
            "        0.9991, 0.9991, 0.9993, 0.9992, 0.9990, 0.9993, 0.9991, 0.9992, 0.9992,\n",
            "        0.9993, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9992, 0.9989, 0.9993,\n",
            "        0.9992, 0.9989, 0.9990, 0.9990, 0.9993, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9992, 0.9990, 0.9990, 0.9990, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9989, 0.9991, 0.9991, 0.9989,\n",
            "        0.9990, 0.9989, 0.9991, 0.9990, 0.9989, 0.9991, 0.9993, 0.9991, 0.9991,\n",
            "        0.9990, 0.9989, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9989, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9988,\n",
            "        0.9990, 0.9990, 0.9992, 0.9989, 0.9991, 0.9989, 0.9992, 0.9991, 0.9989,\n",
            "        0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9992, 0.9990, 0.9992, 0.9994,\n",
            "        0.9991, 0.9992, 0.9992, 0.9993, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9992, 0.9990, 0.9991, 0.9993, 0.9989, 0.9991, 0.9989, 0.9991, 0.9990,\n",
            "        0.9988, 0.9990, 0.9989, 0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991,\n",
            "        0.9992, 0.9988, 0.9993, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992, 0.9991, 0.9990,\n",
            "        0.9988, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9990, 0.9992, 0.9991, 0.9993, 0.9991, 0.9990, 0.9989, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9992, 0.9993, 0.9992, 0.9992, 0.9990, 0.9993,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9989, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990, 0.9989, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990, 0.9993, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9989, 0.9988,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991])), ('module.encoder_k.layer3.2.bn1.bias', tensor([ 1.2458e-04,  2.3025e-04, -4.7111e-05, -2.3815e-06,  4.0075e-05,\n",
            "        -3.8741e-05, -8.5571e-05,  1.8638e-05,  3.5107e-05,  1.1374e-04,\n",
            "        -6.1559e-05,  3.4567e-05, -1.8326e-04,  4.1957e-06,  2.8269e-04,\n",
            "         1.3711e-04, -1.3277e-04,  1.9825e-04,  3.3553e-05, -3.5316e-05,\n",
            "         1.8180e-04,  6.4237e-05, -9.0949e-05,  1.1745e-04,  1.0678e-04,\n",
            "         1.8485e-05,  1.6286e-04,  2.3776e-04,  1.6087e-04, -3.8493e-05,\n",
            "        -9.9865e-05, -6.3993e-05,  2.0476e-04,  1.7471e-04,  2.5687e-06,\n",
            "         1.1936e-04,  9.5367e-05, -2.6334e-04, -1.4107e-04, -1.1649e-04,\n",
            "         1.7067e-04, -1.7727e-05, -6.2329e-05, -4.5702e-05, -1.4401e-04,\n",
            "        -1.2592e-04,  1.8499e-05,  3.0020e-05, -4.7123e-05, -2.6938e-04,\n",
            "        -2.4675e-05,  1.9866e-04,  1.6703e-05, -1.1867e-05,  9.0908e-05,\n",
            "        -2.6238e-05, -1.7126e-04,  1.5171e-04, -8.6317e-05, -1.9414e-05,\n",
            "         5.1595e-05, -1.7557e-05, -1.1882e-04, -1.4456e-04,  9.9098e-05,\n",
            "        -1.6244e-04,  8.7928e-05, -5.1164e-05, -1.8972e-04,  7.1397e-05,\n",
            "         3.6347e-05, -7.6949e-05, -7.5020e-05, -7.8145e-05, -6.7118e-05,\n",
            "        -3.0653e-05, -2.2593e-04, -3.3136e-06,  1.3494e-04,  2.6490e-05,\n",
            "        -2.1029e-04,  9.7952e-05, -7.9914e-05, -1.2068e-04, -1.1843e-04,\n",
            "        -1.0545e-04,  3.5943e-05, -3.9742e-05, -2.2857e-04, -1.3303e-04,\n",
            "        -5.1035e-05,  9.3817e-05, -8.6257e-05,  1.8284e-05, -6.0639e-05,\n",
            "        -2.1171e-04,  3.3484e-05,  6.5671e-05, -1.9387e-04,  1.4340e-05,\n",
            "        -3.3761e-05,  8.2549e-05, -1.1247e-04,  1.9762e-04, -1.1043e-04,\n",
            "        -3.2757e-05,  8.7664e-05, -2.0502e-04, -2.0266e-04, -9.1733e-05,\n",
            "        -4.5885e-05,  7.8472e-05,  7.4242e-05,  1.7651e-04, -6.2041e-05,\n",
            "         9.8045e-05,  7.8111e-05,  4.2961e-05, -8.3315e-05,  2.0143e-05,\n",
            "        -9.1742e-06, -6.9020e-06, -1.4753e-04,  1.0548e-04,  6.5731e-05,\n",
            "         6.5013e-07,  5.0229e-05,  1.3376e-04, -5.2337e-05,  8.5737e-05,\n",
            "        -2.8682e-05,  5.8565e-05, -8.4760e-05,  1.5142e-06, -3.1132e-05,\n",
            "        -8.1651e-05,  2.0022e-04,  5.7637e-05,  1.3981e-04,  8.4464e-05,\n",
            "        -9.4756e-05, -1.0721e-04, -6.5138e-05, -7.4169e-05,  8.0291e-05,\n",
            "        -2.6043e-05,  3.4733e-05,  1.3892e-04, -1.4248e-04, -5.6846e-05,\n",
            "        -8.1405e-05, -8.1156e-05, -3.0883e-05, -2.1419e-04,  5.5522e-05,\n",
            "        -5.3666e-05, -1.0221e-05, -2.3307e-05, -2.3367e-05, -5.5638e-05,\n",
            "        -1.4035e-04,  7.9143e-05,  5.9183e-06, -1.9731e-04,  2.0048e-04,\n",
            "         2.8230e-04, -5.0833e-05, -1.3608e-05,  1.1344e-04,  1.6290e-04,\n",
            "        -2.0098e-04, -9.1793e-05, -1.4710e-05,  1.1712e-04, -2.6468e-05,\n",
            "         1.9556e-05, -6.2353e-05,  2.8465e-04, -8.7818e-05,  3.4982e-06,\n",
            "        -1.6628e-04,  3.1138e-05, -3.9656e-05,  2.4595e-05,  2.3085e-04,\n",
            "         7.5028e-05,  1.0911e-05, -2.0275e-06, -1.7307e-05, -1.0656e-04,\n",
            "         4.5401e-05,  2.9731e-05,  7.7491e-05, -1.0852e-05,  1.2931e-05,\n",
            "        -3.9266e-05, -1.1895e-04,  8.7731e-05, -1.8241e-04,  9.1884e-05,\n",
            "        -5.5805e-05,  2.6926e-04,  1.3358e-04,  9.6209e-05,  3.9380e-05,\n",
            "        -8.6221e-05,  1.8750e-04,  8.8488e-05,  2.1866e-05, -1.3872e-04,\n",
            "        -1.3162e-04,  6.2009e-05, -7.5246e-06, -1.0115e-04, -8.9114e-05,\n",
            "        -2.2737e-04,  4.2688e-05, -1.3981e-05,  1.0229e-04,  1.0456e-04,\n",
            "        -8.6461e-07,  2.1634e-04, -7.2881e-05, -2.3039e-04,  9.2012e-05,\n",
            "        -8.0995e-05, -5.0574e-05, -2.0922e-04, -1.9445e-05, -1.2839e-04,\n",
            "         4.7011e-05,  2.7148e-04, -1.4361e-05, -2.4580e-05,  3.6755e-05,\n",
            "         1.0073e-04,  7.1074e-05, -6.6261e-05,  2.1525e-05, -1.9652e-05,\n",
            "         5.3688e-05,  1.4170e-04,  9.9157e-05, -6.8076e-05,  1.2968e-04,\n",
            "        -1.8988e-04,  2.0159e-05, -1.0133e-04, -4.4489e-05,  1.2146e-06,\n",
            "        -9.5174e-05, -7.3075e-05, -8.6940e-05, -8.7611e-05, -7.5096e-05,\n",
            "         2.4594e-06])), ('module.encoder_k.layer3.2.bn1.running_mean', tensor([-0.3856,  1.6135,  0.7067, -1.4837,  1.9414, -1.1146,  2.2002,  3.2606,\n",
            "        -0.4583,  0.8674, -1.9341,  0.6075,  0.5259,  0.1795,  1.1691, -2.1922,\n",
            "         1.0101,  1.1597, -3.4917, -1.3317, -5.0082,  2.2357,  0.2342,  2.5119,\n",
            "        -0.8155,  1.2532,  4.7098,  1.2110, -1.0734,  0.3452,  0.1282, -2.0853,\n",
            "         2.9842,  1.7576, -1.1450,  0.7037,  0.7322, -0.7475, -0.7785,  0.5365,\n",
            "         0.6678,  3.0325, -0.7462, -0.3297,  0.3110,  1.2674, -3.5070,  1.0788,\n",
            "         0.0150, -0.0986,  1.4548,  1.7050, -1.1260,  1.0299, -1.9385, -0.3890,\n",
            "        -3.0282,  3.3548, -0.3125, -0.2874, -1.4506,  1.2699, -2.6904,  1.8195,\n",
            "        -2.6046, -0.2631, -4.7841, -1.4204,  1.6660,  4.8658, -1.7400,  0.0836,\n",
            "        -1.6556, -0.9316, -1.9704, -2.5321, -0.1051, -0.5556,  0.4409, -1.3555,\n",
            "        -0.1739,  2.1166, -1.8033,  0.6420, -2.8083, -1.7898, -0.1638, -3.9730,\n",
            "        -1.3825, -0.2287, -0.5609,  1.9867, -1.7643,  1.7510, -1.6650, -1.8814,\n",
            "        -0.7457,  0.3676,  3.1150, -3.5350,  1.2251,  2.7756, -4.8208, -1.8365,\n",
            "         0.8560,  0.4066,  0.8679,  3.6888, -3.8777,  2.0819,  0.8604, -0.8392,\n",
            "        -4.1086,  0.9053, -0.0949,  1.0896,  2.1251,  3.0092,  0.4005,  1.2099,\n",
            "         3.6922,  0.5323,  1.8842,  2.5006,  2.5264,  1.4232, -0.5023,  2.2021,\n",
            "         0.8461, -1.8872, -0.4517,  0.3826, -3.3028, -3.1268,  2.3345,  1.3778,\n",
            "        -5.0047,  0.0752, -0.9783,  0.6106,  1.8123,  1.8317, -0.4288, -2.6612,\n",
            "        -1.1682,  3.0083, -0.4327,  0.8587,  0.3698,  0.2380,  1.2451, -0.4782,\n",
            "        -1.5800, -0.0296, -2.7414, -0.2087,  2.4370, -0.1850, -0.4822, -0.7890,\n",
            "         2.3228,  1.1858,  1.6229, -2.9066,  2.0731, -3.6480,  0.6018, -1.7676,\n",
            "         0.2633, -1.5195,  0.7967, -2.0758,  3.2727, -0.6467, -0.2930,  0.3271,\n",
            "        -1.4870,  2.8454,  2.1395,  0.8053, -1.1671, -5.6544, -0.8767, -0.3933,\n",
            "        -0.0682, -0.1567, -1.2768,  3.3331, -3.2251,  0.4174,  1.4132, -1.9242,\n",
            "        -1.4235,  2.3831,  0.9521,  0.1805, -0.9481, -1.0937,  0.3476, -0.7258,\n",
            "        -1.0511,  2.0232,  1.5190, -3.8095,  1.0197, -0.6146,  2.0698,  1.5461,\n",
            "         1.0840, -3.2440, -0.0273, -0.6602,  0.0908, -1.1776,  4.9058, -0.9974,\n",
            "         0.5585,  0.6060,  2.0245,  1.1780,  3.1918,  0.3113, -0.6917,  2.2272,\n",
            "        -1.1734, -1.0417,  2.5212, -3.4635, -1.5685, -0.7563, -1.1371,  0.1206,\n",
            "        -2.9958,  3.0047, -0.3867, -2.2649,  2.0493, -1.5992,  1.9871,  0.6039,\n",
            "        -2.6336, -1.2478, -3.1387, -0.6941,  2.1445,  2.5878,  2.7230,  0.9174,\n",
            "         0.3534,  5.0543, -3.2273, -0.6319,  1.4155,  4.9126,  1.3250,  0.4596])), ('module.encoder_k.layer3.2.bn1.running_var', tensor([ 6.3843,  8.8345,  9.1372,  9.8596,  7.9480, 18.0607,  9.4084, 26.9498,\n",
            "         6.2071,  6.2732, 12.3852,  6.0957,  7.5602,  6.3638,  7.5493, 12.7581,\n",
            "         7.8684,  6.9100, 21.3364,  6.3866, 14.7569, 10.0581,  7.0871,  6.4625,\n",
            "         7.3171,  9.6706, 10.8216,  6.5896,  7.1528,  7.8662,  6.8908,  9.7885,\n",
            "        10.3707, 21.2475,  6.9810,  9.8583,  7.9625,  7.0639,  8.5828,  7.3376,\n",
            "         7.4379,  8.6277,  6.9530, 10.0568, 16.6466,  7.2497, 18.0269,  6.0757,\n",
            "         6.6790,  6.8564, 10.9952,  7.8265,  7.5221,  7.7143,  8.7481, 11.3448,\n",
            "         8.3352,  8.8266,  9.1005,  8.1400,  9.7007,  8.0402,  6.8200,  7.7232,\n",
            "         8.6848,  6.7562, 13.2827,  8.5421,  7.3429,  9.4527,  8.4529,  8.5422,\n",
            "         9.3228,  8.2486,  6.7107,  8.4774,  6.6379,  6.3615,  7.7501,  6.7930,\n",
            "         8.8935,  9.9346,  7.8100,  8.6513, 18.4361, 10.8577,  9.0344, 30.3849,\n",
            "         6.8743,  6.7572,  6.9945,  7.6286, 10.5680,  7.7745,  7.0507,  6.9542,\n",
            "         7.4224,  6.8680,  9.2564,  7.5552,  8.8374, 10.8628, 14.1230,  7.7241,\n",
            "         6.7898,  7.6954,  6.4821,  8.0381, 11.8215,  9.4271,  8.7741,  7.3125,\n",
            "         8.5932, 11.8072,  9.4489,  7.3781, 20.0790,  7.5276,  7.9784,  6.7693,\n",
            "        16.6076,  8.6910,  6.9015, 14.7641, 10.5269,  7.6831,  7.8111,  9.6405,\n",
            "        10.4602,  9.2166, 12.1819,  6.6287, 12.4095, 16.0479,  7.3664,  8.7817,\n",
            "        12.1166,  6.3011,  8.1410,  7.3297, 10.3891, 10.8963,  7.6136, 16.1838,\n",
            "         8.4812, 10.6073,  7.1011,  9.7190, 11.7138,  9.3244,  8.1578,  7.0401,\n",
            "         6.5245,  9.3757,  6.4807, 14.4210,  8.9738,  9.4536,  6.6558, 19.4389,\n",
            "         7.1053,  7.6012, 13.8176,  7.7207,  6.2965,  6.3405,  6.8241,  7.7724,\n",
            "         6.7399,  7.9325,  5.8182,  7.1302,  7.1369,  8.6332,  6.7058,  7.5645,\n",
            "         6.7701,  7.1319, 17.8130,  6.4605,  7.7013, 14.6887,  7.2838,  7.8322,\n",
            "         7.3127,  6.8403,  6.7449, 12.9996,  8.6016,  9.3789, 11.5306,  7.8155,\n",
            "         7.0966,  6.6923,  8.9243,  8.2794,  6.2365,  7.8669,  9.0158,  7.8212,\n",
            "         9.6954,  7.3415,  6.8590,  7.7173,  8.1515,  8.4415,  9.0192,  6.9297,\n",
            "         6.2172, 12.9758,  7.8440,  7.2933,  7.6387,  8.8073, 13.2144,  6.4679,\n",
            "         8.5111,  6.7145,  7.2266,  6.3994,  9.4625,  7.2359,  8.8827, 10.2771,\n",
            "        10.1633,  6.3764,  7.8929,  6.8891, 13.9821,  6.3800,  8.1696,  6.8228,\n",
            "        17.5332, 12.6364,  7.4750,  7.6785,  7.9364, 13.9723,  7.5865,  8.5917,\n",
            "         9.5036,  7.6329,  7.3972,  7.4741,  7.1006,  7.4096, 12.1263,  7.9033,\n",
            "         6.7763, 12.1447,  6.9294,  8.4222,  6.1444, 12.5007,  6.7067,  8.4568])), ('module.encoder_k.layer3.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.2.conv2.weight', tensor([[[[-2.8343e-04,  1.0676e-02, -1.6260e-02],\n",
            "          [-1.7172e-02, -8.7990e-02, -1.0351e-02],\n",
            "          [ 6.3041e-02, -2.9207e-03, -4.1254e-02]],\n",
            "\n",
            "         [[-4.9794e-02, -2.7509e-02, -1.7124e-02],\n",
            "          [ 1.3525e-02, -2.6637e-02,  1.2708e-02],\n",
            "          [-3.0043e-02,  1.4047e-02, -5.6552e-03]],\n",
            "\n",
            "         [[-1.1912e-03, -1.8579e-02, -1.5292e-03],\n",
            "          [-3.5699e-02,  3.2856e-02, -1.2159e-02],\n",
            "          [ 5.1527e-03,  4.1763e-02,  8.8930e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9502e-02,  6.8987e-03,  4.4344e-02],\n",
            "          [-3.3389e-02, -2.9422e-02, -2.3323e-02],\n",
            "          [-3.8395e-03,  4.1378e-02, -5.9860e-02]],\n",
            "\n",
            "         [[ 2.3506e-02,  1.7687e-02, -5.9227e-04],\n",
            "          [ 8.1233e-03,  2.0165e-03, -2.0957e-02],\n",
            "          [-2.1953e-02,  1.9052e-02,  7.5967e-02]],\n",
            "\n",
            "         [[ 4.7288e-02, -1.4123e-02,  4.2495e-02],\n",
            "          [ 2.9974e-02, -4.8760e-02, -1.6661e-02],\n",
            "          [-1.7531e-02,  3.4775e-02, -1.9332e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.3845e-02, -2.4667e-02,  4.1038e-02],\n",
            "          [ 2.9718e-02, -2.8595e-03, -2.4674e-03],\n",
            "          [ 2.3963e-02,  1.6795e-02, -1.1266e-02]],\n",
            "\n",
            "         [[ 2.3596e-03, -1.5823e-02,  2.9249e-02],\n",
            "          [ 1.0457e-02, -4.2885e-02,  8.9919e-03],\n",
            "          [-3.6428e-02,  7.7527e-03,  1.7469e-03]],\n",
            "\n",
            "         [[ 2.0169e-02,  3.1942e-02,  1.8721e-02],\n",
            "          [-1.0831e-04, -2.5458e-02,  1.9479e-02],\n",
            "          [ 1.2964e-02,  1.0509e-02, -9.6427e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.2384e-02, -6.3586e-03, -1.3209e-02],\n",
            "          [-1.8645e-02,  8.3916e-02, -4.4097e-03],\n",
            "          [ 2.9639e-02, -4.0668e-02,  5.8481e-02]],\n",
            "\n",
            "         [[-2.0278e-02, -2.1836e-02,  1.8848e-02],\n",
            "          [-8.9781e-03,  3.4876e-02,  1.3750e-02],\n",
            "          [-2.5961e-02, -1.6169e-02, -2.4888e-02]],\n",
            "\n",
            "         [[-3.3039e-02,  4.6130e-02,  4.3780e-02],\n",
            "          [-3.4341e-02, -4.1416e-02,  5.0572e-02],\n",
            "          [-3.0957e-02,  1.2935e-02,  5.0544e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.8955e-03,  5.2283e-02,  9.6889e-03],\n",
            "          [-4.1401e-02,  3.0678e-02, -5.4760e-02],\n",
            "          [-1.6569e-02, -6.2065e-02,  1.0390e-02]],\n",
            "\n",
            "         [[ 2.7198e-02, -3.3770e-03, -6.0925e-02],\n",
            "          [-2.4926e-02, -2.9341e-02,  3.4201e-02],\n",
            "          [ 7.3103e-03,  1.6918e-02, -4.8897e-03]],\n",
            "\n",
            "         [[ 2.2746e-02,  1.2726e-02, -2.0500e-02],\n",
            "          [ 2.6479e-02, -1.4396e-02, -4.5620e-02],\n",
            "          [ 2.1156e-02, -2.8190e-02, -6.0389e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.5974e-03, -1.7483e-02,  2.1170e-02],\n",
            "          [-1.9865e-02,  2.4015e-03, -1.4055e-02],\n",
            "          [ 2.2634e-02, -5.5975e-03, -5.3017e-02]],\n",
            "\n",
            "         [[-2.9896e-03,  1.0557e-02, -4.3648e-02],\n",
            "          [-2.0358e-02, -1.9362e-02,  2.2985e-02],\n",
            "          [ 2.4300e-02, -3.6784e-02,  2.8711e-02]],\n",
            "\n",
            "         [[ 3.9814e-03,  4.9516e-02, -1.3803e-02],\n",
            "          [-1.7295e-02, -9.4451e-04, -1.1710e-02],\n",
            "          [-3.0618e-02, -6.8984e-03, -1.7729e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.4645e-04, -3.2639e-02,  1.3958e-02],\n",
            "          [ 1.6663e-02, -2.2657e-02, -1.6561e-02],\n",
            "          [-1.0453e-02,  3.5110e-02, -3.2578e-02]],\n",
            "\n",
            "         [[ 3.8470e-02,  6.1384e-02,  3.5844e-02],\n",
            "          [-6.9464e-02, -4.5882e-02,  4.5096e-03],\n",
            "          [ 2.3437e-02, -3.8390e-02,  5.5922e-03]],\n",
            "\n",
            "         [[ 5.0558e-02, -1.3924e-02, -7.6624e-04],\n",
            "          [-1.5735e-02,  1.2368e-02,  2.7147e-02],\n",
            "          [-2.8863e-02,  5.1858e-03,  1.0920e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2809e-02, -6.5400e-02,  4.4599e-02],\n",
            "          [ 2.0920e-05, -4.8413e-02,  2.7582e-03],\n",
            "          [-4.6351e-03,  1.3641e-02, -5.3387e-03]],\n",
            "\n",
            "         [[-2.8253e-02,  2.4636e-02, -3.9868e-03],\n",
            "          [-8.0828e-02,  2.4227e-02,  8.6514e-03],\n",
            "          [ 3.0857e-02,  4.5290e-02,  1.7436e-02]],\n",
            "\n",
            "         [[-4.3011e-04,  4.6840e-02, -5.4312e-02],\n",
            "          [ 8.6022e-03,  2.9453e-02,  3.4632e-02],\n",
            "          [ 5.2700e-02, -1.8342e-03, -2.8273e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.1772e-02, -5.4551e-03, -9.2161e-03],\n",
            "          [-2.0443e-02, -1.8726e-03,  3.6403e-03],\n",
            "          [ 4.3843e-02,  3.1838e-03, -5.7649e-03]],\n",
            "\n",
            "         [[-3.6738e-02,  4.6784e-02,  3.2155e-02],\n",
            "          [-2.5692e-02, -6.1643e-02,  1.6793e-03],\n",
            "          [-3.0725e-03, -1.2099e-02,  2.7430e-02]],\n",
            "\n",
            "         [[ 2.9235e-02,  1.3182e-02,  2.4880e-02],\n",
            "          [-5.7098e-03, -3.3401e-02, -3.8216e-03],\n",
            "          [ 6.8870e-03, -1.4322e-03,  1.2572e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8746e-02, -2.1251e-02,  6.1485e-02],\n",
            "          [ 2.6274e-02,  1.8936e-02, -2.5374e-02],\n",
            "          [ 2.1400e-02, -2.2893e-02, -3.0970e-02]],\n",
            "\n",
            "         [[ 2.5126e-02,  7.4818e-03,  1.8135e-02],\n",
            "          [ 1.9388e-02, -2.5892e-02, -6.6111e-03],\n",
            "          [-1.9806e-02,  3.0134e-02,  2.7098e-03]],\n",
            "\n",
            "         [[-8.9003e-03, -1.9907e-02,  1.0828e-02],\n",
            "          [-3.6403e-03, -2.9518e-02, -2.1780e-03],\n",
            "          [ 2.3875e-02,  5.5644e-03, -1.6617e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.1596e-02, -3.3346e-02,  2.5571e-02],\n",
            "          [ 5.3378e-02,  3.7133e-02, -1.4288e-02],\n",
            "          [-1.4744e-02, -1.5549e-02,  1.4997e-02]],\n",
            "\n",
            "         [[ 3.3580e-02, -9.2103e-03, -2.9169e-02],\n",
            "          [ 5.4566e-02, -2.1903e-02, -1.9873e-02],\n",
            "          [-2.1819e-02,  8.6555e-03, -4.6210e-02]],\n",
            "\n",
            "         [[ 1.3208e-02,  2.6430e-02, -3.2462e-02],\n",
            "          [-2.9695e-02, -2.4647e-02,  1.5054e-02],\n",
            "          [ 1.7210e-02,  1.0964e-02, -1.2827e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0585e-02,  1.7596e-02, -1.7250e-02],\n",
            "          [-2.4605e-02, -2.0432e-03,  2.4993e-02],\n",
            "          [-9.3948e-03,  2.7483e-02,  2.7766e-02]],\n",
            "\n",
            "         [[-1.0149e-02, -4.6474e-02,  1.2367e-02],\n",
            "          [-2.5644e-03, -9.2982e-04,  4.0561e-02],\n",
            "          [-2.0459e-02,  6.6190e-02,  3.9499e-02]],\n",
            "\n",
            "         [[-8.1328e-03,  5.5038e-02, -1.3614e-02],\n",
            "          [-3.9944e-02,  1.9289e-02, -3.3861e-02],\n",
            "          [-6.4891e-03,  1.4930e-02,  3.1841e-02]]]])), ('module.encoder_k.layer3.2.bn2.weight', tensor([0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9989, 0.9993, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9992,\n",
            "        0.9992, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9992, 0.9992,\n",
            "        0.9992, 0.9992, 0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9990, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9990, 0.9990, 0.9990, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9988, 0.9991, 0.9990,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9992, 0.9990, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990, 0.9992, 0.9992,\n",
            "        0.9990, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990, 0.9990, 0.9989, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9992, 0.9989, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9988, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9989, 0.9989, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992,\n",
            "        0.9991, 0.9992, 0.9991, 0.9989, 0.9990, 0.9990, 0.9993, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9992, 0.9990, 0.9990, 0.9989, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9989, 0.9991, 0.9991, 0.9990,\n",
            "        0.9994, 0.9992, 0.9991, 0.9990, 0.9993, 0.9991, 0.9991, 0.9991, 0.9989,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9989, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9989, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9988, 0.9993, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9994, 0.9990, 0.9990, 0.9990, 0.9992, 0.9993, 0.9991,\n",
            "        0.9992, 0.9992, 0.9990, 0.9993, 0.9990, 0.9991, 0.9991, 0.9991, 0.9988,\n",
            "        0.9988, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9989,\n",
            "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9993, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991])), ('module.encoder_k.layer3.2.bn2.bias', tensor([ 6.6743e-05, -1.6940e-05, -1.9162e-04, -6.2188e-05,  1.0031e-04,\n",
            "        -6.6961e-06, -5.5746e-05,  2.1534e-04, -1.5934e-04, -2.6090e-05,\n",
            "         9.3831e-06, -1.4308e-04,  4.0984e-05, -1.2262e-05, -8.8171e-05,\n",
            "        -1.1540e-05, -1.9670e-04, -9.0664e-05, -3.4516e-05,  6.2739e-05,\n",
            "         8.6384e-05,  1.5677e-04,  1.0764e-04,  2.1283e-04, -1.3311e-04,\n",
            "         3.8466e-05,  7.3667e-05,  3.1642e-06,  9.0959e-05, -4.2866e-05,\n",
            "         2.4291e-05, -1.4810e-05, -5.3853e-05, -6.8821e-05, -9.3186e-05,\n",
            "         4.7537e-05, -3.1612e-05, -2.2926e-05,  3.5094e-05,  1.7020e-04,\n",
            "         1.2794e-04,  9.0882e-05, -3.0920e-05, -8.8735e-05, -3.7491e-07,\n",
            "        -2.7931e-05, -8.0534e-06, -1.2189e-04, -1.4295e-04, -9.0411e-05,\n",
            "        -5.2147e-05, -8.4182e-05,  3.3621e-05,  5.6699e-05, -5.6019e-05,\n",
            "        -1.9732e-04,  6.2392e-05,  5.3861e-05, -3.6730e-05, -9.5702e-05,\n",
            "         3.2535e-05,  6.8463e-05,  1.0686e-05,  1.0046e-04,  4.9289e-05,\n",
            "         3.3463e-05, -5.8991e-06,  2.0289e-04, -2.8115e-06, -1.5349e-05,\n",
            "         2.6127e-05,  7.5094e-05, -1.4114e-04, -6.0744e-05,  4.3557e-05,\n",
            "         1.2558e-04, -1.3844e-05,  6.2729e-05, -1.6831e-04, -1.0638e-04,\n",
            "        -1.0686e-04, -4.0816e-06, -1.4613e-04, -5.4878e-05,  1.6507e-04,\n",
            "         2.3295e-05,  8.7261e-05, -1.5002e-04, -5.3835e-05,  1.0041e-06,\n",
            "        -1.3153e-04, -4.2575e-05, -1.9765e-05,  7.5979e-05, -7.9202e-05,\n",
            "        -1.7870e-04, -1.8630e-05,  1.3356e-04, -6.8298e-05, -1.4687e-04,\n",
            "        -7.6605e-05,  1.1437e-05,  9.1356e-07, -1.7620e-04,  1.7881e-04,\n",
            "        -1.1617e-04,  7.8923e-05,  5.1722e-05,  4.7758e-05,  9.9525e-05,\n",
            "        -1.7532e-04, -1.2801e-04,  9.4165e-05, -9.2225e-06,  3.4385e-05,\n",
            "        -1.1961e-05,  1.0804e-04,  1.3935e-04, -3.3347e-05,  7.4142e-05,\n",
            "        -4.1659e-05, -3.6393e-05, -5.2448e-05,  2.2195e-04,  5.4132e-05,\n",
            "         9.5134e-05, -3.3758e-05, -4.5916e-05, -2.8224e-05, -6.0131e-05,\n",
            "         3.8902e-05, -2.2896e-05, -8.5605e-05,  4.4430e-05, -8.9087e-05,\n",
            "        -1.3050e-05, -7.1897e-05, -1.2473e-05,  2.2989e-05, -1.0497e-04,\n",
            "        -1.0097e-04, -1.4079e-04, -2.6183e-05, -5.5696e-05, -7.2354e-05,\n",
            "        -4.1634e-05, -8.4851e-05,  6.8385e-05, -6.1007e-05, -1.9223e-04,\n",
            "         3.5375e-05, -4.3992e-05, -8.2487e-06,  2.1842e-04,  4.3892e-05,\n",
            "         1.3596e-04, -6.1085e-05,  7.0343e-05, -2.5290e-05, -3.3276e-05,\n",
            "         5.9969e-05, -2.3158e-05,  1.9456e-05,  8.6866e-05,  1.5745e-04,\n",
            "         6.0486e-05,  9.9681e-05, -7.2955e-05,  8.6053e-05, -5.3401e-05,\n",
            "         4.4962e-05,  8.9520e-05, -2.3909e-05, -3.0553e-07, -5.6743e-05,\n",
            "         1.8656e-05,  6.3315e-05, -9.3579e-05,  3.5249e-05,  6.5291e-06,\n",
            "         1.2429e-04, -5.6221e-05,  8.8921e-07, -1.0203e-04,  6.4063e-05,\n",
            "         4.3431e-06,  9.1503e-05,  3.8981e-05,  1.1300e-04, -5.9729e-06,\n",
            "        -8.2851e-05, -6.6924e-05,  2.1499e-05, -1.5208e-04, -3.6545e-05,\n",
            "        -1.0108e-04,  2.3429e-05,  3.8354e-05, -5.3448e-05,  4.4272e-05,\n",
            "         4.6204e-05, -2.9471e-05,  9.8211e-05, -1.9365e-04, -1.6715e-05,\n",
            "        -8.3623e-05,  8.1641e-05, -2.2507e-04,  1.2495e-05,  2.4151e-04,\n",
            "         5.4292e-05,  7.5402e-07, -2.6720e-05,  1.6206e-04,  1.9033e-04,\n",
            "         1.0615e-05,  1.3910e-04,  1.3102e-04, -1.3666e-04,  2.1355e-04,\n",
            "        -2.9633e-04, -9.5486e-05,  6.4133e-05, -5.4995e-05,  6.9960e-06,\n",
            "        -1.6915e-04,  1.1261e-04,  6.4413e-05, -3.3591e-05, -3.5422e-06,\n",
            "         6.0075e-05,  4.6730e-05,  4.8018e-05,  1.5571e-05,  5.5816e-05,\n",
            "        -3.4056e-05, -1.6186e-05, -5.2927e-05,  3.4874e-05,  7.0043e-05,\n",
            "        -3.7890e-05,  1.3296e-05, -1.6847e-04, -1.2456e-04,  6.0600e-05,\n",
            "         1.6837e-05, -4.3165e-05, -2.0945e-05,  1.0460e-04,  2.5437e-05,\n",
            "        -6.4068e-05,  6.2604e-05,  2.1536e-05, -1.5020e-05, -1.2383e-06,\n",
            "         8.4702e-07])), ('module.encoder_k.layer3.2.bn2.running_mean', tensor([-0.4396, -0.3835, -0.4247,  0.4210, -0.5425,  0.2171,  0.2317,  0.4233,\n",
            "        -0.0059, -0.0261,  0.2544, -0.2759, -0.6547, -0.3632,  0.3394, -0.3572,\n",
            "        -0.6633,  0.0193, -0.2045, -0.4783, -0.8026, -0.8389,  0.0043,  0.4445,\n",
            "         0.5313,  0.1917, -0.5312,  0.5516, -0.1496, -0.1567,  0.2181, -0.1920,\n",
            "         0.6631, -1.1395,  0.3652, -0.0120, -0.8714,  0.7092,  0.2739, -0.1987,\n",
            "         0.3816,  0.2450, -1.0711,  0.3775, -0.5959, -0.4404, -0.5144,  0.0412,\n",
            "         0.1031, -0.1902,  0.0263, -0.2817,  0.3409,  0.7114,  0.0550,  0.4635,\n",
            "         0.1649,  0.0887, -0.1776,  0.1533,  0.4549, -0.0494,  0.0785,  0.1895,\n",
            "         0.1131,  0.3051,  0.3385, -0.0923,  0.3360,  0.0677,  0.6871,  0.3457,\n",
            "         0.9213, -0.0638, -0.6646, -0.2100,  0.1662,  0.3930, -0.3436, -0.6645,\n",
            "        -0.2573, -0.3662,  0.1786, -0.4208,  0.0121,  0.2547, -0.0700,  0.8632,\n",
            "         0.0669, -0.1843, -0.3718, -0.3542,  0.1630, -0.3170, -0.1726,  0.2119,\n",
            "        -0.4782, -0.1081,  0.0952, -0.4969, -0.2974, -0.1792,  0.6159, -0.5916,\n",
            "         0.3837,  0.3974,  0.0804, -0.2205,  0.1011, -0.0615,  0.3051,  0.2873,\n",
            "        -0.0346,  0.1868, -0.3052,  1.2367, -0.0404,  0.0098,  0.4057, -0.7016,\n",
            "         0.4158, -0.0445, -0.4325,  0.1951, -0.3515, -0.0473, -0.0988,  0.4324,\n",
            "         0.0710, -0.3198, -0.2239, -0.0131, -0.2704,  0.4979,  0.0408,  0.0877,\n",
            "         0.1423,  0.2603,  0.4686, -0.3381,  0.0674, -0.0301,  0.4039, -0.6147,\n",
            "        -1.0779,  0.1522, -0.2794,  0.1187,  0.7235, -0.3282, -0.2886, -0.4917,\n",
            "         0.3165, -0.1281, -0.1048, -0.1041, -0.1641,  0.8725,  0.2374,  0.1613,\n",
            "        -0.3465,  0.0697, -0.3053,  0.7257, -0.8088,  0.6187, -0.4105,  0.3737,\n",
            "        -0.2735, -0.0169,  0.2115, -0.6716,  0.4100,  0.2249,  0.1572,  0.3993,\n",
            "         0.0623,  0.4457,  0.4474, -0.2466, -0.1229, -0.2079, -0.8918, -0.0678,\n",
            "         0.6475,  0.5548,  0.3285, -0.5518, -0.1397, -0.0399,  0.0152, -0.0648,\n",
            "         0.3461, -0.5566, -0.7869,  0.2133,  0.3721, -0.1501, -0.7088,  0.1302,\n",
            "         0.2245, -0.5678, -0.4490, -0.4644,  0.2343, -0.0883, -0.9720,  0.3719,\n",
            "        -0.0162, -0.2082, -0.0924,  0.1129,  0.1923,  0.0538, -0.7562,  0.0752,\n",
            "         0.1274,  0.1392,  0.4053,  0.8636, -0.2807, -0.5297, -0.0141,  0.4325,\n",
            "         0.4478,  0.2196,  0.4864,  0.4004, -0.0349, -0.2351, -0.0499, -0.3915,\n",
            "        -0.3242,  0.4110, -0.2066, -0.1656, -0.0876, -1.8733, -0.6604,  0.1267,\n",
            "         0.6329, -0.5159,  0.0614, -0.5872,  0.0283,  0.4457, -0.4854, -0.0093,\n",
            "        -0.2226,  0.2136, -0.3137, -0.1010, -0.2592,  0.4178,  0.7195, -0.0701])), ('module.encoder_k.layer3.2.bn2.running_var', tensor([0.7522, 1.2620, 0.5421, 0.6027, 0.6924, 0.5894, 0.7349, 0.9987, 0.8594,\n",
            "        0.7495, 0.6219, 0.6722, 1.0455, 0.5988, 1.1441, 0.7948, 0.5864, 0.5522,\n",
            "        0.7030, 0.6442, 1.0691, 0.6551, 0.6231, 0.5955, 0.5824, 0.5642, 0.6699,\n",
            "        1.0164, 0.5473, 0.8436, 0.7688, 0.6227, 0.7605, 1.1455, 0.5337, 0.8286,\n",
            "        0.9216, 0.8264, 0.7029, 0.5969, 0.8179, 0.6459, 0.7590, 0.6301, 0.5490,\n",
            "        0.5335, 0.7010, 0.7259, 0.6254, 0.6164, 0.5577, 0.6534, 0.7096, 0.6358,\n",
            "        0.8180, 0.6243, 0.5977, 0.5938, 0.5496, 0.6670, 0.5731, 0.5803, 0.5481,\n",
            "        0.6325, 0.5689, 0.6527, 0.6230, 0.6504, 0.6740, 1.0818, 0.7295, 0.5415,\n",
            "        0.9496, 0.5296, 0.9037, 0.7240, 0.6583, 0.7381, 0.7390, 0.7184, 0.6105,\n",
            "        0.5570, 0.8353, 1.1832, 0.6269, 0.5344, 0.6551, 0.5716, 0.5429, 0.6207,\n",
            "        0.5918, 0.6835, 0.6025, 1.0852, 0.5791, 0.6360, 0.6187, 0.6477, 0.5852,\n",
            "        0.6823, 1.2390, 0.6046, 1.0097, 0.9652, 0.8277, 0.7975, 0.5989, 0.6434,\n",
            "        0.5819, 1.4415, 0.8152, 0.5783, 0.8819, 0.6102, 1.1242, 1.3005, 0.5174,\n",
            "        0.5537, 0.5670, 0.6361, 0.7248, 0.6170, 0.6983, 0.6837, 0.5937, 0.6574,\n",
            "        0.5859, 0.6460, 0.6449, 0.6856, 0.5470, 0.6497, 0.6786, 0.6890, 0.8852,\n",
            "        0.5644, 1.0156, 0.7479, 0.7074, 0.7467, 0.7005, 0.6289, 0.8199, 0.6421,\n",
            "        0.7659, 0.8204, 0.6145, 0.7162, 0.7069, 0.5391, 0.6672, 1.0177, 0.6504,\n",
            "        0.5750, 0.6470, 0.7106, 0.6714, 0.6361, 0.6174, 0.7738, 0.5700, 0.5614,\n",
            "        1.1489, 0.7040, 0.8492, 0.7663, 0.8361, 0.6347, 0.6130, 0.6079, 0.5480,\n",
            "        0.7221, 1.1620, 0.6835, 0.5309, 0.8707, 0.6192, 0.5693, 1.3874, 0.7532,\n",
            "        0.8109, 0.5767, 0.8856, 0.6033, 0.5473, 1.0464, 0.6540, 0.9680, 0.5433,\n",
            "        0.7882, 0.8956, 0.5580, 0.6022, 0.5983, 0.6459, 0.6838, 0.5947, 0.6191,\n",
            "        1.2425, 0.5513, 0.5734, 1.0300, 0.8843, 0.6848, 0.5272, 0.5965, 0.7304,\n",
            "        0.5006, 0.6785, 0.7603, 0.6223, 0.7407, 0.6801, 0.7318, 0.8130, 1.2558,\n",
            "        0.5379, 0.7572, 0.6216, 0.6429, 0.7392, 0.8269, 0.7270, 0.6941, 0.7102,\n",
            "        0.5873, 0.9619, 0.5550, 0.6368, 1.2630, 0.6094, 0.5497, 0.5947, 0.6876,\n",
            "        0.7770, 0.5172, 0.5648, 1.3350, 0.5435, 0.7251, 0.7106, 0.5883, 0.6357,\n",
            "        0.8032, 0.6019, 0.7491, 0.7672, 0.5214, 0.5287, 0.6461, 0.5870, 0.7708,\n",
            "        0.5481, 0.6006, 0.9083, 0.9069])), ('module.encoder_k.layer3.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.2.conv3.weight', tensor([[[[ 0.0515]],\n",
            "\n",
            "         [[-0.0200]],\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0222]],\n",
            "\n",
            "         [[ 0.0430]],\n",
            "\n",
            "         [[ 0.0099]]],\n",
            "\n",
            "\n",
            "        [[[-0.0782]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[ 0.0302]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0042]],\n",
            "\n",
            "         [[ 0.0372]],\n",
            "\n",
            "         [[ 0.0466]]],\n",
            "\n",
            "\n",
            "        [[[-0.0352]],\n",
            "\n",
            "         [[ 0.0211]],\n",
            "\n",
            "         [[-0.0058]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0332]],\n",
            "\n",
            "         [[-0.0149]],\n",
            "\n",
            "         [[ 0.0523]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0211]],\n",
            "\n",
            "         [[-0.0843]],\n",
            "\n",
            "         [[-0.0278]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0369]],\n",
            "\n",
            "         [[ 0.0558]],\n",
            "\n",
            "         [[-0.0402]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0410]],\n",
            "\n",
            "         [[ 0.0349]],\n",
            "\n",
            "         [[ 0.0054]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0032]],\n",
            "\n",
            "         [[-0.0236]],\n",
            "\n",
            "         [[ 0.0796]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0079]],\n",
            "\n",
            "         [[-0.0112]],\n",
            "\n",
            "         [[-0.0208]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0411]],\n",
            "\n",
            "         [[ 0.0222]],\n",
            "\n",
            "         [[-0.0235]]]])), ('module.encoder_k.layer3.2.bn3.weight', tensor([0.9990, 0.9990, 0.9991,  ..., 0.9991, 0.9990, 0.9990])), ('module.encoder_k.layer3.2.bn3.bias', tensor([-6.2041e-05,  3.6278e-05,  1.8190e-06,  ..., -1.5354e-05,\n",
            "        -6.5536e-05, -3.5848e-05])), ('module.encoder_k.layer3.2.bn3.running_mean', tensor([-0.0281, -0.1030, -0.4047,  ..., -0.6361,  0.2112, -0.2805])), ('module.encoder_k.layer3.2.bn3.running_var', tensor([0.1672, 0.1618, 0.1544,  ..., 0.2396, 0.1295, 0.1709])), ('module.encoder_k.layer3.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.3.conv1.weight', tensor([[[[ 0.1275]],\n",
            "\n",
            "         [[-0.0309]],\n",
            "\n",
            "         [[-0.0222]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1514]],\n",
            "\n",
            "         [[-0.0581]],\n",
            "\n",
            "         [[-0.0083]]],\n",
            "\n",
            "\n",
            "        [[[-0.0562]],\n",
            "\n",
            "         [[ 0.0848]],\n",
            "\n",
            "         [[ 0.0411]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0691]],\n",
            "\n",
            "         [[ 0.0076]],\n",
            "\n",
            "         [[-0.0756]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0159]],\n",
            "\n",
            "         [[ 0.1286]],\n",
            "\n",
            "         [[-0.1332]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0706]],\n",
            "\n",
            "         [[-0.1348]],\n",
            "\n",
            "         [[ 0.0802]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0178]],\n",
            "\n",
            "         [[ 0.0259]],\n",
            "\n",
            "         [[ 0.1168]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0780]],\n",
            "\n",
            "         [[-0.0530]],\n",
            "\n",
            "         [[-0.0363]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0645]],\n",
            "\n",
            "         [[ 0.0967]],\n",
            "\n",
            "         [[ 0.1431]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1013]],\n",
            "\n",
            "         [[ 0.0593]],\n",
            "\n",
            "         [[-0.0442]]],\n",
            "\n",
            "\n",
            "        [[[-0.0733]],\n",
            "\n",
            "         [[ 0.1760]],\n",
            "\n",
            "         [[ 0.0777]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0767]],\n",
            "\n",
            "         [[-0.1242]],\n",
            "\n",
            "         [[-0.0485]]]])), ('module.encoder_k.layer3.3.bn1.weight', tensor([0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9989,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9992, 0.9991, 0.9992, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9992, 0.9989, 0.9991,\n",
            "        0.9992, 0.9990, 0.9989, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9989, 0.9992, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9988, 0.9992, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9992, 0.9990, 0.9991, 0.9989,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9990,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9990, 0.9993,\n",
            "        0.9990, 0.9993, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9989, 0.9990, 0.9991, 0.9990, 0.9990, 0.9993, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9989, 0.9990, 0.9991, 0.9992, 0.9990, 0.9989,\n",
            "        0.9991, 0.9991, 0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9989, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9993, 0.9993, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9992, 0.9991, 0.9992, 0.9989,\n",
            "        0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9988, 0.9989, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9989, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9993, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9992, 0.9992, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9989, 0.9991,\n",
            "        0.9989, 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.3.bn1.bias', tensor([ 9.2280e-05, -2.2163e-05, -6.7976e-05,  8.8972e-05,  4.0824e-05,\n",
            "         1.5742e-05,  9.9970e-05,  1.2462e-04,  8.3983e-05, -4.2739e-05,\n",
            "        -1.0739e-04, -6.3935e-05,  2.7353e-05, -9.5661e-05, -1.6008e-04,\n",
            "         3.3436e-05,  1.2655e-05, -1.5212e-04,  1.9742e-05,  1.6625e-04,\n",
            "        -9.1015e-05,  4.0932e-05,  8.1732e-06, -6.8742e-05, -7.9329e-07,\n",
            "        -8.1631e-05, -3.5312e-05,  1.6941e-05,  9.5883e-05, -5.3963e-05,\n",
            "        -6.2105e-05,  1.8305e-05, -4.3833e-06,  7.1347e-05,  1.1957e-04,\n",
            "        -2.2517e-06,  4.4888e-05,  1.1145e-04, -7.6934e-05,  9.3791e-05,\n",
            "         7.2686e-05, -6.9213e-05, -9.1380e-05, -5.4344e-05, -2.1146e-05,\n",
            "         4.1651e-05, -1.2708e-04, -4.3631e-05,  7.4295e-05, -5.5189e-05,\n",
            "        -7.4293e-05,  9.4552e-05,  8.3631e-06,  5.9040e-05,  6.6697e-05,\n",
            "        -1.7010e-04,  1.2784e-04,  3.7866e-05,  9.6730e-06, -4.3257e-06,\n",
            "         2.6428e-05, -3.8965e-05, -5.0539e-05,  1.0022e-04,  3.6942e-05,\n",
            "         7.7468e-05, -2.2469e-06, -4.1397e-05,  4.8921e-05, -6.9451e-05,\n",
            "         7.6723e-05, -3.3744e-06, -5.1068e-05, -1.1908e-04, -2.2672e-05,\n",
            "         1.3147e-04, -1.2964e-04,  2.2594e-05, -4.8126e-05,  1.2084e-04,\n",
            "        -3.0551e-05, -4.3159e-06,  1.5252e-04,  8.7109e-07, -8.9285e-05,\n",
            "        -8.5623e-05,  8.1249e-05, -1.4931e-04,  3.9152e-06, -2.4534e-06,\n",
            "         4.6400e-05, -1.3190e-04,  9.6766e-05,  7.9198e-05, -7.1179e-05,\n",
            "        -3.3597e-05, -4.3736e-05, -6.6491e-05, -1.1875e-04, -9.5859e-05,\n",
            "         1.9180e-05,  1.1188e-05, -6.5965e-05, -1.1467e-05,  1.5695e-04,\n",
            "        -5.9025e-05,  4.0454e-05, -1.8748e-04, -1.4203e-05,  2.1620e-05,\n",
            "        -8.4972e-05, -2.0755e-05,  1.1657e-04,  6.6374e-05, -9.3063e-05,\n",
            "        -1.5381e-04,  1.4523e-04, -4.7265e-05,  1.3127e-04, -3.7427e-05,\n",
            "        -8.4004e-06, -2.7719e-05, -8.5536e-07, -1.4943e-04, -1.7340e-05,\n",
            "         5.5399e-05, -8.6729e-05, -2.0703e-05, -1.0301e-04, -1.2461e-04,\n",
            "        -2.6175e-05,  5.2372e-05, -2.4610e-06,  4.1565e-05, -1.0094e-05,\n",
            "        -1.3522e-04, -8.4234e-05,  1.3364e-04, -5.6307e-05, -3.5299e-05,\n",
            "         9.4806e-05, -1.2987e-04, -9.1732e-05, -2.0297e-05, -1.5566e-04,\n",
            "        -1.2289e-04,  3.3886e-05, -6.5225e-05,  1.2069e-04,  1.4797e-04,\n",
            "         5.4506e-05,  3.6727e-05,  5.2272e-05,  1.1870e-04, -4.0830e-05,\n",
            "         2.4789e-05, -2.3753e-04, -2.3430e-05,  3.7992e-05,  1.7135e-04,\n",
            "         5.0032e-06, -3.8474e-05,  8.2521e-05,  3.1970e-05,  1.5130e-04,\n",
            "         6.2259e-05,  2.0100e-04,  5.8739e-05, -8.6803e-05,  2.0194e-05,\n",
            "         1.2383e-04,  4.6767e-05, -2.6979e-05,  1.1479e-04, -5.2851e-05,\n",
            "        -7.0103e-05, -1.4916e-05,  1.1924e-04,  2.4338e-05,  9.5926e-05,\n",
            "         5.8169e-05,  2.2485e-04,  4.2891e-05, -4.7874e-06, -1.5148e-04,\n",
            "         5.7561e-05, -1.3496e-04, -3.3885e-05,  7.4096e-06,  1.8003e-04,\n",
            "         9.0148e-05, -6.2779e-05,  1.4670e-04, -1.3933e-04,  7.4404e-05,\n",
            "        -1.5891e-05,  1.1782e-04, -2.3411e-04, -1.2236e-04,  4.5082e-05,\n",
            "        -4.0645e-05, -1.5112e-05,  1.0994e-05, -2.6769e-04, -2.0478e-04,\n",
            "         4.5295e-05, -6.9095e-06, -1.0013e-05, -3.1709e-05,  3.1221e-05,\n",
            "         8.8083e-05,  9.5391e-06,  3.2417e-05,  6.3137e-05, -5.3282e-05,\n",
            "        -6.5328e-05, -5.6878e-05, -1.8382e-04,  2.7890e-05, -9.9368e-05,\n",
            "         2.2646e-05,  3.4119e-05, -8.4591e-05,  1.3004e-04,  4.1938e-05,\n",
            "        -8.1761e-07,  7.2026e-05, -2.5037e-05, -1.2081e-05,  8.9014e-05,\n",
            "         2.4914e-05,  1.0604e-04, -6.3924e-05, -2.5845e-05,  2.2448e-05,\n",
            "        -1.0939e-04, -3.7765e-05,  8.4386e-05,  1.1188e-05, -1.9935e-05,\n",
            "        -8.7258e-05,  1.2749e-04,  4.0202e-05, -1.7243e-06, -1.5811e-05,\n",
            "        -3.3792e-05,  3.2369e-05,  5.2899e-05,  8.2248e-05,  7.0643e-05,\n",
            "        -2.6516e-05,  7.0811e-05, -1.8609e-04, -6.4006e-05,  1.1535e-04,\n",
            "         7.4907e-06])), ('module.encoder_k.layer3.3.bn1.running_mean', tensor([-4.3131e-01,  4.5063e+00, -2.6934e-01, -1.2385e+00,  3.2744e+00,\n",
            "        -2.1043e-02, -1.0996e+00, -7.7663e-01,  2.2535e+00,  2.9987e+00,\n",
            "        -9.9005e-01,  2.7212e+00,  4.0877e+00, -1.0367e+00, -4.3380e-01,\n",
            "         3.7640e+00,  1.1415e+00,  2.4374e+00, -6.6966e-01, -2.9741e+00,\n",
            "         2.6080e+00, -3.2117e+00, -4.7512e-01,  3.8014e+00, -3.3936e+00,\n",
            "         1.8987e+00,  9.2017e-01,  1.5063e+00,  7.9363e-01, -1.2280e-01,\n",
            "        -3.2142e-01, -5.6806e-01,  2.8288e+00,  1.4241e+00,  4.7977e-01,\n",
            "        -9.7376e-01,  3.4866e+00, -1.9438e-01,  2.6614e+00, -1.6493e+00,\n",
            "         3.6334e-01, -3.7438e+00,  2.2384e+00,  4.2650e+00, -1.0451e+00,\n",
            "        -3.6643e+00, -1.3069e+00,  1.8167e+00, -6.7041e+00, -6.9529e-01,\n",
            "        -9.7380e-02, -3.5834e+00, -1.7784e+00,  4.2461e+00,  2.0602e+00,\n",
            "         2.3153e+00,  2.4794e+00,  7.0330e-01, -3.7247e+00, -4.9330e+00,\n",
            "        -2.5473e+00,  1.5749e+00,  1.9707e-01, -3.8676e+00, -1.0663e+00,\n",
            "         1.7521e-01, -2.1082e+00, -9.4834e-01, -5.8302e-01,  8.3921e-01,\n",
            "         1.2780e+00,  9.5862e-01,  9.5335e-01, -7.2012e-01,  1.6617e+00,\n",
            "         2.5504e+00, -2.7232e+00, -1.6937e+00,  5.5601e+00,  3.4438e+00,\n",
            "         4.6677e+00, -2.4570e-01, -1.0438e+00, -2.6474e+00, -2.7410e+00,\n",
            "        -7.5460e-01, -3.8097e+00, -4.2400e+00, -4.2778e-01,  6.0590e-02,\n",
            "        -4.2870e+00, -2.4710e+00, -6.5013e+00,  4.4517e-01, -5.1775e-01,\n",
            "        -1.7293e-01, -5.5077e+00,  1.3165e+00, -3.3049e+00,  2.3591e+00,\n",
            "        -1.9814e+00, -4.6902e-01,  6.8284e-01,  1.8986e+00, -1.7906e+00,\n",
            "        -4.8900e+00, -2.8613e+00, -9.1898e-01,  3.8522e-02,  9.1143e-02,\n",
            "         2.7241e+00, -1.5549e+00, -3.1137e+00,  4.2711e-01,  1.7790e+00,\n",
            "        -4.7906e-01,  3.6000e-01,  2.3615e+00, -2.0704e+00,  3.4374e+00,\n",
            "        -9.4926e-01, -9.2067e-01,  3.2190e+00, -1.3926e+00, -3.6357e+00,\n",
            "         1.2726e+00,  9.4233e-01, -2.7725e+00, -3.2559e-01,  2.1031e+00,\n",
            "        -2.4438e+00,  2.1543e+00,  2.3354e+00,  2.0416e+00, -9.1689e-01,\n",
            "        -1.1751e+00, -2.3275e+00,  1.6800e+00,  2.0268e+00,  1.0800e+00,\n",
            "        -2.2269e-01,  1.4335e+00, -7.5185e-01,  1.8670e+00, -4.8824e-01,\n",
            "        -2.5740e+00, -5.3484e+00, -3.0475e+00,  1.2565e+00,  1.3698e+00,\n",
            "         6.6365e-01,  3.7982e+00, -4.2220e+00,  1.1495e-01, -6.0820e-01,\n",
            "         1.9350e+00, -1.6301e+00,  2.1822e+00, -2.7139e+00, -2.0473e-01,\n",
            "        -1.7170e+00, -4.0479e-01,  2.0159e-01,  1.9959e+00,  4.2509e+00,\n",
            "        -2.1754e+00, -1.2524e+00, -1.9565e+00,  6.7385e-03,  9.5872e-01,\n",
            "        -3.5172e+00,  9.5092e-02, -3.4717e+00,  7.3374e-02, -1.9908e+00,\n",
            "         2.6080e+00, -6.6908e-01, -2.6018e-02, -7.6982e+00,  5.3794e+00,\n",
            "         1.2866e+00,  1.8827e+00, -2.3833e+00,  1.0462e+00, -3.2955e-01,\n",
            "        -3.4522e+00,  5.3528e-01, -1.5995e+00, -7.3193e-01, -1.4913e+00,\n",
            "        -1.5424e+00, -2.3755e-01,  3.4610e+00, -8.8862e-02,  6.3070e+00,\n",
            "        -2.6693e+00,  3.9525e-01, -1.0481e+00,  2.4713e+00, -1.5861e+00,\n",
            "        -2.1510e+00, -5.7819e+00, -2.2162e+00, -7.2489e-01,  8.1638e-01,\n",
            "         1.7240e+00, -1.1670e+00,  1.3375e+00,  2.4534e+00, -2.2171e+00,\n",
            "        -6.5089e+00,  1.0483e+00, -4.1819e+00,  2.1766e+00,  1.8566e-02,\n",
            "        -6.9272e+00, -2.4295e+00, -2.9327e+00, -3.2750e+00,  1.4895e+00,\n",
            "         8.9283e+00, -1.2597e+00, -4.1447e+00, -2.8403e-01, -1.0228e+00,\n",
            "        -5.5290e-01, -1.9946e+00,  1.1867e+00,  7.2384e+00, -1.0929e-02,\n",
            "        -1.0128e+00, -5.2974e+00, -6.9526e-01,  2.0871e+00, -3.6178e+00,\n",
            "         3.1294e+00, -2.2090e+00, -2.5225e+00, -2.7824e+00,  3.7045e+00,\n",
            "         3.3182e+00, -2.9327e+00, -4.7186e+00, -9.2106e-01,  8.6847e-01,\n",
            "         1.2629e-01,  2.6031e+00, -3.3971e+00,  1.9836e+00,  1.1949e+00,\n",
            "         2.3291e+00, -6.0893e-02,  2.5276e+00,  2.7760e+00,  2.7094e+00,\n",
            "         2.9467e+00])), ('module.encoder_k.layer3.3.bn1.running_var', tensor([12.5026, 21.6655, 12.9029, 10.9018,  9.9611,  9.3983,  8.5086, 11.2740,\n",
            "        11.2007, 11.4244,  9.4238, 13.9496, 11.9377, 11.1383,  8.9345, 11.4787,\n",
            "        17.8886, 10.2318,  8.6396, 17.0177, 12.1647, 19.9969, 14.9506,  9.1551,\n",
            "        17.4644,  9.7689,  9.4958, 11.6400, 17.2497, 10.9184, 10.0240, 11.5739,\n",
            "         8.9058, 19.7128, 15.1091,  9.3918, 11.3041,  9.6220, 12.2092, 12.1497,\n",
            "        11.8225, 11.4830,  9.6505, 10.6396,  8.8384, 16.5008,  9.6434, 11.0298,\n",
            "        20.7496,  9.3094, 11.7642, 11.0677,  9.2970, 15.8911, 11.2272,  9.0930,\n",
            "        13.8388, 14.4258, 10.6347, 12.6598,  9.2618, 10.6848, 10.8381, 22.0817,\n",
            "         9.2798,  9.5286, 11.1838,  8.3517, 10.1207, 10.0919, 12.6820, 14.9907,\n",
            "        11.1795, 13.6741,  7.5518, 14.2485, 27.5353, 10.0087, 15.3785, 25.0120,\n",
            "         9.0112,  8.6145, 13.7734, 17.7279, 11.8849,  9.6482, 13.8569,  7.6188,\n",
            "        14.0608, 11.5233, 14.9257,  9.2688, 26.6237,  9.7200,  9.8652,  9.3825,\n",
            "        20.1480, 10.3627, 12.6749, 11.9381,  8.7102,  9.2713,  8.0833,  8.8119,\n",
            "         9.9482, 11.8834, 11.1319,  9.5599,  8.6126, 11.0993, 11.0463,  9.4373,\n",
            "        15.9045, 12.1721,  9.9465, 13.1856, 10.6034,  9.5163,  8.3981, 14.5983,\n",
            "        10.0624,  9.1722, 15.5207,  9.9090, 17.6198,  9.5070,  9.4066,  8.8789,\n",
            "        12.6450, 16.4730, 16.4921, 11.3392, 12.2189, 10.6312, 15.6950, 12.0253,\n",
            "        14.3174, 14.5081, 10.3876, 10.3767, 19.3363, 15.7676, 11.4880,  8.2651,\n",
            "         9.5746, 11.3411, 28.0123, 13.0282, 10.0237,  9.4999, 22.6945, 17.4445,\n",
            "        19.5270, 11.2126, 11.2068,  8.7867, 10.0620,  9.5189, 18.9124, 14.6374,\n",
            "        11.4612,  9.6911,  9.6551, 10.8698, 15.7762,  9.5912, 17.0316,  9.4671,\n",
            "        10.0282, 14.3724, 16.6689,  8.8632, 10.0949,  9.2311,  9.2562, 10.9825,\n",
            "         9.2614, 16.0961, 31.6694, 25.6741, 10.4377, 10.1599, 17.4675,  9.1854,\n",
            "         9.4690, 20.8308, 10.7101, 10.3758, 10.4188, 11.5697,  9.5455,  9.7117,\n",
            "        16.6904, 13.7810, 16.9621, 30.1625, 13.0626, 11.9311,  9.7738,  9.2604,\n",
            "         9.2370, 29.0745, 15.2294, 10.0698, 10.3059, 12.0612,  9.8777, 10.5180,\n",
            "         9.0140, 14.5041, 53.5739, 10.4937, 18.4043,  9.7850,  8.1843, 23.5650,\n",
            "         9.2487, 13.6295,  9.3875,  9.5710, 28.9841, 13.0515, 16.7264,  8.2900,\n",
            "         8.8343,  8.6771, 14.1632, 11.5083, 24.7287, 13.8963, 10.1927, 10.8264,\n",
            "        11.0743,  8.4468, 12.6287, 10.7136,  8.9601, 14.4755, 11.1792, 17.5861,\n",
            "        13.5094,  9.7298, 17.5558, 10.1631,  9.9744,  9.5735,  9.8331, 12.0127,\n",
            "        10.3236,  8.3703, 13.8163,  8.9519, 14.7083,  9.0789, 11.5035,  8.4626])), ('module.encoder_k.layer3.3.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.3.conv2.weight', tensor([[[[-0.0047, -0.0132, -0.0165],\n",
            "          [ 0.0268, -0.0158,  0.0004],\n",
            "          [ 0.0352,  0.0311, -0.0098]],\n",
            "\n",
            "         [[ 0.0200,  0.0603,  0.0573],\n",
            "          [ 0.0187,  0.0086, -0.0330],\n",
            "          [ 0.0346,  0.0211, -0.0490]],\n",
            "\n",
            "         [[ 0.0116,  0.0430,  0.0038],\n",
            "          [-0.0024, -0.0285, -0.0336],\n",
            "          [ 0.0138,  0.0286,  0.0260]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0216, -0.0557, -0.0182],\n",
            "          [-0.0200, -0.0134,  0.0243],\n",
            "          [ 0.0224, -0.0333,  0.0091]],\n",
            "\n",
            "         [[-0.0451,  0.0259,  0.0474],\n",
            "          [-0.0800, -0.0159, -0.0105],\n",
            "          [-0.0491,  0.0262,  0.0110]],\n",
            "\n",
            "         [[ 0.0302,  0.0305, -0.0651],\n",
            "          [-0.0503, -0.0918,  0.0216],\n",
            "          [-0.0118, -0.0284,  0.0077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0527,  0.0130, -0.0189],\n",
            "          [-0.0314,  0.0863,  0.0088],\n",
            "          [ 0.0395, -0.0143, -0.0036]],\n",
            "\n",
            "         [[ 0.0195,  0.0060, -0.0217],\n",
            "          [-0.0131, -0.0056,  0.0113],\n",
            "          [-0.0652, -0.0574, -0.0181]],\n",
            "\n",
            "         [[ 0.0068, -0.0386,  0.0331],\n",
            "          [-0.0288,  0.0131, -0.0339],\n",
            "          [ 0.0232, -0.0384, -0.0236]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0254,  0.0290, -0.0223],\n",
            "          [-0.0036,  0.0019, -0.0156],\n",
            "          [ 0.0014, -0.0382,  0.0022]],\n",
            "\n",
            "         [[ 0.0249, -0.0041, -0.0048],\n",
            "          [-0.0142, -0.0466, -0.0113],\n",
            "          [-0.0080,  0.0006, -0.0238]],\n",
            "\n",
            "         [[ 0.0462,  0.0283, -0.0561],\n",
            "          [-0.0315,  0.0186,  0.0024],\n",
            "          [ 0.0463,  0.0467, -0.0130]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0473,  0.0496, -0.0067],\n",
            "          [-0.0585, -0.0129, -0.0053],\n",
            "          [ 0.0102,  0.0009,  0.0022]],\n",
            "\n",
            "         [[ 0.0015,  0.0008,  0.0161],\n",
            "          [-0.0059,  0.0039,  0.0103],\n",
            "          [ 0.0170,  0.0075, -0.0406]],\n",
            "\n",
            "         [[-0.0306, -0.0067, -0.0223],\n",
            "          [ 0.0121,  0.0097,  0.0081],\n",
            "          [-0.0378,  0.0287, -0.0365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0105,  0.0541, -0.0402],\n",
            "          [ 0.0165,  0.0128, -0.0475],\n",
            "          [ 0.0028, -0.0448,  0.0162]],\n",
            "\n",
            "         [[ 0.0099, -0.0115, -0.0313],\n",
            "          [ 0.0094, -0.0375,  0.0316],\n",
            "          [-0.0519,  0.0497,  0.0794]],\n",
            "\n",
            "         [[-0.0175,  0.0361, -0.0051],\n",
            "          [-0.0070,  0.0154,  0.0373],\n",
            "          [ 0.0205,  0.0181,  0.0754]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0013,  0.0564,  0.0256],\n",
            "          [-0.0074, -0.0110,  0.0102],\n",
            "          [-0.0147, -0.0044, -0.0365]],\n",
            "\n",
            "         [[ 0.0290, -0.0019, -0.0214],\n",
            "          [ 0.0035,  0.0015, -0.0114],\n",
            "          [-0.0459, -0.0028,  0.0109]],\n",
            "\n",
            "         [[ 0.0647, -0.0553, -0.0105],\n",
            "          [ 0.0198,  0.0404,  0.0250],\n",
            "          [-0.0088, -0.0707,  0.0248]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0380, -0.0242,  0.0268],\n",
            "          [-0.0227,  0.0380,  0.0409],\n",
            "          [-0.0189,  0.0315, -0.0129]],\n",
            "\n",
            "         [[ 0.0291,  0.0557, -0.0204],\n",
            "          [ 0.0576,  0.0062,  0.0168],\n",
            "          [-0.0029, -0.0443,  0.0213]],\n",
            "\n",
            "         [[-0.0342,  0.0091,  0.0079],\n",
            "          [ 0.0124,  0.0129, -0.0567],\n",
            "          [ 0.0235, -0.0444,  0.0078]]],\n",
            "\n",
            "\n",
            "        [[[-0.0352, -0.0134,  0.0166],\n",
            "          [-0.0146, -0.0486, -0.0553],\n",
            "          [-0.0518, -0.0225, -0.0376]],\n",
            "\n",
            "         [[ 0.0450,  0.0341,  0.0368],\n",
            "          [-0.0085, -0.0324, -0.0586],\n",
            "          [-0.0117, -0.0020, -0.0066]],\n",
            "\n",
            "         [[ 0.0029,  0.0379, -0.0322],\n",
            "          [-0.0777, -0.0102, -0.0434],\n",
            "          [-0.0739, -0.0194,  0.0525]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0738,  0.0242, -0.0229],\n",
            "          [ 0.0270,  0.0435, -0.0046],\n",
            "          [-0.0252,  0.0398,  0.0208]],\n",
            "\n",
            "         [[ 0.0004, -0.0025,  0.0275],\n",
            "          [ 0.0654,  0.0074,  0.0022],\n",
            "          [-0.0100, -0.0176, -0.0133]],\n",
            "\n",
            "         [[ 0.0786, -0.0070,  0.0160],\n",
            "          [-0.0090,  0.0180, -0.0084],\n",
            "          [ 0.0203, -0.0226,  0.0335]]],\n",
            "\n",
            "\n",
            "        [[[-0.0205, -0.0023, -0.0575],\n",
            "          [ 0.0736, -0.0279,  0.0508],\n",
            "          [-0.0235,  0.0026,  0.0044]],\n",
            "\n",
            "         [[ 0.0225, -0.0158, -0.0006],\n",
            "          [-0.0165, -0.0767, -0.0067],\n",
            "          [-0.0525, -0.0661,  0.0218]],\n",
            "\n",
            "         [[-0.0146, -0.0132,  0.0077],\n",
            "          [-0.0277, -0.0022, -0.0048],\n",
            "          [-0.0606,  0.0133,  0.0118]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0292, -0.0118, -0.0074],\n",
            "          [-0.0310, -0.0082, -0.0182],\n",
            "          [-0.0871, -0.0127,  0.0155]],\n",
            "\n",
            "         [[ 0.0199, -0.0204, -0.0047],\n",
            "          [ 0.0963, -0.0100,  0.0146],\n",
            "          [-0.0156, -0.0631,  0.0056]],\n",
            "\n",
            "         [[-0.0019,  0.0388,  0.0322],\n",
            "          [-0.0189, -0.0531, -0.0224],\n",
            "          [-0.0104, -0.0377, -0.0498]]]])), ('module.encoder_k.layer3.3.bn2.weight', tensor([0.9990, 0.9990, 0.9992, 0.9992, 0.9991, 0.9992, 0.9990, 0.9992, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9991, 0.9990, 0.9992,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9989,\n",
            "        0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9989,\n",
            "        0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9992, 0.9989, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9990, 0.9991, 0.9989, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9989, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9990, 0.9990, 0.9992, 0.9990, 0.9992, 0.9992,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9989, 0.9991, 0.9992, 0.9991, 0.9993,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9989, 0.9990, 0.9992,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9993, 0.9989, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9992, 0.9992, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9992, 0.9990, 0.9991, 0.9989, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9993, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.3.bn2.bias', tensor([ 3.4313e-06, -5.1444e-05,  1.2213e-04, -1.2390e-07, -7.2748e-05,\n",
            "         1.0086e-04,  3.5641e-05,  1.0142e-04,  1.1412e-04,  1.1625e-05,\n",
            "        -1.0773e-05,  1.9794e-05, -4.6150e-05, -1.1786e-05,  1.0526e-04,\n",
            "        -4.2585e-05, -8.6442e-05,  4.7553e-05,  3.6453e-05, -4.0012e-05,\n",
            "        -3.0630e-06, -9.6357e-05,  1.1752e-04, -1.2682e-04,  7.3063e-05,\n",
            "         7.3067e-05, -2.3068e-06,  2.5510e-05,  1.3580e-06,  2.2035e-05,\n",
            "        -3.7883e-05, -4.7217e-05,  2.7416e-05,  5.6235e-05, -1.0545e-06,\n",
            "         1.1698e-04, -5.2898e-05, -2.0980e-05,  1.2800e-04, -4.5175e-05,\n",
            "         2.5039e-05,  5.9127e-05,  6.3594e-05,  3.6712e-05, -8.1477e-05,\n",
            "        -1.5104e-05,  4.9131e-05, -5.8165e-05, -2.9273e-05, -4.3302e-05,\n",
            "         2.4515e-05,  6.3556e-05,  2.8166e-05, -7.5273e-05,  6.5477e-05,\n",
            "        -9.0101e-05,  9.8788e-07, -3.4072e-05,  1.9560e-04, -1.4846e-05,\n",
            "         4.3605e-05, -1.7764e-04,  3.8266e-05, -7.4340e-05,  5.4838e-05,\n",
            "        -1.0112e-04,  8.0211e-05, -5.2044e-05,  1.2080e-05,  6.2392e-05,\n",
            "        -5.7239e-06, -1.3001e-04,  8.4442e-05, -9.8184e-05,  1.6882e-05,\n",
            "        -1.2758e-05,  4.8287e-05,  6.2213e-05,  6.4892e-05,  6.6656e-05,\n",
            "        -1.6269e-05, -1.3923e-04,  2.2458e-05,  8.3346e-05,  9.9375e-05,\n",
            "        -7.9604e-05,  3.9536e-05, -7.8009e-05,  1.3256e-04, -6.2491e-05,\n",
            "        -7.7318e-05, -3.3603e-07,  9.5833e-05, -6.9437e-05,  6.3539e-05,\n",
            "        -1.0733e-04,  4.0071e-07,  4.3288e-05, -9.4127e-05, -3.8749e-05,\n",
            "        -1.1735e-05,  3.8644e-05,  4.8145e-06, -3.9819e-05, -4.0200e-05,\n",
            "        -4.1506e-06, -5.5916e-05, -7.5743e-05,  9.2715e-05,  3.7192e-05,\n",
            "         2.2956e-07,  2.2514e-05, -6.7667e-05,  1.1122e-04,  8.2748e-05,\n",
            "        -8.6280e-05, -7.8888e-05,  3.3935e-05, -1.0666e-04,  3.8416e-05,\n",
            "         4.8297e-05, -7.3160e-05,  3.2396e-05, -1.6725e-05, -1.3085e-04,\n",
            "         3.7038e-05, -2.3760e-05, -1.1108e-05,  6.1064e-05, -6.4614e-05,\n",
            "         8.5227e-06, -2.0412e-05,  2.9935e-05, -6.3635e-05, -4.5655e-05,\n",
            "         4.2978e-05, -1.0085e-04, -4.2469e-05, -8.1550e-05,  4.5730e-05,\n",
            "        -4.3737e-05, -7.6239e-05,  3.3001e-05, -6.8625e-06,  8.8597e-05,\n",
            "        -9.7666e-05, -8.8415e-06,  1.4553e-05,  5.8662e-07,  4.5011e-06,\n",
            "        -5.4229e-06,  1.2954e-04,  9.1462e-05,  4.3525e-05,  2.6664e-05,\n",
            "         3.5243e-05, -3.3506e-05, -1.6864e-04, -4.7765e-05,  7.7933e-05,\n",
            "        -2.1194e-05,  1.7796e-04,  1.1790e-04,  5.2228e-05,  1.3681e-05,\n",
            "         5.8230e-05,  2.9838e-05, -7.1333e-05, -1.6062e-04, -3.8386e-05,\n",
            "         9.0172e-05,  3.5400e-05,  1.2552e-05, -3.9743e-05,  6.8506e-05,\n",
            "        -6.6321e-05,  9.2875e-05,  5.7438e-05,  1.5086e-05, -5.1888e-05,\n",
            "         2.5420e-05, -4.4547e-06,  4.3349e-05, -4.8182e-05, -3.6514e-05,\n",
            "        -1.3191e-05,  1.2418e-04, -1.3831e-04,  8.8603e-06,  2.9341e-06,\n",
            "         3.3673e-05,  9.8820e-05,  7.8284e-05, -3.1453e-05,  2.2609e-05,\n",
            "         3.9028e-05,  5.3247e-05,  6.8401e-06,  8.5677e-05, -5.4435e-05,\n",
            "        -2.1119e-05,  3.6646e-05,  3.1920e-05, -6.8356e-05,  4.7934e-05,\n",
            "        -1.2325e-04,  6.3405e-06, -4.1516e-05,  2.5937e-05, -4.4131e-05,\n",
            "         2.4730e-05, -9.5260e-05, -7.7324e-06, -8.4508e-05,  5.4898e-05,\n",
            "        -1.0156e-05, -8.0981e-05, -2.8525e-05,  9.0814e-05,  7.9616e-05,\n",
            "         1.4231e-05, -3.5128e-05,  1.3906e-04, -7.5435e-06, -1.5075e-04,\n",
            "        -2.2632e-05, -3.0542e-05,  5.2661e-05,  1.1813e-04,  5.6221e-05,\n",
            "         3.0382e-05,  1.0568e-04,  7.0212e-05, -3.7547e-06, -1.3325e-04,\n",
            "         8.2163e-05,  4.7092e-05,  1.0291e-05, -4.0760e-05,  9.2034e-06,\n",
            "         4.1708e-05, -4.3620e-05, -7.5042e-05,  1.2037e-04,  9.3836e-05,\n",
            "         1.6757e-05, -2.3524e-04, -9.5651e-05,  1.3432e-04, -2.1311e-05,\n",
            "        -2.9807e-05, -3.5486e-05, -1.1049e-04,  2.6482e-05, -8.8761e-05,\n",
            "        -1.7551e-05])), ('module.encoder_k.layer3.3.bn2.running_mean', tensor([-1.2419e+00,  1.2994e-01, -4.3652e-02,  1.1991e-01,  2.4940e-01,\n",
            "         7.3325e-01, -7.9443e-02, -1.3346e-01, -1.0037e+00, -5.0771e-01,\n",
            "        -5.6280e-02,  3.2537e-01,  1.0223e-01, -1.9975e-01,  1.8524e-01,\n",
            "        -8.0069e-01,  9.4794e-01, -3.3003e-01, -7.8851e-01, -4.3834e-01,\n",
            "        -9.0168e-01, -4.5814e-01,  1.4916e-01, -5.5249e-01, -2.4518e-02,\n",
            "         3.4883e-01, -1.2229e+00,  1.4573e+00, -1.8583e-01, -4.8592e-02,\n",
            "         3.2564e-01, -6.4659e-01, -8.3440e-02, -4.6201e-02,  4.4247e-01,\n",
            "        -2.8284e-01,  1.7337e-01,  8.6036e-02,  4.1927e-01,  6.6360e-01,\n",
            "         8.1459e-01, -6.2188e-01, -2.5192e-02, -8.6663e-02, -1.5527e+00,\n",
            "         3.8839e-01, -9.0175e-01, -3.0948e-01,  1.2792e-01,  2.8500e-01,\n",
            "        -3.2881e-01, -7.9478e-01,  8.0050e-02,  2.4459e-01, -6.3327e-02,\n",
            "        -1.0412e+00, -2.5216e-01, -3.9977e-01,  5.7415e-01,  2.8693e-01,\n",
            "         7.3221e-02, -2.6402e-01, -5.7777e-01, -5.1572e-01, -5.5477e-01,\n",
            "        -1.2440e-01, -2.6745e-01,  4.3058e-01, -4.9332e-01,  5.6189e-01,\n",
            "        -4.9517e-01,  5.0415e-01, -9.0419e-02, -3.5674e-01, -5.7297e-01,\n",
            "        -7.0689e-01, -4.3633e-01,  7.2700e-01,  1.1632e-02, -7.0251e-04,\n",
            "        -1.9983e-02,  4.2900e-01,  1.4700e+00, -1.1986e-01,  1.6904e-01,\n",
            "         5.6320e-01,  4.4083e-01,  9.1636e-01, -1.7689e-01,  3.3538e-01,\n",
            "        -1.8636e-01,  2.1949e-01, -2.1572e-01,  1.8026e-01,  3.5584e-01,\n",
            "        -5.6794e-02,  3.2108e-01, -3.6658e-01, -4.3478e-01, -2.5708e-01,\n",
            "        -5.8393e-01,  1.0180e-01,  1.6411e-04, -5.1083e-01,  4.8654e-01,\n",
            "        -1.2067e-01, -9.8738e-01, -4.3032e-02, -3.1329e-01,  6.3740e-01,\n",
            "         1.6674e-01, -1.8706e-01,  2.0618e-02, -2.4121e-01, -4.4740e-01,\n",
            "         5.6552e-01, -7.0047e-02, -3.7603e-02,  3.8364e-01,  2.1080e-01,\n",
            "        -1.0582e-01,  3.1756e-01,  7.6460e-01,  4.3096e-02,  1.7528e-01,\n",
            "        -3.0978e-01,  7.8263e-01,  3.0454e-01,  3.3701e-02,  4.0264e-01,\n",
            "         7.4058e-02, -1.2370e+00, -1.5585e-01,  3.5438e-01,  3.6813e-01,\n",
            "        -7.1487e-01,  7.0050e-02,  2.6164e-01, -1.1985e-01, -4.6615e-01,\n",
            "         2.0061e-01,  1.8412e-01, -2.2872e-01, -3.7014e-01,  1.1918e-01,\n",
            "        -1.9791e-01,  2.9365e-01,  3.1702e-01,  3.9690e-01,  8.5586e-02,\n",
            "        -5.7988e-01, -2.6452e-01,  2.0797e-01, -5.7975e-01,  1.5772e-01,\n",
            "        -3.7204e-01, -2.0951e-03,  5.5308e-01, -3.6842e-01,  1.2219e-01,\n",
            "        -7.1617e-01,  4.3944e-01, -6.8198e-01, -1.1305e-01, -2.8048e-01,\n",
            "        -2.3340e-01,  2.4431e-01, -2.8837e-01,  3.6076e-01,  1.1532e+00,\n",
            "        -3.2575e-01, -1.2283e-01, -3.1137e-01, -3.3911e-01,  2.4096e-01,\n",
            "        -4.9848e-01, -6.4218e-01,  4.6461e-01,  7.5282e-01, -6.3097e-01,\n",
            "         7.9415e-01, -3.9110e-01,  5.0624e-01, -2.0339e-02, -1.8257e-01,\n",
            "         1.4285e-01,  3.2972e-01,  4.8047e-01, -2.9909e-01, -1.8416e-01,\n",
            "         1.3081e-01,  1.9063e-01,  4.9219e-01, -8.8521e-01,  3.2367e-01,\n",
            "         3.4938e-01,  4.6251e-01,  9.3310e-01,  9.6971e-01, -3.2538e-01,\n",
            "         3.3635e-01, -5.6793e-01, -1.1771e+00,  6.9477e-01, -1.9270e-01,\n",
            "        -4.1673e-01, -2.1409e-01, -2.2550e-01,  3.9742e-01,  3.1631e-01,\n",
            "        -2.4585e-01, -2.3489e-01,  1.5208e-01,  1.9915e-01,  2.5597e-01,\n",
            "        -3.5828e-01,  5.8023e-01, -1.1613e+00, -7.4506e-02,  3.6739e-01,\n",
            "        -2.1439e-01,  2.6858e-01, -2.3259e-01, -7.4453e-01, -6.2867e-01,\n",
            "        -3.0848e-02,  1.0745e+00, -1.5909e-01,  5.3147e-01,  4.8678e-01,\n",
            "        -4.2098e-01, -5.9474e-01, -6.0293e-02, -1.8771e-01, -3.7505e-01,\n",
            "         7.1946e-01,  8.2270e-02,  5.3909e-01,  1.1296e-01,  3.8736e-02,\n",
            "        -1.0981e-01,  6.7861e-03, -1.1675e-02, -3.1479e-01, -2.3344e-01,\n",
            "         1.1230e-01, -2.1221e-01,  3.0966e-01,  4.0582e-01,  8.2731e-01,\n",
            "        -5.0798e-01, -7.1806e-01,  7.2555e-01,  4.8247e-01,  7.8919e-01,\n",
            "        -5.5997e-01])), ('module.encoder_k.layer3.3.bn2.running_var', tensor([1.3597, 0.8120, 0.7389, 0.6172, 0.5996, 1.1491, 0.5626, 0.5823, 1.0247,\n",
            "        0.5136, 0.5260, 0.8405, 0.5771, 0.6247, 0.7891, 1.3453, 1.5007, 0.5656,\n",
            "        0.7034, 0.5494, 0.6362, 0.5666, 0.5838, 1.2619, 0.5799, 0.7187, 1.0991,\n",
            "        1.9770, 0.5212, 0.6180, 0.6638, 0.6938, 0.5757, 0.7224, 0.8378, 0.6616,\n",
            "        0.5783, 0.6097, 0.8282, 0.6241, 0.6642, 0.6133, 0.6380, 0.4852, 1.5069,\n",
            "        0.9121, 1.5309, 0.6683, 0.5689, 0.5654, 0.6045, 1.8182, 0.5862, 0.6701,\n",
            "        0.5109, 0.8837, 0.5687, 0.7217, 0.5669, 0.7272, 0.6047, 0.5847, 0.6058,\n",
            "        1.0223, 1.0097, 0.5932, 0.5716, 0.7881, 0.7553, 1.5197, 0.5976, 0.5482,\n",
            "        0.7491, 0.5475, 0.6090, 0.8480, 0.6103, 0.7048, 0.8244, 0.6760, 0.6965,\n",
            "        0.5471, 1.0549, 0.5611, 0.5383, 1.3688, 0.6887, 1.2986, 1.0839, 0.5686,\n",
            "        0.6293, 0.7605, 0.7502, 1.0191, 0.5926, 0.6396, 0.5886, 0.7903, 0.6768,\n",
            "        0.4958, 0.6171, 0.6515, 0.6239, 0.8641, 0.9474, 0.5863, 1.2681, 0.5752,\n",
            "        0.5481, 0.7588, 0.6588, 0.8608, 0.6067, 0.5762, 1.0904, 0.7084, 0.6630,\n",
            "        0.5772, 0.5768, 0.6111, 0.5122, 1.2159, 1.6603, 0.6095, 0.7170, 0.5662,\n",
            "        1.1169, 0.5355, 0.5266, 0.6421, 0.6109, 1.0871, 0.7869, 0.6713, 0.9779,\n",
            "        0.8119, 0.7753, 0.6040, 0.6252, 0.7058, 0.6401, 0.6295, 0.8390, 0.7164,\n",
            "        0.6644, 0.5488, 0.7537, 0.7495, 0.5520, 0.5556, 0.6530, 0.7379, 0.5969,\n",
            "        0.5213, 0.7136, 0.5969, 0.5516, 0.5580, 0.6138, 0.6245, 0.7071, 0.7529,\n",
            "        0.5514, 0.6213, 0.6520, 0.5489, 0.7097, 0.5459, 0.7639, 0.6953, 0.6017,\n",
            "        0.5474, 0.6806, 0.5962, 0.6557, 0.6455, 0.5942, 0.8249, 0.7029, 0.6271,\n",
            "        1.1905, 0.7913, 0.7888, 0.5204, 0.5671, 0.6550, 0.8307, 0.6691, 0.5929,\n",
            "        0.5655, 0.5347, 0.5580, 0.6007, 0.9726, 1.0694, 0.6187, 0.5879, 0.8745,\n",
            "        1.2930, 0.7184, 0.7063, 0.5443, 1.1756, 0.7406, 0.5355, 0.7749, 0.6177,\n",
            "        0.6107, 0.5812, 0.9548, 0.5575, 0.7856, 0.7573, 0.6398, 0.5367, 0.5879,\n",
            "        0.7308, 1.1459, 0.6211, 0.5723, 0.6126, 0.7073, 0.8435, 0.7472, 0.6129,\n",
            "        0.5758, 1.2688, 0.9404, 0.6147, 0.6280, 0.5792, 0.5934, 0.6657, 0.5553,\n",
            "        0.5419, 1.1160, 0.7700, 0.6677, 0.5949, 0.5559, 0.6564, 0.6608, 0.5367,\n",
            "        1.0403, 0.7157, 0.6660, 0.5983, 0.6447, 0.9353, 1.1655, 1.1457, 0.6064,\n",
            "        0.6115, 0.5467, 0.7316, 1.0759])), ('module.encoder_k.layer3.3.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.3.conv3.weight', tensor([[[[ 0.0282]],\n",
            "\n",
            "         [[-0.0040]],\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0379]],\n",
            "\n",
            "         [[-0.0005]],\n",
            "\n",
            "         [[-0.0159]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0847]],\n",
            "\n",
            "         [[-0.0917]],\n",
            "\n",
            "         [[ 0.0345]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0205]],\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[-0.0155]]],\n",
            "\n",
            "\n",
            "        [[[-0.0615]],\n",
            "\n",
            "         [[ 0.0230]],\n",
            "\n",
            "         [[-0.0264]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0725]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         [[ 0.0060]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0153]],\n",
            "\n",
            "         [[-0.0497]],\n",
            "\n",
            "         [[ 0.0267]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1010]],\n",
            "\n",
            "         [[ 0.0877]],\n",
            "\n",
            "         [[-0.0525]]],\n",
            "\n",
            "\n",
            "        [[[-0.0328]],\n",
            "\n",
            "         [[-0.0287]],\n",
            "\n",
            "         [[ 0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0220]],\n",
            "\n",
            "         [[-0.0644]],\n",
            "\n",
            "         [[ 0.0295]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0458]],\n",
            "\n",
            "         [[-0.0594]],\n",
            "\n",
            "         [[ 0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0666]],\n",
            "\n",
            "         [[ 0.0504]],\n",
            "\n",
            "         [[-0.0540]]]])), ('module.encoder_k.layer3.3.bn3.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.3.bn3.bias', tensor([-2.4190e-05,  3.4609e-05, -4.6424e-06,  ..., -1.2322e-05,\n",
            "        -1.8060e-05, -1.9452e-05])), ('module.encoder_k.layer3.3.bn3.running_mean', tensor([ 0.3879, -0.0495,  0.0011,  ..., -0.0854,  0.1086, -0.1365])), ('module.encoder_k.layer3.3.bn3.running_var', tensor([0.2795, 0.1408, 0.1864,  ..., 0.1649, 0.1670, 0.3541])), ('module.encoder_k.layer3.3.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.4.conv1.weight', tensor([[[[-0.0167]],\n",
            "\n",
            "         [[ 0.0315]],\n",
            "\n",
            "         [[-0.1228]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0055]],\n",
            "\n",
            "         [[-0.0985]],\n",
            "\n",
            "         [[-0.0357]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0441]],\n",
            "\n",
            "         [[-0.0603]],\n",
            "\n",
            "         [[ 0.0168]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1613]],\n",
            "\n",
            "         [[-0.0352]],\n",
            "\n",
            "         [[-0.2539]]],\n",
            "\n",
            "\n",
            "        [[[-0.0512]],\n",
            "\n",
            "         [[ 0.0335]],\n",
            "\n",
            "         [[ 0.0465]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1561]],\n",
            "\n",
            "         [[-0.1096]],\n",
            "\n",
            "         [[ 0.0974]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0131]],\n",
            "\n",
            "         [[-0.0560]],\n",
            "\n",
            "         [[ 0.0721]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[-0.0662]],\n",
            "\n",
            "         [[ 0.1185]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0733]],\n",
            "\n",
            "         [[-0.0156]],\n",
            "\n",
            "         [[ 0.0939]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0908]],\n",
            "\n",
            "         [[ 0.0490]],\n",
            "\n",
            "         [[-0.0741]]],\n",
            "\n",
            "\n",
            "        [[[-0.0691]],\n",
            "\n",
            "         [[-0.0715]],\n",
            "\n",
            "         [[-0.0728]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0742]],\n",
            "\n",
            "         [[-0.0067]],\n",
            "\n",
            "         [[ 0.0858]]]])), ('module.encoder_k.layer3.4.bn1.weight', tensor([0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9989, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9993, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9993, 0.9991, 0.9989,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9992, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9989, 0.9991, 0.9990, 0.9992,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9990, 0.9990, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9989, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9992, 0.9990, 0.9992])), ('module.encoder_k.layer3.4.bn1.bias', tensor([ 3.0831e-06, -1.0499e-04,  2.8937e-05, -4.2377e-05, -2.0869e-06,\n",
            "        -2.3595e-05,  1.5429e-05, -1.0369e-04,  1.9982e-05,  1.2629e-05,\n",
            "         1.9241e-05, -7.4798e-06, -1.7329e-05,  2.6425e-05, -1.9057e-05,\n",
            "         2.1864e-05,  2.0428e-05, -1.0799e-04,  6.1367e-06,  4.7760e-06,\n",
            "         4.1785e-05, -8.5138e-05, -1.6352e-05,  1.8062e-05, -4.7637e-05,\n",
            "         1.8853e-05, -4.6798e-05,  3.0792e-05,  9.6818e-05,  3.6515e-05,\n",
            "        -1.2103e-04, -4.9857e-05,  5.0654e-05, -1.5567e-04, -4.9976e-05,\n",
            "        -7.8053e-05, -5.5682e-05, -4.5716e-05,  4.3916e-05,  4.4091e-05,\n",
            "        -6.4788e-05,  1.0247e-04, -1.0481e-04, -3.5050e-05,  9.6460e-05,\n",
            "         1.4282e-04,  7.5349e-05,  9.1699e-05,  2.1816e-06,  9.4355e-05,\n",
            "        -8.2167e-05, -9.4575e-06,  5.2726e-05,  9.7345e-05,  6.6485e-05,\n",
            "        -6.8858e-06, -8.1688e-06, -7.0570e-05,  5.0421e-05, -1.4308e-05,\n",
            "         8.3307e-05, -1.3862e-05, -2.3525e-05, -2.8359e-05, -6.2433e-07,\n",
            "        -5.3349e-05, -1.5946e-05,  8.3452e-06, -2.3693e-05,  1.4586e-05,\n",
            "         6.7309e-05,  4.5480e-05, -4.4070e-05, -5.5567e-05, -7.1991e-05,\n",
            "        -3.4926e-05,  8.9586e-06, -2.1543e-05, -1.4843e-04, -4.4022e-06,\n",
            "         7.9515e-05, -1.1073e-05, -2.2272e-05,  1.8712e-05, -1.0679e-04,\n",
            "         9.9013e-05, -4.0257e-05,  1.3757e-04,  1.2462e-04, -3.3833e-05,\n",
            "         6.2872e-05, -1.0040e-04, -2.2872e-05, -3.6947e-05, -9.1343e-05,\n",
            "        -3.3201e-05, -1.9434e-05,  9.8646e-05, -6.4187e-05, -5.6181e-05,\n",
            "         5.1232e-06,  7.5191e-05, -2.5957e-05,  8.7644e-06,  8.6958e-05,\n",
            "        -4.3071e-05, -9.9642e-06, -4.7401e-06,  3.1434e-05, -1.5017e-04,\n",
            "         2.2086e-05,  3.4663e-05,  1.7124e-04,  5.2300e-05, -4.4894e-05,\n",
            "        -6.3412e-05,  3.5440e-05, -5.0407e-05, -7.9997e-05, -1.0451e-05,\n",
            "         1.5770e-05, -3.8278e-05,  1.2290e-04, -5.8120e-06,  3.2397e-05,\n",
            "        -5.3608e-05,  3.8687e-05, -8.7699e-05, -1.0463e-05,  2.1093e-05,\n",
            "         5.3448e-05,  2.8051e-05, -3.5096e-05, -6.6262e-05, -3.3802e-05,\n",
            "         8.6108e-07, -2.4200e-05, -1.9235e-05,  1.3054e-04, -7.1419e-05,\n",
            "         4.7766e-05, -8.0728e-05,  1.2575e-05, -3.9684e-05, -3.5586e-05,\n",
            "        -4.4456e-05,  1.8536e-05, -3.6191e-05, -5.8901e-05, -2.3981e-05,\n",
            "        -5.1384e-05, -2.1683e-05, -7.4133e-05,  2.6972e-05, -1.3090e-07,\n",
            "        -1.1182e-04,  1.5683e-04,  2.0415e-05, -2.8188e-05,  8.4829e-05,\n",
            "         1.3694e-05, -5.3358e-05,  9.4331e-06, -4.2887e-05, -2.6444e-06,\n",
            "         1.8221e-05, -5.2616e-06,  2.9625e-05,  1.7264e-05, -9.0000e-05,\n",
            "        -1.4802e-04,  3.9099e-05, -4.0383e-05, -9.3820e-07,  1.1906e-04,\n",
            "         4.2438e-05,  1.3883e-04,  5.5796e-05,  7.0176e-05, -6.0617e-05,\n",
            "        -3.5815e-05,  8.3504e-05,  5.2922e-05, -6.5937e-05, -4.3195e-05,\n",
            "         1.4849e-04,  5.0122e-05,  1.5173e-04, -3.3862e-05, -9.3828e-05,\n",
            "         2.5923e-05,  6.2715e-05, -7.7765e-06,  9.1448e-06, -1.9797e-05,\n",
            "        -4.0825e-05, -1.7211e-04,  1.1120e-04,  3.6698e-05, -4.7629e-05,\n",
            "        -3.8057e-05, -1.2878e-05,  5.7016e-06,  2.7919e-05, -8.0583e-05,\n",
            "        -7.2191e-05,  1.2743e-04, -4.6140e-05, -2.3519e-05,  3.0187e-06,\n",
            "         1.9426e-05,  7.6406e-05, -1.2375e-05,  9.6267e-05,  4.8505e-05,\n",
            "         4.1689e-05, -2.6782e-06,  1.1906e-05, -1.3581e-05, -4.6601e-05,\n",
            "         1.0377e-04,  1.0144e-04, -1.5386e-05, -2.5763e-05, -8.6985e-05,\n",
            "         7.2970e-05,  9.7659e-05, -2.1504e-05, -6.5225e-05, -3.1669e-05,\n",
            "         1.0238e-04, -9.7035e-05, -1.2524e-05, -7.0594e-05,  4.4828e-05,\n",
            "         2.0665e-05,  5.5969e-05, -5.0230e-05,  1.4043e-04, -6.7803e-05,\n",
            "         4.2046e-05, -3.4281e-06,  3.0885e-05, -2.4493e-05,  5.7307e-05,\n",
            "         5.8939e-05, -4.8565e-05, -8.9084e-05, -4.0182e-05,  5.6122e-05,\n",
            "        -3.0265e-05, -4.2708e-05, -1.9602e-05,  9.4150e-05, -4.3302e-05,\n",
            "        -1.9050e-05])), ('module.encoder_k.layer3.4.bn1.running_mean', tensor([-1.3647e-01,  6.4602e+00, -2.4613e+00,  8.4454e-01,  9.0837e-02,\n",
            "         3.4261e+00, -3.5192e+00, -2.6596e+00,  2.6709e+00,  2.3763e+00,\n",
            "        -2.7385e-01,  1.7754e+00,  3.2286e+00,  6.3058e-01, -2.9717e+00,\n",
            "        -1.6429e+00,  2.9916e+00,  3.2567e+00,  3.7592e+00, -3.5893e-01,\n",
            "        -3.4262e+00, -4.7442e+00,  2.7211e+00,  8.7429e-01,  9.7197e-01,\n",
            "         9.5461e-01,  2.5830e+00,  1.8467e+00, -3.2015e+00, -4.4435e-01,\n",
            "        -7.5687e-01, -2.9884e+00,  3.6688e+00,  8.7231e-02,  2.4590e+00,\n",
            "        -1.4375e+00, -3.1596e-01,  5.3639e-01,  4.4883e+00,  1.3860e+00,\n",
            "        -1.7491e+00, -2.6753e+00,  4.5891e+00,  2.7975e+00,  5.6954e+00,\n",
            "        -2.0163e+00,  1.9716e+00,  2.9736e+00, -7.6833e+00,  1.1273e+00,\n",
            "        -1.6645e+00,  4.0351e-01, -3.0893e-01,  3.4304e-03, -1.3225e+00,\n",
            "         1.3190e-01, -2.2481e+00, -7.7808e-01,  2.5522e+00, -1.6930e+00,\n",
            "         1.8165e+00, -5.6192e-01,  1.7816e+00,  2.0256e+00, -3.6416e+00,\n",
            "        -7.9548e-01,  2.9082e+00, -3.2189e+00, -1.2767e+00,  1.3242e+00,\n",
            "         7.0237e-01, -1.8717e+00,  3.1456e-01, -3.8742e+00,  5.4980e-02,\n",
            "         1.4833e+00,  5.0524e+00, -3.5432e+00, -3.4026e-01, -1.8823e+00,\n",
            "        -1.1220e+00, -3.3490e+00, -9.2680e-01,  2.0939e+00,  3.7128e+00,\n",
            "         2.1166e+00, -2.9529e+00, -2.6234e+00, -8.2788e-01,  2.9524e+00,\n",
            "         2.5127e-01, -4.4983e+00, -4.2543e-01, -4.4584e-01, -3.5251e-01,\n",
            "        -8.8552e-01, -1.2914e+00, -1.2118e+00, -2.8017e-01,  2.0800e+00,\n",
            "         1.7534e+00, -1.1690e+00, -4.2367e+00,  2.0752e-01,  5.2998e+00,\n",
            "        -3.4909e+00,  2.2876e-01,  1.7751e+00,  7.1465e-01, -2.0184e+00,\n",
            "         4.8151e+00,  1.6800e+00,  2.7362e+00, -2.3300e+00, -3.5761e+00,\n",
            "        -2.9976e+00, -4.8480e+00,  8.9203e-01,  5.3834e+00, -5.2372e+00,\n",
            "         4.1570e+00,  9.5944e-01, -3.9630e-01,  2.4070e+00, -1.4293e-01,\n",
            "        -1.9111e+00,  1.1315e+00, -3.4706e+00,  5.1600e+00,  2.1585e-01,\n",
            "        -3.2943e+00, -2.7530e+00,  2.2889e+00, -7.7061e-02, -3.5223e+00,\n",
            "         2.5486e+00,  2.2530e-01,  1.8985e+00, -4.5648e-01, -4.7250e+00,\n",
            "        -3.7969e+00,  1.4166e+00, -2.1215e-01, -4.1127e+00,  2.6685e+00,\n",
            "         1.5510e+00,  4.3926e+00,  7.0207e-01,  1.7074e+00, -8.1255e-01,\n",
            "        -4.7988e+00, -1.9062e+00, -8.2257e-02,  1.9203e+00, -1.7463e-01,\n",
            "        -5.6358e-01,  1.2390e+00,  1.7302e+00, -2.9154e+00,  1.3600e+00,\n",
            "         7.0876e-01,  3.0675e+00, -3.0585e+00,  3.8387e+00, -4.5523e+00,\n",
            "         6.5864e-01, -2.5420e+00, -4.5703e+00,  1.0047e+00, -7.5485e-01,\n",
            "         2.6454e+00, -8.0106e-01,  6.9004e-01, -6.3971e-01,  2.3218e+00,\n",
            "         3.3582e-02, -2.1421e+00, -1.4056e+00,  9.6773e-01,  8.1906e-01,\n",
            "         1.2683e-01, -1.6593e+00, -4.1470e+00, -1.5476e+00, -2.4364e+00,\n",
            "        -2.4401e+00, -4.0406e-01,  3.4271e+00,  2.9641e+00,  1.6352e+00,\n",
            "        -8.1979e-01,  1.6675e+00,  3.2627e-01, -1.1670e+00,  4.2859e+00,\n",
            "        -2.5361e+00, -4.2912e+00,  1.5147e-01,  1.3103e+00,  2.0814e+00,\n",
            "        -1.8779e+00,  5.0006e+00,  1.6751e+00, -3.1738e+00,  1.8583e+00,\n",
            "         1.6099e+00, -8.9154e-01,  4.0445e+00, -2.3547e+00,  1.1199e+00,\n",
            "         4.0446e-01, -3.3952e+00, -4.0611e+00,  2.8037e+00,  1.5979e-01,\n",
            "         3.6095e+00, -5.3779e+00, -5.0533e+00, -4.2700e+00, -4.5972e+00,\n",
            "         3.8507e+00,  5.9344e-01, -3.3052e+00, -9.0930e-01,  1.8730e+00,\n",
            "        -3.7283e+00,  9.5095e-02, -2.7010e-01, -1.2356e+00,  2.0808e-01,\n",
            "        -2.3724e+00,  2.7460e+00, -1.8978e+00,  9.6455e-02, -2.6428e+00,\n",
            "         1.9955e+00,  2.5416e+00, -6.2447e-01,  2.1838e+00, -6.9316e+00,\n",
            "         4.2241e-01,  2.7803e+00,  4.0967e+00,  1.1962e+00,  3.1998e+00,\n",
            "         4.1499e+00, -1.5284e+00,  5.3879e+00, -3.3272e+00,  3.1645e+00,\n",
            "         2.9374e-01, -2.5600e+00,  2.6968e+00, -1.1704e-01, -1.8552e+00,\n",
            "         1.8356e+00])), ('module.encoder_k.layer3.4.bn1.running_var', tensor([12.3750, 18.8974, 23.1600, 11.4523, 11.4893, 12.9462, 14.8286, 12.1363,\n",
            "        43.3892, 13.6227, 14.9163, 17.3898, 21.3371, 13.4732, 14.0740, 12.5173,\n",
            "        13.5178, 11.7279, 22.9170, 13.1317, 17.1027, 21.2233, 18.8988, 11.2913,\n",
            "        11.7570, 13.7886, 14.9072, 14.2721, 22.5083, 12.7192, 13.4684, 20.7707,\n",
            "        18.6886, 11.2077, 16.2944, 12.6771, 12.8487, 15.0801, 18.2443, 18.5579,\n",
            "        12.6637, 14.2091, 13.2069, 13.0153, 24.0570, 11.4885, 14.6769, 13.9580,\n",
            "        56.7343, 11.1924, 12.0473, 14.0178, 15.9003, 16.3595, 11.0320, 11.7972,\n",
            "        11.3108, 12.8455, 10.7017, 14.4971, 26.4764, 11.6688, 17.3378, 14.1885,\n",
            "        30.6376, 15.8893, 11.3091, 15.1297, 13.9649, 12.4222, 12.7507, 33.6692,\n",
            "        16.0063, 11.6954, 10.6927, 10.9010, 18.4428, 16.2362, 11.1765, 14.1099,\n",
            "        17.6933, 14.8279, 11.5132, 14.4651, 11.1640, 11.1399, 13.2124, 15.2473,\n",
            "        21.5666, 15.8311, 11.4293, 14.9679, 10.3682, 14.5418, 16.4383,  9.8123,\n",
            "        12.5595, 12.8442, 12.9594, 23.3538, 12.2416, 12.1765, 12.5292, 12.3052,\n",
            "        26.6132, 12.6308, 13.2528, 32.2818, 20.4445, 11.0237, 23.9675, 15.1434,\n",
            "        12.0261, 11.9362, 22.6973, 29.8313, 19.1262, 14.9508, 26.3019, 28.2358,\n",
            "        31.8142, 14.0715, 14.9132, 12.0549, 11.9235, 16.1202, 12.5516, 13.2579,\n",
            "        21.7432, 11.8857, 23.9231, 15.7621, 21.1565, 19.9941, 11.5759, 13.0480,\n",
            "        11.7854, 16.6925, 10.8780, 13.0774, 15.9819, 12.6927, 13.5098, 22.1761,\n",
            "        18.9267, 11.8108, 30.9122, 11.3531, 12.1403, 12.6912, 22.8348, 10.7915,\n",
            "        14.3689, 13.5554, 20.1017, 10.9854, 13.1761, 15.7850, 13.5460, 11.3351,\n",
            "        13.9337, 27.7870, 17.2988, 18.8280, 19.5824, 11.2510, 19.5055, 25.3244,\n",
            "        11.5591, 12.0274, 12.9741, 17.5956, 11.3336, 23.2285, 12.2958, 12.3156,\n",
            "        16.4674, 13.2785, 13.1462, 13.1606, 11.9144, 13.4289, 18.0800, 12.5629,\n",
            "        10.3685, 10.5512, 18.9732, 17.5076, 14.3328, 13.9680, 13.2886, 13.8029,\n",
            "        11.8964, 18.9756, 17.2461, 13.9068, 16.2118, 11.7868, 13.8199, 12.2755,\n",
            "        16.5659, 16.4761, 12.2840, 13.3319, 12.1090, 11.8466, 12.1001, 13.6007,\n",
            "        11.4755, 19.8525, 10.9143, 10.4664, 13.3296, 12.5987, 11.9051, 14.3883,\n",
            "        16.2422, 23.6894, 11.1433, 26.7397, 15.6275, 11.7597, 15.4127, 13.0034,\n",
            "        18.6519, 19.1584, 22.7517, 11.4677, 11.8758, 16.6560, 11.7005, 11.0523,\n",
            "        14.0171, 10.6647, 13.8181, 11.9928, 16.0932, 12.9929, 26.2822, 45.0192,\n",
            "        19.3003, 11.4700, 20.2189, 13.1841, 11.1447, 17.3905, 12.5947, 27.0292,\n",
            "        11.7849, 11.6617, 11.2745, 15.0293, 10.1013, 12.8280, 12.6995, 13.5240])), ('module.encoder_k.layer3.4.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.4.conv2.weight', tensor([[[[ 4.1805e-02, -2.1912e-02, -1.9606e-02],\n",
            "          [ 1.4848e-02,  1.3663e-02, -4.4959e-03],\n",
            "          [-4.7600e-02, -2.3710e-02, -3.0159e-02]],\n",
            "\n",
            "         [[-2.1981e-02,  3.3618e-02,  1.9092e-03],\n",
            "          [-3.9517e-04,  9.5520e-03,  2.7328e-02],\n",
            "          [-6.7332e-02,  2.2507e-02, -9.6863e-03]],\n",
            "\n",
            "         [[ 1.1061e-02,  2.0422e-02,  1.2776e-02],\n",
            "          [ 2.9005e-02, -2.7336e-02, -2.9830e-02],\n",
            "          [ 5.1213e-02, -3.1390e-02, -2.1600e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1757e-02,  1.5375e-02, -1.7233e-02],\n",
            "          [-2.4884e-02,  1.7048e-02, -1.5328e-02],\n",
            "          [ 4.6342e-03, -3.4624e-03,  1.8026e-02]],\n",
            "\n",
            "         [[ 1.3114e-02, -3.3756e-02, -3.6162e-02],\n",
            "          [-2.0193e-02, -5.1683e-03,  3.7700e-02],\n",
            "          [-3.3535e-03, -4.6217e-02,  4.5015e-04]],\n",
            "\n",
            "         [[-5.9392e-03, -2.1473e-02,  2.3880e-02],\n",
            "          [ 1.0291e-01,  1.6420e-02,  5.6862e-04],\n",
            "          [-1.1021e-02, -1.8142e-02, -6.3582e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.0596e-02,  1.4010e-02,  1.6216e-02],\n",
            "          [-5.5966e-02,  1.7257e-03,  5.0059e-04],\n",
            "          [-6.2727e-03, -2.1602e-02, -1.1793e-02]],\n",
            "\n",
            "         [[ 1.2555e-02,  5.1314e-02, -2.5060e-02],\n",
            "          [ 4.3276e-02,  3.2626e-02,  2.7897e-02],\n",
            "          [ 2.6827e-02,  9.0605e-03, -2.5853e-02]],\n",
            "\n",
            "         [[-5.9080e-02, -1.3141e-02, -1.0277e-02],\n",
            "          [-2.1034e-02, -8.8770e-03, -6.4375e-02],\n",
            "          [-2.2023e-03,  2.2317e-02,  2.5790e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6846e-03,  2.6898e-02, -3.9817e-02],\n",
            "          [ 1.6602e-03, -8.1698e-02,  1.9977e-02],\n",
            "          [ 1.0082e-02, -4.8969e-02, -2.5724e-02]],\n",
            "\n",
            "         [[ 4.5011e-02, -9.9763e-03, -2.0303e-02],\n",
            "          [-1.3351e-02, -2.4255e-02,  3.3424e-03],\n",
            "          [-8.3950e-03, -2.5478e-03,  4.5442e-02]],\n",
            "\n",
            "         [[ 4.5617e-03, -1.2472e-02,  2.4551e-02],\n",
            "          [-3.1271e-02,  1.6209e-02,  3.8872e-02],\n",
            "          [ 2.1736e-02,  1.2044e-02, -2.6359e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.0207e-02, -5.1236e-03,  1.5901e-02],\n",
            "          [-2.5065e-02, -3.8630e-02,  8.1959e-03],\n",
            "          [ 5.0289e-03,  8.1881e-03, -2.0949e-02]],\n",
            "\n",
            "         [[ 1.8130e-02,  7.9910e-02,  8.4629e-03],\n",
            "          [-3.5104e-02,  1.4558e-02,  3.9976e-02],\n",
            "          [-2.6355e-02, -3.2166e-02,  3.9190e-03]],\n",
            "\n",
            "         [[-3.7991e-02, -3.5548e-02,  7.7312e-03],\n",
            "          [ 3.0661e-03, -7.9101e-03,  4.5824e-03],\n",
            "          [-6.6009e-03,  1.2991e-02, -6.7998e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1553e-02, -1.8562e-02,  5.4452e-02],\n",
            "          [ 2.7013e-02, -1.4848e-02, -5.3089e-02],\n",
            "          [ 6.0166e-03,  4.5739e-03, -2.1060e-02]],\n",
            "\n",
            "         [[-4.6018e-02, -4.3090e-02,  5.1699e-03],\n",
            "          [-6.4949e-03, -3.7122e-02, -1.6660e-02],\n",
            "          [ 3.9548e-02, -8.4210e-03, -2.5288e-02]],\n",
            "\n",
            "         [[ 2.5886e-02, -2.9424e-02,  3.8207e-03],\n",
            "          [-6.9817e-03,  4.0890e-02,  4.7745e-03],\n",
            "          [-2.5869e-03, -4.4192e-02, -3.1121e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.9783e-02,  1.8319e-02, -4.9442e-03],\n",
            "          [ 2.9982e-02, -1.4639e-03,  6.1001e-03],\n",
            "          [ 8.0241e-03,  9.4651e-02, -1.4691e-02]],\n",
            "\n",
            "         [[-5.0194e-02,  8.8771e-03,  1.6719e-02],\n",
            "          [-5.0301e-03,  4.3027e-02,  2.2336e-02],\n",
            "          [-3.9974e-03, -3.4925e-02, -2.7331e-02]],\n",
            "\n",
            "         [[ 4.6126e-02,  2.4348e-03,  1.8806e-02],\n",
            "          [ 1.5117e-02, -2.7966e-02, -2.0636e-02],\n",
            "          [-3.4238e-03, -1.4496e-02, -1.0594e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4563e-02, -3.2011e-02, -1.1181e-02],\n",
            "          [-3.8699e-02,  2.3963e-02, -1.4519e-02],\n",
            "          [-2.3834e-03, -5.1373e-02, -7.1145e-03]],\n",
            "\n",
            "         [[ 1.8749e-02, -8.7198e-03,  3.0139e-02],\n",
            "          [ 1.5010e-02, -1.8356e-02,  1.2050e-02],\n",
            "          [ 1.1394e-02, -1.1473e-02,  8.4315e-02]],\n",
            "\n",
            "         [[ 5.4602e-02, -1.0370e-02,  7.1783e-03],\n",
            "          [-1.3508e-02,  1.4772e-02,  3.5346e-02],\n",
            "          [ 1.1355e-02,  6.1972e-02,  6.9389e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.1714e-02,  5.2728e-02,  1.9149e-02],\n",
            "          [-3.7848e-02, -3.2012e-02,  7.0682e-02],\n",
            "          [-1.6771e-02,  7.5339e-02, -3.2446e-02]],\n",
            "\n",
            "         [[ 3.5387e-02, -3.7329e-02,  6.9041e-03],\n",
            "          [ 1.1177e-02,  2.0980e-03, -1.7382e-02],\n",
            "          [ 1.7222e-02, -3.0374e-02, -2.3558e-03]],\n",
            "\n",
            "         [[-1.5907e-03, -1.7403e-02,  1.2330e-02],\n",
            "          [ 7.2100e-02, -1.5566e-02, -4.9566e-02],\n",
            "          [ 1.1244e-02, -9.8320e-03,  1.2766e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1434e-03, -3.5913e-02,  8.8373e-03],\n",
            "          [-1.4491e-02, -3.8578e-03, -4.9779e-03],\n",
            "          [ 3.4777e-02,  1.4433e-02,  5.7695e-02]],\n",
            "\n",
            "         [[-1.3605e-02,  3.0029e-02,  7.0221e-03],\n",
            "          [-2.0458e-02,  9.4681e-03,  9.5545e-03],\n",
            "          [ 3.6887e-02,  4.2453e-02, -6.4661e-02]],\n",
            "\n",
            "         [[ 2.4899e-02,  1.2757e-02, -1.2443e-02],\n",
            "          [-3.7269e-02, -1.4803e-02, -1.0913e-02],\n",
            "          [-8.5576e-03, -7.1066e-02, -2.7656e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3394e-02, -7.8931e-03, -3.2984e-02],\n",
            "          [ 2.1106e-02, -3.4619e-02,  2.7457e-02],\n",
            "          [ 1.5282e-02,  2.8614e-03,  1.3496e-02]],\n",
            "\n",
            "         [[ 1.2090e-02, -1.0127e-04,  2.9181e-02],\n",
            "          [ 1.7856e-02, -2.6490e-02, -2.8356e-02],\n",
            "          [ 2.3573e-02, -5.0213e-02,  7.9960e-03]],\n",
            "\n",
            "         [[ 2.1848e-02,  1.3082e-02,  1.2891e-02],\n",
            "          [-4.5005e-03, -1.1937e-02,  3.1988e-02],\n",
            "          [-4.5462e-02,  6.0249e-02,  1.6312e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7601e-03,  1.6241e-02, -7.2622e-02],\n",
            "          [-4.3662e-02,  2.2719e-02, -3.6349e-02],\n",
            "          [ 1.0742e-03,  2.0453e-02,  6.8054e-03]],\n",
            "\n",
            "         [[ 6.0857e-02,  2.3410e-02,  4.1067e-02],\n",
            "          [ 8.9543e-03,  3.1673e-03,  5.4778e-02],\n",
            "          [ 2.1225e-02, -2.7492e-02,  3.4881e-02]],\n",
            "\n",
            "         [[ 2.3540e-02, -2.3717e-02,  1.1903e-02],\n",
            "          [-1.1340e-02, -1.0369e-02, -9.6527e-04],\n",
            "          [-8.0401e-03, -1.4876e-02,  2.7678e-02]]]])), ('module.encoder_k.layer3.4.bn2.weight', tensor([0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9992, 0.9991, 0.9990, 0.9992, 0.9990, 0.9989, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9992, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9992, 0.9992,\n",
            "        0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9993, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9992, 0.9990, 0.9992, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9992, 0.9992, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.4.bn2.bias', tensor([-3.6393e-05,  5.4411e-05, -3.7425e-05, -5.8207e-05,  7.1260e-05,\n",
            "         1.4236e-06,  4.7035e-05, -1.8176e-05,  1.3840e-05,  1.1760e-04,\n",
            "         5.8930e-05, -5.3959e-05,  6.7873e-05,  5.1282e-05, -1.7515e-05,\n",
            "        -3.3063e-05, -5.2268e-05, -4.9993e-05,  1.6728e-05,  3.8655e-05,\n",
            "        -8.6352e-05,  3.3159e-05, -8.1054e-05,  1.8307e-06,  7.1426e-05,\n",
            "         9.2208e-05, -6.6855e-05, -1.8504e-05,  2.1405e-05, -2.9464e-05,\n",
            "        -7.2605e-05,  1.3834e-05, -1.4086e-05, -5.9720e-05, -6.6382e-05,\n",
            "         7.0796e-07, -8.4244e-05,  1.2880e-06, -8.2705e-05, -2.8592e-06,\n",
            "        -3.2085e-06, -4.3264e-05, -3.7577e-06,  1.5607e-05,  3.2579e-05,\n",
            "         6.1702e-06, -1.2327e-06, -2.7830e-05,  9.5950e-05, -7.2062e-05,\n",
            "         1.4722e-05,  1.1439e-04, -8.8589e-06, -1.8784e-05,  4.1743e-05,\n",
            "         1.5366e-05,  4.8044e-05, -1.6538e-05, -3.6000e-06, -4.4941e-06,\n",
            "        -6.8620e-05, -5.3331e-05,  4.1007e-05,  3.8469e-05, -2.7282e-05,\n",
            "         7.1779e-05, -3.5193e-07, -1.5930e-05,  3.2440e-05, -5.1492e-05,\n",
            "        -2.8342e-07,  1.6906e-05, -3.0170e-05,  5.0589e-05, -2.4793e-05,\n",
            "         4.7332e-05,  2.7612e-05, -2.1748e-05,  9.5989e-06, -5.6626e-08,\n",
            "         1.0011e-05, -5.6372e-05,  1.9743e-05, -7.8247e-05, -1.0015e-04,\n",
            "        -1.9219e-05,  6.8589e-05, -3.8053e-05, -2.4569e-05,  1.3048e-05,\n",
            "         2.9196e-05, -9.0979e-05, -8.9201e-05, -4.5314e-05,  2.4509e-05,\n",
            "        -2.8947e-06, -2.6910e-05, -6.8396e-05,  1.3798e-05,  4.0350e-05,\n",
            "         6.6659e-05, -3.2864e-05, -7.3395e-05, -1.8644e-07, -6.1069e-05,\n",
            "        -2.2147e-05,  1.9760e-05,  3.0990e-05,  2.7002e-05,  4.1222e-05,\n",
            "        -6.9777e-05,  3.2446e-05,  1.8257e-05,  8.2726e-05,  5.3808e-05,\n",
            "        -3.4193e-05, -1.6979e-05,  1.9300e-05,  2.7507e-05,  1.8531e-05,\n",
            "         6.7829e-06, -2.5306e-05, -7.9359e-05, -2.0380e-05, -3.0050e-05,\n",
            "         1.0175e-04, -3.3485e-05, -1.7043e-05, -3.7010e-06,  2.0167e-05,\n",
            "        -1.8119e-05, -4.3651e-05, -3.1503e-05,  1.7484e-05,  5.3630e-05,\n",
            "        -9.2303e-05, -1.1043e-04,  8.4658e-05, -3.6335e-05, -4.3039e-05,\n",
            "         5.1994e-06, -4.6421e-05, -1.0719e-04,  2.2066e-05,  9.1651e-05,\n",
            "        -1.1466e-05, -5.6309e-05, -7.8838e-05,  5.9153e-05,  3.6608e-05,\n",
            "        -2.2144e-05, -2.1837e-05,  3.6494e-05,  6.4597e-05, -2.0905e-05,\n",
            "        -2.2498e-05, -4.9626e-05,  3.9550e-05,  6.4180e-05, -5.8159e-05,\n",
            "         3.8432e-06, -1.2730e-04,  5.8627e-07,  4.7446e-05, -5.3691e-05,\n",
            "        -4.3723e-06, -6.1945e-05, -6.7175e-05, -5.9968e-05, -1.6782e-05,\n",
            "        -1.4852e-05,  3.2126e-05, -5.1124e-05, -2.0247e-05, -1.1267e-04,\n",
            "        -4.2633e-05,  2.3592e-05,  2.4685e-05, -9.1768e-05, -1.5360e-05,\n",
            "         5.0438e-05, -7.0716e-05, -4.9517e-05,  2.0401e-05, -7.4630e-06,\n",
            "        -7.6839e-05,  6.5714e-05,  1.9807e-05,  1.1277e-05,  2.9898e-06,\n",
            "         7.7268e-07, -6.5094e-05, -2.9664e-05, -4.5677e-05,  6.0003e-06,\n",
            "        -1.1561e-04,  5.1263e-05,  1.2314e-05,  4.7896e-05,  3.7913e-05,\n",
            "         1.9972e-05,  9.3430e-05,  3.0333e-05, -6.8769e-05, -7.6832e-05,\n",
            "        -1.2989e-05,  2.9329e-05, -8.1998e-05,  3.7177e-07,  7.5754e-05,\n",
            "        -8.9080e-05, -5.6096e-05,  1.7801e-05, -8.6333e-05, -1.2717e-04,\n",
            "        -5.1622e-05, -1.2438e-05, -5.3468e-05, -1.9842e-05, -9.5313e-05,\n",
            "         3.0044e-05,  1.8278e-05, -4.4435e-05, -5.5878e-06,  1.7818e-05,\n",
            "         8.5876e-05, -7.9950e-05, -6.0989e-07,  8.4407e-05,  3.6646e-05,\n",
            "         4.5466e-06,  1.5050e-05, -1.3304e-05,  1.1607e-04,  1.3636e-04,\n",
            "         9.4847e-05,  1.9575e-05,  3.4846e-05,  2.6979e-06,  1.1340e-04,\n",
            "        -4.9295e-05, -4.4428e-05,  1.6137e-06,  4.0310e-05, -1.8488e-05,\n",
            "         5.1360e-06,  4.3359e-05,  5.9991e-07, -1.3909e-05,  2.9081e-05,\n",
            "         2.4642e-05, -5.6267e-05,  1.1346e-04,  1.4075e-05, -3.1616e-05,\n",
            "         1.0632e-04])), ('module.encoder_k.layer3.4.bn2.running_mean', tensor([-4.8139e-01, -8.6776e-02,  2.7515e-01, -1.3001e-01, -1.8529e-01,\n",
            "        -1.7478e-01, -3.4746e-01,  5.0974e-02,  5.6992e-01,  3.1826e-01,\n",
            "         6.8904e-01, -5.2903e-01,  3.9245e-01,  4.1367e-01, -7.5266e-01,\n",
            "         5.9162e-01,  3.3197e-03, -8.4222e-01,  5.4783e-01, -7.0346e-02,\n",
            "        -1.8922e-02,  5.8136e-01,  5.6910e-01, -5.6111e-02,  2.4273e-01,\n",
            "         9.7598e-01, -5.2985e-01, -8.6142e-01, -3.8495e-02, -3.9145e-01,\n",
            "        -4.1979e-01,  5.3357e-01,  1.8928e-01, -8.8716e-01, -5.1474e-01,\n",
            "         2.4093e-02,  4.2187e-01, -2.1752e-01, -2.9115e-01, -1.3434e-01,\n",
            "        -5.9491e-01, -1.4892e-01, -1.9473e-03,  7.8897e-01,  3.6432e-01,\n",
            "        -2.0440e-01,  3.9401e-01,  2.6899e-01,  1.3174e-01, -3.0174e-01,\n",
            "        -3.3636e-01,  3.2752e-01,  4.9197e-02, -8.0339e-01,  2.1580e-01,\n",
            "        -2.9468e-04,  5.3573e-01,  1.6704e-01, -3.1208e-02,  4.1273e-01,\n",
            "        -1.7739e-01,  1.6298e-01, -1.2910e-01, -4.9190e-02, -2.8548e-01,\n",
            "         1.6700e-01, -6.1958e-01, -6.1557e-01, -4.8586e-01, -3.2530e-01,\n",
            "         1.1358e-01,  2.6705e-01, -1.9965e-01,  3.1769e-01,  7.8472e-02,\n",
            "         4.3932e-02, -4.8607e-01,  1.3425e-01,  6.5607e-02, -5.8279e-01,\n",
            "        -2.3916e-01,  6.6930e-01, -1.1394e-01, -2.9556e-01,  1.1375e-01,\n",
            "        -8.6996e-02, -7.3778e-01,  1.0629e-01, -2.0327e-01, -8.2180e-02,\n",
            "        -2.9107e-01, -2.6049e-01, -1.0168e-01, -6.0016e-01,  1.3387e-01,\n",
            "         7.8176e-01,  1.0035e-01,  2.2206e-01, -2.9712e-01, -1.9916e-01,\n",
            "         2.4811e-01,  2.1901e-01, -2.4091e-01,  5.4036e-01,  2.4075e-01,\n",
            "        -3.2205e-02,  5.9217e-01, -7.8400e-02, -5.5523e-01, -3.0099e-02,\n",
            "         2.6495e-01,  1.8211e-01, -5.2218e-01,  5.0443e-01,  5.0081e-01,\n",
            "         6.4584e-01, -2.3544e-01, -2.4458e-01, -3.5978e-01, -1.1648e+00,\n",
            "         4.9088e-03,  4.1354e-01,  8.4876e-01,  4.4234e-01, -3.7530e-01,\n",
            "        -2.6952e-02,  7.3813e-02,  1.3962e-01, -2.9749e-01,  2.2575e-01,\n",
            "         7.8331e-01,  1.7685e-01,  5.9902e-01, -1.5366e-01,  1.4310e-01,\n",
            "         2.8330e-01, -5.0921e-01, -1.9250e-01, -5.4726e-02, -1.1058e+00,\n",
            "         9.4884e-01, -5.3623e-01, -1.2302e-01,  6.0145e-02, -7.9784e-01,\n",
            "         4.2170e-01,  1.2117e-01,  4.8430e-01, -4.3917e-01, -2.7282e-01,\n",
            "         5.8611e-01,  1.2234e-01, -4.0685e-01,  2.7190e-01,  6.3726e-01,\n",
            "        -1.5889e-01, -2.0995e-01, -1.6408e-01, -1.7440e-01, -2.5831e-01,\n",
            "        -4.6438e-01, -7.9338e-03,  6.6170e-02, -4.4408e-01,  2.2312e-01,\n",
            "         5.2808e-01, -5.0456e-01,  5.4834e-01, -2.7287e-01,  3.4530e-01,\n",
            "        -1.0930e-01,  3.5063e-01,  3.9813e-01,  3.9913e-01,  6.7492e-01,\n",
            "        -1.3539e-01,  2.8631e-01, -1.0253e-01, -2.4788e-01,  7.8886e-01,\n",
            "        -3.0340e-01,  4.2691e-01, -3.5372e-01, -4.4499e-01,  9.3719e-02,\n",
            "         3.2266e-01,  7.4196e-02, -1.7230e-01, -1.7525e-01,  2.8483e-01,\n",
            "        -7.7152e-01, -3.1174e-01, -2.6517e-01,  4.9248e-01, -1.3317e-02,\n",
            "        -8.6211e-02,  7.1274e-01,  4.5842e-01,  6.4348e-01, -1.6639e-01,\n",
            "         5.7139e-02,  3.0385e-01,  4.0062e-01, -5.5416e-01,  2.3256e-02,\n",
            "         6.3555e-01,  4.1976e-01, -2.6987e-01, -2.2879e-01, -1.8917e-01,\n",
            "        -6.7349e-01, -8.9052e-01, -5.1029e-01, -1.3639e-01, -4.9166e-01,\n",
            "         6.0066e-01,  3.9921e-01,  8.1732e-02,  1.5117e+00,  7.2048e-02,\n",
            "         1.9292e-02,  7.6821e-01,  2.7729e-01, -7.0388e-02, -8.1319e-01,\n",
            "        -1.1071e-01,  1.0071e+00,  5.3415e-02, -1.8659e-01,  3.9932e-02,\n",
            "        -2.0247e-01, -1.2307e-01, -6.2654e-01, -5.4784e-01,  3.8856e-01,\n",
            "        -7.1097e-01, -8.5837e-01,  1.6538e-01, -3.2353e-01, -4.2112e-01,\n",
            "        -3.4688e-01,  1.1213e-01, -3.5183e-01,  2.3691e-01, -4.2099e-02,\n",
            "        -7.3082e-01, -9.1284e-01,  1.0091e+00,  1.4461e-01,  8.9361e-01,\n",
            "         7.5321e-02,  2.4127e-01, -2.0138e-02, -1.5082e-01,  2.5637e-01,\n",
            "         5.4573e-01])), ('module.encoder_k.layer3.4.bn2.running_var', tensor([0.6107, 0.5818, 0.6335, 0.5453, 0.7693, 0.5837, 0.7717, 0.6225, 0.7386,\n",
            "        0.8009, 0.5610, 0.6729, 0.5846, 0.5224, 1.2501, 0.8070, 0.5395, 0.6497,\n",
            "        0.5268, 0.6107, 0.8393, 1.0888, 0.9132, 0.5849, 0.5874, 0.7750, 0.5857,\n",
            "        0.5573, 0.5444, 0.7305, 0.9187, 0.5749, 0.7658, 0.6811, 1.4044, 0.5108,\n",
            "        0.6036, 0.6176, 0.8826, 0.7435, 0.5895, 0.6545, 0.5861, 0.8056, 0.7047,\n",
            "        1.0961, 0.8421, 1.0284, 0.5093, 0.5421, 0.5809, 0.5519, 0.8424, 0.5362,\n",
            "        0.6220, 0.5803, 0.8921, 0.6333, 0.8602, 0.6013, 0.5461, 0.6234, 0.6829,\n",
            "        0.5534, 1.3476, 0.5576, 0.7701, 1.5978, 0.5965, 0.7240, 0.5565, 0.6685,\n",
            "        0.7085, 0.7741, 0.5407, 0.5277, 0.5800, 0.6600, 0.5335, 0.5865, 0.7927,\n",
            "        0.6296, 0.6154, 0.6362, 0.6328, 0.6930, 0.6188, 0.5341, 0.8925, 0.5478,\n",
            "        0.8100, 1.1054, 0.6365, 0.6229, 0.5474, 1.1986, 0.7697, 0.5565, 0.5130,\n",
            "        0.7353, 0.9310, 0.5804, 0.6020, 0.8212, 0.6071, 0.6005, 0.6032, 0.7067,\n",
            "        0.6060, 0.5310, 0.6839, 0.9858, 0.5737, 0.5778, 0.6400, 0.7135, 0.9652,\n",
            "        0.6257, 0.5479, 1.1508, 0.5836, 0.7307, 0.7713, 1.1082, 0.5367, 0.5141,\n",
            "        0.6580, 0.5319, 0.7753, 0.5715, 1.6676, 0.7655, 1.3156, 0.5739, 0.5736,\n",
            "        0.6994, 0.5370, 0.5905, 0.6729, 0.9558, 2.1819, 0.5156, 0.6222, 0.6833,\n",
            "        1.8275, 0.6098, 0.5693, 0.9008, 0.6446, 0.5536, 0.8388, 0.6339, 0.9466,\n",
            "        0.5593, 0.7011, 0.5712, 0.6236, 1.0533, 0.5435, 0.5281, 0.8908, 0.6199,\n",
            "        0.5429, 0.6374, 0.5425, 0.6341, 0.7091, 0.5556, 0.5890, 0.6051, 0.6681,\n",
            "        1.4351, 0.9028, 0.4750, 0.5662, 0.7564, 0.8630, 0.5136, 0.5943, 1.5456,\n",
            "        0.6694, 0.6043, 0.5806, 0.5242, 0.6502, 0.5950, 0.5617, 0.7781, 0.5361,\n",
            "        0.6040, 1.0639, 0.5955, 0.6360, 0.6762, 0.8114, 0.8167, 1.3093, 0.6297,\n",
            "        0.5886, 0.7679, 0.6132, 0.6168, 0.5537, 0.8026, 0.8407, 1.2134, 0.7125,\n",
            "        0.8877, 1.0307, 0.5601, 0.6499, 0.6965, 1.0897, 0.5475, 0.4854, 0.6436,\n",
            "        0.6265, 0.5429, 1.4440, 0.5600, 0.7180, 1.2029, 0.7250, 0.6473, 0.8155,\n",
            "        0.5717, 1.4679, 0.7446, 0.8621, 0.6614, 0.5993, 0.7287, 0.6708, 0.6070,\n",
            "        1.1586, 0.6460, 0.5887, 0.6410, 0.5964, 0.5746, 0.5323, 0.6893, 0.8017,\n",
            "        0.5071, 0.5896, 0.8204, 0.7577, 0.7007, 0.7182, 1.4070, 0.6736, 0.5374,\n",
            "        1.1635, 0.5838, 0.5474, 0.6683])), ('module.encoder_k.layer3.4.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.4.conv3.weight', tensor([[[[ 0.0533]],\n",
            "\n",
            "         [[ 0.0062]],\n",
            "\n",
            "         [[-0.0330]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0251]],\n",
            "\n",
            "         [[-0.0163]],\n",
            "\n",
            "         [[ 0.0813]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458]],\n",
            "\n",
            "         [[-0.0163]],\n",
            "\n",
            "         [[-0.0153]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0444]],\n",
            "\n",
            "         [[ 0.0007]],\n",
            "\n",
            "         [[ 0.0175]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0558]],\n",
            "\n",
            "         [[-0.0188]],\n",
            "\n",
            "         [[-0.1094]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0500]],\n",
            "\n",
            "         [[ 0.0024]],\n",
            "\n",
            "         [[-0.0677]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0474]],\n",
            "\n",
            "         [[ 0.0037]],\n",
            "\n",
            "         [[ 0.0103]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0151]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[ 0.0339]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004]],\n",
            "\n",
            "         [[ 0.0458]],\n",
            "\n",
            "         [[ 0.0241]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0317]],\n",
            "\n",
            "         [[-0.0448]]],\n",
            "\n",
            "\n",
            "        [[[-0.0619]],\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         [[-0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0026]],\n",
            "\n",
            "         [[ 0.0654]],\n",
            "\n",
            "         [[-0.0060]]]])), ('module.encoder_k.layer3.4.bn3.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.4.bn3.bias', tensor([ 4.0299e-06,  3.4476e-05,  3.3189e-06,  ..., -5.6845e-06,\n",
            "         2.6867e-06, -3.0009e-05])), ('module.encoder_k.layer3.4.bn3.running_mean', tensor([ 0.1541, -0.1608, -0.0377,  ...,  0.0588,  0.1040,  0.0067])), ('module.encoder_k.layer3.4.bn3.running_var', tensor([0.1677, 0.1499, 0.1911,  ..., 0.2138, 0.1508, 0.1538])), ('module.encoder_k.layer3.4.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.5.conv1.weight', tensor([[[[-0.1066]],\n",
            "\n",
            "         [[ 0.1121]],\n",
            "\n",
            "         [[ 0.0470]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0812]],\n",
            "\n",
            "         [[ 0.1370]],\n",
            "\n",
            "         [[ 0.1746]]],\n",
            "\n",
            "\n",
            "        [[[-0.1406]],\n",
            "\n",
            "         [[-0.0673]],\n",
            "\n",
            "         [[ 0.0400]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0285]],\n",
            "\n",
            "         [[ 0.1879]],\n",
            "\n",
            "         [[-0.1279]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0188]],\n",
            "\n",
            "         [[ 0.1146]],\n",
            "\n",
            "         [[-0.0615]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0493]],\n",
            "\n",
            "         [[-0.0556]],\n",
            "\n",
            "         [[ 0.0722]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0765]],\n",
            "\n",
            "         [[ 0.0381]],\n",
            "\n",
            "         [[ 0.0336]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0615]],\n",
            "\n",
            "         [[ 0.1616]],\n",
            "\n",
            "         [[-0.0813]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0117]],\n",
            "\n",
            "         [[-0.2283]],\n",
            "\n",
            "         [[ 0.1022]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0465]],\n",
            "\n",
            "         [[-0.0363]],\n",
            "\n",
            "         [[-0.0228]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0860]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0595]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1141]],\n",
            "\n",
            "         [[-0.0255]],\n",
            "\n",
            "         [[-0.1197]]]])), ('module.encoder_k.layer3.5.bn1.weight', tensor([0.9991, 0.9993, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9989, 0.9991, 0.9990,\n",
            "        0.9989, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9992, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9993, 0.9990,\n",
            "        0.9992, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9989, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9990, 0.9990, 0.9991, 0.9992, 0.9990, 0.9989, 0.9992, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9989, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9993, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer3.5.bn1.bias', tensor([-3.4451e-05,  1.9277e-04, -8.6607e-05, -7.4146e-05,  5.1892e-05,\n",
            "         5.3019e-05,  5.5327e-05, -1.9878e-05, -1.1284e-04, -1.0331e-05,\n",
            "        -1.2782e-04,  1.3122e-04,  4.3411e-05, -1.1192e-04,  1.1995e-06,\n",
            "        -2.1488e-05,  1.4049e-04, -1.0080e-05, -3.1834e-05, -7.0419e-05,\n",
            "        -5.0463e-05, -1.5292e-05, -7.0626e-05,  4.8336e-05, -3.5004e-05,\n",
            "         8.4782e-05,  8.6332e-05,  1.1366e-04, -8.2284e-06, -4.2068e-05,\n",
            "         4.1038e-05, -6.6189e-05,  2.5628e-05, -3.1910e-05,  1.3274e-04,\n",
            "         2.1926e-05, -3.3034e-05,  2.7786e-05, -1.6780e-05,  1.6228e-06,\n",
            "        -5.5574e-05, -1.7702e-05, -1.2930e-04, -9.1014e-06, -8.3821e-05,\n",
            "        -1.3946e-04,  1.1735e-04,  3.8722e-05, -5.1708e-05, -2.3352e-05,\n",
            "         3.0019e-05,  3.4902e-05, -3.5138e-05, -5.0520e-06,  6.1219e-05,\n",
            "         1.4721e-05,  1.7462e-04,  5.5713e-05, -7.0615e-05,  1.7555e-05,\n",
            "         5.9986e-05, -4.4226e-05, -5.1633e-05,  3.6643e-05, -7.7862e-05,\n",
            "        -2.8695e-05,  3.2101e-05,  1.9920e-06, -9.5978e-05, -5.2717e-06,\n",
            "         3.8820e-05, -4.4456e-05,  6.4955e-05,  1.0511e-04,  2.5526e-05,\n",
            "        -1.1462e-05, -2.7507e-05, -5.1436e-05, -2.8648e-05,  7.8727e-05,\n",
            "         5.8650e-05, -1.2391e-04,  5.6785e-05,  3.8741e-05,  6.2285e-05,\n",
            "         7.8970e-06, -4.1366e-05,  6.7558e-05,  7.0312e-06, -5.9121e-05,\n",
            "         3.3659e-06,  8.0433e-05, -6.9062e-05, -9.7886e-06, -3.9762e-05,\n",
            "        -6.6081e-06, -1.9134e-05, -2.9893e-05,  2.4245e-05,  3.4396e-05,\n",
            "        -1.0739e-05, -4.2997e-05,  6.2187e-05,  1.4510e-05,  6.9200e-05,\n",
            "        -5.0173e-05,  2.5910e-04,  6.1787e-06,  6.1533e-05,  9.1941e-05,\n",
            "        -4.9309e-05, -1.0983e-04, -2.9367e-05, -1.7114e-04, -3.6622e-05,\n",
            "         5.1891e-05, -2.5167e-05, -9.7906e-05, -4.1534e-05,  5.9571e-05,\n",
            "        -6.6910e-05,  4.0852e-05, -3.3261e-05,  2.9742e-06,  3.9750e-05,\n",
            "        -3.9187e-06, -2.3683e-06, -2.4977e-05, -6.8714e-05, -4.9874e-05,\n",
            "         1.6167e-05, -4.0375e-05,  1.4322e-05, -3.7078e-05,  4.3396e-06,\n",
            "         3.7227e-05,  4.2199e-05, -2.8609e-05,  2.0135e-05,  1.2800e-05,\n",
            "         5.0912e-05, -8.6899e-05, -5.3487e-05, -5.5884e-06, -1.1469e-04,\n",
            "        -9.3528e-05,  1.2788e-05, -7.8444e-05, -1.6634e-06,  1.2406e-04,\n",
            "         1.4924e-04,  1.1280e-05, -3.4504e-05, -1.6851e-05,  1.9291e-05,\n",
            "         4.1102e-05, -1.6839e-05,  4.5941e-06,  3.5156e-05, -6.5573e-05,\n",
            "         9.6597e-06,  1.1263e-04, -6.8040e-05, -1.8493e-05,  6.1505e-06,\n",
            "         8.7033e-05, -5.1026e-06,  1.3227e-06,  1.5990e-04,  1.9031e-04,\n",
            "        -7.9287e-05, -7.0284e-06,  1.1612e-05, -3.2890e-05, -4.4130e-05,\n",
            "         1.5889e-05, -5.8283e-05,  3.6689e-05, -6.5645e-05,  4.3870e-05,\n",
            "        -4.2649e-05, -2.6853e-06, -5.2660e-06, -7.6118e-05, -1.0450e-04,\n",
            "         6.8749e-06, -1.7396e-04, -7.2525e-05, -2.1459e-05, -9.4079e-06,\n",
            "        -1.3363e-05,  1.4196e-05, -2.0988e-05, -5.5093e-05, -8.6457e-05,\n",
            "         7.3391e-05, -5.4945e-05,  6.4706e-05,  9.7681e-05, -2.1734e-06,\n",
            "        -6.9818e-05,  7.0247e-05, -6.1891e-05, -1.4610e-04,  2.0221e-05,\n",
            "         1.5574e-04,  6.4906e-05, -2.7858e-05, -1.6894e-05, -3.2377e-05,\n",
            "         5.5498e-05, -5.7805e-07, -1.4272e-05, -4.7885e-05,  4.4565e-06,\n",
            "         4.5470e-05,  1.8482e-05,  2.2156e-05,  2.6707e-05,  1.0518e-04,\n",
            "        -3.4670e-05,  1.1668e-05,  7.5974e-05, -4.6064e-05, -5.4915e-05,\n",
            "         9.6201e-06,  6.2413e-05,  2.5676e-05,  4.3668e-05, -3.2245e-05,\n",
            "         2.5160e-06,  2.8234e-05,  9.2586e-05,  7.5315e-06, -2.7647e-05,\n",
            "         8.1783e-05, -5.3688e-06, -4.5334e-05, -4.5945e-05,  3.2919e-05,\n",
            "         1.2655e-05, -3.6694e-05,  7.4800e-05, -1.1340e-04, -2.5877e-05,\n",
            "         1.3920e-05, -7.1343e-08, -4.8136e-05, -8.0498e-05,  8.3444e-05,\n",
            "         1.3655e-04,  1.6388e-05, -2.9329e-06,  1.5866e-05,  5.8148e-05,\n",
            "         2.5808e-05])), ('module.encoder_k.layer3.5.bn1.running_mean', tensor([-2.6160, -0.2572,  7.5020, -2.8614, -0.7414, -0.7409,  3.1965,  0.4669,\n",
            "         3.4500,  2.2158,  2.7870,  3.3896,  1.2342, -2.9628,  0.3150, -4.7140,\n",
            "        -0.6605,  1.5281,  2.0325, -2.2382, -3.6722, -1.4614, -3.3277, -3.6041,\n",
            "        -1.8512, -4.1124, -0.1312, -1.9460,  1.6773, -1.8269,  1.3714,  1.9641,\n",
            "         3.0190,  0.4497,  3.5554,  2.2700,  3.5652, -4.1225, -5.5043,  5.2030,\n",
            "         0.4005,  2.5675,  1.3610, -1.1185,  2.4994,  1.0239, -5.1018, -1.0427,\n",
            "         0.5198,  2.5583, -0.3070,  4.2388,  5.8024,  5.1407,  1.3427, -2.1651,\n",
            "         8.2070, -3.7922,  0.0368,  4.0891, -1.2034,  0.0731, -2.1354,  2.1945,\n",
            "         1.9375, -0.4638,  8.6655,  0.4786,  4.7439,  2.2703,  1.5077, -1.3785,\n",
            "         3.2157,  3.6567, -2.5761,  4.0617,  7.0703,  0.0172,  4.5271, -0.9937,\n",
            "        -0.4797, -1.8845, -0.9069,  0.1120, -5.2269,  1.0314,  6.4836, -3.9937,\n",
            "        -2.1209, -1.7575, -2.5999,  3.7425,  0.3416,  1.0274, -2.1631,  2.9617,\n",
            "        -0.9363, -3.4987,  1.2470,  0.5558,  0.2936, -0.5316, -2.6257, -3.0969,\n",
            "        -0.3207,  3.3405, -2.7254, -1.8423, -1.2118, -3.1780,  0.2931, -4.8883,\n",
            "         4.1815,  2.7696,  1.7236,  3.7081,  1.7225,  0.9229,  7.2803,  3.6784,\n",
            "        -5.1877,  0.7661, -4.0514,  4.9911, -3.3338, -3.4093, -1.1568,  1.2792,\n",
            "        -4.8108,  2.1514,  5.1802,  4.0512, -1.2742, -1.6679,  2.6960, -3.5517,\n",
            "         4.9839,  2.5555, -1.6313,  2.6995,  1.7439,  5.9071,  4.7977,  2.4559,\n",
            "        -4.9170,  1.9521,  1.0184, -2.4734,  1.6191,  3.4459, -5.8129,  4.2674,\n",
            "        -0.1179, -2.0255,  8.7253, -3.3249, -2.3299,  0.6721,  1.2893,  0.0683,\n",
            "        -6.7600,  1.7027,  0.1680,  0.3096,  3.5725, -3.9215,  1.8166, -2.6103,\n",
            "         4.0483, -1.0204,  3.9843, -2.6890,  1.0606,  0.4635,  6.3278, -1.1265,\n",
            "        -1.7614,  0.5722, -3.5098,  5.2985,  3.3069, -0.1740, -1.3188, -4.8600,\n",
            "        -1.3474,  2.3752, -1.0900, -1.1172,  1.0817,  2.0483,  0.3212, -0.2104,\n",
            "         0.0542, -8.8009, -3.0228,  4.6369,  2.6914, -7.4131, -6.7292, -2.0073,\n",
            "         6.6308,  1.1401, -3.4852,  9.7732,  4.4500,  1.8623,  3.0480,  1.2787,\n",
            "        -2.4728,  2.4059, -1.1845,  0.1415, -1.2734,  4.3608,  5.3297, -1.6367,\n",
            "        -1.4490, -4.1949, -1.9386,  3.7997,  0.5235, -4.1398,  6.5737, -3.5122,\n",
            "        -1.3255,  2.4366,  7.7724, -0.2315,  1.9309,  0.5625, -2.4913, -6.8473,\n",
            "        -4.0990,  2.8290,  2.7195,  5.4377, -4.1135, -5.7458,  1.6999, -0.5171,\n",
            "         0.0826, -2.7892, -0.4130, -3.9423,  1.3423, -4.3373, -2.7179,  0.3159,\n",
            "         2.7140,  2.5910,  7.5844,  4.1806,  4.7287,  1.7910, -4.3255,  2.1530])), ('module.encoder_k.layer3.5.bn1.running_var', tensor([15.6025, 15.4124, 33.7136, 18.3561, 14.1249, 17.2138, 17.0216, 15.8668,\n",
            "        28.3380, 20.0194, 20.5540, 14.5952, 17.8917, 33.8768, 14.6377, 19.9848,\n",
            "        16.0235, 14.8095, 13.4979, 14.8658, 15.8009, 14.8868, 25.9000, 17.7761,\n",
            "        16.6069, 16.8110, 14.0533, 23.7881, 14.7491, 15.1466, 14.6117, 13.5667,\n",
            "        14.0713, 13.8420, 17.5728, 20.8286, 22.8550, 27.0755, 25.1613, 29.7573,\n",
            "        13.0905, 14.6874, 13.9259, 13.4179, 14.6287, 13.0519, 36.6873, 15.5938,\n",
            "        15.4802, 16.0572, 18.0975, 23.7627, 23.5672, 72.6861, 14.6236, 13.2016,\n",
            "        28.5060, 17.0145, 16.2600, 15.8258, 25.3397, 12.2991, 12.4715, 13.7003,\n",
            "        15.3831, 13.1008, 51.8080, 15.3758, 26.1449, 14.3587, 14.7187, 13.7398,\n",
            "        23.2871, 21.9480, 15.6192, 21.8943, 34.5716, 14.2173, 16.3797, 15.1751,\n",
            "        15.7707, 13.6090, 13.5175, 15.2548, 31.4534, 19.6384, 18.2765, 20.1230,\n",
            "        15.1838, 16.6702, 13.5668, 14.6331, 16.1794, 17.1105, 27.3226, 15.0270,\n",
            "        12.8966, 32.7030, 18.6200, 21.8954, 15.1781, 13.7892, 17.5198, 24.6238,\n",
            "        20.0806, 13.6888, 17.0070, 19.2225, 15.1249, 14.9991, 15.4191, 16.3265,\n",
            "        15.5658, 16.8259, 17.8830, 20.9054, 20.4206, 28.5067, 45.7208, 18.4706,\n",
            "        28.1771, 15.0163, 23.7591, 45.8742, 16.7917, 45.5954, 15.9955, 14.5363,\n",
            "        35.6271, 13.3022, 22.1446, 24.9682, 23.8532, 16.3496, 19.2372, 40.1857,\n",
            "        19.5802, 26.3853, 18.5137, 13.2632, 14.1707, 44.0569, 26.6211, 40.6496,\n",
            "        19.2620, 15.3533, 18.7040, 16.7558, 17.5931, 13.1481, 14.6076, 23.6040,\n",
            "        15.6848, 19.3981, 31.0148, 17.6470, 16.6488, 13.4289, 13.8759, 14.4842,\n",
            "        31.0500, 18.6354, 15.4521, 12.9724, 23.0932, 19.2760, 19.8268, 17.5417,\n",
            "        21.1858, 17.9041, 38.5409, 15.1537, 20.3898, 19.4417, 17.4805, 14.3085,\n",
            "        13.9645, 15.9049, 43.2880, 23.4688, 12.6999, 16.5256, 14.9176, 24.1422,\n",
            "        30.1365, 26.2308, 15.6641, 15.7835, 14.9977, 15.5267, 23.0523, 15.4044,\n",
            "        16.4215, 50.6227, 14.6203, 24.7671, 15.4100, 46.9014, 45.0645, 17.5039,\n",
            "        51.7777, 13.2312, 16.4177, 53.7527, 18.8715, 14.4008, 20.6547, 18.5489,\n",
            "        20.5004, 21.0047, 12.5165, 13.6156, 14.2575, 17.7959, 57.0777, 18.0926,\n",
            "        14.5889, 28.1151, 16.9993, 31.9097, 13.9472, 14.2710, 66.3016, 20.3400,\n",
            "        15.0936, 22.7845, 32.9342, 13.0945, 14.3177, 13.5769, 18.2583, 52.4612,\n",
            "        14.1158, 25.2391, 14.8540, 28.0845, 15.0786, 37.3133, 19.6815, 15.0551,\n",
            "        14.4789, 24.5037, 13.1070, 15.1622, 14.7697, 29.3907, 18.4026, 15.6817,\n",
            "        29.8983, 17.0885, 63.7852, 20.2017, 24.7575, 14.5681, 34.9676, 13.0808])), ('module.encoder_k.layer3.5.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.5.conv2.weight', tensor([[[[-2.8271e-02,  3.4389e-02,  2.1198e-02],\n",
            "          [ 2.5239e-02, -6.6532e-03,  2.6124e-02],\n",
            "          [ 2.4573e-02,  2.2058e-03, -2.5459e-02]],\n",
            "\n",
            "         [[-5.0940e-02, -3.2475e-02, -1.3798e-02],\n",
            "          [-4.7729e-02,  1.1924e-02,  4.0800e-02],\n",
            "          [ 3.7894e-03, -2.2264e-02, -2.9354e-02]],\n",
            "\n",
            "         [[ 7.5495e-03, -2.7000e-03, -1.1475e-02],\n",
            "          [-1.9546e-02,  4.8108e-02, -2.5181e-02],\n",
            "          [-6.6664e-03,  1.2943e-02, -6.8417e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.9537e-02,  3.6958e-02,  9.2540e-03],\n",
            "          [-6.0922e-03,  3.7982e-02,  7.3585e-02],\n",
            "          [-4.0712e-03, -2.4090e-02, -8.5210e-04]],\n",
            "\n",
            "         [[ 3.8688e-02, -1.7370e-02,  1.1482e-02],\n",
            "          [ 4.9917e-02,  1.9726e-02,  5.4259e-03],\n",
            "          [-5.0984e-02,  1.6000e-02, -7.5762e-03]],\n",
            "\n",
            "         [[-2.7131e-02,  3.4348e-03,  2.2884e-02],\n",
            "          [ 2.6490e-02, -3.8981e-02, -1.3728e-02],\n",
            "          [-2.8156e-02,  2.1543e-02,  2.1688e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3462e-02, -1.9303e-03,  1.6976e-02],\n",
            "          [ 6.3879e-02, -3.3313e-02,  1.6742e-02],\n",
            "          [-1.4926e-02,  1.2444e-02,  3.0178e-02]],\n",
            "\n",
            "         [[ 2.2038e-02, -3.5361e-03, -1.1304e-02],\n",
            "          [ 1.1003e-02, -2.2080e-02,  5.2066e-02],\n",
            "          [ 4.1071e-02, -3.4092e-02,  2.8021e-02]],\n",
            "\n",
            "         [[-3.0513e-02,  7.6324e-03,  8.5281e-03],\n",
            "          [ 1.1784e-02, -4.1876e-02,  1.9627e-02],\n",
            "          [ 2.9184e-02, -6.3731e-02, -2.1386e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6654e-02, -5.9941e-02,  2.9067e-02],\n",
            "          [ 4.6850e-03, -6.8427e-02, -1.6294e-02],\n",
            "          [ 1.6107e-02,  3.2800e-02,  2.2420e-02]],\n",
            "\n",
            "         [[ 1.3483e-02,  1.5451e-02,  2.3744e-02],\n",
            "          [ 5.1985e-03, -3.2350e-03, -7.4095e-03],\n",
            "          [ 2.7313e-02, -1.8893e-02, -3.9952e-02]],\n",
            "\n",
            "         [[ 4.6767e-02,  1.9827e-02, -2.3901e-05],\n",
            "          [ 1.3107e-02, -1.6672e-02,  5.4966e-02],\n",
            "          [ 3.0589e-02,  1.6939e-03, -2.6995e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.8951e-03, -2.4022e-02,  2.0603e-02],\n",
            "          [-1.9049e-02,  1.0752e-02,  2.6633e-02],\n",
            "          [-3.0419e-02,  1.3593e-02,  6.6192e-03]],\n",
            "\n",
            "         [[-2.9961e-02,  3.1480e-02, -1.0257e-02],\n",
            "          [-2.2958e-02,  1.5360e-02,  5.4580e-02],\n",
            "          [ 5.0782e-02,  1.4663e-02,  1.5188e-03]],\n",
            "\n",
            "         [[ 9.5540e-03, -2.5416e-02,  5.1365e-03],\n",
            "          [-2.3798e-02, -2.8108e-02, -5.5910e-02],\n",
            "          [-1.3070e-03, -5.6812e-02,  1.6348e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.8171e-02, -6.7250e-03, -1.9977e-02],\n",
            "          [ 3.7503e-02, -2.0655e-02,  1.2346e-02],\n",
            "          [ 5.0750e-02, -9.9624e-03, -2.4181e-02]],\n",
            "\n",
            "         [[ 4.3287e-02,  1.3266e-02,  4.0460e-02],\n",
            "          [-5.0701e-02,  5.0500e-02, -1.7449e-02],\n",
            "          [ 1.7765e-03,  5.4373e-04,  5.2753e-04]],\n",
            "\n",
            "         [[-1.1008e-02,  1.0217e-02,  2.5270e-02],\n",
            "          [ 2.3617e-02, -6.4142e-03, -2.4394e-02],\n",
            "          [-7.6947e-03, -3.5207e-02,  3.4418e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.1817e-02, -3.8925e-02,  3.4002e-02],\n",
            "          [-2.7746e-02, -2.6576e-02,  1.2465e-02],\n",
            "          [-1.8937e-02,  2.2461e-03,  3.7981e-02]],\n",
            "\n",
            "         [[-1.4099e-02,  5.7213e-02,  2.7472e-03],\n",
            "          [ 4.0377e-02,  5.2688e-02,  1.7321e-02],\n",
            "          [-5.2528e-03,  2.6180e-02,  1.9820e-04]],\n",
            "\n",
            "         [[-1.4869e-02, -6.2699e-02,  1.5195e-02],\n",
            "          [-1.1843e-03,  1.9919e-02,  1.1969e-02],\n",
            "          [-5.7784e-02, -1.5894e-02, -2.1529e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3729e-02, -4.4451e-02, -2.1915e-02],\n",
            "          [ 9.3294e-03,  4.0092e-02, -6.0489e-02],\n",
            "          [ 1.3874e-02,  2.4821e-03, -2.4393e-02]],\n",
            "\n",
            "         [[-3.7151e-02,  1.9437e-02, -5.7072e-02],\n",
            "          [ 2.5590e-02,  4.4382e-02,  6.7721e-03],\n",
            "          [ 2.5837e-02,  2.3510e-02, -3.4722e-02]],\n",
            "\n",
            "         [[-1.1425e-03,  2.6292e-02,  4.5809e-02],\n",
            "          [-4.1691e-02,  3.9042e-03,  2.3075e-02],\n",
            "          [ 4.6274e-03,  3.2648e-02,  4.1148e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9390e-03, -6.0878e-02,  1.4825e-02],\n",
            "          [ 1.8059e-02,  3.8105e-02,  1.5563e-02],\n",
            "          [-5.2293e-02, -3.1538e-02, -2.2036e-02]],\n",
            "\n",
            "         [[ 8.7898e-03, -1.0386e-02,  9.6166e-03],\n",
            "          [-4.5478e-02, -2.9598e-03,  7.2147e-03],\n",
            "          [-5.8980e-03, -3.6918e-02,  1.6076e-02]],\n",
            "\n",
            "         [[ 2.3011e-02,  7.7019e-03,  4.2038e-02],\n",
            "          [ 1.0387e-03,  2.6759e-02, -1.3418e-02],\n",
            "          [-8.0930e-03, -5.8055e-02, -7.4852e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6039e-02, -4.9358e-04, -1.0859e-02],\n",
            "          [-3.2037e-02, -2.1582e-02, -2.8236e-02],\n",
            "          [-2.5897e-02,  4.6769e-02,  7.2091e-03]],\n",
            "\n",
            "         [[ 3.7384e-02, -3.0088e-02,  2.2544e-02],\n",
            "          [-2.8522e-02, -8.9911e-03, -2.5440e-02],\n",
            "          [ 1.8308e-02, -6.1392e-03,  1.2990e-02]],\n",
            "\n",
            "         [[-3.0135e-02, -2.2745e-02,  7.0464e-03],\n",
            "          [-2.7946e-02, -2.5857e-02, -2.1259e-02],\n",
            "          [-9.3402e-04, -1.3971e-02, -1.7882e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6502e-02,  2.3415e-02,  2.3222e-02],\n",
            "          [ 2.9519e-02,  1.7185e-02,  3.8055e-02],\n",
            "          [-1.1255e-02,  5.0929e-02,  2.1038e-03]],\n",
            "\n",
            "         [[ 2.5895e-03, -2.0686e-03,  2.9853e-02],\n",
            "          [ 6.5986e-03,  6.6278e-02, -3.3007e-02],\n",
            "          [-2.3520e-02,  7.5561e-04, -1.0950e-02]],\n",
            "\n",
            "         [[-3.1691e-02,  2.7880e-02, -4.5735e-05],\n",
            "          [ 5.0931e-02, -1.4780e-02,  9.1634e-03],\n",
            "          [-1.4705e-04, -2.9407e-02, -3.3482e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7036e-02, -4.1441e-04,  1.8722e-02],\n",
            "          [ 9.0421e-03, -2.0972e-02, -2.3410e-02],\n",
            "          [-3.5092e-03,  2.6411e-02,  1.6826e-02]],\n",
            "\n",
            "         [[-7.4147e-03, -4.1041e-02, -1.4812e-03],\n",
            "          [ 4.2037e-02, -1.8689e-02,  4.0193e-02],\n",
            "          [-6.0643e-04, -3.3962e-02, -1.6480e-02]],\n",
            "\n",
            "         [[-5.2177e-02, -1.4754e-02, -1.2286e-02],\n",
            "          [-8.3585e-02, -2.9463e-02, -2.9688e-02],\n",
            "          [ 2.3549e-02,  3.0687e-03,  3.4436e-02]]]])), ('module.encoder_k.layer3.5.bn2.weight', tensor([0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9992, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9989, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9993, 0.9992, 0.9991, 0.9990, 0.9992, 0.9990, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991])), ('module.encoder_k.layer3.5.bn2.bias', tensor([ 4.6828e-07, -1.9349e-05, -4.4428e-05,  5.5844e-05, -9.7005e-05,\n",
            "         1.9976e-05,  4.1405e-05,  3.8526e-06, -5.6585e-06,  3.8853e-05,\n",
            "        -7.0074e-05,  6.3740e-05,  7.1007e-05, -4.3067e-05,  5.0860e-05,\n",
            "        -4.1361e-05,  1.1621e-05,  7.3454e-05, -2.5597e-05, -1.6544e-05,\n",
            "         3.9948e-05, -5.4386e-05, -9.6960e-06,  1.0461e-04,  1.0467e-05,\n",
            "         8.9842e-05,  3.0590e-06, -1.0858e-05, -4.7687e-05, -1.6789e-05,\n",
            "        -5.7807e-06,  4.1882e-05,  7.6177e-05,  2.3555e-05, -3.1856e-05,\n",
            "         1.0049e-05,  7.0454e-05, -1.5151e-04, -8.8103e-05,  3.0356e-05,\n",
            "         5.5822e-05,  1.2147e-04, -2.1513e-05,  1.0052e-05, -3.8375e-05,\n",
            "        -1.2521e-04,  2.2199e-05,  2.7881e-05, -1.7432e-05,  4.4823e-05,\n",
            "         1.7611e-04, -6.5130e-05, -2.1178e-05,  1.9561e-05, -1.8086e-05,\n",
            "        -3.3827e-05,  1.9735e-05, -1.7908e-05,  5.4260e-06, -7.9435e-06,\n",
            "        -7.1241e-05, -4.1721e-06, -6.6128e-06,  4.4171e-05, -3.5588e-05,\n",
            "         4.8167e-05,  1.0099e-05,  1.7343e-06, -5.9918e-05,  8.6734e-05,\n",
            "        -3.2301e-05,  3.9933e-05, -5.9993e-05,  2.3607e-05,  7.5633e-05,\n",
            "         3.2210e-05,  1.2164e-04,  3.4625e-05, -1.4401e-05, -3.0256e-05,\n",
            "         2.5695e-05,  4.3251e-05,  1.2386e-05, -5.0949e-05,  7.8584e-05,\n",
            "         3.6961e-05,  4.8008e-05, -1.2333e-04,  2.5471e-05, -8.9984e-05,\n",
            "        -1.2165e-05, -3.6846e-06, -1.1655e-05, -1.2758e-05, -1.0509e-05,\n",
            "         1.5564e-05, -2.1174e-05, -3.1805e-06, -2.5185e-05,  2.6231e-05,\n",
            "        -6.1764e-05, -9.8198e-05, -5.8942e-05, -5.7316e-05, -7.1101e-05,\n",
            "        -4.5561e-05, -1.3294e-05, -1.1832e-05, -6.1510e-06,  5.0474e-05,\n",
            "         3.2662e-05, -6.8626e-05,  4.9085e-05, -3.4883e-05,  3.1059e-05,\n",
            "        -4.9405e-05,  1.2509e-05,  7.0550e-06,  5.2921e-05, -2.7216e-05,\n",
            "        -4.7923e-05, -6.2021e-06, -1.3361e-06, -9.8660e-05,  5.8845e-05,\n",
            "         1.1423e-05, -1.7335e-05, -2.1968e-05, -6.1327e-05, -9.9287e-05,\n",
            "        -7.3035e-05, -1.1717e-04,  4.6927e-05,  1.0788e-04, -3.6252e-05,\n",
            "         1.0243e-06,  4.7266e-05,  1.2201e-04,  2.6711e-05, -2.7858e-05,\n",
            "         2.6444e-06,  2.3005e-05,  9.0426e-06, -1.5452e-04, -6.3122e-05,\n",
            "         1.4392e-04,  2.1066e-05, -2.5796e-05, -3.5985e-05,  3.6295e-05,\n",
            "        -2.3280e-05,  1.1837e-05, -8.5761e-06, -3.7709e-05,  4.0027e-05,\n",
            "         4.1884e-05,  1.6666e-05, -2.5389e-05, -1.1922e-05,  8.5705e-05,\n",
            "        -6.2217e-06, -9.6900e-05, -4.2583e-05,  5.4759e-05,  3.4509e-06,\n",
            "        -3.4646e-05, -7.5654e-06, -8.8387e-06, -4.2869e-06, -9.5212e-05,\n",
            "         7.2869e-05,  1.8521e-05, -5.1403e-05,  1.2456e-05,  2.1642e-05,\n",
            "         7.3198e-05,  6.5100e-06, -3.1157e-06, -5.5216e-06, -8.7917e-07,\n",
            "         2.3313e-05,  7.4622e-06,  3.0315e-05,  2.9775e-05, -3.0691e-05,\n",
            "         1.3301e-05,  9.2123e-08,  1.5937e-05, -8.1149e-05,  3.6668e-05,\n",
            "        -3.2562e-05, -1.3035e-04, -4.7319e-06,  7.0376e-05, -3.7020e-05,\n",
            "         2.9952e-05, -3.9752e-06,  1.1208e-05,  3.9115e-05,  2.7013e-05,\n",
            "         1.6438e-04, -1.8086e-05,  2.3298e-05, -4.6222e-05,  8.4484e-05,\n",
            "        -2.7774e-05, -4.9186e-05, -8.7605e-05, -8.8780e-05,  4.5957e-05,\n",
            "         1.3652e-04,  8.4659e-05, -1.4397e-06, -6.3692e-05,  1.4280e-04,\n",
            "         8.8460e-06, -3.5439e-05,  5.7224e-05,  1.5440e-04,  4.6007e-05,\n",
            "         2.1267e-05,  2.3978e-05,  2.0832e-05,  5.1543e-05, -4.3871e-06,\n",
            "         3.2318e-06,  1.3059e-05, -6.2194e-05, -5.8293e-06,  4.8146e-05,\n",
            "         1.5328e-05, -7.6833e-06, -9.4247e-05,  5.3116e-05, -2.0267e-05,\n",
            "        -1.1392e-06, -4.3071e-05, -4.1014e-05, -2.9462e-05, -2.9755e-05,\n",
            "         2.7383e-05,  1.0283e-05, -1.9331e-05,  9.9315e-07, -3.6616e-05,\n",
            "         4.1887e-05,  1.2544e-05, -4.5880e-05,  4.3200e-05, -5.8109e-07,\n",
            "        -1.7648e-05, -5.2289e-05,  1.2536e-05, -5.4220e-05, -1.7358e-05,\n",
            "         2.3990e-05])), ('module.encoder_k.layer3.5.bn2.running_mean', tensor([ 0.0930,  0.2234, -0.1122,  0.0108,  0.1818, -0.1869, -0.0787, -0.0504,\n",
            "        -0.7342, -0.6838,  0.2272, -0.0755, -0.1337, -0.2204, -0.8995,  0.0866,\n",
            "         0.0690, -0.1226,  0.7117, -0.0881, -0.3770, -0.2097, -0.0443,  0.1967,\n",
            "         0.3878,  0.2214, -0.0344,  0.4828,  0.1906, -0.9269, -0.2539,  0.2552,\n",
            "        -0.1602,  1.1636,  0.3459,  0.1140,  0.1875, -0.2464, -0.3600, -0.4611,\n",
            "         0.4124,  0.1939, -0.5295,  0.0700, -0.2486, -0.2817, -0.2550,  0.6119,\n",
            "         0.4627,  0.3046,  0.0467,  0.2114, -0.1743,  0.4947, -0.7609,  0.5854,\n",
            "        -0.3294,  0.5678, -0.3706, -0.3102,  0.5331,  0.0719,  0.2192,  1.1960,\n",
            "        -0.0102, -0.2144, -0.4888, -1.1165, -0.0262, -0.8671,  0.0204, -0.0814,\n",
            "        -0.2767, -0.4277, -0.1303, -0.2147, -0.1594, -0.6062, -0.0939, -0.5436,\n",
            "         0.2758,  0.0694,  0.0488, -0.3978,  0.3521, -0.2050, -0.2166, -0.4639,\n",
            "         0.6655,  0.1342, -0.6189,  0.2094, -0.2613, -0.6915,  0.6633, -0.7077,\n",
            "        -0.1682, -1.5356, -0.8467, -0.0445,  0.0883, -0.2462, -0.6421,  0.4786,\n",
            "        -0.0230, -0.4970,  0.5213,  0.0851, -0.6064, -0.2655, -0.3768,  0.2449,\n",
            "         0.0846,  0.0166,  0.1184,  0.1972, -0.8227,  0.1820, -0.0945, -0.4863,\n",
            "        -0.3911,  0.0989,  0.0958, -0.1445,  0.0494, -0.6474, -0.1448, -0.1990,\n",
            "         0.2291, -0.4283, -0.0117,  0.2659, -0.3744,  0.5652, -0.3088, -0.1031,\n",
            "        -0.1521, -0.3343,  0.4770,  0.2626, -0.2306,  0.3939, -0.0872, -0.3698,\n",
            "         0.3275, -0.0191,  0.0704,  0.0099,  0.9084, -0.4856,  0.0716, -0.0199,\n",
            "         0.3590,  0.0855,  0.5287, -0.3466,  0.1212, -0.0611,  0.2387, -0.2636,\n",
            "         0.7309,  1.7550,  0.7013,  0.0788, -0.4333,  0.3109,  0.0974,  0.6183,\n",
            "        -0.0441,  0.0539,  0.1871,  0.3211, -0.4818, -0.8625, -0.0564,  0.9134,\n",
            "        -0.6556,  0.2372,  0.2776, -0.5517,  0.7055,  0.5249,  0.0359,  0.7474,\n",
            "         0.2015,  0.1965,  0.2799, -0.0991, -0.2259,  0.6926,  0.7920,  0.1737,\n",
            "         0.5067,  0.2920, -0.0490, -0.1390,  0.2070, -1.0263,  0.3139,  0.2583,\n",
            "         0.3683,  0.1862,  0.3799,  0.5004, -0.1630, -0.1625,  0.8010, -0.4438,\n",
            "         0.0614,  0.8788, -0.1426, -0.5446, -0.5039, -0.8333,  0.2792,  0.0377,\n",
            "         0.7077,  0.1542,  0.2827, -0.5778, -0.4160, -0.3796, -0.1390,  1.1350,\n",
            "        -0.4250, -0.3418, -0.3586,  1.2000, -0.0785, -0.4765, -0.2275, -0.4256,\n",
            "         0.5855,  0.8285, -0.1608, -0.0619, -0.4813,  0.1337, -0.2844,  0.3221,\n",
            "         0.1952,  0.0312, -0.5899, -0.2990,  0.6171,  0.0786,  0.0302,  0.7819,\n",
            "        -0.3554,  0.4141,  0.3089,  0.3066, -0.7654,  0.3691, -0.7160, -0.0079])), ('module.encoder_k.layer3.5.bn2.running_var', tensor([0.5802, 0.5311, 0.5646, 0.5561, 0.5752, 0.6944, 0.6630, 0.5792, 0.6163,\n",
            "        0.8808, 0.7520, 0.5691, 0.5865, 0.7483, 0.9577, 0.7473, 0.7610, 0.5842,\n",
            "        0.6378, 1.0668, 0.6501, 0.5978, 0.8365, 0.8267, 0.9655, 0.6143, 0.6790,\n",
            "        0.8752, 0.5867, 0.8142, 0.6001, 1.0958, 0.5341, 1.4142, 0.8682, 0.5377,\n",
            "        0.5798, 0.5905, 0.6188, 0.9040, 0.5566, 0.8143, 1.1820, 0.5403, 0.6479,\n",
            "        0.5995, 0.5284, 1.1040, 1.0635, 0.6184, 0.5461, 0.6782, 1.1036, 0.7646,\n",
            "        0.7320, 0.5771, 0.5599, 0.7494, 0.6769, 0.8137, 0.5630, 1.1202, 0.5701,\n",
            "        1.9237, 0.6132, 1.2946, 0.8631, 1.4698, 0.9289, 0.8157, 0.5487, 0.5566,\n",
            "        0.6067, 0.8533, 0.5442, 0.5998, 0.7415, 1.2289, 0.5183, 0.6461, 0.5605,\n",
            "        0.6047, 0.6040, 0.7802, 1.0826, 0.6363, 0.6440, 0.6499, 1.2501, 0.5668,\n",
            "        1.4446, 0.5054, 0.6536, 0.7647, 0.9474, 0.8739, 0.5450, 1.0246, 1.3198,\n",
            "        0.6174, 0.6341, 1.2082, 0.8513, 1.7191, 0.6741, 0.5457, 1.0003, 0.4889,\n",
            "        1.6152, 0.5621, 0.5785, 0.6082, 0.8192, 0.5413, 0.5808, 0.6413, 0.7090,\n",
            "        0.5904, 0.5780, 0.6953, 0.5424, 0.5447, 0.6801, 0.8533, 0.5867, 1.2402,\n",
            "        0.7469, 0.7635, 0.9936, 0.7949, 0.5945, 0.6751, 0.5948, 0.6752, 0.5577,\n",
            "        0.5651, 0.5345, 1.6568, 0.7408, 0.6947, 0.5090, 0.6770, 0.6024, 0.5620,\n",
            "        0.6059, 0.7016, 0.5116, 0.5788, 0.6563, 0.5159, 0.5416, 0.9545, 0.6107,\n",
            "        0.5390, 0.6536, 1.1742, 0.6656, 0.6580, 0.5511, 0.6499, 0.5969, 3.0831,\n",
            "        0.6058, 0.7129, 0.5970, 0.7378, 0.7217, 0.9713, 0.6026, 0.6017, 0.5541,\n",
            "        0.7304, 0.6138, 1.5262, 0.9542, 0.7575, 0.6623, 0.7953, 0.8789, 0.9295,\n",
            "        0.7984, 1.2372, 0.5030, 1.2308, 0.5854, 0.6636, 0.7599, 0.5959, 0.6838,\n",
            "        0.7375, 0.7657, 0.6775, 0.6016, 0.5426, 0.5686, 0.5929, 0.6246, 2.2761,\n",
            "        0.6665, 0.5331, 0.5907, 0.7832, 0.5761, 1.1502, 0.6961, 0.5939, 0.5604,\n",
            "        1.1268, 0.8628, 0.4901, 0.8339, 0.8592, 0.5693, 1.0394, 1.0214, 0.6059,\n",
            "        0.8313, 0.5540, 0.6532, 0.6387, 1.0416, 0.7819, 0.9268, 1.2950, 0.5602,\n",
            "        0.5761, 0.6741, 1.8609, 0.5486, 1.1118, 0.5568, 0.6336, 0.7951, 1.0554,\n",
            "        0.5333, 0.8185, 0.6022, 0.5440, 0.5273, 0.5526, 0.6454, 1.5628, 1.3094,\n",
            "        0.7722, 1.3729, 1.3200, 0.7449, 0.7557, 0.6009, 0.6747, 0.8636, 0.6813,\n",
            "        0.8279, 0.6413, 1.0649, 0.5848])), ('module.encoder_k.layer3.5.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer3.5.conv3.weight', tensor([[[[-0.0221]],\n",
            "\n",
            "         [[-0.0446]],\n",
            "\n",
            "         [[-0.0665]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0222]],\n",
            "\n",
            "         [[-0.0435]],\n",
            "\n",
            "         [[-0.0260]]],\n",
            "\n",
            "\n",
            "        [[[-0.0613]],\n",
            "\n",
            "         [[-0.0258]],\n",
            "\n",
            "         [[-0.0616]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         [[ 0.0243]],\n",
            "\n",
            "         [[-0.0587]]],\n",
            "\n",
            "\n",
            "        [[[-0.0497]],\n",
            "\n",
            "         [[ 0.0082]],\n",
            "\n",
            "         [[ 0.0108]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0718]],\n",
            "\n",
            "         [[ 0.0807]],\n",
            "\n",
            "         [[-0.0910]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0256]],\n",
            "\n",
            "         [[-0.1060]],\n",
            "\n",
            "         [[-0.0859]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0225]],\n",
            "\n",
            "         [[-0.0077]],\n",
            "\n",
            "         [[-0.0268]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0753]],\n",
            "\n",
            "         [[ 0.0493]],\n",
            "\n",
            "         [[ 0.0059]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0529]],\n",
            "\n",
            "         [[-0.0065]],\n",
            "\n",
            "         [[ 0.0275]]],\n",
            "\n",
            "\n",
            "        [[[-0.0898]],\n",
            "\n",
            "         [[-0.0862]],\n",
            "\n",
            "         [[-0.0399]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         [[-0.0127]],\n",
            "\n",
            "         [[-0.0107]]]])), ('module.encoder_k.layer3.5.bn3.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9990, 0.9991, 0.9991])), ('module.encoder_k.layer3.5.bn3.bias', tensor([ 1.8869e-06,  1.2863e-05,  6.0827e-06,  ..., -1.5458e-06,\n",
            "        -5.6612e-06, -1.4473e-06])), ('module.encoder_k.layer3.5.bn3.running_mean', tensor([-0.2488, -0.0231, -0.2537,  ...,  0.1283,  0.0063,  0.1484])), ('module.encoder_k.layer3.5.bn3.running_var', tensor([0.1296, 0.1757, 0.2162,  ..., 0.1495, 0.1378, 0.2270])), ('module.encoder_k.layer3.5.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.0.conv1.weight', tensor([[[[-0.0641]],\n",
            "\n",
            "         [[ 0.0527]],\n",
            "\n",
            "         [[ 0.0303]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0362]],\n",
            "\n",
            "         [[-0.0653]],\n",
            "\n",
            "         [[-0.0357]]],\n",
            "\n",
            "\n",
            "        [[[-0.0597]],\n",
            "\n",
            "         [[-0.0353]],\n",
            "\n",
            "         [[-0.0253]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0761]],\n",
            "\n",
            "         [[ 0.1036]],\n",
            "\n",
            "         [[ 0.0900]]],\n",
            "\n",
            "\n",
            "        [[[-0.0440]],\n",
            "\n",
            "         [[-0.0048]],\n",
            "\n",
            "         [[-0.0308]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0111]],\n",
            "\n",
            "         [[-0.0507]],\n",
            "\n",
            "         [[ 0.0455]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0031]],\n",
            "\n",
            "         [[-0.0765]],\n",
            "\n",
            "         [[-0.0233]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0736]],\n",
            "\n",
            "         [[ 0.0728]],\n",
            "\n",
            "         [[-0.1246]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1014]],\n",
            "\n",
            "         [[-0.0829]],\n",
            "\n",
            "         [[-0.0238]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0029]],\n",
            "\n",
            "         [[-0.0194]],\n",
            "\n",
            "         [[-0.1562]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0083]],\n",
            "\n",
            "         [[-0.0550]],\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0154]],\n",
            "\n",
            "         [[ 0.0124]],\n",
            "\n",
            "         [[-0.1018]]]])), ('module.encoder_k.layer4.0.bn1.weight', tensor([0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9992, 0.9991, 0.9992, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9990,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992, 0.9990,\n",
            "        0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9993, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9992, 0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991])), ('module.encoder_k.layer4.0.bn1.bias', tensor([ 1.0002e-04, -1.0743e-04, -9.9308e-05, -1.9541e-05, -3.6849e-05,\n",
            "         1.3502e-05,  1.7911e-05,  8.5041e-05, -7.8756e-05,  6.4352e-05,\n",
            "         6.8037e-06, -3.4126e-05, -5.0225e-05,  1.3604e-04,  2.7144e-05,\n",
            "         1.3005e-04, -9.6116e-06, -3.2809e-05,  2.1335e-05,  5.6715e-05,\n",
            "        -6.5381e-05, -7.6169e-05, -9.3953e-05,  7.6961e-06,  7.0035e-05,\n",
            "         2.0557e-05,  6.8717e-06,  7.4845e-07,  1.2871e-05, -1.2256e-05,\n",
            "        -3.1262e-05, -2.8119e-07, -8.3394e-05,  3.4081e-05, -2.4051e-05,\n",
            "        -2.0032e-05, -5.6126e-05, -1.6629e-05, -1.8182e-05, -6.3128e-06,\n",
            "        -2.4235e-05,  2.1976e-05, -3.3103e-05,  3.7230e-05, -1.0477e-05,\n",
            "        -2.0581e-05, -7.8215e-06, -8.6644e-05,  6.2910e-05, -2.3086e-05,\n",
            "        -5.2314e-05, -4.2118e-05, -3.4293e-05, -3.6446e-05,  4.9033e-06,\n",
            "         4.4247e-05, -2.8750e-05,  1.4562e-05, -3.0886e-05, -3.9516e-05,\n",
            "         1.0171e-04,  1.0563e-05, -1.8174e-05,  3.9156e-05,  8.6104e-05,\n",
            "        -6.2603e-06, -1.6395e-05, -4.3165e-05,  6.1774e-06, -8.7519e-05,\n",
            "         1.8530e-05, -1.3695e-06,  7.1081e-06, -4.1369e-05,  1.6951e-05,\n",
            "         2.6519e-05, -3.5348e-05, -5.9733e-05, -6.3981e-07, -4.4841e-05,\n",
            "        -1.8469e-05,  6.1082e-05,  9.5170e-06,  3.1288e-06, -4.4069e-05,\n",
            "         5.1909e-05,  2.2573e-05, -4.3233e-05,  3.0459e-05, -2.0211e-05,\n",
            "        -1.8919e-07,  1.5501e-05, -2.2629e-05, -2.4556e-05,  2.2801e-05,\n",
            "        -2.0864e-05,  1.0975e-05, -1.5696e-05,  1.3170e-05, -2.0576e-05,\n",
            "         6.6407e-05,  7.9293e-05, -1.1374e-05,  1.9524e-05,  2.5579e-06,\n",
            "         4.7240e-05,  6.2788e-05,  5.9523e-06,  1.1407e-05, -7.6762e-05,\n",
            "        -4.3050e-05,  1.9270e-05, -1.2710e-05,  3.5599e-05, -3.4456e-05,\n",
            "         4.4270e-05, -1.6264e-05,  5.7316e-05,  7.4770e-05, -1.4644e-05,\n",
            "        -7.9733e-05,  4.3169e-05,  1.6600e-06, -8.3454e-06,  3.9148e-05,\n",
            "        -3.6032e-05, -3.1853e-05,  3.6233e-05,  8.1617e-05, -2.2240e-05,\n",
            "         1.3879e-05,  1.1657e-05, -1.5717e-05,  4.6279e-05,  3.2161e-07,\n",
            "         3.3486e-05,  7.6871e-06,  1.3854e-05,  5.9621e-05,  2.1678e-05,\n",
            "         4.7337e-05,  2.8303e-06, -7.4780e-05,  5.0615e-05,  2.6847e-05,\n",
            "        -1.2642e-04, -2.9710e-05, -4.7394e-06,  4.8219e-05,  1.0890e-05,\n",
            "         6.1687e-05,  2.4236e-05,  1.6517e-06, -1.7917e-05, -3.7708e-07,\n",
            "        -8.6507e-05, -7.5535e-05,  3.3271e-05, -2.9650e-06,  5.0177e-05,\n",
            "        -8.1011e-05,  2.4656e-05, -5.4117e-06,  7.9622e-05,  8.2802e-05,\n",
            "        -4.3980e-06, -9.2625e-05,  5.9683e-06,  3.3964e-05, -4.3865e-05,\n",
            "        -5.6224e-05,  6.0812e-05, -7.2393e-05,  1.7173e-05,  1.1244e-05,\n",
            "         8.2014e-05, -1.2728e-04,  7.5595e-05,  3.3170e-05,  1.9053e-05,\n",
            "         9.4535e-06,  1.5051e-05, -4.5864e-05,  5.3701e-05, -2.9249e-05,\n",
            "         3.8830e-05, -3.2318e-06,  4.2998e-05,  4.3934e-05, -5.8345e-05,\n",
            "         1.3719e-05, -3.7445e-05,  1.4451e-05,  4.0037e-05, -1.2243e-04,\n",
            "        -1.5319e-05, -7.9400e-05,  1.7654e-05, -3.3611e-05,  1.8860e-06,\n",
            "        -4.4650e-06,  2.1305e-05,  1.8698e-05,  2.5467e-05, -3.2630e-05,\n",
            "        -4.1925e-05,  3.1935e-05, -6.5612e-05, -3.2872e-05, -7.2957e-05,\n",
            "         5.5526e-05, -1.8258e-05, -1.8947e-06,  2.4337e-05, -6.0580e-05,\n",
            "        -1.5657e-05, -6.2675e-05,  2.2103e-05,  2.1347e-05, -8.4202e-05,\n",
            "        -6.1624e-05,  7.8640e-05,  7.7433e-05, -3.9073e-06, -1.0419e-04,\n",
            "        -4.2741e-05, -3.1532e-05, -5.3006e-05, -4.3674e-05,  3.9901e-06,\n",
            "        -8.4984e-05,  1.7467e-04, -4.9990e-05,  4.1683e-07,  7.1583e-08,\n",
            "        -4.4399e-05,  3.5407e-06,  1.8951e-06, -4.5759e-06, -4.1633e-05,\n",
            "         5.9648e-05, -3.8241e-05,  2.7383e-05, -8.0975e-05,  4.7796e-05,\n",
            "         5.5934e-05,  6.3736e-05, -4.5203e-05, -4.4142e-05, -3.8519e-05,\n",
            "         5.6476e-05, -5.0286e-06, -2.2544e-05,  5.4476e-05,  5.2821e-05,\n",
            "        -1.9854e-05, -8.3454e-05,  3.9603e-06, -1.9201e-05, -8.1345e-05,\n",
            "        -1.0583e-05,  2.7372e-05,  3.0156e-05, -6.4160e-05, -8.8447e-05,\n",
            "         3.1155e-05, -1.8865e-05,  2.0285e-05, -4.3136e-05, -2.0286e-05,\n",
            "         3.5600e-05, -3.5441e-05, -5.7757e-06, -4.7228e-05,  5.1747e-05,\n",
            "         3.0524e-05,  1.0997e-05,  3.8792e-06,  5.5576e-05, -1.2903e-05,\n",
            "         4.4713e-05, -1.9583e-05, -1.8426e-05,  9.5463e-05,  2.1756e-05,\n",
            "        -5.8095e-06,  2.6663e-05, -3.6131e-05, -5.1690e-05,  4.6935e-05,\n",
            "         1.9711e-05,  2.2649e-05, -5.1761e-06, -6.7381e-05,  2.5701e-05,\n",
            "        -1.7496e-05, -6.7996e-05,  1.0750e-05, -3.5524e-05, -3.8895e-05,\n",
            "         8.8294e-05, -1.4890e-05,  2.6876e-06, -8.0492e-05, -7.8481e-05,\n",
            "         4.8502e-05, -3.4519e-05, -2.8159e-05, -2.6902e-05, -5.0970e-05,\n",
            "         1.6863e-05,  2.8531e-05, -3.9736e-05, -5.6432e-05, -5.3408e-05,\n",
            "         3.4932e-05, -4.7107e-05, -4.4484e-05, -7.9963e-05, -3.7549e-05,\n",
            "         2.8317e-05, -4.6552e-06, -6.5009e-05,  4.7923e-05, -2.0504e-05,\n",
            "        -7.3108e-05, -1.5903e-05, -9.3502e-05,  4.7163e-05, -3.0579e-05,\n",
            "        -3.4110e-05,  9.1220e-05, -5.8717e-05, -8.9881e-06,  5.9459e-05,\n",
            "         3.0431e-05,  4.2497e-06, -6.3770e-05, -2.4030e-05,  2.6805e-05,\n",
            "        -4.1062e-05, -3.3291e-05,  1.7885e-05, -4.4683e-05,  4.3238e-05,\n",
            "        -5.7352e-06, -1.6297e-05, -4.2258e-05, -1.0831e-06,  1.6711e-05,\n",
            "         1.0206e-04, -1.3939e-05,  5.5158e-06,  5.2739e-05, -1.1290e-05,\n",
            "         4.2582e-05,  1.1753e-05, -1.5986e-05, -2.5653e-05,  4.7557e-05,\n",
            "        -1.4966e-05,  5.5059e-05,  2.4092e-06, -8.7388e-07,  1.6786e-05,\n",
            "         7.4931e-05,  8.0301e-05,  6.0173e-05,  3.4734e-06, -4.9563e-05,\n",
            "        -4.7635e-07, -8.0982e-06, -3.6880e-05,  1.4307e-05, -1.3985e-05,\n",
            "        -4.9959e-06,  6.8144e-05,  7.3199e-06,  5.4564e-06, -1.9925e-05,\n",
            "         4.6132e-06, -7.6536e-05,  1.2075e-04, -1.4498e-05, -2.3652e-05,\n",
            "         5.1002e-05, -1.6739e-05,  6.0286e-05, -4.3124e-05,  3.8040e-06,\n",
            "        -5.3791e-05, -8.7144e-06,  4.6941e-05,  3.2000e-05, -6.5895e-06,\n",
            "         4.9796e-06, -4.1851e-05,  1.6597e-05, -5.6128e-06,  2.0357e-06,\n",
            "        -2.8219e-05, -2.5032e-05, -1.2683e-05,  4.8952e-05,  6.2103e-06,\n",
            "         7.8100e-06, -1.7213e-06, -7.6723e-05, -1.0865e-04, -8.1678e-05,\n",
            "        -5.2286e-05, -4.4994e-05, -4.5998e-05,  3.7599e-05, -8.4483e-05,\n",
            "        -2.5571e-05,  3.5450e-05, -7.3096e-05,  4.1315e-05,  1.5630e-06,\n",
            "         1.8639e-05,  2.2012e-05,  3.5358e-05, -1.8731e-05,  3.4939e-06,\n",
            "        -3.3089e-05,  3.2340e-05,  7.7436e-05, -4.7324e-05,  7.1504e-05,\n",
            "        -2.5899e-05, -5.2212e-05, -6.1454e-05,  2.5104e-06,  3.6031e-05,\n",
            "         1.0937e-05, -3.5628e-05,  1.0831e-05, -2.1289e-05,  6.4672e-05,\n",
            "        -4.0579e-05, -7.0836e-05,  1.0179e-05,  7.4974e-05,  5.3796e-05,\n",
            "         3.8517e-05,  6.4196e-05, -2.7081e-05,  3.0616e-05, -3.3285e-05,\n",
            "         1.9437e-04, -1.3187e-05, -1.7934e-06, -1.9686e-05, -1.5881e-05,\n",
            "        -8.2970e-06, -6.9579e-05, -3.5530e-05,  3.7880e-05,  9.0809e-05,\n",
            "         2.9913e-05, -4.8481e-05, -1.5829e-05, -6.7695e-06, -8.3090e-06,\n",
            "        -1.3452e-06, -2.2526e-05, -2.3290e-05, -2.4426e-05, -2.8588e-05,\n",
            "         1.3704e-05,  7.1049e-05,  4.4808e-06,  2.1829e-05,  4.2770e-06,\n",
            "        -3.4625e-05,  7.7619e-05, -2.8831e-05, -1.0172e-05,  8.1310e-05,\n",
            "        -4.6799e-06, -1.2994e-05,  3.7730e-05, -3.0861e-05, -3.3674e-05,\n",
            "         5.1658e-05,  8.6445e-06, -3.5362e-05,  7.7899e-05,  4.2498e-07,\n",
            "        -4.2904e-06,  5.3729e-06, -2.2037e-05, -8.6836e-05,  1.3582e-05,\n",
            "        -1.7333e-05,  6.5136e-06,  9.1114e-05,  6.1644e-05, -7.7455e-05,\n",
            "        -1.4965e-05, -1.2969e-05,  4.5366e-05, -7.8746e-05, -4.4814e-05,\n",
            "         1.7887e-05,  1.7758e-05,  5.8630e-05, -8.2283e-06,  4.3580e-06,\n",
            "        -6.0338e-06, -5.0627e-06])), ('module.encoder_k.layer4.0.bn1.running_mean', tensor([-7.8781e-01, -7.9049e-01, -9.2733e-01, -6.9924e-01,  2.3612e+00,\n",
            "         4.0120e-01, -1.6894e+00, -6.0810e-01,  5.5070e-01, -3.1221e-02,\n",
            "        -1.7087e+00, -2.2434e+00, -1.1113e+00, -3.3642e+00, -7.8557e-01,\n",
            "        -4.1886e+00,  3.6019e+00, -8.2263e-01, -5.2976e+00,  1.9480e+00,\n",
            "        -1.1524e+00,  2.5868e+00,  4.7968e+00,  1.0601e+00,  5.1735e+00,\n",
            "         6.5773e-01,  9.5413e-01,  1.7464e+00,  8.5798e-01,  3.8076e+00,\n",
            "         1.6668e+00,  1.1012e+00,  4.7077e+00,  2.2958e+00, -1.2619e+00,\n",
            "        -1.8247e+00, -2.6966e+00, -7.9961e-01, -1.7380e+00, -3.0811e+00,\n",
            "         4.5363e+00, -5.1240e-01,  4.0363e-01, -5.2067e+00,  5.1829e+00,\n",
            "        -7.5361e-01, -9.0141e-02,  7.3490e-01,  1.7182e+00,  2.3016e+00,\n",
            "        -1.6682e+00, -1.7592e+00,  6.4221e-01,  2.0075e+00,  1.3189e+00,\n",
            "         3.6872e-02, -4.2097e-01,  1.2078e-01, -5.1765e+00, -2.7687e+00,\n",
            "         8.7533e-01, -9.7137e-01,  3.4407e+00, -6.1129e-01,  1.0271e+00,\n",
            "        -8.3241e-01, -6.8301e-01,  7.4983e-01, -4.0841e+00,  6.9564e-01,\n",
            "         9.5757e-01, -8.6493e-01,  6.8667e-01, -3.5354e+00,  8.2297e-01,\n",
            "         3.8470e+00, -1.8024e+00, -1.3690e+00, -1.1383e+00, -2.5813e+00,\n",
            "        -4.4822e+00,  4.1514e+00, -4.5770e+00,  2.1089e+00,  2.6016e+00,\n",
            "         5.9634e+00, -4.9890e+00, -1.7002e+00,  1.7320e-01, -2.5702e+00,\n",
            "        -1.2849e+00,  2.2135e+00, -1.5537e+00,  1.4084e+00, -1.7204e+00,\n",
            "         2.5332e+00, -2.9381e-02,  3.2296e+00,  2.4972e+00, -9.9775e-01,\n",
            "        -4.8677e+00,  6.9547e-01,  9.3713e-01,  9.1708e-02,  1.1396e+00,\n",
            "         3.6690e+00,  5.0970e-01,  8.6142e-01, -2.0076e+00, -3.3949e+00,\n",
            "        -1.7633e-01,  7.9320e-01,  3.3409e+00,  5.9020e+00, -5.1921e-01,\n",
            "         2.1590e+00, -1.1465e+00,  4.3575e-01, -1.7172e+00,  3.2702e+00,\n",
            "         1.2517e-01,  4.3363e+00,  3.3632e+00,  4.4338e+00,  8.6167e-01,\n",
            "         9.3710e-01,  2.0990e+00,  2.1061e-01,  3.0711e+00,  7.9233e+00,\n",
            "         2.7334e+00,  3.5478e+00, -7.0718e-03, -1.6003e+00,  1.3824e+00,\n",
            "         9.3038e+00, -6.8431e-01,  1.9223e+00, -1.0304e+00,  1.3536e+00,\n",
            "         1.3941e+00, -9.3005e-01, -5.2529e-01,  3.6430e+00,  4.0594e+00,\n",
            "        -2.7581e+00,  4.9986e-01, -2.8357e+00, -3.6141e+00,  5.4747e-01,\n",
            "         1.2332e+00,  5.3851e+00, -2.1152e+00,  4.0896e+00,  4.3708e+00,\n",
            "         2.0940e+00,  4.5041e+00, -5.2576e-02,  3.7606e+00,  5.4821e-01,\n",
            "         5.0972e+00,  1.6385e+00, -1.1242e+00, -2.2624e+00,  2.8423e+00,\n",
            "        -5.5575e-01,  1.0284e-01,  3.9351e+00,  1.6173e+00, -5.3269e+00,\n",
            "         1.6242e+00, -4.6167e-01, -3.5845e+00, -2.3682e+00, -4.3125e+00,\n",
            "         1.7932e+00, -1.7090e+00, -9.2982e-01, -1.6665e+00, -2.2676e-02,\n",
            "        -1.4854e+00, -2.0526e+00, -2.1112e+00,  1.8443e+00,  4.5836e+00,\n",
            "        -9.7167e-01,  7.0843e-01, -1.4773e+00, -2.0481e+00, -5.6202e+00,\n",
            "        -2.7857e+00,  5.7238e+00, -1.9747e+00,  2.3198e+00,  1.1863e-01,\n",
            "         9.0638e-01,  3.2602e-01, -1.0986e+00, -8.9701e-01, -2.0597e+00,\n",
            "        -3.3535e+00,  1.0443e+00,  6.3957e-01,  1.0859e+00, -2.6644e+00,\n",
            "         3.3782e+00,  2.6156e-01, -1.3214e+00,  5.0627e-01, -5.5502e+00,\n",
            "         1.0256e+00,  1.9191e+00,  1.4487e+00,  1.6615e+00, -7.3719e-01,\n",
            "         2.3847e+00, -2.1731e+00, -1.9819e+00, -1.6915e+00, -2.1692e-02,\n",
            "         4.1516e+00, -2.4770e+00, -2.8744e+00,  7.4290e+00, -2.0135e+00,\n",
            "         1.1658e+00, -5.2514e-01, -2.9728e+00,  2.0164e+00, -1.1943e+00,\n",
            "         4.6178e+00, -5.8963e-01,  2.9917e+00,  9.5229e-01,  5.5290e+00,\n",
            "        -1.2277e+00, -4.5310e+00, -3.6395e+00, -1.9325e+00,  2.0580e+00,\n",
            "        -1.1930e+00, -1.8000e+00,  4.6206e+00,  9.4750e-01, -2.1121e+00,\n",
            "        -1.4109e+00,  3.3835e+00, -1.3944e+00,  2.0030e+00, -2.5603e+00,\n",
            "         4.7826e+00, -9.2448e-01,  3.1699e-01,  2.7973e+00,  4.0251e+00,\n",
            "        -1.4339e+00, -4.1757e-01,  1.4715e-01, -4.1384e+00, -1.2583e+00,\n",
            "         5.8266e-01,  1.0551e+00, -2.6441e+00, -5.3586e-01, -1.9122e+00,\n",
            "         4.7063e+00,  1.0825e+00,  4.3404e+00,  8.4004e-01, -1.4581e+00,\n",
            "         1.2492e+00, -3.7911e-01,  6.8632e-01,  1.4395e+00,  3.1235e+00,\n",
            "         1.8038e+00,  4.3916e-01, -2.2527e+00,  3.4007e+00,  2.8997e-01,\n",
            "         5.4235e+00, -3.3245e+00, -1.7646e+00, -2.2513e+00, -6.4602e-01,\n",
            "         7.2214e-01,  2.1708e+00,  1.7315e+00, -1.3400e+00, -1.1834e+00,\n",
            "        -1.4679e+00, -5.3803e+00, -3.8245e+00, -3.9695e+00,  2.0386e+00,\n",
            "         3.5937e+00, -2.1723e-01, -9.5916e-01,  4.2881e+00,  5.9553e-02,\n",
            "        -3.4777e-01, -3.4658e+00,  3.9292e+00, -2.1589e+00, -5.2033e+00,\n",
            "         2.5157e+00, -4.4254e-01, -3.3517e+00, -2.6906e+00,  9.2427e-01,\n",
            "         4.4703e+00,  5.8004e+00, -2.0516e-02,  4.5344e+00,  3.4718e+00,\n",
            "         2.4072e-01, -1.8789e+00, -1.5484e+00, -3.8204e-01, -1.2757e+00,\n",
            "         7.0072e-01,  2.2643e+00,  8.5132e-02,  1.9654e-01,  4.6935e-02,\n",
            "         3.1067e+00, -3.5059e+00,  9.3989e-01,  7.7668e-01, -2.1427e+00,\n",
            "        -3.9251e-01,  1.5827e+00, -1.2498e+00, -9.4179e-01, -3.5770e-01,\n",
            "        -3.5879e+00, -4.1974e+00, -6.0068e-01, -4.2815e+00, -2.9938e+00,\n",
            "         1.5199e+00,  1.2992e-01,  1.6161e+00, -7.0170e-01, -2.7824e+00,\n",
            "         1.3568e+00, -4.0978e+00, -1.6723e+00,  2.7026e+00, -1.1326e-01,\n",
            "         2.8974e+00,  1.5031e+00,  2.2146e+00,  1.2437e+00,  1.9929e+00,\n",
            "        -1.9326e+00,  2.6607e-01, -5.2960e+00, -4.1635e-01,  3.6811e+00,\n",
            "        -7.0831e-01, -1.4650e-01, -1.4541e-01,  2.4327e-01,  1.2604e+00,\n",
            "        -2.6077e+00, -1.8303e-01, -4.0464e+00, -6.3946e-01,  1.4925e+00,\n",
            "         2.2128e+00,  2.4118e-01, -4.3198e-01, -1.1294e+00,  2.2249e+00,\n",
            "        -2.3555e+00,  2.7286e+00, -1.3523e+00,  4.2101e+00,  3.6564e+00,\n",
            "        -4.5169e-01, -1.1368e+00, -2.3005e+00,  5.7449e-01,  2.7848e+00,\n",
            "         4.0301e+00,  8.1925e-01,  3.5619e-02,  5.1507e+00, -2.3491e+00,\n",
            "        -5.8667e+00,  5.4866e-01,  8.9864e-01,  3.6472e+00, -2.9043e+00,\n",
            "        -1.3214e+00,  1.7915e+00,  1.0052e+00,  2.4578e+00, -3.5389e-01,\n",
            "         8.2760e-01,  3.1667e+00,  1.9529e+00,  4.9165e-01,  2.9723e+00,\n",
            "        -2.7025e+00, -3.0527e+00,  5.2981e-01,  2.3677e+00,  1.0259e+00,\n",
            "        -1.9447e+00, -3.6450e+00, -3.0539e+00,  1.6234e+00,  6.4535e+00,\n",
            "         1.5667e+00,  1.5839e+00,  7.2319e-01,  1.9229e+00,  6.7252e-01,\n",
            "         4.6873e+00, -1.2299e+00,  3.7883e+00,  1.7288e+00, -2.6804e+00,\n",
            "         8.4021e-02,  1.7985e+00,  3.1152e+00, -4.2200e+00,  6.2006e-01,\n",
            "        -7.0898e-01, -2.1264e-03,  1.0015e+01, -2.1135e+00,  1.7606e+00,\n",
            "         1.8291e+00,  3.6401e+00,  1.0078e-01,  6.0085e-01, -2.1678e-01,\n",
            "        -2.2103e+00, -7.0236e-01, -2.3969e+00,  4.3898e+00,  9.0274e-01,\n",
            "        -4.6895e+00, -3.4865e-01,  2.3086e-01, -2.8881e-01, -3.6645e-01,\n",
            "        -5.4651e+00, -2.6869e-01,  2.3998e+00,  1.0176e+00, -3.7610e-01,\n",
            "        -5.0452e+00, -4.5325e+00, -1.1992e-01,  6.4771e+00, -7.8928e-01,\n",
            "         2.2179e+00, -4.4663e+00, -2.2740e-01, -7.8293e-01, -5.7624e-01,\n",
            "         4.2951e+00, -2.5382e+00, -2.0838e+00, -1.3451e-01,  4.9749e+00,\n",
            "        -1.5036e-01, -7.3098e-01,  1.5017e-01,  1.1186e+00, -5.2899e-01,\n",
            "        -4.0508e+00,  2.3514e+00, -1.2142e+00,  5.7977e-01,  4.5027e-01,\n",
            "         3.9551e+00, -5.7322e-01, -9.2169e-01,  2.1691e+00,  2.6783e+00,\n",
            "        -1.8196e+00,  4.5322e-01, -1.3091e+00, -1.5098e+00, -2.0208e+00,\n",
            "         2.0904e+00, -2.2971e+00, -1.6575e-01, -4.2181e-01, -7.3158e-01,\n",
            "         7.0843e-01, -2.0143e-01,  2.5798e+00,  1.2152e+00, -1.0435e+00,\n",
            "        -1.8221e-01,  3.5207e+00, -1.8550e+00,  2.6112e+00, -2.6248e+00,\n",
            "        -1.5261e+00, -5.4409e-01,  7.8415e+00,  8.4526e-01,  1.3293e-02,\n",
            "         2.0677e+00,  1.6434e+00])), ('module.encoder_k.layer4.0.bn1.running_var', tensor([13.2077, 10.0489,  8.2806,  9.8514,  8.3366, 13.5599,  8.9768,  9.2405,\n",
            "         9.3444, 12.5333,  9.2176, 12.0859,  8.7920, 15.4779,  8.0201, 29.8662,\n",
            "        10.1406,  7.5987, 16.4296, 13.7263,  8.4321, 17.2300, 18.7704, 17.0517,\n",
            "        17.3638,  9.6284,  8.6724, 14.0615,  7.9435,  8.8359, 21.3385,  8.5710,\n",
            "         8.9732, 27.7697,  8.7543,  9.0909, 10.3292, 16.9866,  7.9254, 28.4018,\n",
            "        27.6946,  8.4522,  7.5763, 11.7996,  8.5963,  8.7891, 13.3019, 10.6863,\n",
            "         8.9904,  9.3149, 10.8170,  9.5815,  8.8266, 10.2993, 16.2052,  8.6883,\n",
            "        10.3127,  9.2999, 16.8877, 14.1383,  8.6068,  9.1309, 12.0550, 12.3415,\n",
            "         7.8830, 10.5832, 14.5301,  9.5825, 21.4198,  9.1250,  7.8567, 10.2568,\n",
            "        11.2998, 13.1959,  7.8101, 11.0625,  8.0289,  8.2716,  8.6613, 10.7286,\n",
            "        28.4974, 13.8252, 17.1637, 12.3913, 10.6897, 26.5851, 44.3038,  8.0841,\n",
            "         7.2248, 12.1760, 10.1395, 11.2610,  8.1433,  9.6893,  9.3944,  8.8378,\n",
            "        10.3812,  8.9298, 12.8205, 10.3199, 19.8369, 11.1515,  8.5251,  8.2843,\n",
            "        10.2785, 12.9397, 12.6096,  8.7238, 11.2777, 14.2151, 11.5911,  8.6483,\n",
            "        16.3429, 14.4976,  8.9996, 10.2470,  8.3640,  8.5036,  8.4804,  9.6264,\n",
            "         7.6741, 12.0809, 10.8450, 22.0306,  8.5561,  8.7838,  8.6871,  7.6641,\n",
            "        10.4275, 55.6935, 10.7692, 25.4151, 18.3567, 14.0661,  9.1041, 39.7448,\n",
            "         8.6812,  8.7926,  9.0266,  7.6607,  8.8334, 10.2569, 13.9785, 11.6569,\n",
            "        17.7540, 17.3596,  8.6100, 10.7531,  7.3928,  9.3604, 10.2912, 12.7533,\n",
            "        17.0022, 17.0875, 13.3807, 11.2104, 27.3163,  9.4008, 15.8085,  7.6755,\n",
            "        31.6231,  7.8242, 10.7672, 18.2025, 15.8334, 14.7033,  9.1168, 21.0727,\n",
            "        17.5079, 13.5749, 12.1131, 10.6819, 31.8475,  8.2101, 26.7323,  8.8703,\n",
            "         9.9542,  9.1076, 20.8249,  7.6714, 10.3068,  9.6069, 19.2816, 13.4179,\n",
            "        23.3256, 10.0637,  8.5911, 10.7302,  9.5378, 36.2600,  8.6168, 12.4998,\n",
            "        10.5462, 11.4512,  8.3899,  8.7302,  9.4387,  8.2636,  9.7314, 12.3535,\n",
            "         9.3805,  8.4750,  8.3911,  7.9637,  8.8926, 12.0164, 15.4669,  8.3622,\n",
            "         8.4273, 11.9114,  8.8828, 16.1097,  8.2348, 15.1682,  8.9378,  8.3062,\n",
            "        12.2324, 10.4681,  7.9991,  9.1366, 15.8816,  9.4739, 19.0062, 55.0937,\n",
            "        11.8815, 10.4533,  9.1396,  9.4461, 15.9124,  9.4248, 21.4591,  9.5060,\n",
            "         7.7995, 10.1266, 22.6381,  8.7647, 13.8298, 11.0699, 11.8201, 18.2537,\n",
            "        11.6306, 11.9569, 16.8904, 10.0747, 11.1823,  9.4570, 10.7496, 11.9340,\n",
            "         9.1683, 11.6974, 17.4511, 11.1116,  9.7947, 17.1940, 11.3205, 15.5553,\n",
            "        10.8362, 15.3373, 18.8798, 16.9269,  8.9039, 12.1099, 10.5717, 12.7252,\n",
            "        10.8982, 25.7083,  9.4691, 20.8959, 11.1068, 10.3771,  8.2036, 12.4493,\n",
            "         9.6461,  8.9490, 25.0012,  8.2750,  9.1192, 16.1345, 30.7993,  8.3318,\n",
            "        24.3785, 11.0136,  8.0880,  9.5128, 13.9821, 11.1485, 11.5326, 12.0525,\n",
            "         8.6382, 13.8922,  7.6745, 16.1536, 10.4069,  9.0405,  7.6078,  8.5228,\n",
            "         7.4024, 11.3135, 17.3973,  8.9499,  8.7848,  8.2006,  9.0013,  9.5173,\n",
            "        28.4579, 10.1797,  8.9218, 29.1112,  8.3101,  7.6331, 25.3955, 23.4787,\n",
            "         9.0821, 16.6186, 15.2213,  8.6308, 10.5719,  9.6300,  9.6324,  9.1514,\n",
            "         7.4031,  8.5910,  8.2290,  8.2839,  7.8670, 18.0201, 13.5478,  8.9720,\n",
            "         9.9990, 14.3457,  8.3921, 12.1284,  8.7927,  8.5205, 12.2198, 14.6329,\n",
            "        27.3110,  9.8776,  9.3426, 11.4413, 10.1494,  7.8458, 11.5223, 11.1760,\n",
            "         8.3613,  7.7796, 18.4841,  7.9893, 12.0158,  9.4874, 10.8848, 10.0119,\n",
            "         8.4814, 12.5564,  9.1617,  9.8558, 11.2564, 17.8927,  7.9493, 11.3972,\n",
            "         8.4490,  8.0961, 10.3658,  7.8911, 16.6291, 10.4789, 14.2364, 22.4036,\n",
            "         8.2165, 12.6982, 17.5446, 10.0902, 11.7996, 25.6522,  8.0084, 17.6994,\n",
            "         8.1364,  9.3536, 13.4508, 15.7841,  9.5136,  8.4688, 12.0464,  8.0910,\n",
            "         8.4072,  8.4422,  8.6875,  8.3270, 34.3054,  8.0104, 19.4498,  6.5821,\n",
            "         8.3915,  9.8299, 10.5048,  8.3549,  9.4109, 10.6397, 16.0208,  8.6261,\n",
            "        11.0365, 11.9722, 13.8870, 14.5477, 14.4973,  8.1455, 14.5571,  9.0985,\n",
            "        10.9671,  7.9334, 11.2570, 12.0347, 16.1294,  7.9194, 19.6849, 13.7608,\n",
            "        13.1339,  8.9195, 10.6779,  8.3995, 14.4745, 11.3881, 15.2538, 12.4689,\n",
            "        18.9498, 12.2393,  8.7837, 19.7017, 13.4321, 10.8351,  9.1458, 10.0452,\n",
            "        54.8713, 13.7360,  9.3871,  8.6779, 16.9340, 12.4543, 12.4131,  9.8458,\n",
            "         8.4099,  8.5081, 10.6858, 27.4146,  9.5970,  9.5456,  9.6494,  8.1979,\n",
            "        11.1659,  7.7503, 20.1326, 11.3792, 15.9090,  9.4608,  9.6215, 23.1865,\n",
            "        14.0823,  9.8309, 43.7233,  7.7211,  9.3695, 14.0686,  8.8213,  8.7721,\n",
            "        10.4680, 19.7614, 21.7323, 15.5887,  8.6275, 13.4839,  9.9415, 13.9458,\n",
            "        10.0332, 11.9939,  8.5815,  9.6909,  8.8478,  9.9177,  8.8730,  8.2197,\n",
            "        15.6198,  8.6401,  9.7459, 12.7009,  9.2744, 11.7306,  8.8023,  7.9821,\n",
            "         9.3880, 16.2831, 10.6344, 12.5552, 11.3982, 10.2021,  7.8965,  8.0142,\n",
            "        21.1897, 13.3876,  9.3076,  9.5852,  9.7780, 20.8302,  9.0759, 12.2562,\n",
            "        18.6222, 17.2227,  9.6721, 20.1694,  8.3788,  8.8753, 13.2838,  7.8307])), ('module.encoder_k.layer4.0.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.0.conv2.weight', tensor([[[[ 0.0149, -0.0463, -0.0199],\n",
            "          [ 0.0103, -0.0086,  0.0079],\n",
            "          [ 0.0011,  0.0017,  0.0333]],\n",
            "\n",
            "         [[ 0.0121,  0.0032,  0.0129],\n",
            "          [-0.0100,  0.0020,  0.0242],\n",
            "          [-0.0328, -0.0565, -0.0098]],\n",
            "\n",
            "         [[-0.0191,  0.0053, -0.0172],\n",
            "          [-0.0327, -0.0141, -0.0252],\n",
            "          [ 0.0229,  0.0119, -0.0443]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0316, -0.0008, -0.0160],\n",
            "          [-0.0080,  0.0092,  0.0271],\n",
            "          [-0.0177,  0.0090,  0.0237]],\n",
            "\n",
            "         [[-0.0119, -0.0013, -0.0207],\n",
            "          [ 0.0155, -0.0163, -0.0130],\n",
            "          [ 0.0190, -0.0045, -0.0152]],\n",
            "\n",
            "         [[ 0.0091, -0.0253, -0.0008],\n",
            "          [-0.0276, -0.0419, -0.0005],\n",
            "          [ 0.0017, -0.0109, -0.0064]]],\n",
            "\n",
            "\n",
            "        [[[-0.0024,  0.0032,  0.0146],\n",
            "          [-0.0304, -0.0080, -0.0078],\n",
            "          [-0.0083,  0.0009, -0.0021]],\n",
            "\n",
            "         [[-0.0210, -0.0217, -0.0299],\n",
            "          [ 0.0292, -0.0020,  0.0297],\n",
            "          [ 0.0209,  0.0100,  0.0356]],\n",
            "\n",
            "         [[ 0.0142,  0.0672,  0.0308],\n",
            "          [-0.0184,  0.0318, -0.0048],\n",
            "          [-0.0236, -0.0032, -0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0143, -0.0341, -0.0192],\n",
            "          [-0.0115, -0.0099, -0.0072],\n",
            "          [-0.0172, -0.0387,  0.0074]],\n",
            "\n",
            "         [[ 0.0081, -0.0426, -0.0041],\n",
            "          [-0.0304,  0.0140,  0.0657],\n",
            "          [ 0.0056,  0.0412, -0.0103]],\n",
            "\n",
            "         [[ 0.0062, -0.0041, -0.0078],\n",
            "          [-0.0121, -0.0239,  0.0078],\n",
            "          [-0.0003, -0.0030,  0.0373]]],\n",
            "\n",
            "\n",
            "        [[[-0.0209,  0.0016,  0.0176],\n",
            "          [ 0.0312, -0.0150, -0.0216],\n",
            "          [-0.0133, -0.0530,  0.0196]],\n",
            "\n",
            "         [[ 0.0051, -0.0314, -0.0068],\n",
            "          [ 0.0038,  0.0119, -0.0322],\n",
            "          [-0.0057,  0.0198, -0.0216]],\n",
            "\n",
            "         [[ 0.0171, -0.0120, -0.0033],\n",
            "          [ 0.0303,  0.0043,  0.0373],\n",
            "          [-0.0526,  0.0112, -0.0412]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0231,  0.0085],\n",
            "          [-0.0231, -0.0144,  0.0169],\n",
            "          [-0.0130,  0.0078, -0.0007]],\n",
            "\n",
            "         [[-0.0289, -0.0148, -0.0006],\n",
            "          [-0.0101,  0.0040, -0.0111],\n",
            "          [ 0.0083, -0.0135,  0.0211]],\n",
            "\n",
            "         [[ 0.0138,  0.0489, -0.0212],\n",
            "          [ 0.0192,  0.0051, -0.0205],\n",
            "          [-0.0111, -0.0015,  0.0429]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0068,  0.0171,  0.0011],\n",
            "          [-0.0371, -0.0292,  0.0209],\n",
            "          [-0.0039, -0.0041, -0.0104]],\n",
            "\n",
            "         [[ 0.0259, -0.0163,  0.0179],\n",
            "          [-0.0136,  0.0006,  0.0057],\n",
            "          [-0.0254,  0.0044, -0.0261]],\n",
            "\n",
            "         [[ 0.0245,  0.0144, -0.0269],\n",
            "          [ 0.0140,  0.0216, -0.0007],\n",
            "          [ 0.0356,  0.0200, -0.0173]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0050, -0.0087, -0.0393],\n",
            "          [ 0.0168,  0.0030, -0.0195],\n",
            "          [ 0.0059, -0.0075, -0.0111]],\n",
            "\n",
            "         [[-0.0035,  0.0432,  0.0155],\n",
            "          [-0.0225, -0.0348, -0.0232],\n",
            "          [-0.0264, -0.0478, -0.0034]],\n",
            "\n",
            "         [[-0.0270, -0.0074, -0.0386],\n",
            "          [-0.0058,  0.0023, -0.0283],\n",
            "          [ 0.0159, -0.0039, -0.0049]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0022,  0.0540, -0.0034],\n",
            "          [-0.0104, -0.0263, -0.0234],\n",
            "          [ 0.0065,  0.0052,  0.0053]],\n",
            "\n",
            "         [[-0.0163, -0.0133,  0.0061],\n",
            "          [ 0.0150,  0.0144,  0.0010],\n",
            "          [ 0.0049, -0.0349, -0.0135]],\n",
            "\n",
            "         [[-0.0140, -0.0292, -0.0010],\n",
            "          [ 0.0035, -0.0242,  0.0086],\n",
            "          [ 0.0586, -0.0302,  0.0170]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0134,  0.0050,  0.0170],\n",
            "          [ 0.0091, -0.0100,  0.0217],\n",
            "          [ 0.0200, -0.0256,  0.0036]],\n",
            "\n",
            "         [[ 0.0079, -0.0142, -0.0160],\n",
            "          [ 0.0003,  0.0298,  0.0218],\n",
            "          [-0.0202,  0.0354,  0.0022]],\n",
            "\n",
            "         [[ 0.0031,  0.0212,  0.0059],\n",
            "          [ 0.0004, -0.0090, -0.0025],\n",
            "          [ 0.0065, -0.0118,  0.0060]]],\n",
            "\n",
            "\n",
            "        [[[-0.0348,  0.0073, -0.0358],\n",
            "          [ 0.0122,  0.0359,  0.0072],\n",
            "          [-0.0073,  0.0114,  0.0167]],\n",
            "\n",
            "         [[ 0.0288, -0.0127,  0.0178],\n",
            "          [ 0.0126,  0.0079,  0.0099],\n",
            "          [-0.0166, -0.0115,  0.0019]],\n",
            "\n",
            "         [[-0.0017, -0.0018,  0.0220],\n",
            "          [ 0.0122, -0.0193, -0.0124],\n",
            "          [-0.0084, -0.0108, -0.0331]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0296,  0.0214,  0.0074],\n",
            "          [-0.0240,  0.0417,  0.0133],\n",
            "          [-0.0056,  0.0114,  0.0235]],\n",
            "\n",
            "         [[ 0.0103,  0.0141, -0.0339],\n",
            "          [ 0.0205,  0.0272, -0.0053],\n",
            "          [-0.0666,  0.0053, -0.0123]],\n",
            "\n",
            "         [[-0.0268,  0.0055, -0.0110],\n",
            "          [ 0.0102,  0.0016,  0.0152],\n",
            "          [-0.0207, -0.0180, -0.0262]]]])), ('module.encoder_k.layer4.0.bn2.weight', tensor([0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9990, 0.9992, 0.9990, 0.9992,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9989, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9992, 0.9990, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9993, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9989, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990,\n",
            "        0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9990, 0.9992, 0.9991, 0.9990, 0.9992, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990])), ('module.encoder_k.layer4.0.bn2.bias', tensor([ 2.7546e-05, -1.9852e-05, -4.0597e-05,  1.1218e-05,  2.1002e-05,\n",
            "        -3.5424e-06, -1.0057e-05,  8.8941e-06,  2.8276e-05,  1.2899e-05,\n",
            "        -3.0499e-05,  7.4514e-05, -1.7655e-05, -1.6674e-05, -1.0573e-04,\n",
            "         5.8110e-06, -4.5791e-05,  1.9921e-05, -1.0193e-05, -6.3812e-05,\n",
            "         1.8264e-05, -5.9290e-05, -6.5075e-06,  2.0114e-05,  1.4965e-05,\n",
            "        -2.3055e-05,  8.5092e-06,  4.6355e-05,  1.4161e-05,  1.3224e-04,\n",
            "         1.3241e-04, -1.9384e-05,  2.6389e-05, -6.4890e-07, -6.3566e-06,\n",
            "        -7.8728e-05,  8.0783e-05, -7.3808e-06,  9.4813e-05, -2.4678e-05,\n",
            "        -4.3765e-05, -1.1090e-06, -3.2409e-06, -3.9783e-05, -2.1256e-05,\n",
            "        -3.8085e-05,  5.5136e-05, -6.8691e-06, -2.7855e-05,  9.3226e-05,\n",
            "        -4.3648e-05,  1.0560e-04, -1.7618e-05,  2.4679e-05, -6.4079e-06,\n",
            "         1.0319e-04, -9.7498e-06,  1.7026e-05,  6.0408e-05, -6.9432e-05,\n",
            "         5.1680e-06,  3.9439e-05, -6.6195e-05, -4.9784e-06, -4.5434e-05,\n",
            "         4.4126e-05, -2.1575e-05, -6.9439e-05,  1.2750e-05,  1.7576e-04,\n",
            "        -2.7923e-05,  4.5452e-05, -6.0817e-05,  6.4460e-05, -1.1101e-05,\n",
            "        -8.9764e-05, -4.6206e-05, -2.8395e-05, -2.1579e-05, -1.7549e-05,\n",
            "         1.1091e-04,  7.3988e-05,  1.4186e-05,  2.5702e-05,  6.1398e-05,\n",
            "        -7.3961e-06, -3.7619e-05, -5.6771e-05, -4.1085e-05, -1.0859e-05,\n",
            "         1.5595e-05, -9.1481e-06,  2.3902e-05,  6.9911e-05, -4.2057e-05,\n",
            "        -1.6146e-05, -4.6404e-06,  5.2281e-05,  6.5828e-05, -4.2084e-05,\n",
            "        -6.2592e-05, -4.8353e-05,  3.9721e-06, -1.5530e-05,  9.8896e-05,\n",
            "         1.0716e-04, -8.5856e-05,  2.1646e-05,  2.7192e-06,  5.3066e-05,\n",
            "         2.4188e-05, -3.1831e-05,  1.3495e-05, -6.1902e-05,  2.1154e-05,\n",
            "         4.2797e-06, -3.6959e-05, -4.9392e-05,  3.4436e-06,  5.1583e-05,\n",
            "         3.4091e-06,  6.0918e-05,  6.3394e-05,  5.8009e-05, -1.1049e-05,\n",
            "        -9.3594e-07, -4.1063e-05,  1.1637e-05, -5.8419e-05, -6.7991e-05,\n",
            "        -2.4725e-05,  8.8974e-06,  3.6068e-05, -8.1256e-05,  6.3591e-06,\n",
            "         6.6732e-05,  2.8339e-05,  2.0305e-05,  1.9785e-06,  2.3362e-05,\n",
            "        -7.5769e-06,  1.0846e-05, -5.6642e-06, -6.6923e-06, -5.9253e-06,\n",
            "         2.6270e-05, -1.8386e-05,  3.0542e-05,  4.2168e-05,  5.8650e-05,\n",
            "         1.7513e-05,  9.3599e-06, -7.2734e-05, -5.6560e-05, -4.5307e-05,\n",
            "         6.8564e-06,  5.6228e-05,  8.1172e-05,  2.5285e-05, -9.8389e-06,\n",
            "        -4.9068e-05,  2.1424e-05, -2.5135e-05, -7.3242e-06,  1.0742e-05,\n",
            "         1.1605e-05, -1.5174e-05, -5.8644e-06, -3.6486e-05,  1.5693e-04,\n",
            "        -5.1373e-05,  9.2342e-05,  1.2172e-04,  5.9882e-05,  8.2810e-06,\n",
            "         7.4275e-05,  1.4380e-04,  3.3887e-05,  2.1011e-05,  4.7505e-05,\n",
            "        -1.5959e-05, -1.9709e-05,  1.7484e-05,  8.1689e-06,  6.7586e-06,\n",
            "         5.6699e-05, -6.9181e-05,  5.3793e-05,  4.7435e-05,  8.3425e-05,\n",
            "         2.0189e-05,  7.0164e-05,  3.2759e-05, -1.6321e-06, -2.5998e-05,\n",
            "         1.6499e-06, -9.1527e-05,  2.1192e-05, -8.7823e-05, -3.1088e-05,\n",
            "         2.7096e-05,  1.4876e-05,  2.5671e-06, -4.3585e-05,  3.1245e-05,\n",
            "        -2.3345e-05,  1.8802e-05,  5.1933e-05,  2.0411e-05,  1.1914e-04,\n",
            "         7.4075e-05, -3.9036e-05,  7.5943e-06,  9.8864e-07, -3.0352e-06,\n",
            "        -2.1779e-05,  1.8831e-05, -1.1353e-05, -9.5467e-05,  2.1781e-05,\n",
            "        -1.5979e-05, -8.4047e-05,  2.8895e-05,  8.3266e-06, -3.1013e-05,\n",
            "        -6.4176e-05,  1.1215e-06, -4.1473e-05, -5.3377e-05,  7.0356e-05,\n",
            "         2.7177e-05, -3.9165e-05,  4.4327e-05, -3.5332e-05, -1.9862e-05,\n",
            "         1.2751e-05, -3.3038e-05,  8.2294e-05,  1.4883e-05, -2.7735e-05,\n",
            "         1.1521e-05,  9.7027e-05,  1.0104e-05,  8.9531e-05,  1.3644e-05,\n",
            "         1.7692e-05,  8.1422e-06, -5.6214e-05, -1.0961e-04, -1.7704e-05,\n",
            "         2.8548e-05, -6.0276e-05,  6.6836e-05, -2.4106e-05, -2.0245e-05,\n",
            "         5.2947e-06, -4.2799e-05,  2.4624e-05, -5.2619e-05,  8.0240e-05,\n",
            "        -7.4333e-05,  4.2202e-05,  2.5046e-05,  6.7866e-05, -6.4328e-05,\n",
            "        -4.7283e-05,  2.0782e-05, -1.2451e-05,  1.4127e-05, -7.3532e-06,\n",
            "         1.5482e-05, -8.3375e-05, -5.9749e-05, -3.2483e-05, -7.7258e-06,\n",
            "         1.3163e-06, -3.3169e-05, -3.9669e-05, -4.0142e-05,  1.4963e-04,\n",
            "         1.7834e-05,  2.4580e-05,  1.0382e-05, -2.6635e-05,  1.8420e-05,\n",
            "        -2.4283e-06,  5.2601e-06, -9.6001e-06,  4.7965e-05, -5.2373e-05,\n",
            "         2.5379e-05,  3.8032e-05, -2.6555e-05,  7.9791e-06, -2.2439e-05,\n",
            "        -3.5727e-05,  4.0434e-05,  1.9826e-05,  4.8633e-05, -1.3513e-05,\n",
            "        -5.1705e-07, -3.2966e-05, -4.3748e-05,  5.4882e-05,  4.7425e-06,\n",
            "        -6.9161e-05, -1.5417e-05, -1.8033e-05, -8.6053e-05,  9.7431e-05,\n",
            "         7.0817e-05, -3.2174e-05,  7.1960e-06, -3.7944e-05, -2.6083e-05,\n",
            "        -6.6299e-05,  1.3502e-05, -8.2065e-07, -4.1507e-05,  6.5439e-06,\n",
            "         7.8551e-06, -1.9087e-05,  8.9258e-05, -1.9971e-05,  5.0325e-06,\n",
            "        -3.3112e-05,  1.6111e-05, -4.9215e-05, -3.2713e-05,  4.0226e-06,\n",
            "        -3.0189e-05,  5.1561e-06, -4.3690e-05, -8.6797e-05, -5.8896e-05,\n",
            "        -5.3185e-05,  5.4050e-06, -2.9486e-06,  3.1358e-05,  2.0954e-05,\n",
            "        -3.4323e-05,  8.0296e-06, -7.4986e-06,  3.9403e-05,  3.7830e-05,\n",
            "        -1.0746e-05,  8.9438e-06, -1.8026e-05, -3.0942e-06, -2.4155e-05,\n",
            "         2.2585e-05,  6.3006e-05, -2.6073e-05,  3.0868e-05, -5.8947e-05,\n",
            "        -1.1935e-05, -3.2754e-05,  2.7413e-06,  1.1836e-05,  1.2029e-05,\n",
            "         1.9825e-05,  2.3182e-05, -1.1574e-05,  1.3820e-04, -8.4923e-05,\n",
            "        -5.6194e-05, -7.6551e-05,  9.2180e-05,  4.0063e-05,  2.4176e-06,\n",
            "        -2.9581e-05, -4.8848e-05,  2.1433e-05, -6.5894e-05,  2.9485e-05,\n",
            "         1.6529e-05, -4.2812e-05,  9.2987e-05, -8.0681e-05, -1.3139e-04,\n",
            "        -9.3195e-06, -1.5961e-05,  2.7965e-05,  1.5362e-05,  2.5959e-05,\n",
            "        -7.8478e-06, -3.7748e-06,  2.9956e-05,  4.2324e-05,  4.7976e-05,\n",
            "         1.1634e-04,  1.9952e-05,  1.8284e-05, -1.8896e-06, -1.5485e-05,\n",
            "         2.2857e-05, -1.5547e-05,  6.2795e-05, -3.8214e-05, -8.7339e-06,\n",
            "        -2.8485e-05, -6.8607e-05, -4.2793e-05,  2.6586e-06, -2.7480e-05,\n",
            "         7.4844e-06,  5.7894e-05,  9.4906e-06, -3.8922e-05, -6.4127e-05,\n",
            "         2.6062e-06,  1.2438e-04,  2.7930e-05,  9.5797e-06,  4.1646e-05,\n",
            "         3.1806e-05, -4.1491e-05,  2.0385e-05, -1.2157e-05,  2.8431e-05,\n",
            "        -2.9843e-05, -5.2175e-05, -2.4882e-05, -7.0621e-05, -8.1345e-05,\n",
            "         7.6138e-06, -1.1148e-05,  1.0194e-05, -5.7052e-05, -1.0010e-04,\n",
            "         3.3505e-05, -7.4227e-05, -6.1591e-05,  6.4809e-05, -1.8930e-05,\n",
            "        -4.1174e-05,  3.1389e-05, -1.8080e-05, -1.0336e-05, -2.0328e-05,\n",
            "         2.3235e-05, -5.6425e-06, -3.1226e-05, -4.2921e-06,  5.1350e-05,\n",
            "         3.2698e-05, -3.0709e-05,  7.0457e-05,  5.3746e-05,  9.0801e-06,\n",
            "        -2.1656e-05,  7.3628e-05,  6.9605e-06, -6.2944e-06,  2.8345e-05,\n",
            "        -8.5422e-05, -6.1818e-06, -2.9212e-05,  2.5601e-05, -6.5941e-05,\n",
            "         8.3984e-05,  2.0120e-06, -6.9679e-05,  6.8818e-05,  2.8541e-05,\n",
            "        -1.0083e-04,  4.1635e-05,  1.2711e-04, -6.1277e-05,  9.4712e-05,\n",
            "        -1.7202e-05,  1.1712e-05, -1.9719e-06,  6.2437e-07, -4.9762e-05,\n",
            "        -2.7085e-05,  3.5300e-05,  1.0772e-04,  2.0983e-05, -8.9413e-05,\n",
            "         2.1082e-05, -3.7123e-05,  8.4936e-06,  7.6464e-06, -8.5095e-05,\n",
            "         3.0911e-05, -3.3861e-05, -6.2158e-05,  3.0299e-05,  5.3212e-05,\n",
            "        -5.0952e-05,  2.1595e-05, -3.7943e-05,  1.5756e-05, -2.5568e-05,\n",
            "         2.5828e-05,  3.7022e-05,  2.3512e-05,  3.8387e-05,  2.3354e-05,\n",
            "        -6.9471e-05,  2.5715e-05,  1.9095e-05,  2.2369e-05, -3.9283e-05,\n",
            "        -3.9351e-06, -2.9421e-05,  1.1257e-05,  1.4758e-04, -3.0356e-05,\n",
            "        -6.3298e-05, -1.6225e-05])), ('module.encoder_k.layer4.0.bn2.running_mean', tensor([-0.6730,  0.1980, -0.0735, -0.2252,  0.7879,  0.5490, -0.3386, -0.2660,\n",
            "        -0.0717, -0.5283,  0.5805, -0.3340,  0.2203,  0.4728, -0.3016,  0.0065,\n",
            "         0.0589,  0.5734, -0.3634, -0.5054,  0.0401, -0.0918,  0.0184,  0.1702,\n",
            "        -0.1045,  0.1148,  0.0318,  0.4266, -0.4219, -0.2262,  0.8793,  0.1657,\n",
            "         0.1440,  0.2207,  0.3010,  0.4616,  0.0996,  0.5893,  0.0843, -1.2616,\n",
            "         0.6238,  0.1491,  0.7318, -0.4204,  0.1709,  0.0431, -0.1235,  0.8938,\n",
            "         0.4567, -0.3265, -0.5082,  0.0873, -0.1729,  0.9553, -0.0993,  0.0568,\n",
            "         0.5703,  0.5240,  0.1406,  0.1516, -0.1373,  0.3795, -0.3261,  0.2153,\n",
            "        -0.2866, -0.0325, -0.4838,  0.8938, -0.0887,  0.3626, -0.6592,  0.6571,\n",
            "         0.2777,  0.7570,  0.1588,  0.2811,  0.1687, -0.4145,  0.0472, -0.0839,\n",
            "         0.8087, -0.2202,  0.1619,  0.3816, -0.0985,  0.2199,  0.3240,  0.6045,\n",
            "         0.1123,  0.4524, -0.1471, -0.6211, -0.2918, -0.1915,  0.2723, -0.4541,\n",
            "        -0.0865,  0.1968, -0.2700, -0.0441, -0.5238,  0.5486, -0.4938,  0.1456,\n",
            "         0.2580,  0.0097, -0.5123, -0.6213,  0.2100,  0.2978, -0.1788, -0.5806,\n",
            "         0.2651,  0.4118,  0.2954,  0.1443,  0.4043, -0.0102,  0.2485, -0.2038,\n",
            "         0.1217,  0.1387,  0.2582, -0.4744, -0.5879, -0.1082, -0.2940, -0.4045,\n",
            "        -0.4956, -0.8084,  0.3080,  0.3141, -0.0025, -0.0915,  0.4162,  0.0157,\n",
            "         0.4180,  0.1352,  0.2188, -0.6799,  0.2717, -0.7152,  0.5018,  0.1304,\n",
            "         0.3604,  0.1154,  0.6601, -0.4371, -0.1331,  0.5482, -0.0890, -0.2040,\n",
            "        -0.0596,  0.3686,  0.7857, -0.1088,  0.5168, -0.8390, -0.2395, -0.1774,\n",
            "         0.8760, -0.5913,  0.1431,  0.0200,  0.3820,  0.8005,  0.8048,  0.9362,\n",
            "        -0.1212,  0.7528,  0.2079,  0.1703, -0.5064,  0.6031, -0.3660, -0.0779,\n",
            "         1.3509,  0.1113, -0.6938,  0.2447,  0.8635, -0.3928,  0.4266, -0.0129,\n",
            "        -0.7587,  0.1468,  0.0957,  0.7801, -0.8862, -0.6023, -0.0562,  0.4906,\n",
            "        -0.1542,  0.2500,  0.9239, -0.0760,  0.1710, -0.3391,  0.4914,  0.1912,\n",
            "        -0.0412,  0.1129,  0.4783,  0.8405, -0.3410,  0.4506, -0.2758, -0.2250,\n",
            "        -0.5542, -0.1632,  0.2553, -0.5054, -0.3899,  0.5210, -0.3733,  0.0659,\n",
            "        -0.2756,  0.0913,  0.3533, -0.6204, -0.1234,  0.0313,  0.0097,  0.0956,\n",
            "        -0.5838, -0.2842,  0.1636,  0.1425, -0.5798,  0.3964, -0.0836, -0.2364,\n",
            "        -0.3049,  0.2966,  0.7214, -0.6543, -0.2785,  0.9106,  0.4059,  0.1039,\n",
            "         0.2600, -0.2089, -0.3045,  0.0283,  0.4400, -0.5799,  0.2381, -0.2226,\n",
            "         0.2176,  0.0480,  0.3894,  0.0245, -0.5129,  0.1024,  1.0944,  0.1958,\n",
            "        -0.0375, -0.7422, -0.4289,  0.7595,  0.2424, -0.0949, -0.7161,  0.1289,\n",
            "        -0.3790,  0.7712,  0.1291,  0.3137, -0.6031,  0.2814, -0.1759,  0.7616,\n",
            "         0.1941, -0.4151,  0.8812, -0.9434, -0.2580, -0.2399,  0.2135, -0.4952,\n",
            "         0.7299, -0.4829,  0.3209,  0.2958,  0.5171,  0.2001,  0.0460, -0.3718,\n",
            "         0.0478,  0.4145, -0.1596,  0.6187, -0.2012,  0.4045, -0.2993, -0.6446,\n",
            "         0.0555, -0.5777, -0.4028,  0.7160, -0.3201, -0.0270,  0.2995,  0.1141,\n",
            "        -0.5347,  0.3940,  0.3185,  0.3884, -0.1493, -0.1493, -0.5431, -0.4109,\n",
            "        -0.1025,  0.5262, -0.2801,  0.6001, -0.2671,  0.2478,  0.2797, -0.3034,\n",
            "         0.9757, -0.2997, -0.8821,  0.5791,  0.0709,  0.4359,  0.0072,  0.3370,\n",
            "         0.1728, -0.0447, -0.0619,  0.2087,  0.0407,  0.6410,  0.4788,  0.7981,\n",
            "         0.5966, -0.2084, -0.4165,  0.1943, -0.5904,  0.1129,  0.2163, -0.2321,\n",
            "        -0.1368,  0.2655,  0.1476, -0.1445, -1.1512,  0.7890,  0.4367,  0.0085,\n",
            "        -0.5823, -0.2543,  0.0072,  0.0425,  0.3256,  0.2345, -0.1679,  0.2056,\n",
            "         0.3384, -0.2259, -0.2174,  0.2539,  0.5076, -0.1941,  0.2661, -1.0778,\n",
            "         0.1722,  0.1092, -0.4840, -0.1493, -0.0252,  0.1895, -0.0384, -0.6860,\n",
            "         0.5750, -0.0269, -0.4592,  0.2431, -0.4649, -0.6444, -0.0952,  0.2847,\n",
            "        -0.1522, -0.6339, -0.0941,  0.0390, -0.1928,  0.6203,  0.2090,  1.0415,\n",
            "         1.0213,  0.5256, -0.0493,  0.2344, -0.0039, -0.6394,  0.7617,  0.4434,\n",
            "        -0.0951, -0.0237, -0.5901,  0.2599,  0.0634, -0.3220, -0.2063,  0.1030,\n",
            "        -0.1059,  0.4197,  0.3452, -0.0537, -0.4879,  0.2094,  0.0968,  0.2855,\n",
            "         0.1008, -0.0742,  0.0192,  0.3075,  0.1887,  0.0372,  0.2747, -0.3520,\n",
            "         0.2682, -0.2355,  0.3831,  0.0182,  0.7400,  0.0446,  0.7082, -0.3719,\n",
            "         0.3129,  0.1345, -0.2350,  0.7870,  0.7135,  0.0385,  0.1119,  0.2622,\n",
            "        -0.5589,  0.9734, -0.0234, -0.1397,  0.0409, -0.4415,  0.2868, -0.0232,\n",
            "         0.4942,  0.7642,  0.0967, -0.5358,  0.1978, -0.7216, -0.4695,  0.0492,\n",
            "         0.2038, -0.0813, -0.1221, -0.4526, -0.2240,  0.6357, -0.1941,  0.7240,\n",
            "        -0.4074, -0.1681, -0.4797, -0.1540, -0.2694,  0.2733,  0.1685, -0.2183,\n",
            "         0.1807, -0.1110,  0.5452,  0.6892,  0.5614,  0.3090,  0.8087, -0.2843,\n",
            "        -0.4062, -0.3100, -0.0209, -0.1193, -0.9884, -0.1645,  0.1054, -0.4246,\n",
            "         0.4895, -0.7753,  0.0380,  0.4885,  0.0755, -0.0382, -0.6626, -1.0547,\n",
            "        -0.2241, -0.2954, -0.4018,  0.3755, -0.3022,  0.0886, -0.2813,  0.3503,\n",
            "        -0.3408, -0.1237, -0.5948,  0.0633,  0.5630, -0.5232,  0.2817,  0.3438])), ('module.encoder_k.layer4.0.bn2.running_var', tensor([1.1912, 0.5204, 0.5029, 0.4939, 1.1747, 0.5835, 0.7345, 0.6135, 0.5074,\n",
            "        0.5322, 0.5018, 0.6216, 0.6762, 0.5571, 0.5453, 0.5354, 0.6557, 1.3212,\n",
            "        0.9669, 0.7852, 0.6187, 0.6328, 0.6153, 0.5043, 0.5926, 0.5319, 0.5980,\n",
            "        1.0330, 1.0134, 0.9057, 1.0414, 0.6987, 0.6892, 0.5578, 0.6289, 0.5975,\n",
            "        0.7391, 0.8987, 0.7055, 1.0598, 0.6188, 1.3411, 1.1882, 0.9674, 0.6829,\n",
            "        0.6675, 0.7297, 0.6930, 0.7780, 0.7952, 0.8610, 0.5689, 0.6535, 0.7688,\n",
            "        0.5492, 0.6107, 1.0343, 0.6177, 0.8167, 0.7457, 0.5132, 1.1930, 0.7970,\n",
            "        0.5592, 0.8476, 0.6632, 0.8832, 0.6741, 0.6125, 0.6602, 0.6033, 1.6122,\n",
            "        0.5565, 0.6540, 0.5806, 0.5134, 0.5284, 0.5772, 0.6890, 0.5386, 2.0940,\n",
            "        1.0087, 0.5433, 0.6614, 0.9899, 0.5501, 0.5795, 0.6178, 0.6962, 0.7635,\n",
            "        0.6180, 0.5478, 0.6558, 0.5391, 0.5952, 0.5461, 0.5476, 0.5506, 0.5416,\n",
            "        0.6520, 1.0371, 0.6937, 0.5434, 0.5143, 0.8147, 0.6643, 0.5593, 0.7945,\n",
            "        0.7011, 0.6783, 0.5455, 0.6011, 0.7126, 0.5473, 0.5798, 0.5597, 0.9208,\n",
            "        0.7378, 0.5776, 0.5993, 0.6213, 0.5872, 0.8238, 0.8729, 0.6863, 0.6360,\n",
            "        0.5692, 0.6878, 0.7416, 1.2716, 1.6524, 0.6528, 0.5746, 0.5926, 0.8949,\n",
            "        0.6853, 0.7368, 0.6566, 0.7086, 0.8066, 0.7814, 0.8389, 0.5759, 0.5745,\n",
            "        1.1160, 0.7769, 2.0508, 0.5022, 0.6853, 0.5793, 0.6568, 0.8670, 0.7110,\n",
            "        1.5284, 0.9793, 1.0553, 1.1725, 1.6479, 0.4868, 0.6819, 0.8317, 1.3362,\n",
            "        0.4953, 0.5312, 0.7174, 0.5809, 1.1084, 1.0808, 0.4999, 1.4809, 0.6182,\n",
            "        0.6608, 0.5739, 0.9170, 1.1291, 0.5831, 1.2673, 0.8971, 1.1124, 0.9341,\n",
            "        1.0257, 0.6082, 0.6363, 0.6440, 1.1260, 0.5070, 0.6868, 0.5548, 0.7142,\n",
            "        1.1449, 0.6868, 0.7905, 0.9217, 0.7404, 0.7372, 0.5529, 0.6787, 0.5490,\n",
            "        1.1332, 1.2563, 0.5315, 0.9620, 0.6073, 0.8750, 0.5571, 0.7702, 1.8060,\n",
            "        0.9069, 0.6074, 0.8361, 1.1131, 0.5988, 1.0557, 0.6907, 0.8846, 0.5618,\n",
            "        0.6604, 0.4850, 0.9978, 0.5284, 0.5912, 0.5725, 0.5949, 0.6758, 0.6645,\n",
            "        0.5807, 1.1301, 0.9824, 1.0770, 1.0533, 0.5327, 0.5443, 0.6217, 0.6089,\n",
            "        0.8545, 0.7602, 0.5383, 2.0402, 1.0538, 0.6443, 0.8344, 0.5171, 0.5047,\n",
            "        0.5372, 0.6699, 0.7182, 0.8056, 0.6379, 0.4894, 0.5881, 0.5380, 1.4216,\n",
            "        0.5896, 0.5609, 2.3827, 0.5133, 0.8481, 0.5676, 0.5090, 1.9047, 0.5272,\n",
            "        0.8620, 0.7847, 0.6184, 0.6951, 0.7761, 0.8741, 0.4945, 0.6288, 0.4793,\n",
            "        0.8668, 1.3724, 0.4850, 0.5170, 0.7713, 1.3164, 0.8605, 0.5621, 0.5742,\n",
            "        1.9468, 1.0395, 1.1797, 0.7797, 0.8150, 1.2362, 0.5918, 0.5226, 0.7245,\n",
            "        0.5349, 0.7918, 0.6256, 0.5503, 1.0325, 0.5886, 0.5942, 0.9044, 0.5200,\n",
            "        0.8993, 0.9440, 1.2195, 0.7024, 0.7039, 0.6030, 0.8524, 0.7664, 0.5752,\n",
            "        1.1694, 0.5240, 0.5104, 0.6532, 1.3492, 0.5370, 0.5764, 0.5233, 0.8326,\n",
            "        1.3606, 0.5609, 0.7556, 2.1616, 0.7057, 1.5769, 1.6066, 0.6670, 1.1151,\n",
            "        0.8500, 0.4967, 0.5015, 0.6618, 0.6000, 0.6194, 0.6501, 0.5697, 0.6109,\n",
            "        0.5257, 0.5141, 1.7762, 0.5227, 0.5103, 1.2384, 0.7955, 0.9611, 0.5079,\n",
            "        0.5163, 0.5448, 0.6085, 0.7280, 0.8483, 0.6875, 1.6396, 1.1454, 1.2218,\n",
            "        0.5915, 0.9905, 0.7022, 0.5619, 0.4884, 0.5716, 0.4887, 0.5468, 0.5144,\n",
            "        1.0877, 0.5599, 0.7193, 0.4739, 0.7617, 0.9041, 0.9345, 1.3342, 0.9425,\n",
            "        0.6544, 0.8948, 0.6815, 0.4973, 0.5107, 1.0573, 0.6890, 0.7493, 0.8501,\n",
            "        0.8202, 0.5275, 1.0196, 1.5388, 0.5451, 0.6710, 0.4903, 1.1333, 0.5823,\n",
            "        0.7134, 0.5271, 0.7000, 0.7534, 1.3425, 1.8830, 0.7458, 0.5135, 0.7950,\n",
            "        0.5514, 0.8138, 1.6149, 0.6530, 0.5844, 0.9995, 0.5962, 0.6492, 1.1095,\n",
            "        0.5460, 0.7351, 0.5499, 0.6204, 0.7105, 0.6686, 0.6255, 1.7774, 0.6612,\n",
            "        0.7811, 0.8044, 0.6085, 0.5600, 0.6645, 0.8724, 0.5835, 0.6016, 0.6667,\n",
            "        0.5595, 0.5907, 1.1059, 0.5544, 0.8475, 0.7792, 0.6556, 0.7920, 0.8798,\n",
            "        0.6148, 0.6217, 0.5970, 1.5280, 0.5789, 0.5493, 0.5703, 0.5562, 0.6479,\n",
            "        0.7439, 0.5231, 0.5402, 0.9320, 0.5277, 0.8861, 0.5265, 0.7847, 0.7738,\n",
            "        1.0694, 0.5915, 0.6534, 0.5387, 0.8196, 0.7189, 0.5146, 0.9122, 0.5696,\n",
            "        0.5609, 0.5230, 0.6421, 0.5844, 1.2134, 0.5995, 0.8601, 0.6009, 0.7729,\n",
            "        0.5565, 0.7004, 0.5059, 0.7092, 0.5734, 0.5256, 0.5440, 0.6639, 0.6712,\n",
            "        0.7251, 0.9310, 0.5155, 1.2825, 0.5066, 0.5431, 0.5343, 2.4402, 0.6883,\n",
            "        0.5393, 0.5746, 0.5237, 0.7483, 0.5013, 0.8262, 0.7070, 0.5934, 1.1791,\n",
            "        0.8009, 0.6069, 0.5331, 0.6176, 1.0012, 0.7920, 0.8002, 0.6031, 1.2464,\n",
            "        0.5408, 0.5926, 0.5432, 0.5791, 1.3879, 1.6850, 0.5015, 0.5622])), ('module.encoder_k.layer4.0.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.0.conv3.weight', tensor([[[[ 0.0159]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         [[ 0.0361]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0444]],\n",
            "\n",
            "         [[ 0.0104]],\n",
            "\n",
            "         [[ 0.0138]]],\n",
            "\n",
            "\n",
            "        [[[-0.0201]],\n",
            "\n",
            "         [[ 0.0587]],\n",
            "\n",
            "         [[-0.0445]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0233]],\n",
            "\n",
            "         [[-0.0158]],\n",
            "\n",
            "         [[ 0.0266]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0272]],\n",
            "\n",
            "         [[ 0.0026]],\n",
            "\n",
            "         [[-0.0751]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0253]],\n",
            "\n",
            "         [[-0.0184]],\n",
            "\n",
            "         [[-0.0293]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0098]],\n",
            "\n",
            "         [[-0.0101]],\n",
            "\n",
            "         [[-0.0359]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0094]],\n",
            "\n",
            "         [[ 0.0429]],\n",
            "\n",
            "         [[-0.0484]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0120]],\n",
            "\n",
            "         [[-0.0370]],\n",
            "\n",
            "         [[-0.0424]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         [[ 0.0001]],\n",
            "\n",
            "         [[-0.0105]]],\n",
            "\n",
            "\n",
            "        [[[-0.0056]],\n",
            "\n",
            "         [[-0.0049]],\n",
            "\n",
            "         [[ 0.0565]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0058]],\n",
            "\n",
            "         [[ 0.0320]],\n",
            "\n",
            "         [[-0.0146]]]])), ('module.encoder_k.layer4.0.bn3.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer4.0.bn3.bias', tensor([ 3.7733e-05, -1.7901e-05,  9.7756e-05,  ..., -5.2823e-05,\n",
            "        -3.1535e-05,  2.0119e-05])), ('module.encoder_k.layer4.0.bn3.running_mean', tensor([ 0.3678,  0.0725,  0.1352,  ..., -0.0075, -0.1809,  0.1094])), ('module.encoder_k.layer4.0.bn3.running_var', tensor([0.1334, 0.1787, 0.1837,  ..., 0.1429, 0.1625, 0.1403])), ('module.encoder_k.layer4.0.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.0.downsample.0.weight', tensor([[[[-0.0092]],\n",
            "\n",
            "         [[ 0.0398]],\n",
            "\n",
            "         [[-0.0040]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0229]],\n",
            "\n",
            "         [[-0.0217]],\n",
            "\n",
            "         [[ 0.0304]]],\n",
            "\n",
            "\n",
            "        [[[-0.0108]],\n",
            "\n",
            "         [[ 0.0288]],\n",
            "\n",
            "         [[ 0.0124]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0260]],\n",
            "\n",
            "         [[ 0.0206]],\n",
            "\n",
            "         [[ 0.0582]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0095]],\n",
            "\n",
            "         [[ 0.0102]],\n",
            "\n",
            "         [[-0.0018]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[ 0.0161]],\n",
            "\n",
            "         [[ 0.0116]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0110]],\n",
            "\n",
            "         [[ 0.0109]],\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0108]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         [[-0.0384]]],\n",
            "\n",
            "\n",
            "        [[[-0.0086]],\n",
            "\n",
            "         [[ 0.0179]],\n",
            "\n",
            "         [[ 0.0299]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0559]],\n",
            "\n",
            "         [[-0.0078]],\n",
            "\n",
            "         [[-0.0077]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0498]],\n",
            "\n",
            "         [[-0.0128]],\n",
            "\n",
            "         [[-0.0127]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0070]],\n",
            "\n",
            "         [[-0.0394]],\n",
            "\n",
            "         [[ 0.0189]]]])), ('module.encoder_k.layer4.0.downsample.1.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer4.0.downsample.1.bias', tensor([ 3.7733e-05, -1.7901e-05,  9.7756e-05,  ..., -5.2823e-05,\n",
            "        -3.1535e-05,  2.0119e-05])), ('module.encoder_k.layer4.0.downsample.1.running_mean', tensor([-0.0269,  0.7928, -0.1374,  ...,  0.7843,  1.1869,  0.2255])), ('module.encoder_k.layer4.0.downsample.1.running_var', tensor([2.6546, 2.6409, 2.4613,  ..., 2.2428, 2.1041, 2.0316])), ('module.encoder_k.layer4.0.downsample.1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.1.conv1.weight', tensor([[[[ 0.1075]],\n",
            "\n",
            "         [[-0.0203]],\n",
            "\n",
            "         [[-0.0369]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0537]],\n",
            "\n",
            "         [[-0.0454]],\n",
            "\n",
            "         [[-0.0788]]],\n",
            "\n",
            "\n",
            "        [[[-0.0641]],\n",
            "\n",
            "         [[ 0.0741]],\n",
            "\n",
            "         [[ 0.1192]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1633]],\n",
            "\n",
            "         [[-0.0337]],\n",
            "\n",
            "         [[-0.1341]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0063]],\n",
            "\n",
            "         [[ 0.0592]],\n",
            "\n",
            "         [[ 0.0986]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0338]],\n",
            "\n",
            "         [[ 0.0681]],\n",
            "\n",
            "         [[-0.0238]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0541]],\n",
            "\n",
            "         [[ 0.0601]],\n",
            "\n",
            "         [[-0.0647]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0883]],\n",
            "\n",
            "         [[ 0.0789]],\n",
            "\n",
            "         [[ 0.1152]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0114]],\n",
            "\n",
            "         [[-0.0776]],\n",
            "\n",
            "         [[-0.0684]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0412]],\n",
            "\n",
            "         [[ 0.0039]],\n",
            "\n",
            "         [[-0.0706]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0064]],\n",
            "\n",
            "         [[ 0.0453]],\n",
            "\n",
            "         [[-0.0340]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0136]],\n",
            "\n",
            "         [[-0.0372]],\n",
            "\n",
            "         [[-0.0743]]]])), ('module.encoder_k.layer4.1.bn1.weight', tensor([0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9993, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9993, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9990, 0.9993, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990,\n",
            "        0.9990, 0.9990, 0.9992, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9992, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9993, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9992, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9993, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9990])), ('module.encoder_k.layer4.1.bn1.bias', tensor([ 7.7351e-06,  3.1545e-06,  1.8457e-05,  9.9503e-05, -9.1852e-06,\n",
            "        -2.9361e-05,  1.2625e-05, -4.2539e-05,  1.6529e-05,  6.7669e-06,\n",
            "        -9.9927e-05,  1.8891e-04, -7.0090e-05,  1.0295e-05,  1.4052e-05,\n",
            "         3.5820e-05, -2.2360e-05,  7.3018e-05, -3.2795e-05,  1.0720e-04,\n",
            "        -3.9937e-05,  1.7904e-06, -1.0179e-05, -3.9752e-06, -3.1103e-05,\n",
            "        -2.0132e-05, -1.4744e-05, -1.2957e-05,  3.2692e-05, -3.7004e-08,\n",
            "        -6.5165e-05, -6.0476e-05, -4.1914e-05, -5.9496e-05, -2.0055e-05,\n",
            "         3.1271e-05, -5.9353e-05, -2.7622e-05, -1.5529e-05, -2.6590e-05,\n",
            "        -1.0219e-04, -2.8131e-05,  3.5881e-05,  2.2759e-05, -3.6821e-05,\n",
            "         1.9178e-05, -1.5341e-05, -5.9901e-05,  3.7315e-05,  5.7793e-05,\n",
            "         2.5293e-05, -2.1816e-05, -4.5208e-06, -7.4887e-05, -4.0379e-06,\n",
            "         2.8678e-05,  3.5181e-05, -4.4656e-05, -2.2484e-05,  2.0283e-05,\n",
            "         1.0509e-04,  1.4761e-05,  5.2678e-06,  8.1491e-06, -4.7562e-05,\n",
            "         3.5879e-05,  3.3458e-05, -1.0033e-07,  5.8550e-06,  1.9321e-05,\n",
            "        -2.9207e-05, -8.4204e-05,  8.1017e-06,  1.2002e-05,  4.3310e-05,\n",
            "         3.7401e-05,  8.6902e-06, -4.8311e-05,  9.1804e-07, -7.6324e-05,\n",
            "        -5.7448e-05,  5.7048e-05,  3.9975e-06,  1.5129e-05,  7.5540e-05,\n",
            "        -7.2358e-06,  3.1649e-05, -3.2566e-05,  1.4209e-05, -6.8193e-05,\n",
            "         5.9716e-06,  3.7885e-05,  3.7921e-05, -4.6921e-06, -6.3704e-05,\n",
            "         2.3939e-05, -3.5916e-05,  1.4393e-04, -2.6658e-05, -2.3026e-06,\n",
            "         3.1602e-05, -5.1621e-06, -1.0606e-05,  2.8010e-05, -3.1313e-05,\n",
            "         3.5538e-05,  4.2245e-05,  3.2399e-06,  1.1851e-05,  1.6589e-06,\n",
            "        -1.6193e-05,  3.9419e-05, -3.4960e-05,  1.0953e-05,  1.4326e-05,\n",
            "        -9.5359e-05, -4.0191e-05, -3.5813e-05, -5.7763e-06, -9.1336e-06,\n",
            "         1.6832e-05,  4.0413e-05, -3.4136e-05,  1.0761e-04, -6.9361e-05,\n",
            "        -6.3977e-06,  1.0699e-05, -2.0511e-07,  2.8392e-05,  1.1774e-05,\n",
            "        -3.6177e-05,  4.1145e-05,  2.2845e-05, -1.1915e-05,  2.6361e-05,\n",
            "         5.1612e-05,  1.9668e-05, -3.3318e-05, -2.2815e-05, -1.2800e-05,\n",
            "         3.2454e-05, -6.6383e-07,  5.0561e-05,  3.4264e-05, -5.2453e-05,\n",
            "        -3.8155e-05, -6.7530e-05,  5.5102e-05,  1.0053e-05, -3.5712e-06,\n",
            "         1.0570e-04, -9.7694e-05,  1.1780e-05, -1.2360e-05, -8.0035e-06,\n",
            "         7.7449e-06,  4.7421e-05,  1.3127e-05, -4.7863e-05,  2.1286e-05,\n",
            "        -9.1577e-06, -2.3410e-05,  3.9320e-06, -5.8050e-05, -3.8800e-05,\n",
            "        -1.6593e-05, -5.0004e-05,  2.4812e-05, -3.0707e-05,  2.7827e-05,\n",
            "         2.8380e-05,  2.6126e-05, -2.8348e-05,  8.2675e-05, -1.3805e-05,\n",
            "         5.2292e-05, -2.4424e-05,  2.8789e-05, -5.9727e-05, -6.0923e-05,\n",
            "         3.9293e-05, -3.7760e-05, -1.1543e-05,  7.8418e-06, -1.2268e-05,\n",
            "        -1.0425e-05,  1.7319e-05,  6.7758e-05, -3.8458e-05, -2.2840e-06,\n",
            "        -1.6503e-05, -1.9098e-05,  4.4031e-05,  1.0037e-05,  5.1538e-05,\n",
            "         5.4014e-05,  6.2077e-05, -4.2944e-05, -1.2419e-05,  6.1228e-05,\n",
            "         2.8723e-05, -5.7151e-05, -2.4395e-05,  2.1022e-05, -1.2414e-05,\n",
            "         7.8091e-06, -3.9211e-05,  3.3974e-05, -2.6262e-05,  5.5741e-06,\n",
            "         3.1519e-05,  1.5747e-06, -4.8813e-06, -3.2607e-05, -5.4437e-05,\n",
            "        -5.7088e-05, -1.6103e-05, -3.9434e-05, -6.2489e-05, -5.7842e-06,\n",
            "         5.6196e-05, -4.7661e-05,  8.7694e-06,  5.5165e-05,  4.2157e-05,\n",
            "        -6.0191e-05,  3.8163e-05, -4.1059e-05,  1.0730e-04,  1.3897e-05,\n",
            "        -5.1473e-05,  2.7438e-04, -1.4010e-05,  1.7444e-05, -1.1421e-05,\n",
            "        -1.8824e-05,  3.4563e-06,  2.3473e-05,  1.5044e-05,  7.1286e-05,\n",
            "         1.5065e-05, -6.7111e-06, -2.5175e-05, -8.7311e-06, -1.2506e-05,\n",
            "        -1.7330e-05, -1.0684e-05,  7.5087e-05,  3.9624e-05,  7.0168e-05,\n",
            "        -2.3518e-05, -4.6949e-05, -5.1943e-06, -8.4789e-05,  7.4385e-05,\n",
            "         8.0866e-05,  1.2417e-05,  1.1507e-05,  1.5892e-05,  4.5041e-05,\n",
            "         4.9426e-06, -5.9078e-06,  2.3335e-05,  1.8891e-05,  4.0255e-05,\n",
            "        -2.9458e-06,  3.5086e-05, -1.5783e-05,  3.8078e-05,  1.6657e-05,\n",
            "         4.8252e-06,  6.4589e-05,  1.5882e-05,  2.9565e-05, -4.7600e-05,\n",
            "         6.3159e-05, -1.2788e-05, -1.2679e-05, -2.3666e-05, -2.8540e-05,\n",
            "        -1.5342e-05,  1.8858e-05,  8.7213e-06,  2.8728e-05,  3.7976e-05,\n",
            "        -2.1158e-05,  4.1298e-05, -7.6259e-06,  3.9256e-06, -1.7728e-05,\n",
            "        -5.3896e-06, -1.1171e-05, -2.2691e-05,  4.7127e-05,  7.9584e-05,\n",
            "         4.0333e-05, -4.4290e-05,  2.4377e-05, -2.1337e-05,  3.8818e-05,\n",
            "        -3.5933e-05,  2.1973e-05,  3.5709e-05,  1.4276e-06,  4.9137e-05,\n",
            "        -4.0336e-06, -1.0202e-05,  1.9374e-05, -1.0800e-05,  8.7855e-08,\n",
            "         4.5124e-06,  3.9122e-05, -6.5890e-06,  1.6584e-05, -8.2942e-05,\n",
            "        -5.9669e-06, -1.9791e-05,  4.8112e-05, -7.7449e-06,  5.5777e-05,\n",
            "        -3.2170e-06, -8.2857e-06,  4.3338e-06, -4.3283e-05, -4.8636e-06,\n",
            "         6.7250e-06, -4.5842e-06, -3.9312e-05, -8.7301e-06, -9.2774e-06,\n",
            "         5.8826e-05,  8.4440e-05, -1.4606e-05,  1.4092e-05,  2.5563e-05,\n",
            "         2.6088e-06, -1.6337e-05,  1.2793e-05,  1.1770e-06,  1.7525e-05,\n",
            "        -7.8514e-05,  5.1186e-05, -4.4874e-05,  5.0081e-05, -1.5880e-05,\n",
            "        -2.0081e-05,  6.4174e-05,  2.0842e-05,  1.3009e-05,  2.5418e-05,\n",
            "        -3.2201e-05,  1.5436e-05,  1.4241e-05,  4.8093e-05, -5.3437e-06,\n",
            "         1.9734e-05,  2.1120e-05, -8.9381e-05, -4.8357e-07, -6.9631e-05,\n",
            "         1.0442e-05,  1.4183e-05, -8.5115e-06, -2.8260e-05, -3.5701e-05,\n",
            "        -3.8082e-05, -1.5517e-05,  4.3543e-05,  1.2119e-04,  1.0549e-05,\n",
            "        -3.4491e-05,  3.4381e-05,  6.7210e-05,  5.0018e-05, -4.4230e-05,\n",
            "         1.4666e-05,  3.1124e-05,  4.9459e-05,  5.2552e-05,  1.3828e-05,\n",
            "        -7.3843e-05,  1.0870e-05, -2.5016e-05, -1.0710e-05, -1.7511e-05,\n",
            "         1.1133e-05, -6.3114e-05, -2.8567e-05, -2.8132e-05,  4.8047e-06,\n",
            "         2.7199e-05,  2.4565e-06, -4.5114e-06,  1.2947e-05, -4.8145e-05,\n",
            "         2.0240e-05,  9.1736e-05, -7.5864e-06, -2.3433e-05, -4.8873e-05,\n",
            "         1.2757e-06,  7.7872e-05,  1.1299e-05, -1.2717e-05, -6.2518e-05,\n",
            "         5.9135e-05,  7.4702e-05, -3.5827e-05, -1.2228e-05, -9.2696e-06,\n",
            "         6.7077e-05, -3.5949e-05, -1.1418e-05,  2.1203e-05, -3.4744e-05,\n",
            "        -1.8525e-06,  1.2739e-05, -1.9602e-05, -4.6099e-05,  5.3250e-06,\n",
            "         3.9289e-05,  5.1996e-05,  1.0671e-05,  1.6050e-05,  4.3204e-05,\n",
            "        -3.5303e-05, -1.8542e-05, -8.8290e-06,  5.6014e-05,  5.2870e-06,\n",
            "        -3.5595e-05,  4.3684e-05, -2.3953e-05, -6.6203e-05, -3.0669e-05,\n",
            "        -2.2373e-05,  2.0959e-05, -2.3170e-05, -3.6372e-05, -2.9530e-05,\n",
            "         5.1669e-05, -3.1416e-05,  4.8296e-05, -4.1041e-05,  7.3428e-05,\n",
            "        -3.1127e-05, -1.8644e-05,  2.0576e-05, -1.7512e-05,  4.7349e-05,\n",
            "        -5.9568e-06, -2.0881e-06,  8.0874e-06, -1.8787e-05, -2.4019e-05,\n",
            "         1.8914e-05,  2.3890e-04,  7.1599e-05, -2.0504e-05, -2.1761e-06,\n",
            "         6.1077e-06,  2.6771e-05, -1.0054e-04, -5.8419e-06, -1.5325e-05,\n",
            "        -1.9819e-05, -1.7022e-05,  3.7288e-05,  1.0072e-04, -5.1174e-05,\n",
            "        -1.6323e-05, -2.9371e-06,  5.6101e-05, -3.9384e-05,  3.1335e-05,\n",
            "        -4.7246e-06, -3.1583e-05,  3.1195e-05, -1.2747e-05, -5.3860e-05,\n",
            "        -1.4377e-08, -4.3055e-05, -4.7770e-05,  3.3030e-05, -2.7189e-05,\n",
            "         1.4569e-05, -5.2767e-06, -2.5357e-05, -5.7290e-05, -2.6136e-05,\n",
            "         3.4064e-05, -3.6505e-05,  7.6809e-06,  1.3918e-05,  1.2777e-04,\n",
            "        -3.9604e-05,  1.6517e-05, -1.2246e-05, -2.4847e-05,  1.5521e-04,\n",
            "        -3.9825e-05,  1.7460e-05, -7.2581e-06, -9.1380e-06,  5.6263e-05,\n",
            "        -4.4137e-06,  3.7303e-05, -5.0527e-06, -8.0498e-05,  4.9053e-05,\n",
            "        -1.6185e-05, -3.5346e-05])), ('module.encoder_k.layer4.1.bn1.running_mean', tensor([-8.0345e-01, -7.8780e-01, -2.3218e+00,  8.8667e-01, -1.3713e+00,\n",
            "         2.8124e-01,  9.0296e-01, -1.3190e+00,  7.9564e-01,  4.3156e-01,\n",
            "         1.3161e+00,  1.4675e+00,  2.4762e+00, -7.7758e-01,  4.2294e-01,\n",
            "         1.0305e+00,  2.0330e+00,  2.5080e+00,  1.0362e-01, -3.2802e+00,\n",
            "        -2.9333e+00, -5.5175e-01, -1.0813e+00,  7.8984e-01, -1.2511e+00,\n",
            "        -7.4289e-01,  2.4186e-02, -1.3780e+00,  2.9039e-01, -1.3730e-01,\n",
            "         3.2538e+00, -1.0896e+00, -7.6784e-01, -1.7833e+00,  1.3157e+00,\n",
            "        -3.4024e-01, -2.1682e-01,  8.8994e-01,  1.3471e+00,  2.8917e-01,\n",
            "        -4.3734e-01,  2.4056e+00, -1.1535e+00, -9.6668e-02,  2.2877e+00,\n",
            "        -7.7275e-02, -3.5126e-01, -1.0526e+00, -9.0883e-01,  2.0624e-01,\n",
            "        -1.2156e-01,  1.1747e+00,  1.4427e+00,  5.4059e-01,  2.9196e+00,\n",
            "         2.7751e+00, -2.0760e-01, -4.4773e-01,  6.2255e-01,  6.3178e-01,\n",
            "        -8.7405e-02,  6.8052e-01,  1.6156e+00, -2.7241e+00,  1.8881e-01,\n",
            "        -2.6175e-01, -9.3961e-01,  1.0634e+00, -1.6525e+00,  1.3570e+00,\n",
            "        -8.2798e-01, -9.8468e-01,  5.5707e-01, -5.7220e-01, -2.1894e-01,\n",
            "        -4.7504e-02, -1.9321e+00, -2.9728e-02,  3.7432e+00, -1.0370e+00,\n",
            "         1.4769e+00,  1.8972e+00, -9.0105e-01,  7.3827e-01,  6.3924e-01,\n",
            "         1.7485e+00,  1.6695e+00, -2.1994e-01, -1.9363e+00,  1.4764e+00,\n",
            "         1.0818e+00, -2.3580e+00, -1.0822e+00, -4.5304e-01,  1.1585e+00,\n",
            "         4.2450e-01, -1.6729e+00,  9.9395e-01,  2.2613e+00, -4.6924e-01,\n",
            "         3.9534e-01,  6.4705e-01,  1.5327e+00,  3.7621e-01, -1.6712e+00,\n",
            "         2.9629e-01,  5.0451e-01, -1.0521e+00, -2.6960e+00, -1.8873e+00,\n",
            "        -1.1938e+00, -9.0163e-01, -8.7003e-01,  2.1419e+00, -1.2394e+00,\n",
            "        -2.9941e+00, -9.7401e-01, -1.3413e-01,  2.9259e+00, -8.5199e-01,\n",
            "        -8.7669e-02, -2.2903e+00,  3.2600e-01, -6.3394e-01,  9.7632e-02,\n",
            "        -2.2301e+00, -1.3570e+00, -9.5171e-01,  8.1304e-01, -5.8835e-01,\n",
            "        -3.4607e-01, -5.1204e-02,  1.2671e+00,  8.7695e-01,  1.8315e-01,\n",
            "         1.5516e+00, -8.1453e-01, -6.8907e-01, -2.8933e+00,  5.2414e-01,\n",
            "         3.2202e-01, -2.4399e+00,  3.1078e-01, -4.4242e-01,  8.3685e-01,\n",
            "        -5.3803e-01,  1.9917e+00, -1.1759e+00, -1.4632e+00, -3.0147e+00,\n",
            "        -1.8015e+00, -7.3022e-01,  1.9627e+00, -4.1867e-01, -1.0621e+00,\n",
            "        -1.3660e+00, -8.3944e-01,  5.3362e-01, -1.3299e+00, -8.6083e-01,\n",
            "        -2.0136e-01,  2.8995e-01, -5.7577e-01, -8.6843e-01, -2.0674e+00,\n",
            "         8.6476e-01, -1.9462e+00, -1.7218e+00, -2.0569e+00,  2.3798e+00,\n",
            "         1.8166e-02, -2.1628e+00, -8.2057e-01,  2.7022e+00,  2.4896e+00,\n",
            "        -7.6959e-02, -1.0130e+00, -2.0325e+00, -9.6710e-01, -3.1028e+00,\n",
            "         1.0611e+00,  1.1966e+00, -2.2233e+00,  3.1301e-01, -1.3365e+00,\n",
            "         1.7638e+00,  1.6415e-01,  6.7674e-01,  1.3226e+00,  1.4803e+00,\n",
            "        -1.0907e+00, -1.0292e+00, -2.2178e+00, -3.4346e-01, -1.0485e-01,\n",
            "        -1.2540e+00, -5.7006e-02,  5.0606e-01, -4.9738e-01,  8.6178e-03,\n",
            "        -5.8389e-01, -3.8096e-02,  1.1074e+00, -5.7360e-01, -1.1642e-01,\n",
            "         1.8679e+00, -3.7801e+00,  3.1612e-01, -2.8704e-01,  1.4141e+00,\n",
            "        -1.2589e+00,  1.4801e+00,  2.8492e-01, -1.9656e-01,  2.1468e+00,\n",
            "         2.1299e+00, -8.0526e-01,  7.8450e-01,  8.7975e-01,  9.8746e-01,\n",
            "         1.9029e+00,  2.8963e-01,  9.1700e-02, -9.9922e-01, -6.5489e-01,\n",
            "         2.6186e+00,  7.3981e-01,  4.9273e-02,  1.9759e-01, -2.6015e-03,\n",
            "         4.8628e-01,  1.3910e-01,  6.3031e-01,  9.2504e-01, -6.0909e-01,\n",
            "         1.3416e+00,  6.8785e-02, -1.4400e+00, -1.3955e+00,  2.4679e+00,\n",
            "        -1.1488e+00, -4.0807e-01,  1.9558e+00, -1.9891e+00, -1.5153e+00,\n",
            "         5.8805e-01, -3.7591e-02,  1.4055e+00,  4.3176e-01,  2.0335e+00,\n",
            "        -1.7043e+00, -1.7729e-01,  9.4260e-01,  1.3748e+00,  2.9181e-01,\n",
            "        -4.6127e-01, -1.2071e+00, -2.6203e-01, -6.6975e-01, -8.4512e-01,\n",
            "        -2.0184e-01,  1.8474e+00,  1.0251e+00, -1.3747e+00, -9.9542e-01,\n",
            "        -5.8902e-01, -2.0746e-01,  1.1856e+00,  1.3119e+00,  2.7842e-01,\n",
            "        -9.5879e-01,  2.9382e+00, -1.4093e-01,  1.3373e-02,  9.9583e-01,\n",
            "        -2.3935e+00, -2.6718e-01,  2.6402e+00,  1.8638e-01,  6.1749e-02,\n",
            "        -3.5299e-01, -1.2022e+00, -1.8448e-01,  6.6834e-01, -2.7157e+00,\n",
            "        -4.7661e-01, -1.3180e+00, -1.6665e+00, -7.7509e-01,  1.4980e+00,\n",
            "         1.1859e+00,  1.1286e+00,  7.6404e-01, -1.4342e+00, -9.0701e-01,\n",
            "         1.0442e+00,  3.2073e-01,  1.2309e+00,  1.2534e+00,  3.6991e-01,\n",
            "         5.3312e-01, -6.0652e-01,  1.2988e+00,  2.8672e-01, -2.2160e+00,\n",
            "         1.1650e+00, -7.8828e-01, -3.9534e-01, -2.5528e+00,  4.8320e-01,\n",
            "         1.4628e+00,  2.3939e-01,  4.3476e-01, -1.4321e+00, -7.9056e-02,\n",
            "        -9.2999e-01,  3.8019e-01, -2.0331e+00, -9.2875e-01, -4.4208e-02,\n",
            "         1.1401e+00,  5.7911e-01, -5.7597e-01,  2.0221e+00, -2.1394e+00,\n",
            "         2.3636e+00, -1.0800e-01, -3.6211e-01, -9.7763e-01,  3.5544e+00,\n",
            "         1.3808e+00,  7.3517e-01, -2.0343e+00, -1.3905e+00, -1.6775e+00,\n",
            "        -9.4097e-01, -8.8629e-01, -3.4294e-01,  6.2313e-01, -1.0604e+00,\n",
            "         3.5230e+00,  7.4358e-01,  3.0265e+00, -5.5012e-01,  2.3190e+00,\n",
            "        -2.2941e+00,  2.5919e+00,  6.9087e-01, -4.2528e-03,  8.1836e-01,\n",
            "         2.9191e-02, -1.5259e+00,  1.6035e+00,  8.3277e-02, -2.5510e+00,\n",
            "        -9.3558e-01,  7.5216e-01,  1.5024e+00, -1.1238e+00, -2.4088e+00,\n",
            "        -9.7009e-02,  1.0438e-01,  7.8043e-01,  6.6668e-01,  4.3732e-01,\n",
            "         1.1584e+00, -1.3416e+00, -7.0727e-01,  1.8309e-01,  8.8416e-01,\n",
            "         5.4901e-01,  3.6386e-01,  1.4848e+00,  4.1351e-01, -7.0974e-01,\n",
            "        -2.7895e-01,  2.0252e+00, -1.3637e+00,  7.2816e-01,  1.6691e+00,\n",
            "        -1.4627e+00, -9.9201e-01,  1.2998e+00, -1.8059e+00, -1.3935e+00,\n",
            "        -1.2274e-01, -1.5661e+00,  1.4004e+00, -2.5366e+00,  5.6841e-01,\n",
            "         6.5894e-01,  5.7373e-01,  6.5086e-02,  4.2667e-01, -5.4064e-01,\n",
            "        -9.3248e-01,  1.9301e-01,  7.3045e-01, -5.6712e-01, -1.2857e-01,\n",
            "        -3.4980e+00,  7.7356e-01, -7.6548e-01, -1.3121e+00, -1.5597e+00,\n",
            "         1.2260e+00,  1.1862e+00, -1.4037e+00, -2.4335e+00, -6.1323e-01,\n",
            "        -6.6564e-01,  4.9931e-02, -7.3908e-03, -1.5642e-01,  2.8643e-01,\n",
            "         1.0939e-01,  2.6584e-01,  1.1428e+00,  4.6925e-01,  3.1814e-01,\n",
            "         1.3085e+00,  2.5670e-01,  2.5419e-01,  2.8257e-01, -1.8240e+00,\n",
            "        -2.8479e-01,  7.2555e-02,  1.8325e+00,  8.7723e-01,  2.2425e+00,\n",
            "         2.7917e+00, -2.1178e+00, -4.3382e-01, -1.2524e-01, -1.6896e+00,\n",
            "        -2.6778e-01,  2.3990e+00, -1.9038e+00,  1.0815e+00,  9.9832e-02,\n",
            "         1.9291e-01,  1.1624e+00, -2.3589e-01, -6.2850e-01, -2.0138e+00,\n",
            "        -7.3445e-01,  2.0709e+00, -4.3132e-02, -9.1375e-01,  1.5830e+00,\n",
            "        -1.6910e+00,  1.2708e+00, -3.7997e-01,  2.6928e-01, -5.2241e-01,\n",
            "        -7.4705e-01,  2.0370e+00, -3.4038e+00, -4.8983e-01, -1.9878e+00,\n",
            "        -2.8309e-01,  1.2461e+00, -1.8545e+00, -2.3519e+00, -4.9786e-01,\n",
            "         1.9268e+00, -1.9944e-01,  1.2729e+00, -1.0175e+00, -1.4938e+00,\n",
            "         3.2905e+00, -2.7930e+00, -9.3147e-01, -4.2468e-01, -1.6821e-01,\n",
            "        -3.7939e+00, -1.1636e+00,  3.2479e+00, -4.3677e-01,  8.1586e-01,\n",
            "         6.5258e-01,  6.3906e-01, -4.5495e-01,  6.5550e-01, -1.5308e+00,\n",
            "         4.0229e-01, -6.1311e-01,  1.5315e+00,  1.2932e+00, -1.9250e-01,\n",
            "         9.3562e-01, -5.9931e-01, -1.2514e+00, -8.3866e-01,  9.6311e-01,\n",
            "         1.4903e+00,  2.0532e+00,  5.8758e-01, -2.5742e-01, -7.5490e-01,\n",
            "         7.2882e-01, -6.8578e-01,  1.7588e-01, -2.1382e+00,  1.5020e+00,\n",
            "         1.9889e+00,  3.8727e-01,  2.6535e+00, -2.2845e-01, -2.9508e-01,\n",
            "         1.6927e+00,  2.1578e+00])), ('module.encoder_k.layer4.1.bn1.running_var', tensor([ 4.8602,  4.7111,  6.2793,  6.3522,  4.8052,  4.8368,  5.6551,  7.0484,\n",
            "         4.2952,  4.6916,  7.5170,  5.1644, 10.2481,  5.4277,  5.0701,  4.5253,\n",
            "         5.0603,  7.3971,  7.2226, 10.0647, 10.8974,  4.4971, 11.8435,  4.8244,\n",
            "         5.5601,  5.5202,  5.2473,  3.9636,  4.4006,  4.7602,  6.1525,  8.2629,\n",
            "         9.2168,  5.3101,  5.1500,  4.1535,  5.5359,  4.9924,  9.2443,  4.6969,\n",
            "         4.6151,  5.1743, 17.5031,  4.4973,  5.7377,  5.0594,  4.6670,  5.8625,\n",
            "         4.4127,  4.9984,  4.1932,  5.0010,  4.3290,  6.6950,  9.8726,  6.9025,\n",
            "         4.8341,  5.8620,  5.2832,  4.3778,  4.7588,  4.0322,  6.3757,  5.0653,\n",
            "         5.2548,  4.6912,  4.6529,  5.2079,  7.8688,  4.1550,  4.6212,  4.4837,\n",
            "         4.2808,  6.0272,  4.5316,  6.1302,  4.4824,  4.5862,  9.3534,  5.5781,\n",
            "         8.0363,  5.6491,  6.0756,  4.9619,  4.8130,  4.8135,  7.1838,  8.6783,\n",
            "         8.3209,  7.1722,  4.3058, 12.9236,  4.4710,  5.3496,  4.3349,  4.6591,\n",
            "         4.6897,  4.6535,  5.6756,  4.0397,  4.4206,  7.6879,  9.2782,  5.3677,\n",
            "         4.7846,  4.6176,  4.8479,  4.4148,  7.8310,  9.0648,  4.2793,  4.4719,\n",
            "         8.4802,  4.1121,  4.7124,  5.3023,  4.6393,  4.6835,  8.9857,  4.4120,\n",
            "         4.6478,  9.4379,  7.6112,  4.1761,  6.6073,  8.8144,  5.2421,  5.5665,\n",
            "        13.8833,  4.9580,  7.0731, 11.0414,  5.3420, 13.9366,  5.0682,  5.3814,\n",
            "         6.9723,  5.1537, 10.0717,  4.1656,  9.1529,  5.4803,  4.6971,  4.6301,\n",
            "         4.5537,  5.0003,  6.4131,  4.9875, 14.6059,  4.8447, 10.9597,  6.3192,\n",
            "         6.7820,  9.5349,  8.6347,  5.7639,  5.2068,  4.6310,  4.6782,  4.5608,\n",
            "         7.6692,  4.0317,  5.2782,  6.0913,  6.8151,  6.4044, 10.4025,  8.1678,\n",
            "         5.5710,  7.6399,  6.1989,  7.2952,  6.7400, 12.8829,  7.1628,  5.4544,\n",
            "         6.6749,  7.5339,  5.1137,  5.6340,  4.8025,  6.5805, 18.0572,  4.0253,\n",
            "         8.5920,  5.1186,  4.9456,  7.1059,  9.7082,  5.0148,  5.1711,  4.8206,\n",
            "        13.1538,  4.4631,  4.4759,  5.9617,  4.5594,  4.3704,  9.4398,  4.8088,\n",
            "         4.3667,  5.7269, 12.5779,  6.0202,  4.7933,  4.3196, 13.5681,  5.5811,\n",
            "         5.0941,  5.1956,  7.1229,  6.3107,  4.2922,  4.6971,  6.4795, 10.9403,\n",
            "         5.0422,  5.1075,  6.8689,  6.6484, 13.0941,  4.9471,  5.4477,  4.8284,\n",
            "         4.7475, 16.6362,  4.3519,  4.5149,  5.5350,  9.9968,  4.7006,  6.2864,\n",
            "         6.6914,  5.5117,  5.2297,  5.0512,  6.0683,  4.6599,  4.5905,  9.0722,\n",
            "         5.3637,  5.5907,  4.5184,  5.3462,  4.6584,  6.2635,  5.7377,  7.3545,\n",
            "        10.3630, 12.4822, 10.3431,  4.8454,  7.0263,  4.7516,  5.3059,  5.6476,\n",
            "         5.1538,  4.4768,  4.3839,  5.6520,  4.7076,  4.9214,  4.8896,  9.6843,\n",
            "         4.1849,  4.2682,  7.0580,  4.9989, 11.8990,  5.5149,  4.8192,  6.0533,\n",
            "         5.9450,  6.0720,  7.7514,  8.4284,  4.6377, 10.9429,  6.0529,  6.0398,\n",
            "         9.1809, 11.0336,  5.1049,  4.1739, 13.8619,  4.3645,  5.2392,  4.3856,\n",
            "         5.0313,  5.9970,  4.0980,  7.0879,  9.3765,  7.5788,  5.6599,  7.4111,\n",
            "         4.6053,  6.9259,  4.2010,  6.7831,  4.2002,  4.8184,  4.4777,  4.3335,\n",
            "         8.0222,  4.4888,  8.6595,  4.6197,  8.2250,  4.4574,  7.7199,  5.9544,\n",
            "         4.9957,  4.9178,  4.8807,  4.2809,  4.5455, 10.1067,  4.8268,  4.5457,\n",
            "         4.6001,  4.8156,  4.8414,  6.9585,  4.7592,  7.9162,  4.8961,  5.0139,\n",
            "         4.2520,  8.7194,  4.5796,  5.4970,  7.7619,  5.2263,  4.5621,  6.2026,\n",
            "         5.4310,  4.4432,  4.3517,  5.6988, 10.0418,  5.7645, 13.1304,  5.5321,\n",
            "        10.2838, 10.2324,  7.5274,  5.0419,  4.3826, 11.7228,  4.7455,  6.1071,\n",
            "        13.2877,  4.2270,  5.5410,  5.0022,  4.4769,  8.3456,  5.0807,  6.5089,\n",
            "         5.9248,  5.5414,  4.7350,  5.2764,  3.9342,  3.8919,  4.8829,  4.5894,\n",
            "         5.4015,  9.4418,  7.7271,  5.1828,  6.0152,  5.2828,  4.6720,  4.2022,\n",
            "         5.2360,  7.4137,  4.9996,  4.7681,  6.2842, 10.0228,  6.5554,  6.4008,\n",
            "         4.9782,  5.6859,  4.4933,  5.6064,  7.4950,  4.5106,  6.7105,  4.8142,\n",
            "         7.6124,  5.1355,  4.4598,  4.5352,  5.3571,  7.0529,  4.5454,  4.5550,\n",
            "        10.6050,  4.4081,  7.6861,  6.4474,  5.1593,  5.3594,  5.0408,  7.9149,\n",
            "         7.5218,  5.2077,  5.0920,  4.4650,  4.4116,  4.4978,  6.8618,  4.3636,\n",
            "         6.1489,  5.3245,  4.5928,  6.4227,  4.7474,  4.9617,  5.4027,  5.0302,\n",
            "         8.3667,  4.5382,  4.5767,  7.9885,  5.7987,  6.6154, 12.8042,  4.3433,\n",
            "         6.4404,  4.9131,  5.9356,  5.1495, 10.9850,  4.2636,  4.3301,  5.0052,\n",
            "         9.0756,  4.4318,  5.6952,  5.0303,  4.9395,  5.0737,  8.8843,  5.9915,\n",
            "         6.4498, 17.0054,  5.2072,  4.5180,  4.7086,  4.8027,  4.6584,  4.6698,\n",
            "         6.8817,  5.5696, 10.8524,  4.5478,  4.9180,  5.4872,  5.0716,  7.5700,\n",
            "         5.0839,  6.3282,  5.2296,  4.3368,  4.6688,  6.7563,  8.4476, 12.6008,\n",
            "         4.7947,  8.9136,  5.3339, 12.0016,  4.7529,  5.2116,  7.9646,  3.9376,\n",
            "         5.0904,  7.1039,  9.5694,  4.8270,  6.4236,  4.6458,  5.7386,  4.7043,\n",
            "         4.8648,  4.8924, 11.0526,  5.8674,  5.2492,  4.1412,  8.0752,  5.0436,\n",
            "         7.2484,  6.8867,  4.3097,  4.6768,  4.5518,  6.1219,  4.5707,  5.1235,\n",
            "         6.8553,  5.2696,  4.7513,  6.8310,  4.6411,  5.7241,  8.4189,  6.2671])), ('module.encoder_k.layer4.1.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.1.conv2.weight', tensor([[[[-0.0157, -0.0117,  0.0167],\n",
            "          [ 0.0057,  0.0055, -0.0179],\n",
            "          [-0.0133, -0.0031,  0.0088]],\n",
            "\n",
            "         [[-0.0027,  0.0080, -0.0084],\n",
            "          [ 0.0200,  0.0148,  0.0059],\n",
            "          [ 0.0202, -0.0242,  0.0122]],\n",
            "\n",
            "         [[-0.0030,  0.0089, -0.0071],\n",
            "          [ 0.0220,  0.0172, -0.0093],\n",
            "          [ 0.0164,  0.0192,  0.0103]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0177, -0.0182,  0.0002],\n",
            "          [ 0.0052,  0.0122, -0.0156],\n",
            "          [-0.0329,  0.0206,  0.0137]],\n",
            "\n",
            "         [[ 0.0194, -0.0384, -0.0008],\n",
            "          [-0.0399, -0.0052, -0.0233],\n",
            "          [-0.0512, -0.0096, -0.0004]],\n",
            "\n",
            "         [[-0.0598,  0.0038, -0.0017],\n",
            "          [ 0.0166,  0.0304,  0.0228],\n",
            "          [-0.0215,  0.0121, -0.0440]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047, -0.0070, -0.0067],\n",
            "          [-0.0050, -0.0012,  0.0104],\n",
            "          [-0.0312, -0.0101,  0.0099]],\n",
            "\n",
            "         [[-0.0233, -0.0124, -0.0250],\n",
            "          [-0.0038, -0.0237,  0.0131],\n",
            "          [-0.0335, -0.0247, -0.0557]],\n",
            "\n",
            "         [[ 0.0054, -0.0031,  0.0129],\n",
            "          [-0.0090, -0.0051,  0.0097],\n",
            "          [-0.0322, -0.0050,  0.0158]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0203,  0.0014, -0.0163],\n",
            "          [-0.0048,  0.0119,  0.0215],\n",
            "          [-0.0151,  0.0122,  0.0087]],\n",
            "\n",
            "         [[-0.0007, -0.0012, -0.0066],\n",
            "          [-0.0059, -0.0246, -0.0069],\n",
            "          [ 0.0251,  0.0082, -0.0140]],\n",
            "\n",
            "         [[ 0.0087,  0.0257, -0.0225],\n",
            "          [ 0.0264, -0.0334, -0.0013],\n",
            "          [ 0.0423,  0.0008,  0.0105]]],\n",
            "\n",
            "\n",
            "        [[[-0.0247,  0.0160,  0.0331],\n",
            "          [-0.0012,  0.0228,  0.0239],\n",
            "          [ 0.0063,  0.0088, -0.0220]],\n",
            "\n",
            "         [[ 0.0258,  0.0217,  0.0290],\n",
            "          [-0.0142, -0.0046,  0.0117],\n",
            "          [ 0.0282, -0.0096,  0.0219]],\n",
            "\n",
            "         [[-0.0116,  0.0264, -0.0116],\n",
            "          [ 0.0246, -0.0145, -0.0013],\n",
            "          [-0.0086, -0.0030,  0.0285]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0073,  0.0057,  0.0259],\n",
            "          [ 0.0181, -0.0220, -0.0085],\n",
            "          [-0.0014,  0.0150,  0.0370]],\n",
            "\n",
            "         [[ 0.0160,  0.0263,  0.0009],\n",
            "          [ 0.0005,  0.0245,  0.0177],\n",
            "          [ 0.0005, -0.0195, -0.0293]],\n",
            "\n",
            "         [[ 0.0106,  0.0236,  0.0087],\n",
            "          [-0.0200,  0.0302,  0.0116],\n",
            "          [ 0.0111,  0.0361,  0.0354]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0011, -0.0059, -0.0271],\n",
            "          [-0.0065,  0.0212,  0.0057],\n",
            "          [ 0.0058, -0.0383, -0.0096]],\n",
            "\n",
            "         [[-0.0091, -0.0045, -0.0068],\n",
            "          [ 0.0285, -0.0192,  0.0135],\n",
            "          [-0.0133,  0.0333,  0.0131]],\n",
            "\n",
            "         [[ 0.0121,  0.0085, -0.0224],\n",
            "          [-0.0195, -0.0085, -0.0307],\n",
            "          [-0.0040, -0.0105,  0.0044]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0350, -0.0289, -0.0007],\n",
            "          [ 0.0138,  0.0050,  0.0077],\n",
            "          [-0.0277, -0.0372, -0.0230]],\n",
            "\n",
            "         [[-0.0323, -0.0329, -0.0118],\n",
            "          [-0.0031, -0.0394, -0.0115],\n",
            "          [ 0.0527,  0.0184, -0.0128]],\n",
            "\n",
            "         [[ 0.0645,  0.0060, -0.0313],\n",
            "          [-0.0092, -0.0400, -0.0199],\n",
            "          [-0.0047,  0.0159,  0.0232]]],\n",
            "\n",
            "\n",
            "        [[[-0.0145, -0.0146, -0.0263],\n",
            "          [-0.0195,  0.0009, -0.0268],\n",
            "          [ 0.0185,  0.0129,  0.0137]],\n",
            "\n",
            "         [[-0.0495,  0.0384, -0.0247],\n",
            "          [ 0.0254,  0.0103, -0.0032],\n",
            "          [ 0.0143,  0.0325, -0.0256]],\n",
            "\n",
            "         [[-0.0093,  0.0246,  0.0249],\n",
            "          [-0.0033, -0.0047, -0.0138],\n",
            "          [ 0.0249, -0.0122, -0.0262]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0219, -0.0141, -0.0230],\n",
            "          [-0.0032,  0.0023,  0.0142],\n",
            "          [ 0.0082,  0.0058,  0.0139]],\n",
            "\n",
            "         [[ 0.0271, -0.0124,  0.0230],\n",
            "          [-0.0435, -0.0088,  0.0113],\n",
            "          [-0.0041,  0.0095, -0.0084]],\n",
            "\n",
            "         [[-0.0012,  0.0316,  0.0182],\n",
            "          [ 0.0051,  0.0154, -0.0256],\n",
            "          [-0.0051,  0.0095,  0.0013]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0248, -0.0311, -0.0128],\n",
            "          [-0.0387, -0.0266, -0.0353],\n",
            "          [-0.0096, -0.0051,  0.0050]],\n",
            "\n",
            "         [[-0.0160,  0.0114,  0.0033],\n",
            "          [ 0.0007,  0.0382,  0.0148],\n",
            "          [-0.0278, -0.0192, -0.0005]],\n",
            "\n",
            "         [[ 0.0123, -0.0115, -0.0328],\n",
            "          [ 0.0231, -0.0241,  0.0339],\n",
            "          [ 0.0249, -0.0332, -0.0064]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0267,  0.0195, -0.0317],\n",
            "          [-0.0156, -0.0217, -0.0056],\n",
            "          [-0.0101, -0.0123,  0.0130]],\n",
            "\n",
            "         [[-0.0262, -0.0201, -0.0014],\n",
            "          [ 0.0039, -0.0300,  0.0055],\n",
            "          [-0.0113, -0.0084, -0.0113]],\n",
            "\n",
            "         [[ 0.0369,  0.0270, -0.0336],\n",
            "          [ 0.0078, -0.0029, -0.0192],\n",
            "          [ 0.0295, -0.0145, -0.0180]]]])), ('module.encoder_k.layer4.1.bn2.weight', tensor([0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9990, 0.9992, 0.9990, 0.9992, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9990, 0.9990, 0.9992, 0.9991, 0.9992, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9989, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9989, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9992, 0.9992,\n",
            "        0.9990, 0.9990, 0.9991, 0.9990, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9992, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9989, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9989, 0.9991, 0.9993, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991])), ('module.encoder_k.layer4.1.bn2.bias', tensor([-3.3176e-05,  4.8953e-05, -7.1548e-05, -4.8532e-05,  5.7132e-06,\n",
            "        -6.0181e-06,  2.2414e-05,  1.9721e-05, -3.5999e-05, -2.9629e-05,\n",
            "         1.7215e-05, -2.2134e-05,  9.3881e-06, -3.7955e-05, -2.9191e-05,\n",
            "        -5.0360e-05, -8.7469e-07, -3.4736e-05,  6.9597e-05, -8.8119e-06,\n",
            "         9.0650e-06, -1.0237e-05,  1.8983e-05,  6.7650e-05,  4.2710e-05,\n",
            "        -1.7073e-05, -5.3196e-06, -7.3796e-07,  4.4030e-05,  1.2052e-05,\n",
            "        -4.1527e-05,  4.4124e-05,  4.6716e-05, -2.6511e-05,  4.9435e-06,\n",
            "         5.4965e-06,  4.3391e-05,  4.1910e-05,  1.9896e-04,  5.6175e-05,\n",
            "         2.3506e-05, -1.1987e-05,  3.5954e-05,  1.7010e-05, -5.1847e-05,\n",
            "         1.2946e-06,  5.4747e-05,  1.2975e-04, -1.0182e-06, -7.9991e-06,\n",
            "        -2.1487e-05, -7.5332e-06, -1.2443e-05, -2.0297e-05, -1.7769e-05,\n",
            "         5.5361e-05, -1.7526e-05, -1.1333e-05, -1.0064e-05, -5.9699e-05,\n",
            "         5.6682e-05, -2.0818e-05, -2.8142e-05,  4.2835e-05,  4.2427e-05,\n",
            "        -9.5780e-06,  1.3678e-05, -5.5625e-07,  3.4172e-05, -4.5814e-05,\n",
            "         3.3392e-05, -1.1174e-05, -3.2644e-07, -6.9049e-06, -3.6860e-06,\n",
            "         1.4577e-04, -3.9028e-05,  1.1927e-05,  5.7796e-05,  9.2734e-05,\n",
            "        -1.4356e-05, -4.8163e-05,  5.7807e-05, -1.4867e-05,  1.6631e-05,\n",
            "        -1.1716e-05,  1.0766e-05,  5.5295e-05, -3.3629e-05,  1.2512e-05,\n",
            "         4.7080e-05,  1.7864e-06, -3.4329e-05, -3.2870e-05,  8.8224e-05,\n",
            "         8.0086e-06, -3.5315e-05,  1.9366e-05, -3.1146e-05, -5.7044e-05,\n",
            "         1.0113e-05,  4.9145e-05,  3.6700e-06, -1.9044e-05, -8.8246e-06,\n",
            "        -9.1504e-05,  2.1754e-05,  2.8979e-05,  1.5655e-05,  1.1784e-04,\n",
            "         1.5601e-05,  3.0663e-05,  6.7564e-05, -2.0149e-05,  2.4507e-05,\n",
            "        -1.8851e-06,  2.1704e-06,  3.1101e-05,  3.4831e-05, -2.1224e-06,\n",
            "        -1.4121e-04, -5.5692e-05,  1.8990e-05,  2.1311e-05,  3.0292e-05,\n",
            "        -2.5672e-05, -5.6041e-05,  5.6077e-05, -6.7907e-05,  1.8980e-04,\n",
            "        -1.3976e-05,  1.2816e-05,  1.0359e-04, -8.9188e-05,  8.3987e-06,\n",
            "        -8.9533e-05, -2.0905e-05,  2.2567e-05,  3.2819e-06,  4.4387e-05,\n",
            "        -1.3783e-05, -5.1430e-05, -1.2400e-05, -6.4845e-05, -1.8556e-05,\n",
            "         6.1265e-06, -1.2913e-05,  3.1548e-05, -7.1384e-07, -1.6944e-05,\n",
            "        -1.8698e-05,  1.1110e-04, -2.9119e-05, -8.7535e-06, -3.4122e-05,\n",
            "        -7.3996e-05, -2.5825e-05, -3.6725e-05, -1.8934e-05, -2.1282e-05,\n",
            "         1.6717e-05,  2.0646e-05,  8.5513e-05, -5.9887e-05, -3.9806e-05,\n",
            "        -4.9314e-05, -3.9668e-05, -2.7420e-05,  3.9580e-05, -3.5335e-05,\n",
            "        -2.3932e-06,  1.7498e-05, -3.3664e-05, -3.1498e-05, -2.9644e-05,\n",
            "        -8.7914e-05, -1.6970e-05,  1.9720e-05, -3.8904e-05,  7.3543e-05,\n",
            "         7.2031e-06, -5.0874e-05, -4.9789e-05,  3.3288e-05, -4.2836e-05,\n",
            "        -5.0166e-05,  1.5604e-05,  1.1624e-04, -2.5907e-05, -1.1026e-04,\n",
            "         2.2242e-05, -4.5769e-05,  8.2999e-05,  1.3856e-05, -1.0893e-05,\n",
            "        -1.4108e-05,  6.2713e-05, -3.0484e-05, -3.2134e-06, -2.4216e-05,\n",
            "        -1.9158e-05, -1.7222e-05, -3.3493e-05, -1.2473e-05,  1.5308e-05,\n",
            "        -2.0583e-06, -2.8924e-05, -1.0055e-06,  1.1794e-05, -2.6179e-05,\n",
            "        -4.6279e-06, -4.4713e-05,  1.4258e-05,  3.9428e-05, -4.5226e-05,\n",
            "        -6.9091e-06, -6.8445e-06,  7.6599e-05, -3.5027e-06, -5.3201e-05,\n",
            "        -7.3473e-06, -8.1579e-06, -4.5901e-05, -5.1076e-06, -3.3177e-05,\n",
            "         1.0734e-04,  2.3364e-06,  1.5206e-05,  2.3761e-05, -4.6421e-05,\n",
            "        -1.3696e-05,  2.9292e-05,  3.8225e-05,  2.9975e-05, -1.9365e-05,\n",
            "        -6.4792e-05, -2.5521e-05,  4.5423e-05, -5.5320e-05,  2.3578e-05,\n",
            "        -1.3046e-05,  1.7131e-05,  6.8178e-06, -1.3794e-05,  1.1992e-05,\n",
            "        -4.9478e-05, -3.6855e-05, -5.8882e-06,  3.4802e-05,  1.8005e-05,\n",
            "        -1.2050e-04,  2.1763e-06, -3.6356e-05,  6.2320e-05,  2.3574e-06,\n",
            "         9.7309e-06,  4.5999e-05,  3.2727e-05,  6.8990e-05,  8.5380e-05,\n",
            "         1.0891e-05, -4.8914e-05, -4.7643e-06, -3.9388e-05,  2.4344e-05,\n",
            "         4.7163e-05, -2.3886e-05,  8.0385e-05, -1.2857e-05, -3.9840e-06,\n",
            "         3.1844e-05,  1.1639e-04, -1.6849e-06,  2.1439e-05, -1.9039e-05,\n",
            "         4.3094e-05,  5.4760e-06,  8.1261e-05,  1.0537e-04, -4.2805e-05,\n",
            "        -3.3464e-05,  2.9802e-05, -3.1877e-05,  1.5953e-04, -4.2636e-05,\n",
            "        -6.8201e-06, -1.1800e-05,  6.3011e-06,  3.8954e-05, -3.7414e-06,\n",
            "         1.5191e-05,  5.9681e-06, -1.9781e-05, -5.3632e-05,  3.6514e-05,\n",
            "         1.2759e-04, -2.3473e-05,  1.8305e-05,  9.2030e-05, -1.3242e-05,\n",
            "         2.1931e-05, -4.9775e-06,  3.0328e-05,  1.0263e-05,  5.4952e-05,\n",
            "        -2.0488e-05, -3.8585e-05,  5.7426e-05, -3.6493e-05, -8.8579e-06,\n",
            "        -5.9816e-05, -2.9436e-05,  2.1136e-05,  1.8175e-05,  1.5708e-05,\n",
            "         4.0055e-05, -2.0366e-05,  3.0576e-05, -2.3974e-05,  5.1129e-05,\n",
            "        -1.7439e-05, -1.3040e-05,  7.1900e-06, -7.1458e-06,  1.0827e-06,\n",
            "        -1.3611e-05,  8.9279e-05, -2.3702e-05, -9.6004e-05,  1.2917e-05,\n",
            "        -5.1986e-06,  9.9029e-05, -1.3222e-05,  3.3390e-05, -1.6222e-05,\n",
            "         2.8513e-05,  3.5944e-05, -2.6919e-06,  8.5215e-06, -1.8650e-05,\n",
            "         7.3354e-05, -2.7965e-05,  1.1088e-05, -1.4075e-05,  1.3420e-06,\n",
            "        -6.6985e-05, -4.8059e-05,  1.6928e-04,  1.9943e-05, -1.0928e-05,\n",
            "         3.0865e-05,  1.0103e-05, -6.4797e-05, -2.7095e-05, -1.2234e-05,\n",
            "        -2.3209e-05,  3.4161e-05, -5.7829e-05,  2.2732e-05,  8.7199e-06,\n",
            "        -2.7759e-05,  3.2821e-05,  3.9970e-07, -1.6295e-05,  1.3436e-04,\n",
            "        -1.9478e-05,  6.5863e-05, -2.7237e-05, -4.9733e-06,  2.4995e-06,\n",
            "        -2.3503e-05, -4.4453e-06, -1.2391e-05,  4.8759e-06, -2.7275e-05,\n",
            "         1.5871e-05, -1.0450e-05,  1.0803e-04,  3.2143e-05, -1.1449e-05,\n",
            "        -3.7782e-05,  5.4534e-05, -3.9470e-05, -2.1608e-05, -4.7274e-05,\n",
            "        -3.7178e-06,  2.8182e-05,  5.3293e-05,  2.7961e-06,  6.5855e-05,\n",
            "         1.3552e-05,  1.7310e-05, -7.6904e-06,  6.8962e-05,  7.3940e-05,\n",
            "         7.7144e-06,  1.7556e-05,  9.9449e-06,  3.2489e-06,  4.4923e-06,\n",
            "        -5.9892e-05,  4.6278e-05, -4.0500e-05, -2.1402e-05,  3.0676e-06,\n",
            "        -1.2989e-05, -2.6169e-05,  1.4154e-05,  4.0760e-05,  1.4938e-06,\n",
            "         1.0113e-04, -5.4731e-05,  2.0580e-05,  1.7825e-06, -1.0382e-05,\n",
            "         4.0358e-05, -4.5748e-06, -4.5934e-05, -4.0234e-05, -9.4825e-06,\n",
            "        -3.1815e-06, -2.5923e-05,  7.6622e-06, -2.0560e-05, -5.2325e-05,\n",
            "        -2.1082e-06, -1.3150e-06, -2.9944e-05, -7.9071e-06, -2.3309e-05,\n",
            "         8.7208e-06,  1.1290e-05,  2.8554e-05, -4.3905e-05,  1.4931e-05,\n",
            "         9.8275e-05,  2.3083e-06,  1.1628e-05, -3.0999e-05, -1.7931e-05,\n",
            "        -2.2619e-05, -3.0032e-05,  3.4490e-05, -2.5417e-05,  1.3050e-05,\n",
            "         2.1797e-05,  8.7529e-05,  1.4707e-05, -2.6733e-05, -2.2900e-05,\n",
            "         2.3417e-07, -7.5306e-05, -8.0295e-05, -2.7613e-05, -2.8738e-05,\n",
            "        -1.8917e-06,  7.6647e-05, -8.5264e-06, -1.9884e-05,  6.9263e-05,\n",
            "         6.7564e-05,  2.4937e-05, -1.9549e-05, -6.9834e-05,  4.6674e-05,\n",
            "        -3.3192e-05,  2.2142e-05,  7.3679e-06, -4.6877e-05,  1.3182e-05,\n",
            "        -1.6527e-06,  5.1497e-06, -3.3989e-05,  2.5742e-05, -3.2432e-05,\n",
            "        -3.5971e-06, -2.6862e-05,  7.3757e-05,  4.8998e-06,  6.4694e-05,\n",
            "         4.6512e-05,  8.0076e-06, -8.2060e-05, -3.8607e-05, -2.1066e-05,\n",
            "         1.5893e-05, -7.7386e-06, -2.0233e-05,  4.2660e-05, -5.6460e-05,\n",
            "         1.2869e-04,  8.6362e-05, -3.1254e-06,  2.9140e-05, -1.7446e-05,\n",
            "        -1.7724e-05,  1.2876e-05,  3.2090e-05, -3.2059e-05,  7.5406e-05,\n",
            "        -8.2474e-06,  5.9144e-05,  1.0372e-04, -1.6991e-05,  3.8663e-05,\n",
            "        -1.7124e-05, -2.4646e-06, -4.6007e-05,  2.9084e-05,  1.4858e-05,\n",
            "        -2.5734e-05, -5.7345e-05])), ('module.encoder_k.layer4.1.bn2.running_mean', tensor([ 0.0637,  0.2479, -0.6215,  0.3094, -0.6083, -0.0536, -0.0796, -0.1527,\n",
            "         0.0693,  0.4179,  0.6027, -0.2194,  0.3754,  0.2438,  0.6802,  0.0706,\n",
            "         0.3855,  0.0835, -0.3808, -0.0591,  0.2471,  0.2822,  0.0803, -0.1744,\n",
            "         0.0204,  0.2192, -0.1820,  0.8756, -0.0538, -0.3083,  0.0706,  0.3423,\n",
            "         0.2472, -0.0164,  0.1940, -0.3348,  0.1730,  0.6319,  0.2202,  0.9391,\n",
            "         0.6616, -0.4951, -0.2090,  0.3083, -0.2160,  0.0964, -0.1480, -0.4995,\n",
            "        -0.1848, -0.0117,  0.2859,  0.8848,  0.0417,  0.5688,  0.0200,  0.4271,\n",
            "         0.1993, -0.4226, -0.2609,  0.0970, -0.0244, -0.1060, -0.3366,  0.2851,\n",
            "        -0.3486, -0.2087, -0.0328,  0.8558,  0.2901,  0.6470, -0.0896,  0.2016,\n",
            "         0.5982, -0.5895, -0.2986, -0.3713,  0.7061,  0.0401, -0.6155, -0.2960,\n",
            "         0.2444,  0.9376,  0.2014,  0.2371, -0.0233,  0.1964,  0.1281, -0.4561,\n",
            "        -0.8289,  0.0239, -0.0359, -0.8496,  0.0367, -0.0846,  0.0750, -0.0591,\n",
            "         0.6214, -0.1515, -0.1258, -0.1530,  0.1649, -0.3317, -0.1887, -0.5884,\n",
            "         0.1685, -0.2263,  0.1106, -0.1073,  0.1827, -0.5917,  0.1272, -0.1522,\n",
            "         0.7049,  0.4241, -0.5225,  0.0639, -0.0421,  0.0768,  0.0450, -0.8380,\n",
            "        -0.5044, -0.8232,  0.2008, -0.0339, -0.0031,  0.2433, -0.4641,  0.5350,\n",
            "        -0.4390, -0.7974,  0.4482,  0.4061, -0.5910,  0.5263,  0.2265,  0.3541,\n",
            "        -0.1790, -0.0663,  0.0467,  0.4193, -0.4787, -0.0654, -0.4673,  0.0522,\n",
            "         0.4018, -0.1556, -0.3188,  0.0658,  0.3409, -0.6250,  0.1291, -0.1963,\n",
            "         0.0982,  0.1209,  0.5836,  0.1837, -0.4139, -0.1606, -0.0774, -0.3622,\n",
            "        -0.4178,  0.3830,  0.0582, -0.0435, -0.4236, -0.1851,  0.3340, -0.5841,\n",
            "         0.3050,  0.5946,  0.2315,  0.5466,  0.3420, -0.1493,  0.1421, -0.2902,\n",
            "        -0.2275, -0.2672,  0.0501,  1.1815, -0.1272,  0.1039,  0.1081, -0.4700,\n",
            "         0.1971,  0.6888, -0.2146,  0.3100,  0.2948,  0.4274,  0.0133,  0.2801,\n",
            "        -1.1710,  0.0046, -0.0095, -0.4850,  0.1566, -0.5873, -0.1236,  0.0099,\n",
            "         0.0217,  0.4975,  0.2330, -0.1298,  0.2491, -0.1184, -0.0484,  0.0499,\n",
            "        -0.0118, -0.5804, -0.0328, -0.5010,  0.1215,  0.3052, -0.2760,  0.6221,\n",
            "         0.2531, -0.2643,  0.2102,  0.6035, -1.1167,  0.3311,  0.7871,  0.0599,\n",
            "         0.1556,  0.0640, -0.1495, -0.0858,  0.0967, -0.3158,  0.2312,  0.1866,\n",
            "        -0.3446,  0.0940,  0.1280, -0.0218, -0.6808, -0.4156,  0.6812,  0.6300,\n",
            "        -0.6995, -0.4938, -0.1313,  0.0394,  0.0326,  0.0596, -0.1465, -0.0256,\n",
            "         0.1577,  0.6095,  0.9102,  0.0089, -0.4267,  0.2168, -0.2610,  0.4713,\n",
            "        -0.3881, -0.5029,  0.1923, -0.1146,  0.4425,  0.1930, -0.2924, -0.1189,\n",
            "        -0.3855,  0.4636,  0.4190,  0.7266, -0.1411,  0.1006,  0.3541, -0.8814,\n",
            "         0.1208, -0.2999,  0.4200,  0.3109, -0.4226, -0.0889,  0.3684,  0.4700,\n",
            "        -0.2416,  0.5286,  0.2483, -0.1785,  0.8435, -0.3900,  0.4251, -0.2209,\n",
            "         0.5566, -0.0929, -0.2862,  0.0186, -0.7016, -0.1539,  0.2122, -0.4141,\n",
            "        -0.1290,  0.0902,  0.1374,  0.3260,  0.6489,  0.5522, -0.2006, -0.0329,\n",
            "        -0.1899, -0.2584,  0.0372,  0.0860,  0.0749,  1.0265, -0.2206, -0.0148,\n",
            "        -0.4707, -0.0440,  0.3388, -0.2364, -0.0619, -0.1241, -0.6900,  0.1402,\n",
            "         0.0318,  0.2446,  0.1711, -0.4061,  0.0718,  0.1079,  0.3799, -0.4626,\n",
            "         0.6959, -0.3638, -0.2783,  0.6933,  0.0611, -0.2212, -0.1486, -0.0766,\n",
            "         0.2320,  0.3401, -0.3031,  0.0192,  0.1586,  0.6265, -0.5311, -0.4057,\n",
            "        -0.3106, -0.0269, -0.0299,  0.3033, -0.2796,  0.5426, -0.0888,  0.0960,\n",
            "        -0.8201, -0.3951,  0.3181, -0.4224, -0.4260, -0.9969, -0.0131, -0.4037,\n",
            "        -0.5434, -0.8478, -0.0069,  0.0238, -0.2156, -0.1556, -0.1924,  0.4209,\n",
            "        -0.3676,  0.1091,  0.2671,  0.5797, -0.0450, -0.3020, -0.2754,  0.1052,\n",
            "         0.4935, -0.1802, -0.1655, -0.4640,  0.1280, -0.0793,  0.3903, -0.3626,\n",
            "        -0.0905, -0.0336,  0.6013, -0.1711, -0.1359, -0.1407, -0.2592,  0.0311,\n",
            "         0.4977, -0.5187,  0.1100,  0.1874, -0.4870, -0.3065, -0.5639,  0.1741,\n",
            "         0.1933,  0.2790,  0.2171, -0.3538, -0.0839,  0.5898,  0.3876,  0.3902,\n",
            "        -0.1168,  0.2570,  0.3380,  0.1061,  0.5676,  0.6072, -0.4006,  0.7047,\n",
            "        -0.1209, -0.2082, -0.6290, -0.1487, -0.1719,  0.0564, -0.1053,  0.5879,\n",
            "         0.3593,  0.1972,  0.0878,  0.3358,  0.3303, -0.7975,  0.4250, -0.4743,\n",
            "         0.1366,  0.4635, -0.4709, -0.0250,  0.1809, -0.2288,  0.2356, -0.7132,\n",
            "        -0.3701,  0.0430,  0.4412, -0.2266,  0.6953, -0.3957, -0.4129, -0.1790,\n",
            "        -0.0908, -0.3636, -0.6170,  0.2069,  0.6804,  0.0920, -0.8233,  0.0262,\n",
            "        -0.8663, -0.1957, -0.3160, -0.9261,  0.0546,  0.1061,  0.1653, -0.2281,\n",
            "         0.0265, -0.1217, -0.3244, -0.3064,  0.0048,  0.3455, -0.3907, -0.0492,\n",
            "        -0.0015,  0.6832, -0.0776,  0.4937,  0.0919,  0.1166,  0.3172, -0.3604,\n",
            "         0.2227, -0.2990,  0.1028, -0.0763,  0.1460,  0.2091,  0.3235,  0.5406,\n",
            "         0.3957,  0.2848, -0.2317,  0.4215,  0.3440, -0.4394, -0.4115, -0.2931,\n",
            "        -0.2701,  0.7704, -0.1549,  0.3659, -0.3260,  0.3695,  0.0549,  0.0881,\n",
            "         0.0643, -0.0154, -0.2929, -0.3060,  0.3482, -0.3247, -0.3581, -0.6591])), ('module.encoder_k.layer4.1.bn2.running_var', tensor([0.5844, 0.5406, 0.5951, 0.5931, 1.5953, 0.5589, 0.5391, 0.7351, 0.6792,\n",
            "        0.7378, 0.5707, 0.5522, 0.5659, 0.6184, 0.9742, 0.5216, 0.5010, 0.9158,\n",
            "        1.1023, 0.5593, 0.5972, 0.5647, 0.5705, 0.5179, 0.4916, 0.5391, 0.6561,\n",
            "        0.8339, 0.5376, 0.6191, 0.6366, 0.5670, 0.5511, 0.5875, 1.0275, 0.5515,\n",
            "        0.5008, 0.9669, 0.6054, 1.1832, 0.6903, 0.8333, 0.7375, 0.5430, 0.6212,\n",
            "        0.7042, 0.5374, 0.7651, 0.5281, 0.6012, 1.3104, 1.1146, 0.6314, 0.6624,\n",
            "        0.5729, 0.6568, 0.4769, 0.9983, 0.7926, 0.5781, 1.2033, 0.5098, 1.0384,\n",
            "        0.6584, 0.5303, 0.6113, 0.8285, 1.3008, 1.3397, 1.0880, 0.7125, 0.5441,\n",
            "        0.7926, 1.0199, 0.5350, 0.6104, 0.5989, 0.6051, 0.6594, 0.7477, 0.5402,\n",
            "        0.8688, 0.6046, 0.6378, 0.4786, 0.5198, 0.5184, 0.5919, 0.8475, 0.7380,\n",
            "        0.6906, 1.5293, 0.6787, 0.8431, 0.6229, 0.5562, 0.8586, 0.5689, 0.5742,\n",
            "        0.6100, 0.5206, 0.8601, 0.5733, 0.7428, 0.6346, 0.5735, 0.5814, 0.5796,\n",
            "        0.5360, 0.9021, 0.7283, 0.6674, 0.7727, 1.1346, 0.9143, 0.8541, 0.6310,\n",
            "        0.5108, 0.6336, 1.6714, 1.0663, 0.7289, 0.5697, 0.5868, 0.5838, 0.6146,\n",
            "        0.6971, 0.6418, 0.5502, 1.1508, 0.6883, 0.5399, 0.8337, 1.0910, 0.5654,\n",
            "        0.6158, 0.5638, 0.5359, 0.7501, 0.7296, 0.8259, 0.5407, 0.5506, 0.5601,\n",
            "        0.6254, 0.5902, 0.5041, 0.7132, 0.7947, 1.2883, 0.6467, 0.6918, 0.5267,\n",
            "        0.7235, 0.6712, 0.6980, 0.6584, 0.6577, 0.6910, 0.8334, 0.5540, 0.6600,\n",
            "        0.6194, 0.7231, 0.5313, 0.5677, 0.6489, 0.6434, 0.7058, 0.5213, 0.7307,\n",
            "        1.0716, 0.6760, 0.6785, 0.6135, 0.7322, 0.5062, 0.5153, 0.6713, 1.7340,\n",
            "        0.6866, 0.4951, 0.5290, 0.6623, 0.5168, 1.0559, 0.5868, 1.0421, 0.5571,\n",
            "        0.8354, 0.6250, 0.5750, 1.7052, 0.5929, 0.6113, 0.9574, 0.5603, 2.0237,\n",
            "        0.4713, 0.6147, 0.6977, 0.7756, 0.5340, 0.5268, 0.6137, 0.6084, 0.5442,\n",
            "        0.7328, 0.5802, 1.0522, 0.5827, 0.6362, 0.7796, 0.8011, 0.5459, 1.2836,\n",
            "        0.4626, 0.5829, 0.6801, 0.6377, 1.8998, 0.5902, 0.6458, 0.5556, 0.6360,\n",
            "        0.6870, 0.5275, 0.5349, 0.6198, 0.6489, 0.5308, 0.5222, 0.5993, 0.5384,\n",
            "        0.5737, 0.7195, 0.6363, 1.1149, 1.0327, 0.7397, 0.7619, 0.6901, 0.6495,\n",
            "        0.5464, 0.5193, 0.5634, 0.7072, 0.5481, 0.5748, 1.1065, 1.3085, 0.5578,\n",
            "        0.6450, 0.5255, 0.5187, 0.7099, 1.1566, 0.6997, 0.7021, 0.5849, 0.7267,\n",
            "        0.7447, 0.7248, 0.5892, 0.5624, 0.6197, 1.0092, 1.1379, 0.5415, 0.6445,\n",
            "        0.8956, 1.4649, 0.5956, 0.5521, 0.9136, 0.9046, 0.5682, 0.6055, 0.8616,\n",
            "        0.7419, 0.5245, 0.6563, 0.5150, 0.6427, 0.9450, 0.4829, 0.6116, 0.5499,\n",
            "        0.6860, 0.8750, 0.6945, 0.6001, 0.8798, 0.8482, 0.6338, 0.6133, 0.9000,\n",
            "        0.7583, 0.5718, 0.8211, 1.0996, 0.9206, 0.5753, 0.8009, 0.7248, 0.7347,\n",
            "        0.5530, 0.5839, 0.5093, 1.3399, 0.5290, 0.5620, 0.7827, 0.8095, 0.6018,\n",
            "        0.7069, 0.5272, 0.6175, 0.6191, 0.5062, 0.9131, 0.4770, 0.6149, 0.9519,\n",
            "        0.5295, 0.5585, 1.0954, 0.7109, 1.0055, 0.5085, 0.5762, 0.6959, 0.6515,\n",
            "        1.0985, 0.6237, 0.5348, 0.9100, 0.9236, 0.6984, 0.6568, 0.5262, 0.5123,\n",
            "        0.8911, 0.7590, 1.0911, 0.5941, 0.5445, 0.5943, 0.8284, 0.5449, 0.6756,\n",
            "        0.5475, 0.7422, 1.0568, 0.7305, 0.6242, 0.4876, 1.3630, 0.4945, 0.5138,\n",
            "        1.2629, 1.0615, 0.5523, 0.5458, 0.5977, 0.6031, 0.6629, 0.7788, 0.5659,\n",
            "        0.6756, 0.6161, 0.7131, 0.6382, 0.6377, 0.8977, 0.5353, 0.5549, 0.7692,\n",
            "        0.5499, 0.5460, 0.5694, 0.6251, 1.1378, 0.5636, 0.6701, 0.6697, 0.7821,\n",
            "        0.7620, 0.6640, 0.5843, 0.8440, 0.7311, 1.1285, 0.7526, 0.6800, 0.5155,\n",
            "        0.6776, 0.4941, 0.5959, 0.6888, 0.6785, 0.5858, 0.7998, 0.6653, 0.7201,\n",
            "        0.6831, 0.5421, 1.2771, 0.5574, 0.5534, 0.7167, 0.8326, 0.8047, 0.5424,\n",
            "        0.8396, 0.7212, 0.9312, 0.8556, 0.8849, 0.8648, 0.5535, 0.4930, 0.5557,\n",
            "        1.0230, 0.9471, 0.5086, 0.5345, 0.8519, 0.6277, 0.9294, 0.8970, 0.7189,\n",
            "        0.6301, 1.1687, 0.9884, 0.5394, 0.6964, 1.1516, 0.5713, 0.7631, 0.5900,\n",
            "        0.5488, 0.4750, 0.5121, 1.2745, 1.0551, 0.6492, 0.5358, 0.6467, 0.5847,\n",
            "        0.5969, 0.5189, 0.8673, 0.5488, 0.7823, 0.6835, 1.0346, 0.6243, 0.6006,\n",
            "        1.0327, 0.5504, 0.5609, 0.5461, 0.6209, 0.7565, 0.6483, 0.7671, 0.6579,\n",
            "        0.6825, 0.5300, 0.5852, 0.5700, 0.6457, 1.5320, 0.5756, 0.6181, 0.5368,\n",
            "        0.7696, 0.5123, 0.5144, 0.7396, 0.6487, 0.5132, 0.8035, 0.6744, 0.6266,\n",
            "        0.6132, 0.6607, 0.5743, 0.7445, 1.1030, 0.6918, 0.5201, 0.7769, 0.6918,\n",
            "        0.8385, 0.5410, 1.0547, 0.5290, 0.9299, 0.5884, 0.9927, 0.6129, 0.6596,\n",
            "        0.7767, 0.6992, 0.5395, 0.7644, 0.6380, 0.8300, 0.5180, 0.9130])), ('module.encoder_k.layer4.1.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.1.conv3.weight', tensor([[[[ 0.0011]],\n",
            "\n",
            "         [[-0.0520]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0218]],\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         [[ 0.0265]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0165]],\n",
            "\n",
            "         [[-0.0106]],\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0010]],\n",
            "\n",
            "         [[ 0.0878]],\n",
            "\n",
            "         [[ 0.0112]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0321]],\n",
            "\n",
            "         [[-0.0441]],\n",
            "\n",
            "         [[-0.0439]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0325]],\n",
            "\n",
            "         [[-0.0017]],\n",
            "\n",
            "         [[-0.0251]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0188]],\n",
            "\n",
            "         [[ 0.0143]],\n",
            "\n",
            "         [[-0.0308]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         [[ 0.0317]],\n",
            "\n",
            "         [[ 0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0187]],\n",
            "\n",
            "         [[ 0.0174]],\n",
            "\n",
            "         [[ 0.0730]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0056]],\n",
            "\n",
            "         [[-0.0286]],\n",
            "\n",
            "         [[ 0.0053]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0375]],\n",
            "\n",
            "         [[-0.0294]],\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0121]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[ 0.0054]]]])), ('module.encoder_k.layer4.1.bn3.weight', tensor([0.9991, 0.9991, 0.9991,  ..., 0.9990, 0.9991, 0.9991])), ('module.encoder_k.layer4.1.bn3.bias', tensor([ 7.3606e-05, -1.2290e-05,  9.4896e-05,  ..., -1.1292e-04,\n",
            "        -7.1670e-05,  4.1783e-05])), ('module.encoder_k.layer4.1.bn3.running_mean', tensor([ 0.1222, -0.1980,  0.3180,  ..., -0.4962, -0.0404,  0.2180])), ('module.encoder_k.layer4.1.bn3.running_var', tensor([0.1862, 0.1797, 0.1715,  ..., 0.2497, 0.1472, 0.1991])), ('module.encoder_k.layer4.1.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.2.conv1.weight', tensor([[[[ 0.0239]],\n",
            "\n",
            "         [[ 0.0247]],\n",
            "\n",
            "         [[-0.0346]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0535]],\n",
            "\n",
            "         [[ 0.0836]],\n",
            "\n",
            "         [[ 0.0518]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0478]],\n",
            "\n",
            "         [[ 0.0903]],\n",
            "\n",
            "         [[-0.0202]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0246]],\n",
            "\n",
            "         [[-0.0506]],\n",
            "\n",
            "         [[-0.0990]]],\n",
            "\n",
            "\n",
            "        [[[-0.0008]],\n",
            "\n",
            "         [[ 0.0590]],\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0087]],\n",
            "\n",
            "         [[-0.0188]],\n",
            "\n",
            "         [[ 0.0204]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0534]],\n",
            "\n",
            "         [[-0.0693]],\n",
            "\n",
            "         [[ 0.0148]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0059]],\n",
            "\n",
            "         [[-0.0289]],\n",
            "\n",
            "         [[-0.0614]]],\n",
            "\n",
            "\n",
            "        [[[-0.0600]],\n",
            "\n",
            "         [[-0.0527]],\n",
            "\n",
            "         [[ 0.0973]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0735]],\n",
            "\n",
            "         [[-0.0469]],\n",
            "\n",
            "         [[ 0.0126]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0305]],\n",
            "\n",
            "         [[ 0.0916]],\n",
            "\n",
            "         [[ 0.0010]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0061]],\n",
            "\n",
            "         [[ 0.0158]],\n",
            "\n",
            "         [[ 0.0343]]]])), ('module.encoder_k.layer4.2.bn1.weight', tensor([0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991,\n",
            "        0.9992, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9992, 0.9990,\n",
            "        0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9992, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9993, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9993, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9992,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9992, 0.9992, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9992, 0.9990, 0.9992, 0.9993, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9993, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer4.2.bn1.bias', tensor([ 1.4735e-05, -1.8667e-05, -3.1291e-05, -6.0789e-06, -5.4049e-05,\n",
            "         4.3749e-05,  1.4528e-05, -4.9210e-05, -1.2702e-05, -9.8758e-06,\n",
            "         6.5906e-05,  2.9763e-05,  4.7913e-05, -1.3123e-05, -1.2892e-05,\n",
            "         4.7096e-05,  4.4359e-05,  3.6657e-06, -2.7752e-05,  3.0699e-06,\n",
            "        -4.3358e-05, -4.7289e-05, -1.0975e-05, -3.8676e-05,  2.0106e-05,\n",
            "        -9.7483e-06, -4.0949e-07, -1.6869e-05,  2.1936e-05,  2.4904e-05,\n",
            "        -9.1625e-06, -7.9417e-06,  5.7762e-05,  7.2095e-06,  9.6448e-05,\n",
            "        -7.0167e-05,  7.9516e-05, -4.5847e-06,  2.1845e-05, -9.8508e-06,\n",
            "        -3.1296e-05, -5.5303e-05,  8.5251e-06, -3.6846e-05,  2.9856e-05,\n",
            "        -3.7287e-05,  2.2359e-05,  2.2220e-05, -2.1146e-05,  8.5041e-06,\n",
            "         3.5920e-05, -1.9764e-05,  2.1249e-05, -7.6441e-05,  2.9584e-05,\n",
            "         2.2655e-05,  8.8826e-05, -2.6948e-06,  2.9814e-05, -6.2265e-05,\n",
            "        -2.4590e-05,  3.4853e-05,  2.1285e-05,  3.6436e-05,  5.8389e-06,\n",
            "         2.8446e-06, -2.5385e-05,  1.1199e-05,  5.0437e-05, -2.0560e-05,\n",
            "        -5.0797e-05, -5.6762e-05, -2.0570e-05, -5.0717e-05, -2.0615e-06,\n",
            "        -7.3051e-07, -2.3833e-05,  1.1623e-05, -1.4710e-05,  4.9230e-06,\n",
            "         6.4772e-06,  1.2606e-04,  3.8903e-05, -6.5846e-05, -9.0956e-06,\n",
            "         9.7842e-05,  5.3947e-06, -1.2548e-05, -7.0184e-06,  3.0018e-05,\n",
            "        -2.8782e-05, -2.9535e-06,  4.2573e-05,  1.1851e-04, -4.3109e-06,\n",
            "         2.9400e-05, -2.2113e-05, -1.7595e-05,  2.0755e-05, -4.8670e-06,\n",
            "        -2.6756e-05,  9.7824e-05, -1.9906e-05, -4.7303e-05, -2.6914e-05,\n",
            "        -7.0999e-06,  1.4612e-05, -3.1459e-05,  1.8807e-05, -1.2282e-05,\n",
            "         3.4430e-05, -4.5011e-05, -3.4829e-05,  3.5902e-05, -1.6384e-06,\n",
            "        -6.7270e-06,  2.4637e-05,  1.8653e-05, -2.3445e-05, -3.1028e-05,\n",
            "        -9.2083e-05, -4.4130e-05, -6.8767e-05,  1.1530e-05, -5.0603e-05,\n",
            "        -3.8031e-06,  3.5565e-05, -6.3291e-05, -1.9379e-05,  2.1062e-05,\n",
            "         2.1152e-05, -4.0792e-05,  9.7305e-06, -1.2109e-05, -3.9580e-05,\n",
            "        -4.7106e-06, -2.2667e-05, -7.9039e-05,  7.6285e-05, -2.6953e-05,\n",
            "        -3.4880e-05,  1.2606e-05,  5.3280e-05,  5.6572e-06,  7.6465e-06,\n",
            "        -2.6758e-05,  2.5238e-05, -6.3946e-06, -8.2933e-06, -2.7048e-05,\n",
            "         5.8126e-05, -1.9408e-05, -1.5524e-05,  6.3358e-05,  6.4964e-07,\n",
            "         1.5819e-06,  6.4602e-06, -3.9095e-05,  7.9952e-06,  1.0233e-04,\n",
            "        -1.7719e-05, -1.6349e-05,  4.2674e-06,  6.8153e-06,  3.0438e-08,\n",
            "         2.4013e-05,  6.8058e-05,  7.8648e-06, -3.0721e-05,  6.9743e-05,\n",
            "        -2.7635e-05, -2.3985e-05, -6.0157e-05, -6.1206e-06, -3.8844e-05,\n",
            "        -1.2494e-05, -4.4150e-05, -1.9186e-06, -4.2771e-05,  7.2042e-05,\n",
            "        -4.4878e-05,  7.0880e-06,  7.4361e-06, -4.4934e-05,  1.6033e-05,\n",
            "        -2.8314e-07,  7.4377e-05, -5.8003e-06, -3.4714e-05, -5.9976e-05,\n",
            "        -1.3808e-05,  6.5748e-06, -8.8045e-06,  9.0630e-05, -8.8575e-05,\n",
            "        -4.6733e-05, -1.5872e-05, -9.9679e-06, -3.6163e-05, -1.4103e-05,\n",
            "        -1.6685e-05, -2.0309e-06,  9.4633e-06, -3.3155e-05, -2.4009e-05,\n",
            "         9.7724e-06,  1.9091e-06, -1.1836e-05,  3.3593e-05, -4.8927e-06,\n",
            "        -3.7697e-07, -5.5235e-05,  1.1483e-05,  9.9481e-06, -3.2767e-05,\n",
            "        -2.4017e-05,  2.3442e-05,  3.0681e-06,  4.8063e-05,  1.1771e-05,\n",
            "         3.7918e-05, -1.8487e-05, -1.5949e-05,  1.3991e-05,  6.7840e-05,\n",
            "         6.4330e-05,  1.0204e-05, -6.0391e-06,  4.6599e-06, -2.6860e-06,\n",
            "         1.1256e-05,  2.2166e-05,  2.0069e-06, -4.1708e-05,  2.0048e-04,\n",
            "         5.2597e-05,  7.4480e-05,  4.4328e-05, -3.8071e-05, -1.0269e-05,\n",
            "        -8.3958e-06, -6.0768e-05, -5.0192e-06, -2.5057e-05,  2.9110e-05,\n",
            "        -3.6006e-05, -3.2279e-05,  1.1589e-05,  6.8386e-05,  4.7567e-05,\n",
            "        -2.1501e-05,  2.4887e-06,  7.1566e-05,  1.1480e-05, -5.0909e-05,\n",
            "         6.5250e-05, -1.8568e-05, -2.0817e-05, -7.0929e-06, -6.8351e-05,\n",
            "        -4.9657e-05, -3.6191e-05, -2.7237e-05,  2.6576e-05, -4.1850e-05,\n",
            "        -7.9780e-06, -3.1800e-05,  1.8597e-04,  3.3943e-05, -9.7985e-06,\n",
            "        -5.9518e-06, -2.8246e-05, -1.1819e-05,  1.9856e-05, -7.5878e-06,\n",
            "         3.1109e-05, -9.8017e-06, -3.6335e-06,  1.4543e-05, -4.2645e-05,\n",
            "        -2.9949e-05,  3.7073e-06, -3.3866e-06,  9.4933e-06, -1.0308e-05,\n",
            "        -3.3963e-05,  2.4949e-06, -1.2470e-04, -7.4523e-06,  5.8627e-05,\n",
            "         7.3890e-05, -3.4865e-05, -7.5827e-06,  8.1331e-06, -1.2237e-06,\n",
            "        -1.6714e-05, -1.3456e-05,  2.4670e-05,  6.2820e-05,  1.1359e-05,\n",
            "         1.5510e-05,  6.7522e-05, -1.1116e-05,  1.2243e-05, -7.5688e-05,\n",
            "        -3.3715e-05, -3.2752e-05, -3.8632e-05,  1.7100e-06, -2.7898e-05,\n",
            "        -1.6612e-05,  4.0415e-05,  1.1539e-05, -6.2211e-05,  1.9015e-05,\n",
            "        -2.7357e-05,  1.1072e-05,  1.4969e-05, -3.0063e-05, -1.9332e-05,\n",
            "        -2.9708e-06, -3.9644e-06, -1.2120e-05,  3.9305e-05, -1.1314e-05,\n",
            "         5.4186e-07, -3.6741e-05, -4.0028e-05, -1.4627e-05,  1.5197e-05,\n",
            "         9.8968e-05,  3.1689e-05, -1.2236e-05, -1.3972e-05,  5.3456e-05,\n",
            "        -1.7307e-06,  2.1382e-05, -1.6790e-05,  3.9272e-06,  2.3598e-05,\n",
            "         4.9467e-05,  8.6234e-07,  6.6628e-05, -5.1334e-05, -4.1522e-05,\n",
            "         6.4409e-06, -9.0443e-06, -8.0005e-05, -3.7301e-05,  1.1093e-04,\n",
            "         1.1610e-05, -2.8177e-05, -1.1504e-05,  8.7821e-05, -4.5758e-05,\n",
            "         1.9115e-05, -1.0788e-04, -9.1340e-06,  1.3671e-04,  5.7847e-05,\n",
            "         1.1091e-04, -1.1257e-05, -2.3037e-05, -1.5414e-05,  1.2660e-04,\n",
            "        -9.0334e-06, -2.1254e-05, -9.9837e-06, -1.9074e-05,  2.1977e-05,\n",
            "         3.7020e-05,  5.7674e-06,  5.9057e-06,  2.1268e-05, -2.0266e-05,\n",
            "        -4.4797e-05,  1.5137e-05, -1.9755e-05, -3.1563e-05, -1.3540e-04,\n",
            "         4.9260e-05, -5.0051e-06, -2.9981e-05, -4.4050e-05, -5.3292e-05,\n",
            "         1.3256e-05,  3.2557e-05,  1.1006e-05, -5.7654e-06,  7.6873e-05,\n",
            "        -9.7279e-06,  7.7359e-06,  4.4886e-05,  5.5540e-05,  1.3255e-05,\n",
            "         8.4243e-06, -3.0998e-06, -1.2649e-05, -2.9072e-05,  9.0199e-05,\n",
            "        -3.4954e-05, -3.7161e-08, -3.7969e-05,  1.0339e-04, -3.1697e-05,\n",
            "         7.6045e-06,  5.8176e-05,  8.2171e-06,  4.1415e-05,  1.4405e-05,\n",
            "        -9.9122e-06, -3.7368e-05, -3.6738e-05, -2.2278e-05,  8.5470e-06,\n",
            "        -4.1081e-05, -1.7213e-05, -5.0258e-06,  6.7703e-06,  1.2107e-04,\n",
            "        -1.2021e-05,  3.1013e-05, -8.1762e-06,  2.1976e-05, -5.7238e-05,\n",
            "        -4.6666e-08,  3.5527e-05, -9.4975e-06, -2.4173e-05,  6.0648e-06,\n",
            "         7.4214e-06, -2.8100e-06,  1.0191e-04,  3.4948e-05, -1.0423e-05,\n",
            "         1.2234e-04,  1.9612e-04,  5.3454e-05, -9.3533e-06,  6.9879e-05,\n",
            "        -4.5843e-05,  1.8070e-05, -1.1540e-05, -2.1132e-05, -9.9116e-06,\n",
            "        -2.0248e-05,  1.7052e-04,  2.6045e-05,  4.8389e-05,  5.7133e-06,\n",
            "         1.0702e-04,  1.0548e-05, -2.6572e-05,  3.5158e-05,  1.2992e-04,\n",
            "        -9.7101e-06,  2.0614e-05,  1.0444e-06, -5.2447e-06,  3.7668e-06,\n",
            "         1.8379e-05, -2.9779e-05, -4.2514e-05,  2.6150e-06,  3.0362e-05,\n",
            "        -4.9468e-06,  2.1017e-06,  9.1381e-06, -4.1132e-05,  1.3722e-05,\n",
            "        -4.4618e-06,  1.9118e-05, -6.1908e-05, -8.2105e-06, -6.9496e-06,\n",
            "        -3.0788e-05, -7.7096e-06,  2.5514e-05,  8.5729e-05,  2.0577e-05,\n",
            "         2.2644e-05, -2.2606e-05,  1.9282e-05, -4.4975e-05, -1.5572e-05,\n",
            "        -5.7601e-05,  1.3640e-06,  1.1170e-05,  1.2301e-05,  5.1576e-06,\n",
            "         3.9923e-05, -1.7796e-05,  2.7616e-05, -3.4558e-05,  1.1742e-05,\n",
            "        -5.8007e-05,  8.3923e-06,  2.7998e-06, -6.0676e-05,  1.0359e-07,\n",
            "        -3.0776e-05, -7.1371e-05,  4.0174e-05,  3.1743e-05,  1.1726e-04,\n",
            "         1.0388e-05, -9.3498e-06, -5.7245e-05,  5.8308e-05,  1.4461e-05,\n",
            "        -2.2341e-05, -4.8413e-06])), ('module.encoder_k.layer4.2.bn1.running_mean', tensor([-2.1854e-01, -9.8038e-01, -1.4058e+00,  1.5901e+00,  3.2702e+00,\n",
            "         5.2227e-01,  1.0206e+00, -2.7689e+00,  1.2332e+00,  2.8055e+00,\n",
            "         5.6655e-01, -2.2663e+00,  1.0095e+00,  3.8070e+00, -1.2215e+00,\n",
            "         4.6397e-01, -6.8406e-01, -1.5564e+00,  8.2778e-01, -8.5403e-01,\n",
            "         1.8681e+00, -3.3128e+00,  7.4642e-01,  2.8712e+00, -7.1936e-01,\n",
            "        -2.6226e+00, -4.8025e+00,  1.7979e+00, -1.8968e-01, -1.5207e+00,\n",
            "        -1.6673e+00,  4.7780e-01,  3.3405e+00, -3.6031e+00, -8.2101e-01,\n",
            "         2.2255e+00, -5.3008e-02,  2.9772e+00, -3.0758e+00, -2.5750e+00,\n",
            "         3.8347e+00, -4.3227e-01, -6.5198e-03,  1.7924e+00,  1.0725e+00,\n",
            "        -5.6902e-01, -1.6922e+00, -1.6744e+00,  7.4696e-02, -2.7179e-01,\n",
            "        -2.9845e-01,  2.3778e+00, -2.1156e-01, -3.1692e+00, -1.8094e+00,\n",
            "        -1.0963e+00,  4.3835e+00,  2.2237e+00, -1.8204e-01,  2.6232e+00,\n",
            "        -4.2604e-01, -5.7003e-01, -1.9497e+00, -2.7858e-01,  1.0933e+00,\n",
            "         6.0033e-01, -1.4575e+00,  1.2669e+00, -1.2555e+00, -1.6367e+00,\n",
            "         1.5664e-01, -3.1818e+00, -2.5998e+00, -4.0295e+00, -1.0614e-01,\n",
            "         1.0192e+00, -1.8901e+00,  2.7623e-01,  1.2007e-01,  3.2424e+00,\n",
            "         1.2433e+00,  2.2372e+00, -1.0817e+00, -3.2297e+00,  5.0426e-01,\n",
            "        -7.7812e-02,  4.4848e+00,  1.2568e-01, -2.8024e+00, -7.9160e-01,\n",
            "         2.2685e+00, -4.6592e-01, -1.6134e+00,  5.3941e-02,  2.1029e+00,\n",
            "        -1.2709e+00,  2.1944e+00,  3.7302e+00,  6.4851e-01,  1.0410e+00,\n",
            "        -4.1774e-01, -1.2726e+00, -3.5090e-01, -1.4803e+00,  9.3950e-01,\n",
            "         2.5755e-01,  4.7840e+00,  1.0303e+00,  3.0461e-01, -2.8084e+00,\n",
            "         4.5436e+00, -7.8255e-01, -2.2855e+00,  1.9152e+00, -7.6701e-02,\n",
            "        -8.6794e-01,  3.2770e-01, -1.1113e+00,  2.0043e+00,  5.5563e-01,\n",
            "        -4.0183e-01, -5.8261e-01,  4.9811e-01, -7.7860e-01,  3.9241e+00,\n",
            "        -3.7209e+00, -1.1884e-01, -1.9133e-01,  3.0282e-01, -1.2964e-01,\n",
            "        -4.9249e-01,  3.0621e+00, -1.8533e+00, -7.5544e-01,  7.1815e-02,\n",
            "         5.9885e-01, -7.6518e-01, -7.4833e-01,  1.5221e+00, -1.0475e+00,\n",
            "         1.6876e+00, -2.0533e+00,  2.0555e+00,  2.3737e+00,  7.9871e-01,\n",
            "         1.7037e+00, -2.0518e+00,  1.6159e+00,  3.0782e+00,  4.6018e-01,\n",
            "        -1.1474e+00,  1.2825e+00, -2.8549e+00,  3.4101e-01,  1.3089e+00,\n",
            "         4.2128e+00, -7.3294e-02,  1.6981e+00,  9.0522e-01,  2.9458e+00,\n",
            "         1.6321e+00, -8.8284e-02,  5.3183e-01, -5.7217e-01, -7.5116e-01,\n",
            "        -3.4013e+00,  1.6856e+00,  5.2281e-01,  1.2264e+00,  1.2980e+00,\n",
            "         3.4036e+00,  2.1902e+00,  3.1918e+00,  1.8097e+00,  1.3052e+00,\n",
            "         3.3610e+00, -1.3972e+00,  3.6644e-01,  3.0212e+00,  1.1034e+00,\n",
            "         5.1761e-01,  3.2062e+00,  3.0724e+00,  5.7162e+00, -2.8888e+00,\n",
            "         2.7766e+00,  9.1578e-01,  1.7148e-01, -2.9048e+00, -2.2966e+00,\n",
            "         2.3541e+00, -8.2364e-01,  1.4090e+00, -4.0147e-02, -2.4177e-01,\n",
            "         2.0713e+00,  4.8375e-01, -3.0559e+00,  8.1763e-01,  2.2267e+00,\n",
            "        -5.3961e-01,  1.1290e+00, -1.9576e+00, -2.2014e+00, -4.3131e-01,\n",
            "        -2.2365e+00,  2.4692e+00, -3.0854e+00, -4.9223e-01,  1.5025e+00,\n",
            "         8.7736e-01,  1.1362e+00,  2.3753e+00, -6.7330e-01, -4.8216e-01,\n",
            "         1.0726e+00, -2.8166e+00,  1.2221e+00, -2.1439e+00,  9.2652e-01,\n",
            "         9.2542e-01, -5.9544e-01, -1.7631e+00, -6.2063e+00,  3.8685e+00,\n",
            "        -2.9598e+00,  2.2543e+00,  1.8996e+00, -4.6130e+00,  9.4673e-01,\n",
            "        -2.2317e+00, -2.9784e+00, -1.1908e-02, -1.4067e+00,  1.9549e+00,\n",
            "        -2.6635e+00, -2.6061e+00,  3.3166e+00, -1.5679e+00, -5.4600e-01,\n",
            "        -5.6590e-01,  1.7813e+00,  6.4529e-01, -7.2940e-01, -6.7676e-01,\n",
            "         1.1730e+00,  1.8713e+00,  1.5706e-01, -1.2769e+00,  1.9743e+00,\n",
            "        -4.8392e-01,  9.0227e-01, -7.5144e-01, -2.5766e-01,  4.5269e-01,\n",
            "        -4.3821e+00,  4.5528e-01, -2.1059e+00, -1.5261e+00, -9.0222e-01,\n",
            "         3.8109e-01, -9.3467e-01,  5.0859e-01, -1.0942e-01,  1.2695e+00,\n",
            "        -3.5089e+00, -6.8346e-01,  2.5531e+00,  1.5349e+00,  1.2536e-01,\n",
            "         2.3477e+00,  1.6075e+00,  3.2282e+00, -2.2894e-01, -1.5129e+00,\n",
            "        -2.2093e+00,  5.5044e-02, -1.7796e-01,  2.5821e+00,  2.1260e+00,\n",
            "         2.5661e+00,  1.2136e+00, -1.2047e+00,  1.5845e+00,  4.2420e-01,\n",
            "         4.3874e-01,  2.6354e+00,  4.8050e+00, -5.4080e-01, -5.0832e+00,\n",
            "        -3.2919e-01, -1.3825e+00,  5.2718e-01, -9.1188e-01,  1.7389e+00,\n",
            "         5.3737e-01,  3.7392e-01,  1.6013e+00,  3.5004e+00, -9.9568e-01,\n",
            "        -2.3635e-01, -2.3009e+00,  8.1614e-01,  4.4853e+00,  3.0696e+00,\n",
            "        -6.2930e-01,  1.8337e+00,  4.1246e-01,  1.0133e+00, -2.4694e-03,\n",
            "         8.2415e-01, -1.3799e+00, -3.1047e+00,  7.8112e-01,  6.3194e-01,\n",
            "        -2.4659e+00, -1.1934e-01, -2.9586e+00, -2.7338e+00, -3.2433e+00,\n",
            "        -9.5388e-01, -2.9188e+00, -1.3057e+00, -1.7535e+00,  8.5738e-01,\n",
            "        -1.5824e+00, -2.2273e+00,  9.8198e-01, -3.1481e+00,  4.0928e+00,\n",
            "        -3.2310e+00,  1.5514e+00, -3.7588e-01, -6.3123e-01, -1.1590e+00,\n",
            "        -1.3450e+00, -1.2450e+00,  5.0533e-01,  9.7158e-01, -2.0963e+00,\n",
            "        -1.2025e+00,  1.5389e+00,  5.8760e+00,  1.1866e+00, -1.5753e+00,\n",
            "         2.6872e+00,  1.7053e-01, -1.6376e+00, -2.5937e+00, -7.9670e-01,\n",
            "         9.9175e-02, -3.4102e-01, -2.4419e+00, -3.6644e+00,  2.1148e+00,\n",
            "        -4.5955e+00,  2.0386e+00,  1.3185e+00,  4.2972e-02, -7.3804e-01,\n",
            "        -1.8314e+00, -4.9569e-01, -9.1978e-01,  1.3835e+00,  1.3466e-01,\n",
            "        -9.8576e-01,  8.8767e-01,  5.1175e-02, -7.3332e-01, -2.2450e-01,\n",
            "        -3.4873e-01, -5.9013e-01,  1.2569e+00, -1.8126e+00,  2.5053e-01,\n",
            "        -1.9513e-01, -1.1639e+00,  2.9542e+00, -8.0901e-01,  2.3672e+00,\n",
            "         3.9101e+00,  1.4321e+00,  3.4249e-01, -2.0702e-01,  3.3134e-01,\n",
            "         1.3281e+00, -2.0529e+00, -2.8553e+00, -1.7836e+00,  2.6875e+00,\n",
            "        -7.6609e-01, -1.7275e+00, -1.5513e-01,  2.8024e+00, -1.8504e+00,\n",
            "        -4.3406e-01, -4.9288e-01, -1.7524e+00, -1.6483e+00, -1.1985e+00,\n",
            "         3.9019e-01, -3.3611e+00, -1.2266e+00,  2.7356e-01, -1.3714e+00,\n",
            "         1.2920e+00, -2.0894e+00, -5.5085e-02,  1.7564e+00,  5.6315e-01,\n",
            "         6.6981e-01, -1.7494e+00, -3.1090e+00, -7.3174e-01, -5.7504e-01,\n",
            "        -3.1159e+00,  2.2952e-02,  6.2449e-01,  2.3724e+00,  4.8008e-01,\n",
            "        -3.3164e-01, -7.0521e-01,  3.0030e+00,  1.6774e+00,  4.1409e+00,\n",
            "         6.3459e-01,  6.0777e-01, -5.1762e-01,  2.6400e-01,  1.8435e+00,\n",
            "        -1.8611e+00, -1.6227e+00,  2.3771e+00,  2.6191e+00,  1.0220e+00,\n",
            "         4.4226e-01,  5.9361e-01,  9.1861e-01,  4.5188e-01,  2.3806e+00,\n",
            "        -1.5644e+00,  1.8410e+00,  8.5088e-01,  6.7631e-01,  1.2386e+00,\n",
            "        -9.4167e-01,  2.5816e+00,  6.1013e-01,  2.0004e+00, -6.6832e-01,\n",
            "        -9.5931e-01,  4.3141e-01, -5.6695e+00,  5.2914e-01, -1.9511e+00,\n",
            "        -6.4548e-01, -1.1719e+00,  1.9485e+00,  1.2231e+00,  1.8895e+00,\n",
            "        -1.4909e+00, -2.9485e+00, -1.3749e+00, -1.0830e+00, -3.4096e+00,\n",
            "         2.0263e+00,  2.2185e-01, -2.1120e+00,  8.6769e-01,  1.1569e+00,\n",
            "        -1.4013e+00, -1.0854e+00,  5.0021e-02, -1.8616e+00,  2.4157e-01,\n",
            "        -9.2783e-01, -1.4078e+00,  2.2786e-01, -2.4069e-02, -6.8123e-01,\n",
            "        -9.2957e-01, -2.5658e-01,  1.7471e+00,  9.3095e-01,  3.9160e-02,\n",
            "         1.2057e-01,  2.3238e-01,  1.4572e-01, -1.1747e+00, -3.5331e-01,\n",
            "        -1.1375e+00,  2.8340e+00,  1.4872e+00,  3.4461e+00, -4.1035e-01,\n",
            "        -1.5435e+00,  6.7052e-01,  1.0687e+00,  3.1903e-01, -4.8278e-01,\n",
            "        -1.4193e+00,  3.5057e+00,  1.8977e-01, -6.8061e-01, -7.0222e+00,\n",
            "         1.4540e+00, -3.0794e+00,  1.8207e+00, -8.1564e-01, -1.0718e+00,\n",
            "        -1.8787e+00,  3.4001e+00])), ('module.encoder_k.layer4.2.bn1.running_var', tensor([ 9.3720,  7.1444,  6.8081,  8.9522, 38.2514,  6.3301,  6.6175, 11.7957,\n",
            "         5.9605,  6.6819, 10.2088,  8.1776,  6.7862, 13.2030,  7.7534, 11.1708,\n",
            "         7.3419,  8.0019,  6.7582,  7.4919,  6.8259, 12.9221,  6.4329, 12.6304,\n",
            "        10.9294,  9.6375,  9.4771,  9.4690,  8.1578,  7.6311,  6.8460,  7.5373,\n",
            "        15.9112, 15.2391,  6.6677,  6.0567,  7.1070,  6.7199,  6.7064, 13.0768,\n",
            "        19.1912,  7.6174,  6.3071,  6.9430,  6.8495,  9.8052,  6.9611,  6.6378,\n",
            "         7.9549,  7.2360,  6.9625, 10.6087,  6.5523, 13.5884,  7.0740,  7.3378,\n",
            "        19.8241,  7.4119,  7.0848, 12.5813,  9.9709,  9.1117, 23.3148,  9.1462,\n",
            "        11.7424,  7.0958,  9.3386,  5.9124,  9.9667,  6.9629, 12.8245, 11.1149,\n",
            "        11.8427,  6.3952,  9.6987, 10.1255,  7.5853,  7.7028,  8.0680, 21.8946,\n",
            "         7.9367, 11.8927,  8.3251,  8.4094,  7.5269, 17.7983, 16.1995,  7.4619,\n",
            "        10.9978,  8.1135, 11.2523,  7.5874, 10.7857,  7.3979,  7.1918,  7.0299,\n",
            "         7.7857, 23.7733,  6.6409,  8.6999,  8.8477, 12.0449,  8.0605,  7.5199,\n",
            "         7.7181,  8.2600, 25.7425, 13.1706,  7.7031, 12.0032, 16.3205,  8.5721,\n",
            "        13.0688, 15.7386,  6.5107,  7.0103,  6.4978,  9.7806,  7.4728,  8.5943,\n",
            "        12.1436,  7.0579,  7.2207,  8.4153, 25.9153, 13.3861,  8.1768,  6.2760,\n",
            "         6.9243,  7.8283, 10.6015,  7.7825, 12.4076,  7.9305,  7.2119,  8.1583,\n",
            "         6.8481,  7.8716,  8.3022,  7.5906,  8.6202, 10.1959, 12.0688,  9.5083,\n",
            "         7.8966,  7.1834, 11.4247,  6.2298, 14.9166,  6.9315, 12.2262,  6.6433,\n",
            "        10.4924, 11.9519,  6.8227, 25.8488,  6.2659,  7.1390,  6.8314,  8.4118,\n",
            "         7.7016,  6.9103,  7.1753,  9.7436, 12.8251, 16.2856, 14.6661,  9.3047,\n",
            "         6.8795,  7.0368, 17.0233,  6.9923, 24.0027,  7.3132,  6.4370, 14.2564,\n",
            "         8.3532,  9.5869, 23.3523,  8.5993,  7.2833,  8.0317,  9.7385, 25.8804,\n",
            "         8.9687, 11.0284,  7.9552,  8.6425, 19.1255,  9.0055,  6.2746, 10.8415,\n",
            "         9.7225,  7.7021,  7.9457,  7.9800,  7.0987, 12.0897, 13.7383,  7.7396,\n",
            "         6.6922, 12.4101, 14.0878,  7.4141,  7.7426,  8.4066, 19.8257,  6.5673,\n",
            "         7.7274, 12.2428,  9.1597,  6.6917, 11.3534,  6.1561,  7.4350,  9.7709,\n",
            "        12.0061,  6.6966, 13.7269,  6.6487,  7.9458,  6.4917, 10.4098, 41.3742,\n",
            "        21.5401,  7.4690, 11.5226,  6.4567,  9.7275, 15.4498,  6.7442, 13.7421,\n",
            "         6.3473,  6.9862,  8.3436, 13.1069, 15.5306,  7.8571,  6.2447,  7.3449,\n",
            "         6.2437, 19.3517,  7.9196,  7.4796,  9.5724, 14.1979,  6.7336,  6.3741,\n",
            "         7.5135,  8.3730,  9.1448,  6.6673, 10.7683, 10.8424,  8.9357, 10.6041,\n",
            "         6.4050,  6.6573,  7.2035,  9.5176,  6.4067,  8.5395,  6.9942,  6.9575,\n",
            "         9.9800,  9.4936, 16.6328,  6.1504, 10.5150,  8.7313,  8.3543,  6.8606,\n",
            "        11.8275,  6.7099,  7.0085, 21.8547,  6.7127,  8.6900,  8.4087, 14.3993,\n",
            "         7.1676,  8.3371, 15.8604,  7.4525,  7.8936,  6.5348,  8.5150, 21.0738,\n",
            "         6.4193, 30.3228,  6.5479,  6.4979,  8.2453,  6.8469, 10.8048,  6.9004,\n",
            "         8.5528,  6.5106, 14.8313,  6.5643,  6.9839, 18.7602,  7.0023, 16.5271,\n",
            "        11.2600,  7.1003,  7.5142,  8.6094, 10.1268,  7.9685,  7.1215,  7.3105,\n",
            "        11.0358,  7.5253, 10.2438,  5.9985,  8.4673,  6.4341, 14.3421, 10.9749,\n",
            "        10.2352, 16.6348,  6.8095,  5.8480,  9.4907, 15.2493, 14.1967,  7.0852,\n",
            "         8.1176,  8.5150,  8.4147,  9.0641,  7.7912, 11.1784,  7.2594,  8.1436,\n",
            "         7.2780,  9.2415,  5.7886,  7.7989,  8.0703,  6.8007, 19.3549, 16.5242,\n",
            "        10.0041,  7.7983,  7.4216,  6.5446, 16.2669,  8.7436,  7.5058,  6.7468,\n",
            "         8.9998, 12.7475, 24.5307, 18.9803, 18.2335,  6.6416, 12.9773, 10.0241,\n",
            "        12.5685,  6.8247,  6.6068,  6.6535, 18.7309,  7.8525,  7.9606,  7.9964,\n",
            "         8.5155,  6.3261,  8.2548,  7.5472, 17.1966,  8.3466, 13.2088,  8.7962,\n",
            "         8.5834,  6.4971,  6.7533, 18.4456, 16.6309,  6.2027,  6.9612,  9.9053,\n",
            "         9.8684,  8.6813,  6.7457, 15.4722, 10.9915, 14.2097,  8.5374,  7.2150,\n",
            "         5.9808,  8.2890,  6.3344,  7.9825,  7.0054,  6.9398,  8.8912,  8.4191,\n",
            "         9.3910, 15.2290,  6.3504, 13.6746,  7.4400, 14.5667, 16.8006, 11.5907,\n",
            "         8.5759,  9.3356,  7.3929, 14.6801, 10.7631,  9.9995, 11.4928, 12.7386,\n",
            "         6.6563,  7.1152,  8.3582,  6.2913,  7.3720,  9.2150, 13.5567,  7.1703,\n",
            "         9.9749,  9.7987,  7.6380,  7.2502,  7.7853, 14.9647,  7.1570,  7.9726,\n",
            "         6.7229, 13.3390,  9.7810,  6.9513,  6.8972, 10.3166,  7.7306,  9.4522,\n",
            "        16.6957,  7.7249,  8.5966,  6.3817,  8.9077,  8.0548,  9.7677,  8.0580,\n",
            "         8.6628,  8.6124, 11.5604,  9.5117, 30.1411,  6.2722, 14.0830,  6.3976,\n",
            "         6.7512, 14.8383,  6.6957,  6.4649,  6.0281, 12.8108,  7.3206,  6.4803,\n",
            "         6.5700,  7.5177,  8.5133,  6.8127,  6.3924,  6.2996,  7.0453, 13.1288,\n",
            "         7.2647,  6.2462,  8.6797, 14.9840,  7.1270,  7.5840,  7.2861,  6.7787,\n",
            "         9.9672,  7.6201,  8.2717,  6.3201,  7.0451,  8.6736,  7.0137,  6.1528,\n",
            "        14.4192,  8.2973,  6.7871,  9.4138,  7.4154, 19.7090,  6.9252,  8.3435,\n",
            "         7.3370, 10.7604,  7.6724, 11.4456, 11.6631, 20.2003,  9.0271, 14.7378,\n",
            "        35.8307,  6.6776, 11.6399, 15.5384,  7.6156, 12.1631, 11.8839, 24.2522])), ('module.encoder_k.layer4.2.bn1.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.2.conv2.weight', tensor([[[[-0.0106,  0.0049, -0.0312],\n",
            "          [ 0.0047,  0.0007, -0.0046],\n",
            "          [-0.0171,  0.0190,  0.0118]],\n",
            "\n",
            "         [[-0.0248,  0.0150,  0.0090],\n",
            "          [-0.0264, -0.0241, -0.0008],\n",
            "          [ 0.0146, -0.0084, -0.0150]],\n",
            "\n",
            "         [[ 0.0186,  0.0093, -0.0025],\n",
            "          [ 0.0177,  0.0036,  0.0126],\n",
            "          [-0.0323,  0.0117, -0.0297]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0062, -0.0129,  0.0142],\n",
            "          [ 0.0485,  0.0200, -0.0085],\n",
            "          [ 0.0125, -0.0193, -0.0257]],\n",
            "\n",
            "         [[-0.0197,  0.0106, -0.0015],\n",
            "          [-0.0217, -0.0105, -0.0395],\n",
            "          [-0.0150,  0.0101, -0.0178]],\n",
            "\n",
            "         [[ 0.0180,  0.0050, -0.0163],\n",
            "          [-0.0287, -0.0101,  0.0577],\n",
            "          [ 0.0193, -0.0171, -0.0183]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0234,  0.0110, -0.0194],\n",
            "          [-0.0040,  0.0118,  0.0137],\n",
            "          [ 0.0472,  0.0333,  0.0182]],\n",
            "\n",
            "         [[-0.0025, -0.0121, -0.0005],\n",
            "          [-0.0001, -0.0355,  0.0134],\n",
            "          [-0.0185, -0.0183, -0.0467]],\n",
            "\n",
            "         [[-0.0181,  0.0300, -0.0083],\n",
            "          [-0.0185,  0.0063,  0.0058],\n",
            "          [ 0.0192, -0.0068, -0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0278, -0.0458,  0.0435],\n",
            "          [-0.0201, -0.0225, -0.0238],\n",
            "          [-0.0330, -0.0148,  0.0019]],\n",
            "\n",
            "         [[ 0.0066,  0.0361,  0.0161],\n",
            "          [-0.0027, -0.0009, -0.0362],\n",
            "          [ 0.0205, -0.0020, -0.0194]],\n",
            "\n",
            "         [[ 0.0286, -0.0069, -0.0125],\n",
            "          [-0.0168, -0.0134,  0.0091],\n",
            "          [ 0.0355, -0.0201, -0.0033]]],\n",
            "\n",
            "\n",
            "        [[[-0.0210, -0.0165,  0.0165],\n",
            "          [ 0.0057, -0.0142, -0.0238],\n",
            "          [-0.0144, -0.0443,  0.0233]],\n",
            "\n",
            "         [[ 0.0359,  0.0182, -0.0057],\n",
            "          [-0.0237, -0.0276,  0.0099],\n",
            "          [-0.0137,  0.0049, -0.0355]],\n",
            "\n",
            "         [[ 0.0038,  0.0072,  0.0071],\n",
            "          [-0.0256, -0.0078, -0.0295],\n",
            "          [-0.0047, -0.0158,  0.0108]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0430, -0.0106,  0.0011],\n",
            "          [-0.0015,  0.0044,  0.0041],\n",
            "          [ 0.0221,  0.0097,  0.0306]],\n",
            "\n",
            "         [[ 0.0095, -0.0055,  0.0442],\n",
            "          [ 0.0015, -0.0005,  0.0228],\n",
            "          [ 0.0071, -0.0508,  0.0057]],\n",
            "\n",
            "         [[-0.0123, -0.0230,  0.0258],\n",
            "          [-0.0041, -0.0204, -0.0337],\n",
            "          [-0.0103, -0.0479,  0.0194]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0279, -0.0134,  0.0089],\n",
            "          [ 0.0042, -0.0244,  0.0136],\n",
            "          [-0.0232, -0.0371,  0.0021]],\n",
            "\n",
            "         [[-0.0196,  0.0030,  0.0005],\n",
            "          [-0.0058, -0.0074,  0.0167],\n",
            "          [ 0.0107, -0.0167,  0.0077]],\n",
            "\n",
            "         [[-0.0085,  0.0137, -0.0076],\n",
            "          [-0.0046, -0.0074,  0.0161],\n",
            "          [-0.0092, -0.0244,  0.0180]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0111, -0.0007,  0.0201],\n",
            "          [-0.0026, -0.0034,  0.0083],\n",
            "          [-0.0105, -0.0072, -0.0108]],\n",
            "\n",
            "         [[-0.0048, -0.0186,  0.0433],\n",
            "          [ 0.0151, -0.0022, -0.0259],\n",
            "          [ 0.0461,  0.0321,  0.0016]],\n",
            "\n",
            "         [[-0.0094, -0.0065, -0.0325],\n",
            "          [-0.0113, -0.0130, -0.0118],\n",
            "          [-0.0196,  0.0088, -0.0227]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0174,  0.0270,  0.0067],\n",
            "          [-0.0032, -0.0197,  0.0167],\n",
            "          [-0.0004, -0.0322, -0.0114]],\n",
            "\n",
            "         [[ 0.0154,  0.0118,  0.0383],\n",
            "          [-0.0055, -0.0244,  0.0504],\n",
            "          [ 0.0017,  0.0408, -0.0272]],\n",
            "\n",
            "         [[ 0.0158, -0.0163, -0.0025],\n",
            "          [-0.0037, -0.0107,  0.0147],\n",
            "          [-0.0528, -0.0049,  0.0295]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0097, -0.0184,  0.0018],\n",
            "          [ 0.0155, -0.0208, -0.0241],\n",
            "          [-0.0179, -0.0102,  0.0077]],\n",
            "\n",
            "         [[-0.0173,  0.0033, -0.0222],\n",
            "          [ 0.0240,  0.0143,  0.0108],\n",
            "          [ 0.0160,  0.0114, -0.0178]],\n",
            "\n",
            "         [[ 0.0351,  0.0034, -0.0017],\n",
            "          [-0.0092, -0.0039,  0.0052],\n",
            "          [-0.0068,  0.0179, -0.0210]]],\n",
            "\n",
            "\n",
            "        [[[-0.0234, -0.0143, -0.0134],\n",
            "          [ 0.0417,  0.0308, -0.0113],\n",
            "          [ 0.0105, -0.0093,  0.0191]],\n",
            "\n",
            "         [[-0.0105,  0.0042, -0.0129],\n",
            "          [-0.0444, -0.0028,  0.0125],\n",
            "          [ 0.0196,  0.0476, -0.0043]],\n",
            "\n",
            "         [[-0.0359,  0.0025, -0.0246],\n",
            "          [ 0.0031,  0.0223, -0.0161],\n",
            "          [-0.0435, -0.0203, -0.0266]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0010, -0.0132,  0.0283],\n",
            "          [-0.0103, -0.0153,  0.0127],\n",
            "          [ 0.0286, -0.0110,  0.0282]],\n",
            "\n",
            "         [[ 0.0067, -0.0135, -0.0020],\n",
            "          [ 0.0046, -0.0049, -0.0151],\n",
            "          [ 0.0145,  0.0035, -0.0286]],\n",
            "\n",
            "         [[ 0.0043, -0.0134, -0.0350],\n",
            "          [-0.0201, -0.0060,  0.0095],\n",
            "          [-0.0105,  0.0458,  0.0352]]]])), ('module.encoder_k.layer4.2.bn2.weight', tensor([0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9993, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9993, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990,\n",
            "        0.9991, 0.9992, 0.9992, 0.9992, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9993, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9992, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9993, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991, 0.9990, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9990,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9990, 0.9990, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9992, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9992, 0.9990, 0.9990, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9990,\n",
            "        0.9992, 0.9991, 0.9991, 0.9990, 0.9990, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9992, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9990, 0.9991, 0.9991, 0.9990, 0.9992, 0.9991, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991,\n",
            "        0.9991, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9992, 0.9990, 0.9990, 0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9989, 0.9990, 0.9991, 0.9990, 0.9990, 0.9991, 0.9991,\n",
            "        0.9990, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9990, 0.9992, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991, 0.9991, 0.9991, 0.9991,\n",
            "        0.9993, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9992, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9992, 0.9991, 0.9991, 0.9991, 0.9990, 0.9991, 0.9991,\n",
            "        0.9991, 0.9991, 0.9991, 0.9992, 0.9991, 0.9990, 0.9991, 0.9991])), ('module.encoder_k.layer4.2.bn2.bias', tensor([ 6.8020e-06, -5.9207e-05,  2.4789e-05,  1.1230e-04,  4.3908e-06,\n",
            "         2.0424e-05, -7.3686e-06, -1.6788e-05, -1.2929e-05,  1.5132e-04,\n",
            "        -1.7430e-05, -2.5923e-05, -3.8779e-05, -3.0091e-05,  6.4490e-06,\n",
            "        -8.8794e-05, -6.4519e-06,  1.5581e-05, -1.3990e-05, -2.0980e-05,\n",
            "         8.8793e-06, -8.4259e-06,  5.1200e-07,  9.4236e-06, -1.2124e-05,\n",
            "         7.5861e-06, -7.5475e-06, -4.1445e-05, -3.7089e-05,  4.9304e-05,\n",
            "        -3.2568e-05,  1.0644e-05,  2.6358e-05, -2.0147e-05, -2.6785e-05,\n",
            "        -9.3927e-06, -1.7355e-05, -6.6295e-05, -1.9756e-05,  4.7167e-05,\n",
            "        -1.4538e-05,  1.0245e-04, -5.8652e-05,  1.5452e-05,  1.2349e-04,\n",
            "        -7.8315e-06, -9.6526e-05,  9.4100e-05, -9.0072e-06, -2.7471e-05,\n",
            "        -7.6184e-06, -9.5058e-06,  4.9016e-05,  4.0814e-06,  2.5122e-05,\n",
            "         2.0364e-05,  7.8951e-05,  2.0852e-05, -5.6703e-05, -7.9228e-05,\n",
            "        -6.6113e-05, -2.4546e-06,  4.1007e-05, -6.2020e-05, -4.8721e-05,\n",
            "        -9.9619e-07, -2.9687e-06, -1.8522e-05,  1.6125e-04, -3.0636e-05,\n",
            "        -4.3004e-05,  7.4028e-05, -3.0754e-05,  1.5444e-07, -4.6339e-05,\n",
            "         3.0712e-05, -1.5291e-05,  2.5860e-04,  2.7207e-05, -2.4876e-05,\n",
            "         1.0798e-05,  4.0746e-05, -3.3799e-05, -7.6725e-05, -1.6537e-05,\n",
            "         4.8631e-06, -2.9194e-05, -2.5667e-05, -8.0213e-05, -3.4327e-05,\n",
            "        -5.2169e-06,  1.0015e-04,  1.2039e-04,  6.3259e-05,  1.5740e-05,\n",
            "        -2.4924e-05,  9.4787e-05, -4.2521e-06, -2.8284e-06,  1.7769e-05,\n",
            "         1.1586e-05,  1.2250e-04, -3.2626e-05,  8.7382e-06,  4.6709e-05,\n",
            "        -1.1487e-05, -6.6527e-06,  1.1738e-04, -2.6776e-05, -2.1872e-05,\n",
            "        -2.5392e-05, -1.7642e-05,  1.7740e-05, -2.1413e-05,  9.8528e-07,\n",
            "         8.7702e-06, -1.3299e-05, -6.1560e-05,  3.0038e-06, -1.6641e-06,\n",
            "        -9.6754e-06, -1.7430e-05, -3.8924e-05,  5.5165e-05, -1.0186e-05,\n",
            "        -2.8401e-05, -2.3894e-05,  3.2716e-05, -3.5055e-06,  4.7259e-06,\n",
            "         4.9427e-05, -4.1777e-05, -1.6312e-05,  3.1575e-05,  1.5880e-04,\n",
            "         2.9878e-05, -5.9162e-05,  1.4388e-05, -6.7987e-06,  1.9779e-06,\n",
            "         3.9972e-06, -1.7102e-05,  8.0688e-05,  3.5680e-05, -1.0853e-05,\n",
            "        -7.4738e-05,  2.1060e-05,  6.7611e-05,  4.1553e-05,  2.7749e-05,\n",
            "        -1.8669e-05,  8.5094e-06, -1.6828e-05, -5.0344e-05,  7.7581e-05,\n",
            "        -3.8038e-05, -4.5433e-05, -1.3933e-05,  4.8926e-06,  6.3548e-05,\n",
            "         9.4302e-06, -8.1419e-06,  2.0812e-05, -3.6647e-05,  8.8076e-05,\n",
            "         2.9722e-06, -6.3763e-05, -7.1070e-05, -9.8183e-06,  1.2838e-04,\n",
            "         8.0875e-06, -1.9610e-05, -2.4590e-05,  1.4963e-05, -1.1830e-05,\n",
            "        -1.8326e-05,  1.3922e-05,  2.8755e-05, -5.1430e-05, -1.4501e-05,\n",
            "         9.3835e-05, -3.2253e-05, -5.4967e-05, -1.0734e-05, -1.0592e-05,\n",
            "        -6.1065e-06, -2.1258e-05, -3.2291e-05,  1.0898e-05,  1.7609e-05,\n",
            "        -4.0480e-05,  3.4946e-05,  7.7907e-05, -1.8592e-05, -2.9242e-05,\n",
            "         1.9561e-05,  2.0832e-05, -5.9753e-05, -2.5041e-06, -9.8009e-06,\n",
            "        -1.7905e-05, -4.0850e-06,  1.5820e-05,  2.3369e-05,  1.0495e-05,\n",
            "         6.2243e-05, -1.9780e-05, -5.1113e-05,  8.9000e-05, -2.2329e-05,\n",
            "        -4.9566e-05,  8.4899e-05,  2.4690e-05,  5.5496e-06, -2.0125e-06,\n",
            "        -6.5471e-05,  5.3986e-05, -6.1092e-05, -2.2399e-05, -2.8397e-05,\n",
            "        -1.7283e-05, -1.8060e-05, -2.7693e-07, -2.4902e-05,  2.0088e-07,\n",
            "        -6.0679e-05,  4.6539e-05, -9.0647e-05, -1.2233e-05, -3.6081e-06,\n",
            "        -4.2884e-07, -1.5903e-05, -3.6273e-05,  2.8039e-06, -2.9080e-05,\n",
            "         7.5229e-05, -8.3200e-06, -4.5600e-06, -1.9845e-05,  2.3064e-05,\n",
            "        -1.6956e-05,  5.9231e-05, -1.0905e-05, -6.6774e-06,  7.6417e-05,\n",
            "        -1.2173e-05, -5.3962e-05, -1.1510e-05,  2.0006e-06,  2.5024e-06,\n",
            "         4.3871e-05, -8.4973e-06,  7.4644e-06, -2.9144e-05, -2.8676e-06,\n",
            "         1.3014e-05, -2.1484e-05, -2.7729e-05,  3.5352e-05,  4.3791e-06,\n",
            "        -4.7182e-05,  8.7386e-05, -4.5293e-05,  2.7655e-05,  1.2231e-04,\n",
            "         2.2337e-05, -1.3825e-05,  4.5085e-06,  1.4126e-05, -2.0603e-05,\n",
            "         1.5659e-05, -2.9103e-05, -7.2691e-07,  7.3937e-06,  3.4653e-05,\n",
            "         5.1181e-05, -2.6147e-05, -5.7182e-06, -2.9246e-05, -6.7883e-05,\n",
            "        -1.5236e-05, -9.9052e-05, -1.5964e-05, -1.4537e-05, -1.8158e-05,\n",
            "         1.2506e-05,  3.4331e-06,  2.3136e-05,  7.9200e-06, -3.4235e-05,\n",
            "         3.0139e-05, -1.4997e-05, -8.3361e-06,  8.8738e-05,  8.6077e-05,\n",
            "        -2.4680e-05, -2.6622e-05,  9.6605e-06,  2.3746e-05, -1.3786e-05,\n",
            "         3.0761e-05,  7.1990e-06,  5.0251e-05, -2.3146e-05,  1.5691e-05,\n",
            "        -4.6150e-06,  1.4447e-05,  5.3433e-05,  3.3071e-05,  7.1337e-05,\n",
            "        -1.2697e-05,  4.1102e-05,  1.7393e-05,  1.2243e-06,  2.4840e-05,\n",
            "        -3.2651e-06, -2.9246e-05, -1.2174e-05,  1.4705e-05,  3.3814e-05,\n",
            "        -2.0392e-05, -2.8440e-05, -2.8331e-05, -1.5861e-05, -5.8270e-06,\n",
            "         4.9166e-05, -5.4672e-06, -2.2415e-05, -2.9012e-05,  1.8090e-05,\n",
            "         1.6074e-06, -3.0995e-05,  4.2541e-05, -8.3937e-06,  1.4314e-05,\n",
            "        -9.1113e-06, -8.7552e-05,  2.0417e-05, -4.9896e-05, -1.7750e-05,\n",
            "        -1.9596e-05,  9.3817e-06,  9.8378e-05,  5.2252e-06,  2.2996e-05,\n",
            "         7.8423e-06,  5.0561e-05,  5.6120e-05, -3.9756e-05, -1.8617e-05,\n",
            "        -8.9814e-06,  6.0260e-05,  1.0183e-05,  9.1606e-05, -2.4151e-05,\n",
            "         6.1748e-06,  2.6071e-05,  1.6538e-05,  1.1216e-05,  5.6535e-05,\n",
            "         1.5319e-05,  4.6157e-05, -2.7874e-06, -1.8952e-05,  5.4308e-06,\n",
            "        -1.5078e-05, -2.4342e-05, -3.2205e-05,  1.0740e-04,  4.8397e-06,\n",
            "         7.7283e-05,  9.4927e-06,  5.9319e-06, -1.5973e-05, -3.5033e-05,\n",
            "         5.7921e-05, -8.0770e-06, -2.8422e-05, -3.8160e-05, -2.2677e-05,\n",
            "         1.2342e-04,  7.8521e-05, -4.7955e-05, -6.8067e-05,  4.7050e-05,\n",
            "        -4.8155e-06, -1.7807e-06,  4.0178e-05,  1.2776e-05,  2.1783e-05,\n",
            "         6.7309e-06, -2.8652e-05,  5.7662e-06, -2.3948e-05,  8.2000e-05,\n",
            "         1.1221e-06,  7.4425e-05,  8.7838e-05,  1.5001e-04, -1.0638e-04,\n",
            "        -6.4307e-05, -2.0073e-05, -1.9090e-05, -5.1447e-06, -4.8646e-07,\n",
            "         5.4155e-05, -2.2854e-05, -2.6763e-05,  5.3628e-05,  4.6865e-06,\n",
            "         1.4060e-05, -9.7812e-06,  9.9817e-06, -4.1477e-05, -1.2976e-05,\n",
            "        -4.3267e-05,  7.1470e-05,  2.3655e-05, -1.2694e-05,  4.0346e-05,\n",
            "        -1.4835e-06,  1.6167e-04,  4.7163e-06,  7.3545e-06, -3.1905e-05,\n",
            "         7.2074e-05,  1.0900e-05, -2.3512e-05,  4.3577e-05,  2.2341e-05,\n",
            "        -1.0634e-05, -2.9677e-05, -3.7803e-05, -2.3328e-05, -1.7881e-06,\n",
            "        -5.2353e-05, -2.8940e-05, -2.4621e-05,  5.7612e-06,  1.6964e-05,\n",
            "         2.3504e-05, -4.3854e-05, -9.0053e-06,  7.8268e-06, -4.1644e-06,\n",
            "         2.2130e-05, -1.8014e-05, -3.3518e-06,  8.2289e-05,  4.1097e-05,\n",
            "         2.8660e-05, -1.5227e-05, -1.6846e-05,  9.0556e-07, -1.2570e-05,\n",
            "         4.9790e-05,  1.1406e-04,  1.4641e-05,  3.0106e-05,  5.9111e-05,\n",
            "        -1.8891e-05, -1.7512e-04, -4.9639e-05, -3.3736e-05, -2.9249e-05,\n",
            "        -4.2362e-05, -6.4273e-06,  9.8598e-05, -3.9743e-05,  2.9001e-05,\n",
            "         1.2169e-04,  7.8600e-05, -8.2607e-05,  2.9256e-05, -5.7868e-05,\n",
            "         1.2476e-04,  8.9824e-06, -5.3374e-06, -1.0967e-05,  9.8412e-05,\n",
            "        -4.2470e-05,  4.6127e-05,  4.2567e-05,  6.5096e-05, -7.0550e-06,\n",
            "        -2.5240e-05,  1.4951e-04,  4.6154e-05,  4.8760e-05,  2.5145e-05,\n",
            "        -4.7713e-05, -3.1707e-05,  1.0606e-04, -2.6890e-05, -7.9598e-05,\n",
            "        -1.9893e-05,  5.0492e-05,  7.1560e-05,  1.1597e-06,  1.4901e-05,\n",
            "         2.3155e-06, -7.7925e-05, -4.5643e-06,  5.3399e-05, -1.4840e-05,\n",
            "         2.4911e-05,  1.0735e-04,  1.3938e-04,  3.4257e-05, -5.5376e-05,\n",
            "        -2.5571e-05,  2.2558e-05])), ('module.encoder_k.layer4.2.bn2.running_mean', tensor([ 1.0534e+00,  2.4888e-01,  5.1811e-02, -2.7311e-01,  1.2615e-01,\n",
            "        -1.3322e-01,  2.7042e-01,  8.8493e-02,  4.4951e-01, -5.2831e-01,\n",
            "        -3.9252e-01,  2.1344e-01, -2.3200e-01, -2.3296e-01, -1.1863e-01,\n",
            "        -5.9989e-01, -1.3992e-01,  2.9051e-01,  5.1860e-02,  4.6830e-02,\n",
            "         6.5013e-01,  2.6077e-01, -1.6835e-01, -8.4846e-02, -7.7636e-01,\n",
            "        -3.5567e-02,  4.7926e-01, -2.4453e-01, -2.7942e-01, -4.1459e-01,\n",
            "         4.3679e-02, -1.0007e-01, -3.3565e-01,  3.7441e-01,  8.3379e-02,\n",
            "        -1.9411e-01, -2.4954e-01,  7.1159e-01,  2.6121e-01, -4.1589e-01,\n",
            "        -2.9217e-01,  3.2494e-01, -3.7273e-01, -3.1518e-01, -5.6739e-01,\n",
            "        -1.8050e-01, -7.0414e-01,  4.4846e-02,  6.7770e-02, -1.8670e-01,\n",
            "        -4.4935e-01, -4.8108e-01, -3.1304e-01, -3.9041e-01, -4.4086e-01,\n",
            "        -6.6134e-01,  2.6510e-01, -6.7174e-01,  4.0319e-02,  3.7410e-01,\n",
            "         2.8160e-02,  3.5797e-01, -2.7245e-01,  4.1683e-02,  6.4503e-01,\n",
            "         3.9092e-01, -2.3921e-02, -3.7304e-01, -1.9228e-01, -5.3067e-01,\n",
            "         1.8165e-01, -1.5843e-01,  4.7276e-01, -7.2858e-01,  1.7691e-01,\n",
            "        -4.2389e-03, -3.8094e-01,  8.4164e-01, -4.0109e-01,  6.9391e-02,\n",
            "        -1.3553e-01,  8.9038e-01, -2.2819e-01, -2.6337e-01,  1.3297e-01,\n",
            "        -5.6470e-01,  1.7206e-01,  9.3151e-01, -4.1294e-01,  9.5865e-01,\n",
            "        -1.0448e-01,  1.5358e-02,  4.3424e-01,  1.4514e-01,  6.9429e-01,\n",
            "         1.6645e-01, -5.1940e-01,  5.2234e-01, -1.9935e-01, -3.3556e-01,\n",
            "        -9.3011e-02,  1.6849e-01, -8.9932e-02,  1.2643e-02,  3.4194e-01,\n",
            "         2.0997e-01, -2.6463e-01, -1.0644e-01,  3.5733e-01,  2.3235e-01,\n",
            "         1.8352e-01,  6.9089e-02, -2.6565e-01,  2.9252e-01, -8.9427e-02,\n",
            "         2.5315e-02, -2.6336e-01,  4.8749e-01, -4.5241e-01,  2.8419e-01,\n",
            "        -1.8113e-01,  4.3650e-01, -4.7122e-02,  3.4172e-01, -5.7817e-02,\n",
            "        -6.1005e-01,  5.9408e-02,  2.5852e-01, -9.5904e-02, -1.4102e-01,\n",
            "        -4.6564e-01, -4.0196e-04, -5.6301e-01, -7.5022e-01,  7.7699e-01,\n",
            "         5.5544e-01, -5.3489e-02,  3.7132e-01,  1.4340e-01,  4.2375e-01,\n",
            "         1.9020e-01, -1.6453e-01,  4.3981e-01,  4.6522e-01,  2.3945e-01,\n",
            "         4.2304e-01, -6.3207e-01,  3.8085e-02, -3.9450e-01,  8.4876e-01,\n",
            "        -2.3056e-01,  6.8986e-02, -2.5586e-01, -1.7362e-01, -6.2038e-01,\n",
            "        -4.1722e-02,  3.7062e-01, -4.2938e-01, -2.2619e-01,  2.1219e-01,\n",
            "         4.5494e-01, -3.0031e-01,  9.9957e-02,  3.2430e-02,  3.8604e-01,\n",
            "        -2.3195e-01,  3.2219e-01, -4.5232e-01, -2.3979e-01,  9.6403e-01,\n",
            "        -4.0559e-02, -7.5288e-01, -2.2527e-01,  1.6377e-02,  6.2581e-02,\n",
            "        -5.0397e-02, -1.2896e-01, -1.7228e-01, -3.8905e-01, -2.0788e-01,\n",
            "        -4.0728e-01,  5.8859e-01,  1.6323e-01, -3.7785e-02,  3.6653e-01,\n",
            "         2.8290e-01,  7.6079e-02,  2.0899e-01,  1.7136e-01, -9.1327e-01,\n",
            "        -1.9371e-01,  2.4868e-01, -1.0733e-01, -5.5750e-01, -1.5577e-01,\n",
            "         4.1299e-01,  1.9571e-01, -1.4914e-01,  3.5941e-01, -1.7120e-01,\n",
            "         4.5458e-01,  3.1932e-01, -9.8873e-02,  1.4568e-01,  2.8842e-01,\n",
            "        -4.3247e-01, -3.2822e-01,  1.7114e-02, -3.6345e-01,  3.7487e-01,\n",
            "         1.4643e-01, -1.6406e-01,  2.5901e-01,  3.0916e-02, -5.2408e-01,\n",
            "         4.6926e-01, -4.2475e-01,  7.3489e-02, -1.5914e-01,  1.9550e-01,\n",
            "        -6.9293e-01, -1.9930e-01, -1.0696e-01, -5.1470e-01,  2.0593e-01,\n",
            "        -5.5828e-02,  7.4456e-02,  9.5742e-01,  5.1271e-01, -7.9640e-01,\n",
            "         5.4595e-02,  6.8307e-01,  4.0458e-02, -4.5883e-01,  7.7864e-01,\n",
            "         6.6495e-01,  2.7281e-01, -1.5373e-01,  2.2862e-02,  2.7975e-01,\n",
            "        -4.1532e-01,  7.8166e-01,  3.0739e-01, -7.5322e-01, -4.6023e-01,\n",
            "        -1.0584e-01, -9.7136e-01, -5.8114e-01,  3.1340e-01, -4.1091e-01,\n",
            "         1.8768e-01,  2.7144e-01, -1.5595e-01,  3.6856e-01,  3.6739e-01,\n",
            "         3.5961e-01, -3.2921e-01, -1.2950e-01, -6.5740e-03, -3.6486e-01,\n",
            "         1.4109e-01,  4.7182e-01,  2.4528e-02,  6.7199e-02, -5.3217e-01,\n",
            "         3.4504e-01, -1.8479e-01,  2.1273e-01, -2.5795e-01, -2.5347e-01,\n",
            "         3.5232e-01,  1.5092e-01,  1.5840e-01, -5.3475e-01,  1.4558e-01,\n",
            "        -4.1890e-03, -1.9089e-02, -2.9009e-01,  1.1792e-01,  1.3459e-01,\n",
            "         7.7970e-02, -3.7658e-01, -1.8872e-01, -2.6331e-01,  2.0079e-01,\n",
            "        -3.5079e-01, -5.7633e-01,  2.3138e-01, -1.9671e-01, -9.3412e-02,\n",
            "         1.5021e-01,  3.0482e-02, -9.4511e-02, -2.1516e-01,  5.6799e-01,\n",
            "        -4.0843e-01, -2.2406e-01,  6.6632e-02, -3.4242e-01, -2.3380e-01,\n",
            "        -1.2395e-01, -9.4472e-02,  3.2238e-01,  5.1350e-01, -1.4524e-01,\n",
            "         4.9869e-01, -5.5843e-01,  8.5276e-01, -3.7483e-01, -6.0463e-01,\n",
            "         7.8669e-02, -9.1663e-02,  1.1298e-01,  2.7395e-01,  4.1476e-01,\n",
            "         4.1874e-01,  1.9012e-01,  8.2816e-01, -5.1025e-03,  4.1386e-02,\n",
            "         1.1198e-02,  4.5473e-01,  3.4596e-02, -1.8167e-01, -5.5979e-01,\n",
            "         2.3402e-01, -5.7515e-02,  7.1125e-01, -2.1802e-01,  2.1167e-01,\n",
            "        -2.6426e-01, -2.9744e-02, -3.5992e-01, -1.8847e-01,  6.9639e-02,\n",
            "         8.9301e-01,  1.7084e-01,  8.9969e-01,  2.2760e-02,  4.1242e-01,\n",
            "        -1.7721e-02, -7.1647e-01,  5.1755e-03,  2.2810e-02,  4.5224e-01,\n",
            "        -2.9946e-01, -1.4742e-01,  2.7701e-01,  2.7547e-01,  2.5466e-01,\n",
            "         4.9554e-01,  1.0467e+00, -5.0407e-01, -1.1846e-01, -1.0383e-01,\n",
            "        -4.8250e-01,  3.4745e-01, -3.2186e-01,  1.2486e-01, -9.5222e-01,\n",
            "         6.7871e-01,  3.0128e-01,  1.4666e-01,  3.2992e-01, -9.0332e-01,\n",
            "         1.3183e-01,  4.6462e-01, -7.1324e-01, -3.5653e-01,  4.9982e-01,\n",
            "        -2.4425e-01,  3.8092e-01,  1.6996e-01, -3.8966e-01, -5.3863e-01,\n",
            "        -4.8444e-01,  1.2506e-01, -2.0650e-01, -8.0223e-02, -3.4006e-01,\n",
            "         2.3539e-01,  5.0909e-01,  9.0683e-01,  4.1946e-01, -9.3882e-02,\n",
            "         5.1211e-02, -3.1957e-01, -5.3636e-01,  2.3262e-01,  1.2491e-01,\n",
            "        -1.5910e-01, -5.8125e-01, -7.3195e-02, -6.4306e-01,  2.4450e-01,\n",
            "        -9.5143e-02, -8.2516e-04, -6.5690e-01, -9.5563e-02,  5.9707e-01,\n",
            "         1.0680e-01, -4.2590e-02,  1.0236e-01, -3.5236e-01,  5.1152e-01,\n",
            "         1.4281e-01,  3.5276e-01, -1.0166e-01,  2.8820e-01, -8.9284e-02,\n",
            "        -1.1285e-02,  1.3028e-01, -2.6746e-01, -3.8205e-01, -9.9005e-02,\n",
            "        -7.8680e-02, -4.3733e-01,  2.4144e-01,  1.7394e-02,  4.6732e-01,\n",
            "        -3.1112e-02, -6.7498e-01, -2.4404e-01,  2.2540e-01, -1.6305e-01,\n",
            "         2.9406e-01, -3.0461e-02, -1.0315e-01,  2.2317e-01,  5.3972e-01,\n",
            "         1.0745e-01, -5.3059e-01, -5.1827e-01,  6.6860e-01,  1.5042e-01,\n",
            "         9.8873e-01,  3.1471e-01,  4.0896e-01,  4.0454e-01,  1.9498e-01,\n",
            "         6.1796e-03,  4.9902e-01,  3.2902e-01, -7.2342e-01,  2.0269e-01,\n",
            "         1.7251e-01,  4.0410e-01, -8.6002e-02,  3.7103e-01,  1.9857e-01,\n",
            "         1.3108e-01,  3.4154e-01, -3.1931e-01, -9.3754e-01, -8.6647e-02,\n",
            "         2.0813e-01,  4.8246e-01, -2.4312e-01, -2.5124e-01, -3.0700e-01,\n",
            "        -7.8578e-02,  4.0363e-01,  2.0383e-01,  3.3947e-01, -4.9148e-01,\n",
            "         1.5173e-01,  9.4322e-02, -3.2571e-01, -1.2478e-01, -4.3023e-01,\n",
            "         2.7047e-01, -4.2544e-01, -1.1358e-01, -9.9133e-01,  8.6011e-01,\n",
            "        -4.3685e-01,  2.7988e-02, -3.8873e-02, -4.1444e-01,  5.1372e-01,\n",
            "         9.6855e-01,  2.5128e-01,  5.5796e-01, -1.8777e-01,  3.8684e-02,\n",
            "         9.7860e-02,  5.8491e-01,  2.7076e-01, -4.2148e-01,  3.6902e-01,\n",
            "         1.6700e-01,  2.8365e-02,  1.2653e-01, -3.1748e-01, -3.9917e-01,\n",
            "         4.2772e-01, -6.2272e-01,  2.3193e-01, -2.8729e-01,  4.0411e-01,\n",
            "         7.6369e-02,  2.3471e-02, -4.4921e-01, -2.2293e-01,  3.7621e-01,\n",
            "        -5.3139e-02, -3.6216e-01, -7.5522e-01,  1.7852e-01, -7.5180e-02,\n",
            "         1.2231e-01,  7.9804e-02])), ('module.encoder_k.layer4.2.bn2.running_var', tensor([1.5279, 0.7110, 0.5022, 0.5683, 1.1516, 0.6285, 0.6069, 0.5339, 0.7146,\n",
            "        1.4120, 0.6364, 0.5326, 0.6436, 0.5724, 0.4864, 0.8329, 0.6956, 0.5310,\n",
            "        0.5141, 0.5738, 0.8066, 0.5922, 0.5151, 0.6633, 0.6828, 0.7473, 0.8505,\n",
            "        0.7963, 0.7168, 0.5554, 0.6475, 0.6207, 0.5660, 0.6245, 0.5003, 0.6136,\n",
            "        0.7927, 0.9643, 0.5338, 0.7138, 0.5742, 0.9531, 0.9289, 0.5359, 0.7025,\n",
            "        0.5762, 1.4171, 0.7474, 0.5606, 0.5091, 0.6144, 1.0027, 0.5630, 0.5989,\n",
            "        1.0638, 0.8110, 0.8013, 0.7502, 0.5452, 0.9822, 0.5553, 0.7241, 0.5364,\n",
            "        1.1770, 0.7722, 0.8886, 0.5020, 0.5803, 0.5763, 1.1401, 0.5821, 0.9645,\n",
            "        0.6566, 0.8055, 0.6188, 0.9007, 1.0119, 1.0160, 0.7822, 0.6187, 0.5125,\n",
            "        0.6372, 0.9086, 0.5435, 0.4911, 1.1779, 0.6823, 0.6861, 1.0054, 1.2899,\n",
            "        0.8349, 0.5321, 1.0146, 0.5479, 1.4721, 0.5143, 1.2115, 0.5497, 0.5623,\n",
            "        0.5065, 0.5112, 0.8178, 0.5229, 0.6963, 0.5273, 0.5927, 0.5197, 0.9028,\n",
            "        0.6745, 0.4913, 0.5314, 0.5163, 0.5804, 0.5402, 0.5586, 0.8239, 0.6588,\n",
            "        1.4811, 0.6413, 0.4968, 0.5073, 0.7926, 0.6682, 0.8555, 0.6434, 0.8653,\n",
            "        0.5362, 0.5542, 0.5271, 0.5769, 0.8199, 0.5770, 0.9588, 1.3702, 0.9471,\n",
            "        1.3073, 0.7616, 0.5494, 0.4919, 0.8314, 0.7044, 0.9309, 0.7458, 1.2414,\n",
            "        0.7799, 1.4609, 0.6921, 0.5467, 0.6178, 0.9169, 0.7400, 0.5754, 0.6320,\n",
            "        0.4976, 0.7895, 0.5832, 0.7312, 0.8564, 0.8015, 0.4557, 0.5710, 0.8494,\n",
            "        0.4838, 0.5851, 0.4751, 0.6116, 0.7517, 0.6835, 0.5606, 0.6579, 0.5800,\n",
            "        0.7961, 0.5142, 0.6010, 0.7375, 0.5881, 0.5303, 0.6484, 1.4606, 0.6543,\n",
            "        0.6775, 0.5070, 0.5355, 0.7541, 0.7001, 0.5252, 0.9386, 0.8414, 0.5850,\n",
            "        0.8189, 0.9529, 0.5530, 0.6294, 0.7458, 0.5298, 0.6848, 0.9557, 0.6081,\n",
            "        0.8281, 0.5341, 0.8526, 0.7204, 0.5256, 0.7494, 0.5255, 0.6510, 0.6256,\n",
            "        0.5227, 0.8845, 0.5414, 0.5455, 0.5364, 0.4916, 0.5307, 0.5775, 1.2795,\n",
            "        0.5761, 1.0869, 0.4805, 0.9525, 0.8672, 0.6121, 0.7856, 0.5276, 0.5131,\n",
            "        0.5523, 0.4955, 0.7717, 0.7168, 0.8683, 0.5929, 0.6251, 0.5109, 0.5336,\n",
            "        0.5073, 0.9813, 0.7621, 0.5218, 0.5713, 0.6070, 0.7442, 1.2302, 0.5147,\n",
            "        0.6218, 0.9501, 0.6795, 1.0357, 0.8195, 0.8610, 0.4951, 0.5250, 0.7556,\n",
            "        0.5220, 0.9221, 0.6468, 0.5082, 0.6660, 0.5075, 0.6021, 0.7058, 0.4923,\n",
            "        0.6463, 0.5824, 0.5331, 0.6794, 0.8353, 0.5005, 0.8573, 0.6101, 0.4943,\n",
            "        0.8252, 0.4769, 0.5255, 1.1301, 0.4875, 0.5086, 0.5574, 0.5209, 0.6155,\n",
            "        1.0077, 0.5021, 0.8846, 0.5047, 0.6982, 0.5261, 0.8970, 0.6950, 0.5727,\n",
            "        1.0636, 0.4831, 0.9885, 0.5598, 0.6043, 0.7978, 1.1565, 1.0532, 0.5987,\n",
            "        0.5522, 0.6985, 0.5375, 0.5262, 0.6147, 0.6457, 0.5393, 0.7297, 0.5618,\n",
            "        1.2631, 0.7979, 1.3588, 1.3624, 0.5817, 0.5555, 0.5153, 0.5171, 0.5855,\n",
            "        0.6583, 0.5290, 1.0538, 0.5216, 0.7471, 0.8161, 0.6479, 0.5284, 0.4778,\n",
            "        0.5721, 0.4837, 0.5499, 0.5993, 0.7234, 0.5135, 0.6034, 0.6345, 0.6675,\n",
            "        0.7329, 0.5721, 1.3870, 0.6990, 0.7685, 0.5987, 0.7462, 0.5176, 1.1901,\n",
            "        0.6009, 0.5343, 1.0615, 0.5188, 0.5232, 0.6197, 0.6330, 0.5787, 0.5609,\n",
            "        2.3904, 1.2961, 0.7078, 0.6295, 0.9211, 0.6191, 0.5160, 1.1227, 1.4132,\n",
            "        1.2502, 0.8603, 0.8675, 0.5129, 1.7268, 0.6473, 0.6687, 0.9908, 1.3345,\n",
            "        0.5813, 0.4763, 0.6232, 0.5444, 1.4739, 0.6674, 1.0324, 0.5728, 0.6110,\n",
            "        0.4974, 0.8180, 0.6309, 0.7184, 0.7010, 0.6425, 0.5082, 0.6704, 0.4762,\n",
            "        0.5593, 0.5512, 0.6110, 0.6201, 0.6618, 0.6860, 0.6480, 0.5034, 0.5250,\n",
            "        0.4969, 1.0462, 0.6750, 1.1021, 0.4788, 0.6941, 0.5517, 0.6867, 0.5639,\n",
            "        0.6340, 0.8653, 0.6525, 0.9022, 0.6230, 0.8056, 0.5288, 0.5500, 0.6316,\n",
            "        0.5806, 0.5286, 0.6234, 0.5899, 0.5212, 0.8375, 0.7775, 1.4434, 0.5076,\n",
            "        0.5345, 0.5477, 0.6123, 1.0903, 0.6172, 0.5884, 1.1815, 0.5664, 0.8387,\n",
            "        0.9288, 1.8130, 0.5227, 1.1060, 0.6084, 0.5726, 0.5747, 0.7812, 0.5816,\n",
            "        0.5379, 0.5068, 0.7895, 0.6625, 0.6989, 0.5933, 0.5971, 1.2659, 1.1552,\n",
            "        0.4891, 0.5444, 0.6245, 1.1274, 0.5337, 0.9465, 0.7503, 0.5041, 0.7189,\n",
            "        1.2516, 0.5656, 0.7774, 1.0382, 0.4974, 0.6227, 0.4906, 0.6916, 0.8776,\n",
            "        0.5680, 1.3522, 0.5807, 0.8177, 0.5995, 1.7047, 0.7305, 0.4968, 0.7231,\n",
            "        0.4760, 0.9749, 1.2710, 1.3383, 0.8109, 0.8168, 0.6858, 0.5518, 0.5455,\n",
            "        0.7405, 0.5259, 0.5601, 0.8349, 0.9117, 0.5252, 0.8402, 0.6339, 0.7376,\n",
            "        0.4951, 0.7784, 0.8313, 0.9361, 0.6595, 0.4871, 0.6824, 0.6324, 0.6539,\n",
            "        0.6854, 0.8368, 0.9819, 1.1995, 1.0829, 0.4812, 0.5897, 0.6128])), ('module.encoder_k.layer4.2.bn2.num_batches_tracked', tensor(268)), ('module.encoder_k.layer4.2.conv3.weight', tensor([[[[-0.0247]],\n",
            "\n",
            "         [[ 0.0012]],\n",
            "\n",
            "         [[-0.0745]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0359]],\n",
            "\n",
            "         [[-0.0452]],\n",
            "\n",
            "         [[ 0.0490]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0638]],\n",
            "\n",
            "         [[-0.0264]],\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0515]],\n",
            "\n",
            "         [[-0.0135]],\n",
            "\n",
            "         [[-0.0436]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0553]],\n",
            "\n",
            "         [[ 0.0173]],\n",
            "\n",
            "         [[-0.0090]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0100]],\n",
            "\n",
            "         [[ 0.0058]],\n",
            "\n",
            "         [[-0.0159]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0283]],\n",
            "\n",
            "         [[ 0.0154]],\n",
            "\n",
            "         [[ 0.0509]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0059]],\n",
            "\n",
            "         [[-0.0152]],\n",
            "\n",
            "         [[ 0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0316]],\n",
            "\n",
            "         [[-0.0260]],\n",
            "\n",
            "         [[-0.0498]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0384]],\n",
            "\n",
            "         [[ 0.0440]],\n",
            "\n",
            "         [[ 0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0206]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         [[ 0.0018]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0214]],\n",
            "\n",
            "         [[ 0.0095]],\n",
            "\n",
            "         [[ 0.0402]]]])), ('module.encoder_k.layer4.2.bn3.weight', tensor([0.9991, 0.9991, 0.9990,  ..., 0.9991, 0.9991, 0.9991])), ('module.encoder_k.layer4.2.bn3.bias', tensor([ 1.6029e-04, -2.5799e-05,  4.4257e-05,  ..., -1.1906e-04,\n",
            "        -7.9573e-05,  5.9986e-05])), ('module.encoder_k.layer4.2.bn3.running_mean', tensor([-0.3233, -0.1137,  0.1850,  ..., -0.5083,  0.4625,  0.4089])), ('module.encoder_k.layer4.2.bn3.running_var', tensor([0.2081, 0.1498, 0.2223,  ..., 0.1844, 0.2028, 0.2709])), ('module.encoder_k.layer4.2.bn3.num_batches_tracked', tensor(268)), ('module.encoder_k.fc.weight', tensor([[ 0.0131, -0.0026, -0.0032,  ..., -0.0120,  0.0146, -0.0134],\n",
            "        [-0.0073,  0.0033,  0.0153,  ...,  0.0045, -0.0111,  0.0102],\n",
            "        [ 0.0132, -0.0070, -0.0146,  ..., -0.0185, -0.0105,  0.0162],\n",
            "        ...,\n",
            "        [-0.0216, -0.0021,  0.0097,  ..., -0.0178,  0.0071, -0.0096],\n",
            "        [ 0.0106, -0.0026, -0.0160,  ...,  0.0204,  0.0082,  0.0168],\n",
            "        [-0.0191,  0.0045,  0.0098,  ...,  0.0125,  0.0157,  0.0012]])), ('module.encoder_k.fc.bias', tensor([ 0.0071, -0.0136, -0.0005, -0.0194,  0.0008,  0.0092,  0.0139, -0.0184,\n",
            "         0.0170,  0.0076, -0.0173,  0.0011, -0.0220, -0.0091, -0.0166, -0.0089,\n",
            "         0.0095,  0.0179, -0.0058, -0.0071, -0.0094,  0.0025,  0.0058,  0.0174,\n",
            "        -0.0165,  0.0158,  0.0008,  0.0023,  0.0105, -0.0033, -0.0195,  0.0163,\n",
            "        -0.0016, -0.0087, -0.0147, -0.0103,  0.0156, -0.0156,  0.0181,  0.0108,\n",
            "         0.0207, -0.0023,  0.0200, -0.0116, -0.0027,  0.0150, -0.0185, -0.0195,\n",
            "         0.0089, -0.0200,  0.0107, -0.0180,  0.0125, -0.0020,  0.0183, -0.0181,\n",
            "        -0.0090,  0.0079, -0.0096, -0.0122, -0.0142, -0.0194,  0.0141, -0.0002,\n",
            "        -0.0056, -0.0045, -0.0108,  0.0195,  0.0034, -0.0153,  0.0109, -0.0137,\n",
            "        -0.0216, -0.0019, -0.0053, -0.0119,  0.0016,  0.0102,  0.0077, -0.0201,\n",
            "        -0.0148,  0.0218, -0.0009,  0.0012, -0.0048,  0.0039, -0.0139, -0.0174,\n",
            "         0.0037,  0.0108,  0.0049,  0.0168,  0.0052, -0.0168,  0.0036,  0.0201,\n",
            "         0.0082,  0.0087, -0.0209,  0.0015,  0.0144, -0.0178, -0.0073, -0.0230,\n",
            "        -0.0174, -0.0081, -0.0079, -0.0031, -0.0131,  0.0050,  0.0039, -0.0047,\n",
            "         0.0156, -0.0028,  0.0165, -0.0130, -0.0006,  0.0089,  0.0158,  0.0163,\n",
            "        -0.0169, -0.0077, -0.0216, -0.0118,  0.0111, -0.0101, -0.0156,  0.0130]))]), 'optimizer': {'state': {0: {'momentum_buffer': tensor([[[[ 6.5412e-04,  8.4281e-04,  8.5121e-04,  ...,  7.8243e-04,\n",
            "            7.8746e-04,  7.3414e-04],\n",
            "          [ 7.9298e-04,  8.8283e-04,  8.2901e-04,  ...,  8.3216e-04,\n",
            "            8.0913e-04,  7.1645e-04],\n",
            "          [ 7.0322e-04,  8.0138e-04,  7.9109e-04,  ...,  7.5522e-04,\n",
            "            7.5016e-04,  6.2027e-04],\n",
            "          ...,\n",
            "          [ 7.5582e-04,  7.2070e-04,  6.4614e-04,  ...,  6.6016e-04,\n",
            "            4.9935e-04,  5.5531e-04],\n",
            "          [ 6.2641e-04,  7.3809e-04,  6.6758e-04,  ...,  6.0481e-04,\n",
            "            5.6912e-04,  5.4370e-04],\n",
            "          [ 5.9036e-04,  7.0677e-04,  6.1226e-04,  ...,  5.4260e-04,\n",
            "            4.9446e-04,  4.6451e-04]],\n",
            "\n",
            "         [[-6.1623e-05, -3.3072e-05, -6.5300e-05,  ..., -1.0321e-04,\n",
            "           -1.3186e-04, -1.8511e-04],\n",
            "          [-6.8125e-05, -5.9914e-05, -1.1190e-04,  ..., -1.2606e-04,\n",
            "           -9.2769e-05, -2.5871e-04],\n",
            "          [-8.0490e-05,  1.6017e-05, -1.1744e-04,  ..., -3.3184e-04,\n",
            "           -3.3506e-04, -3.9004e-04],\n",
            "          ...,\n",
            "          [ 1.7734e-06, -8.7540e-05, -2.2023e-04,  ..., -4.9402e-04,\n",
            "           -5.7362e-04, -6.1274e-04],\n",
            "          [ 1.1250e-04,  4.6799e-05, -7.6185e-05,  ..., -4.4602e-04,\n",
            "           -5.2608e-04, -4.9795e-04],\n",
            "          [ 1.4270e-04,  1.7505e-04,  6.8120e-05,  ..., -3.0072e-04,\n",
            "           -4.4275e-04, -3.3851e-04]],\n",
            "\n",
            "         [[ 5.7903e-05,  1.6184e-04,  4.6982e-05,  ..., -6.9684e-05,\n",
            "           -1.2065e-07, -3.2479e-05],\n",
            "          [ 4.5068e-05,  1.2730e-04, -3.4524e-06,  ..., -1.1216e-04,\n",
            "           -6.7698e-06, -8.2497e-05],\n",
            "          [ 1.2089e-04,  1.2674e-04, -2.7111e-05,  ..., -1.0229e-04,\n",
            "           -6.9655e-05, -7.2839e-05],\n",
            "          ...,\n",
            "          [ 1.8013e-04,  1.6717e-04,  1.3806e-05,  ..., -1.1034e-04,\n",
            "           -2.0954e-04, -1.1513e-04],\n",
            "          [ 2.4108e-04,  2.6913e-04,  2.0968e-04,  ..., -4.8237e-05,\n",
            "           -1.5713e-04, -1.0686e-04],\n",
            "          [ 2.7027e-04,  3.4732e-04,  2.6105e-04,  ..., -7.1022e-05,\n",
            "           -6.3833e-05, -6.2209e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.9519e-04, -2.5935e-04, -5.6160e-04,  ..., -2.6040e-04,\n",
            "           -1.6426e-04,  1.5358e-04],\n",
            "          [-5.2104e-04, -5.0572e-04, -5.2683e-04,  ..., -2.8081e-04,\n",
            "           -3.6952e-04, -5.9730e-05],\n",
            "          [-6.7196e-04, -5.9950e-04, -5.6122e-04,  ..., -1.3973e-04,\n",
            "           -9.0838e-05,  2.5256e-04],\n",
            "          ...,\n",
            "          [-6.0076e-04, -4.9773e-04, -5.5770e-04,  ..., -4.3535e-04,\n",
            "           -3.1959e-04, -1.5122e-04],\n",
            "          [-6.0569e-04, -6.0822e-04, -5.7847e-04,  ..., -5.5615e-04,\n",
            "           -4.0733e-04, -3.1634e-04],\n",
            "          [-7.7590e-04, -7.8949e-04, -6.7356e-04,  ..., -6.9542e-04,\n",
            "           -7.2323e-04, -6.4570e-04]],\n",
            "\n",
            "         [[ 1.3930e-03,  1.2245e-03,  6.9106e-04,  ..., -2.3618e-04,\n",
            "           -5.7240e-04, -4.4190e-04],\n",
            "          [ 1.4149e-03,  1.2934e-03,  8.5582e-04,  ..., -1.1994e-04,\n",
            "           -4.4977e-04, -4.6454e-04],\n",
            "          [ 1.5606e-03,  1.4640e-03,  1.1416e-03,  ...,  4.1847e-04,\n",
            "            3.6469e-05,  8.4664e-05],\n",
            "          ...,\n",
            "          [ 1.7194e-03,  1.8380e-03,  1.4082e-03,  ...,  9.1145e-04,\n",
            "            5.8057e-04,  3.2390e-04],\n",
            "          [ 1.5451e-03,  1.6109e-03,  1.3164e-03,  ...,  6.6807e-04,\n",
            "            5.1850e-04,  3.2299e-04],\n",
            "          [ 1.4276e-03,  1.4603e-03,  1.4583e-03,  ...,  7.1495e-04,\n",
            "            4.6907e-04,  2.2721e-04]],\n",
            "\n",
            "         [[-1.2463e-04, -2.5019e-04, -5.1468e-04,  ..., -4.7365e-04,\n",
            "           -5.4552e-04, -2.1068e-04],\n",
            "          [-2.9033e-04, -3.9969e-04, -6.2395e-04,  ..., -7.4731e-04,\n",
            "           -8.0764e-04, -5.0898e-04],\n",
            "          [-2.6521e-04, -3.4294e-04, -5.7003e-04,  ..., -5.2549e-04,\n",
            "           -6.1812e-04, -3.3561e-04],\n",
            "          ...,\n",
            "          [-1.0890e-04, -1.2957e-04, -3.0505e-04,  ..., -4.3483e-04,\n",
            "           -5.0027e-04, -3.6230e-04],\n",
            "          [ 8.4176e-06, -1.1457e-04, -2.2578e-04,  ..., -5.8253e-04,\n",
            "           -4.4905e-04, -4.3094e-04],\n",
            "          [ 2.1954e-04,  2.5148e-05,  1.0138e-05,  ..., -3.8873e-04,\n",
            "           -4.7891e-04, -4.0493e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1962e-03,  2.4197e-03,  2.4427e-03,  ...,  2.4078e-03,\n",
            "            2.4563e-03,  2.5664e-03],\n",
            "          [ 2.1984e-03,  2.5020e-03,  2.5363e-03,  ...,  2.4629e-03,\n",
            "            2.5027e-03,  2.5776e-03],\n",
            "          [ 2.4992e-03,  2.6376e-03,  2.6671e-03,  ...,  2.4934e-03,\n",
            "            2.5440e-03,  2.4119e-03],\n",
            "          ...,\n",
            "          [ 2.2375e-03,  2.1921e-03,  2.1390e-03,  ...,  2.0282e-03,\n",
            "            2.2921e-03,  2.3213e-03],\n",
            "          [ 2.1484e-03,  2.1837e-03,  2.3577e-03,  ...,  2.2321e-03,\n",
            "            2.3135e-03,  2.3813e-03],\n",
            "          [ 1.8573e-03,  1.7951e-03,  2.0608e-03,  ...,  2.0896e-03,\n",
            "            2.3427e-03,  2.4396e-03]],\n",
            "\n",
            "         [[-4.1367e-04, -3.9995e-04, -6.1262e-04,  ..., -1.2951e-03,\n",
            "           -1.6889e-03, -1.4651e-03],\n",
            "          [-9.8016e-04, -7.2436e-04, -7.2449e-04,  ..., -1.3424e-03,\n",
            "           -1.7366e-03, -1.7003e-03],\n",
            "          [-1.4892e-03, -1.1572e-03, -1.0484e-03,  ..., -1.6970e-03,\n",
            "           -2.2187e-03, -2.1705e-03],\n",
            "          ...,\n",
            "          [-2.0579e-03, -1.9087e-03, -1.8923e-03,  ..., -1.8607e-03,\n",
            "           -2.0688e-03, -2.0490e-03],\n",
            "          [-2.1813e-03, -1.9396e-03, -1.7010e-03,  ..., -1.4704e-03,\n",
            "           -1.6312e-03, -1.5260e-03],\n",
            "          [-2.1400e-03, -1.9102e-03, -1.6582e-03,  ..., -1.5243e-03,\n",
            "           -1.4250e-03, -1.3017e-03]],\n",
            "\n",
            "         [[-7.6558e-04, -6.2375e-04, -4.0622e-04,  ..., -3.7872e-04,\n",
            "           -4.8866e-04, -4.1442e-04],\n",
            "          [-1.0588e-03, -6.4299e-04, -3.7992e-04,  ..., -3.6456e-04,\n",
            "           -5.4775e-04, -6.7686e-04],\n",
            "          [-1.1890e-03, -7.2177e-04, -4.7802e-04,  ..., -6.5329e-04,\n",
            "           -8.2769e-04, -9.1428e-04],\n",
            "          ...,\n",
            "          [-1.3853e-03, -1.1750e-03, -8.9500e-04,  ..., -5.7366e-04,\n",
            "           -5.6342e-04, -6.0859e-04],\n",
            "          [-1.3313e-03, -1.0948e-03, -6.7284e-04,  ..., -3.4098e-04,\n",
            "           -1.9196e-04, -3.6612e-04],\n",
            "          [-1.5456e-03, -1.2104e-03, -7.8693e-04,  ..., -5.0285e-04,\n",
            "           -2.6009e-04, -3.4564e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8216e-04,  2.1661e-04,  1.7213e-04,  ...,  5.6690e-04,\n",
            "            8.7773e-04,  8.6285e-04],\n",
            "          [-5.4884e-04, -6.6866e-04, -7.2679e-04,  ..., -3.2735e-04,\n",
            "            9.4552e-05,  3.1020e-05],\n",
            "          [-4.9564e-04, -5.9773e-04, -6.7743e-04,  ..., -2.6197e-04,\n",
            "            1.3644e-04,  1.0444e-04],\n",
            "          ...,\n",
            "          [-4.9429e-04, -5.6652e-04, -5.7315e-04,  ..., -2.3784e-04,\n",
            "           -3.3294e-06, -1.1057e-04],\n",
            "          [-4.4634e-04, -4.5892e-04, -4.9816e-04,  ..., -2.4356e-04,\n",
            "           -7.1434e-05, -1.2206e-04],\n",
            "          [-2.7949e-04, -3.8054e-04, -3.6048e-04,  ..., -2.5217e-04,\n",
            "           -8.8125e-05, -9.0548e-05]],\n",
            "\n",
            "         [[-5.2990e-04, -7.1565e-04, -7.9551e-04,  ..., -5.8436e-04,\n",
            "           -4.6452e-04, -4.5919e-04],\n",
            "          [-7.2305e-04, -8.4510e-04, -9.0901e-04,  ..., -7.5650e-04,\n",
            "           -6.4423e-04, -5.9036e-04],\n",
            "          [-6.4950e-04, -8.0816e-04, -8.4074e-04,  ..., -6.2974e-04,\n",
            "           -5.6605e-04, -5.4336e-04],\n",
            "          ...,\n",
            "          [-6.4131e-04, -8.2110e-04, -8.8947e-04,  ..., -7.4004e-04,\n",
            "           -8.3844e-04, -8.3538e-04],\n",
            "          [-5.5131e-04, -7.2084e-04, -9.2451e-04,  ..., -7.6699e-04,\n",
            "           -8.1980e-04, -8.1594e-04],\n",
            "          [-3.1078e-04, -6.1134e-04, -7.7887e-04,  ..., -7.2685e-04,\n",
            "           -8.6896e-04, -7.0385e-04]],\n",
            "\n",
            "         [[ 8.0602e-04,  6.4997e-04,  6.8233e-04,  ...,  9.7361e-04,\n",
            "            1.4450e-03,  1.4788e-03],\n",
            "          [ 1.0929e-04,  3.2302e-06, -1.0268e-04,  ...,  2.9945e-04,\n",
            "            6.1993e-04,  7.0827e-04],\n",
            "          [ 7.2229e-05, -3.0796e-05, -6.8121e-05,  ...,  2.2568e-04,\n",
            "            7.6773e-04,  6.9337e-04],\n",
            "          ...,\n",
            "          [-1.3279e-04, -1.6477e-04, -2.3530e-04,  ...,  1.8913e-05,\n",
            "            4.0547e-04,  3.5717e-04],\n",
            "          [-9.3065e-05, -1.0617e-04, -1.6216e-04,  ...,  1.1974e-05,\n",
            "            3.3458e-04,  3.6093e-04],\n",
            "          [ 7.6791e-05, -2.2074e-05, -8.6435e-05,  ..., -6.8389e-05,\n",
            "            3.4165e-04,  3.6435e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5424e-04,  1.5712e-04,  6.6166e-05,  ...,  3.5781e-04,\n",
            "            7.0457e-04,  1.0857e-03],\n",
            "          [ 6.5356e-04, -1.2229e-04,  1.9239e-04,  ...,  3.5980e-04,\n",
            "            6.1183e-04,  1.2058e-03],\n",
            "          [ 5.5345e-04,  1.9953e-04,  3.7988e-04,  ...,  4.7637e-04,\n",
            "            3.3609e-04,  9.1671e-04],\n",
            "          ...,\n",
            "          [ 6.2098e-04,  5.6271e-04,  6.8713e-04,  ...,  5.9123e-04,\n",
            "            6.0361e-04,  9.0869e-04],\n",
            "          [ 1.1250e-03,  8.4691e-04,  9.8129e-04,  ...,  1.0800e-03,\n",
            "            1.1129e-03,  1.3845e-03],\n",
            "          [ 1.2289e-03,  1.0347e-03,  1.2745e-03,  ...,  1.3975e-03,\n",
            "            1.1288e-03,  1.5683e-03]],\n",
            "\n",
            "         [[-9.5652e-05, -7.8861e-04, -8.2171e-04,  ..., -2.6531e-05,\n",
            "           -3.5062e-06, -1.9791e-04],\n",
            "          [-7.4438e-04, -1.3069e-03, -1.2298e-03,  ..., -6.2555e-04,\n",
            "           -5.6066e-04, -6.3712e-04],\n",
            "          [-6.6244e-04, -1.0970e-03, -9.7138e-04,  ..., -5.9302e-04,\n",
            "           -4.1831e-04, -5.1430e-04],\n",
            "          ...,\n",
            "          [ 3.0483e-04,  1.1029e-04,  1.1103e-04,  ..., -2.0061e-04,\n",
            "            6.2626e-05,  3.9815e-04],\n",
            "          [ 4.4200e-04,  3.7083e-04,  3.6020e-04,  ...,  1.7549e-04,\n",
            "            3.8951e-04,  8.2561e-04],\n",
            "          [ 8.3733e-04,  7.0340e-04,  7.4368e-04,  ...,  4.9907e-04,\n",
            "            4.5383e-04,  8.0571e-04]],\n",
            "\n",
            "         [[ 9.4369e-04,  4.2254e-04,  1.6224e-04,  ...,  5.3644e-04,\n",
            "            4.9701e-04, -6.7962e-05],\n",
            "          [ 5.2014e-04,  4.1800e-05, -7.9303e-05,  ...,  4.0252e-04,\n",
            "            3.5248e-04,  6.6086e-05],\n",
            "          [ 5.1424e-04,  6.1812e-05, -3.3215e-05,  ...,  3.5137e-04,\n",
            "            3.2281e-04,  1.7096e-04],\n",
            "          ...,\n",
            "          [ 9.1079e-04,  8.0408e-04,  5.1629e-04,  ...,  2.2431e-04,\n",
            "            1.3737e-04,  2.1387e-04],\n",
            "          [ 1.3359e-03,  1.1046e-03,  9.1992e-04,  ...,  7.8829e-04,\n",
            "            8.0670e-04,  1.0145e-03],\n",
            "          [ 1.2369e-03,  1.2156e-03,  1.0948e-03,  ...,  1.0193e-03,\n",
            "            9.3992e-04,  1.1240e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2625e-03,  2.3723e-03,  2.2891e-03,  ...,  1.8429e-03,\n",
            "            1.8849e-03,  1.7442e-03],\n",
            "          [ 1.5387e-03,  1.8328e-03,  1.7317e-03,  ...,  1.1466e-03,\n",
            "            1.3500e-03,  1.2656e-03],\n",
            "          [ 1.5784e-03,  1.8141e-03,  1.9235e-03,  ...,  1.3785e-03,\n",
            "            1.4576e-03,  1.2602e-03],\n",
            "          ...,\n",
            "          [ 1.4340e-03,  1.9724e-03,  2.1763e-03,  ...,  1.2282e-03,\n",
            "            9.4876e-04,  6.8786e-04],\n",
            "          [ 1.2749e-03,  1.6330e-03,  1.4880e-03,  ...,  4.0538e-04,\n",
            "            3.1233e-04,  3.2800e-04],\n",
            "          [ 9.5851e-04,  1.3258e-03,  1.0417e-03,  ...,  1.6557e-04,\n",
            "            1.9602e-04,  2.3482e-04]],\n",
            "\n",
            "         [[ 4.1901e-03,  3.9946e-03,  3.7826e-03,  ...,  3.6865e-03,\n",
            "            3.9646e-03,  4.3083e-03],\n",
            "          [ 3.9639e-03,  3.9018e-03,  3.5305e-03,  ...,  3.3462e-03,\n",
            "            3.5009e-03,  3.8374e-03],\n",
            "          [ 4.0676e-03,  4.0507e-03,  3.8938e-03,  ...,  3.6184e-03,\n",
            "            3.6789e-03,  3.8004e-03],\n",
            "          ...,\n",
            "          [ 4.3776e-03,  4.5247e-03,  4.3674e-03,  ...,  3.8804e-03,\n",
            "            3.5914e-03,  3.4797e-03],\n",
            "          [ 4.2013e-03,  4.2976e-03,  4.0103e-03,  ...,  3.3720e-03,\n",
            "            3.2390e-03,  3.2976e-03],\n",
            "          [ 4.0036e-03,  3.9429e-03,  3.6244e-03,  ...,  3.0657e-03,\n",
            "            2.9728e-03,  3.1117e-03]],\n",
            "\n",
            "         [[ 2.4672e-03,  3.2072e-03,  3.3103e-03,  ...,  2.6263e-03,\n",
            "            2.7729e-03,  2.8767e-03],\n",
            "          [ 1.5778e-03,  2.4306e-03,  2.3457e-03,  ...,  1.4772e-03,\n",
            "            1.6452e-03,  1.7652e-03],\n",
            "          [ 1.6790e-03,  2.3976e-03,  2.3486e-03,  ...,  1.5301e-03,\n",
            "            1.6620e-03,  1.7215e-03],\n",
            "          ...,\n",
            "          [ 2.1636e-03,  3.0885e-03,  3.2345e-03,  ...,  2.3436e-03,\n",
            "            2.3171e-03,  2.3861e-03],\n",
            "          [ 1.9246e-03,  2.8675e-03,  2.9405e-03,  ...,  1.9830e-03,\n",
            "            2.0638e-03,  2.2876e-03],\n",
            "          [ 1.8254e-03,  2.6171e-03,  2.5670e-03,  ...,  1.7328e-03,\n",
            "            1.7864e-03,  2.0515e-03]]]])}, 1: {'momentum_buffer': tensor([-2.7776e-03,  6.5580e-03,  6.0592e-03,  1.2624e-04,  1.7708e-03,\n",
            "        -3.3153e-04, -1.7990e-04,  1.9420e-03, -1.0651e-03, -2.4903e-03,\n",
            "         6.1160e-03, -4.9277e-03,  4.3831e-03,  6.1179e-03,  9.2571e-03,\n",
            "         1.7463e-04,  2.7049e-03, -5.5041e-05,  6.4042e-04,  4.6561e-03,\n",
            "         3.1271e-03,  7.1765e-03, -1.1098e-02, -2.5739e-03,  1.4751e-03,\n",
            "        -1.8160e-03, -2.9395e-03,  1.0671e-03,  3.1091e-03,  1.9269e-03,\n",
            "         7.5606e-03, -4.9750e-04, -1.3272e-04, -3.3063e-03, -1.0108e-03,\n",
            "         1.7265e-04,  1.7968e-03, -3.4279e-03,  4.6493e-03,  3.2763e-03,\n",
            "        -7.0870e-03,  5.0832e-03,  4.3430e-03, -2.2269e-04, -5.4719e-03,\n",
            "         5.9240e-03,  9.3843e-03,  1.3922e-03,  9.1162e-04, -9.3339e-04,\n",
            "         1.2008e-03, -1.7928e-03, -2.1728e-03, -2.3164e-03, -1.0832e-03,\n",
            "         9.1570e-03, -3.6941e-03,  4.1041e-03,  2.9093e-03, -2.0826e-04,\n",
            "         1.8855e-03, -4.3794e-03, -2.0689e-03,  3.2097e-04])}, 2: {'momentum_buffer': tensor([ 0.0003,  0.0010,  0.0040, -0.0004,  0.0017, -0.0011,  0.0005, -0.0028,\n",
            "        -0.0031,  0.0048, -0.0025,  0.0004, -0.0042,  0.0078,  0.0034, -0.0045,\n",
            "         0.0020, -0.0045,  0.0010,  0.0033,  0.0039,  0.0035, -0.0079, -0.0005,\n",
            "         0.0005,  0.0028,  0.0041, -0.0040, -0.0020,  0.0013,  0.0050, -0.0078,\n",
            "         0.0074, -0.0077, -0.0041,  0.0008,  0.0055, -0.0004,  0.0039,  0.0065,\n",
            "        -0.0012,  0.0020, -0.0014,  0.0026, -0.0017,  0.0008,  0.0070,  0.0045,\n",
            "         0.0036, -0.0030, -0.0033, -0.0061,  0.0036, -0.0062, -0.0019,  0.0026,\n",
            "        -0.0014, -0.0002, -0.0043,  0.0025, -0.0022, -0.0069,  0.0008, -0.0061])}, 3: {'momentum_buffer': tensor([[[[-8.9931e-06]],\n",
            "\n",
            "         [[ 6.9722e-07]],\n",
            "\n",
            "         [[ 6.1941e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9168e-03]],\n",
            "\n",
            "         [[ 1.1074e-03]],\n",
            "\n",
            "         [[ 1.9279e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.7867e-05]],\n",
            "\n",
            "         [[ 2.3025e-04]],\n",
            "\n",
            "         [[-7.0547e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0572e-03]],\n",
            "\n",
            "         [[-1.2560e-03]],\n",
            "\n",
            "         [[ 1.6293e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9661e-05]],\n",
            "\n",
            "         [[-8.5466e-05]],\n",
            "\n",
            "         [[ 9.4064e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2389e-03]],\n",
            "\n",
            "         [[-9.3264e-04]],\n",
            "\n",
            "         [[ 2.5392e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.9500e-03]],\n",
            "\n",
            "         [[-2.9944e-03]],\n",
            "\n",
            "         [[-2.1754e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3765e-03]],\n",
            "\n",
            "         [[-3.2179e-04]],\n",
            "\n",
            "         [[-1.5387e-04]]],\n",
            "\n",
            "\n",
            "        [[[-6.9952e-04]],\n",
            "\n",
            "         [[-2.9549e-03]],\n",
            "\n",
            "         [[ 1.3498e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0164e-03]],\n",
            "\n",
            "         [[-2.0609e-03]],\n",
            "\n",
            "         [[ 9.8836e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2447e-03]],\n",
            "\n",
            "         [[ 2.1463e-03]],\n",
            "\n",
            "         [[ 1.2026e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1088e-03]],\n",
            "\n",
            "         [[-2.0568e-03]],\n",
            "\n",
            "         [[-4.9131e-04]]]])}, 4: {'momentum_buffer': tensor([ 2.9558e-03, -8.1121e-05,  2.8442e-03,  1.2922e-03,  2.5895e-03,\n",
            "         2.3671e-04, -1.1869e-03,  4.6444e-04, -1.1736e-03,  1.2148e-03,\n",
            "        -1.7335e-03,  3.4977e-03,  3.3733e-03,  2.6669e-03, -5.8919e-05,\n",
            "        -1.7857e-03,  1.9194e-03,  6.8526e-04,  1.1327e-03,  9.3875e-04,\n",
            "         5.6534e-03,  1.3221e-03,  5.9286e-04,  4.4147e-03,  1.4793e-03,\n",
            "        -1.9398e-04,  1.1766e-03,  2.6076e-03,  1.7262e-03,  3.4562e-03,\n",
            "        -2.2252e-03,  2.0728e-04,  1.8429e-03,  2.7162e-03,  2.4712e-03,\n",
            "         2.3131e-03, -1.5228e-03, -1.3786e-03,  9.1529e-05,  4.6910e-03,\n",
            "         2.2793e-03,  1.9977e-03,  1.2209e-03, -1.8099e-03, -4.6528e-04,\n",
            "         1.7387e-03, -6.6791e-04,  1.1066e-03, -2.1037e-03,  2.2387e-03,\n",
            "        -1.9560e-03,  2.5467e-03, -5.6951e-04,  2.1760e-04, -9.3795e-04,\n",
            "        -1.1410e-03,  2.7114e-03,  3.9701e-03, -1.7741e-03,  3.9275e-04,\n",
            "         1.5513e-03, -1.0356e-03,  6.6014e-05,  2.7704e-03])}, 5: {'momentum_buffer': tensor([-1.7822e-03, -2.1736e-03,  7.2174e-04, -1.1808e-03,  5.3886e-04,\n",
            "        -3.3678e-03, -2.5050e-03, -1.6818e-03, -1.8415e-03,  1.6467e-03,\n",
            "        -2.1102e-03,  2.9515e-04, -2.0649e-05,  1.6759e-03, -3.8448e-03,\n",
            "        -6.9456e-04, -8.0009e-04,  9.3521e-04,  1.5143e-03, -2.5467e-03,\n",
            "        -1.4966e-03, -4.1145e-03, -3.0874e-05,  1.3224e-03, -1.3982e-03,\n",
            "        -1.1302e-03, -8.3190e-05,  3.3016e-03, -1.5320e-03,  4.2900e-04,\n",
            "        -1.1308e-03,  1.4050e-03, -1.1881e-03,  2.5461e-03,  5.0806e-03,\n",
            "        -1.6900e-03, -3.6753e-03, -5.1087e-04, -1.8622e-03,  4.1250e-03,\n",
            "         2.0841e-03,  6.3963e-04,  9.0989e-04, -1.9098e-03, -1.8192e-03,\n",
            "         8.7041e-04, -7.2767e-04,  1.2715e-03, -2.0961e-05, -1.8705e-03,\n",
            "        -1.0787e-03,  2.7729e-03,  1.4438e-03, -2.0219e-03, -5.4181e-03,\n",
            "        -3.0288e-03, -1.4832e-03,  1.5450e-03,  2.7829e-03,  7.4061e-04,\n",
            "         2.3412e-03, -3.9644e-03, -3.0762e-03,  2.6381e-03])}, 6: {'momentum_buffer': tensor([[[[ 3.6297e-04, -6.8428e-05, -3.6124e-04],\n",
            "          [ 2.2367e-04, -5.0404e-04, -6.4419e-04],\n",
            "          [-3.4994e-04, -1.2038e-03, -1.2016e-03]],\n",
            "\n",
            "         [[-3.1258e-03, -2.5770e-03, -2.8828e-03],\n",
            "          [-1.7729e-03, -1.6352e-03, -2.4398e-03],\n",
            "          [-6.8035e-04, -6.7419e-04, -1.5763e-03]],\n",
            "\n",
            "         [[-3.1959e-03, -2.1204e-03, -3.6385e-03],\n",
            "          [-1.8255e-03, -1.4315e-03, -2.7075e-03],\n",
            "          [-1.7894e-03, -1.4859e-03, -2.4827e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.1854e-04,  2.6488e-04,  1.4372e-04],\n",
            "          [ 3.0005e-04, -2.1566e-04, -1.3437e-04],\n",
            "          [-5.7269e-04, -7.7865e-04, -4.2486e-04]],\n",
            "\n",
            "         [[-1.3483e-04, -3.9768e-04,  5.0408e-04],\n",
            "          [-8.3760e-04, -3.2155e-04,  2.7726e-04],\n",
            "          [-7.3865e-04, -2.2550e-04,  6.6147e-05]],\n",
            "\n",
            "         [[ 1.6254e-03,  1.7645e-03,  8.1377e-04],\n",
            "          [ 1.7453e-03,  1.7547e-03,  1.0479e-03],\n",
            "          [ 1.4620e-03,  1.5466e-03,  8.2318e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.2682e-04, -9.8976e-05,  2.2700e-04],\n",
            "          [-7.2468e-04, -2.6589e-04,  2.4537e-04],\n",
            "          [-6.9045e-04, -1.6798e-04,  5.8070e-04]],\n",
            "\n",
            "         [[-1.0175e-05, -1.1888e-04,  3.8105e-05],\n",
            "          [-2.2076e-04, -2.8530e-04, -1.7078e-04],\n",
            "          [-1.4406e-04, -1.4068e-04,  1.0459e-04]],\n",
            "\n",
            "         [[ 9.0660e-05, -1.2677e-04, -1.7068e-04],\n",
            "          [-1.2880e-05, -2.5980e-04, -2.5730e-04],\n",
            "          [ 1.4898e-04, -6.2404e-05, -1.6341e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.4454e-04, -6.1893e-04, -6.2285e-04],\n",
            "          [-8.6960e-04, -4.8838e-04, -3.5013e-04],\n",
            "          [-9.1709e-04, -6.3599e-04,  3.2324e-05]],\n",
            "\n",
            "         [[ 1.3258e-03,  9.6095e-04,  8.9343e-04],\n",
            "          [ 1.8141e-03,  1.2444e-03,  1.0081e-03],\n",
            "          [ 1.4462e-03,  1.0012e-03,  6.6644e-04]],\n",
            "\n",
            "         [[-1.8841e-04, -3.1722e-04, -2.7838e-04],\n",
            "          [-1.3729e-04, -3.9735e-04, -2.4103e-04],\n",
            "          [ 2.6252e-05, -1.6922e-04, -2.8611e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6203e-04,  6.2831e-04,  7.8752e-04],\n",
            "          [ 2.3205e-05,  3.4029e-04,  5.0160e-04],\n",
            "          [-1.2657e-04,  1.7123e-04,  5.7272e-04]],\n",
            "\n",
            "         [[-1.3631e-03, -1.5130e-03, -1.4449e-03],\n",
            "          [-1.4037e-03, -1.3469e-03, -1.9333e-03],\n",
            "          [-1.7032e-03, -1.3390e-03, -1.9444e-03]],\n",
            "\n",
            "         [[-2.2048e-03, -1.9774e-03, -1.8387e-03],\n",
            "          [-1.7407e-03, -1.5006e-03, -2.3638e-03],\n",
            "          [-2.1113e-03, -2.2062e-03, -2.5283e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2214e-04, -7.4287e-04, -6.2316e-04],\n",
            "          [-6.8599e-04, -7.2835e-04, -6.0446e-04],\n",
            "          [-1.0125e-03, -7.6804e-04, -8.9555e-04]],\n",
            "\n",
            "         [[ 2.8382e-03,  2.6955e-03,  2.8144e-03],\n",
            "          [ 2.1545e-03,  2.8495e-03,  2.8180e-03],\n",
            "          [ 2.5413e-03,  2.9155e-03,  2.9392e-03]],\n",
            "\n",
            "         [[-3.5104e-03, -3.3988e-03, -3.6163e-03],\n",
            "          [-3.5224e-03, -3.4411e-03, -3.9135e-03],\n",
            "          [-4.0555e-03, -4.1049e-03, -4.3426e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3156e-03,  1.4417e-03,  1.0954e-03],\n",
            "          [ 2.0972e-03,  1.7098e-03,  1.6723e-03],\n",
            "          [ 2.3463e-03,  2.1675e-03,  2.0094e-03]],\n",
            "\n",
            "         [[-2.4464e-03, -1.7941e-03, -1.6197e-03],\n",
            "          [-2.4629e-03, -1.5044e-03, -1.4686e-03],\n",
            "          [-2.4141e-03, -1.1188e-03, -1.0115e-03]],\n",
            "\n",
            "         [[-1.5634e-03, -8.2306e-04, -5.9460e-04],\n",
            "          [-1.4491e-03, -7.2167e-04, -3.8867e-04],\n",
            "          [-1.4889e-03, -7.1455e-04, -3.1648e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5495e-03,  1.2996e-03,  1.1499e-03],\n",
            "          [ 2.0934e-03,  1.8181e-03,  1.3553e-03],\n",
            "          [ 2.4281e-03,  1.8208e-03,  1.6701e-03]],\n",
            "\n",
            "         [[ 2.8083e-04, -1.2420e-04,  2.7663e-05],\n",
            "          [-5.1959e-04, -4.5582e-04, -4.6233e-04],\n",
            "          [-1.0167e-03, -1.0336e-03, -7.6323e-04]],\n",
            "\n",
            "         [[-4.3947e-04, -2.7728e-04, -4.2530e-04],\n",
            "          [-5.4615e-04, -6.1985e-04, -7.5681e-04],\n",
            "          [-6.9701e-04, -7.7532e-04, -8.4661e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.8195e-03, -2.2992e-03, -2.4653e-03],\n",
            "          [-1.7164e-03, -2.1452e-03, -2.1792e-03],\n",
            "          [-2.0833e-03, -2.1115e-03, -1.9515e-03]],\n",
            "\n",
            "         [[ 4.6075e-04,  1.0944e-03,  1.3387e-03],\n",
            "          [ 8.0675e-04,  8.9703e-04,  1.2353e-03],\n",
            "          [ 1.0603e-03,  9.5267e-04,  1.1700e-03]],\n",
            "\n",
            "         [[ 5.8972e-04,  6.0774e-04,  9.5444e-04],\n",
            "          [ 3.8622e-04,  4.1932e-04,  6.4884e-04],\n",
            "          [ 7.8318e-04,  7.3400e-04,  6.2959e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7801e-03, -2.9647e-03, -2.6714e-03],\n",
            "          [-2.4284e-03, -2.6901e-03, -2.6464e-03],\n",
            "          [-2.0161e-03, -2.2684e-03, -2.5643e-03]],\n",
            "\n",
            "         [[ 1.9307e-03,  1.2883e-03,  2.8712e-04],\n",
            "          [ 8.6836e-04,  1.0587e-03,  1.7639e-04],\n",
            "          [ 1.9057e-04,  7.8300e-04,  2.3206e-04]],\n",
            "\n",
            "         [[ 1.2414e-03,  6.0691e-04,  5.4828e-04],\n",
            "          [ 7.5171e-04,  7.7163e-04,  6.4538e-04],\n",
            "          [ 9.2109e-04,  7.2279e-04,  4.1030e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.9372e-04,  7.0755e-04,  4.0713e-04],\n",
            "          [ 3.5300e-04,  3.2969e-04, -2.7420e-04],\n",
            "          [ 7.2478e-05,  2.4143e-05, -7.1938e-04]],\n",
            "\n",
            "         [[ 1.6198e-03,  1.4432e-03,  1.0938e-03],\n",
            "          [ 1.1743e-03,  1.1896e-03,  9.1224e-04],\n",
            "          [ 3.8929e-04,  6.6559e-04,  7.6333e-04]],\n",
            "\n",
            "         [[ 1.4473e-03,  1.2962e-03,  9.6819e-04],\n",
            "          [ 1.2658e-03,  1.0033e-03,  1.0536e-03],\n",
            "          [ 1.3221e-03,  1.0554e-03,  1.1430e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5517e-03, -1.2018e-03, -1.2421e-03],\n",
            "          [-1.4089e-03, -1.4813e-03, -1.9544e-03],\n",
            "          [-1.9166e-03, -1.8766e-03, -2.5932e-03]],\n",
            "\n",
            "         [[-1.3589e-03, -1.4496e-03, -1.2720e-03],\n",
            "          [-6.2248e-04, -7.4145e-04, -2.3972e-05],\n",
            "          [-1.4277e-04, -2.3496e-04,  5.5083e-04]],\n",
            "\n",
            "         [[ 7.5065e-05,  7.0453e-05,  5.6799e-05],\n",
            "          [ 1.1141e-04, -7.5330e-05, -5.8487e-05],\n",
            "          [ 7.8399e-05, -2.3665e-05,  9.8587e-05]]]])}, 7: {'momentum_buffer': tensor([-2.9850e-03, -1.5020e-04, -6.0785e-03,  2.9682e-03,  2.8655e-03,\n",
            "         2.9280e-03, -2.6688e-04, -4.7650e-04,  2.0674e-03,  1.0474e-04,\n",
            "         2.0946e-03,  3.0699e-03, -3.0661e-03, -5.7027e-03,  2.5529e-03,\n",
            "         9.2792e-04,  3.7628e-03, -2.1570e-03, -4.9445e-03,  1.6194e-03,\n",
            "         3.3669e-03,  5.6560e-04,  7.9046e-04, -1.3094e-03,  3.5537e-03,\n",
            "        -1.2928e-03,  2.1261e-03,  2.9694e-03,  4.7970e-03, -3.1634e-03,\n",
            "        -2.7365e-03, -1.5385e-04,  6.1957e-03,  5.2131e-03,  2.1125e-03,\n",
            "         5.5972e-03, -2.2640e-04,  6.6218e-04,  1.1139e-03,  4.2594e-03,\n",
            "         1.1894e-03,  3.1155e-04,  1.3450e-03,  3.0760e-03,  8.1396e-04,\n",
            "         3.0795e-03, -3.7767e-04,  7.2254e-03,  3.7295e-03,  2.1067e-03,\n",
            "        -1.3743e-03,  3.5122e-03,  2.4845e-03, -1.2707e-05,  5.7156e-03,\n",
            "        -1.2350e-03, -3.9299e-03, -6.8539e-04, -2.9691e-03,  3.1610e-05,\n",
            "         1.3605e-03, -9.8537e-04,  4.6844e-03,  1.0012e-03])}, 8: {'momentum_buffer': tensor([-2.4001e-03,  4.3840e-04, -2.9557e-03, -3.4597e-03,  1.2186e-03,\n",
            "         9.6576e-04, -1.9309e-03, -3.9923e-03,  3.3492e-04,  1.4215e-03,\n",
            "         1.0813e-04,  1.4863e-03, -5.2125e-03,  1.7453e-03, -2.7086e-03,\n",
            "        -1.0965e-03, -1.4740e-04, -2.9639e-03, -4.3928e-03,  4.1917e-04,\n",
            "         2.4585e-05, -1.1980e-04,  2.0233e-03, -2.4570e-03,  1.3458e-03,\n",
            "        -4.8383e-03,  8.4732e-04,  2.0891e-03,  1.5500e-03, -1.5898e-03,\n",
            "         9.5236e-04, -1.3513e-03,  1.2060e-03,  2.1368e-03, -2.0235e-03,\n",
            "         2.2462e-03, -2.5648e-03, -2.1554e-03,  1.0394e-03,  1.0620e-03,\n",
            "         1.7272e-03, -3.5800e-03,  2.2450e-03,  4.1472e-04, -1.0720e-03,\n",
            "         1.8516e-04, -4.6061e-03,  3.9318e-03,  1.7566e-04,  3.9669e-03,\n",
            "        -1.9580e-03, -1.3770e-03, -1.6087e-03,  6.8688e-04,  3.8286e-03,\n",
            "        -1.8851e-03, -5.0512e-03,  4.8538e-04, -2.6760e-03, -3.3186e-03,\n",
            "         1.7108e-03, -1.7745e-03, -7.9366e-05,  1.6349e-03])}, 9: {'momentum_buffer': tensor([[[[ 2.2137e-03]],\n",
            "\n",
            "         [[-1.7466e-03]],\n",
            "\n",
            "         [[ 1.4500e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1229e-04]],\n",
            "\n",
            "         [[-1.4513e-03]],\n",
            "\n",
            "         [[ 1.5376e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3480e-05]],\n",
            "\n",
            "         [[-1.7375e-03]],\n",
            "\n",
            "         [[ 4.0778e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2298e-04]],\n",
            "\n",
            "         [[ 3.0309e-04]],\n",
            "\n",
            "         [[-5.4244e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.8464e-04]],\n",
            "\n",
            "         [[-4.0068e-04]],\n",
            "\n",
            "         [[ 3.8579e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.1788e-04]],\n",
            "\n",
            "         [[ 1.0205e-03]],\n",
            "\n",
            "         [[ 2.6406e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.5701e-04]],\n",
            "\n",
            "         [[-6.5768e-04]],\n",
            "\n",
            "         [[ 9.9865e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.0575e-04]],\n",
            "\n",
            "         [[-3.0279e-04]],\n",
            "\n",
            "         [[-8.3174e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.1591e-03]],\n",
            "\n",
            "         [[-1.8411e-03]],\n",
            "\n",
            "         [[-1.6893e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.5931e-04]],\n",
            "\n",
            "         [[-3.4295e-03]],\n",
            "\n",
            "         [[ 9.6260e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4074e-03]],\n",
            "\n",
            "         [[-2.0601e-03]],\n",
            "\n",
            "         [[ 3.4391e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5115e-04]],\n",
            "\n",
            "         [[-3.0675e-03]],\n",
            "\n",
            "         [[-1.3640e-03]]]])}, 10: {'momentum_buffer': tensor([ 2.3919e-03,  1.9403e-03, -7.3797e-04,  3.2299e-03, -3.7609e-04,\n",
            "         2.0830e-03,  3.5299e-03,  1.8594e-03,  2.4681e-03, -8.9652e-04,\n",
            "         4.2606e-04, -6.2678e-04,  5.4747e-05,  1.3822e-03,  6.8611e-04,\n",
            "        -1.9012e-03, -4.3095e-04,  2.5765e-03, -1.6825e-03,  8.8378e-04,\n",
            "         1.5910e-03,  1.7896e-03,  7.3389e-04,  1.7821e-04,  1.8791e-04,\n",
            "        -2.0269e-04,  5.4287e-04,  1.0737e-03,  8.1140e-04,  2.9303e-03,\n",
            "         1.6132e-03,  2.8861e-03,  1.8226e-03,  1.4922e-04,  6.3762e-04,\n",
            "         2.4466e-04,  1.9759e-03, -6.9974e-04,  2.0161e-04,  5.0389e-04,\n",
            "         4.9081e-03,  3.0788e-04,  1.3301e-04,  3.4607e-03,  2.1376e-03,\n",
            "         1.5207e-03,  7.8347e-04,  3.6470e-03,  5.5263e-04,  5.2408e-04,\n",
            "         2.5066e-03,  1.2262e-03,  1.6619e-03,  2.6726e-03, -1.4387e-04,\n",
            "        -1.9004e-04,  2.3778e-03, -4.5633e-04,  1.9616e-04,  3.0980e-03,\n",
            "         1.2471e-03,  1.9507e-03,  5.3076e-04,  1.0674e-03, -8.2009e-06,\n",
            "         5.2364e-04,  1.3297e-03, -1.6915e-03, -1.7861e-04,  1.5301e-03,\n",
            "         2.1714e-03,  3.8770e-04,  1.1229e-03,  2.8907e-03,  2.8589e-03,\n",
            "         1.4412e-03,  1.0750e-03, -2.7807e-03,  9.1625e-04,  1.5435e-03,\n",
            "         8.2530e-04,  1.0481e-03,  1.1385e-03,  2.8933e-03, -1.4637e-04,\n",
            "         1.4734e-03,  1.7498e-03,  3.7506e-03,  1.4553e-03,  1.5840e-03,\n",
            "        -6.1398e-04,  8.1468e-04,  2.2156e-03, -8.4536e-04,  3.1906e-03,\n",
            "         2.3554e-03,  2.1080e-03, -1.6334e-03, -3.1021e-05, -1.2260e-04,\n",
            "         2.2543e-03,  1.8983e-05,  3.7602e-04,  1.1589e-03, -5.7755e-04,\n",
            "         1.5197e-03, -3.3690e-04,  7.7952e-04,  2.1899e-03,  2.6353e-03,\n",
            "         3.5563e-04,  2.2958e-03,  5.2673e-04,  4.0662e-03,  1.3933e-03,\n",
            "        -2.6706e-04,  2.8418e-03,  1.6008e-03,  2.0813e-03,  1.7140e-03,\n",
            "         4.8916e-04,  2.9427e-03,  1.7629e-03,  1.5612e-03, -3.0579e-04,\n",
            "         1.6586e-03,  1.7305e-03,  2.8324e-04,  3.7124e-04,  4.6087e-04,\n",
            "         1.6935e-04,  1.6764e-03,  7.1041e-04,  2.6162e-04, -4.0862e-04,\n",
            "         1.8652e-03, -1.4025e-03, -8.0793e-04, -1.5334e-03, -3.0631e-05,\n",
            "         1.0921e-03,  1.7672e-03,  7.8622e-04,  1.1390e-03,  8.4057e-04,\n",
            "         3.3175e-03,  6.2649e-04,  2.6857e-03,  1.7654e-03,  1.5595e-03,\n",
            "         1.6872e-03,  2.4528e-04,  2.8034e-03,  3.1394e-04,  2.7908e-03,\n",
            "         1.2499e-03,  2.9277e-03,  3.3552e-03, -4.7071e-04,  4.1181e-03,\n",
            "         9.8388e-04, -2.0717e-04,  4.0116e-04,  1.2142e-03, -1.1634e-03,\n",
            "        -9.5007e-04,  1.6942e-03,  2.4431e-04,  1.9207e-03,  1.0625e-03,\n",
            "         6.0967e-04,  1.4077e-03, -1.1741e-03,  1.4062e-03,  1.2316e-03,\n",
            "         2.0079e-03, -3.4032e-03,  3.4468e-04, -8.9649e-04,  2.6750e-03,\n",
            "        -9.5710e-04,  1.6478e-04,  1.5359e-03,  3.1255e-03, -7.6318e-04,\n",
            "        -6.5161e-04,  2.2042e-03,  2.1282e-03,  8.4251e-04,  1.3488e-03,\n",
            "         3.0357e-03, -1.4301e-03,  2.2282e-03,  8.0765e-04,  6.8913e-04,\n",
            "         2.1470e-03, -9.7474e-04,  1.3220e-03,  9.8510e-04,  1.8126e-03,\n",
            "         2.0354e-03,  2.8278e-04,  3.3860e-03,  1.4564e-03, -9.1461e-04,\n",
            "        -6.0364e-05,  2.5626e-04,  2.0194e-03,  1.8868e-03, -5.2849e-04,\n",
            "         3.8008e-05,  1.3498e-03, -8.1819e-04, -1.0687e-03,  1.0810e-03,\n",
            "         1.5644e-03,  1.7572e-03,  1.3129e-03,  2.0629e-04,  9.5650e-04,\n",
            "         2.8669e-04,  1.4134e-03,  5.1513e-04,  1.5836e-03, -1.1053e-03,\n",
            "        -6.6203e-04,  9.3657e-04,  3.8181e-03,  2.3644e-03,  1.2811e-03,\n",
            "        -6.9861e-04,  2.9296e-03, -3.0948e-03,  1.2099e-03,  1.4508e-03,\n",
            "        -8.7498e-04, -1.5347e-03, -4.3366e-04, -5.1392e-04,  7.3927e-04,\n",
            "         1.1479e-03,  7.3747e-04, -1.1494e-03, -3.1438e-04,  7.4041e-04,\n",
            "         3.1535e-03,  2.4122e-03,  1.1545e-04,  2.0342e-03,  4.2126e-03,\n",
            "         1.8136e-03, -1.1625e-04,  1.5717e-03,  8.6911e-04, -3.8410e-04,\n",
            "        -5.6748e-04])}, 11: {'momentum_buffer': tensor([-3.7475e-04,  1.6885e-03, -8.3146e-04,  7.0845e-04, -5.8121e-04,\n",
            "        -3.1720e-04,  1.9855e-04, -5.9236e-04,  1.0229e-03, -2.4482e-03,\n",
            "        -7.1709e-04,  5.7139e-04, -1.3692e-04,  4.6055e-04,  5.4208e-04,\n",
            "        -1.1681e-03, -2.0905e-03,  3.6712e-04,  3.3357e-04,  8.1063e-04,\n",
            "         1.2762e-03,  6.5498e-04,  2.4542e-04, -3.2050e-05, -6.2147e-04,\n",
            "        -7.7222e-04,  8.1548e-04,  3.0864e-04,  1.1143e-04,  1.5560e-03,\n",
            "         2.4580e-03, -4.1108e-04, -8.2181e-04, -9.5462e-04, -5.9324e-04,\n",
            "        -1.3767e-03, -1.2146e-04,  5.9579e-04,  1.2672e-04,  9.1559e-04,\n",
            "         1.2247e-03,  8.1259e-04,  8.7207e-04,  7.3062e-04,  2.7883e-04,\n",
            "         9.9734e-04,  3.0731e-04,  2.7281e-04, -1.9604e-04,  1.1385e-03,\n",
            "         9.6443e-04,  3.7593e-04, -1.1533e-04,  1.9997e-03, -3.2287e-03,\n",
            "        -1.7176e-04,  1.9101e-03, -8.4335e-04, -3.8580e-04, -1.0425e-04,\n",
            "         1.3163e-03, -1.1795e-03, -2.7894e-03, -4.0539e-04,  7.3503e-04,\n",
            "        -1.9641e-03,  7.0696e-04, -1.9456e-03,  2.2608e-04,  8.0020e-04,\n",
            "         1.6840e-03,  1.0883e-04,  4.8309e-04,  1.0737e-03, -1.3489e-05,\n",
            "         3.0636e-04, -3.0299e-04, -1.3888e-03, -1.9353e-03,  5.4947e-04,\n",
            "         1.2472e-03, -4.4017e-04, -6.0228e-04, -1.0082e-04, -1.9500e-03,\n",
            "        -4.2975e-04,  5.8309e-04,  6.7815e-04,  2.4764e-04, -8.0025e-04,\n",
            "        -2.8795e-03,  1.6696e-04,  1.7332e-03,  4.6238e-04,  1.6010e-05,\n",
            "        -2.0854e-03, -1.2231e-03,  1.0261e-03, -3.6004e-04, -2.9459e-03,\n",
            "         5.7328e-04, -3.4812e-04, -5.1326e-04, -1.4258e-03,  1.1365e-04,\n",
            "        -2.5989e-04,  6.9212e-04, -5.6715e-04,  3.4530e-05,  5.9818e-04,\n",
            "         2.4894e-04,  2.5414e-05,  6.0904e-04,  2.1059e-03, -3.1197e-04,\n",
            "        -6.1786e-04,  1.4101e-03,  1.8052e-03,  7.2523e-04, -7.0858e-04,\n",
            "        -1.8564e-03,  1.8990e-05,  1.4901e-03,  1.8819e-04, -9.3506e-05,\n",
            "        -5.3596e-04, -4.9089e-04, -1.5332e-03, -9.3251e-04, -4.8153e-04,\n",
            "         7.3791e-04,  4.7989e-04,  6.5724e-05, -1.6726e-03, -2.1638e-03,\n",
            "        -1.0185e-06, -4.3836e-04, -1.3208e-03, -1.6116e-03, -2.5516e-03,\n",
            "        -3.2195e-04,  8.2256e-04, -5.3342e-04,  2.6065e-03, -3.4669e-04,\n",
            "         2.6323e-03,  9.2250e-04, -3.2139e-04, -5.1957e-04, -1.1287e-03,\n",
            "         1.4835e-04, -2.9220e-04, -1.2069e-05, -9.4020e-04,  2.0243e-03,\n",
            "        -8.0176e-04,  1.1804e-03,  2.5023e-03, -3.0999e-05,  1.8626e-03,\n",
            "        -5.6390e-04,  3.7916e-04,  1.9681e-03,  5.6721e-05, -1.3015e-03,\n",
            "         8.3996e-04, -3.5766e-04,  1.8636e-03, -2.0128e-05, -6.6639e-04,\n",
            "         9.8061e-04, -1.0607e-03, -2.2694e-03, -3.3389e-04, -5.0021e-04,\n",
            "        -4.6383e-04, -6.2764e-04,  2.5668e-03, -1.5730e-03,  1.6433e-03,\n",
            "        -1.6337e-03,  6.9318e-04, -1.6987e-04,  2.0750e-03, -1.7452e-03,\n",
            "        -5.2195e-04,  3.4417e-04, -1.4366e-04,  1.4452e-04, -5.9085e-04,\n",
            "         4.3038e-04, -1.2243e-03, -1.4348e-03, -1.3944e-03, -1.9051e-03,\n",
            "        -1.2169e-03, -1.2425e-03,  3.1871e-04, -3.8858e-04, -1.4451e-03,\n",
            "        -9.7100e-04, -2.6204e-04,  1.1570e-03, -1.4939e-03, -2.7194e-03,\n",
            "         1.8165e-03,  3.6340e-04, -1.3074e-03,  1.7478e-03, -6.9934e-04,\n",
            "         9.3413e-04,  1.8146e-04, -3.3831e-04, -6.3774e-04, -8.0594e-04,\n",
            "         7.4289e-04,  8.3137e-04, -2.4924e-04, -1.1234e-03,  2.8591e-04,\n",
            "        -1.1706e-03, -5.8120e-04,  5.0966e-05, -4.5102e-04, -1.2382e-03,\n",
            "         4.5969e-04,  1.4968e-03,  7.3634e-04,  7.7273e-04,  1.5541e-03,\n",
            "        -1.2332e-03,  1.7419e-03, -3.4279e-03,  7.1745e-04, -3.2430e-04,\n",
            "        -1.0210e-03, -1.3624e-03, -1.5737e-03, -1.3545e-03,  1.1045e-03,\n",
            "        -1.1903e-03, -7.7808e-04, -5.6372e-05, -1.6280e-03, -1.1001e-03,\n",
            "         3.5778e-04,  1.0693e-03, -1.1293e-03,  3.2106e-04,  1.2028e-03,\n",
            "         1.6809e-03,  6.1383e-04, -9.7947e-04,  1.0570e-03, -8.9932e-04,\n",
            "        -1.7873e-03])}, 12: {'momentum_buffer': tensor([[[[ 2.5862e-04]],\n",
            "\n",
            "         [[ 1.3034e-03]],\n",
            "\n",
            "         [[ 6.0569e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.9980e-05]],\n",
            "\n",
            "         [[ 1.1426e-04]],\n",
            "\n",
            "         [[ 1.6191e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3262e-03]],\n",
            "\n",
            "         [[-8.7582e-04]],\n",
            "\n",
            "         [[ 2.9850e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7762e-04]],\n",
            "\n",
            "         [[-2.0295e-03]],\n",
            "\n",
            "         [[ 2.3941e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.6393e-04]],\n",
            "\n",
            "         [[-3.1840e-04]],\n",
            "\n",
            "         [[-8.1894e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1827e-03]],\n",
            "\n",
            "         [[ 2.3072e-04]],\n",
            "\n",
            "         [[ 2.4798e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3755e-03]],\n",
            "\n",
            "         [[ 2.2402e-03]],\n",
            "\n",
            "         [[ 6.3514e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3699e-04]],\n",
            "\n",
            "         [[-6.5581e-04]],\n",
            "\n",
            "         [[-5.6987e-04]]],\n",
            "\n",
            "\n",
            "        [[[-4.7156e-03]],\n",
            "\n",
            "         [[-2.9412e-03]],\n",
            "\n",
            "         [[-5.3433e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3525e-03]],\n",
            "\n",
            "         [[-2.6958e-03]],\n",
            "\n",
            "         [[ 4.2300e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.1472e-03]],\n",
            "\n",
            "         [[-3.7298e-03]],\n",
            "\n",
            "         [[-6.4545e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9340e-03]],\n",
            "\n",
            "         [[ 2.8756e-04]],\n",
            "\n",
            "         [[ 5.4045e-03]]]])}, 13: {'momentum_buffer': tensor([-6.5912e-04,  6.2508e-04, -3.4125e-05,  1.5606e-03, -1.1410e-03,\n",
            "         3.0728e-03,  1.3047e-03,  1.0272e-03,  2.3897e-03, -3.0629e-04,\n",
            "         4.5880e-04,  1.2338e-03,  6.7315e-04, -3.9597e-04, -1.3527e-03,\n",
            "        -2.0417e-04, -6.9784e-04,  9.0523e-04,  2.5508e-03,  1.7558e-03,\n",
            "         2.5352e-05,  7.0080e-04,  1.1894e-03, -1.1474e-03,  1.6891e-03,\n",
            "         1.1119e-03,  2.4769e-03,  1.2924e-04,  2.6934e-03,  3.8722e-04,\n",
            "         2.1334e-03, -5.5745e-04, -6.5465e-04, -7.0531e-04,  8.5454e-04,\n",
            "         1.0035e-03,  3.1481e-04,  1.7031e-03,  1.6486e-03,  2.7841e-03,\n",
            "        -1.8957e-04,  1.0989e-03,  1.1652e-03, -2.7774e-03,  1.6130e-03,\n",
            "         1.0153e-03,  1.5970e-03,  2.7037e-03, -8.2378e-05,  3.2786e-03,\n",
            "         1.5307e-03,  1.1811e-04,  2.3387e-04,  1.9555e-03, -1.6076e-03,\n",
            "         4.9728e-04,  1.0447e-03,  7.8578e-04,  8.3950e-04,  2.4206e-05,\n",
            "         2.5606e-03,  8.1297e-04, -4.4477e-04,  4.7355e-04,  7.3049e-04,\n",
            "         1.1227e-05,  1.4888e-03,  9.2462e-04, -2.8490e-04,  2.5475e-03,\n",
            "         2.3875e-03,  8.5624e-04,  5.8990e-04,  8.6827e-04,  4.4120e-03,\n",
            "         8.8235e-04,  4.0206e-03, -6.4972e-04,  1.0604e-03,  4.5125e-04,\n",
            "         1.4654e-03,  1.3282e-03,  6.2455e-04,  1.4579e-03, -1.5357e-03,\n",
            "         1.0440e-03, -1.1754e-03, -3.2474e-04, -5.8557e-04, -6.2014e-04,\n",
            "         1.0105e-04,  2.6729e-03, -4.8630e-04,  1.2288e-03,  5.0676e-05,\n",
            "        -1.8451e-03,  2.4000e-04,  3.1481e-03, -3.0746e-04, -6.7513e-04,\n",
            "        -2.8237e-04,  1.9702e-03,  1.0837e-03, -6.7911e-04,  1.2238e-03,\n",
            "         4.9034e-04,  2.5047e-03, -8.2742e-04, -5.2868e-04,  7.3236e-04,\n",
            "         1.5736e-04,  2.8114e-05,  9.6425e-04,  1.6933e-03, -9.7091e-05,\n",
            "        -1.2454e-03,  2.8304e-03,  8.8619e-04,  1.9547e-03,  1.7546e-03,\n",
            "        -2.0715e-03, -1.2754e-03,  1.8912e-03,  1.8515e-03,  1.6674e-03,\n",
            "        -7.4083e-05, -2.3143e-04,  9.4138e-04, -1.2974e-03, -1.7129e-04,\n",
            "         1.1878e-03,  2.2822e-04,  1.3578e-03,  5.6928e-04,  1.3368e-03,\n",
            "         1.2187e-03,  2.0744e-03,  1.3932e-03,  5.6195e-04, -1.2285e-03,\n",
            "         2.1388e-04,  2.2699e-03,  5.5391e-05,  2.2075e-03, -1.2953e-03,\n",
            "         3.6362e-03,  1.8645e-03,  1.7030e-04, -4.4478e-04,  2.7026e-03,\n",
            "         4.0858e-04,  1.1802e-03,  3.5046e-03,  1.5857e-03,  2.2684e-03,\n",
            "         2.8727e-04,  2.6541e-03, -7.7589e-06,  2.8258e-03,  1.6222e-03,\n",
            "         2.4201e-03,  2.7806e-03,  3.3850e-03,  1.2549e-03,  1.6635e-03,\n",
            "         3.7159e-03,  5.7365e-04,  1.6398e-03,  2.3021e-03,  1.2656e-03,\n",
            "         3.7972e-03,  5.1232e-04, -9.3361e-04,  3.0404e-05, -9.4705e-04,\n",
            "        -1.9026e-04,  3.0944e-03,  4.3223e-03,  1.4659e-03, -1.5083e-04,\n",
            "        -9.0856e-04,  3.5360e-04,  9.5864e-04,  5.7029e-03, -2.9635e-04,\n",
            "        -1.5070e-04,  6.7832e-04,  1.2283e-03,  1.4183e-03,  1.0877e-03,\n",
            "        -3.6521e-04, -7.4186e-04,  7.0617e-05,  4.3351e-04,  1.4264e-04,\n",
            "        -2.1020e-03,  2.7001e-03,  4.8889e-04, -2.8685e-04,  1.9325e-04,\n",
            "         1.6176e-03,  1.4319e-03,  3.5892e-03, -1.9295e-03, -1.2909e-03,\n",
            "         4.8052e-03,  9.5545e-04,  1.7204e-04,  1.3666e-03,  9.2691e-04,\n",
            "         1.5040e-03,  1.8972e-03,  3.0802e-03,  1.1784e-03,  8.1695e-04,\n",
            "         1.7772e-03,  9.0479e-04,  8.2908e-04,  8.9374e-04,  1.6571e-03,\n",
            "        -6.6481e-04,  1.5109e-03,  1.4096e-03,  8.2434e-04, -1.3473e-04,\n",
            "         2.5842e-03,  9.6585e-04,  2.4520e-03, -2.3403e-04,  2.1745e-03,\n",
            "         2.1198e-03,  2.9711e-03, -2.8576e-03, -3.7033e-05,  5.8960e-04,\n",
            "         3.7725e-03,  3.1151e-03,  2.1668e-03,  1.9491e-04,  2.0319e-03,\n",
            "         1.2850e-04,  2.1220e-03,  2.9453e-04,  9.1668e-04,  1.3217e-03,\n",
            "        -2.8062e-04,  2.1944e-03,  9.8565e-04,  1.9861e-03,  3.3367e-03,\n",
            "         3.1429e-03,  1.0517e-03,  5.5330e-04,  2.1300e-03,  5.9241e-04,\n",
            "         4.6395e-04])}, 14: {'momentum_buffer': tensor([-3.7475e-04,  1.6885e-03, -8.3146e-04,  7.0845e-04, -5.8121e-04,\n",
            "        -3.1720e-04,  1.9855e-04, -5.9236e-04,  1.0229e-03, -2.4482e-03,\n",
            "        -7.1709e-04,  5.7139e-04, -1.3692e-04,  4.6055e-04,  5.4208e-04,\n",
            "        -1.1681e-03, -2.0905e-03,  3.6712e-04,  3.3357e-04,  8.1063e-04,\n",
            "         1.2762e-03,  6.5498e-04,  2.4542e-04, -3.2050e-05, -6.2147e-04,\n",
            "        -7.7222e-04,  8.1548e-04,  3.0864e-04,  1.1143e-04,  1.5560e-03,\n",
            "         2.4580e-03, -4.1108e-04, -8.2181e-04, -9.5462e-04, -5.9324e-04,\n",
            "        -1.3767e-03, -1.2146e-04,  5.9579e-04,  1.2672e-04,  9.1559e-04,\n",
            "         1.2247e-03,  8.1259e-04,  8.7207e-04,  7.3062e-04,  2.7883e-04,\n",
            "         9.9734e-04,  3.0731e-04,  2.7281e-04, -1.9604e-04,  1.1385e-03,\n",
            "         9.6443e-04,  3.7593e-04, -1.1533e-04,  1.9997e-03, -3.2287e-03,\n",
            "        -1.7176e-04,  1.9101e-03, -8.4335e-04, -3.8580e-04, -1.0425e-04,\n",
            "         1.3163e-03, -1.1795e-03, -2.7894e-03, -4.0539e-04,  7.3503e-04,\n",
            "        -1.9641e-03,  7.0696e-04, -1.9456e-03,  2.2608e-04,  8.0020e-04,\n",
            "         1.6840e-03,  1.0883e-04,  4.8309e-04,  1.0737e-03, -1.3489e-05,\n",
            "         3.0636e-04, -3.0299e-04, -1.3888e-03, -1.9353e-03,  5.4947e-04,\n",
            "         1.2472e-03, -4.4017e-04, -6.0228e-04, -1.0082e-04, -1.9500e-03,\n",
            "        -4.2975e-04,  5.8309e-04,  6.7815e-04,  2.4764e-04, -8.0025e-04,\n",
            "        -2.8795e-03,  1.6696e-04,  1.7332e-03,  4.6238e-04,  1.6010e-05,\n",
            "        -2.0854e-03, -1.2231e-03,  1.0261e-03, -3.6004e-04, -2.9459e-03,\n",
            "         5.7328e-04, -3.4812e-04, -5.1326e-04, -1.4258e-03,  1.1365e-04,\n",
            "        -2.5989e-04,  6.9212e-04, -5.6715e-04,  3.4530e-05,  5.9818e-04,\n",
            "         2.4894e-04,  2.5414e-05,  6.0904e-04,  2.1059e-03, -3.1197e-04,\n",
            "        -6.1786e-04,  1.4101e-03,  1.8052e-03,  7.2523e-04, -7.0858e-04,\n",
            "        -1.8564e-03,  1.8990e-05,  1.4901e-03,  1.8819e-04, -9.3506e-05,\n",
            "        -5.3596e-04, -4.9089e-04, -1.5332e-03, -9.3251e-04, -4.8153e-04,\n",
            "         7.3791e-04,  4.7989e-04,  6.5724e-05, -1.6726e-03, -2.1638e-03,\n",
            "        -1.0185e-06, -4.3836e-04, -1.3208e-03, -1.6116e-03, -2.5516e-03,\n",
            "        -3.2195e-04,  8.2256e-04, -5.3342e-04,  2.6065e-03, -3.4669e-04,\n",
            "         2.6323e-03,  9.2250e-04, -3.2139e-04, -5.1957e-04, -1.1287e-03,\n",
            "         1.4835e-04, -2.9220e-04, -1.2069e-05, -9.4020e-04,  2.0243e-03,\n",
            "        -8.0176e-04,  1.1804e-03,  2.5023e-03, -3.0999e-05,  1.8626e-03,\n",
            "        -5.6390e-04,  3.7916e-04,  1.9681e-03,  5.6721e-05, -1.3015e-03,\n",
            "         8.3996e-04, -3.5766e-04,  1.8636e-03, -2.0128e-05, -6.6639e-04,\n",
            "         9.8061e-04, -1.0607e-03, -2.2694e-03, -3.3389e-04, -5.0021e-04,\n",
            "        -4.6383e-04, -6.2764e-04,  2.5668e-03, -1.5730e-03,  1.6433e-03,\n",
            "        -1.6337e-03,  6.9318e-04, -1.6987e-04,  2.0750e-03, -1.7452e-03,\n",
            "        -5.2195e-04,  3.4417e-04, -1.4366e-04,  1.4452e-04, -5.9085e-04,\n",
            "         4.3038e-04, -1.2243e-03, -1.4348e-03, -1.3944e-03, -1.9051e-03,\n",
            "        -1.2169e-03, -1.2425e-03,  3.1871e-04, -3.8858e-04, -1.4451e-03,\n",
            "        -9.7100e-04, -2.6204e-04,  1.1570e-03, -1.4939e-03, -2.7194e-03,\n",
            "         1.8165e-03,  3.6340e-04, -1.3074e-03,  1.7478e-03, -6.9934e-04,\n",
            "         9.3413e-04,  1.8146e-04, -3.3831e-04, -6.3774e-04, -8.0594e-04,\n",
            "         7.4289e-04,  8.3137e-04, -2.4924e-04, -1.1234e-03,  2.8591e-04,\n",
            "        -1.1706e-03, -5.8120e-04,  5.0966e-05, -4.5102e-04, -1.2382e-03,\n",
            "         4.5969e-04,  1.4968e-03,  7.3634e-04,  7.7273e-04,  1.5541e-03,\n",
            "        -1.2332e-03,  1.7419e-03, -3.4279e-03,  7.1745e-04, -3.2430e-04,\n",
            "        -1.0210e-03, -1.3624e-03, -1.5737e-03, -1.3545e-03,  1.1045e-03,\n",
            "        -1.1903e-03, -7.7808e-04, -5.6372e-05, -1.6280e-03, -1.1001e-03,\n",
            "         3.5778e-04,  1.0693e-03, -1.1293e-03,  3.2106e-04,  1.2028e-03,\n",
            "         1.6809e-03,  6.1383e-04, -9.7947e-04,  1.0570e-03, -8.9932e-04,\n",
            "        -1.7873e-03])}, 15: {'momentum_buffer': tensor([[[[-4.9379e-04]],\n",
            "\n",
            "         [[ 2.6657e-03]],\n",
            "\n",
            "         [[-4.7961e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3902e-03]],\n",
            "\n",
            "         [[-3.1358e-05]],\n",
            "\n",
            "         [[ 1.3743e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9948e-04]],\n",
            "\n",
            "         [[-1.3525e-03]],\n",
            "\n",
            "         [[ 1.0399e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.8041e-04]],\n",
            "\n",
            "         [[-4.1845e-04]],\n",
            "\n",
            "         [[-1.6324e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.3647e-04]],\n",
            "\n",
            "         [[ 1.2572e-03]],\n",
            "\n",
            "         [[ 2.7560e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5011e-03]],\n",
            "\n",
            "         [[-1.5910e-03]],\n",
            "\n",
            "         [[ 3.9598e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5749e-04]],\n",
            "\n",
            "         [[-5.4224e-04]],\n",
            "\n",
            "         [[-8.0085e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.0688e-05]],\n",
            "\n",
            "         [[ 1.1736e-03]],\n",
            "\n",
            "         [[ 1.1661e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4148e-04]],\n",
            "\n",
            "         [[-5.8596e-04]],\n",
            "\n",
            "         [[-2.1908e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8577e-04]],\n",
            "\n",
            "         [[ 7.1954e-05]],\n",
            "\n",
            "         [[-9.7762e-05]]],\n",
            "\n",
            "\n",
            "        [[[-7.3941e-05]],\n",
            "\n",
            "         [[-7.9066e-04]],\n",
            "\n",
            "         [[-1.2147e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8328e-04]],\n",
            "\n",
            "         [[-1.4745e-04]],\n",
            "\n",
            "         [[ 1.2176e-03]]]])}, 16: {'momentum_buffer': tensor([-8.0504e-04,  3.2449e-03,  4.8405e-04, -4.6372e-03,  1.7011e-03,\n",
            "        -2.3617e-03,  5.6547e-05,  4.0571e-04,  2.2891e-03,  6.1644e-05,\n",
            "        -1.8034e-03, -2.2125e-03, -1.0822e-03,  4.5000e-03,  3.8830e-03,\n",
            "         1.3101e-03,  5.2942e-04,  1.1739e-03, -3.3246e-04,  1.7234e-03,\n",
            "         3.6065e-03, -1.7823e-03,  3.6444e-04,  4.0360e-04,  7.6235e-04,\n",
            "         4.4423e-03,  3.1961e-03,  9.7127e-04,  1.8813e-03, -3.6442e-04,\n",
            "         2.2281e-03,  7.6327e-03, -3.3272e-03,  2.8233e-03, -2.1251e-04,\n",
            "        -9.6188e-05,  1.1396e-03,  6.2787e-04, -1.5630e-03, -2.8031e-03,\n",
            "        -7.5109e-04,  1.8390e-03,  2.7295e-03, -3.2675e-04, -1.4522e-03,\n",
            "         1.0922e-03,  1.3434e-03, -4.4937e-04,  6.8593e-03, -1.3780e-03,\n",
            "        -1.1628e-03,  2.1821e-03,  1.6696e-03,  1.4203e-03,  1.4443e-03,\n",
            "         2.4116e-03, -3.2251e-05,  5.7707e-04,  2.5989e-03,  5.3496e-03,\n",
            "         3.1376e-03,  4.9343e-03, -2.7574e-04,  1.1295e-03])}, 17: {'momentum_buffer': tensor([-0.0038,  0.0015, -0.0011, -0.0033,  0.0024, -0.0037,  0.0003, -0.0019,\n",
            "         0.0029,  0.0008,  0.0022, -0.0057,  0.0006,  0.0015,  0.0003, -0.0002,\n",
            "         0.0003,  0.0011, -0.0033,  0.0004,  0.0051,  0.0008,  0.0004,  0.0005,\n",
            "         0.0029,  0.0050, -0.0021,  0.0013, -0.0023, -0.0008,  0.0010,  0.0041,\n",
            "        -0.0022,  0.0023, -0.0025,  0.0015, -0.0029, -0.0022, -0.0011,  0.0010,\n",
            "        -0.0017, -0.0002,  0.0051, -0.0016, -0.0010,  0.0004,  0.0003, -0.0002,\n",
            "         0.0029, -0.0018, -0.0028,  0.0006,  0.0016, -0.0011,  0.0026,  0.0017,\n",
            "        -0.0031, -0.0013,  0.0015,  0.0037,  0.0004, -0.0005, -0.0027, -0.0008])}, 18: {'momentum_buffer': tensor([[[[-2.1108e-03, -1.7685e-03, -1.0137e-03],\n",
            "          [-1.4036e-03, -1.6128e-03, -1.4080e-03],\n",
            "          [-3.9016e-04, -9.0382e-04, -2.1485e-03]],\n",
            "\n",
            "         [[-4.5094e-04, -3.6091e-04, -1.5238e-04],\n",
            "          [-6.8700e-04, -7.5218e-04, -7.0595e-04],\n",
            "          [-2.2740e-04, -4.5526e-04, -8.4828e-06]],\n",
            "\n",
            "         [[-6.6082e-04, -9.1123e-04, -3.7322e-04],\n",
            "          [-5.1916e-04, -4.0438e-04, -2.2521e-04],\n",
            "          [-1.1016e-03, -4.2736e-04, -6.6060e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2933e-03,  3.4554e-04,  4.6993e-04],\n",
            "          [ 1.4726e-03,  9.7528e-04,  1.1669e-03],\n",
            "          [ 6.0527e-04,  1.0535e-03,  1.6684e-03]],\n",
            "\n",
            "         [[-3.0930e-04, -4.6287e-04, -7.0889e-04],\n",
            "          [-6.4118e-04, -5.4099e-04, -9.6318e-04],\n",
            "          [-7.9445e-04, -1.0182e-03, -1.2440e-03]],\n",
            "\n",
            "         [[-2.0071e-03, -1.4441e-03, -7.6939e-04],\n",
            "          [-1.4568e-03, -1.4241e-03, -9.5311e-04],\n",
            "          [-5.6063e-04, -1.0080e-03, -9.4850e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.7304e-04, -8.9414e-04, -5.7811e-04],\n",
            "          [-1.7972e-03, -1.4276e-03, -7.2279e-04],\n",
            "          [-2.1911e-03, -1.9200e-03, -1.4287e-03]],\n",
            "\n",
            "         [[ 3.1153e-04, -7.2291e-05, -1.8728e-04],\n",
            "          [ 3.9407e-04,  6.9672e-05,  1.4899e-05],\n",
            "          [ 1.3864e-04, -2.3104e-04,  1.8622e-04]],\n",
            "\n",
            "         [[ 2.9410e-03,  3.0560e-03,  4.1191e-03],\n",
            "          [ 2.9595e-03,  2.9463e-03,  3.6797e-03],\n",
            "          [ 2.8090e-03,  3.0210e-03,  3.7140e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9057e-03,  3.2279e-03,  3.5162e-03],\n",
            "          [ 4.3370e-03,  4.0207e-03,  4.1553e-03],\n",
            "          [ 4.3705e-03,  4.5498e-03,  4.8286e-03]],\n",
            "\n",
            "         [[ 2.6456e-04, -1.1225e-05, -5.6940e-05],\n",
            "          [-2.7606e-04,  1.9194e-05, -5.3298e-04],\n",
            "          [-6.0684e-04, -4.5992e-04, -4.2988e-04]],\n",
            "\n",
            "         [[ 2.2374e-03,  2.1593e-03,  2.1752e-03],\n",
            "          [ 2.0511e-03,  1.8680e-03,  2.6003e-03],\n",
            "          [ 2.3287e-03,  2.0087e-03,  2.9132e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.3426e-04, -1.6828e-04,  6.2184e-04],\n",
            "          [-4.6941e-05, -1.6995e-04,  1.6994e-04],\n",
            "          [ 4.1963e-04,  6.0504e-04,  4.9896e-04]],\n",
            "\n",
            "         [[-1.4935e-04, -5.0707e-05,  1.3133e-04],\n",
            "          [-9.5463e-06, -1.4072e-04,  8.3830e-05],\n",
            "          [-3.0491e-04, -2.0443e-04, -5.7548e-05]],\n",
            "\n",
            "         [[-4.2644e-04, -3.9771e-04, -8.2869e-04],\n",
            "          [-4.1569e-04, -4.9332e-04, -4.9496e-04],\n",
            "          [-5.7931e-04, -7.2333e-04, -2.8044e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0535e-03,  6.9319e-04,  1.0046e-03],\n",
            "          [ 1.0761e-03,  6.7868e-04,  7.1183e-04],\n",
            "          [ 5.3450e-04,  1.2165e-04,  4.3927e-04]],\n",
            "\n",
            "         [[-4.9643e-04, -6.1538e-04, -1.0955e-03],\n",
            "          [-7.0987e-04, -9.4619e-04, -1.0284e-03],\n",
            "          [-1.0829e-03, -8.6680e-04, -6.2489e-04]],\n",
            "\n",
            "         [[ 5.4927e-04,  5.1925e-05,  4.7532e-04],\n",
            "          [ 4.3003e-04,  1.7894e-04,  5.4632e-04],\n",
            "          [ 3.5835e-04,  3.0566e-04,  4.2885e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3244e-04,  6.2866e-04,  3.1943e-05],\n",
            "          [ 1.1158e-03,  1.1781e-04, -4.6560e-04],\n",
            "          [ 1.5873e-03,  2.9721e-04, -1.0150e-04]],\n",
            "\n",
            "         [[ 1.4688e-04, -6.8832e-04, -1.1931e-03],\n",
            "          [ 5.9542e-04, -1.3636e-04, -4.5368e-04],\n",
            "          [-8.2238e-05, -1.6662e-04, -4.1733e-05]],\n",
            "\n",
            "         [[-7.1064e-04, -2.1635e-04,  1.7816e-04],\n",
            "          [-8.5353e-04, -7.0445e-04,  8.3445e-05],\n",
            "          [-7.3555e-04, -7.0420e-04, -2.8730e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9336e-04, -6.9037e-04, -8.0883e-04],\n",
            "          [-2.5866e-04,  8.1814e-04,  1.1629e-03],\n",
            "          [ 4.8954e-04,  2.1064e-03,  2.2574e-03]],\n",
            "\n",
            "         [[-4.6067e-04, -1.1960e-03, -1.3412e-03],\n",
            "          [ 1.0722e-05, -1.4475e-04, -1.0590e-03],\n",
            "          [-2.6350e-04, -7.5991e-04, -1.1349e-03]],\n",
            "\n",
            "         [[-4.8034e-04, -7.0598e-04,  5.6461e-04],\n",
            "          [ 8.4038e-05,  7.9071e-06,  2.4900e-04],\n",
            "          [-1.6256e-04,  2.4657e-04,  6.8939e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.4413e-04, -4.1857e-04,  4.8188e-04],\n",
            "          [-1.2242e-03, -3.6574e-04,  8.0420e-04],\n",
            "          [-1.3774e-03, -2.9265e-05,  5.1360e-04]],\n",
            "\n",
            "         [[-6.6343e-04, -4.9110e-04,  2.8741e-04],\n",
            "          [-7.6171e-04, -5.0451e-04,  3.9258e-04],\n",
            "          [-8.9960e-04, -3.3457e-04,  6.4666e-04]],\n",
            "\n",
            "         [[ 9.7631e-04,  8.0337e-04,  6.3028e-04],\n",
            "          [ 1.0158e-03,  8.5508e-04,  6.0071e-04],\n",
            "          [ 7.6661e-04,  6.8615e-04,  9.0966e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5211e-04,  5.1051e-04,  6.9695e-04],\n",
            "          [-5.6902e-04,  1.0759e-04,  1.0487e-04],\n",
            "          [-7.6308e-04, -4.1183e-04, -1.5838e-03]],\n",
            "\n",
            "         [[-1.3595e-04, -3.6453e-04, -4.1305e-04],\n",
            "          [-2.0783e-04, -8.8274e-05,  1.3592e-05],\n",
            "          [-2.5650e-04, -2.7455e-04, -3.0016e-04]],\n",
            "\n",
            "         [[ 6.7789e-04,  6.4641e-04,  1.6588e-03],\n",
            "          [-1.5826e-05,  4.1754e-04,  8.0722e-04],\n",
            "          [-2.7649e-05,  5.1534e-05,  3.5772e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.0951e-03, -6.0508e-05,  9.1918e-04],\n",
            "          [-2.4274e-03, -5.9754e-04,  9.6129e-04],\n",
            "          [-7.7770e-04, -8.3259e-04, -7.4232e-04]],\n",
            "\n",
            "         [[ 9.0318e-04,  8.9139e-04,  1.0060e-03],\n",
            "          [-1.5300e-05,  3.9595e-04,  9.8095e-04],\n",
            "          [ 3.7231e-04,  2.8145e-04,  3.9569e-04]],\n",
            "\n",
            "         [[ 1.3129e-03,  1.3133e-03,  7.0346e-04],\n",
            "          [ 1.1638e-03,  1.2490e-03,  4.0964e-04],\n",
            "          [ 9.4608e-04,  8.3279e-04,  4.8111e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.1196e-04,  1.4825e-03,  2.4319e-03],\n",
            "          [ 2.0398e-03,  1.8168e-03,  2.7283e-03],\n",
            "          [ 2.6099e-03,  2.7962e-03,  3.0809e-03]],\n",
            "\n",
            "         [[ 4.7450e-04, -4.5672e-04, -4.4683e-04],\n",
            "          [ 3.3836e-04, -1.8164e-04,  6.0709e-05],\n",
            "          [ 1.1136e-04, -1.0203e-04, -3.4906e-04]],\n",
            "\n",
            "         [[ 6.2993e-04,  1.5303e-03,  1.3525e-03],\n",
            "          [ 7.9685e-04,  7.2012e-04,  1.1642e-03],\n",
            "          [ 1.1107e-03,  1.2304e-03,  1.3560e-03]]]])}, 19: {'momentum_buffer': tensor([ 9.8265e-04,  3.7727e-03,  1.7055e-03, -4.1794e-03,  1.2566e-03,\n",
            "         3.2530e-03, -3.4731e-03, -4.9877e-04,  5.8598e-03, -2.9541e-03,\n",
            "         9.3493e-04, -1.8621e-04,  4.1139e-03,  1.2597e-03, -1.9874e-03,\n",
            "         1.1243e-03, -2.4611e-03,  3.6834e-03, -2.2210e-03,  2.1515e-03,\n",
            "        -2.5401e-03,  5.4185e-04,  2.7907e-03, -1.9377e-03,  1.8196e-04,\n",
            "         2.9614e-03, -2.9248e-04,  3.6766e-03,  3.6247e-03, -2.7671e-03,\n",
            "         9.8911e-04, -3.0787e-04,  7.1946e-04,  2.9650e-03, -8.6970e-04,\n",
            "         6.0423e-04,  2.9694e-03,  5.3797e-03,  3.5889e-03, -4.4105e-05,\n",
            "         1.3851e-03,  2.3440e-03,  1.8859e-03,  1.1650e-03,  4.0926e-03,\n",
            "         1.9969e-04,  3.6040e-03,  2.5148e-03,  6.5475e-04,  3.1613e-03,\n",
            "        -1.9383e-03, -1.6903e-04,  1.9265e-03,  3.6974e-04,  1.9007e-03,\n",
            "        -2.4804e-03,  3.1425e-03,  1.2885e-03, -4.3903e-04, -2.1258e-03,\n",
            "         3.6215e-03,  3.0388e-03, -1.9691e-04,  1.1542e-04])}, 20: {'momentum_buffer': tensor([-3.4947e-03, -1.0252e-03, -6.8086e-05,  2.1790e-04,  1.0927e-04,\n",
            "         2.8873e-03, -5.4589e-03, -3.4395e-04,  1.8156e-03, -1.1664e-03,\n",
            "         4.4587e-05,  1.6327e-03,  3.6114e-03, -7.4673e-04, -3.9345e-03,\n",
            "         2.0377e-03, -2.4810e-03,  2.1644e-03,  3.5420e-04, -3.0532e-03,\n",
            "        -2.1689e-03, -3.9181e-04, -8.2665e-04, -1.0882e-03, -2.1602e-03,\n",
            "         2.8583e-03, -8.9135e-04,  3.0317e-03,  1.9988e-03,  4.8278e-04,\n",
            "         3.4490e-03, -1.0467e-03,  2.1296e-03,  1.7348e-03,  3.3049e-04,\n",
            "        -1.3669e-04, -7.0787e-04,  1.4812e-03,  2.9925e-03, -5.8807e-04,\n",
            "        -9.0683e-04, -1.5444e-03,  1.5219e-03, -4.2718e-04,  2.9704e-03,\n",
            "        -6.0823e-04,  3.6606e-03,  4.1947e-03, -7.0777e-04,  9.9033e-04,\n",
            "        -1.5429e-03,  6.0107e-04,  1.7492e-03, -7.4934e-04,  1.1144e-03,\n",
            "        -4.3767e-04,  2.0412e-03,  2.7455e-03,  1.3479e-03, -3.3079e-03,\n",
            "         5.0424e-03,  2.7153e-03, -1.1505e-03, -9.7645e-04])}, 21: {'momentum_buffer': tensor([[[[-6.3475e-04]],\n",
            "\n",
            "         [[-1.1772e-04]],\n",
            "\n",
            "         [[-1.3793e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7369e-03]],\n",
            "\n",
            "         [[ 1.0149e-04]],\n",
            "\n",
            "         [[ 5.5210e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.0927e-05]],\n",
            "\n",
            "         [[ 3.0281e-03]],\n",
            "\n",
            "         [[-1.1772e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0296e-03]],\n",
            "\n",
            "         [[ 1.7202e-03]],\n",
            "\n",
            "         [[ 1.2100e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.6125e-04]],\n",
            "\n",
            "         [[-6.0611e-04]],\n",
            "\n",
            "         [[ 6.8733e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5340e-03]],\n",
            "\n",
            "         [[-1.4659e-05]],\n",
            "\n",
            "         [[ 4.7254e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.4829e-03]],\n",
            "\n",
            "         [[ 3.4923e-04]],\n",
            "\n",
            "         [[-1.3192e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1040e-03]],\n",
            "\n",
            "         [[ 2.2529e-03]],\n",
            "\n",
            "         [[ 1.7975e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5376e-03]],\n",
            "\n",
            "         [[-2.7739e-03]],\n",
            "\n",
            "         [[ 1.1159e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5275e-03]],\n",
            "\n",
            "         [[-1.2438e-04]],\n",
            "\n",
            "         [[ 1.2617e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7024e-03]],\n",
            "\n",
            "         [[ 9.1033e-04]],\n",
            "\n",
            "         [[ 5.2276e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1176e-03]],\n",
            "\n",
            "         [[-6.5497e-04]],\n",
            "\n",
            "         [[-1.9857e-03]]]])}, 22: {'momentum_buffer': tensor([ 1.4044e-03,  9.5855e-04,  1.2951e-03, -1.7131e-03,  3.5285e-04,\n",
            "         1.7319e-03,  7.6381e-04,  1.2384e-03, -1.8527e-04,  7.6786e-04,\n",
            "        -5.4915e-04,  2.3961e-04,  3.7285e-04,  1.1024e-03,  2.6149e-03,\n",
            "         5.3429e-04,  1.6951e-03,  2.5190e-03,  5.0866e-04,  9.4402e-04,\n",
            "         1.0405e-03,  1.1371e-03,  1.3652e-03,  1.5233e-03,  1.5850e-03,\n",
            "         5.7443e-04, -2.0247e-03,  1.0150e-03,  6.9243e-04,  1.7160e-03,\n",
            "        -3.3785e-04, -1.6816e-03, -8.0785e-06, -1.0584e-04, -2.4538e-05,\n",
            "         1.3026e-03,  1.6716e-03,  5.7930e-04,  8.1313e-04, -8.3800e-04,\n",
            "         1.4733e-03,  7.6892e-04,  2.9340e-04,  2.0398e-04,  1.4692e-03,\n",
            "         2.7184e-04,  8.4445e-04,  1.2835e-03,  1.6206e-03,  1.9160e-03,\n",
            "         1.3264e-03, -3.5452e-04,  2.5429e-03,  2.4003e-03,  2.6444e-04,\n",
            "         6.8221e-05,  2.3417e-03,  1.5693e-03,  1.2151e-03, -2.3134e-04,\n",
            "         1.4862e-03,  2.4588e-04,  6.6651e-04,  2.5597e-03,  1.0347e-03,\n",
            "         2.5364e-03,  1.0378e-03, -5.3026e-04,  3.2355e-03,  1.5171e-03,\n",
            "        -3.3610e-05,  1.8634e-03,  2.3351e-03, -5.1072e-04,  2.5799e-03,\n",
            "         1.2115e-03,  1.5848e-03,  7.9927e-04,  1.7091e-03,  1.3039e-03,\n",
            "         9.4848e-04,  1.9422e-03,  1.4752e-03,  1.9237e-03,  1.4629e-03,\n",
            "         9.9465e-05,  6.7887e-04,  2.4257e-04,  3.5289e-04,  1.6286e-03,\n",
            "        -2.3068e-04,  1.3289e-03,  1.9216e-03, -8.1035e-04,  8.5710e-04,\n",
            "         1.3532e-04, -1.7687e-04,  2.4770e-03,  3.6879e-03,  2.0133e-04,\n",
            "         1.8033e-03,  1.8920e-03,  1.1812e-03,  2.2557e-03,  1.2022e-03,\n",
            "         1.2276e-03,  1.8102e-03,  2.0159e-03, -6.8714e-04, -3.8417e-04,\n",
            "         1.6137e-03,  1.7197e-03,  3.4919e-03, -2.2356e-03,  3.4976e-03,\n",
            "         1.5738e-03, -1.8784e-03, -8.3295e-05,  5.5768e-04,  1.8814e-03,\n",
            "        -8.0494e-04,  1.0609e-03, -3.1019e-04,  1.6064e-03,  2.3449e-03,\n",
            "         1.4259e-03,  1.8762e-03,  9.7128e-04,  4.8934e-04,  1.0502e-03,\n",
            "         3.5537e-03,  1.6100e-03,  1.8025e-05,  1.5408e-03, -3.4344e-05,\n",
            "        -2.0892e-03,  1.4478e-03,  1.8785e-03,  1.0335e-03,  8.3288e-04,\n",
            "         2.3744e-03,  1.6492e-04,  1.0845e-03,  2.3612e-03,  1.9144e-03,\n",
            "         2.1520e-03,  5.1970e-04,  1.4506e-03,  3.9107e-04,  3.4623e-03,\n",
            "         1.1927e-03, -5.3407e-04,  9.7330e-04, -2.6552e-04,  1.7533e-03,\n",
            "         2.3042e-04,  2.7208e-03,  2.7999e-03,  7.5244e-04,  5.2851e-05,\n",
            "         2.6171e-03,  1.6920e-03,  9.7589e-04,  2.2212e-03, -9.0365e-04,\n",
            "         2.1140e-03,  9.3014e-04,  1.8542e-04,  7.7293e-04, -1.1727e-03,\n",
            "         1.8002e-04,  8.2665e-04,  9.8640e-04, -1.7880e-03,  2.3435e-03,\n",
            "         8.2348e-04,  9.1869e-04,  1.5279e-03, -5.0205e-04, -1.3819e-03,\n",
            "         1.2430e-03,  1.0955e-03,  2.8261e-03,  1.6851e-03,  2.9180e-03,\n",
            "         2.6934e-03,  7.5902e-04,  2.4923e-03,  1.0742e-03,  7.6333e-04,\n",
            "        -1.1841e-03,  1.2386e-03,  5.2345e-04, -1.5741e-03,  4.6852e-04,\n",
            "        -1.3626e-04, -5.8406e-04,  5.2395e-04,  4.9374e-04, -4.3304e-05,\n",
            "         7.4086e-05,  3.5750e-03,  2.3131e-03, -2.5486e-05,  2.3724e-03,\n",
            "         1.4798e-03,  9.5483e-04, -1.9195e-03,  1.7045e-03,  1.3248e-03,\n",
            "         4.1725e-05,  8.6963e-04,  1.3213e-03,  6.6990e-04, -1.1992e-03,\n",
            "         2.1716e-03,  1.6816e-03,  3.2304e-04,  2.4086e-03,  1.4184e-03,\n",
            "         8.7482e-04,  1.2836e-03, -8.7634e-04,  7.9923e-04,  1.6826e-03,\n",
            "         3.1148e-03,  2.6631e-03, -2.1841e-04,  1.2296e-03, -1.1109e-03,\n",
            "         2.9148e-03,  1.0534e-03,  8.9855e-04,  1.0836e-03,  1.8271e-04,\n",
            "        -1.2082e-03,  2.7255e-03,  1.8550e-03,  2.0086e-03,  1.7783e-03,\n",
            "        -9.3698e-05,  4.6215e-04,  4.6409e-03,  1.2183e-04,  1.3803e-03,\n",
            "         1.3015e-03,  9.4802e-04, -2.1990e-04,  2.1165e-03, -6.6327e-04,\n",
            "         2.7872e-03, -1.3351e-03,  1.2821e-03,  4.9274e-04,  1.2602e-03,\n",
            "         2.2582e-03])}, 23: {'momentum_buffer': tensor([-3.1452e-04,  1.7515e-03,  7.9217e-05,  4.4756e-04, -5.9730e-04,\n",
            "        -6.6807e-04, -4.0671e-05, -9.9853e-05,  7.3468e-04, -1.7617e-03,\n",
            "        -4.5703e-04,  1.8221e-04,  6.4416e-05,  1.0153e-03, -2.8686e-04,\n",
            "        -6.5769e-04, -1.6555e-03,  2.8542e-03,  4.3629e-05,  1.4239e-03,\n",
            "         2.3956e-04, -3.1187e-04, -2.2808e-05,  3.6979e-04, -4.2894e-04,\n",
            "        -1.6681e-04, -9.0934e-04,  7.9703e-04, -9.8713e-04, -9.8316e-05,\n",
            "         5.7645e-04, -1.2695e-04,  2.2223e-05,  7.5380e-04, -5.1260e-04,\n",
            "        -3.7455e-04,  3.0802e-04, -1.3671e-03, -1.9262e-04, -2.7989e-04,\n",
            "        -1.5229e-03,  4.2022e-04, -4.3093e-04,  1.7430e-03,  2.4498e-04,\n",
            "        -2.5324e-04,  8.8468e-04, -2.8266e-04, -4.2080e-04,  3.1266e-04,\n",
            "         1.1617e-03,  1.1126e-04, -9.1785e-05,  7.0229e-04, -2.2410e-03,\n",
            "         1.1089e-04,  1.4315e-03, -4.4676e-04, -3.1482e-04,  1.0609e-04,\n",
            "         2.3146e-04, -8.5412e-05, -1.3836e-03, -2.9904e-04, -1.0338e-04,\n",
            "        -6.7106e-04,  4.5896e-04, -1.9313e-03,  7.0829e-04, -3.4344e-04,\n",
            "        -6.9720e-06,  4.1128e-04,  1.2404e-03,  9.2355e-04,  5.1837e-04,\n",
            "        -7.8010e-04,  4.3621e-04, -4.6508e-04, -1.1637e-03,  1.4663e-03,\n",
            "         1.0399e-03, -1.2023e-03,  6.1684e-04,  1.1960e-03, -1.3019e-03,\n",
            "        -2.5333e-04, -8.5435e-04, -1.0722e-03,  6.9928e-04, -8.3268e-04,\n",
            "        -1.8346e-03,  7.8413e-04,  1.5906e-03, -3.5025e-04, -1.0193e-03,\n",
            "        -2.9032e-04, -4.7574e-04, -3.3825e-04,  1.4296e-03, -2.4485e-03,\n",
            "        -1.7134e-04, -7.6996e-05,  8.0887e-04,  3.8441e-04, -1.5849e-04,\n",
            "        -6.6579e-04,  7.0762e-04,  1.4980e-03, -5.8323e-04,  2.4655e-04,\n",
            "         1.1272e-03,  1.1601e-03,  1.2621e-04, -7.2943e-04,  7.3052e-04,\n",
            "        -5.2811e-05,  4.0888e-04,  1.2041e-03, -5.1573e-04,  6.8373e-04,\n",
            "        -7.2602e-04, -1.0915e-03, -1.9955e-04,  1.1515e-03,  4.4540e-04,\n",
            "        -2.9105e-04,  4.9749e-04, -8.3972e-04,  2.3990e-04, -7.6833e-04,\n",
            "        -1.9533e-04, -1.2125e-03,  6.9012e-04, -4.7450e-04, -1.8397e-03,\n",
            "        -7.0382e-04, -1.4073e-04, -2.3159e-04, -5.6751e-04,  1.7005e-07,\n",
            "         3.5803e-04,  6.8259e-04,  4.1945e-04,  7.7402e-04, -2.9735e-04,\n",
            "         2.0344e-03, -6.4126e-04, -4.3307e-04,  6.5526e-04, -1.7060e-03,\n",
            "         5.8659e-04,  1.5852e-04, -4.4214e-04, -3.5789e-04,  9.9687e-04,\n",
            "        -4.4085e-04,  9.3419e-04,  2.1761e-03, -3.6692e-04, -2.1752e-04,\n",
            "        -2.8434e-04,  7.9069e-04,  5.9488e-04,  1.4164e-03, -1.8684e-03,\n",
            "         4.9762e-04,  4.9261e-04,  7.6697e-04, -1.0763e-03,  7.7131e-05,\n",
            "        -8.8173e-04, -7.9306e-04,  1.0447e-04, -1.0985e-03,  3.0787e-04,\n",
            "         7.1265e-04,  2.9562e-04,  6.8899e-04, -1.0900e-03, -1.1978e-03,\n",
            "        -3.3418e-05,  1.1084e-03,  1.4177e-03,  3.1385e-04, -5.2063e-04,\n",
            "         2.6803e-04, -8.3259e-04,  6.4019e-04,  7.9085e-04,  1.6087e-03,\n",
            "        -7.2304e-04, -1.4913e-03,  9.5740e-04, -4.3088e-04, -1.1895e-03,\n",
            "        -1.3211e-03, -1.1721e-03,  2.8912e-04, -1.0679e-03, -9.3582e-04,\n",
            "        -1.3423e-04,  6.4421e-04,  7.7191e-04, -1.4774e-03, -6.9105e-04,\n",
            "         1.1917e-04,  8.4743e-04, -1.3000e-03,  1.6667e-03, -4.7111e-04,\n",
            "         2.5918e-05,  1.4120e-03,  2.5433e-04,  1.0056e-03, -2.0277e-06,\n",
            "        -1.1073e-05,  7.9236e-04,  1.5416e-03, -8.6387e-04,  3.8313e-04,\n",
            "        -1.0529e-03,  1.1395e-03, -1.5274e-03, -6.1456e-04, -3.7767e-04,\n",
            "         4.6079e-05,  8.5118e-04,  3.7858e-04,  1.0164e-03,  1.4694e-04,\n",
            "         1.4878e-04,  7.2826e-04, -1.4603e-03, -3.4234e-04, -3.6955e-04,\n",
            "         4.1089e-04, -8.5184e-04, -4.4026e-04, -1.1212e-03,  6.6495e-04,\n",
            "        -1.4624e-03, -1.1632e-03,  8.5098e-04, -2.1004e-03,  5.5417e-04,\n",
            "         1.2224e-03,  6.6342e-04, -1.5598e-03,  4.9571e-04,  1.0902e-03,\n",
            "         2.2274e-04, -5.1254e-04, -9.3500e-04,  4.5116e-05,  7.4496e-04,\n",
            "        -1.8203e-04])}, 24: {'momentum_buffer': tensor([[[[-9.1814e-04]],\n",
            "\n",
            "         [[ 4.0242e-04]],\n",
            "\n",
            "         [[ 1.6575e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.3064e-04]],\n",
            "\n",
            "         [[-4.0531e-04]],\n",
            "\n",
            "         [[-4.2175e-04]]],\n",
            "\n",
            "\n",
            "        [[[-8.2798e-05]],\n",
            "\n",
            "         [[-4.3386e-04]],\n",
            "\n",
            "         [[ 3.2186e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9050e-05]],\n",
            "\n",
            "         [[ 1.3620e-04]],\n",
            "\n",
            "         [[ 1.8759e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.5518e-05]],\n",
            "\n",
            "         [[-1.5692e-04]],\n",
            "\n",
            "         [[ 4.3674e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.1786e-04]],\n",
            "\n",
            "         [[ 2.5377e-04]],\n",
            "\n",
            "         [[ 3.7521e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.6430e-04]],\n",
            "\n",
            "         [[ 7.3353e-04]],\n",
            "\n",
            "         [[-5.2624e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.3600e-04]],\n",
            "\n",
            "         [[-3.4618e-04]],\n",
            "\n",
            "         [[ 5.0099e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.1964e-04]],\n",
            "\n",
            "         [[-5.7409e-06]],\n",
            "\n",
            "         [[-5.3379e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.6287e-04]],\n",
            "\n",
            "         [[-5.1959e-04]],\n",
            "\n",
            "         [[-2.4633e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.1595e-04]],\n",
            "\n",
            "         [[ 1.6235e-03]],\n",
            "\n",
            "         [[-1.5489e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7565e-04]],\n",
            "\n",
            "         [[ 1.5204e-04]],\n",
            "\n",
            "         [[ 8.1729e-04]]]])}, 25: {'momentum_buffer': tensor([ 1.3998e-03,  2.5223e-04,  9.2794e-04,  9.7489e-04,  4.3744e-03,\n",
            "        -2.8739e-04,  2.9850e-04,  3.5614e-03,  4.6155e-03,  1.6735e-03,\n",
            "         3.2613e-03,  1.5693e-03, -7.4180e-04,  2.4535e-03,  2.4704e-04,\n",
            "        -3.5782e-03,  2.2194e-03,  6.6183e-04,  2.7327e-03,  4.9797e-03,\n",
            "         1.8931e-03, -1.5027e-03, -8.9507e-04,  5.2472e-03, -6.4305e-04,\n",
            "        -1.1600e-04, -2.3706e-03, -3.0241e-03, -8.7603e-04,  4.6609e-03,\n",
            "         3.6731e-03,  2.2100e-03,  8.3373e-04, -5.3081e-04, -2.6525e-03,\n",
            "         2.5886e-04,  4.9877e-04, -9.7570e-04,  4.1418e-03,  2.9434e-03,\n",
            "         1.0163e-03, -1.5174e-03,  2.7185e-03,  3.6563e-03, -3.2394e-04,\n",
            "        -5.3644e-04, -6.9833e-04,  1.7089e-03,  1.5357e-03,  2.5202e-03,\n",
            "         4.0402e-04,  5.2934e-04, -9.3220e-07, -1.7026e-03, -1.2780e-03,\n",
            "         2.2106e-03, -1.0623e-03, -5.7166e-04, -8.7608e-04,  2.9197e-03,\n",
            "         1.7545e-03,  2.9498e-03,  1.1132e-03,  2.9366e-03])}, 26: {'momentum_buffer': tensor([ 2.0516e-03, -3.0689e-04, -2.2678e-03,  7.6946e-04,  3.8522e-03,\n",
            "        -1.4636e-03,  2.2253e-03,  2.6094e-04,  2.5595e-03,  1.0341e-03,\n",
            "        -1.2898e-03, -7.0032e-05, -1.8230e-03,  1.7312e-03,  5.4269e-04,\n",
            "        -1.2786e-03,  9.8171e-04,  1.4525e-03,  1.5927e-03, -4.2719e-04,\n",
            "        -1.1697e-03,  2.8260e-03, -3.6002e-04,  2.9346e-03, -2.9277e-03,\n",
            "        -1.0083e-03, -1.9702e-03, -1.5782e-03, -2.8585e-03,  2.9207e-03,\n",
            "         1.9609e-03,  3.5141e-03,  1.0762e-03,  1.6471e-03, -2.7109e-03,\n",
            "        -2.6402e-03,  2.9154e-03,  6.2676e-04,  1.4519e-03,  7.0896e-04,\n",
            "         2.1116e-04, -4.3220e-04,  1.2901e-04,  1.3170e-03, -2.5135e-03,\n",
            "        -1.2459e-03, -1.0088e-03, -1.1291e-03,  1.5679e-03,  1.3285e-04,\n",
            "         1.6574e-03,  2.7949e-04, -1.4812e-03, -1.8933e-03, -6.6679e-04,\n",
            "         3.4834e-03, -8.9834e-04, -1.9994e-03,  5.5508e-06,  2.4598e-03,\n",
            "         9.8422e-04,  2.5375e-03,  1.2655e-03, -1.3821e-03])}, 27: {'momentum_buffer': tensor([[[[ 1.3014e-03,  6.8565e-04,  8.6234e-04],\n",
            "          [ 6.1033e-04,  7.9507e-04,  1.0989e-03],\n",
            "          [ 1.5200e-04,  7.8271e-04,  8.3449e-04]],\n",
            "\n",
            "         [[ 5.3095e-04,  1.0329e-03,  4.6492e-04],\n",
            "          [ 1.9092e-04,  3.5444e-04,  1.1412e-04],\n",
            "          [ 3.4752e-04,  1.0704e-03,  1.0418e-03]],\n",
            "\n",
            "         [[ 1.2869e-04,  6.2299e-04,  1.7764e-03],\n",
            "          [-3.6811e-04, -1.2421e-04,  1.6686e-03],\n",
            "          [-2.3034e-03, -9.9003e-04,  6.1973e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8190e-03,  2.8643e-03,  3.1614e-03],\n",
            "          [ 2.7252e-03,  3.5691e-03,  3.6726e-03],\n",
            "          [ 2.8537e-03,  3.5226e-03,  4.0084e-03]],\n",
            "\n",
            "         [[ 2.2463e-03,  2.6295e-03,  2.4248e-03],\n",
            "          [ 2.3627e-03,  2.5980e-03,  2.0746e-03],\n",
            "          [ 2.8840e-03,  2.5778e-03,  2.0879e-03]],\n",
            "\n",
            "         [[ 1.6242e-03,  2.0892e-03,  3.0790e-03],\n",
            "          [ 1.1171e-03,  2.4656e-03,  2.9274e-03],\n",
            "          [ 1.7193e-04,  5.5428e-04,  1.7408e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1433e-03,  1.6274e-03,  1.3427e-03],\n",
            "          [ 1.3181e-03,  1.6205e-03,  9.6530e-04],\n",
            "          [ 9.6401e-04,  7.8540e-04,  2.0165e-04]],\n",
            "\n",
            "         [[ 1.8427e-03,  2.7532e-03,  2.2924e-03],\n",
            "          [ 1.2358e-03,  1.3946e-03,  1.0506e-03],\n",
            "          [ 1.7833e-03,  1.1076e-03, -7.3282e-04]],\n",
            "\n",
            "         [[ 6.9230e-04,  2.3528e-04, -3.7385e-04],\n",
            "          [ 3.7122e-04, -3.4601e-04, -1.9486e-03],\n",
            "          [ 2.1062e-03,  6.2839e-04, -1.5977e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5209e-03, -1.7271e-03, -1.8975e-03],\n",
            "          [-1.5070e-03, -1.4596e-03, -1.2116e-03],\n",
            "          [-1.0943e-03, -1.2279e-03, -1.5450e-03]],\n",
            "\n",
            "         [[-2.9241e-03, -3.8496e-03, -2.8513e-03],\n",
            "          [-1.7811e-03, -1.8807e-03, -1.7969e-03],\n",
            "          [-8.5524e-04, -5.8777e-04, -2.9755e-04]],\n",
            "\n",
            "         [[-3.0511e-04,  4.0686e-04,  1.3992e-04],\n",
            "          [ 4.1845e-04,  2.3825e-04,  1.8111e-04],\n",
            "          [ 4.2757e-04,  3.1961e-04, -1.3341e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 8.4355e-04,  3.2981e-04,  2.3196e-04],\n",
            "          [ 5.5299e-04,  3.4176e-04,  2.9034e-05],\n",
            "          [ 2.2620e-04,  1.7159e-04,  3.5587e-05]],\n",
            "\n",
            "         [[-6.8894e-04,  1.0047e-04,  8.9955e-05],\n",
            "          [-8.0616e-04, -4.5174e-04, -1.4822e-04],\n",
            "          [-1.1652e-03, -8.7822e-04, -6.7344e-04]],\n",
            "\n",
            "         [[ 1.2063e-03,  8.5599e-04,  8.0112e-05],\n",
            "          [ 5.5513e-04,  8.9675e-04,  8.6551e-05],\n",
            "          [ 6.9806e-04,  8.6339e-04,  1.9562e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7485e-03, -1.5673e-03, -1.3666e-03],\n",
            "          [-1.8917e-03, -2.0784e-03, -1.8755e-03],\n",
            "          [-1.8516e-03, -1.8219e-03, -1.6651e-03]],\n",
            "\n",
            "         [[-2.3030e-04, -4.9304e-04, -9.2890e-04],\n",
            "          [-5.0789e-04, -5.8688e-04, -1.3027e-03],\n",
            "          [-8.7982e-04, -6.8479e-04, -1.1828e-03]],\n",
            "\n",
            "         [[ 1.9303e-03,  9.9441e-04,  7.6278e-04],\n",
            "          [ 2.0576e-03,  1.2897e-03,  1.0311e-03],\n",
            "          [ 1.9274e-03,  1.5523e-03,  1.1783e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.6041e-04,  2.6895e-04,  2.6699e-04],\n",
            "          [-5.0178e-04,  1.0454e-04,  2.3157e-04],\n",
            "          [ 3.7430e-04,  7.2138e-04,  8.5399e-04]],\n",
            "\n",
            "         [[-1.4817e-03, -1.7723e-03, -1.8420e-03],\n",
            "          [ 3.5924e-04, -2.2477e-04, -1.5652e-03],\n",
            "          [-3.4682e-04, -1.6594e-04, -1.3725e-03]],\n",
            "\n",
            "         [[ 1.1087e-03,  2.2658e-03,  4.0988e-04],\n",
            "          [ 9.5493e-04,  4.5826e-04, -2.2133e-04],\n",
            "          [ 5.9524e-04,  5.8408e-04, -2.3466e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0802e-03, -4.1040e-05, -5.5898e-04],\n",
            "          [-2.0767e-03, -8.1965e-04, -1.2001e-03],\n",
            "          [-1.9736e-03, -1.3340e-03, -2.4027e-03]],\n",
            "\n",
            "         [[-1.2015e-03, -1.7449e-03, -2.9168e-03],\n",
            "          [-2.1643e-03, -1.6404e-03, -2.9701e-03],\n",
            "          [-2.5545e-03, -1.6070e-03, -2.1461e-03]],\n",
            "\n",
            "         [[-1.9409e-03, -1.9803e-03, -1.8497e-03],\n",
            "          [-2.5367e-03, -2.5988e-03, -2.5891e-03],\n",
            "          [-2.6830e-03, -2.4404e-03, -3.1406e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1780e-04, -6.1161e-04, -4.4152e-04],\n",
            "          [-6.2967e-04, -7.8165e-04, -8.4792e-04],\n",
            "          [-6.7002e-04, -7.3713e-04, -9.6569e-04]],\n",
            "\n",
            "         [[ 1.9157e-03,  1.3221e-03,  1.3103e-03],\n",
            "          [ 1.0758e-03,  7.4904e-04,  5.9842e-04],\n",
            "          [ 1.1524e-03,  6.4937e-04,  2.5320e-04]],\n",
            "\n",
            "         [[ 1.6533e-03,  1.5102e-03,  1.4278e-05],\n",
            "          [ 3.0083e-03,  1.8555e-03, -9.1967e-04],\n",
            "          [ 2.5914e-03,  7.9385e-04, -2.0260e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1399e-03, -1.3050e-03, -1.0931e-03],\n",
            "          [-6.9011e-04, -6.0270e-04, -3.7407e-04],\n",
            "          [-9.8392e-05, -6.0190e-04, -8.4181e-04]],\n",
            "\n",
            "         [[-1.6850e-03, -1.2196e-03, -1.3967e-03],\n",
            "          [-1.7212e-03, -1.2582e-03, -1.9041e-03],\n",
            "          [-2.0230e-03, -1.9825e-03, -2.3916e-03]],\n",
            "\n",
            "         [[-1.1261e-03, -7.7209e-04, -7.1939e-04],\n",
            "          [-3.3401e-04,  1.2345e-04, -5.3311e-04],\n",
            "          [-1.4455e-04,  2.0571e-04, -1.3053e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4684e-04,  1.6163e-05,  3.1121e-04],\n",
            "          [ 3.7556e-04,  1.1111e-04,  3.1140e-04],\n",
            "          [ 7.6754e-04,  6.6384e-04,  5.4856e-04]],\n",
            "\n",
            "         [[ 9.0383e-04,  8.0022e-04,  2.4547e-04],\n",
            "          [ 4.4038e-04,  1.2875e-04,  1.1819e-03],\n",
            "          [ 9.0593e-04, -7.4698e-04,  6.9243e-04]],\n",
            "\n",
            "         [[-9.7828e-04, -1.5596e-04, -5.4938e-04],\n",
            "          [-1.9130e-03, -1.0463e-03, -5.5833e-04],\n",
            "          [-3.8958e-03, -1.8210e-03, -4.3765e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.2128e-04, -7.4946e-04, -7.7237e-04],\n",
            "          [-1.0020e-03, -1.0210e-03, -8.9274e-04],\n",
            "          [-8.5264e-04, -1.2080e-03, -1.0312e-03]],\n",
            "\n",
            "         [[-1.2866e-03, -1.0620e-03, -8.0871e-04],\n",
            "          [-1.1123e-03, -1.2299e-03, -1.0276e-03],\n",
            "          [-9.5814e-04, -7.5209e-04, -5.8905e-04]],\n",
            "\n",
            "         [[-3.7869e-04,  7.0947e-05,  2.9557e-04],\n",
            "          [-1.1222e-03, -3.9625e-04, -2.6443e-04],\n",
            "          [-1.4850e-03, -1.2312e-03, -4.9473e-04]]]])}, 28: {'momentum_buffer': tensor([ 1.6726e-03, -4.3254e-03,  8.0148e-04,  4.7359e-03,  1.1222e-03,\n",
            "         1.1028e-03,  5.7883e-04,  2.2161e-04,  6.2083e-04,  7.9929e-03,\n",
            "         1.8138e-03, -1.8071e-03, -6.1352e-03,  4.2254e-03, -3.4122e-03,\n",
            "         2.4634e-05,  1.6947e-03,  1.6487e-03,  2.1174e-03,  2.5127e-03,\n",
            "         1.5366e-03, -7.1182e-04,  6.0522e-03, -1.4532e-04,  1.9230e-03,\n",
            "         4.0131e-03,  5.7785e-04,  4.4693e-03, -4.1532e-03, -1.2668e-03,\n",
            "        -4.1260e-04,  6.2404e-04,  4.5871e-03, -2.2497e-03,  9.1852e-04,\n",
            "         1.1641e-03,  5.5235e-03,  3.0077e-03,  2.0780e-03, -2.0135e-03,\n",
            "         1.6201e-03,  2.3615e-04,  2.2652e-03,  3.4116e-03, -1.9476e-03,\n",
            "         1.3265e-03,  4.2249e-03,  2.7525e-03, -8.0508e-04, -2.1193e-03,\n",
            "         1.7417e-03,  3.2627e-04,  1.5528e-03,  6.2712e-04,  1.5547e-03,\n",
            "         1.9714e-03,  5.3416e-04,  1.7530e-04, -1.0094e-03, -3.5416e-03,\n",
            "         8.9510e-04,  4.8319e-03,  4.9923e-04, -2.8012e-04])}, 29: {'momentum_buffer': tensor([-1.8035e-03, -3.9335e-03, -1.0171e-03,  8.5772e-04,  2.0884e-03,\n",
            "         6.6428e-04, -6.7707e-04, -1.3955e-04,  2.9015e-04,  4.7324e-03,\n",
            "         2.9277e-03, -1.2732e-03, -2.9689e-03, -4.9707e-04, -4.6098e-03,\n",
            "        -7.7576e-04,  3.4068e-03, -1.5330e-03,  2.1166e-03,  2.0063e-03,\n",
            "        -1.0307e-03, -1.1519e-04,  1.2439e-03, -3.8676e-04,  7.7487e-04,\n",
            "         1.5974e-04,  5.5117e-04,  1.2213e-03, -1.4844e-03, -3.3941e-03,\n",
            "        -1.2300e-03, -3.6098e-04,  2.9345e-03, -5.4179e-04, -1.4796e-03,\n",
            "         9.2193e-04,  2.1166e-03,  7.0201e-04,  1.0451e-03, -5.4448e-04,\n",
            "         3.4098e-03,  9.7214e-05, -4.6305e-04, -3.6749e-03, -5.8127e-04,\n",
            "         7.5528e-04, -1.4473e-04, -2.9383e-03, -3.3097e-04, -4.7312e-03,\n",
            "        -2.4875e-04, -2.3741e-04,  1.6810e-03, -1.4822e-03, -6.5470e-04,\n",
            "         1.3723e-03, -1.5723e-04,  6.2217e-04, -8.0885e-04, -3.9653e-03,\n",
            "         1.8690e-03,  3.8948e-03, -2.7068e-03, -1.1467e-03])}, 30: {'momentum_buffer': tensor([[[[-1.2068e-03]],\n",
            "\n",
            "         [[ 1.6361e-03]],\n",
            "\n",
            "         [[-1.6195e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1637e-03]],\n",
            "\n",
            "         [[-7.7565e-05]],\n",
            "\n",
            "         [[-1.2942e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.0152e-03]],\n",
            "\n",
            "         [[-2.6340e-03]],\n",
            "\n",
            "         [[ 1.9788e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8688e-04]],\n",
            "\n",
            "         [[-2.6615e-03]],\n",
            "\n",
            "         [[-1.2779e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.7659e-04]],\n",
            "\n",
            "         [[-2.4313e-03]],\n",
            "\n",
            "         [[-7.5075e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3413e-03]],\n",
            "\n",
            "         [[ 6.3664e-04]],\n",
            "\n",
            "         [[ 1.4796e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.2855e-03]],\n",
            "\n",
            "         [[ 9.3444e-03]],\n",
            "\n",
            "         [[ 2.4674e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1621e-03]],\n",
            "\n",
            "         [[ 1.6028e-03]],\n",
            "\n",
            "         [[ 7.2310e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.5006e-04]],\n",
            "\n",
            "         [[ 2.4962e-03]],\n",
            "\n",
            "         [[-1.0971e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1033e-03]],\n",
            "\n",
            "         [[ 1.8626e-03]],\n",
            "\n",
            "         [[-1.0528e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.7608e-03]],\n",
            "\n",
            "         [[-1.1499e-03]],\n",
            "\n",
            "         [[ 6.4158e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0072e-03]],\n",
            "\n",
            "         [[-4.3013e-03]],\n",
            "\n",
            "         [[-1.7151e-03]]]])}, 31: {'momentum_buffer': tensor([ 1.8665e-03,  1.9496e-04,  1.3816e-03,  3.1043e-03,  2.4520e-03,\n",
            "         1.8036e-03,  1.1224e-03,  1.2503e-03,  1.1631e-04, -1.4804e-04,\n",
            "         4.9083e-04,  6.8228e-06, -4.3621e-04,  8.9856e-04,  5.5761e-04,\n",
            "         2.4747e-03,  8.4689e-04,  1.9067e-03,  1.2517e-03,  7.3090e-04,\n",
            "         1.0324e-03,  7.4663e-04,  1.3129e-03,  1.7131e-03,  1.2841e-03,\n",
            "         2.1756e-03, -1.8115e-03,  7.1567e-04,  1.5490e-03, -5.9780e-05,\n",
            "         2.5160e-03,  1.7515e-03,  3.6634e-04,  4.8959e-04,  5.5317e-04,\n",
            "         1.6329e-03, -1.3396e-03,  5.7576e-04,  4.9218e-04,  2.1779e-03,\n",
            "        -5.6184e-04,  1.2911e-03,  4.6866e-04,  4.1627e-04,  7.1542e-04,\n",
            "         6.4017e-04,  1.5147e-03, -6.0895e-04,  2.8835e-03,  1.9684e-03,\n",
            "         1.1710e-03,  1.4837e-03, -5.6253e-04,  1.3293e-03,  2.9904e-03,\n",
            "         1.2193e-03,  9.4524e-04, -1.9483e-04,  5.5281e-04,  1.7155e-03,\n",
            "         6.4707e-04,  1.0859e-03,  1.2160e-03,  1.5328e-03,  9.3793e-04,\n",
            "         1.2756e-03,  1.8753e-03,  1.4880e-03,  6.5315e-05,  1.7409e-03,\n",
            "         8.4992e-04,  7.7084e-04,  1.9322e-03,  8.1870e-04,  3.5973e-04,\n",
            "         1.3686e-03,  1.5266e-03,  1.1427e-03,  2.2307e-03,  1.6455e-03,\n",
            "         1.6244e-03,  4.0059e-04,  4.2755e-04, -1.7517e-03,  6.2601e-04,\n",
            "         3.7534e-04,  9.7667e-04,  8.3021e-04,  9.5045e-04,  8.7464e-04,\n",
            "         1.3906e-03,  1.3526e-03,  1.4486e-03,  2.8354e-04,  1.7283e-03,\n",
            "         7.1525e-04,  9.3858e-04,  4.9301e-04,  2.1859e-03,  2.3567e-03,\n",
            "         2.3901e-03,  1.6595e-03,  4.0699e-04,  1.6967e-03,  5.9235e-04,\n",
            "        -3.0220e-04,  1.0079e-03,  7.7749e-04,  1.4117e-03,  2.2268e-03,\n",
            "         2.2501e-03,  2.2808e-03,  1.4426e-03,  2.5737e-03, -1.6250e-03,\n",
            "         1.7354e-03,  2.3268e-03,  5.8418e-04,  2.7090e-03, -8.6739e-05,\n",
            "         2.6442e-03,  2.8715e-03,  1.4808e-03,  3.5632e-04,  1.5875e-03,\n",
            "         1.4503e-03,  5.1898e-04,  2.3494e-03,  6.8837e-04,  3.6560e-04,\n",
            "         4.1865e-04,  3.2001e-04,  1.9545e-03,  7.8636e-04,  2.3406e-03,\n",
            "         1.2126e-03,  5.5332e-04,  2.6025e-03, -1.0691e-03,  1.1741e-03,\n",
            "         4.3987e-04,  2.7162e-03,  1.4595e-03, -8.5328e-05, -7.1313e-04,\n",
            "         3.0398e-04,  1.6589e-03, -1.3082e-04,  1.9795e-03, -1.1490e-03,\n",
            "        -7.2594e-04,  9.4074e-04,  9.0374e-04,  3.3583e-04,  8.3581e-04,\n",
            "         1.0081e-03,  7.2809e-04,  1.3756e-04, -2.5097e-04,  1.1064e-03,\n",
            "         1.3992e-03, -6.1424e-04, -5.0681e-04,  1.6820e-03,  6.4701e-04,\n",
            "         1.4812e-03,  1.3907e-03, -4.2141e-05,  5.8178e-04,  1.3527e-03,\n",
            "         1.4750e-05,  1.7969e-03,  1.1522e-03,  8.8861e-04,  2.4159e-04,\n",
            "         1.4106e-03,  1.2235e-03,  5.3301e-04,  1.6803e-03,  2.7646e-03,\n",
            "        -7.8781e-04, -7.9387e-05,  8.2207e-04,  5.8642e-04, -1.1076e-03,\n",
            "         2.5748e-03, -3.7993e-05,  2.5719e-03,  2.4553e-03,  6.2067e-04,\n",
            "         1.5125e-03,  4.5619e-03,  1.9241e-03,  1.2154e-03,  1.6731e-03,\n",
            "         1.3938e-03, -1.1708e-04,  2.5188e-03,  2.9243e-03,  2.3441e-03,\n",
            "         2.3696e-03,  2.7379e-03,  2.3856e-03,  1.1277e-03,  1.2524e-03,\n",
            "        -3.3902e-04, -5.9815e-04,  1.0697e-03,  5.4629e-04, -2.8365e-04,\n",
            "         2.6623e-05, -6.9057e-04,  5.3300e-04,  2.0075e-03,  1.6406e-03,\n",
            "         1.0595e-03,  2.5662e-03,  3.8816e-04, -9.0281e-04, -5.4066e-04,\n",
            "         2.0686e-03,  2.0758e-03,  1.8252e-03, -4.0433e-05,  1.5607e-03,\n",
            "         6.8618e-04,  1.0077e-03, -3.9698e-04,  5.4681e-04,  8.1756e-04,\n",
            "        -5.4277e-04,  7.7789e-04,  8.9971e-04,  1.3909e-04,  1.0585e-03,\n",
            "         1.8639e-03, -7.5215e-04,  3.3387e-04,  2.3561e-03,  9.1764e-04,\n",
            "         2.5137e-03,  2.3603e-03,  3.4166e-03,  1.1392e-04,  1.6139e-03,\n",
            "        -4.8132e-04,  1.9262e-03,  1.5143e-03,  2.7968e-03,  1.0435e-03,\n",
            "         2.2185e-03, -1.2664e-03,  1.0877e-03,  1.7311e-03,  1.3245e-03,\n",
            "         3.1150e-03])}, 32: {'momentum_buffer': tensor([ 7.9975e-04,  8.7963e-04, -2.5826e-04,  6.9600e-04, -5.2854e-04,\n",
            "        -1.5154e-04,  1.4982e-04,  1.0268e-04,  7.0055e-04, -8.6494e-04,\n",
            "        -4.1361e-04, -4.0264e-04, -9.6607e-04,  7.4535e-04,  2.7511e-04,\n",
            "        -2.4598e-04, -1.0681e-03,  1.0773e-03,  1.9066e-03,  1.7040e-03,\n",
            "         6.0605e-04,  8.0823e-04,  2.0108e-04,  5.0612e-04, -6.2842e-04,\n",
            "         1.1815e-04, -9.5732e-04,  4.3218e-04, -3.1725e-04,  3.7347e-05,\n",
            "         4.7660e-04,  1.5228e-04,  3.3333e-05, -4.3114e-04,  9.2977e-05,\n",
            "        -4.8611e-05,  2.0473e-04, -4.1256e-05, -1.9990e-04,  1.0224e-03,\n",
            "        -1.0150e-03,  4.8958e-04, -7.1414e-04,  1.2245e-04,  2.3864e-04,\n",
            "        -1.2025e-04, -5.1331e-04, -1.0817e-03,  7.0573e-05, -1.8209e-04,\n",
            "         2.5610e-04,  3.3770e-04,  5.0065e-04,  2.2288e-04, -8.7612e-04,\n",
            "         3.9772e-04,  8.3518e-04, -1.5261e-04, -3.3125e-04,  1.1880e-04,\n",
            "         6.2894e-05,  5.5644e-04, -1.0937e-04,  4.0926e-04,  1.9367e-04,\n",
            "         5.5060e-05,  5.0398e-04, -1.1030e-04, -2.6561e-04, -1.3949e-03,\n",
            "        -1.0239e-04,  3.0113e-04,  5.9843e-04, -3.3130e-04,  1.2574e-04,\n",
            "        -8.8720e-04,  4.3639e-04, -5.8513e-06, -1.5409e-03,  1.4806e-03,\n",
            "         5.5004e-04, -4.9038e-04,  3.5926e-04,  3.6865e-04, -6.0591e-05,\n",
            "        -1.0327e-03,  2.1375e-04, -1.2047e-04, -2.8301e-04,  2.2987e-05,\n",
            "        -7.7285e-04,  9.2543e-04,  1.2573e-04, -2.3550e-04, -2.0714e-04,\n",
            "        -2.5011e-04, -5.4118e-04, -7.8522e-04,  9.0857e-04, -6.7463e-04,\n",
            "         6.4370e-04, -5.3033e-04, -1.4188e-04,  9.8363e-04, -2.3274e-05,\n",
            "         3.0886e-04,  9.9403e-04,  9.1224e-04, -4.6146e-04,  9.5769e-04,\n",
            "         1.2113e-03,  5.9935e-04, -1.2260e-04, -2.2765e-04,  4.5323e-04,\n",
            "        -3.7230e-04,  2.0035e-04,  1.0072e-04,  4.6861e-04, -6.8504e-06,\n",
            "         1.3108e-03, -2.3660e-05,  5.8169e-04, -1.2353e-04,  4.9406e-04,\n",
            "         1.7752e-04,  8.0803e-04, -6.0863e-05,  1.0487e-03, -1.2781e-05,\n",
            "         1.6133e-04, -9.8406e-04,  2.7208e-04, -9.2742e-04, -2.4642e-04,\n",
            "        -5.7868e-04,  3.0348e-04, -8.1084e-04, -1.0639e-03, -3.1686e-04,\n",
            "        -5.6085e-04,  9.9851e-04, -1.6460e-04, -2.6784e-04, -3.3345e-04,\n",
            "        -4.3461e-04, -8.8379e-04, -1.3761e-04,  5.0765e-04, -3.0180e-05,\n",
            "        -2.6726e-04,  1.4378e-03, -1.8852e-04, -7.3558e-04, -4.0890e-04,\n",
            "         1.7964e-04, -4.0935e-04,  7.2820e-04, -1.6187e-04,  3.8187e-05,\n",
            "         3.5791e-04,  6.5420e-04,  1.0099e-03,  6.5107e-04, -1.8456e-03,\n",
            "         8.7467e-04,  7.7847e-04,  1.2291e-04,  2.6285e-04, -1.2343e-04,\n",
            "        -1.0259e-03,  1.0619e-04,  4.8902e-04, -1.4492e-03,  1.3774e-05,\n",
            "         4.6024e-04,  1.4224e-03,  3.7900e-04, -3.5432e-04, -1.0263e-03,\n",
            "        -2.6731e-04,  3.8565e-05,  3.3955e-04,  7.8882e-04, -8.5600e-05,\n",
            "        -2.6546e-04,  7.9702e-04, -6.0476e-04,  1.6853e-03, -3.1518e-04,\n",
            "        -7.4414e-04,  7.8859e-04,  1.5926e-04, -4.0963e-04, -8.1756e-04,\n",
            "        -1.1121e-03, -8.2122e-04,  2.3894e-04, -7.9857e-04,  2.3711e-04,\n",
            "        -1.5185e-04,  1.5839e-03,  9.5885e-04, -3.5599e-04, -9.7704e-04,\n",
            "        -7.4467e-04,  5.4991e-05, -8.6570e-04,  4.3986e-04, -1.8457e-05,\n",
            "        -8.3139e-04,  5.1332e-04, -1.3726e-04,  7.2276e-04, -4.2838e-04,\n",
            "         8.3524e-05,  2.8510e-04,  7.1209e-05, -9.4694e-04, -5.9072e-04,\n",
            "        -1.2335e-03, -7.3369e-05, -3.1048e-04,  6.3458e-05, -2.3958e-04,\n",
            "        -7.3214e-04, -7.8042e-06,  8.9336e-05,  6.3477e-04,  2.8518e-04,\n",
            "         8.6901e-04,  8.6586e-04,  3.5306e-04, -6.3192e-04, -7.5139e-04,\n",
            "        -3.7035e-04, -4.5789e-04, -3.7207e-04, -1.0822e-03,  4.4317e-04,\n",
            "        -3.9915e-04, -8.0371e-04,  5.7274e-04, -3.1675e-04,  5.3354e-04,\n",
            "         1.1263e-03,  5.9617e-04, -1.0034e-03,  1.0372e-03, -3.9416e-04,\n",
            "         4.4821e-05, -5.8871e-04, -6.1256e-05, -4.6800e-04,  4.5880e-04,\n",
            "         5.9488e-04])}, 33: {'momentum_buffer': tensor([[[[ 6.7453e-04]],\n",
            "\n",
            "         [[-1.2206e-04]],\n",
            "\n",
            "         [[ 3.9211e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1365e-04]],\n",
            "\n",
            "         [[-2.6576e-04]],\n",
            "\n",
            "         [[ 1.1245e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2987e-04]],\n",
            "\n",
            "         [[ 2.0098e-04]],\n",
            "\n",
            "         [[ 8.7220e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5510e-04]],\n",
            "\n",
            "         [[-2.5746e-04]],\n",
            "\n",
            "         [[ 5.9066e-04]]],\n",
            "\n",
            "\n",
            "        [[[-4.8294e-04]],\n",
            "\n",
            "         [[-5.7674e-04]],\n",
            "\n",
            "         [[ 1.1850e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3048e-03]],\n",
            "\n",
            "         [[ 1.7356e-04]],\n",
            "\n",
            "         [[-7.5519e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.4637e-04]],\n",
            "\n",
            "         [[-7.0610e-04]],\n",
            "\n",
            "         [[-7.5591e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.5042e-04]],\n",
            "\n",
            "         [[-1.0606e-03]],\n",
            "\n",
            "         [[-1.2810e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.3076e-03]],\n",
            "\n",
            "         [[-1.2187e-03]],\n",
            "\n",
            "         [[-8.8762e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3975e-04]],\n",
            "\n",
            "         [[-3.4994e-05]],\n",
            "\n",
            "         [[-1.1226e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.7865e-03]],\n",
            "\n",
            "         [[-2.4073e-04]],\n",
            "\n",
            "         [[ 1.0562e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2261e-04]],\n",
            "\n",
            "         [[ 9.0335e-04]],\n",
            "\n",
            "         [[ 2.2596e-04]]]])}, 34: {'momentum_buffer': tensor([ 4.2234e-03,  3.6266e-03, -1.6487e-04,  9.7216e-04,  1.3599e-03,\n",
            "         1.5463e-03,  1.6642e-03,  1.5770e-03,  2.0960e-03, -8.0181e-04,\n",
            "        -3.4266e-04, -5.9110e-04,  4.6257e-03,  2.0468e-03,  3.0307e-03,\n",
            "         1.7457e-03,  4.4440e-03,  2.4957e-04, -3.4137e-03,  9.0184e-04,\n",
            "         2.8028e-04,  7.0761e-04,  1.3558e-03,  2.5387e-03,  9.1640e-04,\n",
            "         1.9666e-03, -6.4900e-04,  1.0933e-03,  1.0721e-03,  3.5147e-04,\n",
            "         3.2295e-03,  1.5825e-04,  2.9743e-04,  5.5901e-04,  6.2046e-04,\n",
            "         1.8306e-04,  1.5308e-03,  8.5893e-04, -3.7522e-03, -2.1994e-04,\n",
            "        -9.8775e-04, -2.5548e-03,  1.0263e-03,  2.5349e-04,  1.6823e-03,\n",
            "        -4.8014e-04,  1.2690e-03,  2.5210e-03, -6.0156e-04,  3.8165e-04,\n",
            "         2.5728e-03,  2.0205e-04,  1.6288e-04, -2.7357e-03,  1.6484e-03,\n",
            "         8.4754e-04,  1.5225e-03,  1.5086e-03,  3.1874e-04,  3.6424e-03,\n",
            "         3.4047e-03, -1.6158e-04, -7.7554e-04, -2.2732e-03, -1.1679e-03,\n",
            "         1.6105e-03, -4.2824e-04,  2.3812e-03,  2.7132e-03,  2.1824e-03,\n",
            "         3.2900e-03, -3.2655e-04, -3.0751e-03,  8.1419e-04,  1.0244e-03,\n",
            "         5.6185e-04, -1.1133e-03,  3.9655e-04,  3.2614e-03,  2.1073e-04,\n",
            "         2.2993e-03, -4.2831e-04,  1.3352e-03,  1.4682e-03,  1.8090e-03,\n",
            "        -8.7686e-05,  3.6286e-04,  2.1933e-03,  5.6206e-04,  1.2958e-03,\n",
            "         7.5516e-04,  2.0447e-03,  1.1464e-03,  1.0532e-03,  1.6938e-03,\n",
            "         3.5246e-03,  3.3421e-04,  6.5306e-04,  1.8672e-03,  2.9259e-03,\n",
            "         3.9739e-03, -5.6663e-04,  3.6406e-03,  1.8041e-03, -1.6101e-03,\n",
            "         1.0519e-03,  1.1537e-03,  1.4932e-03, -2.1719e-03,  1.6923e-03,\n",
            "         3.1096e-04,  2.7703e-03,  2.5257e-04,  1.7735e-03, -4.1339e-03,\n",
            "         2.5655e-03,  8.3462e-04,  2.4983e-03, -1.3224e-04,  4.7930e-03,\n",
            "         4.5325e-04,  3.2178e-03,  4.2637e-04,  2.0203e-03, -4.9767e-04,\n",
            "         3.7173e-03,  1.9828e-03,  5.2843e-04])}, 35: {'momentum_buffer': tensor([ 1.1236e-03,  9.2979e-04, -1.0469e-03, -1.2029e-03, -7.6410e-05,\n",
            "         1.4057e-03,  8.2350e-04,  2.5587e-03, -1.1527e-03, -1.3775e-03,\n",
            "        -1.0209e-03, -1.8350e-03,  2.1455e-03,  1.1352e-03,  2.5528e-04,\n",
            "        -3.2984e-04,  4.7654e-04,  2.3209e-04,  4.2095e-05, -1.8212e-03,\n",
            "        -1.1419e-03, -1.8595e-04,  1.2102e-03,  1.7708e-03, -8.1255e-04,\n",
            "         2.9461e-03, -1.4475e-03,  7.2615e-04, -9.7465e-04, -2.2232e-03,\n",
            "         2.4276e-03, -7.5761e-04, -7.4629e-04,  7.1930e-04, -3.2801e-04,\n",
            "        -1.4355e-03,  3.6541e-05, -9.3287e-04, -2.9269e-03, -1.8472e-04,\n",
            "        -1.4250e-03, -2.4350e-03,  8.5583e-04,  1.8691e-05,  1.5897e-03,\n",
            "        -1.6441e-06,  5.0743e-05,  8.6640e-04, -1.7777e-03,  6.3052e-04,\n",
            "         7.7996e-04, -1.1233e-03, -5.2840e-04,  6.0823e-05, -1.4176e-03,\n",
            "        -1.8610e-04,  1.3022e-03, -1.1307e-03, -1.5525e-03,  1.8342e-03,\n",
            "         1.5308e-04, -3.9438e-04,  1.5328e-03, -1.2262e-03, -1.4766e-03,\n",
            "        -5.6979e-04, -1.2307e-03,  1.1172e-03,  8.1439e-04,  8.0976e-04,\n",
            "         1.4508e-03, -3.5758e-03, -2.7895e-03,  3.5961e-04, -1.7920e-03,\n",
            "        -3.5754e-05,  9.8956e-04,  5.0901e-04,  7.2639e-06,  7.0171e-04,\n",
            "         1.2043e-03, -2.1983e-03, -1.2423e-03,  1.4630e-03,  1.4793e-04,\n",
            "         4.6263e-04, -2.8712e-03, -8.5109e-05, -1.3916e-03, -7.1372e-04,\n",
            "        -8.7420e-04,  8.8715e-04,  5.8176e-05,  6.0052e-04, -5.3334e-04,\n",
            "         7.9911e-04,  1.1695e-03,  3.3180e-04, -2.9581e-04,  2.2543e-03,\n",
            "         2.0474e-03, -1.1501e-03,  2.2630e-03,  9.1483e-05, -1.7527e-03,\n",
            "        -2.3863e-04,  3.9306e-04,  3.2762e-04, -1.8966e-03,  7.3843e-04,\n",
            "        -1.2175e-03,  8.8114e-04, -2.2038e-04,  2.9524e-04, -1.5566e-03,\n",
            "         1.9775e-03, -1.2183e-03, -6.0841e-04, -3.9355e-04,  3.6065e-03,\n",
            "        -8.3224e-04,  6.9752e-04, -1.1761e-03, -1.5003e-04, -4.0129e-04,\n",
            "         3.9652e-03,  2.0868e-03,  7.5665e-04])}, 36: {'momentum_buffer': tensor([[[[-3.1321e-04,  5.3723e-04,  1.3357e-03],\n",
            "          [ 5.0352e-04,  1.1724e-03,  1.4386e-03],\n",
            "          [ 5.6292e-04,  1.0910e-03,  9.4700e-04]],\n",
            "\n",
            "         [[ 3.7088e-04,  3.2044e-04,  4.2920e-04],\n",
            "          [ 3.6645e-04,  4.6669e-04,  5.0634e-04],\n",
            "          [ 7.8089e-04,  9.2350e-04,  9.7481e-04]],\n",
            "\n",
            "         [[ 1.0782e-04, -8.4025e-05,  4.1711e-04],\n",
            "          [-2.0320e-04,  1.9322e-04,  7.3327e-04],\n",
            "          [-1.2159e-04,  5.3536e-04,  7.3678e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.7537e-04, -1.0723e-03, -9.4736e-04],\n",
            "          [-4.7179e-04, -1.1887e-03, -9.1049e-04],\n",
            "          [-9.4140e-04, -5.4275e-04, -8.0559e-04]],\n",
            "\n",
            "         [[ 4.8720e-05,  7.3676e-04,  4.1403e-04],\n",
            "          [ 6.5536e-04,  1.2266e-03,  1.1706e-03],\n",
            "          [ 1.7782e-03,  2.0501e-03,  1.8163e-03]],\n",
            "\n",
            "         [[-1.0779e-04,  3.8607e-04,  6.5373e-04],\n",
            "          [ 4.0929e-04,  7.2298e-04,  6.6559e-04],\n",
            "          [ 1.1714e-03,  7.9740e-04,  9.2726e-04]]],\n",
            "\n",
            "\n",
            "        [[[-6.9861e-04, -6.0263e-04, -9.7412e-04],\n",
            "          [-9.4288e-04, -8.8182e-04, -1.1801e-03],\n",
            "          [-1.1209e-03, -1.2917e-03, -1.6468e-03]],\n",
            "\n",
            "         [[-1.2576e-04, -2.4385e-04,  1.8349e-04],\n",
            "          [ 1.8276e-05, -6.4974e-05, -1.8745e-04],\n",
            "          [ 6.2117e-05, -1.5438e-04, -2.2995e-05]],\n",
            "\n",
            "         [[-1.9696e-03, -2.2167e-03, -2.4832e-03],\n",
            "          [-2.4589e-03, -2.4149e-03, -2.7216e-03],\n",
            "          [-2.1625e-03, -2.3038e-03, -2.5596e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4584e-04,  9.5779e-05,  6.4380e-04],\n",
            "          [ 1.9438e-04,  6.1962e-04,  8.2780e-04],\n",
            "          [ 4.3132e-04,  7.0313e-04,  8.3161e-04]],\n",
            "\n",
            "         [[ 7.1204e-04,  7.1310e-04,  7.8190e-04],\n",
            "          [ 5.0886e-04,  3.2590e-04,  1.8731e-04],\n",
            "          [ 4.1226e-04,  3.8122e-04, -1.5897e-04]],\n",
            "\n",
            "         [[-5.1607e-04, -5.8646e-04, -6.1420e-04],\n",
            "          [-9.5910e-04, -1.0643e-03, -1.0368e-03],\n",
            "          [-7.8044e-04, -1.2071e-03, -1.0785e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1841e-04, -5.1340e-04, -3.3738e-05],\n",
            "          [-4.3136e-04, -6.2954e-04, -6.5598e-04],\n",
            "          [-3.6985e-04, -8.5992e-04, -9.5280e-04]],\n",
            "\n",
            "         [[-2.1656e-04, -2.9283e-04, -1.5829e-04],\n",
            "          [-6.1226e-04, -4.7957e-04, -4.7553e-05],\n",
            "          [-8.0692e-04, -7.7735e-04, -4.7097e-04]],\n",
            "\n",
            "         [[ 5.6638e-04,  8.3660e-04,  1.3329e-03],\n",
            "          [ 4.8308e-04,  1.2180e-03,  1.4517e-03],\n",
            "          [ 6.9311e-04,  1.3368e-03,  1.2968e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.9055e-04, -6.3401e-04, -5.3788e-04],\n",
            "          [-7.6330e-04, -8.6402e-04, -8.2059e-04],\n",
            "          [-5.3193e-04, -6.4689e-04, -5.9847e-04]],\n",
            "\n",
            "         [[-7.6014e-04, -7.9687e-04, -5.6999e-04],\n",
            "          [-9.6442e-04, -1.0614e-03, -1.2283e-03],\n",
            "          [-1.0860e-03, -1.3628e-03, -1.7031e-03]],\n",
            "\n",
            "         [[-7.0826e-04, -9.5908e-04, -6.7084e-04],\n",
            "          [-7.4182e-04, -1.2882e-03, -1.0595e-03],\n",
            "          [-1.0882e-03, -1.3214e-03, -1.1761e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.9108e-04, -3.4531e-04,  7.7269e-05],\n",
            "          [-1.2074e-04,  5.1067e-05,  3.3071e-04],\n",
            "          [ 4.0372e-04,  6.2037e-05,  6.7890e-05]],\n",
            "\n",
            "         [[ 7.5989e-04,  1.3088e-03,  1.5745e-03],\n",
            "          [ 4.5711e-04,  1.3288e-03,  1.2659e-03],\n",
            "          [ 6.7859e-04,  8.1523e-04,  7.5714e-04]],\n",
            "\n",
            "         [[ 8.9941e-04,  7.7282e-04,  6.4715e-04],\n",
            "          [ 8.7573e-04,  9.7437e-04,  1.0743e-03],\n",
            "          [ 1.0307e-03,  1.2836e-03,  1.4498e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2256e-04,  5.2143e-05,  2.2009e-04],\n",
            "          [-4.9559e-04, -8.8436e-04, -3.4397e-04],\n",
            "          [-2.7533e-04, -9.0126e-04, -2.2547e-04]],\n",
            "\n",
            "         [[-7.0422e-04, -5.0591e-04, -6.6211e-04],\n",
            "          [-1.8710e-04, -2.4991e-04, -6.5177e-04],\n",
            "          [-4.9933e-04, -2.7875e-04, -1.2221e-03]],\n",
            "\n",
            "         [[-2.1470e-04, -3.9321e-04,  6.1999e-06],\n",
            "          [-6.4942e-04, -7.4510e-04, -4.4589e-04],\n",
            "          [-6.1889e-04, -2.4131e-04, -6.0833e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.8289e-03, -2.8738e-03, -3.0343e-03],\n",
            "          [-2.8146e-03, -2.8059e-03, -3.1781e-03],\n",
            "          [-1.9979e-03, -2.4071e-03, -3.0751e-03]],\n",
            "\n",
            "         [[ 3.2470e-04, -1.0053e-03, -2.0975e-03],\n",
            "          [ 9.4443e-04, -8.7758e-05, -1.8398e-03],\n",
            "          [ 7.9152e-04, -3.6315e-04, -1.3444e-03]],\n",
            "\n",
            "         [[-5.1970e-04, -5.4500e-04, -1.1521e-04],\n",
            "          [-7.1345e-04, -6.3060e-04, -3.7747e-04],\n",
            "          [-8.6020e-04, -7.9208e-04, -4.7031e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2616e-04, -6.9464e-05, -6.5947e-04],\n",
            "          [-7.4581e-04, -4.3863e-04, -1.1019e-03],\n",
            "          [-8.0828e-04, -9.3525e-04, -9.4159e-04]],\n",
            "\n",
            "         [[-9.6841e-04, -1.3761e-03, -1.2297e-03],\n",
            "          [-2.2936e-04, -1.1962e-03, -1.5000e-03],\n",
            "          [ 1.1393e-04, -8.0566e-04, -1.1543e-03]],\n",
            "\n",
            "         [[-1.1672e-03, -1.2941e-03, -1.8373e-03],\n",
            "          [-1.0963e-03, -1.8963e-03, -2.4393e-03],\n",
            "          [-6.3736e-04, -1.7958e-03, -2.7827e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.3175e-04,  2.2568e-04,  8.2659e-04],\n",
            "          [ 1.3525e-04,  7.0906e-04,  1.0524e-03],\n",
            "          [ 4.8322e-04,  7.2489e-04,  9.6449e-04]],\n",
            "\n",
            "         [[-1.3348e-03, -3.1967e-04,  3.2870e-04],\n",
            "          [-9.5864e-04, -5.9933e-04, -1.8014e-04],\n",
            "          [-9.6299e-04, -2.9480e-04, -2.8859e-04]],\n",
            "\n",
            "         [[-4.3229e-04, -6.5322e-04, -8.2477e-04],\n",
            "          [ 7.2300e-05, -3.7657e-04, -6.8036e-04],\n",
            "          [ 3.4877e-04, -3.2360e-04, -3.8027e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1626e-04, -6.1095e-04, -9.2310e-04],\n",
            "          [-6.6814e-04, -9.3480e-04, -1.1744e-03],\n",
            "          [-3.0548e-04, -3.7202e-04, -1.1370e-03]],\n",
            "\n",
            "         [[ 2.8791e-04,  3.3764e-04,  7.3703e-04],\n",
            "          [ 2.1528e-04,  5.8922e-04,  7.9969e-04],\n",
            "          [ 1.9614e-04,  8.3111e-04,  1.3950e-03]],\n",
            "\n",
            "         [[-4.3918e-05,  1.3234e-04,  6.3233e-04],\n",
            "          [-1.3001e-04,  1.3094e-04,  9.8718e-04],\n",
            "          [-4.8997e-05,  6.5297e-05,  8.3401e-04]]]])}, 37: {'momentum_buffer': tensor([ 1.9101e-03,  6.8619e-04,  2.4242e-04,  2.4437e-03,  2.2856e-03,\n",
            "        -2.0595e-03, -1.0456e-04, -1.3891e-03,  3.0897e-03,  3.8581e-04,\n",
            "        -4.7630e-04,  1.8442e-03,  2.2178e-03,  2.9417e-03,  1.3503e-03,\n",
            "         1.4155e-04,  3.2677e-03,  1.9757e-03,  2.1411e-03,  2.8353e-03,\n",
            "         1.3907e-03,  1.0364e-03,  1.3547e-03,  3.4855e-03,  1.4957e-03,\n",
            "         2.1243e-03,  6.3543e-05,  4.7596e-04, -3.0346e-03, -3.6206e-04,\n",
            "        -7.5775e-04,  3.5253e-03,  7.7017e-04,  1.0964e-04,  6.9581e-05,\n",
            "        -2.6897e-04,  1.7060e-03, -1.3197e-03,  7.2225e-04,  1.1952e-04,\n",
            "         4.7130e-03,  4.4850e-04, -2.0735e-04, -1.4644e-03,  2.8650e-03,\n",
            "         4.8270e-03,  1.4710e-03, -1.3796e-03, -3.3964e-04,  6.4603e-04,\n",
            "         1.9165e-03,  1.4443e-03, -4.0696e-03,  1.5551e-03,  1.6436e-04,\n",
            "         9.9265e-04, -1.3577e-03, -1.1762e-03,  1.1870e-03,  1.4341e-03,\n",
            "         2.6854e-03,  3.5284e-03, -9.3151e-04,  1.6085e-03,  7.6836e-04,\n",
            "         2.6151e-04,  2.3345e-03, -2.9259e-05,  3.9437e-04,  9.4300e-04,\n",
            "        -2.5831e-03,  9.1879e-04, -1.8050e-04,  4.1076e-03,  9.0840e-04,\n",
            "         2.2339e-03,  1.1761e-03,  3.9197e-03, -1.8593e-03,  3.9484e-03,\n",
            "        -2.0923e-03, -6.6304e-04,  4.9382e-03,  1.6973e-03,  1.2851e-03,\n",
            "         2.4965e-06,  4.4086e-03,  7.6594e-04,  4.6443e-03, -8.9407e-04,\n",
            "         2.6753e-03,  7.2215e-04, -1.4692e-04,  7.2071e-04,  1.0796e-03,\n",
            "         6.6686e-04,  1.3057e-03,  2.8921e-03,  1.8250e-04, -1.5031e-04,\n",
            "         3.2769e-03,  8.1359e-04,  2.4118e-03,  1.0171e-04,  7.1827e-04,\n",
            "         2.0967e-03,  4.0014e-04, -2.7672e-04,  3.4945e-04,  1.4375e-03,\n",
            "         1.1558e-03, -1.5566e-03, -3.0753e-04,  3.1403e-03,  2.3315e-03,\n",
            "         2.6042e-03, -1.0294e-03,  2.3088e-03,  3.8991e-03,  1.2579e-03,\n",
            "        -1.4865e-03,  3.4333e-04,  1.7251e-03,  3.6405e-03, -7.4823e-04,\n",
            "        -3.3966e-03,  4.7653e-04,  1.1041e-03])}, 38: {'momentum_buffer': tensor([ 1.3442e-03, -1.1580e-03, -1.5440e-03,  6.4708e-04,  2.0584e-03,\n",
            "        -6.8431e-04, -2.0481e-03, -1.7312e-03,  1.0998e-03, -3.5680e-04,\n",
            "        -1.1239e-03,  2.1926e-03,  1.5283e-03,  1.3181e-03, -4.3861e-05,\n",
            "         7.7353e-04,  1.0789e-03, -8.4240e-04,  3.4514e-04,  1.6093e-03,\n",
            "         3.1793e-03,  1.8317e-04,  1.4738e-04, -4.8713e-04, -2.8491e-04,\n",
            "         4.8402e-04,  7.9281e-04,  7.0509e-04, -2.2752e-03, -1.5617e-04,\n",
            "        -1.7876e-03,  4.4048e-04,  8.7648e-04, -1.2978e-04, -1.4214e-03,\n",
            "        -2.0901e-03,  1.0796e-03, -1.1875e-03,  1.6627e-03,  2.1566e-04,\n",
            "         1.3405e-03,  1.0402e-04, -1.2349e-03, -2.0612e-03,  2.6991e-03,\n",
            "         1.6032e-03, -1.5337e-04, -2.9403e-03, -1.5678e-03,  2.5490e-04,\n",
            "         1.1243e-03,  4.7040e-04, -1.7483e-03,  1.4065e-03,  3.0161e-04,\n",
            "        -1.8559e-03, -3.4504e-04, -1.7323e-03,  1.3320e-03,  3.4110e-04,\n",
            "         5.9136e-04,  7.0733e-05, -1.3188e-03, -4.0452e-05, -2.4935e-04,\n",
            "        -1.5768e-03,  2.0665e-03, -1.4252e-03,  4.4269e-04,  2.0091e-05,\n",
            "        -1.2964e-03,  1.8900e-05, -1.9190e-03,  5.9415e-04, -1.0174e-03,\n",
            "         1.2470e-04,  5.0630e-04,  1.5276e-03, -8.5134e-04, -1.1100e-03,\n",
            "        -7.1674e-05,  8.4318e-05,  3.2648e-03,  3.5118e-04, -2.7699e-04,\n",
            "        -2.4488e-03,  3.0341e-03, -1.0546e-03,  1.8689e-03, -1.8130e-03,\n",
            "         1.4726e-03, -1.4788e-03, -1.0575e-05, -4.6826e-04, -4.7957e-04,\n",
            "        -4.5560e-04, -1.2120e-03,  1.1712e-03, -7.2632e-04, -4.5371e-04,\n",
            "         3.3153e-04, -7.4188e-04,  2.3150e-04, -1.3932e-03, -1.1275e-03,\n",
            "        -1.2528e-04, -2.7634e-04,  5.4358e-04, -7.1357e-04,  2.5971e-05,\n",
            "         8.1060e-04, -1.4663e-03, -1.2366e-03,  2.2357e-03, -3.3618e-04,\n",
            "         7.9960e-04, -8.5630e-05,  1.2265e-03,  2.4225e-03,  5.2650e-04,\n",
            "        -9.8858e-04,  5.6164e-04,  1.5634e-03,  9.7626e-04, -1.2388e-03,\n",
            "        -1.5251e-03,  4.6897e-04,  5.2800e-04])}, 39: {'momentum_buffer': tensor([[[[ 1.8123e-04]],\n",
            "\n",
            "         [[-6.1234e-04]],\n",
            "\n",
            "         [[ 4.4619e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2925e-03]],\n",
            "\n",
            "         [[-3.6902e-04]],\n",
            "\n",
            "         [[-1.7050e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.8684e-03]],\n",
            "\n",
            "         [[ 1.5393e-03]],\n",
            "\n",
            "         [[ 1.9412e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6272e-03]],\n",
            "\n",
            "         [[ 6.5163e-04]],\n",
            "\n",
            "         [[ 1.7043e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.1165e-03]],\n",
            "\n",
            "         [[ 1.5262e-03]],\n",
            "\n",
            "         [[ 5.8260e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.4144e-04]],\n",
            "\n",
            "         [[-1.0078e-03]],\n",
            "\n",
            "         [[-1.5019e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1232e-03]],\n",
            "\n",
            "         [[-7.3496e-04]],\n",
            "\n",
            "         [[-1.6366e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.2768e-05]],\n",
            "\n",
            "         [[ 4.5482e-04]],\n",
            "\n",
            "         [[ 1.6283e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.4298e-04]],\n",
            "\n",
            "         [[-3.6799e-04]],\n",
            "\n",
            "         [[ 6.6099e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.6027e-04]],\n",
            "\n",
            "         [[ 8.4786e-04]],\n",
            "\n",
            "         [[ 1.4910e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 9.1851e-04]],\n",
            "\n",
            "         [[ 3.4487e-04]],\n",
            "\n",
            "         [[-1.5746e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.8162e-04]],\n",
            "\n",
            "         [[-2.7083e-04]],\n",
            "\n",
            "         [[-3.5136e-05]]]])}, 40: {'momentum_buffer': tensor([ 1.0640e-03,  1.6019e-03, -5.7171e-05,  1.1912e-03,  1.5457e-03,\n",
            "         2.4347e-03,  9.0863e-04,  1.7400e-03,  9.9111e-04,  1.4326e-03,\n",
            "         1.1377e-03, -3.3161e-04, -1.4465e-03,  2.0880e-03,  9.6700e-04,\n",
            "         8.0281e-05,  1.2414e-03,  9.0242e-06,  1.7042e-04, -8.2612e-05,\n",
            "         1.2604e-03,  1.1716e-03,  5.8404e-04,  7.5641e-04,  2.1541e-03,\n",
            "         2.0090e-03, -8.1804e-05,  1.7200e-03,  1.4183e-03,  2.7997e-03,\n",
            "         2.0080e-03,  1.1063e-03,  1.0747e-03,  1.2392e-03,  3.0488e-04,\n",
            "         1.0721e-03,  2.4148e-03,  1.1093e-03,  1.0051e-03,  1.7891e-03,\n",
            "         7.6934e-04,  1.1222e-03,  2.8457e-04,  1.5788e-03,  1.4911e-04,\n",
            "         4.1978e-04,  1.2107e-03,  1.2307e-03,  2.8212e-03,  6.9019e-04,\n",
            "         2.4253e-04,  1.4325e-03, -1.7374e-03,  2.3898e-03,  2.3746e-03,\n",
            "         1.1144e-03, -5.8949e-04,  2.5579e-03, -5.3747e-04,  5.8931e-05,\n",
            "         1.1928e-03,  7.2975e-04,  6.0372e-04,  1.1832e-03,  8.3912e-04,\n",
            "         8.4622e-04,  1.5000e-03,  2.2536e-03,  1.3573e-03,  1.3840e-03,\n",
            "         4.8662e-04, -2.3475e-04, -1.2656e-04,  1.4101e-03,  4.8325e-05,\n",
            "         1.2443e-03,  1.0891e-03,  1.6300e-04,  1.3738e-04, -2.1581e-04,\n",
            "         6.4344e-04,  7.1928e-04,  2.1504e-03,  1.4802e-03,  1.3893e-04,\n",
            "         8.0998e-04, -6.6029e-06,  1.8011e-03, -2.4981e-04,  5.0810e-04,\n",
            "         1.3204e-03,  1.3012e-03,  1.4254e-03,  1.5544e-03,  2.3543e-03,\n",
            "         1.9927e-03,  1.1729e-03,  5.4812e-04,  1.8146e-03,  9.7997e-04,\n",
            "         1.1698e-03,  5.7204e-04,  5.7562e-04,  1.6885e-03,  1.7614e-03,\n",
            "         1.3346e-03,  2.7238e-03,  2.3822e-03,  6.2920e-04,  1.4475e-03,\n",
            "         1.9049e-03,  1.4473e-03,  1.4413e-03,  1.4342e-03,  1.5997e-03,\n",
            "         5.5950e-04,  4.3659e-04,  6.2056e-04,  7.6190e-04,  1.4758e-04,\n",
            "         1.5698e-03,  1.8370e-03,  7.7292e-04,  1.7936e-03,  9.8021e-04,\n",
            "         9.0596e-04,  1.7684e-03,  1.6296e-03,  2.1499e-03,  3.1963e-03,\n",
            "        -1.1731e-04,  6.7129e-04,  8.2225e-06,  6.4478e-04,  1.6573e-03,\n",
            "         7.3145e-04, -1.5734e-03,  1.6368e-04,  1.9795e-03,  2.3615e-03,\n",
            "         5.9921e-04,  1.3910e-03,  1.3426e-03,  4.1310e-04,  1.0724e-03,\n",
            "        -2.6647e-03,  6.3790e-04,  1.9361e-03,  6.1706e-04,  6.5566e-04,\n",
            "         1.1489e-03,  1.4194e-04, -7.5133e-04,  1.1740e-03,  2.3912e-03,\n",
            "         8.5079e-04,  2.0696e-03, -1.6615e-04,  2.1542e-04,  5.7391e-04,\n",
            "         9.2812e-04,  1.3166e-03,  6.0836e-04, -4.4882e-04,  2.1763e-03,\n",
            "         7.2091e-04,  1.4259e-03,  1.5467e-03, -6.9895e-05, -7.8241e-05,\n",
            "         1.7121e-03,  1.8280e-03,  1.5791e-05,  1.4876e-03,  1.3994e-03,\n",
            "         1.1778e-03,  1.3015e-03,  1.3473e-03,  1.5509e-03,  5.0136e-04,\n",
            "         1.2455e-03, -8.8200e-04,  6.1372e-04,  1.2565e-03,  2.6404e-04,\n",
            "         1.1185e-03,  2.2748e-03,  3.3592e-04,  1.1395e-04,  1.7936e-03,\n",
            "         2.3387e-04,  1.9576e-03,  9.9310e-04,  1.4071e-03,  1.0366e-03,\n",
            "         1.1502e-03,  9.5883e-04, -4.9061e-04, -1.6021e-04,  9.2019e-04,\n",
            "         1.0376e-03,  1.2444e-03,  1.2944e-03,  8.3413e-04,  6.5738e-04,\n",
            "         2.0661e-03,  1.4305e-03,  7.8443e-04,  2.3643e-04,  7.6213e-04,\n",
            "         5.5933e-04,  1.3788e-03,  2.0340e-03,  1.4471e-03,  1.0948e-03,\n",
            "         1.0011e-03,  1.3566e-03,  6.5680e-04,  2.1199e-03,  7.5170e-04,\n",
            "         1.2658e-03, -8.1244e-05,  1.8563e-03,  1.6506e-03,  1.4290e-03,\n",
            "         1.7140e-04,  1.2622e-03, -1.0571e-04,  6.3131e-04,  3.4425e-04,\n",
            "         5.1959e-04,  1.4121e-03,  1.1549e-03,  5.3745e-04,  8.6871e-04,\n",
            "         1.5128e-03,  2.6355e-04,  1.3602e-04,  8.3587e-04,  5.0741e-04,\n",
            "         1.6378e-03,  1.6506e-03,  1.1783e-04,  7.5037e-04,  1.2034e-03,\n",
            "         1.2403e-03,  1.7977e-03,  2.9629e-04,  8.4734e-04,  7.7182e-04,\n",
            "         1.1101e-03,  1.7926e-03,  6.2340e-04,  6.2248e-04,  5.3577e-04,\n",
            "         1.1191e-03,  4.0107e-04, -3.8589e-04, -2.0872e-05,  7.2059e-04,\n",
            "         1.1903e-03,  1.3900e-03,  1.5960e-03,  1.8156e-04,  5.4807e-04,\n",
            "         9.7273e-04, -3.7775e-04,  7.5960e-04,  1.5309e-04,  2.3615e-03,\n",
            "         4.8640e-04,  2.3292e-03,  9.2542e-04,  9.0074e-04,  1.9899e-03,\n",
            "         2.8436e-03,  1.2663e-03, -3.6854e-04,  8.2064e-04,  6.9087e-04,\n",
            "         1.5904e-03, -1.1184e-03,  1.2211e-03,  6.6914e-04,  1.6028e-03,\n",
            "         2.0255e-03,  1.2346e-03,  2.6471e-03,  2.1639e-03,  1.1529e-03,\n",
            "         1.0798e-03,  6.2831e-04,  1.8584e-03,  8.1257e-04,  1.4357e-03,\n",
            "         1.8842e-03,  2.7770e-03, -2.6559e-04,  1.0891e-03,  2.0962e-03,\n",
            "         7.9933e-04, -3.3417e-04,  1.0608e-04,  1.6661e-03,  5.9727e-04,\n",
            "         2.5171e-03,  1.9887e-03,  5.6023e-04,  1.7107e-03,  1.1018e-03,\n",
            "         1.1721e-03,  2.6193e-03,  2.5250e-03, -2.1782e-05,  1.3691e-03,\n",
            "         2.0223e-04, -6.6217e-04,  8.1418e-04, -3.0426e-04,  6.0364e-04,\n",
            "         1.3051e-03,  1.1703e-03,  8.1182e-04,  1.0965e-03, -1.2435e-04,\n",
            "         1.8114e-03,  6.5623e-04,  7.9481e-04,  1.5238e-03, -1.5064e-04,\n",
            "         1.8795e-03,  6.9589e-04,  1.7317e-03,  1.8668e-03,  2.0380e-03,\n",
            "        -1.3167e-03,  6.8857e-04,  1.1189e-03,  1.6303e-03,  7.7721e-04,\n",
            "         1.4294e-03,  1.7961e-03,  2.9587e-04,  1.3098e-03, -5.0406e-05,\n",
            "         8.7311e-04,  1.0192e-03,  1.0276e-03,  1.5721e-03,  1.0637e-03,\n",
            "         3.0491e-04,  9.6944e-04,  2.7441e-03,  7.3278e-04,  1.3285e-03,\n",
            "         2.3992e-03,  8.0329e-04,  1.3420e-03,  1.2819e-03,  1.7935e-03,\n",
            "         1.2416e-03, -6.2700e-05,  2.2049e-03,  1.8697e-03,  1.7456e-04,\n",
            "         2.8916e-03, -1.6561e-04,  7.3464e-04,  1.2525e-03,  7.3828e-04,\n",
            "         1.9798e-03,  1.6003e-03,  2.3909e-04, -7.0138e-04, -4.8281e-04,\n",
            "         8.5928e-04,  4.3271e-04,  1.7663e-03,  1.8274e-03, -2.2178e-05,\n",
            "         9.0197e-04,  2.0973e-03,  1.3096e-03,  1.5350e-03,  2.1786e-03,\n",
            "        -1.5466e-04, -1.0160e-04,  1.2968e-03, -3.2769e-05,  4.0127e-04,\n",
            "         1.0039e-03,  1.3782e-03, -2.2288e-04,  1.2878e-03,  4.1359e-05,\n",
            "        -2.4059e-04,  2.8093e-05,  1.3768e-03,  1.5607e-03,  9.7724e-04,\n",
            "         8.0608e-05,  8.4287e-04,  1.9329e-03,  6.7499e-04,  1.9727e-04,\n",
            "        -1.1542e-04,  1.6303e-03,  1.8377e-03,  1.6184e-03,  6.6081e-04,\n",
            "         1.5612e-03,  1.9493e-03,  2.2021e-03,  1.2909e-03, -6.1509e-05,\n",
            "        -1.4937e-03,  1.5821e-03,  1.4944e-03,  5.6221e-04,  5.0828e-04,\n",
            "         1.2689e-04,  1.4887e-03,  5.0069e-04,  6.0039e-04, -7.4914e-04,\n",
            "         2.7107e-04,  1.5202e-03,  2.8275e-03,  1.0201e-03,  3.2660e-03,\n",
            "         1.4287e-03,  9.8220e-04,  9.8965e-04,  6.9660e-04,  7.9421e-04,\n",
            "         9.9605e-04,  1.4153e-03,  3.9925e-04,  4.0780e-04,  6.0736e-04,\n",
            "         1.8813e-04,  1.4388e-03, -7.8305e-04,  1.3737e-04,  1.8749e-03,\n",
            "         8.9698e-04,  1.5018e-03,  2.3075e-03,  8.1847e-04,  5.8736e-04,\n",
            "         7.0004e-04,  8.8351e-04,  1.0066e-03,  2.0060e-04,  1.6185e-03,\n",
            "         1.6754e-03,  1.4981e-03,  1.1610e-03, -5.0340e-05,  7.9816e-04,\n",
            "         3.3897e-05,  3.0482e-04,  1.2548e-03,  6.5718e-04,  9.1730e-04,\n",
            "         6.0575e-04,  1.6910e-03,  2.3864e-03,  2.3695e-03,  5.0298e-04,\n",
            "         1.7175e-03,  7.1651e-04, -1.3016e-04,  1.7757e-03,  1.4352e-03,\n",
            "         1.1721e-03,  5.7914e-04,  2.6272e-04,  1.6366e-03,  1.7233e-03,\n",
            "         7.9278e-04,  9.9755e-05,  5.7544e-04,  7.2173e-04, -1.6833e-04,\n",
            "         7.9730e-04,  1.5147e-03,  1.3359e-03,  7.4091e-04,  3.0510e-03,\n",
            "         2.0044e-04,  4.2446e-04,  3.1742e-04, -3.8657e-04, -4.0687e-04,\n",
            "         2.7566e-03,  2.0795e-03,  2.5894e-04,  6.8039e-04,  1.2075e-03,\n",
            "         3.6233e-04,  4.9753e-04,  3.4402e-04,  1.2959e-03,  3.6543e-04,\n",
            "         1.5257e-03,  1.1877e-03,  2.1515e-03, -4.7814e-05,  1.9447e-03,\n",
            "        -4.0146e-04,  3.5881e-04])}, 41: {'momentum_buffer': tensor([-8.5161e-04, -4.9480e-04, -1.1530e-04,  7.7038e-04, -6.5719e-04,\n",
            "        -4.4822e-05, -1.1662e-03,  6.4363e-05, -1.4079e-04, -7.7003e-04,\n",
            "         7.4992e-05, -9.3250e-04, -1.0464e-04, -1.1221e-03,  7.0285e-05,\n",
            "         2.0114e-05, -2.7335e-04, -7.3694e-04, -4.4631e-04, -5.1684e-04,\n",
            "         2.6924e-04,  3.2296e-04,  6.5658e-04, -4.7196e-04,  1.5325e-03,\n",
            "         8.5040e-05,  3.3538e-04,  2.9662e-04, -5.5924e-04,  1.1041e-03,\n",
            "         3.4792e-04, -7.7726e-04, -3.8971e-04,  3.4775e-04, -2.1924e-05,\n",
            "        -1.6745e-06,  5.2998e-04,  1.3252e-03, -3.8091e-04, -1.6937e-04,\n",
            "        -1.0857e-03,  3.6655e-04, -7.3534e-04,  8.4764e-04, -3.7084e-04,\n",
            "        -7.5315e-04,  5.2934e-04, -1.6110e-05,  8.7238e-04,  2.8917e-04,\n",
            "         4.5799e-04,  4.1015e-04,  9.9187e-06,  4.8696e-06,  9.7584e-04,\n",
            "        -6.9876e-05, -1.0854e-03,  9.4248e-04, -2.9988e-04, -1.4013e-04,\n",
            "         1.5239e-04, -7.4869e-04,  2.9495e-04,  3.0175e-04,  6.0550e-04,\n",
            "         5.9391e-05,  9.3933e-05,  7.7528e-04,  3.0202e-04, -1.2024e-04,\n",
            "        -1.2242e-03, -4.9894e-04, -1.3703e-03,  5.4961e-04, -5.0169e-04,\n",
            "        -4.2628e-05, -2.3861e-04, -7.9037e-04,  5.3334e-04, -3.0760e-04,\n",
            "        -9.1963e-06, -3.1367e-04,  3.1836e-04,  8.2341e-04, -9.9009e-04,\n",
            "         3.7926e-04,  3.0083e-04,  3.1255e-04, -1.2331e-03, -3.4787e-04,\n",
            "         2.2781e-04,  5.6035e-04,  3.7738e-04,  1.7971e-04, -5.3282e-04,\n",
            "        -3.0426e-04,  4.8922e-04, -2.3005e-04,  3.3310e-04, -6.9248e-04,\n",
            "         5.3008e-04,  7.1017e-04, -6.3543e-05,  4.1248e-04,  1.1646e-03,\n",
            "         6.8221e-05,  3.0930e-04,  6.9225e-05, -8.4450e-04,  5.2428e-05,\n",
            "         1.2312e-03,  8.6390e-04,  5.3517e-06,  5.6893e-04,  7.5187e-04,\n",
            "        -8.5178e-04, -5.6023e-04, -8.4561e-04, -9.3061e-04, -2.7097e-04,\n",
            "         6.5903e-04,  3.0677e-04, -7.4606e-04,  1.0877e-03, -5.1623e-04,\n",
            "         3.3717e-04,  3.1896e-04,  2.1036e-04,  1.2214e-03,  4.4698e-04,\n",
            "         5.1510e-04, -5.6746e-04, -9.0618e-05, -5.5262e-04, -3.5318e-04,\n",
            "         1.7911e-04, -1.1693e-03, -6.9296e-04,  8.2561e-04,  5.0149e-04,\n",
            "        -1.8561e-04,  5.7619e-04, -2.4870e-04, -7.0974e-04,  3.4012e-05,\n",
            "        -1.3741e-03,  8.9445e-04,  6.0763e-04,  5.1369e-04,  6.6656e-05,\n",
            "        -4.7245e-04, -1.2008e-04, -1.1035e-03,  1.2075e-03,  2.7815e-04,\n",
            "         4.1386e-04,  7.2846e-04, -6.5650e-04, -1.1950e-04, -6.3905e-08,\n",
            "        -3.1406e-04,  1.0133e-03, -2.0543e-04, -1.9123e-04,  3.9158e-06,\n",
            "         1.6319e-04,  3.9812e-04,  3.8702e-04, -2.7915e-04,  1.0028e-04,\n",
            "         2.6726e-05,  1.4326e-04, -1.6540e-03,  5.6615e-04,  4.0008e-05,\n",
            "        -1.1592e-04,  1.1253e-04,  7.4471e-04, -9.2278e-05, -9.7000e-04,\n",
            "         8.2529e-05, -4.0472e-04, -4.8522e-04, -3.7462e-04,  4.7133e-05,\n",
            "        -8.3891e-04,  1.1609e-03, -9.0800e-04, -1.3669e-03, -7.3941e-05,\n",
            "         4.8631e-05,  4.5709e-04, -3.6955e-04, -7.0810e-04,  1.4870e-04,\n",
            "         6.0378e-04, -3.9749e-04, -4.8262e-04, -1.5296e-03,  1.0968e-03,\n",
            "         1.2013e-03,  4.4868e-04, -1.3521e-04, -6.2716e-04,  3.8032e-04,\n",
            "         7.0348e-04,  1.8071e-03,  1.1177e-04, -5.7361e-04,  3.0921e-04,\n",
            "        -5.5434e-04,  1.8537e-04,  3.4435e-04,  2.9622e-04, -3.2477e-04,\n",
            "        -3.0371e-04, -4.4515e-05,  3.9315e-05,  4.7673e-04,  5.8296e-04,\n",
            "         1.9245e-04, -9.3445e-04,  6.3417e-04,  1.0126e-03,  1.7398e-04,\n",
            "        -9.5770e-04, -6.2675e-05, -4.9293e-04, -8.8471e-05,  6.7095e-04,\n",
            "        -4.0039e-04,  2.3759e-04,  9.4250e-04, -5.9890e-04,  1.6485e-03,\n",
            "         3.9129e-04, -4.8810e-04, -2.9536e-04, -2.4869e-05, -5.1510e-04,\n",
            "         8.9127e-04,  8.9376e-04, -1.0672e-03,  1.0656e-04,  6.4483e-04,\n",
            "        -1.0680e-04, -5.4131e-04, -7.4342e-04,  1.9197e-04, -3.2331e-05,\n",
            "        -1.0917e-03,  4.0487e-04, -9.5670e-04,  1.1213e-04,  3.7530e-04,\n",
            "        -5.0328e-04,  1.1588e-04,  4.1102e-04,  1.8755e-04,  7.0041e-04,\n",
            "         3.7135e-04,  2.0533e-04, -1.8188e-04, -1.7163e-04, -2.5299e-05,\n",
            "         4.2371e-04, -3.6242e-04, -4.3762e-04, -2.9364e-04, -3.6847e-04,\n",
            "        -6.4159e-05,  7.0734e-04,  4.0270e-04, -8.5496e-04, -7.1328e-05,\n",
            "         6.6931e-04,  7.7168e-04,  5.2824e-04, -9.0266e-04, -6.5670e-04,\n",
            "         4.4493e-04, -1.3176e-03, -2.4776e-04,  3.8882e-05,  1.1188e-03,\n",
            "         1.1175e-03, -5.0450e-04,  3.9076e-04,  5.1078e-05,  1.1234e-03,\n",
            "        -3.1960e-04,  5.0551e-04,  3.0823e-04, -1.8896e-04,  1.7487e-04,\n",
            "         9.7954e-05, -9.6382e-04,  5.8985e-05,  1.1608e-03,  9.2576e-04,\n",
            "        -4.7223e-04, -1.0241e-03, -7.2309e-04,  1.2682e-03, -2.5265e-04,\n",
            "         1.8972e-04, -5.2990e-04,  1.2506e-03,  2.4508e-04,  6.2602e-04,\n",
            "         7.5455e-05,  2.3959e-04,  1.7572e-04,  9.0479e-04,  4.3037e-04,\n",
            "        -1.2698e-04,  1.4077e-05,  1.5765e-04,  3.6787e-04,  3.4693e-04,\n",
            "        -2.7434e-05, -1.3821e-03, -7.8800e-04, -9.6329e-04, -6.4639e-04,\n",
            "         1.6668e-03,  1.9437e-04,  7.2730e-04,  5.1351e-04, -5.4040e-04,\n",
            "         7.8165e-04,  3.0466e-04,  7.7736e-04,  4.9183e-04,  6.4722e-04,\n",
            "        -1.0313e-03, -3.2927e-04, -5.2831e-04,  4.6687e-04, -2.4626e-04,\n",
            "        -1.4248e-03,  5.6045e-04, -2.6590e-04, -3.1295e-04, -1.2532e-05,\n",
            "        -2.9990e-05,  2.4174e-04, -5.4933e-04,  3.7049e-04,  2.2290e-04,\n",
            "         8.1097e-04, -3.8752e-04,  1.3767e-03, -1.5125e-04,  2.8065e-04,\n",
            "         1.7882e-03, -7.7361e-05,  1.2936e-03, -1.8691e-04,  1.0098e-03,\n",
            "         5.9047e-04,  3.2373e-04, -2.3707e-04, -8.0307e-04,  5.0939e-05,\n",
            "         1.6870e-03,  2.5004e-04, -5.2055e-04,  1.6911e-04, -2.9625e-04,\n",
            "         3.9845e-04,  7.4636e-04, -1.0016e-03, -4.1069e-04, -1.6246e-04,\n",
            "        -3.5090e-05, -1.2250e-04,  6.2051e-04, -2.9266e-04, -4.0637e-04,\n",
            "        -2.4700e-04,  1.3188e-04,  2.8232e-04,  7.8414e-04,  5.2694e-04,\n",
            "        -5.5167e-04, -1.6080e-03, -1.1226e-04, -1.0200e-05,  2.7088e-04,\n",
            "         1.0567e-03,  6.7102e-04, -5.8488e-05, -6.8752e-05, -6.9560e-04,\n",
            "        -1.4337e-03, -3.2359e-04, -5.8899e-04,  1.4835e-03,  1.9255e-04,\n",
            "         2.8007e-04, -9.8018e-04,  3.8370e-04,  5.5256e-04, -6.4784e-04,\n",
            "        -1.1104e-03,  1.6624e-03,  3.4598e-04,  5.8124e-04,  9.2813e-04,\n",
            "        -4.3714e-04,  5.4573e-04,  7.6372e-04, -4.1580e-04,  6.3716e-04,\n",
            "         3.5521e-05,  4.3251e-04,  6.4763e-04,  9.7514e-06, -3.7453e-04,\n",
            "         9.7054e-04,  9.1869e-04,  3.0442e-04, -7.5316e-04, -5.5061e-04,\n",
            "        -9.5218e-04, -4.2662e-05, -2.2667e-04,  7.9791e-04,  4.2668e-04,\n",
            "         9.3952e-05, -1.9247e-04, -6.7990e-04, -4.0246e-04, -1.7736e-03,\n",
            "         7.5342e-04, -2.6263e-04,  7.7191e-04,  2.3654e-04, -2.8014e-04,\n",
            "        -6.9173e-04,  3.8573e-04, -6.5954e-04, -2.4863e-04, -4.3199e-04,\n",
            "        -7.1882e-04,  5.7670e-04, -4.4272e-04,  4.5116e-04, -3.0380e-04,\n",
            "        -1.6135e-04,  3.7292e-04, -8.4513e-04, -9.8158e-04, -5.6820e-04,\n",
            "         1.1200e-04,  3.3343e-04,  4.4024e-04,  7.6372e-05,  3.3612e-04,\n",
            "         9.1443e-05, -8.6752e-04,  2.0726e-04, -6.6425e-04,  1.0829e-04,\n",
            "        -1.1520e-03,  3.9492e-04,  5.8189e-04,  4.5209e-04,  4.2020e-04,\n",
            "         6.0833e-04,  3.3267e-04,  7.2028e-04, -1.9779e-05, -3.1881e-04,\n",
            "         4.1150e-05, -5.3294e-04,  1.3234e-04,  2.3186e-04,  9.0306e-04,\n",
            "        -7.9166e-04, -4.4746e-05,  4.8580e-04, -9.9357e-05, -2.3294e-04,\n",
            "        -4.9985e-04,  1.1426e-04, -1.0651e-03, -3.3316e-04,  2.2456e-04,\n",
            "        -1.0094e-04, -4.1765e-04,  3.3855e-04, -2.5078e-04,  2.3616e-04,\n",
            "         7.7314e-05,  4.6037e-04, -3.7874e-04,  5.3020e-04,  9.7153e-04,\n",
            "        -1.8035e-05, -5.0143e-04, -5.9046e-04,  6.2844e-04,  3.0317e-04,\n",
            "         8.7305e-04, -3.4956e-04,  3.2898e-04, -6.9637e-04,  9.7761e-04,\n",
            "        -5.6421e-04, -2.8823e-04])}, 42: {'momentum_buffer': tensor([[[[ 4.3047e-04]],\n",
            "\n",
            "         [[-3.1027e-04]],\n",
            "\n",
            "         [[ 2.4927e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7164e-04]],\n",
            "\n",
            "         [[-2.4310e-04]],\n",
            "\n",
            "         [[ 2.7594e-04]]],\n",
            "\n",
            "\n",
            "        [[[-6.8217e-04]],\n",
            "\n",
            "         [[ 3.9909e-04]],\n",
            "\n",
            "         [[ 6.6712e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4061e-04]],\n",
            "\n",
            "         [[-2.8088e-04]],\n",
            "\n",
            "         [[-1.0994e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.8287e-04]],\n",
            "\n",
            "         [[-1.3043e-03]],\n",
            "\n",
            "         [[-1.8928e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.6621e-04]],\n",
            "\n",
            "         [[-8.5680e-04]],\n",
            "\n",
            "         [[-2.4000e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.8928e-04]],\n",
            "\n",
            "         [[-2.0571e-04]],\n",
            "\n",
            "         [[ 5.1719e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9394e-05]],\n",
            "\n",
            "         [[-8.8134e-04]],\n",
            "\n",
            "         [[-7.8810e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.5365e-05]],\n",
            "\n",
            "         [[ 8.5389e-04]],\n",
            "\n",
            "         [[ 1.7679e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.5379e-04]],\n",
            "\n",
            "         [[ 7.1969e-04]],\n",
            "\n",
            "         [[ 1.4264e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.5134e-04]],\n",
            "\n",
            "         [[ 2.6236e-04]],\n",
            "\n",
            "         [[-1.9232e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4353e-03]],\n",
            "\n",
            "         [[-4.7792e-04]],\n",
            "\n",
            "         [[-4.1637e-04]]]])}, 43: {'momentum_buffer': tensor([-5.2992e-05, -3.4312e-04,  8.1336e-04,  1.4019e-03, -3.5314e-04,\n",
            "         8.1616e-04,  1.5715e-03,  5.2595e-04,  1.7451e-03,  2.2963e-04,\n",
            "        -1.8066e-04,  6.1653e-04,  1.8407e-03,  3.8223e-04,  4.6418e-04,\n",
            "         2.4404e-03, -1.1481e-04,  6.4852e-04, -1.9094e-04,  5.5662e-04,\n",
            "         1.5182e-03,  5.6605e-04,  1.5016e-03,  2.0264e-05,  1.8044e-03,\n",
            "         1.4228e-04,  2.2766e-03,  2.2606e-04,  3.3877e-04, -5.4856e-05,\n",
            "         5.2018e-04,  2.4629e-04,  1.4136e-03,  1.4297e-03,  1.6629e-03,\n",
            "         7.9017e-04,  1.0984e-03,  1.9433e-03,  5.8372e-04, -3.4140e-04,\n",
            "        -2.5520e-05,  2.2278e-03,  8.8855e-04,  8.8685e-04,  1.2328e-03,\n",
            "         1.6305e-03,  1.4417e-03,  1.1354e-04,  1.0265e-03,  2.4989e-03,\n",
            "         9.5677e-04,  1.3789e-03,  1.5847e-03,  1.1048e-04,  1.7631e-03,\n",
            "         1.5660e-03,  1.0333e-03,  6.9922e-04,  9.5446e-04,  8.0298e-04,\n",
            "         2.3796e-04,  5.8158e-04,  2.1655e-03,  1.6191e-03,  1.8079e-03,\n",
            "         7.4298e-04,  8.0627e-04,  9.5839e-04,  1.1071e-03,  2.0077e-03,\n",
            "         1.9214e-04,  9.1374e-04,  4.3365e-04,  1.0515e-03,  1.2602e-03,\n",
            "         6.6881e-04,  7.2755e-04,  4.8722e-04,  6.3496e-04,  6.5558e-04,\n",
            "         1.3138e-03,  5.7359e-04,  5.3720e-04,  1.1697e-03,  1.1172e-03,\n",
            "         1.0525e-03,  7.7132e-04,  6.7158e-04, -1.1462e-03,  5.4354e-04,\n",
            "        -1.1588e-04,  1.6324e-03,  1.0455e-03,  4.0603e-04,  4.9492e-04,\n",
            "         1.7620e-03,  8.7597e-04,  9.6664e-04,  5.9033e-04,  7.1579e-04,\n",
            "         2.5298e-03,  1.1175e-03,  7.2333e-04,  6.0546e-04,  2.4141e-03,\n",
            "         1.0431e-03,  1.6983e-03,  1.2278e-03,  2.8555e-04,  9.2015e-04,\n",
            "         1.2317e-03,  4.9208e-04,  3.4177e-04,  1.5484e-03,  2.3608e-03,\n",
            "         7.0128e-05,  2.1901e-04,  4.5694e-04,  2.4564e-04,  1.3622e-03,\n",
            "         1.5727e-03,  9.2526e-04,  2.5254e-04,  2.4492e-03,  4.5897e-04,\n",
            "         1.3992e-03,  1.4365e-03,  1.6280e-03,  1.3092e-03,  1.3245e-03,\n",
            "         1.5889e-03,  1.2611e-03,  1.7650e-03,  8.2828e-04,  1.1510e-03,\n",
            "         5.3067e-04, -7.7753e-04,  8.0973e-04,  1.2467e-03,  1.5398e-03,\n",
            "         3.1643e-04,  1.2821e-03,  7.2509e-04,  3.5174e-04,  1.4422e-03,\n",
            "        -2.8399e-04,  9.6388e-04,  9.5109e-04,  1.3790e-03,  2.5690e-03,\n",
            "         5.8680e-04,  7.8770e-04,  8.0836e-04,  2.5439e-03,  1.4265e-03,\n",
            "         2.0145e-03,  1.0725e-03,  2.4568e-04,  7.8999e-04,  2.1288e-03,\n",
            "         9.5832e-04,  1.4752e-03,  1.0358e-03,  1.5173e-03, -2.1181e-05,\n",
            "         1.3252e-03,  1.0480e-03,  1.2038e-03,  5.8273e-04,  1.5141e-03,\n",
            "         3.3300e-04,  5.6058e-04,  1.6893e-04,  7.7368e-04,  1.4476e-03,\n",
            "        -3.2919e-04,  1.6334e-03,  1.0198e-03,  1.5057e-03,  1.4874e-03,\n",
            "         1.5454e-03,  2.9106e-04,  1.0526e-03,  8.0154e-04,  1.8079e-03,\n",
            "         6.4544e-04,  2.4063e-03,  6.3632e-04,  7.9555e-05,  2.8172e-04,\n",
            "         7.9639e-04,  8.7407e-04,  1.6486e-03,  1.8741e-04,  4.3712e-04,\n",
            "         1.0372e-03,  1.0689e-03,  1.2832e-03,  3.3064e-04,  5.9977e-04,\n",
            "         1.7579e-03, -3.4488e-04,  1.0305e-03,  2.7229e-04,  6.3486e-04,\n",
            "         1.6774e-03,  2.3073e-03,  2.1114e-03, -7.5469e-05,  1.4759e-03,\n",
            "        -6.4021e-05,  9.6301e-04,  9.8699e-04,  2.4372e-03,  5.6899e-04,\n",
            "         1.1975e-03,  7.3864e-04,  1.5704e-03,  6.2261e-04,  2.9379e-03,\n",
            "         1.0419e-03,  9.3612e-04,  1.1799e-03,  1.1936e-03,  4.5971e-04,\n",
            "         2.6081e-04, -2.1957e-04,  1.0945e-03,  7.4124e-04,  1.7782e-03,\n",
            "         4.2651e-04,  4.3934e-04,  1.3958e-03,  1.3957e-03,  1.7140e-03,\n",
            "         1.6313e-03,  4.3318e-04,  1.7340e-03,  1.7123e-03,  3.5433e-04,\n",
            "         9.0802e-04,  1.2226e-03,  6.1765e-04,  6.7285e-04,  3.7159e-04,\n",
            "        -1.2000e-03, -3.0082e-04,  1.3703e-03,  7.8387e-04,  2.0879e-03,\n",
            "         1.6023e-04,  1.3059e-03,  1.4456e-04,  1.5268e-03, -6.2257e-05,\n",
            "         1.1779e-03,  6.4972e-04,  9.4318e-04,  1.4068e-03,  1.8215e-03,\n",
            "         2.1983e-03,  6.9668e-04,  6.5606e-04,  3.0492e-04,  1.1888e-03,\n",
            "         1.1744e-03,  2.8396e-03,  3.1208e-04, -8.5126e-04,  4.4516e-05,\n",
            "         1.4623e-03,  1.5963e-03,  1.5718e-03, -2.1083e-04, -5.2439e-05,\n",
            "         2.0437e-03,  2.3813e-03,  2.4762e-03,  1.2211e-03,  1.3407e-03,\n",
            "         9.5586e-04,  5.1507e-04,  1.1166e-03,  2.3480e-03,  1.9826e-03,\n",
            "         1.0510e-03,  3.7533e-04,  1.5937e-03,  2.0526e-03,  1.0697e-03,\n",
            "        -1.9147e-04,  1.9678e-03,  1.2404e-03,  1.2203e-03,  1.1291e-03,\n",
            "         4.8779e-04, -2.1630e-03,  2.2898e-03,  1.5777e-03,  5.7479e-04,\n",
            "         1.2407e-03,  1.4956e-03,  2.8249e-04,  2.2237e-03, -1.4074e-04,\n",
            "         9.1238e-04, -9.2099e-04,  2.4790e-03,  9.2300e-04, -1.8678e-04,\n",
            "         1.6869e-03,  1.2625e-03,  1.2066e-03,  2.4009e-03,  8.5541e-04,\n",
            "         1.3659e-03,  1.6334e-03,  1.6572e-03,  6.0374e-04,  6.1297e-04,\n",
            "         6.3369e-04, -6.9703e-04, -4.3853e-05,  9.9594e-04,  5.7141e-04,\n",
            "         4.2044e-03,  1.5008e-03,  1.7397e-03,  2.3389e-03,  8.6583e-04,\n",
            "         1.1931e-03,  1.7976e-03,  1.1621e-03,  1.8053e-03,  1.9325e-03,\n",
            "         2.5385e-03,  1.2432e-03,  9.2882e-04,  2.2803e-03,  4.9504e-04,\n",
            "        -5.4305e-04,  1.9524e-03,  1.6569e-03,  8.0569e-04,  1.1922e-03,\n",
            "         2.4184e-04,  1.5701e-03,  6.6460e-04,  5.1760e-04,  1.2789e-03,\n",
            "         1.3646e-03,  3.8779e-04,  1.0349e-03,  1.1284e-03,  9.5827e-04,\n",
            "         1.9517e-03,  1.4825e-03,  1.4533e-03,  9.5106e-04,  1.2823e-03,\n",
            "         1.3848e-03,  2.0851e-03,  1.9458e-04,  3.0032e-04,  1.4054e-03,\n",
            "         1.1836e-03,  1.8527e-03,  9.2270e-04,  9.3640e-04,  1.6699e-03,\n",
            "         7.7914e-04,  9.7391e-04, -9.4020e-05,  6.6701e-04,  1.0280e-03,\n",
            "         1.7857e-03,  2.1024e-03,  1.6606e-03,  2.8324e-04,  1.8564e-03,\n",
            "         9.1551e-05,  9.4319e-04,  1.1889e-03,  9.2457e-04,  1.3359e-03,\n",
            "         8.7183e-04, -1.3832e-03,  4.9276e-04,  1.0233e-03,  1.3148e-03,\n",
            "         2.4013e-03,  1.5196e-03,  8.4599e-04,  6.8057e-04,  1.4416e-03,\n",
            "         6.3558e-05,  3.7989e-04,  9.8617e-04,  1.9345e-03,  6.1404e-04,\n",
            "         1.3948e-03,  4.3303e-05,  2.2845e-03,  4.8006e-04,  8.6276e-04,\n",
            "        -5.5328e-04,  1.7770e-03,  2.0082e-05,  1.0747e-03,  2.3197e-03,\n",
            "         8.4869e-04,  4.3819e-04,  1.3163e-03,  1.3990e-03,  2.0572e-03,\n",
            "         1.9685e-03,  1.1153e-03,  1.0230e-03,  9.9896e-04,  1.9150e-03,\n",
            "         9.6350e-04,  1.8470e-03,  1.2331e-03, -1.9585e-04,  1.5211e-03,\n",
            "         1.6272e-04,  7.0276e-04, -5.7451e-05,  7.7083e-04, -3.5837e-04,\n",
            "         1.3494e-03,  1.0852e-03,  5.0098e-04,  3.0831e-04, -6.7952e-04,\n",
            "         1.1825e-03, -6.9393e-05,  2.1488e-03,  2.3366e-03, -2.4192e-04,\n",
            "         4.0847e-04,  1.6157e-03, -5.5775e-04,  1.6811e-03, -2.3884e-04,\n",
            "         2.1159e-04,  1.7449e-03, -1.4310e-03,  1.1611e-03,  6.0307e-04,\n",
            "         8.7762e-04,  8.0405e-04,  7.9669e-04,  4.3048e-04,  5.6422e-04,\n",
            "         1.6925e-04,  6.9114e-04,  1.0734e-03,  2.3745e-04,  6.3016e-04,\n",
            "         2.2965e-03,  1.1382e-03,  1.3118e-03,  5.6745e-04,  6.6031e-05,\n",
            "         1.4327e-03,  1.1477e-03,  3.1696e-03,  6.4539e-04,  1.1135e-03,\n",
            "         1.4098e-03,  5.4503e-04,  1.7616e-03, -2.6351e-04,  1.1331e-04,\n",
            "         1.1094e-03,  7.6178e-04,  1.3764e-03,  9.0268e-04,  1.0450e-03,\n",
            "         5.0096e-04,  1.0966e-03,  1.8277e-04,  1.3928e-03,  1.3429e-03,\n",
            "         1.1213e-03,  3.2534e-04, -3.6701e-04,  3.3040e-04, -1.2705e-04,\n",
            "         2.6499e-04,  1.8415e-04,  2.6379e-04,  8.4922e-04,  2.0331e-03,\n",
            "         2.8967e-04, -2.0589e-04,  1.7075e-03,  2.1627e-03,  2.5352e-03,\n",
            "         6.8793e-04,  9.1643e-05,  1.1528e-03,  8.7314e-04,  1.2397e-03,\n",
            "         1.1701e-03,  9.7087e-04,  1.0469e-03, -9.3778e-04,  1.7784e-03,\n",
            "         1.7838e-03,  9.9089e-04])}, 44: {'momentum_buffer': tensor([-8.5161e-04, -4.9480e-04, -1.1530e-04,  7.7038e-04, -6.5719e-04,\n",
            "        -4.4822e-05, -1.1662e-03,  6.4363e-05, -1.4079e-04, -7.7003e-04,\n",
            "         7.4992e-05, -9.3250e-04, -1.0464e-04, -1.1221e-03,  7.0285e-05,\n",
            "         2.0114e-05, -2.7335e-04, -7.3694e-04, -4.4631e-04, -5.1684e-04,\n",
            "         2.6924e-04,  3.2296e-04,  6.5658e-04, -4.7196e-04,  1.5325e-03,\n",
            "         8.5040e-05,  3.3538e-04,  2.9662e-04, -5.5924e-04,  1.1041e-03,\n",
            "         3.4792e-04, -7.7726e-04, -3.8971e-04,  3.4775e-04, -2.1924e-05,\n",
            "        -1.6745e-06,  5.2998e-04,  1.3252e-03, -3.8091e-04, -1.6937e-04,\n",
            "        -1.0857e-03,  3.6655e-04, -7.3534e-04,  8.4764e-04, -3.7084e-04,\n",
            "        -7.5315e-04,  5.2934e-04, -1.6110e-05,  8.7238e-04,  2.8917e-04,\n",
            "         4.5799e-04,  4.1015e-04,  9.9187e-06,  4.8696e-06,  9.7584e-04,\n",
            "        -6.9876e-05, -1.0854e-03,  9.4248e-04, -2.9988e-04, -1.4013e-04,\n",
            "         1.5239e-04, -7.4869e-04,  2.9495e-04,  3.0175e-04,  6.0550e-04,\n",
            "         5.9391e-05,  9.3933e-05,  7.7528e-04,  3.0202e-04, -1.2024e-04,\n",
            "        -1.2242e-03, -4.9894e-04, -1.3703e-03,  5.4961e-04, -5.0169e-04,\n",
            "        -4.2628e-05, -2.3861e-04, -7.9037e-04,  5.3334e-04, -3.0760e-04,\n",
            "        -9.1963e-06, -3.1367e-04,  3.1836e-04,  8.2341e-04, -9.9009e-04,\n",
            "         3.7926e-04,  3.0083e-04,  3.1255e-04, -1.2331e-03, -3.4787e-04,\n",
            "         2.2781e-04,  5.6035e-04,  3.7738e-04,  1.7971e-04, -5.3282e-04,\n",
            "        -3.0426e-04,  4.8922e-04, -2.3005e-04,  3.3310e-04, -6.9248e-04,\n",
            "         5.3008e-04,  7.1017e-04, -6.3543e-05,  4.1248e-04,  1.1646e-03,\n",
            "         6.8221e-05,  3.0930e-04,  6.9225e-05, -8.4450e-04,  5.2428e-05,\n",
            "         1.2312e-03,  8.6390e-04,  5.3517e-06,  5.6893e-04,  7.5187e-04,\n",
            "        -8.5178e-04, -5.6023e-04, -8.4561e-04, -9.3061e-04, -2.7097e-04,\n",
            "         6.5903e-04,  3.0677e-04, -7.4606e-04,  1.0877e-03, -5.1623e-04,\n",
            "         3.3717e-04,  3.1896e-04,  2.1036e-04,  1.2214e-03,  4.4698e-04,\n",
            "         5.1510e-04, -5.6746e-04, -9.0618e-05, -5.5262e-04, -3.5318e-04,\n",
            "         1.7911e-04, -1.1693e-03, -6.9296e-04,  8.2561e-04,  5.0149e-04,\n",
            "        -1.8561e-04,  5.7619e-04, -2.4870e-04, -7.0974e-04,  3.4012e-05,\n",
            "        -1.3741e-03,  8.9445e-04,  6.0763e-04,  5.1369e-04,  6.6656e-05,\n",
            "        -4.7245e-04, -1.2008e-04, -1.1035e-03,  1.2075e-03,  2.7815e-04,\n",
            "         4.1386e-04,  7.2846e-04, -6.5650e-04, -1.1950e-04, -6.3905e-08,\n",
            "        -3.1406e-04,  1.0133e-03, -2.0543e-04, -1.9123e-04,  3.9158e-06,\n",
            "         1.6319e-04,  3.9812e-04,  3.8702e-04, -2.7915e-04,  1.0028e-04,\n",
            "         2.6726e-05,  1.4326e-04, -1.6540e-03,  5.6615e-04,  4.0008e-05,\n",
            "        -1.1592e-04,  1.1253e-04,  7.4471e-04, -9.2278e-05, -9.7000e-04,\n",
            "         8.2529e-05, -4.0472e-04, -4.8522e-04, -3.7462e-04,  4.7133e-05,\n",
            "        -8.3891e-04,  1.1609e-03, -9.0800e-04, -1.3669e-03, -7.3941e-05,\n",
            "         4.8631e-05,  4.5709e-04, -3.6955e-04, -7.0810e-04,  1.4870e-04,\n",
            "         6.0378e-04, -3.9749e-04, -4.8262e-04, -1.5296e-03,  1.0968e-03,\n",
            "         1.2013e-03,  4.4868e-04, -1.3521e-04, -6.2716e-04,  3.8032e-04,\n",
            "         7.0348e-04,  1.8071e-03,  1.1177e-04, -5.7361e-04,  3.0921e-04,\n",
            "        -5.5434e-04,  1.8537e-04,  3.4435e-04,  2.9622e-04, -3.2477e-04,\n",
            "        -3.0371e-04, -4.4515e-05,  3.9315e-05,  4.7673e-04,  5.8296e-04,\n",
            "         1.9245e-04, -9.3445e-04,  6.3417e-04,  1.0126e-03,  1.7398e-04,\n",
            "        -9.5770e-04, -6.2675e-05, -4.9293e-04, -8.8471e-05,  6.7095e-04,\n",
            "        -4.0039e-04,  2.3759e-04,  9.4250e-04, -5.9890e-04,  1.6485e-03,\n",
            "         3.9129e-04, -4.8810e-04, -2.9536e-04, -2.4869e-05, -5.1510e-04,\n",
            "         8.9127e-04,  8.9376e-04, -1.0672e-03,  1.0656e-04,  6.4483e-04,\n",
            "        -1.0680e-04, -5.4131e-04, -7.4342e-04,  1.9197e-04, -3.2331e-05,\n",
            "        -1.0917e-03,  4.0487e-04, -9.5670e-04,  1.1213e-04,  3.7530e-04,\n",
            "        -5.0328e-04,  1.1588e-04,  4.1102e-04,  1.8755e-04,  7.0041e-04,\n",
            "         3.7135e-04,  2.0533e-04, -1.8188e-04, -1.7163e-04, -2.5299e-05,\n",
            "         4.2371e-04, -3.6242e-04, -4.3762e-04, -2.9364e-04, -3.6847e-04,\n",
            "        -6.4159e-05,  7.0734e-04,  4.0270e-04, -8.5496e-04, -7.1328e-05,\n",
            "         6.6931e-04,  7.7168e-04,  5.2824e-04, -9.0266e-04, -6.5670e-04,\n",
            "         4.4493e-04, -1.3176e-03, -2.4776e-04,  3.8882e-05,  1.1188e-03,\n",
            "         1.1175e-03, -5.0450e-04,  3.9076e-04,  5.1078e-05,  1.1234e-03,\n",
            "        -3.1960e-04,  5.0551e-04,  3.0823e-04, -1.8896e-04,  1.7487e-04,\n",
            "         9.7954e-05, -9.6382e-04,  5.8985e-05,  1.1608e-03,  9.2576e-04,\n",
            "        -4.7223e-04, -1.0241e-03, -7.2309e-04,  1.2682e-03, -2.5265e-04,\n",
            "         1.8972e-04, -5.2990e-04,  1.2506e-03,  2.4508e-04,  6.2602e-04,\n",
            "         7.5455e-05,  2.3959e-04,  1.7572e-04,  9.0479e-04,  4.3037e-04,\n",
            "        -1.2698e-04,  1.4077e-05,  1.5765e-04,  3.6787e-04,  3.4693e-04,\n",
            "        -2.7434e-05, -1.3821e-03, -7.8800e-04, -9.6329e-04, -6.4639e-04,\n",
            "         1.6668e-03,  1.9437e-04,  7.2730e-04,  5.1351e-04, -5.4040e-04,\n",
            "         7.8165e-04,  3.0466e-04,  7.7736e-04,  4.9183e-04,  6.4722e-04,\n",
            "        -1.0313e-03, -3.2927e-04, -5.2831e-04,  4.6687e-04, -2.4626e-04,\n",
            "        -1.4248e-03,  5.6045e-04, -2.6590e-04, -3.1295e-04, -1.2532e-05,\n",
            "        -2.9990e-05,  2.4174e-04, -5.4933e-04,  3.7049e-04,  2.2290e-04,\n",
            "         8.1097e-04, -3.8752e-04,  1.3767e-03, -1.5125e-04,  2.8065e-04,\n",
            "         1.7882e-03, -7.7361e-05,  1.2936e-03, -1.8691e-04,  1.0098e-03,\n",
            "         5.9047e-04,  3.2373e-04, -2.3707e-04, -8.0307e-04,  5.0939e-05,\n",
            "         1.6870e-03,  2.5004e-04, -5.2055e-04,  1.6911e-04, -2.9625e-04,\n",
            "         3.9845e-04,  7.4636e-04, -1.0016e-03, -4.1069e-04, -1.6246e-04,\n",
            "        -3.5090e-05, -1.2250e-04,  6.2051e-04, -2.9266e-04, -4.0637e-04,\n",
            "        -2.4700e-04,  1.3188e-04,  2.8232e-04,  7.8414e-04,  5.2694e-04,\n",
            "        -5.5167e-04, -1.6080e-03, -1.1226e-04, -1.0200e-05,  2.7088e-04,\n",
            "         1.0567e-03,  6.7102e-04, -5.8488e-05, -6.8752e-05, -6.9560e-04,\n",
            "        -1.4337e-03, -3.2359e-04, -5.8899e-04,  1.4835e-03,  1.9255e-04,\n",
            "         2.8007e-04, -9.8018e-04,  3.8370e-04,  5.5256e-04, -6.4784e-04,\n",
            "        -1.1104e-03,  1.6624e-03,  3.4598e-04,  5.8124e-04,  9.2813e-04,\n",
            "        -4.3714e-04,  5.4573e-04,  7.6372e-04, -4.1580e-04,  6.3716e-04,\n",
            "         3.5521e-05,  4.3251e-04,  6.4763e-04,  9.7514e-06, -3.7453e-04,\n",
            "         9.7054e-04,  9.1869e-04,  3.0442e-04, -7.5316e-04, -5.5061e-04,\n",
            "        -9.5218e-04, -4.2662e-05, -2.2667e-04,  7.9791e-04,  4.2668e-04,\n",
            "         9.3952e-05, -1.9247e-04, -6.7990e-04, -4.0246e-04, -1.7736e-03,\n",
            "         7.5342e-04, -2.6263e-04,  7.7191e-04,  2.3654e-04, -2.8014e-04,\n",
            "        -6.9173e-04,  3.8573e-04, -6.5954e-04, -2.4863e-04, -4.3199e-04,\n",
            "        -7.1882e-04,  5.7670e-04, -4.4272e-04,  4.5116e-04, -3.0380e-04,\n",
            "        -1.6135e-04,  3.7292e-04, -8.4513e-04, -9.8158e-04, -5.6820e-04,\n",
            "         1.1200e-04,  3.3343e-04,  4.4024e-04,  7.6372e-05,  3.3612e-04,\n",
            "         9.1443e-05, -8.6752e-04,  2.0726e-04, -6.6425e-04,  1.0829e-04,\n",
            "        -1.1520e-03,  3.9492e-04,  5.8189e-04,  4.5209e-04,  4.2020e-04,\n",
            "         6.0833e-04,  3.3267e-04,  7.2028e-04, -1.9779e-05, -3.1881e-04,\n",
            "         4.1150e-05, -5.3294e-04,  1.3234e-04,  2.3186e-04,  9.0306e-04,\n",
            "        -7.9166e-04, -4.4746e-05,  4.8580e-04, -9.9357e-05, -2.3294e-04,\n",
            "        -4.9985e-04,  1.1426e-04, -1.0651e-03, -3.3316e-04,  2.2456e-04,\n",
            "        -1.0094e-04, -4.1765e-04,  3.3855e-04, -2.5078e-04,  2.3616e-04,\n",
            "         7.7314e-05,  4.6037e-04, -3.7874e-04,  5.3020e-04,  9.7153e-04,\n",
            "        -1.8035e-05, -5.0143e-04, -5.9046e-04,  6.2844e-04,  3.0317e-04,\n",
            "         8.7305e-04, -3.4956e-04,  3.2898e-04, -6.9637e-04,  9.7761e-04,\n",
            "        -5.6421e-04, -2.8823e-04])}, 45: {'momentum_buffer': tensor([[[[ 4.4613e-04]],\n",
            "\n",
            "         [[ 6.0383e-04]],\n",
            "\n",
            "         [[-3.6371e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.3980e-04]],\n",
            "\n",
            "         [[ 3.3293e-04]],\n",
            "\n",
            "         [[-6.2237e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.7580e-04]],\n",
            "\n",
            "         [[ 6.7870e-04]],\n",
            "\n",
            "         [[ 4.4738e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8078e-04]],\n",
            "\n",
            "         [[-4.7177e-04]],\n",
            "\n",
            "         [[ 4.8941e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.9125e-04]],\n",
            "\n",
            "         [[-4.6146e-04]],\n",
            "\n",
            "         [[ 4.8143e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9607e-04]],\n",
            "\n",
            "         [[ 5.5027e-04]],\n",
            "\n",
            "         [[ 9.9854e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.3758e-04]],\n",
            "\n",
            "         [[ 1.1868e-04]],\n",
            "\n",
            "         [[-2.0383e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8953e-04]],\n",
            "\n",
            "         [[-6.2520e-06]],\n",
            "\n",
            "         [[ 9.9780e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.8240e-04]],\n",
            "\n",
            "         [[ 4.4990e-05]],\n",
            "\n",
            "         [[-5.3517e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3053e-04]],\n",
            "\n",
            "         [[ 2.8638e-04]],\n",
            "\n",
            "         [[ 5.2056e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 4.9632e-04]],\n",
            "\n",
            "         [[ 1.7355e-04]],\n",
            "\n",
            "         [[ 3.9945e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1900e-03]],\n",
            "\n",
            "         [[ 7.2315e-05]],\n",
            "\n",
            "         [[-4.1850e-04]]]])}, 46: {'momentum_buffer': tensor([ 1.5800e-03, -3.7081e-03,  7.5162e-04, -6.5598e-05,  1.2754e-03,\n",
            "         2.0938e-03,  3.2767e-05,  1.1577e-03, -6.2946e-04,  4.8287e-04,\n",
            "         5.8349e-05,  2.3957e-03,  2.3042e-03,  1.1106e-03,  1.2078e-03,\n",
            "         6.7025e-03,  2.2955e-03,  3.5493e-03,  1.4863e-03,  2.0484e-04,\n",
            "        -4.4070e-04,  1.7995e-03, -6.0963e-04,  7.4111e-04, -2.2462e-04,\n",
            "         3.1957e-03,  6.2425e-04,  1.4480e-03, -5.8030e-04, -7.8762e-04,\n",
            "        -5.3899e-06,  1.4233e-03,  5.6599e-04,  4.4662e-03, -9.0756e-04,\n",
            "         1.1738e-03, -2.2557e-04,  1.5487e-03,  3.0970e-03,  1.0846e-03,\n",
            "         2.9647e-03, -1.3861e-04, -3.2728e-03,  1.6165e-03, -6.9391e-04,\n",
            "        -4.0494e-04,  1.0820e-03,  1.3215e-03,  2.0309e-03,  7.6798e-04,\n",
            "         2.8434e-03,  1.6245e-03,  2.3523e-03,  2.0874e-03, -3.1839e-04,\n",
            "         3.8880e-03,  1.8104e-05,  9.0785e-04,  9.8381e-04,  1.2726e-03,\n",
            "         7.8890e-04, -1.3099e-03,  1.4337e-03,  2.0697e-03,  2.1371e-03,\n",
            "        -3.0944e-04,  1.1286e-03,  2.4928e-03,  9.9634e-04,  1.6962e-03,\n",
            "        -8.9778e-04,  8.5151e-04, -1.5507e-03,  1.7513e-03,  1.2233e-03,\n",
            "        -1.8427e-03,  1.5917e-04, -2.0481e-04,  1.1381e-03,  3.6390e-03,\n",
            "         1.8533e-03,  1.3315e-03,  1.4782e-03,  9.6200e-04, -1.3531e-03,\n",
            "         2.2365e-03,  2.8123e-03,  1.3737e-03,  2.3089e-03,  2.0700e-03,\n",
            "         8.1895e-04, -1.7378e-03,  9.6821e-04, -6.4849e-05,  9.3747e-04,\n",
            "        -4.6010e-04,  2.1534e-03,  1.3641e-03,  3.2782e-03, -2.6925e-03,\n",
            "         1.4739e-03, -2.2693e-03,  1.4328e-03,  2.3762e-03,  1.5694e-03,\n",
            "         3.4267e-03,  3.3083e-03,  2.4746e-03,  7.4293e-04,  7.7164e-04,\n",
            "         1.1341e-03,  1.6276e-03, -1.1391e-04,  3.1840e-03,  2.4936e-03,\n",
            "         1.4176e-03,  1.0621e-03, -1.6239e-04,  2.0084e-03,  1.9347e-03,\n",
            "        -1.2312e-03,  7.4664e-06, -2.0187e-04,  3.0788e-04,  1.1477e-06,\n",
            "         1.4101e-04, -6.7754e-04,  1.1234e-03])}, 47: {'momentum_buffer': tensor([-1.5804e-03, -2.5802e-03,  2.8949e-04, -2.9137e-03, -4.8347e-04,\n",
            "         1.3857e-03, -2.1768e-04,  2.4943e-05, -2.0820e-03, -4.6983e-04,\n",
            "         2.0721e-04,  6.8530e-04,  1.6807e-03, -3.3646e-04, -2.9376e-04,\n",
            "         1.4755e-03,  2.9578e-04,  2.5478e-03,  2.6644e-04, -1.1107e-03,\n",
            "         5.8093e-04,  1.1743e-03,  4.8995e-04,  1.1612e-03, -3.2346e-04,\n",
            "         1.4886e-03, -1.0881e-03, -2.5741e-04,  5.4527e-04, -9.7408e-04,\n",
            "        -1.1419e-03,  3.5616e-04,  1.1256e-03,  2.2432e-03, -2.1124e-03,\n",
            "        -4.9663e-04,  6.6344e-04,  2.7180e-05,  8.5427e-04, -3.3983e-04,\n",
            "         8.6839e-04, -1.6537e-03, -1.7239e-03,  3.3487e-04,  5.8766e-04,\n",
            "        -1.7135e-03,  1.0064e-03,  2.3863e-04,  1.6870e-03,  1.1265e-03,\n",
            "         1.8873e-03, -4.1246e-04, -1.0308e-03,  2.1788e-03, -2.3411e-03,\n",
            "        -2.3349e-04, -1.7666e-03, -4.5917e-04,  3.6825e-04, -3.9768e-05,\n",
            "         1.3146e-03, -6.7511e-04, -8.0291e-04,  2.8430e-03,  1.0468e-03,\n",
            "         1.8757e-04, -3.3865e-04,  1.1619e-03,  1.0215e-03,  1.2446e-03,\n",
            "        -5.5472e-04,  3.2331e-04, -5.7227e-04,  1.5261e-03,  6.4018e-04,\n",
            "        -1.1961e-03, -8.9103e-04, -5.7989e-04, -9.3005e-04,  1.8203e-03,\n",
            "         2.2037e-04, -9.1967e-04,  5.2117e-04,  1.3884e-03, -1.9982e-03,\n",
            "         8.2584e-05, -6.1021e-04,  9.9933e-04, -8.8836e-05, -5.8322e-04,\n",
            "         1.9843e-05, -6.9389e-04, -3.5316e-04, -1.3832e-03, -3.6238e-04,\n",
            "        -7.2832e-04,  1.1592e-04, -1.6953e-03, -1.2441e-03, -1.7927e-03,\n",
            "        -2.2869e-04, -3.5710e-03,  7.9421e-04,  2.6170e-04,  2.2945e-03,\n",
            "         1.4335e-03,  1.9427e-03,  1.1172e-03, -3.6390e-04,  1.0393e-04,\n",
            "         1.2991e-04, -8.7643e-04, -4.7146e-04,  1.0298e-04, -4.6651e-04,\n",
            "         1.4221e-03, -5.2167e-04,  7.5865e-04,  4.6964e-04,  3.7844e-04,\n",
            "        -1.3640e-03, -7.5487e-04, -1.3745e-03, -3.1581e-04,  9.3377e-04,\n",
            "         6.0504e-04, -6.6620e-04, -1.8284e-04])}, 48: {'momentum_buffer': tensor([[[[ 5.4324e-04, -7.1341e-04,  1.4240e-03],\n",
            "          [ 3.6971e-04, -1.2783e-03,  3.3600e-04],\n",
            "          [ 9.4695e-04, -1.1334e-03, -8.0864e-04]],\n",
            "\n",
            "         [[ 2.2072e-04, -4.7440e-04, -3.3832e-05],\n",
            "          [ 1.3864e-03, -2.9827e-05, -5.6114e-04],\n",
            "          [ 2.2367e-03,  2.2236e-05, -2.6211e-04]],\n",
            "\n",
            "         [[ 2.4464e-04,  1.2511e-04,  3.0426e-04],\n",
            "          [-7.2243e-04, -3.4819e-04, -1.0623e-04],\n",
            "          [-3.9527e-04, -5.8864e-04,  3.2251e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.6781e-04, -8.9101e-04,  5.8831e-04],\n",
            "          [-1.4451e-03, -1.6290e-03,  1.0079e-03],\n",
            "          [-1.2873e-03, -3.1930e-03, -2.8882e-03]],\n",
            "\n",
            "         [[-1.1623e-03, -1.3942e-03, -9.3535e-04],\n",
            "          [-1.6654e-03, -1.2351e-04, -9.5402e-05],\n",
            "          [-5.1692e-04, -2.8228e-04, -1.5172e-04]],\n",
            "\n",
            "         [[-1.4614e-04, -1.0941e-04,  3.0618e-04],\n",
            "          [ 8.5429e-05,  3.9850e-04,  1.4483e-03],\n",
            "          [ 2.4181e-04, -1.2158e-03, -7.3033e-04]]],\n",
            "\n",
            "\n",
            "        [[[-8.7206e-04,  2.6414e-04, -1.2816e-03],\n",
            "          [-5.8531e-04, -1.0193e-03, -1.3708e-03],\n",
            "          [-4.5878e-04, -1.2788e-03, -1.3071e-03]],\n",
            "\n",
            "         [[ 1.0058e-03,  9.7994e-04,  7.0952e-04],\n",
            "          [ 2.2184e-03,  3.0047e-03,  1.9915e-03],\n",
            "          [ 2.1454e-03,  2.4493e-03,  2.2651e-03]],\n",
            "\n",
            "         [[-3.9953e-04,  1.8663e-04,  1.6577e-04],\n",
            "          [-3.4104e-04,  3.7417e-04,  4.7791e-04],\n",
            "          [ 7.9071e-05,  2.2571e-04,  3.0322e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.9511e-04,  2.1619e-04,  3.5068e-04],\n",
            "          [-1.5420e-04, -9.3638e-04, -4.1054e-04],\n",
            "          [-4.9433e-04, -1.0340e-03, -7.2217e-04]],\n",
            "\n",
            "         [[ 1.2947e-03,  4.5524e-04,  6.8344e-06],\n",
            "          [ 8.5938e-04,  5.4984e-04,  5.5190e-04],\n",
            "          [ 3.6792e-04, -4.4013e-04, -6.9451e-04]],\n",
            "\n",
            "         [[-1.3015e-05, -7.5411e-04, -2.0486e-04],\n",
            "          [-7.2480e-04, -2.6047e-03, -2.0248e-03],\n",
            "          [-1.5872e-03, -2.2444e-03, -2.7399e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.5919e-04, -1.2374e-03,  2.6444e-04],\n",
            "          [ 2.5572e-04,  2.0449e-04,  6.2062e-04],\n",
            "          [ 1.2623e-04, -3.4457e-04, -2.8135e-04]],\n",
            "\n",
            "         [[-2.2753e-04, -1.4381e-03, -1.0059e-03],\n",
            "          [-1.3937e-03, -1.4831e-03, -1.0492e-03],\n",
            "          [-5.0077e-04, -2.0602e-03, -1.7241e-03]],\n",
            "\n",
            "         [[ 6.3689e-04,  6.1296e-05, -2.8711e-04],\n",
            "          [ 1.3281e-04, -1.7795e-04, -3.0249e-04],\n",
            "          [-3.4874e-04, -4.2124e-04, -5.0164e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0544e-03, -7.5388e-04,  7.5750e-04],\n",
            "          [-7.8427e-04, -4.1661e-04, -5.0505e-04],\n",
            "          [ 7.2973e-04,  6.3034e-05, -6.0117e-04]],\n",
            "\n",
            "         [[-2.5221e-03, -1.2601e-03, -7.6954e-04],\n",
            "          [-2.1704e-03, -1.8156e-03, -1.1587e-03],\n",
            "          [-1.4141e-03, -1.0418e-03, -8.0132e-04]],\n",
            "\n",
            "         [[-6.4057e-04, -6.2775e-04,  2.6726e-04],\n",
            "          [-1.0021e-03, -8.4781e-04, -5.0952e-05],\n",
            "          [-7.5308e-04, -1.1701e-03,  6.5776e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-8.0750e-05,  4.0479e-04,  3.2367e-04],\n",
            "          [ 5.5859e-04,  1.1861e-03,  5.8486e-04],\n",
            "          [ 1.0643e-03,  1.2782e-03,  2.1436e-03]],\n",
            "\n",
            "         [[-8.1896e-04, -1.1906e-03, -1.2322e-03],\n",
            "          [-8.0825e-04, -2.4712e-03, -1.1539e-03],\n",
            "          [-6.2652e-04, -6.1883e-04, -7.3519e-04]],\n",
            "\n",
            "         [[ 3.3026e-04,  7.0001e-04,  3.7361e-04],\n",
            "          [ 1.1548e-04,  5.1153e-04,  4.3561e-04],\n",
            "          [ 1.3811e-04,  1.9687e-04, -2.9827e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.2095e-04,  1.3462e-03,  3.2611e-04],\n",
            "          [-5.4422e-04,  2.7269e-04,  2.6514e-04],\n",
            "          [-3.4256e-04, -1.0958e-04,  5.5474e-04]],\n",
            "\n",
            "         [[ 1.0570e-04,  5.9125e-04,  7.6174e-05],\n",
            "          [-3.9993e-04, -1.5275e-04,  5.0907e-04],\n",
            "          [-1.6951e-04, -6.2114e-04, -3.6462e-04]],\n",
            "\n",
            "         [[ 5.6732e-05, -8.3161e-05, -6.6198e-04],\n",
            "          [ 1.2753e-04, -1.0603e-03, -1.2404e-03],\n",
            "          [ 2.5311e-04, -2.7827e-04, -9.4940e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.4750e-04, -1.6861e-03, -2.1677e-03],\n",
            "          [-1.5711e-03, -4.3900e-04, -1.6311e-04],\n",
            "          [-4.0583e-04,  2.2064e-04, -9.5978e-04]],\n",
            "\n",
            "         [[-8.5637e-04, -5.1269e-04, -3.0373e-04],\n",
            "          [-8.3591e-04, -1.7816e-03, -3.3124e-04],\n",
            "          [-1.5869e-03, -1.9213e-03, -1.0965e-03]],\n",
            "\n",
            "         [[ 2.1469e-03,  2.1718e-03,  1.6766e-03],\n",
            "          [ 1.4175e-03,  1.4016e-03,  1.9169e-03],\n",
            "          [ 1.0844e-03,  1.2475e-03,  1.3822e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6661e-04,  2.8070e-04,  5.4074e-04],\n",
            "          [ 1.2438e-03,  6.3075e-04,  1.5785e-03],\n",
            "          [ 9.3113e-04,  3.9867e-04,  4.1554e-04]],\n",
            "\n",
            "         [[ 1.1237e-03,  4.5780e-05,  3.4104e-04],\n",
            "          [ 8.9450e-05,  6.0145e-04, -3.8781e-04],\n",
            "          [ 1.9000e-03,  1.5270e-03,  1.0331e-03]],\n",
            "\n",
            "         [[ 2.7179e-04, -4.2008e-04, -1.6299e-03],\n",
            "          [-3.2358e-04, -8.9383e-05,  4.7111e-05],\n",
            "          [ 4.3293e-04, -5.4766e-04,  3.0836e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.2745e-04, -2.4394e-06,  5.9346e-04],\n",
            "          [-4.4405e-04, -4.4368e-04, -5.6400e-04],\n",
            "          [ 2.0934e-04, -2.3629e-04, -7.8103e-04]],\n",
            "\n",
            "         [[ 2.8116e-04, -4.4734e-05, -1.7046e-04],\n",
            "          [ 3.4984e-04,  5.4232e-04, -4.8760e-04],\n",
            "          [-4.4317e-04,  2.2094e-04, -4.5750e-04]],\n",
            "\n",
            "         [[ 6.7450e-04,  8.9696e-04,  1.0574e-03],\n",
            "          [ 1.1737e-04,  5.9101e-04,  9.2257e-04],\n",
            "          [ 3.1088e-04,  1.0013e-03,  1.2891e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1338e-04, -3.6601e-04, -3.8841e-04],\n",
            "          [-3.7054e-04, -1.2398e-03, -9.6228e-04],\n",
            "          [-1.0908e-03, -4.6449e-04, -1.2943e-03]],\n",
            "\n",
            "         [[-6.6014e-04, -1.9592e-04, -1.8358e-04],\n",
            "          [-8.2420e-04, -1.1447e-03, -6.8893e-04],\n",
            "          [-8.5355e-04, -1.4815e-03, -1.9585e-03]],\n",
            "\n",
            "         [[-3.8429e-04, -7.8914e-04, -1.2044e-03],\n",
            "          [ 5.6681e-05, -3.9385e-04, -7.5488e-04],\n",
            "          [-4.1734e-04, -2.4134e-04, -8.1937e-04]]]])}, 49: {'momentum_buffer': tensor([ 7.4302e-04, -1.7255e-04,  5.9671e-04,  1.9731e-03,  1.1057e-03,\n",
            "         2.7050e-03,  2.6261e-03,  8.3508e-04,  1.5957e-04,  2.8676e-03,\n",
            "         3.7444e-03,  2.1162e-03,  1.8377e-03,  1.4351e-03,  2.1713e-03,\n",
            "         1.1197e-03, -1.3032e-03,  1.6400e-03,  9.3950e-04,  9.6752e-04,\n",
            "         1.3634e-03,  1.3619e-05,  2.8791e-03,  5.3975e-04,  5.0616e-04,\n",
            "        -9.0087e-04,  4.8500e-03, -8.9435e-05,  1.3220e-03, -4.0801e-04,\n",
            "         1.1012e-03,  2.3712e-03,  2.6517e-03,  2.6373e-04,  8.6989e-04,\n",
            "         1.5843e-03, -3.3698e-04,  2.3162e-03,  2.9570e-04,  1.4139e-04,\n",
            "         4.1057e-04,  9.0906e-04,  4.4612e-03,  2.8394e-03,  1.8813e-03,\n",
            "         7.7068e-05,  2.2813e-03,  2.4526e-03,  9.7695e-04, -6.4971e-04,\n",
            "         2.6897e-03, -1.4182e-03,  7.3366e-04,  5.8034e-04,  2.2636e-03,\n",
            "         1.5601e-03, -2.0812e-04,  7.1056e-04,  2.1629e-03,  2.1881e-03,\n",
            "        -3.9490e-04,  2.3705e-03,  1.4997e-04,  1.3912e-03,  1.5785e-04,\n",
            "         2.0811e-03,  1.8398e-03, -9.5054e-04, -7.2779e-04,  1.5130e-03,\n",
            "        -6.4404e-05,  2.6191e-04,  2.3418e-04,  9.0898e-04,  8.1590e-04,\n",
            "         7.8563e-04, -4.5465e-04, -2.8428e-04,  2.5640e-04,  4.2470e-03,\n",
            "        -1.6047e-03,  4.6544e-04,  6.6172e-04,  4.1639e-04,  7.9227e-04,\n",
            "        -2.2333e-04,  1.7304e-03,  2.0247e-03, -2.1788e-03,  2.3154e-03,\n",
            "         1.4508e-03,  2.7159e-03,  1.1884e-03,  2.9930e-03,  7.1224e-04,\n",
            "         2.8660e-04, -2.0816e-03,  1.5894e-03,  2.2125e-03,  3.0503e-03,\n",
            "         1.1711e-03,  2.9923e-03, -2.0802e-03, -1.2701e-03,  2.2334e-03,\n",
            "         1.8347e-03,  9.3290e-04,  1.3687e-03, -1.8258e-03,  1.2811e-03,\n",
            "         5.7968e-04,  1.9084e-03, -7.1407e-04,  2.5047e-03,  1.0632e-03,\n",
            "        -2.3655e-04, -2.0615e-03,  1.8302e-03,  1.7168e-03, -8.7709e-04,\n",
            "         1.2110e-03, -6.9061e-05,  6.8137e-04,  2.5225e-04,  1.3581e-03,\n",
            "        -3.4502e-04,  1.5887e-03,  1.0380e-03])}, 50: {'momentum_buffer': tensor([-1.2439e-04, -2.6916e-03,  4.3406e-04, -9.9987e-04, -1.9111e-04,\n",
            "         1.3607e-03,  7.3185e-04,  6.2489e-04, -5.6644e-04,  1.7055e-03,\n",
            "         9.9793e-04,  2.8498e-04, -7.6691e-04, -1.7317e-03,  1.7729e-04,\n",
            "         3.2523e-05, -1.6592e-04, -1.0602e-03, -1.3204e-03, -1.2880e-03,\n",
            "         4.0050e-04,  1.6271e-04,  3.9854e-04, -5.9212e-04, -1.1618e-04,\n",
            "        -8.3838e-04,  2.8336e-04, -4.9755e-04,  8.6739e-04, -3.7598e-04,\n",
            "         8.6763e-04,  6.6289e-04,  8.4933e-04, -1.3458e-03,  2.4799e-05,\n",
            "         4.4672e-05,  2.2121e-03,  3.0027e-04, -3.4653e-04,  3.5191e-04,\n",
            "         6.8563e-04, -3.9436e-05,  2.7337e-03, -7.9121e-05,  7.3929e-04,\n",
            "        -7.4980e-04, -1.1005e-04, -8.2133e-04, -3.7672e-04,  4.3705e-04,\n",
            "        -3.9185e-04, -1.3095e-03, -4.9182e-04, -1.5724e-03,  1.2314e-04,\n",
            "        -2.2831e-04, -1.3896e-03, -6.1987e-04,  1.7423e-03,  7.9297e-05,\n",
            "        -2.8325e-04,  1.8520e-03, -2.0262e-03,  8.9802e-06, -1.8346e-03,\n",
            "        -1.2265e-03, -5.3879e-04, -1.0215e-04, -6.3072e-04,  1.3461e-03,\n",
            "         7.2027e-04,  5.0006e-04,  2.3550e-04, -1.4783e-03, -1.5641e-03,\n",
            "        -5.4654e-04, -1.0491e-03,  4.2934e-05,  1.0540e-04,  1.3245e-03,\n",
            "        -6.7021e-04, -1.3524e-03, -7.7654e-04,  8.5581e-04,  2.7503e-03,\n",
            "        -7.5436e-04, -7.4588e-04,  8.3359e-04, -1.8111e-03,  4.2075e-04,\n",
            "         1.3835e-03,  7.1968e-04,  5.0425e-04, -4.1973e-04, -2.5141e-04,\n",
            "         1.0085e-03, -2.6575e-03, -3.6455e-04, -1.5739e-04,  4.8614e-04,\n",
            "        -5.7669e-04,  1.3387e-03, -1.8379e-03, -1.2809e-03,  6.7637e-04,\n",
            "         1.6363e-03, -1.0678e-03, -9.0183e-04, -6.9733e-04, -1.8139e-04,\n",
            "        -1.7448e-04,  6.5606e-04, -6.9552e-04,  3.9010e-04,  7.7542e-04,\n",
            "         5.1934e-05, -1.7636e-03,  8.2583e-04,  1.9333e-03, -2.3329e-03,\n",
            "         7.7823e-04, -3.8464e-06, -8.6987e-04, -6.6643e-04,  2.2990e-04,\n",
            "        -7.2732e-04, -7.3086e-04,  1.1172e-03])}, 51: {'momentum_buffer': tensor([[[[-1.3861e-03]],\n",
            "\n",
            "         [[-6.9335e-04]],\n",
            "\n",
            "         [[ 1.2444e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0400e-03]],\n",
            "\n",
            "         [[-1.9310e-03]],\n",
            "\n",
            "         [[-8.0506e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.4792e-04]],\n",
            "\n",
            "         [[-8.9182e-04]],\n",
            "\n",
            "         [[ 1.3506e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.7276e-04]],\n",
            "\n",
            "         [[-6.4402e-04]],\n",
            "\n",
            "         [[-1.1727e-03]]],\n",
            "\n",
            "\n",
            "        [[[-9.4484e-05]],\n",
            "\n",
            "         [[-1.4486e-03]],\n",
            "\n",
            "         [[-4.1042e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2125e-04]],\n",
            "\n",
            "         [[ 1.1175e-04]],\n",
            "\n",
            "         [[-1.8968e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.1324e-04]],\n",
            "\n",
            "         [[-5.1806e-04]],\n",
            "\n",
            "         [[-6.1188e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9936e-04]],\n",
            "\n",
            "         [[ 5.0391e-04]],\n",
            "\n",
            "         [[-4.1820e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.1282e-04]],\n",
            "\n",
            "         [[ 8.2243e-04]],\n",
            "\n",
            "         [[ 4.8787e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7687e-04]],\n",
            "\n",
            "         [[ 9.9772e-04]],\n",
            "\n",
            "         [[-6.0891e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.9293e-05]],\n",
            "\n",
            "         [[ 1.7109e-03]],\n",
            "\n",
            "         [[ 8.0644e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3007e-04]],\n",
            "\n",
            "         [[ 4.1208e-04]],\n",
            "\n",
            "         [[ 3.8482e-04]]]])}, 52: {'momentum_buffer': tensor([ 1.4080e-03,  1.2311e-03,  1.4951e-03,  2.1115e-03,  1.5253e-03,\n",
            "         1.4893e-03,  4.8704e-04,  1.8753e-03,  9.7602e-04,  1.7857e-04,\n",
            "         2.5745e-04,  1.7224e-03,  5.7300e-04,  1.0952e-03,  1.4380e-03,\n",
            "         1.1010e-03,  1.1851e-03,  7.0737e-04,  1.5858e-03,  8.5040e-04,\n",
            "         1.2467e-03,  7.2516e-04,  6.8866e-04,  3.6494e-04,  1.3482e-03,\n",
            "         5.0689e-04,  1.5883e-03,  9.9214e-04,  1.3078e-03,  1.2193e-03,\n",
            "         1.0944e-03,  9.2833e-04,  2.0397e-04,  8.9292e-04,  8.7268e-04,\n",
            "         7.0514e-04, -5.9207e-04,  4.5379e-04,  1.0294e-03,  5.2995e-04,\n",
            "         9.6478e-04, -6.8956e-04,  1.0139e-03,  8.6909e-04,  1.0345e-03,\n",
            "         1.0462e-03,  4.8429e-04,  1.3254e-03,  1.0482e-03,  4.4448e-04,\n",
            "         1.2024e-03,  7.9523e-04,  1.1715e-03,  1.8138e-03,  1.6355e-03,\n",
            "         9.4421e-04,  1.8557e-03,  1.0559e-03,  1.1289e-03,  4.6802e-04,\n",
            "         6.9406e-04, -3.7000e-05,  8.8701e-04,  9.6013e-04,  8.8610e-04,\n",
            "         7.5798e-04,  1.4334e-03,  1.0097e-03,  2.6234e-04,  1.6566e-03,\n",
            "         9.2812e-04,  2.4419e-03,  9.0782e-04,  1.0570e-03, -5.1091e-04,\n",
            "         1.6109e-03,  5.0495e-04,  1.2635e-03,  3.5272e-04,  4.4164e-04,\n",
            "         1.2117e-03,  9.3714e-04,  1.7397e-03,  8.1409e-04,  1.7675e-03,\n",
            "         1.5670e-03,  7.1015e-04,  2.0420e-03,  1.7784e-03,  8.7052e-04,\n",
            "         6.3670e-04,  1.2151e-03,  6.1612e-04,  8.0778e-04, -3.8908e-04,\n",
            "         1.1497e-03,  1.9531e-03,  7.4014e-04,  1.4128e-03,  1.2004e-03,\n",
            "         1.8790e-03,  1.6551e-04,  4.5181e-04,  8.2670e-04,  1.7413e-03,\n",
            "         1.5886e-03,  1.8466e-03,  8.4602e-04,  8.2721e-04,  5.7853e-04,\n",
            "         1.6503e-03,  1.0945e-03,  8.8961e-04,  9.8326e-04,  8.7357e-04,\n",
            "         1.3498e-03,  8.9213e-04,  2.9243e-03,  1.2613e-03, -7.1093e-05,\n",
            "        -1.1571e-04,  1.0189e-03,  3.7203e-04,  6.8200e-04,  4.0357e-04,\n",
            "         8.9161e-04,  9.8061e-04,  2.6297e-03,  8.5435e-04, -4.8954e-04,\n",
            "         1.7230e-03,  1.0633e-03,  1.0103e-03,  1.7182e-03,  2.2366e-04,\n",
            "         6.4147e-04,  1.0227e-03,  4.6483e-04,  1.0084e-03,  1.5114e-03,\n",
            "         1.2605e-03,  6.8235e-04,  5.8012e-04,  1.1048e-03,  7.9630e-04,\n",
            "        -4.2941e-04,  4.2349e-04,  2.8367e-03,  1.2920e-03,  1.1023e-03,\n",
            "         1.4319e-03,  7.4683e-04,  5.8368e-04,  6.9394e-04, -1.2754e-04,\n",
            "         5.6806e-04,  1.2245e-03,  1.3983e-03,  1.9512e-03,  1.4892e-03,\n",
            "         1.6700e-03, -1.0090e-04,  1.4728e-03,  2.9736e-04,  1.0192e-03,\n",
            "         7.5446e-05,  8.2730e-04,  5.1413e-06,  1.2052e-03,  1.6531e-03,\n",
            "         7.6897e-04,  1.4882e-03,  1.7566e-03,  6.7340e-04,  6.1135e-04,\n",
            "         1.3578e-03,  9.0005e-04,  1.9139e-03,  1.2254e-03,  1.3962e-03,\n",
            "        -3.0974e-04,  1.8933e-03,  1.0375e-03,  1.5964e-03,  8.4564e-04,\n",
            "         1.1227e-03,  1.1602e-03,  1.5169e-03,  6.5595e-04,  1.2245e-03,\n",
            "         1.4713e-03,  8.1009e-04,  4.5255e-04,  2.4175e-04,  1.4222e-03,\n",
            "         1.4355e-03,  1.2011e-03,  1.7027e-03,  1.0431e-03,  6.6698e-04,\n",
            "         8.6346e-04,  1.9878e-03,  1.5960e-03,  1.4072e-03,  5.6393e-04,\n",
            "         6.4249e-04,  2.6980e-03,  7.3034e-04,  1.5889e-03,  1.0536e-03,\n",
            "         5.4991e-04,  9.9065e-06,  3.8675e-04,  3.2002e-04,  1.3441e-03,\n",
            "         8.1218e-04,  3.1998e-04,  2.3477e-07,  1.8920e-03,  7.4297e-04,\n",
            "         8.1984e-04,  6.4637e-04, -1.3222e-04,  1.0481e-03, -1.4709e-04,\n",
            "         7.9915e-04, -8.4478e-05,  1.5483e-03,  6.1906e-04, -1.6702e-04,\n",
            "         1.4323e-03,  1.1408e-04,  1.3198e-03,  1.1705e-03,  1.0913e-03,\n",
            "         1.2006e-03,  9.0562e-04,  8.4622e-04,  1.5151e-03,  5.7066e-04,\n",
            "         1.0626e-03,  6.0032e-04,  1.4464e-03,  1.2755e-03,  7.3737e-04,\n",
            "         1.1134e-03,  4.8256e-04,  1.0884e-03,  6.7027e-05,  9.4239e-04,\n",
            "         1.3843e-03,  1.5201e-03,  1.3009e-03,  1.0042e-03,  9.8743e-04,\n",
            "         4.9909e-04,  1.1445e-03, -2.2471e-04,  1.7148e-03,  1.5246e-03,\n",
            "         1.8600e-03,  6.6860e-04, -2.3723e-04,  1.0885e-03,  1.4110e-03,\n",
            "         6.1409e-04,  6.1961e-04,  1.3589e-03,  1.8356e-03, -8.8942e-05,\n",
            "         1.0939e-03,  7.9358e-04,  7.8546e-04,  7.8890e-04,  1.2564e-03,\n",
            "        -1.3034e-04,  1.3821e-03,  3.5638e-04,  5.0234e-04,  5.8254e-04,\n",
            "         1.4093e-03,  1.4831e-03,  9.6341e-04,  1.6052e-03,  1.0064e-03,\n",
            "         7.5025e-04,  1.2343e-03,  1.4459e-03,  1.3385e-03,  8.0220e-04,\n",
            "         1.1459e-03,  1.7078e-03,  1.1446e-03,  5.6310e-04,  1.5593e-03,\n",
            "         5.5901e-04,  2.8341e-04,  1.5502e-03,  1.5325e-03,  1.4410e-03,\n",
            "         1.3409e-03,  4.2395e-04,  7.7042e-04,  1.4063e-03,  2.3074e-04,\n",
            "         9.6905e-04,  1.5301e-03,  1.0710e-03,  5.0869e-04,  9.1380e-04,\n",
            "         1.4658e-03,  4.2488e-04,  1.2422e-03,  1.4166e-03,  8.6514e-04,\n",
            "         1.2835e-03,  9.8377e-04,  1.1221e-03,  3.7161e-04,  2.6549e-03,\n",
            "         9.6603e-04,  1.1040e-03,  7.0509e-04, -4.0593e-05,  1.2822e-03,\n",
            "         1.2857e-03,  3.0134e-04,  1.0246e-03,  9.3560e-04,  7.7184e-04,\n",
            "         7.0839e-04,  1.4590e-03,  1.0033e-03,  1.4772e-03,  1.7299e-03,\n",
            "         1.6779e-03,  1.4605e-03,  1.7839e-03,  1.3831e-03,  7.8260e-04,\n",
            "         1.3984e-03,  1.3477e-03,  6.0505e-04,  2.3532e-03,  1.6045e-03,\n",
            "         8.7693e-04,  1.8420e-03,  6.2925e-04,  7.6799e-04,  1.6970e-03,\n",
            "         1.1755e-03,  1.1828e-03,  1.1808e-03,  2.2207e-03,  7.2353e-04,\n",
            "         9.1888e-04,  1.9097e-03,  8.0117e-04,  6.9103e-04,  1.3812e-03,\n",
            "         9.9897e-04,  1.2854e-03,  6.9949e-04,  1.6823e-03,  3.3014e-04,\n",
            "         1.1256e-03,  1.3889e-03,  1.2891e-03,  8.1910e-04,  1.5513e-03,\n",
            "         1.0494e-03,  1.3805e-03,  1.0146e-03,  1.2229e-03,  1.0124e-03,\n",
            "         1.0549e-03,  7.5813e-04,  9.6534e-04,  1.0907e-03,  1.0976e-03,\n",
            "         8.9446e-04, -5.7380e-04,  2.1352e-04,  1.0905e-03,  7.1654e-04,\n",
            "         8.7359e-04,  3.2660e-04,  1.2510e-03,  1.2541e-03,  1.5140e-03,\n",
            "         8.3369e-04,  5.5032e-04,  1.8104e-03, -3.6670e-04,  5.7096e-04,\n",
            "         8.3324e-04,  1.3449e-03,  1.3230e-03,  8.8840e-04,  6.4174e-04,\n",
            "        -8.6244e-04,  5.9130e-04,  1.4575e-03,  1.1202e-03,  1.2411e-03,\n",
            "         2.0266e-03,  1.5779e-03,  3.2518e-04,  1.0393e-03,  1.1947e-03,\n",
            "         1.4291e-03,  4.6995e-04,  7.1621e-04,  5.1724e-04,  1.8971e-03,\n",
            "         2.2195e-04,  1.2954e-03,  1.3955e-04,  1.2598e-03,  7.7734e-04,\n",
            "         9.8793e-04,  1.1271e-03,  1.1711e-03,  1.2169e-03,  7.3336e-04,\n",
            "         8.0453e-04,  3.7378e-04,  1.8905e-03,  9.6065e-04,  1.4395e-03,\n",
            "         1.6539e-03,  1.0263e-03,  1.0104e-03,  1.7121e-03,  7.7415e-04,\n",
            "         1.2625e-03,  1.1511e-03,  8.9513e-04,  1.8893e-03,  1.0894e-03,\n",
            "         8.8753e-04,  1.0823e-03,  1.0609e-03,  4.8253e-04,  1.1791e-03,\n",
            "         1.7387e-04,  1.1914e-03,  8.2133e-04,  8.8300e-04,  3.1247e-04,\n",
            "         1.1713e-03,  1.4253e-03,  4.2538e-04,  2.0362e-03,  1.2989e-03,\n",
            "         1.0877e-03,  6.6603e-04,  1.3674e-03,  8.4813e-04,  2.2685e-03,\n",
            "         1.0874e-03,  2.4694e-04,  8.6279e-04,  4.1683e-04,  2.7893e-03,\n",
            "         1.0948e-03,  1.6121e-04,  3.1314e-04,  5.0884e-04,  1.0633e-03,\n",
            "         2.0471e-04,  1.7376e-03,  1.3169e-03,  2.2410e-03,  1.5152e-03,\n",
            "         5.0579e-04,  1.2710e-03,  2.1786e-03,  1.4308e-03,  1.3629e-03,\n",
            "         8.8386e-04,  1.6254e-03,  1.9027e-03,  2.8259e-04,  1.1911e-03,\n",
            "         1.4011e-03,  1.6202e-03,  1.5451e-03,  9.8835e-04,  4.8874e-04,\n",
            "         4.7084e-04,  9.1335e-04,  1.3641e-03,  1.9130e-04,  1.2170e-03,\n",
            "         8.9651e-04,  1.2730e-03,  9.7557e-04,  9.2391e-04,  1.9112e-03,\n",
            "         1.1845e-03,  1.1114e-03, -1.6470e-04,  1.2454e-05,  1.1072e-03,\n",
            "         8.5215e-04,  1.0680e-03,  1.9463e-03,  2.7844e-04,  8.9690e-04,\n",
            "         1.3175e-03,  9.5294e-04])}, 53: {'momentum_buffer': tensor([-3.1588e-04,  2.3383e-05,  1.8487e-04,  5.3701e-05,  2.8374e-04,\n",
            "         6.2510e-04, -4.1735e-04,  5.6459e-04,  1.0395e-03, -2.3372e-04,\n",
            "        -2.2915e-04, -1.8833e-04, -8.7585e-04,  5.8854e-05,  1.4732e-04,\n",
            "         1.2379e-04, -7.9316e-04, -1.6558e-06,  3.8161e-04, -2.7625e-04,\n",
            "        -1.0078e-04,  1.3273e-04,  1.0246e-04, -3.9512e-04,  1.4315e-04,\n",
            "         2.4053e-04,  7.2399e-04, -4.5528e-04, -2.0173e-05, -1.6399e-05,\n",
            "         1.3196e-03,  5.9452e-04, -1.9719e-04,  1.8737e-05,  3.0442e-04,\n",
            "         3.7034e-04, -3.7094e-06,  2.3898e-04,  9.6588e-06, -5.8920e-04,\n",
            "        -4.5061e-04, -2.4420e-05, -5.4921e-05, -2.8349e-05, -1.2423e-04,\n",
            "        -4.1457e-05, -8.1453e-04, -2.9784e-04,  6.6374e-04, -6.4884e-05,\n",
            "         4.1516e-05,  9.5451e-05,  1.1101e-04, -9.0776e-05,  9.2196e-04,\n",
            "         4.4633e-05, -2.6130e-04,  4.7150e-04,  4.5388e-04, -5.9065e-04,\n",
            "         3.3567e-04, -4.9546e-04, -1.2376e-04, -2.1471e-04, -2.7207e-04,\n",
            "        -5.5665e-04,  2.6693e-04, -2.9338e-04,  5.4125e-04,  4.7332e-04,\n",
            "        -6.2766e-04, -2.9898e-04, -3.4542e-04, -9.9960e-05, -7.0539e-04,\n",
            "         3.1716e-04, -1.0061e-04, -8.8655e-05, -4.0561e-04,  3.8818e-04,\n",
            "        -8.4017e-05, -1.5159e-04,  2.3059e-04,  1.5324e-04,  1.0089e-04,\n",
            "         9.7392e-04,  2.7058e-04, -8.3435e-05, -3.6346e-04, -4.8046e-04,\n",
            "        -5.3283e-04,  7.0498e-05, -5.6223e-04,  1.7207e-04, -8.7500e-04,\n",
            "         1.6506e-04,  4.0142e-04, -1.1248e-04,  7.7540e-04, -6.4031e-04,\n",
            "         7.4722e-04, -5.3098e-04, -9.7796e-05, -3.1683e-05,  8.0744e-04,\n",
            "         5.6593e-04,  6.3632e-05,  1.0615e-04, -3.8794e-04, -1.1853e-03,\n",
            "        -6.8979e-06,  5.3399e-04, -1.0036e-04,  7.4056e-05,  2.8609e-04,\n",
            "         1.2162e-04,  7.1706e-05,  6.2969e-04,  3.0969e-05, -1.8213e-05,\n",
            "         4.5436e-04,  4.9726e-04, -4.4613e-05, -1.2623e-04, -2.8319e-04,\n",
            "         1.5899e-04,  3.2272e-04,  8.2574e-04,  9.2286e-05,  5.5995e-05,\n",
            "         1.3201e-04, -4.3745e-04,  1.3322e-04, -3.4342e-04,  2.2839e-05,\n",
            "        -3.2497e-04,  1.3402e-04,  2.5991e-04,  6.6178e-04,  1.6907e-04,\n",
            "        -5.3080e-05, -2.3297e-04, -2.5126e-04, -5.5031e-04,  3.1850e-05,\n",
            "        -4.2554e-04,  4.1972e-04,  5.2176e-04,  7.9176e-04,  5.7555e-04,\n",
            "         5.1991e-04, -6.8679e-04, -7.6188e-04,  8.3936e-04, -5.5578e-04,\n",
            "         1.2112e-04,  3.2680e-05, -5.0430e-05,  6.4633e-04,  5.1724e-04,\n",
            "         3.9207e-04, -4.5415e-05,  2.0563e-05, -6.5111e-06,  3.3912e-04,\n",
            "        -7.1683e-04, -2.9403e-04, -2.0671e-04,  1.9706e-04,  1.2681e-04,\n",
            "         3.7499e-04,  3.0798e-04, -7.2858e-04, -9.7571e-05,  1.4647e-04,\n",
            "         1.8631e-04,  1.8129e-04,  4.4937e-04, -2.1432e-04, -7.9909e-04,\n",
            "        -1.8594e-04,  3.4404e-04, -2.1396e-04, -2.7021e-04, -2.3742e-04,\n",
            "        -3.6657e-04,  6.3829e-05, -4.0634e-05,  1.5467e-04,  2.5325e-04,\n",
            "         8.0421e-04, -2.3900e-04, -6.3133e-04, -2.5982e-04, -4.1023e-04,\n",
            "         3.9095e-04, -2.1737e-04, -2.6441e-05, -2.4145e-04, -2.1004e-07,\n",
            "         4.4085e-04,  2.1646e-05,  3.9163e-04,  4.1401e-04,  7.6110e-05,\n",
            "        -1.3536e-04,  7.3761e-04, -2.2272e-04, -3.5952e-05, -6.7680e-05,\n",
            "        -5.8304e-04, -1.3155e-04,  3.9698e-04, -2.7735e-04, -2.1816e-04,\n",
            "        -1.0072e-04, -6.8287e-04, -1.3065e-04,  2.5540e-04,  1.9524e-04,\n",
            "        -1.2218e-04,  3.2876e-05, -3.0771e-04,  1.8581e-04,  4.1579e-04,\n",
            "        -8.3872e-05, -7.0500e-04, -2.8343e-04, -7.6313e-05,  1.0665e-04,\n",
            "         2.1310e-05, -1.8300e-04, -2.2732e-04,  2.8640e-04,  8.9498e-04,\n",
            "        -4.4045e-04, -4.1520e-04, -3.7616e-04,  1.9818e-05, -2.9728e-06,\n",
            "         5.6700e-04,  4.5457e-04,  3.0860e-05, -1.4403e-04,  8.8813e-04,\n",
            "        -3.9357e-04,  2.4618e-04, -7.0024e-04, -5.2961e-04,  8.5951e-06,\n",
            "        -4.6298e-04, -3.8041e-05,  2.6449e-04, -2.7145e-05,  1.0598e-05,\n",
            "        -7.5908e-04,  5.7466e-05, -1.9039e-04,  5.6948e-04,  4.1477e-04,\n",
            "         3.1545e-04,  4.0017e-04,  1.6440e-04, -7.0695e-04,  4.2305e-04,\n",
            "        -1.6105e-04, -5.6509e-04, -4.6869e-04,  1.5144e-05,  1.2795e-04,\n",
            "         2.2710e-04,  9.4856e-05,  9.6163e-04, -2.6277e-04, -3.4798e-04,\n",
            "         4.0831e-04, -2.8969e-04,  7.0967e-05, -6.3327e-04,  1.8713e-04,\n",
            "        -3.2944e-05,  1.3363e-04, -2.6030e-04, -1.1870e-04,  2.0568e-04,\n",
            "         1.0233e-03, -2.2124e-04,  6.7788e-04,  6.4405e-04,  7.2273e-04,\n",
            "         3.8609e-04,  2.6555e-04,  1.0844e-04,  4.1295e-04, -2.7409e-04,\n",
            "        -2.3708e-04, -1.1217e-03,  5.4537e-06,  9.7581e-04,  2.0755e-04,\n",
            "        -3.7975e-04, -2.4152e-04, -7.1680e-04,  6.3783e-04, -6.9460e-04,\n",
            "        -4.7527e-04,  2.2490e-04,  7.4375e-04,  3.7468e-05, -1.0417e-04,\n",
            "         1.3908e-04,  1.6982e-04,  4.3437e-04,  2.9388e-04, -3.6174e-05,\n",
            "         1.2525e-04, -4.4853e-04,  6.1969e-04, -3.3920e-05, -4.2722e-06,\n",
            "         3.1223e-04, -6.6465e-04, -2.6747e-04, -2.5210e-05, -3.1589e-04,\n",
            "         8.2388e-04, -7.2551e-04,  3.9628e-04,  2.9825e-04, -2.0308e-04,\n",
            "         1.2527e-04, -9.5441e-05,  2.3592e-04,  3.5842e-04, -1.3842e-05,\n",
            "         3.8242e-04,  3.8527e-04, -9.0602e-05,  7.2803e-04, -6.4974e-04,\n",
            "        -1.0582e-03,  6.0864e-04, -2.6935e-04,  2.5099e-04,  3.9112e-04,\n",
            "        -2.8345e-04,  4.5760e-04, -8.0373e-05, -2.7227e-04, -7.0739e-05,\n",
            "         3.6596e-04, -1.9751e-05,  9.2194e-04,  4.4848e-04,  1.3708e-04,\n",
            "         1.1214e-03, -1.4733e-04,  3.2738e-04, -5.8256e-04,  5.7440e-04,\n",
            "         1.3376e-04, -2.0888e-04, -2.4723e-04,  1.3888e-04, -1.6983e-04,\n",
            "         1.7054e-03,  8.1543e-04,  3.0373e-04, -2.9033e-04,  5.1495e-04,\n",
            "        -1.2933e-04,  7.1281e-04, -6.0854e-04, -1.9761e-04, -4.3494e-04,\n",
            "         6.1801e-04, -8.7660e-05,  5.8678e-04,  1.3872e-04, -2.1602e-04,\n",
            "        -4.6913e-04, -2.7271e-04,  1.4966e-04,  6.1912e-04, -2.2409e-04,\n",
            "        -4.7849e-04, -7.5258e-04,  4.6804e-04,  5.8919e-05,  1.5726e-04,\n",
            "        -2.2947e-04,  7.6293e-04,  3.5279e-04, -1.7965e-04, -9.6951e-04,\n",
            "        -1.8943e-04, -2.9140e-04, -5.3381e-05,  2.4733e-04, -9.0337e-05,\n",
            "        -9.2829e-04, -2.9940e-05,  5.0512e-05,  4.4372e-04,  1.0634e-04,\n",
            "        -3.6560e-04,  6.8616e-04, -7.3944e-05, -2.7113e-04,  2.4824e-04,\n",
            "         1.5058e-04,  5.9332e-05, -3.2132e-04, -6.0895e-05,  4.2175e-04,\n",
            "        -4.9803e-04,  2.6592e-04, -2.3607e-04,  3.1004e-04, -8.1623e-04,\n",
            "        -3.7007e-05, -3.2979e-04,  3.2278e-04,  8.9722e-05, -5.2822e-04,\n",
            "        -6.0544e-04, -4.8917e-04, -2.9761e-04,  9.3286e-04,  6.0396e-04,\n",
            "         2.5494e-04,  2.5350e-04, -1.4062e-04, -4.2597e-04, -4.1897e-04,\n",
            "        -9.7636e-06,  1.0238e-04, -4.6426e-05,  5.9186e-04, -2.3503e-04,\n",
            "        -3.2661e-05, -2.5374e-04,  5.2396e-04, -9.0860e-04,  2.7469e-04,\n",
            "        -8.0785e-04, -5.0336e-04, -7.3343e-04,  2.3167e-04, -3.6413e-04,\n",
            "        -7.3344e-04, -1.7523e-04, -1.4166e-04,  2.2539e-04, -3.5563e-04,\n",
            "         2.0614e-04, -3.4686e-04,  8.0389e-04, -1.1834e-04, -1.5659e-04,\n",
            "         2.4510e-04, -9.8779e-04, -2.1453e-04, -3.9234e-04,  7.5353e-04,\n",
            "         4.8088e-04, -1.1290e-04,  1.1428e-04, -1.8466e-04,  3.8646e-04,\n",
            "         5.9792e-05,  7.9812e-04,  3.5519e-04,  1.6370e-04,  8.5374e-05,\n",
            "        -1.2231e-04,  3.9013e-04,  5.8872e-04,  4.6163e-04,  6.4200e-04,\n",
            "        -8.8284e-04, -2.0575e-04, -3.3792e-04, -5.4732e-04,  4.6110e-04,\n",
            "         1.8276e-04,  1.8250e-04, -3.7453e-04, -2.6257e-04, -3.0187e-04,\n",
            "         3.2042e-05,  3.0708e-04,  2.6688e-04, -1.0205e-03,  3.2147e-04,\n",
            "         2.8684e-05,  3.6743e-04,  2.4029e-04, -2.7921e-04,  1.1069e-04,\n",
            "        -5.9125e-04, -2.5036e-04, -1.2882e-04, -2.6789e-04,  1.4664e-04,\n",
            "         5.6896e-04,  5.5060e-05,  8.7578e-05, -5.9547e-04,  3.0142e-04,\n",
            "        -2.8361e-04, -7.0408e-04])}, 54: {'momentum_buffer': tensor([[[[ 4.2818e-04]],\n",
            "\n",
            "         [[ 4.1334e-04]],\n",
            "\n",
            "         [[ 1.1553e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.6318e-05]],\n",
            "\n",
            "         [[-3.3334e-05]],\n",
            "\n",
            "         [[-3.1646e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5598e-04]],\n",
            "\n",
            "         [[ 3.6210e-05]],\n",
            "\n",
            "         [[-2.0014e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.1612e-04]],\n",
            "\n",
            "         [[ 4.2988e-04]],\n",
            "\n",
            "         [[-2.0011e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0161e-04]],\n",
            "\n",
            "         [[ 1.3932e-04]],\n",
            "\n",
            "         [[ 7.9609e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7741e-04]],\n",
            "\n",
            "         [[ 1.9099e-04]],\n",
            "\n",
            "         [[-1.5829e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.1790e-04]],\n",
            "\n",
            "         [[-1.8564e-04]],\n",
            "\n",
            "         [[-5.2293e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7818e-04]],\n",
            "\n",
            "         [[-6.6927e-05]],\n",
            "\n",
            "         [[ 8.1627e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.5373e-04]],\n",
            "\n",
            "         [[ 2.8573e-04]],\n",
            "\n",
            "         [[ 7.3723e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.3471e-04]],\n",
            "\n",
            "         [[ 3.6132e-04]],\n",
            "\n",
            "         [[-2.2107e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0267e-03]],\n",
            "\n",
            "         [[-3.4221e-04]],\n",
            "\n",
            "         [[-4.0042e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8652e-05]],\n",
            "\n",
            "         [[-3.1787e-04]],\n",
            "\n",
            "         [[-3.0772e-04]]]])}, 55: {'momentum_buffer': tensor([-3.1006e-04,  1.7639e-03,  1.4305e-03,  1.0750e-03,  1.5722e-03,\n",
            "         1.0740e-03,  1.4928e-03,  1.4144e-03,  9.3825e-04,  1.3496e-03,\n",
            "         2.9962e-04,  1.1706e-03, -2.1411e-04,  3.1416e-03,  6.5977e-04,\n",
            "         2.4563e-03,  3.5331e-04,  1.6579e-03,  3.7076e-04, -4.4287e-04,\n",
            "         1.0431e-03,  1.7923e-03, -3.8555e-04,  1.9906e-04,  1.8138e-03,\n",
            "         8.1640e-04,  3.3433e-04,  1.2899e-03,  1.4345e-03, -3.7747e-04,\n",
            "         2.1537e-03,  1.4832e-03, -1.1669e-03,  8.8636e-04, -3.3035e-04,\n",
            "         1.2055e-03,  2.6961e-04, -6.5808e-04,  1.0586e-03,  2.6634e-03,\n",
            "        -9.5112e-04,  1.8838e-03,  6.5428e-04, -6.2944e-04,  1.9708e-03,\n",
            "        -9.5951e-05,  2.8617e-03,  7.9482e-04,  1.2543e-03,  2.6201e-03,\n",
            "         1.6021e-03,  1.9603e-03,  7.5118e-04, -1.8688e-04, -2.8359e-04,\n",
            "         8.0700e-04,  3.0579e-03, -1.2117e-03,  7.4630e-04,  3.4428e-04,\n",
            "         8.8472e-04,  2.3110e-03, -7.0538e-04,  1.9319e-03,  1.8761e-03,\n",
            "        -6.8819e-04,  2.6826e-03, -1.7968e-03, -4.0755e-04,  4.7234e-04,\n",
            "         1.3215e-03,  1.5973e-03,  2.2039e-03,  1.4553e-03,  1.1048e-03,\n",
            "         1.1490e-03,  3.3447e-03,  5.3909e-04, -7.1584e-05,  2.5353e-03,\n",
            "         1.4159e-03,  1.7020e-03,  5.9943e-04,  4.3256e-04,  7.8030e-04,\n",
            "         8.4037e-04, -8.8269e-04,  2.0517e-03,  1.9460e-04,  6.5377e-05,\n",
            "         5.6128e-04, -6.1641e-04,  1.6624e-03, -6.8537e-04,  1.3753e-03,\n",
            "         3.3580e-03,  1.6880e-03,  1.3904e-03,  3.6375e-04,  7.7431e-04,\n",
            "         1.8514e-03,  1.5493e-03,  1.8008e-03,  7.3001e-04,  2.7852e-03,\n",
            "         2.6936e-04,  1.3246e-03,  3.3067e-03,  5.9995e-04,  7.6886e-04,\n",
            "         1.3337e-04, -5.4487e-04,  3.1999e-04,  1.3277e-03,  1.7779e-03,\n",
            "         1.4506e-03,  1.5590e-03,  2.4129e-03,  1.5161e-03,  3.3251e-03,\n",
            "        -9.1333e-04,  8.1359e-04,  3.6617e-04,  1.8617e-03, -8.1964e-04,\n",
            "         1.3519e-03,  1.0720e-03,  1.4775e-03])}, 56: {'momentum_buffer': tensor([-1.7917e-03, -2.3857e-04, -7.0388e-04, -5.8869e-04,  2.2912e-03,\n",
            "         7.5787e-05,  1.0054e-03, -5.1213e-05, -5.6640e-04,  2.2215e-04,\n",
            "        -1.4940e-03,  8.4884e-04,  5.6061e-04,  1.0407e-03,  4.8678e-04,\n",
            "         4.8113e-04, -6.8361e-04,  7.9294e-05, -1.0739e-04, -1.0627e-03,\n",
            "         8.1386e-04, -2.4197e-05, -3.0341e-04,  3.9042e-04,  1.6084e-04,\n",
            "         2.3771e-03, -9.9071e-04, -1.7823e-04,  8.9081e-04, -1.8584e-04,\n",
            "         2.8293e-04, -1.4744e-04, -1.0621e-03, -3.9924e-04, -4.6640e-04,\n",
            "         5.8301e-04,  2.5991e-04, -1.0462e-04, -3.8646e-04,  8.0797e-04,\n",
            "         5.3868e-05,  1.1857e-04, -1.0764e-03, -1.4640e-03,  8.3403e-04,\n",
            "        -2.1910e-04,  2.3954e-04, -4.7997e-04,  1.2873e-03,  1.1223e-03,\n",
            "         6.2316e-04, -5.2439e-07, -7.8319e-04,  3.2923e-04, -1.1529e-03,\n",
            "         1.1286e-04,  8.4464e-04, -9.5611e-04, -3.4542e-04,  4.3565e-04,\n",
            "        -2.2118e-04,  1.1169e-03, -7.6396e-04, -5.5521e-04,  3.6228e-04,\n",
            "        -1.6848e-04,  8.3501e-04, -5.7539e-04, -1.1542e-03, -8.4579e-05,\n",
            "         8.9658e-04, -1.1721e-04,  8.1900e-04,  1.4082e-03, -8.2961e-04,\n",
            "         1.0781e-04,  6.2932e-05,  3.8872e-04, -2.8334e-03,  5.9807e-04,\n",
            "         6.5539e-05,  8.1671e-04, -3.9031e-04,  1.7000e-03, -1.1079e-03,\n",
            "         3.7713e-04, -1.6436e-03,  5.0302e-04,  4.2690e-04,  5.1485e-04,\n",
            "        -7.8324e-04, -1.7856e-03,  2.6575e-04, -1.5075e-03,  3.8416e-05,\n",
            "         2.1711e-04,  3.4562e-04, -1.1524e-04, -1.3842e-03, -7.4463e-04,\n",
            "         6.3074e-04,  1.6467e-04,  5.2014e-04, -4.6755e-04,  1.2028e-03,\n",
            "         3.2356e-04,  1.4594e-03,  6.9333e-04, -1.4618e-03, -2.9249e-04,\n",
            "        -4.7968e-04, -8.8070e-04, -1.8770e-04, -1.2663e-03,  1.9868e-04,\n",
            "         8.2487e-04, -6.7649e-04,  1.5489e-03,  6.9900e-04,  2.1173e-03,\n",
            "        -8.8500e-04,  4.5906e-04,  1.4379e-04,  3.6561e-04, -1.1091e-03,\n",
            "         6.5092e-04, -1.2879e-04,  8.6379e-04])}, 57: {'momentum_buffer': tensor([[[[ 3.3325e-04, -1.4921e-04,  2.2141e-04],\n",
            "          [ 4.4053e-04,  4.4584e-04,  6.6207e-04],\n",
            "          [ 4.4611e-04,  7.7280e-04,  1.0598e-03]],\n",
            "\n",
            "         [[-1.3559e-03, -2.0997e-03, -1.0633e-03],\n",
            "          [-1.3064e-03, -1.7774e-03, -1.3425e-03],\n",
            "          [-3.7742e-04, -1.4563e-04, -2.5873e-04]],\n",
            "\n",
            "         [[ 1.5110e-04, -1.2100e-04,  2.7040e-04],\n",
            "          [ 1.5375e-04, -1.9279e-05,  4.2489e-04],\n",
            "          [ 3.6631e-04,  1.5885e-04,  3.6329e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9133e-04, -7.9725e-04, -8.5132e-04],\n",
            "          [-2.6444e-04, -5.4223e-04, -8.9121e-04],\n",
            "          [-2.7510e-04, -5.0234e-04, -8.1040e-04]],\n",
            "\n",
            "         [[-1.2605e-03, -4.9075e-04, -7.1351e-04],\n",
            "          [-1.5126e-04, -5.7187e-04, -6.4902e-04],\n",
            "          [-4.3307e-04, -4.7395e-04, -1.5368e-04]],\n",
            "\n",
            "         [[-1.3167e-04,  6.2804e-04,  4.0667e-04],\n",
            "          [ 9.9752e-06,  1.4373e-04,  5.9113e-04],\n",
            "          [-3.6371e-04, -3.3053e-04, -1.6873e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 9.3745e-05,  2.9358e-04,  3.3900e-04],\n",
            "          [ 5.2941e-04,  6.8827e-04,  4.4936e-04],\n",
            "          [ 6.5463e-04,  8.7615e-04,  7.3161e-04]],\n",
            "\n",
            "         [[-5.1834e-04, -8.0811e-04, -5.0716e-04],\n",
            "          [-9.1584e-04, -5.1069e-04,  8.5714e-05],\n",
            "          [-1.6129e-04, -1.6735e-04,  2.7970e-04]],\n",
            "\n",
            "         [[ 8.4229e-04,  1.0328e-03,  7.3795e-04],\n",
            "          [ 5.2131e-04,  1.3098e-03,  7.7602e-04],\n",
            "          [ 9.5148e-04,  8.8984e-04,  1.0042e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0778e-04,  1.2288e-03,  3.7704e-04],\n",
            "          [ 1.0216e-03,  5.7218e-04,  1.8107e-04],\n",
            "          [ 2.5603e-04,  6.3943e-04,  8.2998e-04]],\n",
            "\n",
            "         [[-4.5610e-04, -7.9855e-04, -7.3224e-04],\n",
            "          [-8.5541e-04, -2.9765e-04, -8.0997e-04],\n",
            "          [-1.3246e-04, -1.9636e-04, -3.3263e-04]],\n",
            "\n",
            "         [[ 3.5404e-04,  9.4873e-05,  5.8255e-05],\n",
            "          [ 1.2719e-04,  3.6037e-04,  1.1671e-04],\n",
            "          [ 3.1415e-05,  6.7074e-04,  1.1690e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6447e-04,  5.5595e-04,  8.2768e-05],\n",
            "          [ 5.4433e-04,  8.5681e-04,  1.5788e-04],\n",
            "          [ 3.7915e-04,  6.8344e-04,  3.6542e-04]],\n",
            "\n",
            "         [[ 7.5773e-05, -1.5883e-05, -6.6064e-04],\n",
            "          [-4.6135e-04, -1.9084e-04,  2.5440e-05],\n",
            "          [-5.3960e-04, -7.5390e-04, -4.3847e-04]],\n",
            "\n",
            "         [[ 4.2778e-04, -2.2583e-04, -8.6771e-05],\n",
            "          [-1.3185e-04, -2.3835e-04, -6.0903e-04],\n",
            "          [ 2.3420e-04,  5.3291e-04,  3.3969e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4103e-04,  2.2700e-04,  8.6337e-04],\n",
            "          [ 1.3531e-03,  9.4326e-04,  1.1102e-03],\n",
            "          [ 1.2296e-03,  9.9902e-04,  6.4460e-04]],\n",
            "\n",
            "         [[-1.2550e-03, -1.9346e-03, -1.9191e-03],\n",
            "          [-7.1889e-04, -1.2426e-03, -1.5242e-03],\n",
            "          [-1.1694e-03, -1.1621e-03, -1.4320e-03]],\n",
            "\n",
            "         [[ 4.3537e-04,  1.1849e-04,  5.9399e-04],\n",
            "          [ 4.4204e-04,  1.2361e-04,  3.3424e-04],\n",
            "          [-4.7805e-05, -1.2332e-04,  8.9527e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.4573e-04,  1.8554e-04,  4.4442e-04],\n",
            "          [ 5.4976e-05,  2.5795e-04,  7.4931e-05],\n",
            "          [ 5.2691e-04,  7.8806e-04,  3.0265e-04]],\n",
            "\n",
            "         [[ 7.1368e-04,  6.3150e-04,  4.9338e-04],\n",
            "          [ 5.8673e-04,  2.5111e-05,  1.6073e-06],\n",
            "          [ 1.3766e-03,  1.7035e-04,  1.8896e-04]],\n",
            "\n",
            "         [[ 2.2857e-04,  2.0557e-04, -2.6180e-04],\n",
            "          [-9.7623e-05,  4.3997e-04, -3.3114e-04],\n",
            "          [-3.5396e-04,  3.3961e-04,  8.1812e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.3919e-04,  2.4655e-04,  5.0926e-04],\n",
            "          [ 5.8849e-04,  6.1224e-04,  2.6453e-04],\n",
            "          [-4.3395e-04, -1.8446e-04, -6.7662e-04]],\n",
            "\n",
            "         [[ 9.4685e-04, -1.3413e-04,  1.4985e-04],\n",
            "          [ 5.7918e-04,  4.0271e-04, -1.2049e-04],\n",
            "          [-1.6072e-04,  2.2354e-04,  5.8295e-04]],\n",
            "\n",
            "         [[ 1.1421e-03,  3.3355e-05, -3.5210e-04],\n",
            "          [ 9.6220e-04, -3.9732e-05,  9.2606e-05],\n",
            "          [ 7.8165e-04,  2.5343e-04,  3.3597e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.2441e-05, -4.6874e-04, -5.7851e-04],\n",
            "          [-1.6201e-04, -9.6501e-04, -1.4429e-03],\n",
            "          [-1.9270e-04, -7.5057e-04, -6.6127e-04]],\n",
            "\n",
            "         [[ 1.2206e-03,  6.6689e-04,  2.0907e-04],\n",
            "          [ 5.0962e-04,  6.1886e-04,  7.6289e-04],\n",
            "          [ 8.9616e-04, -2.3633e-04,  1.3001e-03]],\n",
            "\n",
            "         [[-4.8922e-04, -3.3235e-04, -4.3209e-05],\n",
            "          [-6.9017e-04, -5.6255e-04, -4.1323e-04],\n",
            "          [-1.1591e-03, -2.4780e-04, -2.2404e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9979e-03, -2.1358e-03, -1.6444e-03],\n",
            "          [-2.0300e-03, -1.5917e-03, -1.1413e-03],\n",
            "          [-1.2232e-03, -1.5658e-03, -1.5288e-03]],\n",
            "\n",
            "         [[ 1.7443e-03,  9.1012e-04,  2.0850e-03],\n",
            "          [ 1.1659e-03,  1.9486e-03,  1.8603e-03],\n",
            "          [ 2.3085e-03,  1.7161e-03,  1.9140e-03]],\n",
            "\n",
            "         [[ 1.2473e-03,  1.0131e-03,  2.0633e-04],\n",
            "          [ 2.0022e-04, -3.5884e-05,  4.7341e-04],\n",
            "          [-7.5226e-04, -3.2412e-04,  1.4993e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.9153e-04, -4.4112e-04, -7.8450e-04],\n",
            "          [-4.1080e-04, -1.2006e-04, -4.6562e-04],\n",
            "          [-3.4869e-04, -5.1749e-05, -2.9128e-04]],\n",
            "\n",
            "         [[ 7.7018e-05,  1.5988e-04,  5.6940e-04],\n",
            "          [ 7.1936e-04,  1.1652e-04,  6.4561e-04],\n",
            "          [ 1.6269e-03,  1.1961e-03, -1.0697e-04]],\n",
            "\n",
            "         [[ 2.8450e-04, -4.7240e-04, -2.5519e-04],\n",
            "          [ 4.0984e-04,  5.2990e-04,  5.5267e-04],\n",
            "          [ 2.4586e-04, -3.0398e-05, -2.6832e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1146e-04,  1.0823e-06, -4.1900e-04],\n",
            "          [-5.1863e-04,  1.7896e-04,  5.8562e-04],\n",
            "          [-2.3155e-04, -1.2731e-04,  5.3708e-04]],\n",
            "\n",
            "         [[-6.8279e-04, -5.3469e-04, -3.5463e-04],\n",
            "          [-9.1310e-04, -1.3753e-03, -1.0177e-03],\n",
            "          [-1.7030e-03, -1.3221e-03, -5.5466e-04]],\n",
            "\n",
            "         [[-6.4602e-04, -6.6702e-04,  4.4602e-04],\n",
            "          [-6.9064e-04, -3.1623e-04, -1.2058e-04],\n",
            "          [-8.5178e-04, -6.7198e-04, -5.1636e-04]]]])}, 58: {'momentum_buffer': tensor([ 1.0498e-03,  4.1389e-04,  1.1366e-03,  1.1419e-03,  1.6518e-03,\n",
            "         7.3758e-04,  8.5928e-04, -1.4924e-04,  1.3495e-03, -3.0596e-04,\n",
            "         2.2720e-03,  1.4405e-03,  2.6628e-03,  3.9998e-04,  2.0359e-03,\n",
            "         2.5003e-03, -5.0054e-04,  1.0089e-03,  2.6447e-03,  1.7316e-03,\n",
            "         1.1249e-03, -9.9871e-04, -3.1634e-04,  1.6021e-03,  1.7662e-03,\n",
            "         8.8272e-04,  1.7982e-03,  1.5119e-03,  1.2582e-03,  1.9682e-03,\n",
            "         4.2169e-04,  1.4825e-03,  1.1607e-03,  6.9329e-04,  1.7805e-03,\n",
            "         1.3181e-03, -1.8478e-04,  1.7942e-03, -4.1837e-04, -1.8683e-04,\n",
            "         3.8873e-04,  4.7424e-04,  6.6747e-04, -9.9352e-04,  4.1063e-04,\n",
            "         7.5950e-04,  2.6249e-04,  1.1951e-03,  1.8247e-03,  2.2163e-04,\n",
            "         2.1012e-03,  1.3703e-03,  2.5815e-05,  7.3840e-04,  2.6143e-03,\n",
            "         2.0105e-03,  1.4329e-03,  3.1423e-04,  6.6475e-04,  1.3717e-03,\n",
            "         1.9372e-04, -1.8703e-04,  9.2341e-04,  1.1902e-03,  6.3799e-04,\n",
            "         1.1752e-03,  3.3472e-04,  1.0413e-04,  2.7117e-03,  1.9353e-03,\n",
            "         1.6372e-03,  1.0602e-03,  8.7266e-04,  1.3700e-03,  1.8210e-03,\n",
            "         1.9757e-03,  1.6131e-03,  1.3144e-04,  8.1655e-04,  1.5264e-03,\n",
            "         3.1194e-03,  1.0816e-04,  9.0897e-04, -4.1287e-04,  1.5932e-03,\n",
            "         1.7197e-04, -7.9851e-04,  1.8065e-03,  2.9378e-04,  9.9517e-04,\n",
            "         3.5002e-04,  1.1305e-03,  3.0715e-04,  1.6027e-03,  1.1595e-03,\n",
            "         9.9298e-04,  6.5404e-04,  1.7459e-03,  5.3291e-04,  1.9708e-03,\n",
            "         6.1028e-04, -4.9737e-05,  2.0158e-03,  3.6193e-04, -1.4541e-04,\n",
            "         1.3440e-03,  2.8903e-03,  6.2929e-04, -5.0795e-04,  1.2098e-03,\n",
            "         2.6360e-04,  9.2819e-04,  1.8804e-03,  1.1542e-03,  2.8164e-03,\n",
            "         3.2233e-03,  4.3401e-04,  1.0365e-03,  5.5847e-04, -7.4379e-05,\n",
            "         2.2636e-03,  3.1272e-04,  1.0594e-04,  1.7765e-03,  1.6175e-04,\n",
            "        -4.1385e-04,  1.9948e-04,  1.5700e-03])}, 59: {'momentum_buffer': tensor([ 9.8658e-04, -3.0490e-04, -1.0317e-03,  5.4843e-04,  5.9588e-06,\n",
            "        -1.7314e-05, -5.9136e-04, -9.3783e-04, -5.7350e-04, -8.8514e-04,\n",
            "        -1.0920e-03,  2.5675e-04,  1.0447e-03, -7.8200e-04,  1.6424e-03,\n",
            "         1.4652e-03, -1.1139e-03,  1.0494e-03,  4.5560e-04, -2.2023e-04,\n",
            "        -3.0726e-04, -1.8222e-04, -7.4750e-04, -1.2512e-05,  1.8674e-04,\n",
            "        -9.0771e-04,  5.2414e-04,  7.5529e-04, -8.4872e-05,  5.0672e-04,\n",
            "        -5.3224e-04, -4.0295e-04,  1.2944e-04, -2.4074e-04, -4.8464e-04,\n",
            "         8.1729e-04, -5.6152e-04,  9.7854e-04, -1.2751e-03, -3.7690e-04,\n",
            "        -1.5979e-04,  4.7129e-04,  6.8289e-05, -1.0302e-03, -2.0753e-04,\n",
            "        -3.0105e-04, -1.1655e-04,  7.8760e-04,  6.6492e-04, -2.4653e-04,\n",
            "         2.2507e-04, -7.3083e-05, -2.7460e-04, -1.2975e-03,  1.6051e-03,\n",
            "         7.1032e-04,  1.3352e-03, -4.3836e-04, -5.0746e-04, -1.5035e-04,\n",
            "        -4.7078e-04, -1.8653e-03, -7.9075e-04, -1.0702e-03, -5.5237e-04,\n",
            "         1.0712e-03,  1.6111e-04, -3.0342e-04, -1.7208e-04,  8.9754e-04,\n",
            "        -4.3282e-04,  3.5616e-04,  1.3409e-04,  2.7034e-04,  1.2066e-03,\n",
            "         8.6105e-04, -5.0523e-04,  6.9318e-05, -6.1884e-04, -7.2406e-04,\n",
            "         8.2845e-04, -8.9777e-04, -9.5731e-05, -1.2056e-03,  7.3826e-04,\n",
            "        -5.0221e-04, -1.2938e-03, -5.9575e-04, -1.0035e-03, -6.4490e-04,\n",
            "        -8.3811e-05, -1.2458e-03, -1.1007e-03,  8.4588e-04,  1.0753e-03,\n",
            "        -2.2048e-04, -4.0824e-04,  3.3382e-04, -1.2541e-03,  1.4828e-03,\n",
            "         2.5953e-04, -2.0157e-03, -4.7421e-04, -6.8531e-04, -1.4791e-03,\n",
            "         1.0223e-04,  1.3550e-03, -7.0405e-04, -1.5656e-03, -8.4028e-04,\n",
            "         1.1435e-03,  6.6391e-04,  6.2661e-04,  1.3263e-04,  8.0831e-04,\n",
            "         1.8766e-03, -5.6813e-04,  2.7662e-04, -4.5055e-04,  1.2227e-03,\n",
            "         1.2355e-03, -1.9254e-05,  1.0550e-03,  3.2996e-04, -2.4814e-04,\n",
            "        -9.0322e-04, -8.0478e-04, -7.4004e-05])}, 60: {'momentum_buffer': tensor([[[[-1.5834e-03]],\n",
            "\n",
            "         [[ 1.0467e-04]],\n",
            "\n",
            "         [[-2.7533e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3105e-04]],\n",
            "\n",
            "         [[-2.5266e-04]],\n",
            "\n",
            "         [[-1.2872e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 6.8663e-04]],\n",
            "\n",
            "         [[-4.6508e-04]],\n",
            "\n",
            "         [[-1.8738e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2599e-03]],\n",
            "\n",
            "         [[-2.1944e-03]],\n",
            "\n",
            "         [[ 1.6014e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4279e-05]],\n",
            "\n",
            "         [[-6.1866e-05]],\n",
            "\n",
            "         [[ 8.4426e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.7696e-04]],\n",
            "\n",
            "         [[ 1.7770e-03]],\n",
            "\n",
            "         [[ 3.8598e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.3486e-04]],\n",
            "\n",
            "         [[ 2.9491e-04]],\n",
            "\n",
            "         [[ 3.2625e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.9109e-04]],\n",
            "\n",
            "         [[-7.5989e-04]],\n",
            "\n",
            "         [[ 5.2696e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.1257e-04]],\n",
            "\n",
            "         [[ 3.6572e-04]],\n",
            "\n",
            "         [[ 1.0370e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9396e-04]],\n",
            "\n",
            "         [[ 6.9242e-04]],\n",
            "\n",
            "         [[ 5.3572e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.5449e-05]],\n",
            "\n",
            "         [[ 3.9306e-04]],\n",
            "\n",
            "         [[ 7.2859e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2033e-04]],\n",
            "\n",
            "         [[ 8.0408e-04]],\n",
            "\n",
            "         [[-4.6494e-04]]]])}, 61: {'momentum_buffer': tensor([ 8.8730e-04,  1.3978e-04,  1.4912e-03,  6.1746e-04,  7.4792e-04,\n",
            "         1.3662e-03,  1.0146e-03,  3.3585e-04,  9.2563e-04,  5.6637e-04,\n",
            "         6.0463e-04,  1.5209e-03,  9.1299e-04,  1.1257e-03,  9.7384e-04,\n",
            "         8.5879e-04,  1.0634e-03,  6.2446e-04,  1.6066e-03,  1.1281e-03,\n",
            "         2.7453e-04,  1.0616e-03,  1.3417e-03,  7.9618e-04,  7.6483e-04,\n",
            "         7.8471e-04,  2.5694e-04,  9.1718e-04,  9.9877e-04,  3.5190e-04,\n",
            "         7.4796e-04,  2.1893e-03,  1.6070e-03,  4.6880e-04,  1.2294e-03,\n",
            "         1.1317e-03,  1.2326e-03,  1.0777e-03,  8.7676e-04,  4.0849e-04,\n",
            "         1.4923e-03,  9.7185e-04,  1.5973e-03,  6.2793e-04,  1.1358e-03,\n",
            "        -1.5244e-05,  6.7905e-04,  6.5332e-05,  1.0900e-03,  7.6582e-04,\n",
            "         9.2830e-04,  2.6404e-04,  1.1282e-03,  4.9532e-04,  1.5825e-03,\n",
            "         1.2361e-03,  7.6423e-04,  8.1985e-04,  8.5245e-04,  1.2268e-03,\n",
            "         9.5684e-04,  5.0775e-04,  1.0521e-03,  1.6840e-03,  1.4873e-03,\n",
            "         6.8061e-04,  7.6201e-04,  5.7525e-04,  1.1749e-03, -6.7401e-05,\n",
            "         1.4770e-03,  3.2024e-04,  1.2355e-03,  5.6291e-04,  1.2631e-03,\n",
            "         1.0429e-03,  9.3901e-04,  9.4132e-04,  8.3745e-04,  1.7117e-03,\n",
            "         6.4752e-04,  1.9693e-03,  5.7612e-04,  9.0074e-04,  7.8512e-04,\n",
            "         1.3810e-03,  1.9957e-03,  4.4900e-04,  1.0988e-03,  9.3737e-04,\n",
            "         1.3849e-03,  1.4411e-03,  1.1823e-03,  1.2700e-03, -2.3045e-04,\n",
            "         6.0699e-04,  1.5107e-03,  1.2263e-03,  1.7970e-03,  1.1344e-03,\n",
            "         1.5226e-03,  1.1628e-03,  8.1682e-04,  1.0251e-03,  1.0180e-03,\n",
            "         1.3704e-03,  8.2417e-04,  7.5123e-04,  1.1887e-03, -1.6453e-04,\n",
            "         1.1008e-03,  2.1334e-04,  3.3986e-04,  7.5530e-04,  1.2600e-03,\n",
            "         1.3533e-03,  4.5631e-04,  7.3748e-04,  1.0865e-03,  5.5611e-04,\n",
            "         1.3950e-03,  6.1629e-04,  7.3116e-04,  1.5464e-03,  1.0264e-03,\n",
            "         1.1383e-03,  8.0928e-05,  1.1689e-03,  7.5488e-04,  8.8439e-04,\n",
            "         1.1977e-03,  1.4433e-04,  1.4102e-03,  6.8165e-04,  4.2121e-04,\n",
            "         9.6582e-04,  1.1288e-03,  1.2968e-03,  1.1119e-03,  1.4710e-03,\n",
            "         1.3340e-03,  6.4085e-04,  7.3574e-04, -1.9059e-04,  2.0836e-03,\n",
            "         9.7832e-04,  9.6580e-04,  3.6150e-04,  1.3122e-03,  8.3837e-04,\n",
            "         1.3894e-03,  8.1653e-04,  4.3445e-04,  1.8139e-03,  5.8283e-04,\n",
            "         7.2663e-04,  1.7491e-03,  7.3283e-04,  1.4508e-03,  1.0623e-03,\n",
            "         1.3481e-03,  1.6797e-03,  6.7568e-04,  4.9594e-04,  9.6746e-04,\n",
            "         6.4518e-04,  1.5442e-03,  1.2873e-03,  1.4278e-03,  1.5204e-03,\n",
            "         5.3136e-04,  9.5093e-04,  1.4543e-03,  3.9573e-04,  7.9410e-04,\n",
            "         1.2885e-03,  9.6122e-04,  9.0657e-04,  1.0791e-03,  9.5272e-04,\n",
            "         4.4260e-04,  6.0834e-04,  1.0940e-03,  1.0623e-03,  4.9428e-04,\n",
            "         5.6424e-04,  7.9355e-04,  4.9073e-04,  1.7724e-03,  6.0712e-04,\n",
            "         1.2598e-03,  7.0138e-04,  9.4255e-04,  4.4342e-04,  7.7174e-04,\n",
            "         1.3316e-03,  1.3211e-03,  8.0894e-04,  9.7313e-04,  8.9252e-04,\n",
            "         1.1207e-03,  9.8728e-04,  1.0282e-03,  1.0730e-03,  2.2744e-03,\n",
            "         1.3811e-03,  1.4123e-03,  1.9936e-03,  8.1144e-04,  1.5336e-03,\n",
            "         4.6932e-04,  1.4793e-03,  7.3452e-04,  5.1427e-04,  1.5066e-03,\n",
            "         1.2765e-03,  1.0209e-03,  3.4206e-04,  1.7499e-03,  1.1534e-03,\n",
            "         1.3612e-03,  9.0299e-04,  1.3448e-04,  1.2079e-03,  5.3558e-04,\n",
            "         1.2445e-03,  1.0797e-03,  7.8069e-04,  1.3395e-03,  7.2295e-04,\n",
            "         7.9701e-04,  1.9266e-03,  2.3703e-04,  1.6685e-03,  8.5491e-04,\n",
            "         1.2832e-03,  9.3920e-04,  5.8708e-04,  1.2193e-03,  1.0627e-03,\n",
            "         1.1133e-03,  1.6807e-03,  1.2158e-03,  7.8007e-04,  9.1608e-04,\n",
            "         3.5826e-04,  6.0566e-04,  4.8312e-04,  4.7006e-04,  1.0508e-03,\n",
            "         4.7724e-04,  5.3769e-04,  9.4011e-04,  1.2270e-03,  1.7141e-03,\n",
            "         4.0690e-05,  6.5058e-04,  1.6333e-03,  9.5925e-04,  1.0993e-03,\n",
            "         4.1654e-04,  9.4225e-04,  1.0520e-03,  1.5759e-03,  7.3158e-04,\n",
            "         9.2925e-04,  8.9356e-04,  1.9198e-04,  5.9565e-04,  1.2073e-03,\n",
            "         1.6387e-03,  1.1132e-03,  2.0343e-03,  4.6548e-04,  7.0842e-04,\n",
            "         1.2271e-03,  2.2287e-03,  7.5709e-04,  1.0154e-03,  1.1363e-03,\n",
            "         7.3850e-04,  1.2934e-03,  5.1036e-04,  1.6688e-03,  1.1721e-03,\n",
            "         1.2010e-03,  4.1701e-04,  7.0680e-04,  9.0772e-04,  1.3372e-03,\n",
            "         2.0989e-04,  1.2326e-03,  6.4254e-04,  8.7916e-04,  1.2984e-03,\n",
            "         4.7401e-04,  1.1913e-03,  1.1479e-03,  2.7989e-04,  1.0133e-03,\n",
            "         1.2559e-03,  1.0257e-03,  1.1849e-03,  1.0760e-03,  7.9068e-04,\n",
            "         1.5612e-03,  9.7678e-04,  6.3356e-04,  9.4217e-04,  8.4150e-04,\n",
            "         1.0757e-03,  1.0685e-03,  1.4050e-03,  6.9718e-04,  3.8917e-04,\n",
            "         1.1014e-03,  1.3280e-03,  1.1323e-03,  6.8047e-04,  1.0475e-03,\n",
            "         7.4208e-04,  1.5054e-03,  8.5868e-04,  1.7135e-03, -4.3369e-04,\n",
            "         2.7172e-04,  7.5655e-04,  1.0269e-03,  4.0886e-04,  6.3957e-04,\n",
            "         1.8047e-03,  1.3899e-03,  6.3071e-04,  1.3516e-03,  1.1413e-03,\n",
            "         1.8005e-03,  9.3402e-04,  1.1899e-03,  1.5629e-03,  1.1012e-03,\n",
            "         9.1058e-04,  8.2306e-04,  1.8176e-03,  9.2851e-04,  1.3829e-03,\n",
            "         1.0043e-04,  1.1621e-03,  4.4459e-04,  1.1238e-03,  1.4648e-03,\n",
            "        -4.2222e-04,  1.1036e-03,  8.4219e-04,  1.2603e-03,  2.0267e-04,\n",
            "         9.7993e-04,  5.6041e-04,  1.2481e-03,  4.6892e-04,  7.5868e-04,\n",
            "         1.3250e-03,  1.8119e-03,  7.2697e-04,  8.3006e-04,  8.2315e-04,\n",
            "         1.3242e-03,  8.1908e-04,  5.9987e-04,  1.2680e-03,  1.0771e-03,\n",
            "         1.1484e-03,  1.1665e-03,  1.1270e-03,  1.1620e-03,  1.6018e-03,\n",
            "         9.6261e-04,  5.1612e-04,  1.7698e-03,  9.8874e-04,  3.2382e-04,\n",
            "         1.0311e-03,  1.2832e-03,  7.1890e-04,  7.5820e-04,  6.2272e-04,\n",
            "         1.1076e-03,  8.5961e-04,  3.7804e-04,  1.1018e-03,  1.0786e-03,\n",
            "         1.0541e-03,  1.1499e-03,  4.2694e-04,  6.4902e-04,  1.4715e-03,\n",
            "         1.7037e-03,  3.4512e-04,  6.9771e-04,  1.1653e-03, -4.7400e-04,\n",
            "         8.3097e-04, -2.8831e-04,  1.3995e-03,  1.1373e-03,  1.1480e-03,\n",
            "         7.1773e-04,  9.7365e-04,  1.4436e-03,  6.6939e-04,  3.0510e-04,\n",
            "         1.3756e-03,  1.1495e-03,  1.1069e-03,  1.6641e-03,  7.4388e-04,\n",
            "         1.3878e-03,  1.0810e-03,  1.7302e-03,  9.7059e-04,  5.9961e-04,\n",
            "         1.3883e-03,  1.0789e-03,  4.3397e-04,  1.0581e-03,  8.9755e-04,\n",
            "         6.7823e-04,  5.3857e-04,  1.1016e-03,  1.2666e-03,  4.5561e-04,\n",
            "         9.1602e-04,  1.1074e-03,  6.4474e-04,  1.4355e-03,  9.6050e-04,\n",
            "         1.1617e-03,  1.0678e-03,  5.6698e-04,  1.8252e-03,  1.0992e-03,\n",
            "         1.0010e-03,  1.2137e-03,  1.2822e-03,  9.4349e-04,  3.7362e-04,\n",
            "         4.1820e-04,  1.4359e-03,  6.1464e-04,  1.0988e-03,  1.2757e-03,\n",
            "         9.2796e-04,  9.3047e-04,  1.0802e-03, -1.3594e-04,  7.8591e-04,\n",
            "         8.7747e-04,  1.8096e-03,  1.0682e-03,  6.1836e-04,  1.5315e-03,\n",
            "         1.2176e-03,  9.6460e-04,  1.1384e-03,  3.6471e-04,  8.3149e-04,\n",
            "         1.3168e-03,  1.1438e-03,  6.4311e-04,  1.2473e-03,  1.2114e-03,\n",
            "         3.7488e-04,  1.1502e-03,  9.3290e-04,  1.3121e-03,  8.1023e-04,\n",
            "         8.7507e-04,  1.0033e-03,  1.0633e-03,  2.3652e-04,  1.4459e-03,\n",
            "         6.6572e-04,  1.1521e-03,  1.4355e-03,  9.7520e-04,  1.3513e-03,\n",
            "         9.0037e-04,  9.3380e-04,  6.2109e-04,  4.5885e-04,  5.2539e-04,\n",
            "         1.2411e-03,  1.5130e-03,  3.7984e-04,  2.6835e-05,  6.8657e-04,\n",
            "         9.9076e-04,  1.1063e-03,  1.1460e-03,  8.3609e-04,  1.2196e-03,\n",
            "         1.1500e-03,  9.1100e-04,  1.4320e-03, -7.0132e-05,  6.5533e-04,\n",
            "         1.2582e-03,  1.6044e-03,  1.3503e-03,  1.5154e-03,  1.5034e-03,\n",
            "         1.2741e-03,  3.0506e-04])}, 62: {'momentum_buffer': tensor([-1.1161e-04,  3.1274e-04,  4.7168e-06, -2.9261e-04, -3.1055e-04,\n",
            "         3.8457e-04, -1.0575e-04,  3.3028e-04,  2.8909e-04, -9.3847e-04,\n",
            "         7.0252e-05, -1.8463e-04, -8.0553e-04, -1.3140e-05, -2.1071e-05,\n",
            "         5.7452e-05, -3.8697e-04,  9.2419e-05,  8.3188e-05, -8.6161e-05,\n",
            "        -6.0623e-05, -1.9354e-04, -3.0006e-04, -4.5797e-04,  2.1470e-04,\n",
            "         3.0523e-04,  1.9015e-04, -1.8403e-04, -3.9775e-04, -3.5252e-04,\n",
            "         4.0085e-04, -2.8522e-04,  1.2599e-04, -2.2584e-04,  2.8413e-04,\n",
            "        -1.5968e-04, -1.7370e-04,  1.9213e-04,  9.0620e-06, -2.6325e-04,\n",
            "        -1.1278e-04,  5.1036e-05,  6.0756e-05,  7.7062e-05,  1.2516e-04,\n",
            "         1.3387e-04,  1.0390e-04,  8.5341e-05,  5.3422e-04, -2.3533e-05,\n",
            "        -4.1590e-04, -7.4004e-04,  1.2687e-04, -8.3898e-06,  5.4775e-04,\n",
            "         3.0557e-04,  3.8999e-05,  1.2300e-05,  4.0983e-04,  3.2963e-05,\n",
            "         2.0616e-04, -7.6205e-05, -3.6326e-04,  7.8904e-05, -2.8180e-04,\n",
            "        -1.4102e-04,  4.3973e-04, -2.5092e-04,  5.6574e-04, -1.4882e-04,\n",
            "        -4.8399e-04, -1.5183e-04, -1.8907e-04, -1.7371e-04,  2.5450e-04,\n",
            "         1.6414e-04,  7.6855e-05,  1.5468e-04, -1.5107e-04,  2.5715e-04,\n",
            "         2.3368e-05,  1.8387e-04, -2.0450e-05, -4.3951e-05, -2.0234e-04,\n",
            "         4.7389e-04,  3.1789e-04,  2.9009e-04, -2.5263e-04, -9.3030e-05,\n",
            "         5.3633e-05,  8.0623e-05, -2.3063e-04, -3.5406e-04, -6.3387e-04,\n",
            "        -2.9316e-04,  3.5339e-04,  4.7767e-04,  5.2838e-04, -1.3166e-04,\n",
            "         7.6704e-04, -2.8413e-04,  1.8939e-04, -5.3390e-05,  3.0411e-04,\n",
            "         2.7625e-04,  7.8030e-05, -3.2284e-05, -4.5039e-06, -9.5506e-04,\n",
            "        -9.2903e-05,  3.6559e-04,  4.1351e-04,  2.7777e-05,  3.5499e-04,\n",
            "         3.4687e-04, -4.1359e-04,  5.0364e-05,  1.1200e-04, -2.4595e-04,\n",
            "         4.0852e-04,  5.7056e-04, -7.1946e-04, -1.6913e-04, -1.7634e-05,\n",
            "         2.8382e-04, -2.3800e-04,  7.2727e-04,  5.1938e-04,  2.7899e-04,\n",
            "         1.7480e-04, -5.3403e-04,  1.3022e-04, -5.8623e-04,  2.0007e-04,\n",
            "         1.3819e-04, -1.1316e-04, -9.6426e-05,  1.1687e-04,  7.1123e-05,\n",
            "        -1.5218e-04, -7.3592e-04, -1.5453e-04, -5.1962e-04,  2.7678e-04,\n",
            "        -1.9169e-04,  2.1499e-04, -9.1054e-05,  5.9009e-04,  1.6109e-04,\n",
            "         4.9988e-04, -4.9070e-04, -7.8112e-05,  4.9640e-04, -4.0658e-04,\n",
            "        -6.8252e-05,  3.6165e-04,  2.2017e-04,  5.4229e-04, -2.1295e-04,\n",
            "        -1.9089e-05,  5.8419e-05,  1.7228e-04,  1.4298e-04,  2.4638e-04,\n",
            "        -3.5321e-04, -3.5766e-04,  2.8333e-05,  1.4671e-04,  1.9113e-04,\n",
            "         2.7958e-04,  1.9393e-04, -1.4845e-04, -1.6909e-05,  8.9972e-04,\n",
            "         3.3499e-04, -4.5289e-05, -1.2881e-05,  1.5008e-05, -4.8892e-04,\n",
            "        -4.3043e-04, -4.7865e-06, -3.0193e-04,  2.4230e-04, -1.3834e-05,\n",
            "         1.3962e-04,  2.6005e-04,  2.3503e-04,  1.8587e-04,  2.1878e-04,\n",
            "        -7.1825e-05, -1.5273e-05, -8.7402e-05, -6.8847e-04, -4.2089e-04,\n",
            "         5.8660e-04, -1.2943e-04,  2.6123e-04, -6.7466e-05, -3.7236e-04,\n",
            "         5.1661e-04, -1.5369e-04,  2.6566e-04, -3.2045e-05,  5.4331e-04,\n",
            "        -1.2716e-04,  1.5008e-04, -4.1668e-04,  2.9609e-04,  5.4685e-06,\n",
            "         4.8979e-05, -2.7495e-05, -1.0086e-04, -1.7996e-04,  1.8767e-04,\n",
            "        -1.9924e-04, -4.1054e-04,  1.7289e-04,  6.6383e-04,  1.2163e-05,\n",
            "         4.4001e-04, -6.5248e-05, -2.0602e-04, -7.6404e-05,  1.6918e-04,\n",
            "         3.4306e-04, -2.6706e-04, -2.9141e-04,  4.4000e-04, -2.3180e-04,\n",
            "         1.6792e-04,  4.0660e-05, -2.4234e-04,  6.2746e-04,  8.3313e-04,\n",
            "         2.0186e-04, -6.5942e-04, -1.2201e-04,  1.3976e-04,  4.7451e-05,\n",
            "         4.7845e-04,  5.1786e-04, -1.4695e-04, -4.7603e-04,  1.3806e-04,\n",
            "        -6.4937e-04, -1.6874e-05,  4.8427e-06, -3.8579e-04,  2.5305e-04,\n",
            "         5.6038e-05, -4.0700e-04,  2.9958e-04,  5.2246e-06,  2.6888e-04,\n",
            "        -1.1223e-03,  8.2967e-06, -1.4581e-04,  7.1908e-05,  3.1313e-04,\n",
            "        -2.5056e-06,  4.4544e-04,  3.5013e-04, -2.3893e-04,  1.8615e-04,\n",
            "         3.6918e-04, -6.0624e-04,  1.3559e-04, -1.0708e-04,  2.2279e-04,\n",
            "         1.4440e-04,  2.5052e-04,  5.8957e-04, -6.6540e-05, -3.3187e-05,\n",
            "         5.3452e-04,  2.2667e-04, -4.5460e-05, -2.0903e-05,  8.9446e-05,\n",
            "        -2.6280e-05, -3.3634e-05, -1.9571e-04,  1.7373e-04,  1.8503e-04,\n",
            "         1.8977e-04, -3.7400e-05, -5.1920e-05,  3.6358e-04,  5.8160e-04,\n",
            "         1.9839e-04,  5.0538e-04, -4.0301e-04, -1.2303e-04, -1.1390e-04,\n",
            "        -4.5849e-04, -8.7349e-04,  1.1633e-04, -5.5179e-05, -9.5376e-05,\n",
            "        -3.1928e-04, -2.8931e-04, -2.9121e-04,  4.7123e-04, -1.8647e-04,\n",
            "         4.4266e-05,  1.5374e-04,  2.5213e-04,  1.0019e-04,  3.2901e-04,\n",
            "         1.7590e-04, -3.9258e-04, -2.7972e-04, -8.3586e-06, -2.3808e-04,\n",
            "         5.2210e-04, -2.4798e-04,  4.0743e-04, -1.9027e-04,  1.5083e-04,\n",
            "         2.2863e-05, -5.6611e-04, -3.0642e-04,  7.4431e-05, -8.4691e-04,\n",
            "         6.8398e-05,  2.0434e-04,  4.9786e-04,  2.9201e-05,  3.0606e-04,\n",
            "         1.8120e-04, -2.0363e-04,  4.3763e-04,  5.0462e-04,  1.9343e-04,\n",
            "         3.6625e-04,  2.5395e-04,  6.1994e-05,  8.4835e-04, -3.4474e-04,\n",
            "        -4.1070e-04,  4.2766e-04,  2.3041e-04, -6.2187e-04, -2.2217e-04,\n",
            "        -3.7700e-04, -4.6164e-04, -6.6616e-05, -2.6037e-04,  1.2467e-04,\n",
            "        -2.2369e-04,  1.5980e-04,  3.5028e-04,  2.7295e-04, -2.6538e-04,\n",
            "         2.4582e-04,  2.2205e-05,  1.4002e-04, -1.3538e-04,  2.0361e-04,\n",
            "         2.0902e-04,  1.7439e-04, -8.2814e-05, -6.2067e-05, -4.3643e-04,\n",
            "         4.4805e-04,  3.6865e-04,  2.1231e-04,  2.0214e-04,  5.9726e-04,\n",
            "        -2.9055e-04,  2.7623e-04, -2.8819e-04, -3.5943e-05,  2.9371e-06,\n",
            "         1.0907e-04, -4.3190e-05,  4.9256e-04, -2.8594e-04, -4.0076e-04,\n",
            "        -4.8672e-04,  2.5213e-04, -5.9447e-05,  4.2374e-04,  2.7089e-04,\n",
            "         1.1362e-05, -2.8650e-04,  8.0744e-04, -2.3120e-04,  2.9354e-04,\n",
            "        -4.5060e-04,  3.5604e-04,  1.5583e-04, -2.3398e-04, -3.6305e-04,\n",
            "        -4.2137e-04, -3.0356e-05, -3.8709e-04, -1.1504e-04,  1.0875e-04,\n",
            "        -6.5263e-04, -4.9955e-04,  9.0164e-05,  3.6083e-04, -3.2305e-04,\n",
            "        -4.1934e-04,  5.5496e-04, -1.0089e-04, -2.5573e-04,  1.5223e-04,\n",
            "         3.9626e-04,  2.7145e-04, -4.3286e-05, -2.8337e-07,  5.2333e-04,\n",
            "         4.7334e-04, -8.8560e-05,  1.2152e-04,  1.5078e-04, -2.4917e-04,\n",
            "         1.1903e-04, -1.5661e-04, -2.8245e-04, -4.1714e-04, -2.9804e-04,\n",
            "        -3.0514e-04, -6.3747e-04, -2.9046e-04,  3.1424e-04, -4.5797e-05,\n",
            "        -1.5089e-04, -2.3798e-05,  3.9575e-06, -5.7130e-06, -3.4547e-04,\n",
            "        -2.8765e-05,  3.1241e-04, -1.1666e-04,  2.9636e-04, -9.8621e-05,\n",
            "        -1.9701e-04,  2.2717e-05,  5.6849e-04, -2.2706e-05, -1.7409e-04,\n",
            "        -4.2847e-04, -2.7918e-05, -3.9253e-04,  6.5900e-05, -2.4193e-04,\n",
            "        -2.3136e-04, -3.3976e-04,  1.1564e-04, -2.1636e-04,  2.7713e-04,\n",
            "         3.6874e-04,  3.4012e-04,  5.3023e-04,  2.0677e-04, -1.1423e-04,\n",
            "         7.8900e-06, -4.9635e-04, -6.5351e-07,  2.0445e-04,  8.3627e-05,\n",
            "         3.2555e-04, -2.6243e-04,  3.4674e-04,  3.8030e-04,  1.0456e-04,\n",
            "        -3.7701e-06,  2.8222e-04, -1.4051e-04, -8.8841e-06, -1.9401e-04,\n",
            "        -3.3930e-04,  4.0508e-04,  3.3543e-04, -4.8850e-05,  3.0000e-04,\n",
            "        -2.0221e-04,  3.3162e-04, -8.8031e-05, -3.7002e-04,  3.1598e-04,\n",
            "        -1.6516e-04, -3.2939e-05,  1.1628e-04,  8.5583e-05, -3.5072e-04,\n",
            "        -2.5323e-04,  1.3130e-05, -4.0953e-05, -7.5919e-04, -2.8708e-04,\n",
            "         6.3857e-04,  5.8027e-05,  1.3814e-04, -1.0494e-04,  3.1822e-04,\n",
            "        -1.9421e-04,  6.1737e-05, -6.3635e-04,  2.2117e-04, -3.3632e-04,\n",
            "         3.0686e-04, -1.2745e-04, -8.1036e-05,  4.0939e-04,  4.0603e-04,\n",
            "        -4.5388e-04, -1.8038e-05])}, 63: {'momentum_buffer': tensor([[[[-8.4331e-04]],\n",
            "\n",
            "         [[-5.6604e-04]],\n",
            "\n",
            "         [[-4.8570e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7874e-04]],\n",
            "\n",
            "         [[-2.8553e-04]],\n",
            "\n",
            "         [[-3.3401e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.6388e-04]],\n",
            "\n",
            "         [[ 5.1727e-04]],\n",
            "\n",
            "         [[ 7.8292e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3685e-04]],\n",
            "\n",
            "         [[ 5.7325e-04]],\n",
            "\n",
            "         [[-2.7317e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.1716e-04]],\n",
            "\n",
            "         [[ 5.5292e-04]],\n",
            "\n",
            "         [[ 9.8891e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7279e-04]],\n",
            "\n",
            "         [[-1.0545e-04]],\n",
            "\n",
            "         [[ 8.7887e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.7602e-04]],\n",
            "\n",
            "         [[ 1.4182e-04]],\n",
            "\n",
            "         [[-1.1814e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0278e-04]],\n",
            "\n",
            "         [[ 1.0811e-05]],\n",
            "\n",
            "         [[ 7.2124e-04]]],\n",
            "\n",
            "\n",
            "        [[[-6.2634e-04]],\n",
            "\n",
            "         [[-2.3068e-04]],\n",
            "\n",
            "         [[-7.2059e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0279e-04]],\n",
            "\n",
            "         [[-6.6536e-04]],\n",
            "\n",
            "         [[ 5.5370e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0079e-04]],\n",
            "\n",
            "         [[ 4.4782e-04]],\n",
            "\n",
            "         [[-7.6289e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8547e-04]],\n",
            "\n",
            "         [[ 4.2978e-04]],\n",
            "\n",
            "         [[ 1.9079e-04]]]])}, 64: {'momentum_buffer': tensor([ 7.0345e-04,  9.7238e-04,  2.4071e-03,  2.3658e-03,  1.8187e-03,\n",
            "        -6.0850e-04,  7.6497e-04,  1.2307e-03,  7.5151e-04,  1.5055e-03,\n",
            "         1.3169e-03,  1.1104e-03,  1.6696e-03,  1.4290e-03,  6.8846e-04,\n",
            "         9.0755e-06,  9.6157e-04,  1.4360e-03,  8.8675e-04,  5.6374e-04,\n",
            "         1.6402e-03,  1.7087e-03,  2.0087e-03,  7.7363e-04,  1.3254e-03,\n",
            "         8.9410e-04,  7.6140e-04, -3.0122e-04,  3.1587e-04,  8.6777e-04,\n",
            "         1.0925e-03,  1.9029e-03,  1.4457e-04,  3.1307e-04,  1.5239e-04,\n",
            "         4.6058e-04,  2.2307e-03,  2.7883e-03,  9.2728e-04,  1.0474e-03,\n",
            "         1.2238e-03,  3.4042e-04,  2.5138e-03,  1.1287e-03,  1.7511e-03,\n",
            "         1.6102e-03,  3.6764e-04,  1.0622e-03,  1.8311e-03,  6.2047e-04,\n",
            "         4.5641e-04,  1.5170e-03,  2.8190e-03,  9.0248e-04,  2.2033e-03,\n",
            "         1.5351e-03, -8.7162e-04,  5.9650e-04,  3.0336e-04,  1.0313e-03,\n",
            "         1.0857e-03,  9.4873e-04,  2.6241e-03,  7.2118e-04,  4.1501e-04,\n",
            "         7.7676e-04,  3.5092e-04,  7.8539e-04,  7.4078e-04,  1.9207e-03,\n",
            "         5.9404e-04,  4.0366e-04,  4.6651e-04,  2.0329e-03, -6.9111e-04,\n",
            "         7.2891e-04,  5.2582e-05,  1.8411e-03,  6.5467e-04, -2.8942e-04,\n",
            "         5.5282e-04,  4.3560e-05,  9.4337e-04, -2.0612e-04,  4.4426e-04,\n",
            "         1.6223e-03,  2.2894e-03,  7.6087e-04,  2.7965e-03, -2.0607e-04,\n",
            "        -1.8602e-05,  4.5278e-04, -2.8371e-04,  6.5969e-04, -1.5757e-05,\n",
            "         9.0989e-04,  6.8590e-04,  1.7800e-03,  6.3951e-04,  1.2999e-03,\n",
            "        -6.3028e-05,  1.5266e-03,  1.2581e-03,  1.6456e-03,  7.8504e-04,\n",
            "         1.5071e-03,  1.5052e-03,  1.2721e-03,  7.8558e-04,  1.6455e-03,\n",
            "         1.2684e-03,  2.0267e-03,  9.6658e-04,  1.4940e-03,  6.7569e-04,\n",
            "         7.0325e-04,  1.4414e-04,  2.5195e-03, -1.3511e-03,  3.0152e-03,\n",
            "         1.3624e-03, -4.5344e-04,  4.2830e-05,  1.2536e-03,  4.8956e-04,\n",
            "         1.1742e-03,  1.4840e-03,  1.1031e-03])}, 65: {'momentum_buffer': tensor([ 5.2527e-04,  8.3829e-04,  2.3175e-04,  4.6152e-04,  1.5328e-03,\n",
            "        -8.8895e-04,  1.2759e-03,  9.8000e-05,  8.2392e-04,  5.4730e-04,\n",
            "         3.8360e-04,  1.1355e-04,  6.7985e-04,  7.4125e-04, -4.9979e-04,\n",
            "        -6.7733e-04,  7.1977e-04,  3.9146e-04, -7.1530e-05, -1.2122e-03,\n",
            "         8.7622e-04,  6.4845e-04,  1.4526e-04, -9.3823e-04,  5.8194e-04,\n",
            "         2.0559e-04, -3.1407e-04, -3.7068e-04, -1.5725e-03, -4.0755e-04,\n",
            "        -5.2770e-04, -1.5147e-04, -7.1961e-04,  9.0140e-05,  5.7058e-05,\n",
            "        -8.0667e-04,  2.4689e-04,  1.4806e-03,  1.0666e-04, -2.4234e-04,\n",
            "        -8.4909e-04, -1.3507e-03,  5.1308e-04, -1.2245e-04,  4.9285e-04,\n",
            "        -2.4542e-04,  6.6435e-07,  6.5485e-04,  6.6803e-04, -7.8937e-04,\n",
            "        -1.4441e-03, -8.4201e-04,  1.4907e-03, -5.1386e-04,  1.4947e-03,\n",
            "         4.4230e-05, -1.2278e-03, -5.9509e-04, -8.7481e-04, -6.6762e-04,\n",
            "         3.4563e-04,  6.0412e-04,  3.7995e-04,  3.2915e-04, -9.5723e-05,\n",
            "         1.8820e-04, -3.6334e-04, -5.6145e-04,  1.2924e-04,  5.1707e-06,\n",
            "         4.5363e-04,  4.8809e-04,  4.3429e-05,  8.4780e-04, -6.5220e-04,\n",
            "        -4.4755e-04, -3.2219e-04,  8.9756e-04, -2.9166e-04, -3.9708e-04,\n",
            "        -1.5518e-04, -1.2678e-03, -5.8867e-04, -5.6971e-04,  4.2794e-04,\n",
            "         1.4383e-03,  5.6941e-04, -1.6639e-04,  1.1507e-03, -3.2474e-04,\n",
            "        -1.0776e-03, -9.2020e-05, -1.1427e-03, -1.0044e-03, -8.5674e-04,\n",
            "        -6.2307e-04,  3.0033e-04, -2.1191e-04, -4.0448e-04,  1.0166e-03,\n",
            "        -1.3900e-03, -2.1016e-04, -4.0250e-05, -8.8799e-04,  1.0292e-04,\n",
            "        -4.6200e-04, -1.1274e-04,  4.8637e-04,  4.0273e-04,  4.0031e-04,\n",
            "         1.6016e-04,  7.8280e-04, -5.4747e-05,  3.8882e-04, -6.4482e-04,\n",
            "        -1.4925e-04,  2.9409e-04, -2.1981e-04, -6.4579e-04,  2.0012e-03,\n",
            "         7.7428e-04, -1.5702e-03, -1.3158e-03, -1.3091e-06, -3.2768e-04,\n",
            "         1.8096e-04,  5.6470e-04,  4.6076e-04])}, 66: {'momentum_buffer': tensor([[[[ 8.0075e-04,  6.1382e-04,  2.3842e-04],\n",
            "          [ 7.5314e-04,  6.2904e-04,  3.8480e-04],\n",
            "          [ 5.9426e-04,  7.0018e-04,  5.5434e-04]],\n",
            "\n",
            "         [[ 5.9076e-04,  8.4044e-04,  1.8125e-04],\n",
            "          [ 1.0817e-03,  9.7776e-04,  2.3782e-04],\n",
            "          [ 6.8962e-04,  2.1221e-04, -1.2958e-04]],\n",
            "\n",
            "         [[ 5.6817e-04,  4.0151e-04, -2.2310e-04],\n",
            "          [-2.1307e-05, -1.0592e-05,  3.4285e-04],\n",
            "          [-2.8995e-04,  1.3889e-04,  5.3412e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.4914e-04, -4.2087e-04, -6.0213e-04],\n",
            "          [-2.8676e-04, -4.0863e-04, -2.8467e-04],\n",
            "          [-3.7925e-04, -3.8048e-05, -5.1511e-04]],\n",
            "\n",
            "         [[ 3.2487e-04, -9.6910e-05,  2.5172e-04],\n",
            "          [ 2.5442e-04,  3.4771e-04,  6.3319e-05],\n",
            "          [ 3.9703e-04,  5.7098e-05,  2.8101e-04]],\n",
            "\n",
            "         [[ 8.5841e-05,  1.0148e-04,  1.1651e-04],\n",
            "          [-4.1764e-04, -1.8671e-04, -3.2782e-04],\n",
            "          [-5.4654e-04, -2.2211e-04, -1.7102e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5939e-03,  2.1661e-03,  2.7745e-03],\n",
            "          [ 1.3753e-03,  1.5895e-03,  2.0990e-03],\n",
            "          [ 1.4794e-03,  1.3101e-03,  1.9457e-03]],\n",
            "\n",
            "         [[-8.4024e-04, -8.6188e-04, -1.2256e-03],\n",
            "          [-4.3496e-04, -5.6590e-04, -1.4932e-03],\n",
            "          [-1.2197e-03, -1.3125e-03, -1.3803e-03]],\n",
            "\n",
            "         [[-1.1114e-03,  4.0025e-04,  2.8510e-04],\n",
            "          [-6.9774e-04, -3.2950e-05, -4.1801e-04],\n",
            "          [-7.8746e-04, -4.3539e-04, -4.4000e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.7907e-04, -6.8588e-04, -1.2221e-03],\n",
            "          [-2.7813e-04, -3.9905e-05, -9.1782e-04],\n",
            "          [-3.0099e-04, -6.0401e-04,  7.2286e-05]],\n",
            "\n",
            "         [[-1.3795e-03, -6.5320e-04, -6.1672e-04],\n",
            "          [-2.1650e-03, -1.3267e-03, -6.7223e-04],\n",
            "          [-1.4535e-03, -8.5091e-04, -2.5715e-04]],\n",
            "\n",
            "         [[-7.2980e-05, -1.1518e-04, -3.6116e-04],\n",
            "          [-9.3719e-06, -1.5460e-04, -2.1410e-04],\n",
            "          [-2.7074e-05, -2.6810e-04, -2.1469e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.6544e-04, -5.2911e-04, -5.6900e-04],\n",
            "          [-3.6138e-04, -1.6410e-04, -4.1593e-04],\n",
            "          [-2.3808e-04,  1.4539e-04, -1.6755e-04]],\n",
            "\n",
            "         [[ 1.0357e-04,  1.4797e-04,  4.0651e-04],\n",
            "          [-3.1580e-04,  2.7958e-04, -2.2434e-04],\n",
            "          [-6.0473e-04,  2.3748e-04,  3.8278e-04]],\n",
            "\n",
            "         [[-7.5408e-05, -1.3199e-07, -9.0436e-05],\n",
            "          [ 2.0411e-05,  2.4685e-04,  2.9109e-04],\n",
            "          [ 1.2364e-04,  1.8968e-04,  3.2211e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1845e-04,  1.5675e-04,  1.4326e-04],\n",
            "          [ 2.3851e-04,  3.1081e-04,  4.3218e-04],\n",
            "          [ 4.2729e-04,  2.6579e-04, -1.3737e-04]],\n",
            "\n",
            "         [[-1.2545e-04, -5.2476e-04,  2.1681e-05],\n",
            "          [-5.7387e-04, -1.2987e-04, -1.0052e-04],\n",
            "          [-1.1771e-04,  2.4569e-04,  2.9769e-04]],\n",
            "\n",
            "         [[-8.6581e-05, -1.7350e-04,  7.8452e-06],\n",
            "          [ 1.7685e-04,  1.0948e-04,  2.6298e-04],\n",
            "          [ 3.7040e-04, -2.0512e-05,  4.1707e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.8495e-04,  7.4358e-04,  1.3165e-03],\n",
            "          [ 8.4606e-04,  6.9931e-04,  8.6916e-04],\n",
            "          [ 9.9860e-04,  4.0356e-05,  2.1029e-04]],\n",
            "\n",
            "         [[ 2.0750e-04,  4.6051e-04,  6.1684e-04],\n",
            "          [ 7.3117e-04,  4.5809e-04,  5.1673e-04],\n",
            "          [ 7.9330e-04,  2.4780e-04,  3.9418e-04]],\n",
            "\n",
            "         [[-5.8682e-04, -8.4572e-04, -4.0476e-04],\n",
            "          [-1.0455e-03, -1.1295e-03, -1.0469e-03],\n",
            "          [-6.3582e-04, -1.2315e-03, -9.5465e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7289e-05,  6.1989e-06,  4.9072e-04],\n",
            "          [-7.8553e-04, -7.7488e-04,  1.8710e-04],\n",
            "          [-7.2617e-04, -1.3891e-04, -7.1141e-04]],\n",
            "\n",
            "         [[ 6.8992e-04,  3.8914e-04,  1.2189e-03],\n",
            "          [ 8.5743e-04,  7.4798e-04,  9.3189e-04],\n",
            "          [ 1.9386e-04,  6.9549e-05,  7.3553e-04]],\n",
            "\n",
            "         [[ 7.7369e-05, -2.5931e-04, -9.5905e-04],\n",
            "          [ 3.9985e-04,  6.2935e-05, -3.4418e-04],\n",
            "          [-4.8939e-05, -2.1017e-04, -4.5943e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8646e-04,  3.1856e-04,  3.2178e-04],\n",
            "          [ 5.3710e-04,  6.2070e-04,  5.0019e-04],\n",
            "          [ 4.7872e-04,  9.2726e-04,  7.8078e-04]],\n",
            "\n",
            "         [[ 4.6117e-04,  6.1051e-04,  7.4193e-04],\n",
            "          [ 4.7939e-04,  7.5912e-04,  5.0546e-04],\n",
            "          [ 4.1959e-04,  4.8046e-04, -2.4412e-04]],\n",
            "\n",
            "         [[ 6.5155e-04,  1.6538e-03,  1.0710e-03],\n",
            "          [ 8.8586e-04,  1.0271e-03,  1.1842e-03],\n",
            "          [ 4.5386e-04,  8.8491e-04,  9.2663e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5834e-03,  7.1645e-04,  5.7831e-04],\n",
            "          [ 1.0445e-03,  8.5185e-04,  8.6841e-04],\n",
            "          [ 7.0172e-05,  9.0257e-04,  8.5917e-04]],\n",
            "\n",
            "         [[-4.4481e-04, -1.8599e-05, -1.0491e-04],\n",
            "          [-4.6848e-06, -4.4729e-04,  5.4521e-04],\n",
            "          [ 6.3506e-04,  4.0609e-06,  7.4829e-04]],\n",
            "\n",
            "         [[ 3.4973e-04, -1.6871e-04, -1.3767e-04],\n",
            "          [-8.7053e-06, -5.7597e-04, -6.2785e-04],\n",
            "          [-3.6252e-04, -7.1721e-04, -7.2043e-04]]],\n",
            "\n",
            "\n",
            "        [[[-4.1921e-04, -3.5705e-04, -3.5925e-04],\n",
            "          [ 1.6327e-04,  2.7785e-04,  1.4759e-04],\n",
            "          [ 6.2912e-05,  9.6559e-05,  2.6817e-04]],\n",
            "\n",
            "         [[-2.0448e-04,  5.1102e-04,  8.6471e-04],\n",
            "          [-6.2011e-04,  1.3522e-04,  1.0151e-03],\n",
            "          [-6.5522e-04, -1.8756e-04, -5.2488e-05]],\n",
            "\n",
            "         [[ 4.0444e-04,  9.9295e-07,  6.1625e-04],\n",
            "          [ 1.3598e-04,  8.1723e-04,  1.0998e-03],\n",
            "          [ 8.5671e-04,  7.3383e-04,  8.4539e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.3464e-04,  4.8293e-04,  6.7400e-04],\n",
            "          [-1.0205e-04,  1.9105e-04,  1.2997e-03],\n",
            "          [ 4.6675e-04,  1.1441e-03,  9.5114e-04]],\n",
            "\n",
            "         [[-1.2851e-05,  2.1017e-04, -2.4573e-04],\n",
            "          [-5.3838e-04,  1.3271e-04, -5.8013e-04],\n",
            "          [-1.2037e-03, -7.9511e-04, -4.3785e-04]],\n",
            "\n",
            "         [[ 4.6612e-05, -9.1487e-05, -5.1374e-04],\n",
            "          [ 1.9629e-04,  2.0008e-04, -2.0196e-04],\n",
            "          [-2.1536e-04, -2.6147e-04, -7.9835e-04]]]])}, 67: {'momentum_buffer': tensor([ 2.1814e-03,  2.3638e-03,  6.9394e-04,  1.2963e-03,  1.3456e-03,\n",
            "         1.1221e-04,  1.4675e-03,  1.0477e-03,  1.4573e-03,  4.6948e-04,\n",
            "         3.3998e-03,  7.8295e-04,  1.5256e-03,  1.1216e-03,  2.6101e-03,\n",
            "         4.0585e-04,  3.6042e-04,  1.3980e-04, -1.0794e-03,  3.4912e-04,\n",
            "         1.0712e-04,  3.4674e-04, -3.7148e-04,  1.1756e-03, -2.3007e-04,\n",
            "         1.2717e-03,  1.4034e-03,  4.1325e-04,  6.8177e-04,  8.2207e-04,\n",
            "         1.1871e-03,  1.8790e-03,  2.0153e-03,  1.1251e-03,  8.3025e-04,\n",
            "         7.3202e-04,  1.3018e-03,  1.9666e-03,  5.6232e-04,  7.6228e-04,\n",
            "         5.4104e-04,  2.3125e-03,  1.8043e-03,  1.1365e-03,  2.2959e-04,\n",
            "         1.1427e-03,  1.8853e-04,  1.6819e-03,  8.9440e-04,  1.5850e-03,\n",
            "         2.5299e-04,  1.8255e-03,  1.0713e-03,  2.1148e-03, -1.1509e-03,\n",
            "         1.5355e-03,  8.0171e-04, -5.2471e-04,  3.1735e-04,  5.6373e-04,\n",
            "         6.0552e-04,  5.3865e-04,  1.0003e-03, -4.2404e-04,  1.1599e-03,\n",
            "         7.9166e-04,  8.8957e-04,  1.2780e-03,  1.0031e-03,  1.0137e-03,\n",
            "         1.1182e-03,  1.2044e-03,  5.9122e-04,  8.8826e-04,  1.9114e-03,\n",
            "         4.5536e-04,  1.0182e-03,  1.0346e-03,  1.6404e-03,  2.4215e-03,\n",
            "        -9.4106e-05, -3.7447e-04,  6.2572e-04,  8.4032e-04, -2.8429e-04,\n",
            "         1.8202e-04,  6.3963e-04,  1.9761e-03,  2.5098e-03,  1.6962e-04,\n",
            "         1.3168e-03,  1.5513e-03,  7.7238e-04,  7.1354e-04,  5.4648e-04,\n",
            "         2.0863e-03,  1.2388e-03,  3.1991e-04,  9.0973e-04,  1.0111e-03,\n",
            "         9.9758e-04,  1.3277e-03,  5.8951e-04,  1.5066e-03,  1.3690e-03,\n",
            "         1.7600e-03,  2.5057e-04,  1.5797e-03,  1.8980e-03,  1.2382e-03,\n",
            "         1.5831e-03,  6.4914e-04,  1.9432e-04,  1.1295e-03,  1.1401e-03,\n",
            "         2.4910e-03,  2.5434e-03,  7.1437e-04,  7.6455e-04,  7.8972e-04,\n",
            "        -1.1919e-04,  1.2858e-03,  5.9521e-04,  2.5462e-03,  6.0360e-04,\n",
            "         9.2887e-04,  9.1267e-04,  6.3433e-04])}, 68: {'momentum_buffer': tensor([ 6.9451e-04,  3.1115e-04, -1.9913e-04,  8.0766e-04,  6.3902e-04,\n",
            "        -4.3696e-04, -8.5368e-04,  6.1214e-04,  3.1503e-04, -8.8516e-04,\n",
            "         1.5574e-03, -5.7699e-04,  2.3405e-05,  1.8795e-04,  7.2082e-04,\n",
            "        -2.8000e-04, -2.6521e-04, -7.7486e-04, -3.2710e-04, -4.8823e-04,\n",
            "        -5.4161e-04,  5.6472e-04, -1.7272e-03, -2.1788e-04,  2.5030e-04,\n",
            "        -4.0762e-04, -4.2575e-04, -6.9565e-04, -1.7610e-05, -9.6466e-04,\n",
            "        -4.5409e-04, -8.6385e-05,  1.5762e-04, -1.0374e-03,  5.6257e-04,\n",
            "         5.7264e-04,  2.7735e-04, -5.5999e-05, -9.6837e-04, -5.1908e-04,\n",
            "        -5.0749e-05,  1.1493e-03,  2.2020e-04, -6.1539e-04, -4.0590e-04,\n",
            "        -6.4023e-04, -1.2810e-03,  7.6428e-04,  8.4821e-05,  2.0204e-04,\n",
            "        -3.0728e-04,  4.4895e-04,  7.4141e-04,  3.4814e-04, -1.6381e-03,\n",
            "         1.0807e-03, -2.4453e-04, -7.1984e-04, -6.2281e-04,  3.4312e-06,\n",
            "        -8.1538e-04,  1.5792e-04, -2.3689e-04, -3.3605e-04,  3.1728e-04,\n",
            "         2.0274e-04, -1.7106e-04,  1.1880e-03, -4.6618e-04, -1.8435e-04,\n",
            "        -4.8872e-04, -9.7658e-04, -4.7043e-04,  1.9885e-05,  7.5338e-04,\n",
            "        -1.5527e-04, -2.4403e-04, -2.6646e-04,  1.1477e-03,  3.7310e-04,\n",
            "        -1.0670e-03, -5.4022e-04, -5.0994e-04, -1.0147e-04, -5.6918e-04,\n",
            "         2.8575e-05,  1.7567e-04,  7.2393e-04,  1.0518e-03, -6.0911e-04,\n",
            "        -6.0476e-04, -3.5983e-04, -5.1048e-04, -1.7927e-04,  1.2123e-03,\n",
            "         8.0667e-04, -1.5993e-03, -1.1510e-03, -2.4931e-04,  4.0568e-04,\n",
            "        -9.7393e-04, -2.6300e-04, -9.7136e-04,  2.5468e-04,  6.1732e-04,\n",
            "         3.4842e-04, -4.6104e-04,  5.8400e-04,  7.7717e-04,  2.4771e-04,\n",
            "         5.6590e-04, -5.4516e-04, -6.7562e-04, -3.9461e-04,  1.6370e-04,\n",
            "         3.4667e-04,  6.6193e-04,  1.5579e-04,  2.8186e-04,  7.8550e-05,\n",
            "        -6.9506e-04, -5.6000e-04, -2.0768e-04,  4.3232e-04, -5.0930e-04,\n",
            "        -7.4680e-05, -2.0957e-04, -2.6586e-04])}, 69: {'momentum_buffer': tensor([[[[ 4.1748e-04]],\n",
            "\n",
            "         [[-7.1792e-04]],\n",
            "\n",
            "         [[-1.2357e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1749e-04]],\n",
            "\n",
            "         [[-5.5807e-04]],\n",
            "\n",
            "         [[-2.0638e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1568e-03]],\n",
            "\n",
            "         [[-4.3334e-04]],\n",
            "\n",
            "         [[-2.7046e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6787e-04]],\n",
            "\n",
            "         [[-4.8614e-04]],\n",
            "\n",
            "         [[-4.8744e-04]]],\n",
            "\n",
            "\n",
            "        [[[-4.4021e-04]],\n",
            "\n",
            "         [[ 7.3673e-04]],\n",
            "\n",
            "         [[ 2.8088e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6906e-04]],\n",
            "\n",
            "         [[ 7.2866e-04]],\n",
            "\n",
            "         [[ 4.5685e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.1801e-03]],\n",
            "\n",
            "         [[ 4.9503e-04]],\n",
            "\n",
            "         [[ 3.9577e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.4299e-05]],\n",
            "\n",
            "         [[ 2.4544e-04]],\n",
            "\n",
            "         [[-3.9423e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.0109e-04]],\n",
            "\n",
            "         [[ 5.4791e-04]],\n",
            "\n",
            "         [[ 7.3767e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4300e-04]],\n",
            "\n",
            "         [[ 3.0985e-04]],\n",
            "\n",
            "         [[ 9.0095e-05]]],\n",
            "\n",
            "\n",
            "        [[[-4.5866e-04]],\n",
            "\n",
            "         [[ 1.0284e-03]],\n",
            "\n",
            "         [[ 5.1891e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.2633e-04]],\n",
            "\n",
            "         [[ 5.1970e-04]],\n",
            "\n",
            "         [[-1.5730e-04]]]])}, 70: {'momentum_buffer': tensor([ 9.9380e-04,  7.5330e-04,  1.3965e-03,  1.1138e-03,  1.0826e-03,\n",
            "         1.3728e-03,  8.5656e-04,  1.1601e-03,  6.1757e-04,  8.5079e-04,\n",
            "         1.1191e-03,  6.2286e-04,  1.4358e-03,  7.4425e-04,  6.5266e-04,\n",
            "         4.9630e-04,  8.2814e-04,  1.1740e-03,  7.2013e-04,  3.8058e-04,\n",
            "         7.0195e-04,  3.0155e-04,  9.1598e-04,  9.2496e-04,  6.9296e-04,\n",
            "         6.4713e-04,  8.2859e-04,  8.9834e-04,  1.0574e-03,  1.0491e-03,\n",
            "         8.7407e-04,  1.3736e-03,  1.4995e-03,  8.8348e-04,  1.1380e-03,\n",
            "         6.8093e-04,  1.0248e-03,  1.4403e-03,  1.0774e-03,  1.3788e-03,\n",
            "         1.1544e-03,  9.6972e-04,  5.7776e-04,  1.1831e-03,  9.7864e-04,\n",
            "         1.1041e-03,  7.3220e-04,  1.0680e-03,  1.3550e-03,  1.6673e-03,\n",
            "         4.9604e-04,  6.1427e-04,  6.2231e-04,  1.1315e-03,  8.2647e-04,\n",
            "         1.5097e-03,  9.8559e-04,  8.3835e-04,  1.2127e-03,  1.3718e-03,\n",
            "         1.1218e-03,  1.3877e-03,  1.3347e-03,  1.3205e-03,  1.1472e-04,\n",
            "         1.1454e-03,  6.8356e-04,  1.2912e-03,  1.7563e-03,  1.1304e-03,\n",
            "         1.1024e-03,  1.5314e-03,  1.1558e-03,  1.1468e-03,  3.1136e-04,\n",
            "         5.8205e-04,  7.0944e-04,  1.4649e-03,  5.0954e-04,  8.5408e-04,\n",
            "         1.1219e-03,  9.6584e-04,  1.0435e-03,  1.0839e-03,  4.8915e-04,\n",
            "         1.2352e-03,  1.5240e-03,  8.2239e-04,  1.3608e-03,  8.2911e-04,\n",
            "         8.6163e-04,  8.0738e-04,  8.9661e-04,  1.5126e-03,  1.8200e-03,\n",
            "         1.2138e-03,  1.5860e-03,  1.3659e-03,  9.3332e-04,  1.3124e-03,\n",
            "         1.1514e-03,  7.9436e-04,  9.4154e-04,  3.9521e-04,  1.4899e-03,\n",
            "         7.8210e-04,  1.4881e-03,  9.6334e-04,  1.2915e-03,  1.1313e-03,\n",
            "         8.9920e-04,  1.1656e-03,  1.0800e-03,  1.3768e-03,  1.2475e-03,\n",
            "         4.3476e-05,  1.4271e-03,  1.2158e-03,  1.4476e-03,  1.3744e-03,\n",
            "         1.1687e-03,  6.6304e-04,  1.2450e-03,  1.1570e-03,  1.1854e-03,\n",
            "         9.8574e-04,  9.8335e-04,  7.9781e-04,  1.1090e-03,  1.1043e-03,\n",
            "        -1.3837e-04,  1.0987e-03,  1.5062e-03,  9.3658e-04,  7.5991e-04,\n",
            "         1.2274e-03,  1.5017e-03,  1.1255e-03,  1.0739e-03,  1.2316e-03,\n",
            "         1.0294e-03,  9.6904e-04,  1.7054e-03,  1.2003e-03,  6.9392e-04,\n",
            "         6.9985e-04,  1.3902e-03,  1.2372e-03,  8.6577e-04,  8.8445e-04,\n",
            "         8.8946e-04,  1.0965e-03,  3.7302e-04,  1.1777e-03,  1.5373e-03,\n",
            "         1.1344e-03,  8.1874e-04,  1.2301e-03,  7.7364e-04,  4.7472e-04,\n",
            "         8.0770e-04,  9.9603e-04,  7.1738e-04,  1.5074e-03,  1.1858e-03,\n",
            "         1.0652e-03,  4.2641e-04,  1.1393e-03,  4.3882e-04,  5.3750e-04,\n",
            "         5.5239e-04,  9.1344e-04,  9.9910e-04,  2.1165e-03,  9.5775e-04,\n",
            "         7.8523e-04,  8.9462e-04,  8.4721e-04,  1.5193e-03,  1.2425e-03,\n",
            "         1.0136e-03,  1.0110e-03,  1.7236e-03,  4.6931e-04,  8.1022e-04,\n",
            "         1.1271e-03,  1.7085e-03,  1.1900e-03,  9.1455e-04,  9.2642e-04,\n",
            "         3.9946e-04,  1.1767e-03,  1.4066e-03,  1.0449e-03,  9.6580e-04,\n",
            "         2.9373e-04,  1.0316e-03,  1.0974e-03,  1.3476e-03,  1.1482e-03,\n",
            "         1.3439e-03,  5.1666e-04,  8.1186e-04,  1.0677e-03,  8.0129e-04,\n",
            "         5.4284e-04,  1.0375e-03,  8.5727e-04,  1.1986e-03,  1.3534e-03,\n",
            "         9.2267e-04,  2.7323e-04,  9.1844e-04,  4.6015e-04,  5.7266e-04,\n",
            "         7.3479e-04,  1.1622e-03,  8.4533e-04,  8.7301e-04,  1.0193e-03,\n",
            "         8.2794e-04,  1.6261e-03,  1.7439e-03,  1.1264e-03,  8.8118e-04,\n",
            "         9.3902e-04,  9.0804e-04,  8.1076e-04,  1.1876e-03,  1.3894e-03,\n",
            "         1.3391e-03,  9.7465e-04,  1.1335e-03,  8.5782e-04,  1.3768e-03,\n",
            "         8.7108e-04,  1.1010e-03,  3.5380e-04,  1.8382e-03,  9.1710e-04,\n",
            "         1.5413e-04,  1.0301e-03,  1.3301e-03,  1.3108e-03,  9.8845e-04,\n",
            "         3.3937e-04,  1.8639e-03,  1.7743e-03,  6.1102e-04,  1.3440e-03,\n",
            "         3.7958e-04,  1.2939e-03,  7.7489e-04,  1.1384e-03,  6.7902e-04,\n",
            "         6.6244e-04,  1.7605e-03,  1.1559e-03,  8.9748e-04,  5.0835e-04,\n",
            "         1.2697e-03,  1.1959e-03,  8.6499e-04,  1.3700e-03,  1.1338e-03,\n",
            "         1.1727e-03,  1.3535e-03,  1.0970e-03,  1.0890e-03,  8.1784e-04,\n",
            "         9.9021e-04,  1.0025e-03,  1.1162e-03,  5.5518e-04,  1.1299e-03,\n",
            "         1.1418e-03,  1.3122e-03,  4.8495e-04,  5.0756e-04,  5.3129e-04,\n",
            "         7.0624e-04,  1.6472e-03,  8.3075e-04,  1.0353e-03,  8.8456e-04,\n",
            "         1.8709e-03,  1.8195e-03,  5.1647e-04,  1.0011e-03,  1.1286e-03,\n",
            "         1.0174e-03,  1.1809e-03,  8.9870e-04,  1.0219e-03,  7.2293e-04,\n",
            "         1.1026e-03,  4.4833e-04,  1.1533e-03,  1.0760e-03,  6.2589e-04,\n",
            "         6.7487e-04,  1.3860e-03,  9.8327e-04,  1.2278e-03,  1.3409e-03,\n",
            "         6.5514e-04,  5.6788e-04,  4.4126e-04,  7.6098e-04,  1.0421e-03,\n",
            "         9.1246e-04,  1.3250e-03,  1.2004e-03,  4.8736e-04,  8.1428e-04,\n",
            "         1.1963e-03,  9.4125e-04,  1.5136e-03,  8.3843e-04,  1.0612e-03,\n",
            "         8.2740e-04,  1.2207e-03,  1.1989e-03,  8.3541e-04,  1.1306e-03,\n",
            "         1.2693e-03,  9.9517e-04,  7.3758e-04,  8.0993e-04,  1.0188e-03,\n",
            "         1.0998e-03,  1.1307e-03,  7.2496e-04,  8.5488e-04,  1.3354e-03,\n",
            "         6.9939e-04,  9.2193e-04,  8.3539e-04,  1.3316e-03,  1.1086e-03,\n",
            "         1.1377e-03,  9.4145e-04,  5.6158e-04,  1.3193e-03,  1.2475e-03,\n",
            "         8.0731e-04,  6.2963e-04,  1.6634e-03,  1.1498e-03,  1.2325e-03,\n",
            "         5.4268e-04,  1.2512e-03,  1.1345e-03,  1.1384e-03,  1.1088e-03,\n",
            "         1.0085e-03,  1.1540e-03,  8.7363e-04,  1.1251e-03,  1.0259e-03,\n",
            "         1.2596e-03,  1.3343e-03,  1.1505e-03,  7.5592e-04,  5.4745e-04,\n",
            "         9.6161e-04,  4.4703e-04,  1.0033e-03,  4.8928e-04,  9.0440e-04,\n",
            "         1.4861e-03,  8.7937e-04,  8.3673e-04,  1.1355e-03,  1.1095e-04,\n",
            "         8.2370e-04,  1.0000e-03,  1.6796e-03,  7.7902e-04,  1.0899e-03,\n",
            "         1.1100e-03,  1.2136e-03,  1.5221e-03,  8.9542e-04,  1.1985e-03,\n",
            "         9.9711e-04,  9.6449e-04,  9.6226e-04,  1.0235e-03,  9.6400e-04,\n",
            "         1.0938e-03,  8.8419e-04,  1.6065e-03,  1.2345e-03,  8.8107e-04,\n",
            "         1.4328e-03,  1.2384e-03,  6.4867e-04,  6.1298e-04,  1.0530e-03,\n",
            "         1.1269e-03,  1.0379e-03,  1.2210e-03,  9.9736e-04,  1.2774e-03,\n",
            "         1.1376e-03,  1.4532e-03,  1.2134e-03,  8.9107e-04,  1.2967e-03,\n",
            "         8.2353e-04,  1.2184e-03,  1.1783e-03,  8.2705e-04,  1.2077e-03,\n",
            "         1.2946e-03,  1.2255e-03,  1.4027e-03,  7.7178e-04,  1.5409e-03,\n",
            "         9.3084e-04,  8.6829e-04,  1.1457e-03,  1.1503e-03,  1.2026e-03,\n",
            "         1.1929e-03,  1.1726e-03,  1.0763e-03,  1.2182e-03,  1.1864e-03,\n",
            "         1.6876e-03,  9.2144e-04,  1.2428e-03,  1.0734e-03,  1.1998e-03,\n",
            "         9.4354e-04,  1.4029e-03,  1.2235e-03,  1.5300e-03,  3.0683e-04,\n",
            "         6.3377e-05,  1.1511e-03,  9.6036e-04,  1.2783e-03,  9.4430e-04,\n",
            "         5.8210e-04,  7.4226e-04,  5.0031e-04,  1.3651e-03,  9.3202e-04,\n",
            "         4.6552e-04,  8.5043e-04,  8.6307e-04,  1.0282e-03,  1.1001e-03,\n",
            "         6.5485e-04,  1.5005e-03,  5.6027e-04,  1.0697e-03,  9.0195e-04,\n",
            "         1.2093e-03,  7.9189e-04,  6.8810e-04,  1.1671e-03,  7.9075e-04,\n",
            "         1.0802e-03,  9.6452e-04,  1.3176e-03,  1.2001e-03,  7.9207e-04,\n",
            "         6.3647e-04,  1.0982e-03,  1.0310e-03,  7.9987e-04,  5.6471e-04,\n",
            "         1.2414e-03,  6.5954e-04,  1.3453e-03,  1.1381e-03,  9.3804e-04,\n",
            "         1.2183e-03,  1.2364e-03,  7.6981e-04,  9.6257e-04,  8.4976e-04,\n",
            "         1.0297e-03,  9.2651e-04,  1.8448e-03,  6.5982e-04,  9.5128e-04,\n",
            "         1.3439e-03,  1.0169e-03,  8.9899e-04,  1.0025e-03,  1.0637e-03,\n",
            "         8.8383e-04,  1.2634e-03,  1.4121e-03,  1.0178e-03,  6.9243e-04,\n",
            "         1.0906e-03,  1.5566e-03,  1.5613e-03,  1.0508e-03,  8.5386e-04,\n",
            "         1.4818e-03,  8.2791e-04,  9.6387e-04,  2.7158e-04,  1.1156e-03,\n",
            "         1.3031e-03,  9.5690e-04])}, 71: {'momentum_buffer': tensor([-8.8942e-05,  7.1730e-05, -1.1165e-04, -2.6961e-04, -1.4482e-04,\n",
            "        -1.1814e-04, -1.0687e-04, -4.6051e-05, -6.2696e-05, -4.3461e-04,\n",
            "        -5.8252e-05, -1.5699e-04, -3.8093e-04, -3.7310e-04,  5.0931e-05,\n",
            "         6.0899e-05, -2.4444e-04, -1.6529e-04, -2.7320e-04, -1.8410e-05,\n",
            "         2.2231e-04, -1.9180e-04, -2.2055e-04, -1.3177e-04, -7.7249e-05,\n",
            "         1.5490e-04,  1.6637e-04, -7.6195e-05, -2.4676e-04, -3.0502e-04,\n",
            "         1.1572e-04, -1.7360e-04,  7.8627e-06,  3.9360e-05,  1.6383e-04,\n",
            "        -3.0688e-04, -2.8914e-04,  1.1290e-04,  2.2723e-04, -7.8069e-05,\n",
            "        -2.6279e-04, -1.0918e-04,  1.4559e-04,  1.7486e-04,  1.0214e-04,\n",
            "        -5.7922e-05,  5.0680e-05, -3.2868e-04,  6.4127e-04,  1.9032e-04,\n",
            "        -4.2437e-04, -2.7241e-04,  1.6666e-05, -2.6602e-05,  6.9216e-05,\n",
            "        -3.7687e-05, -1.8139e-04, -7.7296e-05, -1.1846e-04,  2.8622e-05,\n",
            "         1.2139e-04,  5.4352e-05,  1.9587e-04,  7.6204e-05, -1.0133e-04,\n",
            "         7.6676e-05,  2.8262e-04,  4.4414e-05,  3.8338e-04, -3.2793e-04,\n",
            "        -1.3837e-04, -2.2408e-05, -7.0274e-05, -3.3536e-04,  4.7709e-05,\n",
            "         1.3238e-04,  5.1266e-05, -2.4766e-05, -1.1105e-04,  3.3132e-04,\n",
            "        -9.9880e-05,  2.3016e-04,  7.8885e-05,  1.9036e-05, -8.5311e-05,\n",
            "         1.4641e-04, -1.2029e-04,  2.3480e-04, -8.4924e-05, -1.7082e-04,\n",
            "        -9.1218e-05, -3.0292e-05,  3.8041e-05,  1.8682e-04, -4.6373e-04,\n",
            "        -6.9242e-06,  1.1835e-04,  5.3763e-05,  3.4330e-04, -1.1107e-04,\n",
            "         4.0218e-04, -1.3327e-04, -8.1748e-05, -1.1891e-04, -3.1667e-04,\n",
            "        -6.8250e-05,  6.8491e-05,  1.7798e-04,  2.0988e-05, -2.8756e-04,\n",
            "        -3.5975e-05,  1.1351e-04,  3.2805e-05,  1.3218e-04,  4.7324e-04,\n",
            "         1.4679e-04,  3.0630e-05,  1.8269e-05,  6.4077e-05, -6.3122e-05,\n",
            "         4.6823e-05,  2.2153e-04, -2.2757e-04,  9.4292e-05, -1.8025e-04,\n",
            "        -5.2217e-05,  3.4867e-05,  3.7055e-04,  1.1264e-04,  4.6809e-05,\n",
            "        -1.9025e-04, -1.8951e-04,  2.2529e-04, -1.0464e-04,  2.0194e-04,\n",
            "         1.6818e-04,  1.1163e-04, -1.0439e-04, -2.8616e-04, -1.8855e-04,\n",
            "         2.1353e-04, -5.9123e-05, -1.9871e-04, -4.6299e-04,  3.9983e-05,\n",
            "         7.3698e-05, -7.9917e-05, -1.1823e-04,  2.7363e-04,  2.3327e-04,\n",
            "         5.8623e-05, -2.0213e-04,  1.7100e-05,  2.0151e-04,  1.3688e-04,\n",
            "         2.9613e-04,  4.6581e-04,  2.9297e-04,  1.7353e-04,  7.8403e-05,\n",
            "        -2.7019e-04,  1.2179e-04,  1.6111e-06, -3.4811e-06,  1.9463e-04,\n",
            "        -1.4504e-04, -1.2763e-04, -1.6565e-04,  3.4135e-05, -2.7262e-04,\n",
            "         2.1083e-04, -1.7907e-04, -1.2446e-04,  4.1445e-05,  3.5589e-04,\n",
            "         4.6690e-05,  3.7540e-05,  8.7770e-05,  1.1681e-04, -2.1297e-04,\n",
            "         3.0851e-05, -1.1710e-04,  2.8798e-04,  2.2084e-04,  2.9754e-04,\n",
            "         3.1522e-04,  3.3014e-04, -2.4235e-05, -7.4226e-05,  5.9748e-05,\n",
            "         6.3425e-05, -6.1395e-05,  2.5854e-05, -2.7195e-06, -3.6378e-04,\n",
            "         7.6988e-06, -1.9879e-04, -1.2766e-04, -6.8728e-05, -1.3385e-04,\n",
            "         1.9347e-04,  9.4990e-05,  1.0054e-04,  1.0894e-04,  1.9318e-04,\n",
            "        -4.6369e-05, -4.7138e-05, -3.1560e-04,  5.4794e-05,  3.5190e-05,\n",
            "         2.0932e-05, -2.4564e-05,  1.5855e-04,  6.7289e-05,  8.9031e-05,\n",
            "        -2.0278e-04, -1.9268e-04,  2.6365e-05,  1.1726e-04, -9.2019e-05,\n",
            "         2.4824e-04,  2.6193e-04,  2.1180e-05,  6.6756e-05,  3.1848e-04,\n",
            "         2.9243e-04, -1.3356e-04, -3.3748e-04,  1.2839e-05, -1.3778e-04,\n",
            "        -1.2572e-05, -2.8806e-04,  5.3753e-05,  5.5015e-04,  3.8399e-04,\n",
            "         2.1649e-04, -2.3725e-04, -4.5097e-05, -1.9311e-04,  1.0815e-04,\n",
            "         1.3686e-05,  2.2998e-04, -1.4984e-04, -1.7233e-04,  3.4707e-04,\n",
            "        -2.3864e-04,  2.8222e-04,  1.9967e-04, -6.1242e-05,  3.0338e-04,\n",
            "        -7.0151e-05, -2.1665e-05,  4.7318e-05, -1.4710e-05,  1.8867e-04,\n",
            "        -5.3659e-04, -4.7627e-05,  8.7769e-05,  2.9949e-04, -4.3287e-05,\n",
            "         5.1117e-05,  9.9339e-05,  6.2910e-05,  1.8533e-04,  1.8695e-04,\n",
            "         4.5832e-05, -2.0110e-04, -4.7754e-04,  2.5106e-04,  4.3001e-05,\n",
            "         4.5396e-06, -9.4690e-05,  2.3245e-04, -2.9415e-04,  2.3078e-04,\n",
            "         1.6644e-04,  1.9964e-04,  4.2029e-05, -5.4291e-05, -7.8346e-05,\n",
            "         2.3502e-05,  2.1635e-04, -1.3224e-04, -3.9276e-05, -7.7806e-05,\n",
            "        -9.4759e-05, -1.0211e-04,  9.9797e-05,  1.2899e-04,  2.8845e-04,\n",
            "         7.2714e-05,  1.7903e-04, -8.3823e-05,  1.1392e-05, -1.7370e-04,\n",
            "        -3.6468e-05, -2.9113e-04,  2.1366e-04,  3.1166e-05, -6.2928e-05,\n",
            "        -1.0484e-04, -2.6436e-04, -1.9653e-04,  3.1966e-04, -3.3639e-05,\n",
            "         7.5802e-05,  1.5811e-04,  1.0461e-04, -2.2993e-04,  1.7271e-04,\n",
            "         1.7377e-04, -4.1377e-05, -9.1460e-05, -3.8897e-04,  2.3453e-05,\n",
            "         4.3958e-04, -3.8711e-05,  2.1395e-04,  2.1844e-04,  2.3830e-05,\n",
            "        -2.0592e-05, -2.6471e-04, -1.5102e-04, -4.3502e-06, -3.6590e-04,\n",
            "         2.5178e-04,  1.8581e-04,  8.5085e-05, -6.8270e-05, -2.2553e-04,\n",
            "         4.6446e-05, -2.9502e-05,  1.0603e-04,  2.8522e-04, -7.1673e-05,\n",
            "         1.9002e-04, -5.6014e-05, -1.0677e-04,  4.0388e-04, -1.5150e-04,\n",
            "        -1.6694e-04,  1.9800e-04,  1.4912e-04, -4.4855e-04, -7.0435e-05,\n",
            "        -2.2644e-04,  1.0041e-04, -1.3255e-05,  7.9965e-05, -2.6718e-05,\n",
            "         1.6690e-04,  1.0386e-04, -3.0535e-04,  1.7682e-04, -2.9943e-04,\n",
            "         2.0100e-04,  1.8970e-04,  1.8808e-04,  1.4365e-05, -5.4007e-05,\n",
            "        -1.1024e-04,  1.2717e-04, -3.4654e-05,  1.8356e-04, -6.5835e-05,\n",
            "        -2.3234e-05,  6.2938e-05,  9.9054e-05,  6.1123e-05,  3.8770e-04,\n",
            "        -2.5524e-04,  4.3036e-04,  2.5114e-06, -1.2453e-04,  1.2357e-05,\n",
            "        -1.1288e-04, -2.1225e-04,  4.2222e-04, -1.4463e-04, -2.4140e-04,\n",
            "         1.3314e-04,  3.5404e-04,  6.9973e-05,  2.2062e-04, -1.2358e-04,\n",
            "         2.2187e-05, -1.8764e-04,  2.0403e-04, -2.3845e-04,  2.0065e-04,\n",
            "        -1.4018e-04,  1.7963e-04,  3.4882e-04, -2.9931e-04, -2.1107e-04,\n",
            "        -1.7010e-04, -5.9852e-05, -5.1552e-04,  5.6201e-05,  9.6343e-05,\n",
            "        -5.7860e-05, -5.5665e-05, -1.5416e-04, -1.5496e-04, -2.2155e-04,\n",
            "         1.2754e-04,  2.2483e-04,  9.5071e-06, -8.6700e-05,  9.8160e-06,\n",
            "         4.8864e-05,  2.7771e-04, -1.9082e-04,  1.0847e-04, -1.2539e-04,\n",
            "         8.3061e-05,  1.1029e-04, -3.9458e-05, -3.7769e-05, -3.8429e-04,\n",
            "         5.5325e-05, -4.5148e-05, -2.1915e-05, -1.5337e-04,  4.0103e-05,\n",
            "         2.6946e-04, -4.4208e-04, -3.7636e-04, -2.6514e-04, -1.7323e-04,\n",
            "        -1.5834e-04, -1.1513e-04, -1.0763e-04, -2.1836e-04, -2.2778e-04,\n",
            "         2.8044e-05,  2.3651e-04,  1.4951e-04,  2.2624e-04, -1.1619e-04,\n",
            "        -1.1534e-04,  9.1661e-05,  2.5684e-04, -1.4307e-04, -7.4081e-05,\n",
            "        -2.3476e-04,  8.4832e-05, -2.6219e-04, -3.3632e-05, -2.7321e-04,\n",
            "         1.0935e-04, -2.1791e-04, -1.5980e-04,  5.9563e-05,  1.9683e-04,\n",
            "         3.1795e-04,  1.6969e-04,  2.0395e-04,  1.7270e-04,  2.6756e-05,\n",
            "        -3.4943e-05, -1.4456e-04, -4.0107e-04, -3.2605e-06,  1.4962e-04,\n",
            "         3.1915e-04, -1.9730e-04,  2.0263e-04,  1.6495e-04, -4.3224e-05,\n",
            "        -1.9798e-04,  2.3462e-04,  1.6690e-04,  3.0657e-04, -1.6257e-04,\n",
            "        -5.5913e-05, -1.0214e-04,  3.8094e-04, -2.7589e-04, -1.1825e-04,\n",
            "        -5.0018e-05, -1.3594e-05, -1.5773e-04, -1.6170e-04,  1.2426e-04,\n",
            "        -1.6220e-04, -1.8343e-04, -7.3017e-05,  2.8319e-04,  2.3870e-05,\n",
            "        -1.1561e-04, -1.7634e-05,  9.1820e-05, -7.1379e-04, -1.8749e-04,\n",
            "         4.1922e-04,  6.9018e-05,  2.0116e-04,  1.9609e-05, -1.5264e-04,\n",
            "        -1.0499e-04, -9.4280e-05, -2.1664e-04, -2.6656e-04, -1.3256e-04,\n",
            "         3.0293e-04,  8.2206e-05,  1.0287e-04,  2.0282e-04,  4.1200e-04,\n",
            "        -1.2684e-04,  6.6094e-05])}, 72: {'momentum_buffer': tensor([[[[-7.4796e-05]],\n",
            "\n",
            "         [[-1.6299e-04]],\n",
            "\n",
            "         [[ 5.9521e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.1477e-05]],\n",
            "\n",
            "         [[-7.4772e-06]],\n",
            "\n",
            "         [[-4.4402e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.6137e-05]],\n",
            "\n",
            "         [[-4.6882e-04]],\n",
            "\n",
            "         [[ 1.5377e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7762e-04]],\n",
            "\n",
            "         [[-3.0606e-04]],\n",
            "\n",
            "         [[-1.9974e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.4233e-04]],\n",
            "\n",
            "         [[-1.9449e-04]],\n",
            "\n",
            "         [[-4.0597e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.5540e-04]],\n",
            "\n",
            "         [[-2.1437e-04]],\n",
            "\n",
            "         [[-6.4706e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 3.3583e-04]],\n",
            "\n",
            "         [[-4.2461e-04]],\n",
            "\n",
            "         [[ 9.8223e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1922e-04]],\n",
            "\n",
            "         [[-4.7572e-05]],\n",
            "\n",
            "         [[ 3.1970e-05]]],\n",
            "\n",
            "\n",
            "        [[[-8.5867e-04]],\n",
            "\n",
            "         [[-1.0054e-04]],\n",
            "\n",
            "         [[-4.0810e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9158e-05]],\n",
            "\n",
            "         [[-9.0770e-05]],\n",
            "\n",
            "         [[-3.2079e-04]]],\n",
            "\n",
            "\n",
            "        [[[-7.4793e-05]],\n",
            "\n",
            "         [[ 4.3010e-04]],\n",
            "\n",
            "         [[ 3.4352e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.1251e-05]],\n",
            "\n",
            "         [[-1.5516e-04]],\n",
            "\n",
            "         [[ 9.9696e-05]]]])}, 73: {'momentum_buffer': tensor([ 9.0557e-04,  1.9073e-03,  1.0655e-03,  9.0259e-04, -7.0817e-04,\n",
            "         4.4753e-04,  2.8035e-04,  1.7905e-03,  4.5526e-04,  1.5946e-03,\n",
            "         1.1432e-03,  1.9360e-03,  7.5024e-04,  1.5834e-03,  2.6614e-04,\n",
            "         2.0709e-04,  3.3299e-04,  1.3340e-03,  2.2574e-03,  3.9553e-04,\n",
            "         1.3586e-03,  5.9612e-04,  2.0388e-03,  7.3637e-04,  1.5789e-03,\n",
            "        -5.3945e-04, -9.6983e-04,  6.4875e-04,  3.7516e-04,  1.1913e-03,\n",
            "         1.2203e-03,  1.3414e-03,  2.0623e-04,  1.8279e-03,  1.5807e-03,\n",
            "         9.1315e-04,  1.6689e-03,  2.3368e-03,  6.6549e-04,  5.5340e-04,\n",
            "         1.5044e-04,  2.7402e-03,  9.2062e-04,  1.7374e-03,  7.9167e-04,\n",
            "         1.4980e-03,  7.7850e-04,  1.3033e-03,  1.7172e-03,  9.8201e-04,\n",
            "         1.1006e-03,  1.5164e-03,  2.0666e-03,  1.4256e-03,  2.2600e-03,\n",
            "         3.9211e-04,  1.1037e-03,  1.0764e-03,  4.0581e-04,  1.8026e-03,\n",
            "         9.6004e-04,  1.7298e-03,  1.6429e-03,  1.2384e-03,  1.4441e-03,\n",
            "         1.8898e-03,  9.6420e-04,  5.5076e-04,  1.3570e-03,  1.1074e-03,\n",
            "        -3.8472e-04,  6.5693e-04,  8.2218e-04,  6.0196e-04,  7.7253e-04,\n",
            "         2.0620e-04,  1.0064e-04,  8.3091e-04,  5.1132e-04,  1.7221e-03,\n",
            "        -1.3045e-04,  1.2914e-03,  2.1542e-03,  1.4301e-03,  2.1219e-03,\n",
            "         2.0575e-03,  1.2043e-03,  9.3146e-04,  1.3299e-03,  2.0603e-03,\n",
            "         5.7816e-04, -6.3873e-04,  7.0562e-04,  1.4068e-04,  7.6159e-04,\n",
            "         6.9872e-04,  1.4786e-03,  1.3250e-03,  3.1018e-04,  1.7567e-03,\n",
            "         1.4643e-03,  1.2880e-03,  1.0782e-03,  1.2857e-03,  8.3371e-04,\n",
            "         6.5995e-04,  4.2674e-04,  2.3045e-03, -9.5455e-05,  3.9156e-04,\n",
            "         8.5241e-04,  1.7575e-04,  1.9194e-03,  1.2190e-03,  7.5719e-04,\n",
            "         2.2678e-03,  8.3376e-04,  9.7001e-04,  2.4382e-03,  1.0407e-03,\n",
            "         3.8915e-04,  1.3290e-03,  1.6730e-04,  7.3639e-04,  9.7826e-04,\n",
            "         1.4890e-03,  1.6022e-03,  1.8484e-03,  1.4021e-03,  2.0728e-04,\n",
            "         8.7441e-04,  7.7898e-04,  1.1805e-03,  1.3657e-04,  1.5359e-03,\n",
            "         3.1310e-04,  8.4202e-04,  5.9959e-04,  1.3055e-03,  8.5649e-04,\n",
            "         1.3187e-03,  3.4878e-04,  1.9012e-03,  2.1882e-03,  5.6186e-04,\n",
            "         1.5572e-03,  6.5666e-04,  4.3561e-04,  1.4511e-03,  1.5051e-03,\n",
            "         7.6952e-04,  5.8567e-04,  8.6057e-04,  5.9223e-04,  4.8250e-04,\n",
            "         2.8567e-04,  6.5558e-04,  3.6386e-04,  8.5625e-04, -1.0232e-04,\n",
            "         9.4621e-04, -1.6161e-04,  1.2207e-03,  1.8804e-03,  4.7472e-05,\n",
            "         1.5042e-03,  2.4832e-05,  1.2424e-03,  1.3392e-03,  4.4606e-04,\n",
            "         2.1442e-03,  1.8880e-03,  1.3775e-03, -2.8418e-04,  1.5004e-04,\n",
            "         5.0898e-04, -1.0739e-04,  8.3596e-04,  9.6811e-04,  1.4668e-03,\n",
            "         4.6102e-04,  1.6146e-03,  1.2043e-03,  6.2783e-04,  3.2003e-04,\n",
            "         1.4381e-03,  1.4050e-03,  1.8339e-03,  1.2610e-03,  1.1487e-03,\n",
            "         1.7308e-03,  1.1881e-03,  1.2210e-03,  1.7576e-03,  8.5103e-04,\n",
            "         1.1796e-03,  1.2452e-03,  2.1304e-04,  1.6849e-03,  1.2419e-03,\n",
            "         1.1392e-03,  7.9157e-04,  1.4163e-03,  3.2185e-04,  6.8679e-04,\n",
            "         7.0581e-04,  5.9753e-04,  1.5385e-03,  1.1357e-03,  8.2355e-04,\n",
            "         4.0113e-04, -4.6974e-04,  1.0800e-03,  9.3490e-04,  1.3888e-03,\n",
            "         1.6131e-03,  1.1708e-03, -3.6398e-04,  1.0998e-03, -2.9035e-04,\n",
            "        -6.2209e-04,  9.0041e-04,  7.9151e-04,  2.0254e-03,  7.4387e-04,\n",
            "         4.6459e-04,  6.5554e-04,  1.7124e-03,  9.2705e-04,  9.8779e-04,\n",
            "         1.6797e-03, -8.0944e-04,  1.1192e-03,  2.3737e-04,  2.1300e-03,\n",
            "         2.4323e-03,  1.0645e-03,  9.0441e-04,  7.0669e-04,  1.1736e-03,\n",
            "         8.1270e-04,  1.3977e-03,  7.5322e-04,  1.1851e-03,  1.0256e-03,\n",
            "         1.3789e-03,  9.7953e-04,  6.3456e-04,  1.0736e-03,  1.2399e-03,\n",
            "         1.9700e-03,  1.2272e-03,  3.5057e-04, -3.0978e-04,  6.3114e-04,\n",
            "         1.5439e-03])}, 74: {'momentum_buffer': tensor([-1.6002e-04, -3.7401e-04,  7.2045e-04,  3.2035e-04, -6.2085e-04,\n",
            "         2.8685e-04,  3.4932e-04,  5.9310e-04,  5.1533e-05,  2.8124e-04,\n",
            "         6.0622e-04,  3.8175e-04, -3.7152e-04,  9.0320e-04, -7.3389e-04,\n",
            "        -6.9404e-04,  2.1217e-05,  1.4422e-04, -1.2570e-04, -5.9262e-04,\n",
            "         1.7054e-04, -2.6271e-04,  1.1412e-03, -6.5124e-04, -2.3760e-04,\n",
            "        -1.3385e-03, -9.4713e-04,  4.2525e-04, -4.4852e-04,  1.1742e-05,\n",
            "        -4.5670e-04, -1.4548e-04, -6.1903e-04,  5.8611e-04,  6.0930e-04,\n",
            "         2.5333e-04,  6.2030e-04,  6.2456e-04, -3.4632e-04, -4.6942e-04,\n",
            "        -5.7179e-04,  1.3219e-03,  4.9720e-06,  7.4373e-04, -8.2139e-04,\n",
            "         2.3837e-04,  1.9700e-04,  2.7661e-04,  4.1402e-05,  2.8584e-04,\n",
            "         2.0557e-04, -3.9386e-04, -5.1514e-04,  9.5749e-04,  6.9275e-04,\n",
            "        -5.6691e-04, -1.8124e-04, -5.0663e-05,  3.7008e-04,  2.5556e-04,\n",
            "         9.9624e-04, -1.7751e-04,  5.6601e-04,  8.5994e-05, -5.3524e-05,\n",
            "         7.8561e-04,  1.5688e-06,  4.2369e-04,  4.9827e-04, -9.5678e-05,\n",
            "        -5.7308e-04,  2.2419e-04, -1.9229e-04, -5.0132e-04, -6.1522e-04,\n",
            "        -5.8854e-04, -2.4342e-04,  1.8378e-04, -1.1970e-04, -4.6927e-04,\n",
            "        -3.8769e-04, -8.6173e-05,  2.8593e-04,  1.4386e-04,  3.8830e-04,\n",
            "         9.3433e-04, -6.2487e-04, -5.9966e-04,  2.4719e-04,  9.1586e-04,\n",
            "        -3.3470e-04, -7.5891e-04, -1.8855e-04, -1.7980e-04,  6.8749e-05,\n",
            "         6.6634e-04,  1.8544e-04,  4.9864e-04, -4.0140e-04,  9.7931e-05,\n",
            "         3.0654e-04,  1.8420e-04,  4.5605e-04, -1.6668e-04, -7.4911e-04,\n",
            "         3.4695e-04, -2.6289e-04,  1.1196e-03, -4.5621e-04, -7.3497e-05,\n",
            "        -2.2951e-04, -4.2564e-04, -1.5343e-04,  2.0451e-04,  2.9265e-05,\n",
            "         1.0923e-03,  1.8124e-05,  1.6287e-04,  4.5536e-04, -5.7207e-04,\n",
            "        -8.4263e-04, -2.9289e-05, -9.0201e-04,  4.5363e-04,  1.0859e-04,\n",
            "        -9.1427e-05,  1.6301e-04,  1.7045e-04,  7.6629e-05, -2.3264e-04,\n",
            "         1.0708e-04, -2.7271e-04,  6.7842e-05, -7.6663e-04,  3.6069e-05,\n",
            "        -6.3271e-05,  5.7669e-04,  2.9209e-05,  9.1952e-05, -2.8309e-04,\n",
            "         5.4304e-04,  2.0088e-04,  3.9487e-04,  9.1128e-04,  2.2149e-04,\n",
            "         4.7558e-04, -1.0801e-03,  6.6697e-04, -2.7897e-04,  1.3788e-04,\n",
            "         1.5547e-04, -2.0227e-04, -7.9517e-04, -5.2775e-05, -2.7935e-05,\n",
            "        -2.3219e-04, -1.2108e-04,  2.8276e-05,  1.7911e-04, -1.4765e-03,\n",
            "        -8.8994e-04, -1.0097e-03,  4.9887e-04,  4.5731e-04, -1.0483e-03,\n",
            "        -3.7263e-04, -7.9972e-04,  4.9940e-04,  1.1807e-04, -5.0285e-04,\n",
            "         1.2126e-03,  5.5720e-05,  6.0176e-04, -7.8040e-04, -4.7816e-04,\n",
            "        -1.8380e-04, -1.0076e-03,  3.2916e-04,  5.1031e-05,  2.0254e-04,\n",
            "        -6.6909e-04,  3.7198e-04,  4.4624e-04, -8.3694e-04, -3.0107e-04,\n",
            "        -3.7233e-04, -1.5060e-04,  3.6792e-04,  3.1536e-04, -1.0782e-03,\n",
            "         8.6341e-04,  3.4124e-04,  3.5733e-04,  9.4790e-04,  4.8115e-04,\n",
            "         6.8432e-04, -2.5616e-04, -2.9771e-04,  6.1427e-04,  5.4903e-04,\n",
            "         2.6164e-04, -5.4618e-04,  8.1091e-04, -5.0025e-04,  3.5610e-04,\n",
            "        -3.3823e-04, -8.3312e-04, -1.8706e-04,  3.7598e-04,  2.2704e-04,\n",
            "        -7.9773e-04, -1.5007e-03,  1.5629e-04, -1.7005e-04,  2.1763e-04,\n",
            "         4.7495e-04, -2.1833e-04, -4.2264e-04, -3.8023e-04, -1.9488e-03,\n",
            "        -3.8858e-04,  4.2899e-04, -1.1901e-03,  1.3956e-03,  4.8491e-04,\n",
            "         2.3525e-04, -1.5503e-05,  1.9912e-04, -7.2524e-04,  2.7505e-04,\n",
            "         9.0240e-04, -1.1989e-03,  3.3351e-04, -5.4363e-05,  3.9543e-04,\n",
            "         6.0949e-04, -4.5585e-04,  3.3089e-04, -1.5109e-04,  3.4306e-04,\n",
            "         5.0115e-04,  1.2734e-03,  2.2773e-04,  7.2117e-04,  2.3414e-04,\n",
            "         6.3977e-04, -1.5797e-03, -1.0431e-03, -2.5168e-05,  4.3545e-04,\n",
            "         8.8494e-04,  2.7419e-04, -7.1040e-04, -9.7709e-04, -6.9015e-04,\n",
            "         1.7470e-04])}, 75: {'momentum_buffer': tensor([[[[-3.8722e-04, -1.8403e-04, -1.3650e-05],\n",
            "          [-3.9940e-04, -3.9424e-04, -6.0347e-05],\n",
            "          [-1.0927e-04, -1.5450e-05,  5.4846e-05]],\n",
            "\n",
            "         [[-3.7518e-04, -5.0981e-04,  1.0007e-04],\n",
            "          [ 1.9052e-04,  1.9087e-04,  2.6346e-04],\n",
            "          [ 6.0145e-04,  2.5522e-04,  2.7244e-04]],\n",
            "\n",
            "         [[ 7.2550e-04,  5.0039e-04,  1.0633e-04],\n",
            "          [ 5.8901e-04,  8.3366e-04,  7.9226e-04],\n",
            "          [ 6.3621e-04,  6.0847e-04,  7.1034e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6568e-04,  1.3962e-04,  4.1964e-04],\n",
            "          [ 3.3174e-05,  1.0528e-04,  4.7362e-04],\n",
            "          [ 4.2018e-05,  1.3989e-04,  6.2210e-04]],\n",
            "\n",
            "         [[ 4.4496e-04,  5.8845e-04,  4.5618e-04],\n",
            "          [ 3.1868e-04,  4.8743e-04,  2.8264e-04],\n",
            "          [ 5.6235e-04,  4.5382e-04,  4.0959e-04]],\n",
            "\n",
            "         [[ 1.6168e-04,  2.9568e-04,  2.6272e-04],\n",
            "          [ 4.3148e-04,  2.5592e-04,  2.7113e-04],\n",
            "          [ 6.2720e-04,  6.7077e-04,  1.8660e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1603e-04, -1.0103e-04,  2.5685e-05],\n",
            "          [-1.1226e-04,  2.2284e-04, -3.1297e-04],\n",
            "          [-2.8718e-05, -7.5442e-05, -6.7427e-05]],\n",
            "\n",
            "         [[-5.3791e-04, -4.0357e-04, -5.3747e-04],\n",
            "          [-5.7978e-04, -6.5565e-04, -8.2125e-04],\n",
            "          [-3.3566e-04, -9.4575e-04, -9.4938e-04]],\n",
            "\n",
            "         [[-1.3160e-04,  1.7089e-04, -7.7550e-05],\n",
            "          [ 3.7355e-05,  2.4277e-04,  2.6253e-05],\n",
            "          [ 2.3822e-05, -5.8932e-05,  2.3455e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.6953e-05, -5.4421e-04, -5.7700e-04],\n",
            "          [-7.3963e-05, -3.7563e-04, -4.6274e-04],\n",
            "          [-2.9488e-04, -6.5975e-04, -1.2583e-04]],\n",
            "\n",
            "         [[-6.0382e-04, -2.8653e-04, -2.4735e-04],\n",
            "          [-4.2970e-04, -7.5583e-04, -2.3855e-04],\n",
            "          [-3.9352e-04, -7.0594e-04, -3.1855e-04]],\n",
            "\n",
            "         [[ 4.3236e-04,  2.7212e-04,  3.4842e-04],\n",
            "          [ 5.0651e-04,  4.0018e-04,  5.9999e-04],\n",
            "          [ 7.0247e-04,  6.0612e-04,  5.4682e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2789e-05,  2.2525e-04,  1.0937e-04],\n",
            "          [ 5.0012e-05,  8.6913e-05,  2.9789e-04],\n",
            "          [-1.5360e-04, -2.6195e-04,  2.0756e-04]],\n",
            "\n",
            "         [[-3.2225e-04,  1.6469e-05, -2.6625e-04],\n",
            "          [ 1.4294e-04, -1.4492e-04,  1.6409e-04],\n",
            "          [ 3.4935e-04,  3.7235e-04,  1.6856e-04]],\n",
            "\n",
            "         [[-8.8303e-05, -1.2594e-04,  3.1997e-04],\n",
            "          [-6.8880e-05,  1.6437e-05,  5.7857e-05],\n",
            "          [-1.4563e-04, -7.2986e-05,  3.8784e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8470e-04, -3.7579e-04, -8.8433e-05],\n",
            "          [-2.0517e-04, -2.5734e-04, -8.0563e-05],\n",
            "          [-6.1376e-05, -1.7837e-05, -6.3187e-05]],\n",
            "\n",
            "         [[-2.2370e-04, -2.3128e-04, -4.9409e-04],\n",
            "          [-4.4477e-05, -2.8169e-04, -1.4471e-04],\n",
            "          [ 5.4333e-05, -2.0588e-05, -3.0866e-04]],\n",
            "\n",
            "         [[-2.0616e-04, -3.1386e-04, -5.7518e-04],\n",
            "          [-6.1768e-05, -1.1973e-04, -1.6351e-04],\n",
            "          [-1.7477e-04, -4.6271e-04, -2.1505e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.7270e-04, -3.0051e-04, -2.5729e-04],\n",
            "          [-3.8255e-05,  1.3193e-04,  1.2262e-05],\n",
            "          [ 9.3844e-05,  1.6213e-04, -2.3977e-04]],\n",
            "\n",
            "         [[-3.4007e-04, -1.6708e-04, -3.0168e-04],\n",
            "          [-2.0282e-04, -1.9473e-04, -2.2633e-04],\n",
            "          [-1.7306e-04,  4.4366e-05, -1.9635e-04]],\n",
            "\n",
            "         [[ 5.5110e-05, -1.1278e-04, -4.1959e-04],\n",
            "          [-6.5483e-06, -2.8248e-06, -2.3407e-04],\n",
            "          [ 5.5082e-05,  2.8590e-04,  2.1129e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9593e-05, -1.2229e-04,  2.2339e-04],\n",
            "          [ 1.4600e-04,  8.2397e-05,  2.0365e-04],\n",
            "          [-3.2216e-06,  1.3063e-04,  2.1642e-04]],\n",
            "\n",
            "         [[-9.8468e-06,  1.6475e-04,  1.2943e-04],\n",
            "          [ 2.5128e-04,  4.6419e-05,  9.7415e-05],\n",
            "          [ 1.3902e-05,  1.7678e-04,  5.9625e-07]],\n",
            "\n",
            "         [[-3.0846e-04, -1.4280e-04, -3.0033e-04],\n",
            "          [-3.1191e-04, -7.7826e-06, -2.4450e-04],\n",
            "          [-2.3395e-04, -1.2391e-04, -1.1771e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.0428e-05, -2.3140e-04,  3.4855e-04],\n",
            "          [ 5.1094e-04,  2.4490e-05,  1.3818e-04],\n",
            "          [ 6.2096e-05,  8.5728e-05, -5.3500e-04]],\n",
            "\n",
            "         [[ 1.4867e-04, -7.3871e-05, -5.6104e-04],\n",
            "          [ 4.0746e-04, -9.0829e-05, -5.3359e-04],\n",
            "          [ 2.6942e-04,  1.1367e-04, -4.6184e-04]],\n",
            "\n",
            "         [[ 5.8526e-04, -1.8641e-04,  2.8711e-04],\n",
            "          [ 3.8274e-04, -7.4799e-05,  2.4695e-04],\n",
            "          [ 2.7022e-04,  3.1145e-04,  2.7590e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0477e-05, -3.6159e-05,  4.0325e-04],\n",
            "          [ 1.2362e-05,  3.3866e-04,  3.4567e-04],\n",
            "          [ 3.4573e-04,  3.2698e-05,  6.8479e-05]],\n",
            "\n",
            "         [[ 3.9646e-04, -8.1967e-05,  5.6188e-05],\n",
            "          [ 1.3644e-04, -5.3693e-05, -2.7669e-05],\n",
            "          [-1.6424e-04, -3.0038e-04,  3.4969e-05]],\n",
            "\n",
            "         [[-1.2692e-04, -5.3074e-04, -3.8732e-04],\n",
            "          [-1.8421e-04, -4.3535e-04, -9.8583e-05],\n",
            "          [ 3.2227e-05, -3.6132e-04,  9.0677e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.1399e-04, -1.3936e-04, -1.5833e-04],\n",
            "          [ 4.2432e-05, -1.3756e-04, -6.3337e-05],\n",
            "          [-1.7942e-04,  3.7268e-04, -6.0389e-05]],\n",
            "\n",
            "         [[ 5.3445e-05,  2.0921e-04,  1.3276e-04],\n",
            "          [ 1.0860e-04,  5.2061e-05,  1.2308e-04],\n",
            "          [ 1.2755e-04, -2.0041e-04, -9.8819e-05]],\n",
            "\n",
            "         [[-6.8881e-04, -2.4734e-04, -3.3101e-04],\n",
            "          [-2.1734e-04, -8.2570e-05,  1.2194e-04],\n",
            "          [-4.7718e-04,  1.0820e-04,  1.8495e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1310e-04, -3.4245e-04, -4.8399e-04],\n",
            "          [-1.2368e-04, -4.0098e-04, -3.2904e-04],\n",
            "          [-5.2765e-04, -5.9867e-04, -5.7402e-04]],\n",
            "\n",
            "         [[ 1.3325e-04,  2.2892e-04,  4.0001e-04],\n",
            "          [-6.7963e-05,  2.5315e-04,  5.7470e-04],\n",
            "          [ 8.3050e-05,  3.4851e-04,  3.6402e-04]],\n",
            "\n",
            "         [[-1.6880e-04, -1.5860e-04, -2.4687e-04],\n",
            "          [-1.8702e-04, -2.4248e-04, -1.9952e-04],\n",
            "          [-2.7185e-04, -1.5840e-04,  5.8222e-05]]]])}, 76: {'momentum_buffer': tensor([-5.4350e-05,  3.1485e-04,  4.9744e-04,  9.2787e-04,  1.1164e-03,\n",
            "         4.7536e-04,  1.3200e-03,  1.9150e-03,  1.4467e-03,  1.3754e-03,\n",
            "         1.2443e-03,  7.5143e-04,  1.3165e-03,  1.4996e-03,  1.6547e-03,\n",
            "         7.3752e-04, -5.2676e-05,  9.4437e-04,  9.8814e-04,  8.2233e-04,\n",
            "         1.3317e-03,  1.4934e-03,  1.5378e-03,  1.1149e-03,  1.0513e-03,\n",
            "         7.4617e-04,  2.1543e-04,  8.4970e-04,  2.0210e-03,  7.7682e-04,\n",
            "         4.3723e-04,  1.3896e-03,  9.3166e-04,  2.0764e-04,  1.4657e-03,\n",
            "         1.4082e-04,  1.4490e-03,  1.7547e-04,  6.6313e-04,  2.3829e-07,\n",
            "         1.0264e-03,  6.4691e-04,  5.4045e-04,  1.0562e-03,  1.4201e-03,\n",
            "         8.3939e-04,  8.1960e-04,  1.1229e-03,  1.8819e-03,  1.1491e-03,\n",
            "         4.6668e-04,  8.2980e-04,  1.5703e-03,  1.6901e-03,  7.3585e-04,\n",
            "         1.3777e-03,  1.4822e-03,  8.1963e-04,  1.2986e-03,  1.2901e-03,\n",
            "         9.2892e-04,  3.9012e-04,  8.5487e-04,  9.7127e-04,  7.1812e-05,\n",
            "         1.6977e-03,  7.3472e-04, -3.6401e-05,  1.4006e-03,  1.0172e-03,\n",
            "         2.1368e-03,  7.4869e-04,  8.5520e-04,  8.6138e-04,  1.4866e-03,\n",
            "         8.9558e-04,  1.0245e-03,  9.5100e-04,  1.6172e-03,  1.5115e-03,\n",
            "         1.7442e-03, -2.9440e-06,  7.6090e-04,  1.2359e-03,  6.4740e-04,\n",
            "         1.2995e-03,  1.0756e-03,  8.9499e-04,  1.4089e-04,  8.9582e-04,\n",
            "         8.7325e-04,  1.2214e-03,  2.0498e-04,  1.6539e-04,  7.1400e-04,\n",
            "         8.3340e-04,  7.9077e-04,  1.1716e-03,  1.5496e-03,  1.9490e-03,\n",
            "         1.1043e-03,  8.6820e-04,  1.4637e-03,  9.2763e-04,  7.5423e-04,\n",
            "        -2.8757e-04,  9.5227e-04,  1.4264e-03,  1.6107e-03,  1.0631e-03,\n",
            "         1.6079e-04,  1.0461e-03,  1.1576e-03,  1.4272e-04,  1.6651e-03,\n",
            "         1.7174e-03,  9.8880e-04,  9.2981e-04,  5.8296e-04,  7.3878e-04,\n",
            "         9.3424e-04,  1.0421e-03,  1.0311e-03,  5.8956e-04,  3.2118e-04,\n",
            "         1.0646e-03,  1.0384e-03,  1.4175e-03,  1.4785e-03,  8.7519e-04,\n",
            "         3.3352e-04,  2.1481e-03,  1.6810e-03,  5.4735e-04,  8.1917e-05,\n",
            "         1.1625e-03,  6.3863e-05,  1.2394e-03,  1.0224e-03,  1.2565e-03,\n",
            "         1.5402e-04,  7.8172e-04,  1.6149e-03,  1.4183e-03,  1.9471e-03,\n",
            "         8.8376e-04, -1.6207e-04,  1.5925e-03,  7.4821e-04,  7.0342e-04,\n",
            "         1.7387e-03,  7.4477e-04,  3.6591e-04,  1.4953e-03,  6.1415e-04,\n",
            "         9.1191e-04,  1.6098e-03,  1.0589e-04,  2.2740e-04,  1.2830e-03,\n",
            "         1.3877e-03,  1.4049e-03,  1.1285e-03,  1.4730e-03,  7.5595e-04,\n",
            "         1.2571e-03,  1.3341e-03,  5.4780e-04,  5.8593e-04,  8.1184e-04,\n",
            "         8.7550e-04,  1.3590e-03,  1.7896e-03,  1.0924e-03,  5.9323e-04,\n",
            "         4.9141e-04,  6.1706e-04,  1.4785e-03,  9.5853e-04,  7.3255e-04,\n",
            "         1.3824e-03,  1.3328e-03,  3.7980e-04,  2.1734e-03,  9.2217e-05,\n",
            "        -3.3129e-04,  4.7422e-04,  9.5105e-04,  1.1078e-03,  1.7570e-03,\n",
            "         1.0910e-03,  1.5876e-03,  1.1976e-03,  1.3087e-03,  1.1046e-03,\n",
            "         1.2967e-03,  1.7796e-03,  6.3374e-04,  1.6771e-03,  6.9083e-04,\n",
            "         2.0845e-03,  1.4216e-03,  6.5120e-04,  1.7866e-03,  5.3979e-04,\n",
            "         9.3499e-04,  1.2858e-03,  5.1670e-04,  1.1992e-03,  1.3803e-03,\n",
            "         7.3585e-04,  1.2196e-03,  1.1747e-03,  1.6654e-03,  5.7414e-04,\n",
            "         8.1471e-04,  4.1369e-04,  4.4411e-04,  1.0591e-03,  1.5503e-03,\n",
            "         1.8258e-04,  2.5447e-03,  7.3109e-04,  1.8535e-04,  5.8254e-04,\n",
            "         1.5945e-03,  1.0965e-03,  6.0427e-04,  5.0666e-04,  1.4486e-03,\n",
            "         9.2996e-04,  5.4746e-04,  9.3856e-04,  1.7067e-03,  1.1658e-03,\n",
            "        -6.4542e-05,  4.3161e-04,  6.2850e-04,  1.8909e-03,  1.7900e-04,\n",
            "         5.9261e-04,  7.8221e-04,  1.2575e-03,  1.6946e-03,  1.1559e-03,\n",
            "         1.3510e-03,  1.0620e-03,  7.7814e-04,  8.4927e-04,  1.2862e-03,\n",
            "         9.1141e-04,  1.0742e-03,  1.8514e-03,  6.2324e-04,  1.4682e-03,\n",
            "         9.8807e-04])}, 77: {'momentum_buffer': tensor([-9.0617e-04, -4.7275e-04,  1.7946e-04, -1.6179e-04,  4.6229e-05,\n",
            "        -6.3050e-04, -3.9003e-04,  1.2317e-03,  6.7811e-04,  3.0836e-04,\n",
            "         5.7140e-05, -2.3194e-04,  5.1382e-04,  2.8506e-04,  3.0523e-04,\n",
            "         6.4467e-05, -3.5312e-04,  1.1743e-04,  2.5957e-04,  1.1414e-04,\n",
            "         6.8769e-04,  4.4170e-04,  4.1067e-04,  4.1944e-04, -5.7194e-05,\n",
            "        -5.5714e-04, -6.2792e-04,  3.3930e-04,  9.9274e-04,  8.5506e-05,\n",
            "        -7.0894e-04,  6.3012e-04,  4.7820e-04,  3.4235e-04,  3.5551e-04,\n",
            "        -8.2006e-04,  6.2660e-04, -1.1334e-03, -1.1051e-03, -7.9464e-06,\n",
            "         4.6031e-04,  9.8165e-05,  4.8191e-04,  1.4638e-04, -3.8363e-04,\n",
            "        -4.5687e-04,  1.6969e-04,  2.4993e-04,  8.4165e-04,  1.6980e-04,\n",
            "         3.2461e-04,  5.6044e-04, -2.1975e-04,  3.6261e-04, -4.4416e-04,\n",
            "         4.9672e-04,  3.1952e-04, -4.2952e-04,  7.6176e-04,  4.9329e-04,\n",
            "        -1.0859e-04, -6.6488e-04, -1.0604e-03, -3.6104e-04, -2.2493e-04,\n",
            "         5.9524e-04,  1.9235e-04, -5.7147e-04, -1.1925e-04, -1.0511e-04,\n",
            "        -2.4420e-04,  1.7128e-04, -4.8663e-07, -6.4495e-04,  3.4833e-04,\n",
            "        -4.0736e-04,  1.3081e-05, -1.0294e-04,  3.0006e-04, -2.4386e-04,\n",
            "         1.6567e-04, -4.4752e-04, -1.6503e-04, -1.4907e-04,  4.0861e-04,\n",
            "        -9.4711e-05,  6.7245e-06, -1.1057e-03, -1.6207e-04,  5.2393e-04,\n",
            "        -2.0488e-04,  4.4017e-04, -7.5844e-04, -5.8846e-04,  7.6594e-04,\n",
            "         5.2190e-05, -4.6315e-04, -1.0661e-04, -1.5133e-04,  4.2265e-04,\n",
            "        -8.6198e-06,  4.6923e-04, -2.6420e-04, -1.0808e-04, -2.2108e-04,\n",
            "        -2.0319e-04, -3.3689e-04,  7.2098e-05,  5.8464e-04, -8.6870e-05,\n",
            "        -7.8852e-04,  3.0489e-04,  1.7918e-04, -4.7988e-04, -4.3481e-04,\n",
            "         6.0427e-04,  3.1533e-04, -2.6275e-04,  1.9547e-05,  4.8052e-04,\n",
            "        -3.6758e-04, -3.2892e-04, -3.9943e-04, -9.7266e-04, -3.4111e-04,\n",
            "         1.2829e-03, -4.8642e-05,  9.2750e-06,  5.6246e-04, -9.2883e-04,\n",
            "        -8.0538e-04,  6.0371e-04,  2.7032e-04, -4.7187e-04, -4.8501e-04,\n",
            "        -9.3651e-05, -6.3077e-04,  3.5739e-04, -2.2732e-04,  4.3565e-05,\n",
            "        -4.4708e-04, -6.8530e-04,  3.0627e-04,  3.6191e-05,  7.2942e-04,\n",
            "         2.6510e-04, -6.3098e-04,  5.2270e-04,  1.9766e-04, -1.0198e-04,\n",
            "         2.8835e-04, -6.3700e-04, -7.5827e-04,  2.6970e-04,  9.9885e-05,\n",
            "        -2.8246e-04,  3.3093e-05,  1.5447e-04, -3.2979e-04,  2.1537e-05,\n",
            "         2.4444e-04,  5.2452e-04, -5.3497e-04,  1.2174e-04,  6.2961e-05,\n",
            "        -2.8045e-04, -1.3244e-05,  2.0782e-04,  2.4502e-04, -4.8244e-04,\n",
            "         1.0173e-04,  3.5862e-04, -1.1302e-04, -8.5027e-04,  4.4232e-05,\n",
            "         2.1992e-05,  3.1356e-04,  6.6053e-05, -6.5321e-04,  1.5025e-04,\n",
            "         3.4406e-04,  2.8042e-04, -2.7365e-04,  4.5240e-04, -3.6752e-04,\n",
            "        -1.6722e-03, -4.0095e-04,  8.2979e-05, -3.2866e-05,  2.0684e-04,\n",
            "        -7.4761e-05,  7.1427e-04, -4.3221e-04,  2.5529e-04,  5.0631e-04,\n",
            "        -8.4827e-05,  6.2304e-04,  3.7651e-04,  3.6665e-04,  3.2663e-04,\n",
            "         8.8109e-04,  3.7923e-04, -1.5626e-04, -1.4452e-05, -3.1750e-05,\n",
            "         8.2428e-04,  4.4946e-04, -3.3956e-04,  3.3746e-04,  8.0944e-05,\n",
            "        -8.4123e-04,  2.2995e-04,  2.5308e-04,  5.5497e-04, -2.9330e-04,\n",
            "        -4.2326e-04, -2.0704e-04, -2.7570e-04, -3.3864e-04,  7.4528e-04,\n",
            "        -7.8444e-05,  9.0760e-04,  1.3750e-04,  7.7235e-04, -2.5957e-04,\n",
            "         1.3150e-03,  5.7213e-04, -9.2027e-04, -4.0192e-04,  2.9271e-04,\n",
            "        -1.0646e-04, -6.9741e-04,  6.7853e-05,  5.8374e-04, -8.0744e-04,\n",
            "        -7.8807e-04, -1.2427e-04, -4.6540e-04,  8.1300e-04, -2.6895e-04,\n",
            "        -9.2785e-04,  1.8900e-05,  5.2068e-04,  8.5576e-05, -2.2819e-04,\n",
            "        -1.7351e-04, -1.4679e-04, -1.6951e-04, -1.2671e-04,  6.4504e-04,\n",
            "         1.0218e-04,  4.1117e-04, -3.7842e-04, -4.4526e-04, -1.6727e-04,\n",
            "        -1.5259e-04])}, 78: {'momentum_buffer': tensor([[[[ 3.3068e-04]],\n",
            "\n",
            "         [[ 1.2036e-04]],\n",
            "\n",
            "         [[ 6.9387e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5218e-04]],\n",
            "\n",
            "         [[ 2.5474e-04]],\n",
            "\n",
            "         [[ 4.0114e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.6135e-04]],\n",
            "\n",
            "         [[-2.9953e-04]],\n",
            "\n",
            "         [[ 3.2652e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.0373e-05]],\n",
            "\n",
            "         [[ 3.4139e-04]],\n",
            "\n",
            "         [[ 2.6763e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.6839e-04]],\n",
            "\n",
            "         [[ 3.8331e-04]],\n",
            "\n",
            "         [[-1.5058e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.3352e-05]],\n",
            "\n",
            "         [[-7.4295e-05]],\n",
            "\n",
            "         [[-2.0306e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.2283e-05]],\n",
            "\n",
            "         [[-3.1273e-04]],\n",
            "\n",
            "         [[ 6.2915e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.3694e-05]],\n",
            "\n",
            "         [[ 2.0225e-04]],\n",
            "\n",
            "         [[ 3.7773e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1974e-04]],\n",
            "\n",
            "         [[ 3.1494e-04]],\n",
            "\n",
            "         [[ 2.0008e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0554e-04]],\n",
            "\n",
            "         [[ 1.2736e-05]],\n",
            "\n",
            "         [[ 1.3816e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.5857e-04]],\n",
            "\n",
            "         [[-4.9369e-04]],\n",
            "\n",
            "         [[-4.5921e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.6466e-05]],\n",
            "\n",
            "         [[-1.0468e-04]],\n",
            "\n",
            "         [[-1.8852e-04]]]])}, 79: {'momentum_buffer': tensor([0.0009, 0.0008, 0.0012,  ..., 0.0014, 0.0012, 0.0011])}, 80: {'momentum_buffer': tensor([ 1.1123e-04, -6.5778e-04,  2.5964e-04,  ...,  2.2368e-04,\n",
            "         4.3805e-05,  2.8573e-04])}, 81: {'momentum_buffer': tensor([[[[-9.6547e-06]],\n",
            "\n",
            "         [[ 1.2254e-04]],\n",
            "\n",
            "         [[ 8.5837e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9334e-04]],\n",
            "\n",
            "         [[ 7.0236e-05]],\n",
            "\n",
            "         [[-5.9841e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.9097e-06]],\n",
            "\n",
            "         [[-1.1678e-04]],\n",
            "\n",
            "         [[ 1.7384e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4798e-04]],\n",
            "\n",
            "         [[ 9.6784e-05]],\n",
            "\n",
            "         [[-5.3745e-05]]],\n",
            "\n",
            "\n",
            "        [[[-5.0681e-04]],\n",
            "\n",
            "         [[ 7.5796e-05]],\n",
            "\n",
            "         [[-2.7300e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.3442e-05]],\n",
            "\n",
            "         [[-1.4584e-04]],\n",
            "\n",
            "         [[-1.5129e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5071e-04]],\n",
            "\n",
            "         [[-3.2823e-04]],\n",
            "\n",
            "         [[ 3.1448e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4662e-04]],\n",
            "\n",
            "         [[-3.6599e-04]],\n",
            "\n",
            "         [[ 4.6318e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 9.3296e-05]],\n",
            "\n",
            "         [[ 2.5379e-05]],\n",
            "\n",
            "         [[-5.2267e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.8474e-05]],\n",
            "\n",
            "         [[-1.8565e-04]],\n",
            "\n",
            "         [[-4.7560e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6581e-04]],\n",
            "\n",
            "         [[ 2.7356e-04]],\n",
            "\n",
            "         [[ 6.7171e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5487e-04]],\n",
            "\n",
            "         [[ 2.4927e-04]],\n",
            "\n",
            "         [[ 3.4686e-04]]]])}, 82: {'momentum_buffer': tensor([0.0013, 0.0007, 0.0011,  ..., 0.0011, 0.0009, 0.0017])}, 83: {'momentum_buffer': tensor([ 1.1123e-04, -6.5778e-04,  2.5964e-04,  ...,  2.2368e-04,\n",
            "         4.3805e-05,  2.8573e-04])}, 84: {'momentum_buffer': tensor([[[[ 6.0160e-04]],\n",
            "\n",
            "         [[ 1.9384e-04]],\n",
            "\n",
            "         [[ 1.0098e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.1141e-04]],\n",
            "\n",
            "         [[-4.4060e-05]],\n",
            "\n",
            "         [[ 6.7670e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.7059e-04]],\n",
            "\n",
            "         [[-1.3841e-04]],\n",
            "\n",
            "         [[ 2.1282e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.2569e-04]],\n",
            "\n",
            "         [[ 1.3967e-04]],\n",
            "\n",
            "         [[-3.5139e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2377e-05]],\n",
            "\n",
            "         [[ 7.0682e-05]],\n",
            "\n",
            "         [[-4.2990e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9688e-05]],\n",
            "\n",
            "         [[-2.1880e-05]],\n",
            "\n",
            "         [[ 1.8865e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.3038e-05]],\n",
            "\n",
            "         [[-2.8432e-04]],\n",
            "\n",
            "         [[-1.7137e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.3467e-04]],\n",
            "\n",
            "         [[-7.8804e-05]],\n",
            "\n",
            "         [[-1.5324e-04]]],\n",
            "\n",
            "\n",
            "        [[[-5.1000e-05]],\n",
            "\n",
            "         [[ 8.3990e-05]],\n",
            "\n",
            "         [[ 1.2301e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9348e-05]],\n",
            "\n",
            "         [[ 1.9554e-04]],\n",
            "\n",
            "         [[-3.7804e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 3.7357e-04]],\n",
            "\n",
            "         [[ 1.3794e-04]],\n",
            "\n",
            "         [[-2.7399e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.6437e-04]],\n",
            "\n",
            "         [[ 1.6618e-04]],\n",
            "\n",
            "         [[ 8.5805e-05]]]])}, 85: {'momentum_buffer': tensor([ 1.5873e-03, -3.3506e-05,  1.4644e-03, -9.7608e-05,  9.9425e-04,\n",
            "         1.0557e-03,  1.5868e-03,  4.1736e-04,  1.5379e-03,  1.3182e-03,\n",
            "         9.3199e-04,  1.5933e-03,  1.2420e-03,  6.8666e-04,  1.1335e-03,\n",
            "         1.0363e-03,  1.5614e-03,  2.0895e-03,  5.5072e-04,  9.6461e-04,\n",
            "         1.2430e-03,  8.6483e-04,  1.0238e-03,  1.5363e-03,  1.1322e-03,\n",
            "         1.7458e-03,  1.1136e-03,  1.8176e-03,  5.7294e-04,  5.1315e-04,\n",
            "         7.4319e-04,  7.0755e-04,  8.7615e-04,  9.2809e-04,  1.2239e-03,\n",
            "         1.5327e-03,  8.5887e-04,  1.0886e-03,  1.1197e-03,  1.0777e-03,\n",
            "         9.2705e-04, -8.2831e-05,  8.3641e-04,  5.9516e-04,  1.2114e-03,\n",
            "         1.2029e-03,  9.1274e-04,  1.4669e-03,  1.6895e-03,  7.8223e-04,\n",
            "         6.5604e-04,  1.5923e-03,  1.2268e-03,  2.0471e-03,  1.1588e-04,\n",
            "         8.9580e-04,  1.1339e-03,  6.7394e-04,  8.3418e-04,  6.0921e-04,\n",
            "         7.3439e-04,  9.3456e-04,  9.3347e-04,  1.0997e-03,  1.6681e-03,\n",
            "         3.6264e-04,  9.8043e-04,  9.2276e-04,  1.2946e-03,  9.5123e-04,\n",
            "         1.7084e-03,  1.1356e-03,  1.3171e-03,  2.1672e-03,  9.6372e-04,\n",
            "         7.0682e-04,  8.7005e-04,  7.0415e-04,  1.3741e-03,  1.4053e-03,\n",
            "         1.0741e-03,  6.2098e-04,  8.3824e-04,  3.1325e-04,  1.0814e-03,\n",
            "         1.4056e-03,  1.5625e-03,  6.5223e-04,  1.3334e-03,  1.5616e-04,\n",
            "         1.2331e-03,  1.0103e-03,  1.3733e-03,  1.2214e-03,  5.3024e-04,\n",
            "         1.6040e-03,  1.2426e-03,  6.7059e-04,  2.2809e-04,  7.3592e-04,\n",
            "         4.6705e-04,  1.6415e-03,  1.1885e-03,  9.1205e-04,  1.2911e-03,\n",
            "         1.4909e-04,  1.3746e-03,  1.0259e-03,  8.5754e-04,  6.5982e-04,\n",
            "         9.6461e-04,  8.2570e-04,  7.6330e-04,  5.6794e-04,  1.5243e-03,\n",
            "         1.0338e-03,  8.1192e-04,  1.3985e-03,  9.5540e-04,  7.1090e-04,\n",
            "         1.1208e-03,  5.4815e-04,  9.2740e-04,  9.6832e-04, -4.6187e-04,\n",
            "         8.8144e-04,  6.9139e-04,  4.5792e-04,  1.6854e-03,  1.5825e-03,\n",
            "         5.3143e-04,  4.9169e-04,  3.4827e-04,  7.1941e-04,  9.4909e-04,\n",
            "         1.4032e-03,  1.1652e-03,  1.1371e-03,  1.6801e-03,  3.0671e-04,\n",
            "         5.2152e-04,  1.6792e-03,  1.4727e-03,  1.4189e-03,  1.9389e-03,\n",
            "         1.3248e-03,  6.2632e-04,  1.4984e-03,  1.5593e-03, -7.4978e-05,\n",
            "         1.6189e-03,  1.5032e-03,  8.1686e-05,  1.6626e-03,  1.0149e-03,\n",
            "         7.9679e-04,  1.0138e-03,  1.1430e-03,  1.2834e-03,  1.1566e-03,\n",
            "         1.0280e-03,  6.4177e-04,  7.0644e-04,  1.1626e-03,  4.5122e-04,\n",
            "         1.2098e-03,  5.8693e-04,  4.1531e-04,  1.6075e-03,  4.3988e-04,\n",
            "         9.9994e-04,  7.2085e-04,  2.2136e-04,  1.5134e-03,  1.5356e-03,\n",
            "         1.8331e-03,  7.5696e-04,  1.3039e-03,  5.0645e-04,  2.3024e-03,\n",
            "         1.2527e-03,  6.7916e-04,  1.2800e-03,  1.1501e-03,  1.5801e-03,\n",
            "         1.0204e-03,  1.3390e-03,  7.2971e-04,  1.0844e-03,  1.0897e-03,\n",
            "         1.2775e-03,  8.8562e-04,  1.3874e-03,  1.1478e-03,  1.2446e-03,\n",
            "         2.0779e-03,  6.0651e-04,  1.6342e-04,  6.6301e-04,  1.1111e-03,\n",
            "         5.3930e-04,  4.7158e-04,  1.2267e-03,  9.0906e-04,  6.5850e-04,\n",
            "         4.5201e-04,  1.8119e-03,  7.5194e-04,  7.1819e-04,  1.1891e-03,\n",
            "         1.2700e-03,  7.1937e-04,  6.8274e-04,  9.1997e-05,  9.1338e-04,\n",
            "         1.0946e-03,  9.4377e-04,  1.2207e-03,  5.8730e-04,  8.9066e-04,\n",
            "         7.0580e-04,  1.4110e-03,  1.3243e-03,  6.0241e-04,  1.5476e-03,\n",
            "         5.3772e-04,  8.3297e-04,  3.3169e-04,  1.2893e-03,  1.0531e-03,\n",
            "         1.2396e-03,  7.4307e-04,  1.0388e-03,  1.0488e-03,  1.2424e-03,\n",
            "         1.0405e-03,  3.0383e-04,  4.3052e-04,  3.8792e-04,  7.0841e-04,\n",
            "         6.8337e-04,  6.0230e-04,  5.2809e-04,  1.4089e-03,  1.0261e-03,\n",
            "         5.9353e-04,  1.2932e-03,  1.2010e-03,  8.4178e-04,  9.1673e-04,\n",
            "         1.1623e-03,  3.3922e-04,  1.2231e-03,  4.9819e-04,  1.1173e-03,\n",
            "         7.0626e-04])}, 86: {'momentum_buffer': tensor([ 1.3673e-04, -8.6960e-04,  2.4162e-04, -1.4642e-04, -5.7213e-05,\n",
            "         6.1396e-04, -4.3371e-04,  7.3736e-05,  1.5994e-04,  2.6887e-04,\n",
            "         1.1293e-04,  1.2920e-04,  6.3930e-04, -7.8127e-05,  3.1300e-04,\n",
            "         3.1963e-04,  4.8581e-04, -1.8611e-04, -4.0878e-04, -3.3351e-04,\n",
            "         4.6536e-04, -1.4051e-04,  3.2979e-04,  6.1367e-04,  4.7740e-05,\n",
            "         3.7147e-04, -3.6682e-04,  8.2514e-04, -5.6470e-04, -4.4888e-04,\n",
            "         6.3466e-05, -1.4560e-04, -7.8764e-05, -1.1860e-04, -9.3301e-05,\n",
            "         8.4095e-05, -1.8966e-04, -7.2419e-05,  3.9225e-04,  2.2341e-04,\n",
            "         5.6541e-04, -6.4932e-04,  2.7088e-04,  1.7239e-04, -1.4990e-04,\n",
            "        -2.8427e-04,  1.1754e-04,  4.6493e-04,  4.7409e-04, -6.7087e-04,\n",
            "        -3.9333e-04,  4.0071e-04,  7.2865e-04,  1.0684e-03, -1.7265e-04,\n",
            "        -2.0760e-04, -9.6111e-05,  3.7987e-04,  3.2162e-04, -7.6468e-04,\n",
            "        -3.4478e-04,  2.5486e-04,  2.3042e-04,  1.6570e-04,  8.5514e-04,\n",
            "        -4.2091e-04,  1.0061e-04,  2.0105e-04,  2.2075e-04, -1.4649e-04,\n",
            "         6.0656e-04, -2.1407e-04, -2.9326e-05,  8.6159e-05,  6.3950e-05,\n",
            "        -8.6345e-06,  1.4803e-04, -2.8922e-04,  7.3021e-04,  8.1763e-04,\n",
            "         9.5514e-05, -6.1320e-04,  1.4536e-04, -2.0050e-04,  2.4291e-04,\n",
            "         1.6632e-04,  1.3376e-04, -7.0790e-04,  4.2544e-06, -5.3456e-04,\n",
            "         1.4964e-05, -3.5323e-04,  1.3385e-04, -2.8712e-04, -3.5952e-04,\n",
            "         1.4349e-04, -1.7336e-04, -8.6136e-05, -9.5929e-04, -2.4080e-04,\n",
            "        -3.1622e-04,  3.9891e-04,  2.6011e-04, -4.9539e-05,  6.1977e-05,\n",
            "        -9.7719e-04, -3.5176e-05, -1.1065e-04,  2.7694e-05,  5.3557e-04,\n",
            "        -4.6525e-04,  1.9518e-04, -5.4744e-04, -2.3654e-04,  1.8947e-04,\n",
            "         3.5868e-04, -5.0171e-04,  1.5534e-04, -3.3128e-04, -1.7890e-04,\n",
            "         3.4087e-05, -5.1815e-04,  8.3616e-05, -1.9335e-05, -4.6010e-04,\n",
            "        -4.3530e-04, -3.7250e-05, -1.7606e-04, -9.0585e-05,  7.3608e-04,\n",
            "        -2.1174e-04, -4.0181e-04, -8.4552e-04, -3.4527e-04,  1.6924e-04,\n",
            "         7.3969e-04,  3.2023e-04,  4.7314e-04,  6.2126e-04, -3.6668e-04,\n",
            "         1.0160e-04,  5.2055e-04,  5.0167e-05, -5.9661e-05,  1.0103e-03,\n",
            "         7.8693e-05,  2.0122e-04, -1.1103e-05,  3.3920e-04, -1.0943e-03,\n",
            "         6.3909e-04, -2.6283e-05, -3.7234e-04,  8.0229e-04, -7.6571e-05,\n",
            "        -2.5542e-04,  8.8518e-05,  3.8928e-04, -4.6435e-04, -4.0904e-05,\n",
            "         2.7552e-04, -1.1100e-04, -7.1911e-05,  4.1179e-05,  1.5833e-04,\n",
            "         2.8295e-04, -3.7391e-04, -1.8998e-04,  2.4627e-04, -1.2986e-03,\n",
            "        -2.4174e-04, -1.8586e-04, -5.2426e-04,  7.1227e-04,  4.0305e-04,\n",
            "         8.7628e-04, -3.5560e-04,  2.6099e-04, -6.1927e-04,  4.1878e-04,\n",
            "         1.7093e-04, -4.1035e-04, -1.6236e-04,  6.7859e-05, -1.0659e-04,\n",
            "         2.5166e-04,  6.5955e-04, -3.1331e-04,  4.5268e-04, -3.4902e-04,\n",
            "        -4.2124e-04, -2.5307e-04,  8.2967e-04,  5.1894e-04,  4.2181e-04,\n",
            "         2.5181e-05, -3.6715e-04, -3.4829e-04, -4.1734e-04, -5.5160e-05,\n",
            "        -2.1253e-04, -1.1499e-04,  2.9020e-04, -1.9998e-04, -9.9596e-05,\n",
            "        -9.1722e-04,  3.8759e-04, -2.8133e-04, -2.9895e-04,  5.6596e-04,\n",
            "        -2.3871e-04, -5.8821e-04, -2.1415e-04, -2.0002e-04, -6.6586e-04,\n",
            "         6.4820e-04,  1.4656e-04,  1.6931e-05, -9.8508e-05, -1.7791e-04,\n",
            "         2.8119e-04,  8.8507e-04, -4.6076e-04,  2.4310e-04,  2.3135e-04,\n",
            "        -2.7115e-04, -1.9086e-04, -2.9878e-04,  1.7083e-04,  4.1342e-04,\n",
            "         1.2682e-04, -8.1232e-04,  8.6125e-04,  5.5555e-04,  1.5918e-04,\n",
            "         3.1125e-04, -7.3576e-04,  5.2748e-06, -7.1581e-04,  3.5629e-04,\n",
            "        -2.6065e-04, -1.6181e-04, -5.2445e-04,  3.0705e-04,  1.4712e-04,\n",
            "        -3.5196e-04,  2.6415e-04, -4.0036e-04, -2.9837e-04,  2.2618e-04,\n",
            "         2.5670e-05, -2.6984e-04, -1.7999e-04,  1.4846e-05,  3.2234e-04,\n",
            "        -6.0104e-04])}, 87: {'momentum_buffer': tensor([[[[ 5.1861e-04,  2.8438e-05,  3.5386e-04],\n",
            "          [ 4.5151e-04,  1.1698e-04,  3.0177e-04],\n",
            "          [ 6.4827e-04,  4.8095e-04,  6.5001e-04]],\n",
            "\n",
            "         [[ 3.9720e-04,  1.1103e-04,  2.0678e-04],\n",
            "          [ 7.2579e-04, -2.2509e-05,  8.0056e-05],\n",
            "          [-1.1376e-04,  2.7089e-04, -2.8584e-04]],\n",
            "\n",
            "         [[ 5.6483e-04,  4.4088e-05,  1.6690e-04],\n",
            "          [ 4.0082e-04,  4.2716e-04,  4.5843e-05],\n",
            "          [ 6.3769e-04,  3.3770e-04,  4.3839e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1385e-05,  4.7996e-05, -2.7219e-04],\n",
            "          [-5.9157e-04,  1.3266e-04, -1.8434e-04],\n",
            "          [-3.5486e-04, -2.3413e-04, -1.7454e-04]],\n",
            "\n",
            "         [[-1.0978e-06, -3.8115e-04, -2.1728e-04],\n",
            "          [ 1.1951e-04, -2.2723e-04, -1.9703e-04],\n",
            "          [ 1.8957e-05,  1.6023e-04,  2.4303e-04]],\n",
            "\n",
            "         [[ 4.1036e-04,  2.8326e-04,  5.7423e-04],\n",
            "          [ 1.5846e-04, -4.3311e-05,  6.9477e-04],\n",
            "          [ 1.9772e-04, -1.5888e-04,  4.2956e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4911e-04, -1.4225e-04,  9.2477e-05],\n",
            "          [ 9.1754e-05,  1.9030e-05, -7.1491e-05],\n",
            "          [-2.1921e-04, -3.8624e-04, -3.5635e-04]],\n",
            "\n",
            "         [[-8.5268e-04, -4.2929e-04, -9.3890e-05],\n",
            "          [-3.4286e-04, -2.1625e-04, -6.5987e-05],\n",
            "          [-2.0478e-05, -4.9855e-04,  2.1319e-04]],\n",
            "\n",
            "         [[-3.8887e-04, -3.7202e-04, -3.8360e-04],\n",
            "          [-3.0706e-04,  3.9727e-04, -6.3426e-05],\n",
            "          [-4.7946e-04,  3.6462e-04,  3.6726e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7537e-04,  4.4743e-04,  2.5653e-04],\n",
            "          [-8.2062e-05,  5.2389e-04,  6.2549e-04],\n",
            "          [-1.3198e-04,  1.1827e-04,  5.1479e-04]],\n",
            "\n",
            "         [[ 5.6286e-04, -2.0529e-04,  2.1853e-04],\n",
            "          [ 1.8771e-04, -7.6203e-06, -2.5527e-05],\n",
            "          [ 2.5421e-04,  6.6741e-05,  9.6846e-05]],\n",
            "\n",
            "         [[-2.6092e-04, -3.3748e-04, -2.8801e-04],\n",
            "          [-4.0872e-04, -5.6779e-04, -8.4695e-04],\n",
            "          [-1.6227e-04, -6.4831e-04, -1.1020e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6325e-04,  3.1074e-04, -2.1385e-05],\n",
            "          [ 2.3279e-04,  1.4092e-04,  7.8535e-05],\n",
            "          [ 2.7142e-04,  3.1845e-04,  1.0492e-04]],\n",
            "\n",
            "         [[ 1.3345e-04, -1.0274e-04,  4.5844e-04],\n",
            "          [ 1.4987e-04,  2.6363e-04,  4.8591e-05],\n",
            "          [ 9.6476e-05,  2.2818e-04,  2.6402e-04]],\n",
            "\n",
            "         [[-8.0102e-06, -3.9555e-04,  3.6373e-05],\n",
            "          [-1.9993e-04, -1.6356e-04, -1.8053e-04],\n",
            "          [-7.8649e-05, -2.0471e-04, -7.9677e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2195e-04, -1.4720e-04, -2.2462e-04],\n",
            "          [-3.3447e-04,  1.9408e-05, -2.8551e-04],\n",
            "          [-4.8692e-05, -1.7302e-04, -8.8857e-05]],\n",
            "\n",
            "         [[ 9.2789e-05,  2.9529e-05,  6.2943e-05],\n",
            "          [ 3.4178e-06,  4.7731e-05,  2.1973e-04],\n",
            "          [-4.7821e-05,  3.7774e-05, -4.0726e-05]],\n",
            "\n",
            "         [[ 1.4397e-04, -1.5614e-04, -2.4943e-04],\n",
            "          [-1.6728e-05,  2.0037e-04,  1.8450e-04],\n",
            "          [ 2.4085e-04,  2.6873e-05, -2.2024e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.5231e-05,  1.6491e-04,  2.2426e-04],\n",
            "          [ 3.3946e-04,  5.2308e-05,  1.6398e-04],\n",
            "          [-1.0542e-04, -1.6632e-04,  9.1131e-05]],\n",
            "\n",
            "         [[-2.5062e-04, -4.1835e-04, -1.0110e-04],\n",
            "          [-3.6572e-04, -3.6778e-04, -1.7947e-04],\n",
            "          [-3.1905e-05, -9.7676e-05,  4.8279e-05]],\n",
            "\n",
            "         [[ 1.8466e-04,  4.2409e-05,  1.3435e-05],\n",
            "          [ 1.0086e-04,  1.6829e-04, -8.0152e-05],\n",
            "          [-1.6717e-04,  8.5083e-05, -7.8453e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1962e-04, -7.5342e-05, -1.7061e-04],\n",
            "          [ 1.7168e-04,  1.4075e-05, -1.2499e-05],\n",
            "          [ 1.0201e-04, -1.5013e-04, -8.7391e-05]],\n",
            "\n",
            "         [[-9.9516e-06,  3.7746e-05,  6.4435e-05],\n",
            "          [-3.5955e-05, -1.1660e-05,  3.7333e-06],\n",
            "          [-1.0368e-04, -1.2411e-04,  1.7203e-04]],\n",
            "\n",
            "         [[-1.1789e-04, -1.5857e-04, -7.6396e-05],\n",
            "          [-1.2096e-04,  2.7695e-06, -2.0811e-04],\n",
            "          [-7.6180e-05, -9.4892e-05, -2.2743e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 4.0395e-04,  6.3177e-04,  3.9855e-04],\n",
            "          [ 1.3850e-04,  5.9100e-04,  3.6162e-04],\n",
            "          [ 2.0013e-04,  7.3586e-05,  4.3825e-04]],\n",
            "\n",
            "         [[ 1.6952e-04,  1.1543e-04, -5.9739e-04],\n",
            "          [ 1.6263e-04, -2.7678e-05,  2.3633e-05],\n",
            "          [ 1.2245e-04,  6.5554e-05,  2.3235e-06]],\n",
            "\n",
            "         [[ 1.0521e-04, -2.1023e-04, -1.4507e-04],\n",
            "          [-1.3400e-04, -1.2572e-04, -2.8112e-04],\n",
            "          [-3.6147e-04, -6.5720e-05, -5.1016e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5920e-04, -1.7907e-04, -1.8451e-04],\n",
            "          [ 3.1889e-04,  1.0260e-04, -2.7328e-04],\n",
            "          [ 5.2288e-05, -5.5556e-04, -7.4663e-04]],\n",
            "\n",
            "         [[-1.1722e-04,  3.9753e-04,  1.2993e-04],\n",
            "          [ 5.8314e-05,  7.9272e-04,  5.5973e-04],\n",
            "          [-3.6734e-05,  2.0520e-05,  1.1826e-04]],\n",
            "\n",
            "         [[-1.5120e-04,  2.3215e-04, -5.3264e-05],\n",
            "          [ 1.6637e-04,  3.8606e-04,  8.1807e-05],\n",
            "          [ 1.7044e-05,  2.5920e-05, -2.5766e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.5178e-04, -3.3630e-05, -3.8120e-06],\n",
            "          [-3.4645e-04, -1.0152e-04,  1.0275e-04],\n",
            "          [ 4.7441e-05, -4.6543e-05,  1.9130e-04]],\n",
            "\n",
            "         [[ 1.5455e-04,  3.0031e-04, -5.9001e-07],\n",
            "          [-1.5183e-04,  6.5563e-05,  3.8664e-05],\n",
            "          [-3.2002e-04,  4.8562e-04,  2.9323e-04]],\n",
            "\n",
            "         [[-3.6077e-04, -1.2104e-04,  4.6481e-04],\n",
            "          [-5.7348e-05, -7.5703e-05, -2.6547e-04],\n",
            "          [ 4.7194e-05,  8.3077e-06, -5.8776e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0843e-04,  5.3630e-05,  4.1151e-04],\n",
            "          [ 7.6288e-05,  9.2585e-06, -4.6035e-05],\n",
            "          [-2.8413e-04, -2.8066e-04, -3.4498e-04]],\n",
            "\n",
            "         [[-2.3983e-04, -1.9453e-04, -1.4447e-04],\n",
            "          [-2.1894e-05, -5.6178e-04, -1.0390e-04],\n",
            "          [-6.3143e-05,  5.7062e-05, -6.3462e-05]],\n",
            "\n",
            "         [[ 6.7509e-05,  1.3224e-04,  5.9198e-04],\n",
            "          [-6.7159e-05,  7.6888e-05,  1.5184e-04],\n",
            "          [-1.2227e-04,  4.5919e-05, -1.2982e-04]]]])}, 88: {'momentum_buffer': tensor([ 7.5521e-04,  1.2078e-03,  1.1698e-03,  5.0716e-04,  1.1680e-03,\n",
            "         1.1590e-03,  6.7097e-04,  7.8578e-04,  1.3471e-03,  7.9218e-04,\n",
            "         1.6726e-03,  1.1994e-03,  8.7862e-04,  2.7815e-04,  6.7776e-04,\n",
            "         1.7531e-03,  1.2368e-03,  1.2943e-03,  1.3243e-03,  3.1086e-04,\n",
            "         1.1840e-03,  1.8321e-05,  1.0105e-03,  9.9341e-04,  9.9680e-04,\n",
            "         1.4501e-03,  1.1069e-03,  9.2064e-04,  7.7915e-04,  8.9087e-04,\n",
            "         6.6157e-04,  9.2934e-04,  5.2151e-04,  5.9779e-04,  9.4357e-04,\n",
            "         5.7678e-04,  5.2725e-04,  6.1714e-04,  1.2808e-03,  1.4955e-03,\n",
            "         1.3725e-03,  6.4930e-04,  8.5942e-04,  1.3899e-03,  1.6566e-03,\n",
            "         7.0911e-04,  5.9324e-04,  5.4718e-04,  5.7631e-04,  1.2864e-03,\n",
            "         1.1003e-03,  8.4462e-04,  1.1732e-03,  6.6799e-04,  8.4225e-04,\n",
            "         1.3009e-03, -2.3498e-04,  9.1342e-04,  9.2951e-04, -2.6623e-05,\n",
            "         6.0510e-04,  1.0404e-03,  5.6228e-04,  6.6758e-04,  1.2724e-03,\n",
            "         9.9164e-04,  6.4203e-04,  5.5022e-04,  6.4316e-04,  9.3374e-04,\n",
            "         7.6210e-04,  1.1225e-03,  1.3571e-03,  9.3049e-04,  1.4455e-03,\n",
            "         1.1411e-03,  8.9026e-04,  1.1118e-03,  8.1596e-04,  9.3941e-04,\n",
            "         7.4572e-05,  1.1932e-03,  1.1337e-03,  6.8272e-04,  1.4408e-03,\n",
            "         1.5277e-03,  1.0787e-03,  1.4106e-03,  1.2906e-03,  8.4100e-04,\n",
            "         1.6181e-03,  1.3020e-03,  1.0718e-03,  1.3646e-03,  9.6095e-04,\n",
            "         3.8264e-04,  2.4870e-04,  7.7287e-04,  3.9750e-04,  1.5024e-03,\n",
            "         8.3911e-04,  1.3681e-03,  1.1907e-03,  7.7339e-04,  1.1115e-03,\n",
            "         1.4533e-03,  8.4516e-04,  1.1471e-03,  1.4328e-03,  1.3107e-03,\n",
            "         1.5179e-03,  6.7850e-04,  1.3262e-03,  9.2471e-04,  5.2821e-04,\n",
            "         8.6022e-04,  1.3963e-03,  9.5961e-04,  7.2499e-04,  1.3870e-03,\n",
            "         1.3136e-03,  7.0301e-04,  6.9557e-04,  9.8321e-04,  1.5779e-03,\n",
            "         1.4558e-03,  7.0227e-04,  9.3317e-04,  1.2652e-03,  2.0108e-03,\n",
            "         9.2922e-04,  1.0699e-03,  7.1820e-04,  5.6420e-04,  8.5154e-04,\n",
            "         1.0437e-03,  8.0899e-04,  1.2474e-03,  1.0765e-03,  1.1101e-03,\n",
            "         1.2921e-03,  1.3396e-03,  6.2949e-04,  1.1385e-03,  5.0701e-04,\n",
            "         6.5924e-04,  7.4548e-04,  1.0056e-03,  1.2414e-03,  2.8366e-04,\n",
            "         8.3701e-04,  9.4151e-04,  1.3378e-03,  1.4605e-03,  1.0624e-03,\n",
            "         3.9559e-04,  1.4143e-03,  1.1361e-03,  1.5602e-03,  3.2770e-04,\n",
            "         1.9159e-03,  6.9333e-04,  7.2456e-04,  1.3419e-03,  1.7133e-03,\n",
            "         8.0431e-04,  9.8038e-04,  1.3319e-03,  1.0054e-03,  9.6371e-04,\n",
            "         1.3672e-03,  3.2754e-04,  1.0653e-03,  7.2357e-04,  1.0960e-03,\n",
            "         1.0913e-03,  4.3153e-04,  4.4053e-04,  1.0722e-03,  1.5345e-03,\n",
            "         8.9679e-04,  1.9998e-03,  6.6448e-04,  1.2994e-03,  1.2665e-03,\n",
            "         9.3880e-04,  1.0459e-03,  7.3461e-04,  5.4558e-04,  9.9140e-04,\n",
            "         1.2359e-03,  1.6713e-03,  5.5335e-04,  1.0646e-03,  1.3368e-03,\n",
            "         1.4395e-03,  6.6373e-04,  1.2707e-03,  1.2117e-03,  1.1588e-03,\n",
            "         1.1307e-03,  9.2854e-04,  9.9010e-04,  4.9358e-04, -8.6010e-05,\n",
            "         1.0609e-03,  1.3424e-04,  1.8370e-03,  1.1416e-03,  1.0063e-03,\n",
            "         1.3038e-03,  1.0299e-03,  9.5597e-04,  9.7131e-04,  1.9441e-04,\n",
            "         1.2706e-03,  3.1100e-04,  1.0723e-03,  9.5063e-04,  3.5242e-05,\n",
            "         8.0781e-04,  1.7591e-03,  1.3687e-03,  1.7466e-03,  1.3744e-03,\n",
            "         1.0658e-03,  8.1639e-04,  8.5324e-04,  4.6352e-04,  8.5648e-04,\n",
            "         1.5552e-03,  7.2261e-04,  2.6916e-04,  7.2461e-04,  1.7276e-03,\n",
            "         1.4355e-03,  2.4234e-04,  1.9233e-03,  1.2508e-03,  1.3696e-03,\n",
            "         1.6807e-03,  1.3897e-03,  1.3228e-03,  9.7101e-04,  1.1398e-03,\n",
            "         1.3799e-03,  5.2226e-04,  1.3468e-03,  1.0727e-03,  9.0789e-04,\n",
            "         5.2141e-04,  7.1411e-04,  1.0201e-03,  1.1594e-03,  4.4243e-04,\n",
            "         1.1055e-03])}, 89: {'momentum_buffer': tensor([-2.5511e-04,  2.3855e-04,  3.4670e-04, -6.9263e-04,  1.4533e-05,\n",
            "        -6.5526e-05, -2.4639e-04, -6.6062e-04,  5.3332e-06, -1.2481e-04,\n",
            "         5.6867e-04,  2.2850e-04,  1.1382e-04, -3.0590e-04, -2.6429e-04,\n",
            "        -4.2466e-05,  1.8685e-04,  1.3264e-04,  3.8371e-04, -8.6102e-04,\n",
            "         3.8526e-04, -6.8338e-04,  1.3193e-04,  6.0455e-05,  1.7446e-04,\n",
            "         1.0299e-04, -8.4682e-05, -3.4383e-04, -1.6394e-04,  8.2726e-05,\n",
            "         6.7207e-04, -9.3962e-06, -3.8380e-04, -1.4736e-04, -4.5867e-04,\n",
            "        -3.3976e-04, -5.3107e-04, -2.9461e-04,  3.3442e-05,  1.0595e-04,\n",
            "         1.6822e-04,  3.4158e-05, -3.3539e-04,  1.6943e-04,  2.5798e-04,\n",
            "        -4.1037e-04, -4.6913e-04, -1.5910e-04, -4.0599e-05,  1.1572e-04,\n",
            "         6.1789e-05, -2.8607e-04, -5.8770e-04, -8.5090e-05,  3.1411e-04,\n",
            "         1.9452e-04, -6.2699e-04,  4.5440e-05,  3.5447e-04, -7.0326e-04,\n",
            "        -1.0438e-04,  4.1038e-05, -2.0181e-04, -3.4820e-04, -1.1344e-04,\n",
            "         1.7257e-04, -3.7042e-04,  5.0725e-06, -8.0662e-05,  1.0928e-04,\n",
            "         3.1797e-05,  9.6649e-05,  2.2041e-04, -3.3773e-04,  3.7973e-04,\n",
            "         1.8728e-04, -1.5579e-06,  5.7193e-05, -4.4193e-04, -8.9910e-05,\n",
            "        -2.6963e-04,  5.5345e-05,  4.0187e-04,  2.7130e-04,  4.2010e-04,\n",
            "         2.4676e-04, -6.2481e-05,  4.7001e-04,  3.1073e-04,  1.5520e-04,\n",
            "         2.8708e-04, -3.1947e-04,  2.6349e-04,  2.0961e-04,  3.0890e-04,\n",
            "        -8.0282e-04, -4.5700e-04, -7.4398e-05, -4.4577e-04,  6.9978e-04,\n",
            "        -3.8527e-04,  2.2360e-04,  1.5158e-04, -9.4742e-06, -4.5265e-04,\n",
            "        -6.3925e-05, -2.0300e-04,  1.5679e-04,  3.0787e-04,  1.6409e-05,\n",
            "         9.0294e-04,  5.9944e-05,  3.1942e-04,  1.3400e-04, -9.5248e-05,\n",
            "        -1.4352e-04,  8.0146e-05, -1.0259e-05,  1.9800e-04,  1.0213e-04,\n",
            "         2.6368e-04, -6.1373e-05,  2.3681e-04, -4.2034e-04,  3.7793e-04,\n",
            "         4.2424e-04, -4.4357e-04, -1.7449e-04, -6.3792e-05,  7.7649e-04,\n",
            "         4.9146e-05, -1.9251e-04, -1.1947e-04, -1.0446e-04,  8.2882e-05,\n",
            "        -1.9458e-04, -1.7348e-05,  1.4271e-04,  8.0353e-05, -8.1773e-05,\n",
            "         5.0948e-04,  4.2965e-04,  1.7172e-04,  2.4916e-04, -2.0524e-04,\n",
            "        -2.9909e-04,  4.0711e-05, -4.5913e-04,  4.4252e-04, -7.0861e-04,\n",
            "        -2.7520e-04, -3.0170e-04,  1.7224e-04,  2.9312e-04,  7.9423e-06,\n",
            "        -8.0534e-04,  1.1854e-04,  5.0913e-04,  9.7101e-05, -6.8864e-04,\n",
            "         3.4304e-04, -3.6303e-04, -2.0122e-04,  4.6191e-04,  9.4360e-04,\n",
            "        -2.4045e-04, -4.8780e-04,  1.9188e-04, -4.0432e-05, -5.9826e-05,\n",
            "         3.6847e-04, -9.3001e-04, -1.9928e-04, -1.7403e-04,  4.2654e-06,\n",
            "        -1.1493e-04, -5.9014e-04, -4.6060e-04, -2.4415e-04,  3.0388e-04,\n",
            "        -1.6374e-04,  5.3033e-04, -3.0498e-04, -2.0659e-04,  1.4748e-04,\n",
            "        -2.9671e-04, -5.2309e-05,  2.5582e-04, -4.9376e-04,  2.1141e-04,\n",
            "         2.5155e-04,  7.0061e-06, -2.8745e-04,  2.0025e-04,  8.2991e-06,\n",
            "         3.0662e-05, -1.2243e-05, -5.9251e-04,  1.1452e-05,  2.3472e-04,\n",
            "         5.4706e-04, -2.7138e-04,  1.9492e-04, -4.1624e-04, -3.5006e-04,\n",
            "        -3.3621e-05, -5.1671e-04,  4.2274e-04,  4.8186e-05,  2.1345e-04,\n",
            "         4.2977e-04,  9.8584e-05, -1.3438e-04, -1.4161e-04, -4.7079e-04,\n",
            "         5.9311e-04, -5.7859e-04,  3.5391e-05,  1.9374e-04, -4.6403e-04,\n",
            "         5.8065e-05,  5.5033e-04,  2.4605e-04,  4.0494e-04,  7.3133e-04,\n",
            "         1.3425e-04, -3.0951e-04, -3.0949e-04, -1.2114e-04, -2.6782e-04,\n",
            "        -4.6068e-04, -3.5240e-04, -5.6011e-04, -9.2349e-06,  1.6416e-04,\n",
            "        -8.5966e-05, -5.4455e-04,  6.5497e-04,  7.2138e-05,  5.0622e-06,\n",
            "         4.5849e-04, -1.2173e-04,  3.7665e-04,  7.0299e-05,  7.2863e-05,\n",
            "        -4.0651e-05, -2.8030e-04, -8.4595e-05, -8.8677e-05,  4.6399e-04,\n",
            "        -8.1795e-05, -4.2711e-05, -4.8628e-04, -2.9025e-04, -1.7030e-04,\n",
            "         2.0973e-04])}, 90: {'momentum_buffer': tensor([[[[ 8.6949e-05]],\n",
            "\n",
            "         [[ 4.9906e-05]],\n",
            "\n",
            "         [[ 4.2494e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.8687e-05]],\n",
            "\n",
            "         [[-3.7734e-05]],\n",
            "\n",
            "         [[ 1.7572e-05]]],\n",
            "\n",
            "\n",
            "        [[[-8.8749e-05]],\n",
            "\n",
            "         [[-6.4378e-05]],\n",
            "\n",
            "         [[-2.8642e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8304e-04]],\n",
            "\n",
            "         [[-1.3046e-04]],\n",
            "\n",
            "         [[-4.8288e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7478e-05]],\n",
            "\n",
            "         [[-1.3072e-05]],\n",
            "\n",
            "         [[ 4.1631e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8643e-04]],\n",
            "\n",
            "         [[-4.9141e-05]],\n",
            "\n",
            "         [[-2.0456e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.6392e-04]],\n",
            "\n",
            "         [[ 1.6742e-04]],\n",
            "\n",
            "         [[ 3.7510e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.2698e-05]],\n",
            "\n",
            "         [[-4.9952e-04]],\n",
            "\n",
            "         [[-1.4998e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2895e-04]],\n",
            "\n",
            "         [[-6.5969e-05]],\n",
            "\n",
            "         [[ 2.6810e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3552e-04]],\n",
            "\n",
            "         [[-4.3408e-05]],\n",
            "\n",
            "         [[ 1.8359e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.3797e-04]],\n",
            "\n",
            "         [[-1.4341e-04]],\n",
            "\n",
            "         [[ 4.4085e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1517e-04]],\n",
            "\n",
            "         [[-1.0260e-04]],\n",
            "\n",
            "         [[-2.2936e-04]]]])}, 91: {'momentum_buffer': tensor([0.0008, 0.0008, 0.0012,  ..., 0.0009, 0.0010, 0.0009])}, 92: {'momentum_buffer': tensor([ 1.7556e-04, -2.6165e-04, -8.9841e-06,  ..., -1.0879e-04,\n",
            "         5.3615e-05,  5.0946e-05])}, 93: {'momentum_buffer': tensor([[[[ 2.8886e-04]],\n",
            "\n",
            "         [[ 1.5764e-04]],\n",
            "\n",
            "         [[ 3.4349e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0501e-04]],\n",
            "\n",
            "         [[-4.4920e-05]],\n",
            "\n",
            "         [[ 9.2049e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 5.6335e-05]],\n",
            "\n",
            "         [[ 1.5672e-04]],\n",
            "\n",
            "         [[ 3.1329e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7881e-04]],\n",
            "\n",
            "         [[ 1.2352e-06]],\n",
            "\n",
            "         [[-4.4747e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.2289e-04]],\n",
            "\n",
            "         [[-3.7794e-05]],\n",
            "\n",
            "         [[ 7.8763e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4424e-04]],\n",
            "\n",
            "         [[ 1.0682e-04]],\n",
            "\n",
            "         [[ 2.6441e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.0013e-05]],\n",
            "\n",
            "         [[-5.1539e-05]],\n",
            "\n",
            "         [[ 7.0379e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.6996e-05]],\n",
            "\n",
            "         [[-8.9249e-05]],\n",
            "\n",
            "         [[ 1.7165e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.5717e-05]],\n",
            "\n",
            "         [[ 6.8502e-05]],\n",
            "\n",
            "         [[-9.5847e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0494e-04]],\n",
            "\n",
            "         [[-4.6747e-05]],\n",
            "\n",
            "         [[ 1.6674e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.1795e-05]],\n",
            "\n",
            "         [[-7.2742e-05]],\n",
            "\n",
            "         [[-9.4784e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6044e-04]],\n",
            "\n",
            "         [[-6.5632e-05]],\n",
            "\n",
            "         [[-4.8138e-05]]]])}, 94: {'momentum_buffer': tensor([ 6.8080e-04,  5.6185e-04,  8.4198e-04,  6.3415e-04,  9.0975e-04,\n",
            "         6.0056e-04,  8.9032e-04,  1.2261e-03,  1.0591e-03,  1.2925e-03,\n",
            "         1.0739e-03,  9.3887e-04,  1.4008e-03,  1.0164e-03,  1.1088e-03,\n",
            "         8.0487e-04,  1.5485e-03,  1.1916e-03,  1.0700e-03,  1.1215e-03,\n",
            "         8.0626e-04,  1.0949e-03,  1.2491e-03,  7.8654e-04,  1.3094e-03,\n",
            "         1.0125e-03,  7.9149e-04,  1.1868e-03,  5.6399e-04,  1.6479e-03,\n",
            "         1.4227e-03,  1.3450e-03,  9.3460e-04,  5.2961e-04,  1.5434e-03,\n",
            "         8.7722e-04,  1.4053e-03,  9.0870e-04,  5.5781e-04,  1.0715e-03,\n",
            "         1.0531e-03,  6.2243e-04,  7.4402e-04,  8.0897e-04,  1.1331e-03,\n",
            "         1.4697e-03,  1.3503e-03,  9.2093e-04,  6.9295e-04,  9.2380e-04,\n",
            "         1.1650e-03,  1.1307e-03,  9.2161e-04,  1.3668e-03,  1.0980e-03,\n",
            "         8.6392e-04,  1.0588e-03,  6.4663e-04,  1.4867e-03,  8.8232e-04,\n",
            "         9.9242e-04,  4.2317e-04,  1.6122e-03,  2.6961e-04,  6.5166e-04,\n",
            "         1.2440e-03,  9.4667e-04,  1.5367e-03,  1.0215e-03,  8.7389e-04,\n",
            "         2.9196e-04,  8.9782e-04,  9.7728e-04,  7.3518e-04, -3.4710e-05,\n",
            "         6.2887e-04,  8.0191e-04,  1.0692e-03,  1.3745e-03,  1.2451e-03,\n",
            "         1.5333e-03,  7.1029e-04,  1.2108e-03,  8.1917e-04,  9.2431e-04,\n",
            "         6.2554e-04,  9.1768e-04,  8.3235e-04,  1.2085e-03,  9.9197e-04,\n",
            "         1.2644e-03,  9.8591e-04,  9.0180e-04,  9.6083e-04,  8.0505e-04,\n",
            "         1.0872e-03,  1.0951e-03,  8.8890e-04,  1.0914e-03,  1.1009e-03,\n",
            "         9.4555e-04,  5.7230e-04,  1.3458e-03,  6.7604e-04,  7.0458e-04,\n",
            "         6.0576e-04,  1.0891e-03,  8.5688e-04,  9.1964e-04,  1.4761e-03,\n",
            "         8.4222e-04,  8.5673e-04,  1.1355e-03,  4.3764e-04,  7.3100e-04,\n",
            "         8.5066e-04,  8.6145e-04,  1.6788e-03,  1.3914e-03,  1.0272e-03,\n",
            "         4.3698e-04,  1.2827e-03,  7.2719e-04,  1.5354e-03,  8.3630e-04,\n",
            "         1.0626e-03,  1.3786e-03,  5.9427e-04,  1.1938e-03,  7.5794e-04,\n",
            "         1.1352e-03,  1.1709e-03,  1.0471e-03,  1.1940e-03,  1.0028e-03,\n",
            "         1.3419e-03,  1.0384e-03,  1.1156e-03,  1.2069e-03,  1.5561e-03,\n",
            "         7.1810e-04,  7.4224e-04,  7.4413e-04,  7.7115e-04,  1.6313e-03,\n",
            "         1.1294e-03,  1.1320e-03,  8.2733e-04,  8.2948e-04,  7.3466e-04,\n",
            "         9.5990e-04,  1.0418e-03,  8.7653e-04,  9.7809e-04,  1.1365e-03,\n",
            "         1.0517e-03,  1.0599e-03,  1.0051e-03,  3.5961e-04,  8.8829e-04,\n",
            "         1.5870e-03,  6.1067e-04,  1.4062e-03,  9.3690e-04,  1.2918e-03,\n",
            "         1.2561e-03,  1.4763e-03,  5.3849e-04,  1.8295e-03,  6.5127e-04,\n",
            "         1.3116e-03,  9.4870e-04,  1.0304e-03,  1.4666e-03, -1.9165e-05,\n",
            "         8.1667e-04,  9.8692e-04,  1.8089e-03,  5.8813e-04,  7.4464e-04,\n",
            "         1.0655e-03,  6.0991e-04,  3.2471e-04,  1.8869e-03,  1.0068e-03,\n",
            "         1.1565e-03,  1.0261e-03,  1.1583e-03,  1.2181e-03,  1.1376e-03,\n",
            "         8.0625e-04,  8.8137e-04,  3.7559e-04,  7.8853e-04,  1.4869e-03,\n",
            "         1.4081e-03,  9.4981e-04,  1.1338e-03,  8.9280e-04,  8.0214e-04,\n",
            "         8.5299e-04,  1.0011e-03,  1.2001e-03,  7.7407e-04,  9.5139e-04,\n",
            "         7.3341e-04,  4.4308e-04,  7.4301e-04,  1.4597e-04,  6.9869e-04,\n",
            "         4.6104e-04,  3.2438e-04,  1.1411e-03,  1.0894e-03,  5.1076e-04,\n",
            "         9.5578e-04,  7.1268e-04,  1.0347e-03,  9.3867e-04,  1.0632e-03,\n",
            "         1.3796e-03,  1.2897e-03,  8.4647e-04,  8.8281e-04,  8.1896e-04,\n",
            "         4.5903e-04,  8.1821e-04,  1.3772e-03,  1.2759e-03,  8.4571e-04,\n",
            "         8.5065e-04,  1.7106e-03,  6.4657e-04,  1.4488e-03,  8.7195e-04,\n",
            "         1.3577e-03,  1.2693e-03,  1.3216e-03,  1.2264e-03,  1.4508e-03,\n",
            "         9.5392e-04,  1.0718e-03,  1.7168e-03,  6.4915e-04,  2.9793e-04,\n",
            "         1.2684e-03,  1.4007e-03,  1.5918e-03,  1.0145e-03,  4.1810e-04,\n",
            "         1.2702e-03,  1.1836e-03,  1.4898e-03,  7.6839e-04,  4.7616e-04,\n",
            "         1.1155e-03])}, 95: {'momentum_buffer': tensor([ 1.9850e-04, -2.9205e-04,  1.0036e-04, -2.1072e-04, -1.6441e-04,\n",
            "        -2.1118e-04, -5.3768e-05,  8.9732e-05,  2.6549e-04,  2.1785e-04,\n",
            "        -1.7264e-04, -2.9220e-04,  1.1202e-04,  1.4877e-04,  2.5989e-04,\n",
            "        -2.6847e-04,  4.6250e-04,  1.0993e-04,  1.8712e-04, -1.7706e-04,\n",
            "        -1.1397e-04,  1.6982e-04,  1.1242e-05,  2.6589e-04, -3.7955e-04,\n",
            "         1.1007e-04, -3.2246e-04, -4.5871e-04, -5.0811e-04,  2.3622e-04,\n",
            "         1.8290e-04,  1.2752e-04, -9.0482e-06, -1.7131e-04,  5.4524e-06,\n",
            "         3.7178e-04,  8.9655e-05,  2.4161e-05, -3.4880e-04, -2.9002e-04,\n",
            "        -1.6838e-04, -3.2734e-04, -5.0064e-04,  5.3566e-04, -1.3130e-04,\n",
            "         1.5216e-04,  5.1288e-04, -1.9899e-04, -1.6909e-04, -4.7622e-04,\n",
            "         3.5141e-04, -1.1384e-04, -1.5492e-04,  3.1304e-04, -8.6123e-05,\n",
            "        -4.9789e-05,  1.1091e-04, -2.5039e-05,  6.5959e-04,  1.3728e-04,\n",
            "         4.6005e-05, -4.2067e-04,  4.2700e-05,  2.8768e-04, -2.9972e-04,\n",
            "         4.2036e-04,  3.3994e-04,  6.7123e-04,  4.9821e-04, -4.4985e-04,\n",
            "        -6.0941e-04, -2.2132e-04, -6.1977e-05, -4.5962e-04, -7.3879e-04,\n",
            "         4.6209e-05, -1.7730e-04, -1.2609e-04,  9.1217e-04,  4.1250e-04,\n",
            "         4.7818e-04, -3.0888e-04,  8.0176e-05, -4.6761e-05,  6.3586e-06,\n",
            "         1.0011e-04,  1.1260e-04, -1.4649e-05,  5.1324e-05, -2.1729e-04,\n",
            "        -3.1114e-04, -3.9853e-06,  1.4113e-04, -3.5092e-04, -3.3886e-05,\n",
            "         1.8460e-04,  2.5244e-04,  2.2226e-04, -1.6595e-04, -3.4463e-05,\n",
            "         1.3294e-05, -1.5364e-04,  2.5964e-04, -1.1365e-04, -1.7850e-04,\n",
            "        -2.4477e-04, -1.8653e-04,  4.4679e-04, -1.8200e-04,  4.2607e-04,\n",
            "         1.4617e-04, -3.8891e-04,  6.8070e-05, -4.2229e-04,  9.9444e-06,\n",
            "         6.1369e-05,  7.9732e-05,  4.3512e-04,  5.1090e-04,  1.0724e-05,\n",
            "        -3.0420e-04,  1.8922e-04, -1.5275e-04,  2.3381e-04, -7.8735e-05,\n",
            "        -4.3854e-04, -6.6909e-05, -1.5800e-04,  4.3719e-05, -1.6422e-04,\n",
            "        -7.2241e-05,  1.7246e-04,  1.3968e-04,  1.1746e-04,  2.4981e-04,\n",
            "        -2.3967e-04,  7.6411e-05, -1.0323e-05, -1.5234e-04,  1.7918e-04,\n",
            "         3.4128e-05, -1.7830e-04, -5.4193e-04, -2.0923e-04,  1.4351e-04,\n",
            "        -8.9512e-06,  3.0773e-04, -7.8173e-04,  1.1260e-04, -2.8231e-04,\n",
            "         2.5493e-04,  2.2009e-04,  3.8610e-04,  1.0892e-05, -2.1671e-04,\n",
            "         3.0718e-04,  3.7456e-05, -6.2773e-04, -7.7504e-04, -1.5008e-04,\n",
            "         3.7783e-05, -5.1006e-04, -2.3052e-04, -6.1120e-05,  3.5135e-04,\n",
            "         8.1503e-04,  3.5668e-04,  1.4055e-05,  6.0787e-04, -4.3770e-05,\n",
            "         2.8149e-04,  2.3838e-04, -3.1771e-04,  2.7047e-04, -4.1854e-04,\n",
            "        -1.4771e-04,  1.6105e-04,  6.7247e-04,  4.1189e-05,  3.5523e-05,\n",
            "        -9.0300e-05,  6.6950e-05, -5.1696e-04,  7.6292e-04,  4.2520e-04,\n",
            "         7.3533e-05, -1.3701e-06, -3.3826e-04, -3.4087e-04, -5.4938e-05,\n",
            "        -4.4514e-05, -3.0045e-05, -2.0555e-04, -2.8236e-04,  8.8138e-05,\n",
            "         2.3185e-06, -2.4204e-04,  2.5561e-04, -2.7961e-04,  4.1914e-04,\n",
            "        -1.7079e-04,  1.4644e-04, -1.3655e-04, -1.3796e-04, -1.0877e-05,\n",
            "        -3.7059e-04, -1.7910e-05,  3.4540e-06, -1.2791e-04, -2.3051e-04,\n",
            "         3.7474e-05, -1.0257e-04,  3.1131e-04,  1.3362e-04,  1.9445e-05,\n",
            "         2.1449e-04, -2.2807e-06, -9.9311e-05, -1.8103e-04, -1.1766e-05,\n",
            "         2.3389e-04,  7.4127e-04, -4.6665e-04, -2.4983e-05, -3.3563e-04,\n",
            "        -5.1501e-05, -3.8945e-04, -1.9744e-04,  4.6391e-04,  2.6651e-04,\n",
            "        -2.8201e-04,  1.5438e-04, -3.8775e-04,  2.8832e-04,  3.0137e-04,\n",
            "         6.8554e-04,  3.8011e-04,  3.0862e-04, -6.7969e-05,  4.5129e-04,\n",
            "        -5.0929e-04, -1.7068e-04,  2.9552e-04, -1.7370e-04, -5.5190e-04,\n",
            "         1.6038e-04,  3.4515e-04,  6.0693e-04, -2.4763e-04, -5.5657e-04,\n",
            "         2.0509e-04,  1.0763e-04,  4.3035e-04,  3.7382e-04,  1.9853e-05,\n",
            "        -4.2389e-07])}, 96: {'momentum_buffer': tensor([[[[-2.7825e-04, -6.3776e-05, -2.0472e-04],\n",
            "          [ 1.8642e-05, -1.4958e-04,  2.6788e-05],\n",
            "          [ 5.0523e-05,  1.7253e-04, -1.4116e-04]],\n",
            "\n",
            "         [[-8.0848e-05, -1.6945e-05, -6.9313e-05],\n",
            "          [ 8.9850e-05, -1.7971e-05, -8.9036e-06],\n",
            "          [-2.3832e-05,  4.3413e-06,  1.0368e-04]],\n",
            "\n",
            "         [[ 9.3770e-05,  7.0157e-05,  1.9183e-04],\n",
            "          [-1.3230e-04,  1.3486e-04,  5.8848e-05],\n",
            "          [ 1.9600e-05,  1.2237e-04,  1.0431e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1569e-04,  1.6708e-04,  9.2973e-05],\n",
            "          [ 1.5085e-04,  9.0252e-05,  8.9206e-05],\n",
            "          [ 5.6732e-05,  1.6933e-04,  1.2778e-05]],\n",
            "\n",
            "         [[ 1.9077e-05,  5.9166e-05,  8.1260e-06],\n",
            "          [-1.6208e-04, -2.0023e-04, -1.7408e-05],\n",
            "          [-2.5700e-04, -6.0678e-05,  2.0074e-04]],\n",
            "\n",
            "         [[ 9.5779e-05, -1.7137e-05,  6.1116e-05],\n",
            "          [ 1.0891e-04, -3.4508e-05,  9.6395e-05],\n",
            "          [ 2.3484e-04,  1.8067e-04,  9.0959e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.2847e-04, -3.9050e-04, -1.1997e-04],\n",
            "          [-1.3293e-04, -4.4495e-04, -1.3178e-04],\n",
            "          [-5.5350e-04, -2.8560e-04, -2.2938e-04]],\n",
            "\n",
            "         [[-3.4965e-04, -5.1583e-04, -4.4697e-04],\n",
            "          [-2.8406e-04, -3.0869e-04, -3.0390e-04],\n",
            "          [-1.4726e-04, -5.2117e-04, -2.6783e-04]],\n",
            "\n",
            "         [[-2.8407e-05, -4.1860e-05, -9.0682e-05],\n",
            "          [ 1.9657e-04, -2.1620e-04, -3.2287e-04],\n",
            "          [ 5.3115e-05,  5.6379e-05, -3.6191e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.0242e-04, -4.1360e-04, -2.9950e-04],\n",
            "          [-4.9072e-04, -6.2258e-04, -3.3126e-04],\n",
            "          [-5.3613e-04, -5.5846e-04, -7.0924e-04]],\n",
            "\n",
            "         [[-8.7949e-05, -1.3942e-04,  2.1091e-04],\n",
            "          [-1.1844e-04, -5.0158e-04, -5.7254e-05],\n",
            "          [-1.5093e-04, -3.3788e-04, -8.6876e-05]],\n",
            "\n",
            "         [[-8.1029e-05,  3.7436e-05,  6.2398e-05],\n",
            "          [-3.3290e-04,  1.2870e-04, -3.1711e-04],\n",
            "          [-1.8439e-04, -3.0408e-04, -2.8322e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.0627e-04, -8.6285e-05,  2.4401e-04],\n",
            "          [-1.9575e-04,  1.0405e-04,  1.7525e-04],\n",
            "          [ 1.3719e-04, -6.0487e-06, -1.0682e-04]],\n",
            "\n",
            "         [[-2.2870e-04,  5.9792e-05, -3.5908e-04],\n",
            "          [ 3.4292e-04,  1.0457e-04,  2.8779e-04],\n",
            "          [ 1.0805e-04,  4.3463e-04,  1.9041e-04]],\n",
            "\n",
            "         [[-1.4348e-04, -7.6394e-05,  9.6408e-05],\n",
            "          [-9.6583e-05, -9.6130e-05,  9.7722e-05],\n",
            "          [ 4.2715e-05,  2.1448e-04,  3.4297e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3017e-04,  2.8713e-04, -2.4128e-05],\n",
            "          [ 2.2309e-04,  9.2461e-05,  4.0401e-04],\n",
            "          [-1.5837e-04,  3.7471e-05, -2.3986e-04]],\n",
            "\n",
            "         [[ 1.8008e-04,  2.6038e-04,  1.0183e-04],\n",
            "          [ 3.8996e-04,  1.7233e-04, -1.0443e-05],\n",
            "          [ 2.7804e-04, -7.7342e-05,  5.7978e-05]],\n",
            "\n",
            "         [[ 8.7560e-05, -1.6871e-05, -3.2356e-04],\n",
            "          [-7.0746e-05,  7.5071e-05, -3.7834e-07],\n",
            "          [-2.6417e-06, -4.9523e-05,  9.5566e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-8.8457e-06,  1.7455e-04,  5.8341e-05],\n",
            "          [ 6.4825e-05, -4.9328e-04, -3.7135e-04],\n",
            "          [-4.5042e-04, -3.0239e-04, -1.9020e-04]],\n",
            "\n",
            "         [[-1.2116e-04, -2.3258e-04,  2.2942e-04],\n",
            "          [-5.9233e-04, -3.9238e-04,  1.4820e-04],\n",
            "          [-2.2241e-04, -5.4002e-04, -4.1757e-04]],\n",
            "\n",
            "         [[ 2.3201e-04,  2.1190e-04, -4.6791e-05],\n",
            "          [ 3.0726e-04, -3.2182e-06, -2.5730e-04],\n",
            "          [ 2.4253e-04, -2.2780e-05, -1.3231e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.1605e-05, -2.9626e-04, -3.4782e-04],\n",
            "          [-6.0900e-04, -6.2917e-04, -7.0924e-04],\n",
            "          [-3.6897e-04, -4.3096e-04, -7.3400e-04]],\n",
            "\n",
            "         [[ 2.3600e-04, -3.5609e-05, -3.0593e-05],\n",
            "          [-1.4038e-04, -1.3191e-04, -6.2512e-04],\n",
            "          [-3.6835e-04,  2.7384e-04, -1.8571e-04]],\n",
            "\n",
            "         [[ 5.0710e-04,  1.7779e-04,  9.2932e-05],\n",
            "          [ 1.9782e-04,  2.1327e-04, -3.7842e-06],\n",
            "          [ 5.4679e-05,  1.9200e-04,  1.3618e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4499e-05, -3.6369e-04, -1.8034e-04],\n",
            "          [-1.4593e-04, -2.1168e-06, -3.8668e-05],\n",
            "          [-2.3232e-04, -3.1000e-04, -2.8616e-04]],\n",
            "\n",
            "         [[-2.4036e-05, -4.0037e-05,  3.7857e-04],\n",
            "          [-2.7517e-04, -2.2502e-04, -3.5773e-05],\n",
            "          [-5.5503e-05, -4.5368e-04, -1.8310e-04]],\n",
            "\n",
            "         [[ 5.0269e-05,  3.1647e-04,  4.8336e-04],\n",
            "          [ 4.3967e-05,  1.3173e-04,  3.3811e-04],\n",
            "          [-2.1803e-04, -1.8477e-04, -2.6773e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0686e-05,  8.4715e-05,  2.3238e-04],\n",
            "          [-1.9309e-04, -4.7586e-05, -9.6549e-05],\n",
            "          [-1.9233e-04, -3.2783e-04, -7.3443e-05]],\n",
            "\n",
            "         [[ 1.1207e-04,  1.1847e-04,  3.7923e-05],\n",
            "          [ 1.0983e-04,  7.8347e-05, -2.5841e-04],\n",
            "          [-2.0507e-04, -9.7268e-06,  1.3948e-04]],\n",
            "\n",
            "         [[ 6.4515e-06,  3.1304e-04,  6.1005e-05],\n",
            "          [ 3.2290e-04,  1.6240e-04,  2.8561e-04],\n",
            "          [ 1.9969e-04, -1.8329e-04, -2.6134e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8567e-05,  1.9274e-04,  9.5142e-05],\n",
            "          [ 1.1048e-04,  2.3376e-04, -1.2497e-04],\n",
            "          [-2.9300e-05,  2.5157e-04,  1.5152e-04]],\n",
            "\n",
            "         [[ 2.3856e-04,  1.4618e-04,  2.6689e-04],\n",
            "          [ 5.3420e-05,  3.8615e-05, -1.1687e-04],\n",
            "          [ 2.2197e-04,  1.9693e-04,  1.4891e-04]],\n",
            "\n",
            "         [[ 2.9428e-05, -1.4842e-05,  2.4635e-04],\n",
            "          [-1.5088e-04, -3.3963e-05,  4.2576e-05],\n",
            "          [ 3.2902e-04,  3.9598e-05, -1.4805e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9110e-04,  1.7339e-04, -1.9119e-05],\n",
            "          [-2.1958e-04,  3.2958e-04,  8.4632e-05],\n",
            "          [ 2.5847e-04,  3.2383e-04,  4.3260e-04]],\n",
            "\n",
            "         [[ 3.4519e-04,  3.1406e-04, -2.3288e-04],\n",
            "          [ 2.1358e-04, -2.6313e-05, -2.2357e-04],\n",
            "          [-2.1152e-04,  3.6031e-04,  3.1548e-04]],\n",
            "\n",
            "         [[ 1.2838e-04,  2.6686e-04,  2.4386e-04],\n",
            "          [ 3.4299e-04,  9.1679e-05,  3.2014e-05],\n",
            "          [ 1.4915e-04,  8.0110e-05, -3.2998e-05]]]])}, 97: {'momentum_buffer': tensor([0.0013, 0.0004, 0.0014, 0.0010, 0.0011, 0.0006, 0.0008, 0.0009, 0.0010,\n",
            "        0.0010, 0.0013, 0.0009, 0.0009, 0.0014, 0.0013, 0.0013, 0.0014, 0.0006,\n",
            "        0.0003, 0.0013, 0.0011, 0.0008, 0.0008, 0.0007, 0.0012, 0.0011, 0.0014,\n",
            "        0.0009, 0.0012, 0.0012, 0.0012, 0.0013, 0.0011, 0.0009, 0.0013, 0.0008,\n",
            "        0.0008, 0.0006, 0.0011, 0.0009, 0.0006, 0.0011, 0.0010, 0.0008, 0.0010,\n",
            "        0.0011, 0.0009, 0.0009, 0.0012, 0.0011, 0.0012, 0.0009, 0.0011, 0.0005,\n",
            "        0.0006, 0.0010, 0.0021, 0.0012, 0.0012, 0.0014, 0.0011, 0.0013, 0.0012,\n",
            "        0.0010, 0.0012, 0.0011, 0.0003, 0.0012, 0.0014, 0.0009, 0.0009, 0.0009,\n",
            "        0.0011, 0.0007, 0.0012, 0.0009, 0.0016, 0.0007, 0.0008, 0.0011, 0.0010,\n",
            "        0.0011, 0.0010, 0.0007, 0.0012, 0.0013, 0.0008, 0.0012, 0.0008, 0.0006,\n",
            "        0.0013, 0.0014, 0.0007, 0.0010, 0.0011, 0.0015, 0.0013, 0.0014, 0.0012,\n",
            "        0.0013, 0.0011, 0.0013, 0.0008, 0.0010, 0.0009, 0.0006, 0.0009, 0.0015,\n",
            "        0.0014, 0.0010, 0.0007, 0.0009, 0.0013, 0.0006, 0.0011, 0.0009, 0.0007,\n",
            "        0.0006, 0.0007, 0.0015, 0.0008, 0.0010, 0.0014, 0.0011, 0.0008, 0.0004,\n",
            "        0.0010, 0.0007, 0.0013, 0.0013, 0.0012, 0.0012, 0.0011, 0.0011, 0.0010,\n",
            "        0.0002, 0.0012, 0.0010, 0.0009, 0.0008, 0.0005, 0.0010, 0.0015, 0.0008,\n",
            "        0.0011, 0.0008, 0.0008, 0.0009, 0.0010, 0.0009, 0.0009, 0.0008, 0.0008,\n",
            "        0.0009, 0.0012, 0.0010, 0.0010, 0.0003, 0.0013, 0.0007, 0.0010, 0.0008,\n",
            "        0.0010, 0.0013, 0.0006, 0.0006, 0.0010, 0.0009, 0.0010, 0.0011, 0.0011,\n",
            "        0.0007, 0.0008, 0.0008, 0.0013, 0.0011, 0.0011, 0.0011, 0.0010, 0.0007,\n",
            "        0.0013, 0.0009, 0.0011, 0.0013, 0.0011, 0.0008, 0.0005, 0.0011, 0.0013,\n",
            "        0.0008, 0.0007, 0.0009, 0.0008, 0.0006, 0.0007, 0.0009, 0.0011, 0.0013,\n",
            "        0.0013, 0.0007, 0.0012, 0.0009, 0.0010, 0.0008, 0.0012, 0.0016, 0.0009,\n",
            "        0.0011, 0.0012, 0.0003, 0.0007, 0.0013, 0.0011, 0.0014, 0.0007, 0.0012,\n",
            "        0.0015, 0.0006, 0.0007, 0.0010, 0.0008, 0.0009, 0.0009, 0.0011, 0.0009,\n",
            "        0.0011, 0.0007, 0.0009, 0.0006, 0.0010, 0.0015, 0.0010, 0.0008, 0.0010,\n",
            "        0.0009, 0.0007, 0.0009, 0.0010, 0.0011, 0.0009, 0.0006, 0.0010, 0.0011,\n",
            "        0.0011, 0.0014, 0.0011, 0.0010, 0.0011, 0.0009, 0.0007, 0.0008, 0.0012,\n",
            "        0.0008, 0.0004, 0.0011, 0.0012])}, 98: {'momentum_buffer': tensor([-8.7404e-05, -3.6941e-04, -6.3843e-05, -8.0920e-05, -7.4820e-05,\n",
            "        -4.5247e-05, -2.7965e-04, -3.5805e-04,  8.7197e-06, -8.4628e-05,\n",
            "         1.4931e-04, -9.0490e-05, -5.4880e-05,  6.3256e-05,  3.2610e-04,\n",
            "         3.1647e-04,  4.5257e-04,  5.0222e-05, -5.2584e-04,  2.7218e-04,\n",
            "         2.3991e-04, -1.1214e-04, -2.5531e-04,  3.2086e-05,  3.5914e-04,\n",
            "         2.5465e-05,  4.3414e-04, -1.5749e-04,  3.6462e-05,  3.6331e-04,\n",
            "        -9.8673e-05,  3.4828e-04,  3.8314e-04, -1.4618e-04,  5.8969e-05,\n",
            "         1.7771e-04,  1.3364e-04, -9.3349e-05,  2.7125e-05, -1.1044e-04,\n",
            "        -1.5282e-04,  5.4714e-05,  1.0184e-04,  9.9841e-05, -1.1666e-04,\n",
            "         1.5301e-04,  1.6406e-05, -1.3445e-04, -6.4489e-05, -1.3219e-04,\n",
            "         2.6187e-04, -3.1156e-04, -1.1910e-04, -2.9995e-04, -1.0271e-04,\n",
            "         4.9071e-05,  5.1199e-04, -6.7557e-05,  1.8778e-04,  3.5371e-04,\n",
            "        -1.3404e-04,  3.4614e-04, -1.0469e-04,  4.8749e-05,  5.6440e-04,\n",
            "         1.4864e-04, -2.5172e-04, -1.1079e-05,  1.5208e-04, -4.3146e-04,\n",
            "        -1.0031e-05, -4.2660e-04,  4.9068e-05, -8.3483e-05, -7.7901e-05,\n",
            "        -2.5400e-04,  6.0787e-04,  1.4170e-05,  3.5030e-05,  1.4980e-04,\n",
            "        -7.2785e-05,  1.4236e-05, -1.2106e-04, -4.3187e-04, -5.1734e-05,\n",
            "        -1.1712e-05,  9.1561e-06,  1.6447e-04, -2.6571e-04, -4.9601e-04,\n",
            "         1.6486e-04,  2.8936e-04, -1.0943e-04, -2.3576e-04,  2.9740e-04,\n",
            "         1.0972e-04,  5.2869e-05,  4.9457e-05,  7.7827e-04,  2.0783e-05,\n",
            "        -7.1104e-05, -1.7439e-04,  1.4926e-04,  2.1169e-05,  1.9123e-04,\n",
            "        -4.8248e-04,  1.2350e-04,  2.9779e-04,  3.3174e-05, -1.7313e-04,\n",
            "        -1.4728e-04, -3.5645e-05,  4.9060e-04,  1.0292e-04,  1.7363e-04,\n",
            "        -4.9404e-04,  1.8903e-04, -1.5245e-04, -4.6080e-04,  4.0293e-04,\n",
            "        -7.4338e-05,  2.1651e-04,  2.5811e-04,  6.4863e-06,  5.2538e-05,\n",
            "        -5.1460e-04, -2.6913e-04, -5.3622e-05, -3.1832e-04,  3.4748e-04,\n",
            "         1.4714e-04, -2.3347e-05, -7.8319e-05,  4.5051e-04, -1.0860e-04,\n",
            "        -5.2806e-04,  4.0879e-04, -1.7824e-04, -1.6518e-04, -4.8258e-04,\n",
            "        -3.2495e-04, -1.4765e-04,  4.1581e-04, -3.0288e-04,  1.1213e-05,\n",
            "        -4.6482e-04, -2.5961e-04, -7.9160e-05, -2.6342e-05, -2.1438e-04,\n",
            "        -6.4331e-05,  6.9562e-05, -3.0077e-04, -4.0479e-04, -2.8284e-05,\n",
            "         6.9759e-05, -2.1595e-04, -3.8640e-05,  3.7245e-04, -3.3177e-04,\n",
            "         7.5403e-06, -9.8433e-05, -6.4019e-05, -1.3115e-04, -1.3599e-04,\n",
            "        -4.8682e-04,  2.0447e-04, -2.7037e-04,  4.3515e-05,  2.6363e-05,\n",
            "         4.8830e-06, -2.8928e-04, -4.0344e-05, -3.6495e-04,  1.2467e-04,\n",
            "         8.6127e-05,  8.5115e-05,  1.4644e-04,  4.7841e-05, -4.2450e-04,\n",
            "        -2.4610e-05,  2.1471e-04,  1.2005e-04, -3.0343e-04,  2.2005e-04,\n",
            "        -2.1382e-04, -1.7415e-04,  4.5069e-05,  2.6524e-04, -3.7400e-04,\n",
            "        -3.0245e-04, -1.5635e-04,  1.2576e-04, -2.9262e-04, -2.1690e-04,\n",
            "        -2.4614e-04, -5.2808e-04, -5.5031e-06, -2.0751e-04, -1.1197e-04,\n",
            "        -1.6224e-04, -3.5644e-04, -1.1183e-04, -1.7331e-04,  3.2621e-04,\n",
            "         2.8038e-04, -1.1554e-04,  8.7431e-05,  1.3190e-04, -7.0734e-04,\n",
            "         3.5918e-04, -2.8044e-06,  2.4269e-04, -1.5769e-04, -3.7893e-05,\n",
            "        -1.5467e-04,  1.2850e-04, -5.2392e-04, -2.9867e-04, -3.8932e-05,\n",
            "        -7.1114e-06, -7.0521e-05,  2.6602e-04,  3.8037e-04,  1.5531e-05,\n",
            "         1.3205e-04, -3.7271e-04, -3.1712e-04, -5.1500e-04, -1.2517e-04,\n",
            "        -2.2931e-04, -2.0569e-04, -2.2568e-04, -1.0067e-04,  2.7549e-04,\n",
            "        -3.9301e-04, -2.4681e-04, -2.1812e-04,  8.0778e-05, -2.8319e-04,\n",
            "         1.4067e-04, -2.2146e-04,  2.6971e-04, -6.4477e-05,  3.6236e-04,\n",
            "        -3.3989e-04, -5.5189e-05,  1.4159e-04, -2.7665e-04, -1.8640e-04,\n",
            "        -1.6761e-04,  1.6348e-04, -4.6518e-04, -3.3623e-04, -6.6150e-05,\n",
            "        -2.0613e-04])}, 99: {'momentum_buffer': tensor([[[[ 7.0520e-05]],\n",
            "\n",
            "         [[ 4.9657e-05]],\n",
            "\n",
            "         [[ 1.1723e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0743e-04]],\n",
            "\n",
            "         [[-1.3073e-04]],\n",
            "\n",
            "         [[-5.5850e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.2582e-04]],\n",
            "\n",
            "         [[-2.0398e-04]],\n",
            "\n",
            "         [[ 1.2005e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1327e-04]],\n",
            "\n",
            "         [[ 1.1128e-04]],\n",
            "\n",
            "         [[ 1.8891e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9745e-06]],\n",
            "\n",
            "         [[ 2.0267e-04]],\n",
            "\n",
            "         [[-2.3881e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9664e-05]],\n",
            "\n",
            "         [[-5.2456e-05]],\n",
            "\n",
            "         [[ 6.4184e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 6.5188e-05]],\n",
            "\n",
            "         [[-9.6360e-05]],\n",
            "\n",
            "         [[ 1.4893e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7272e-04]],\n",
            "\n",
            "         [[-4.2848e-05]],\n",
            "\n",
            "         [[-8.3724e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.1038e-05]],\n",
            "\n",
            "         [[-1.4663e-04]],\n",
            "\n",
            "         [[ 4.3975e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.4805e-04]],\n",
            "\n",
            "         [[ 2.1973e-04]],\n",
            "\n",
            "         [[ 3.6316e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.9225e-04]],\n",
            "\n",
            "         [[-6.0677e-05]],\n",
            "\n",
            "         [[-1.4466e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8117e-04]],\n",
            "\n",
            "         [[ 3.5802e-05]],\n",
            "\n",
            "         [[-4.0489e-04]]]])}, 100: {'momentum_buffer': tensor([0.0010, 0.0009, 0.0009,  ..., 0.0009, 0.0009, 0.0010])}, 101: {'momentum_buffer': tensor([ 9.3026e-05, -1.6557e-04, -2.0686e-04,  ..., -1.8826e-05,\n",
            "        -3.1467e-06,  1.1218e-04])}, 102: {'momentum_buffer': tensor([[[[ 2.5849e-04]],\n",
            "\n",
            "         [[ 9.8583e-05]],\n",
            "\n",
            "         [[ 1.5738e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1622e-04]],\n",
            "\n",
            "         [[-1.1970e-04]],\n",
            "\n",
            "         [[-3.4890e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.3332e-04]],\n",
            "\n",
            "         [[ 1.3063e-04]],\n",
            "\n",
            "         [[-3.4249e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9533e-04]],\n",
            "\n",
            "         [[ 7.2857e-05]],\n",
            "\n",
            "         [[-7.6495e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.5136e-04]],\n",
            "\n",
            "         [[ 1.6319e-04]],\n",
            "\n",
            "         [[-2.5944e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9401e-05]],\n",
            "\n",
            "         [[-1.2356e-04]],\n",
            "\n",
            "         [[ 8.0263e-07]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1043e-04]],\n",
            "\n",
            "         [[ 1.8462e-05]],\n",
            "\n",
            "         [[ 1.1937e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4510e-05]],\n",
            "\n",
            "         [[-2.2361e-05]],\n",
            "\n",
            "         [[ 8.8539e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3739e-05]],\n",
            "\n",
            "         [[ 8.1062e-05]],\n",
            "\n",
            "         [[ 1.3339e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2384e-04]],\n",
            "\n",
            "         [[ 1.0085e-04]],\n",
            "\n",
            "         [[-5.0982e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.4559e-04]],\n",
            "\n",
            "         [[ 1.0043e-04]],\n",
            "\n",
            "         [[ 2.4429e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.1012e-04]],\n",
            "\n",
            "         [[-1.6377e-04]],\n",
            "\n",
            "         [[-2.4892e-04]]]])}, 103: {'momentum_buffer': tensor([0.0013, 0.0014, 0.0005, 0.0014, 0.0010, 0.0011, 0.0005, 0.0012, 0.0008,\n",
            "        0.0010, 0.0010, 0.0012, 0.0012, 0.0011, 0.0010, 0.0015, 0.0010, 0.0011,\n",
            "        0.0015, 0.0008, 0.0006, 0.0008, 0.0006, 0.0009, 0.0008, 0.0007, 0.0009,\n",
            "        0.0009, 0.0012, 0.0011, 0.0009, 0.0016, 0.0014, 0.0007, 0.0009, 0.0005,\n",
            "        0.0010, 0.0012, 0.0008, 0.0008, 0.0012, 0.0010, 0.0011, 0.0009, 0.0010,\n",
            "        0.0008, 0.0010, 0.0011, 0.0011, 0.0009, 0.0010, 0.0008, 0.0011, 0.0016,\n",
            "        0.0014, 0.0011, 0.0008, 0.0013, 0.0009, 0.0008, 0.0009, 0.0009, 0.0007,\n",
            "        0.0009, 0.0012, 0.0010, 0.0011, 0.0009, 0.0010, 0.0008, 0.0010, 0.0008,\n",
            "        0.0015, 0.0010, 0.0008, 0.0006, 0.0010, 0.0009, 0.0010, 0.0014, 0.0010,\n",
            "        0.0010, 0.0012, 0.0014, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010, 0.0011,\n",
            "        0.0009, 0.0009, 0.0012, 0.0013, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009,\n",
            "        0.0007, 0.0011, 0.0006, 0.0011, 0.0010, 0.0009, 0.0009, 0.0008, 0.0009,\n",
            "        0.0006, 0.0010, 0.0012, 0.0008, 0.0011, 0.0012, 0.0011, 0.0007, 0.0016,\n",
            "        0.0012, 0.0013, 0.0011, 0.0011, 0.0012, 0.0009, 0.0010, 0.0008, 0.0009,\n",
            "        0.0006, 0.0008, 0.0012, 0.0012, 0.0005, 0.0004, 0.0011, 0.0010, 0.0008,\n",
            "        0.0012, 0.0009, 0.0005, 0.0007, 0.0010, 0.0008, 0.0010, 0.0007, 0.0008,\n",
            "        0.0010, 0.0010, 0.0011, 0.0012, 0.0014, 0.0006, 0.0008, 0.0012, 0.0008,\n",
            "        0.0010, 0.0008, 0.0013, 0.0011, 0.0011, 0.0008, 0.0008, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0005, 0.0008, 0.0009, 0.0009, 0.0017, 0.0008, 0.0009,\n",
            "        0.0011, 0.0010, 0.0010, 0.0013, 0.0015, 0.0009, 0.0010, 0.0011, 0.0009,\n",
            "        0.0008, 0.0011, 0.0012, 0.0009, 0.0012, 0.0010, 0.0012, 0.0011, 0.0010,\n",
            "        0.0012, 0.0008, 0.0011, 0.0009, 0.0012, 0.0008, 0.0013, 0.0011, 0.0009,\n",
            "        0.0009, 0.0007, 0.0012, 0.0010, 0.0010, 0.0008, 0.0006, 0.0007, 0.0008,\n",
            "        0.0015, 0.0011, 0.0005, 0.0011, 0.0006, 0.0007, 0.0008, 0.0009, 0.0011,\n",
            "        0.0011, 0.0013, 0.0011, 0.0012, 0.0007, 0.0009, 0.0009, 0.0010, 0.0010,\n",
            "        0.0009, 0.0012, 0.0013, 0.0013, 0.0008, 0.0012, 0.0012, 0.0014, 0.0011,\n",
            "        0.0011, 0.0009, 0.0009, 0.0011, 0.0009, 0.0014, 0.0012, 0.0012, 0.0008,\n",
            "        0.0007, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010,\n",
            "        0.0006, 0.0008, 0.0011, 0.0010])}, 104: {'momentum_buffer': tensor([-9.4321e-05, -3.8824e-05, -4.0017e-04,  5.5631e-04,  5.5632e-05,\n",
            "         1.0802e-04, -5.9484e-04,  1.5258e-04, -2.5639e-04, -5.7321e-05,\n",
            "        -7.6305e-05,  1.7362e-04, -6.9787e-05, -3.2170e-04,  1.2684e-04,\n",
            "         6.2730e-04, -4.4323e-05,  3.4609e-04,  3.6021e-04, -2.5967e-04,\n",
            "        -3.1845e-04,  2.5368e-05, -3.4432e-04, -2.4355e-04, -2.4558e-04,\n",
            "        -2.8599e-05, -3.0948e-04, -2.6587e-05, -1.9848e-04, -3.1661e-05,\n",
            "         5.2149e-05,  1.9859e-04,  4.8382e-04, -2.9436e-04, -2.8769e-04,\n",
            "        -4.0738e-04, -4.3475e-07,  8.7510e-05, -6.0044e-05,  5.7586e-05,\n",
            "         2.0229e-05,  1.8734e-04, -1.0559e-04, -1.9890e-04, -1.0557e-04,\n",
            "        -1.7714e-04, -1.9956e-04,  4.4657e-04,  1.5403e-04, -7.2632e-05,\n",
            "        -2.5233e-04, -2.0710e-04,  1.6315e-04,  1.9177e-04,  4.0686e-04,\n",
            "         2.0164e-05,  2.2788e-05, -3.7555e-06, -2.0079e-04,  5.4065e-05,\n",
            "        -8.0079e-05,  4.6417e-05, -1.7734e-04, -2.0425e-04,  1.5364e-04,\n",
            "         9.8062e-05,  1.8796e-04, -3.9062e-05, -2.2544e-05, -6.9629e-05,\n",
            "        -2.4381e-04, -1.4722e-04,  1.3305e-04,  7.5539e-05, -3.1607e-04,\n",
            "        -2.4727e-04, -2.3069e-04,  1.4481e-04,  2.1309e-05,  7.3534e-05,\n",
            "        -3.4433e-04, -3.6261e-04,  1.3815e-04,  4.1084e-04, -1.4976e-05,\n",
            "        -3.3725e-04,  1.7347e-04,  1.1667e-04, -1.7402e-04,  2.1198e-04,\n",
            "         2.2086e-05,  2.1687e-04,  8.5185e-05,  2.4755e-04, -2.6250e-05,\n",
            "         7.2745e-06, -2.4378e-04, -7.3041e-05, -9.0362e-05, -2.1220e-04,\n",
            "         2.6948e-04, -2.7953e-04,  2.9955e-05,  2.5533e-04,  1.6427e-04,\n",
            "        -4.9587e-04, -3.1420e-04,  1.9766e-04, -3.7125e-04,  5.2762e-05,\n",
            "        -2.3215e-04, -2.1324e-04,  3.4282e-04, -1.1909e-04,  1.8819e-04,\n",
            "        -2.2913e-04,  9.3688e-05,  2.9879e-04,  9.4921e-05,  2.1682e-04,\n",
            "         4.7903e-05, -3.6045e-05,  1.3792e-05,  2.7966e-04, -1.3681e-04,\n",
            "         8.6567e-05, -3.7513e-04, -1.1039e-04,  2.4980e-04, -1.8344e-05,\n",
            "        -2.9894e-04, -2.6777e-04, -6.8009e-05, -1.3174e-04, -3.2320e-04,\n",
            "         3.8270e-04, -1.6328e-04, -2.6729e-04, -9.0857e-05,  7.2614e-05,\n",
            "         2.9124e-05,  2.5327e-04, -1.8507e-04, -1.1612e-04, -1.1404e-04,\n",
            "        -2.1288e-04,  2.4457e-04,  1.3047e-04, -1.8444e-05, -1.6378e-04,\n",
            "        -3.8120e-04,  2.3581e-04, -3.5439e-05, -3.4736e-04,  3.4572e-04,\n",
            "        -6.2180e-05,  1.4969e-04, -7.7070e-05, -3.5143e-04, -2.2996e-04,\n",
            "        -3.0941e-04,  4.9578e-05,  4.7452e-05, -1.7890e-05, -2.1610e-04,\n",
            "        -1.4625e-04, -3.6487e-04,  2.3609e-04, -8.5610e-05, -1.0441e-04,\n",
            "        -1.4811e-04,  1.2017e-04, -5.6261e-05,  3.2505e-04, -5.3948e-06,\n",
            "         8.6080e-05, -3.5572e-05, -4.1410e-04,  1.6594e-05, -8.2641e-05,\n",
            "         5.9425e-05, -3.9489e-05,  2.9717e-05, -2.4805e-04,  1.5001e-04,\n",
            "         1.1463e-05,  1.6974e-04,  9.4544e-05,  3.2725e-04,  8.0825e-05,\n",
            "        -2.5803e-04,  2.9079e-04, -4.6939e-05,  3.6668e-04, -9.7063e-05,\n",
            "         4.5086e-04,  1.1299e-04, -1.7288e-04, -5.0420e-05, -4.2600e-04,\n",
            "         1.9123e-04,  5.6634e-05,  3.0857e-04, -3.9050e-05, -2.7169e-04,\n",
            "        -1.6731e-04, -1.8128e-04,  3.0725e-04,  3.4672e-04, -2.3773e-04,\n",
            "         2.3841e-04, -2.5094e-04, -1.7069e-04,  1.0138e-04,  7.3686e-05,\n",
            "         6.4733e-05, -1.9810e-04,  4.8094e-04, -1.1642e-05, -6.4585e-05,\n",
            "        -3.5942e-04,  6.7182e-05,  1.6231e-05,  5.2135e-06, -1.3529e-05,\n",
            "         6.9838e-05,  9.3551e-05,  1.8019e-04,  7.7103e-05, -5.1592e-04,\n",
            "         3.3100e-04,  2.6988e-04,  4.2658e-04, -7.7358e-05, -1.5676e-05,\n",
            "        -1.9074e-04, -8.9451e-07,  2.0853e-04, -2.0972e-04,  3.8823e-04,\n",
            "        -8.3461e-07,  1.4561e-04, -2.8057e-04,  5.3704e-05,  1.5557e-04,\n",
            "        -1.8519e-04,  1.3889e-04,  2.5407e-04,  7.6073e-05, -3.0942e-05,\n",
            "        -2.4571e-04, -5.9520e-05, -2.2560e-04,  1.2060e-04,  1.7881e-04,\n",
            "        -1.2650e-04])}, 105: {'momentum_buffer': tensor([[[[-8.8158e-05, -1.3698e-04, -1.1862e-04],\n",
            "          [ 5.7992e-05, -1.1593e-04, -2.5065e-04],\n",
            "          [ 4.0182e-05, -9.4488e-05, -1.2012e-04]],\n",
            "\n",
            "         [[ 7.0922e-05,  1.6825e-04,  8.9220e-05],\n",
            "          [ 1.0152e-05,  1.1038e-04,  4.9234e-05],\n",
            "          [ 6.7170e-05,  1.4888e-04,  1.6689e-04]],\n",
            "\n",
            "         [[ 1.0112e-04,  3.6438e-05,  6.8568e-05],\n",
            "          [-6.8897e-05, -8.2226e-05, -7.9893e-06],\n",
            "          [ 8.7542e-05, -2.8575e-05, -1.3082e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4993e-04,  2.3254e-04,  2.7704e-04],\n",
            "          [ 2.1571e-04,  3.6944e-04,  3.2336e-04],\n",
            "          [ 1.0611e-04,  1.5865e-04,  2.5706e-04]],\n",
            "\n",
            "         [[-2.1112e-04,  9.2320e-05,  5.4198e-05],\n",
            "          [-9.3408e-05,  1.0231e-04,  7.5994e-05],\n",
            "          [-3.1183e-05,  1.2238e-04, -4.2990e-05]],\n",
            "\n",
            "         [[ 1.0283e-04, -8.4849e-05,  7.3612e-05],\n",
            "          [ 6.6709e-05,  7.0450e-05,  2.3414e-04],\n",
            "          [-2.0578e-06,  9.0109e-05,  1.4466e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.1603e-05,  8.7587e-05, -5.6511e-05],\n",
            "          [-2.5140e-04,  1.6205e-04,  2.6935e-05],\n",
            "          [-6.9071e-05, -1.6131e-04, -2.0398e-04]],\n",
            "\n",
            "         [[ 2.0735e-06, -1.3361e-04,  5.5025e-07],\n",
            "          [-1.8161e-04,  1.0692e-04, -6.5774e-05],\n",
            "          [-9.3753e-05, -1.7165e-04,  9.0184e-05]],\n",
            "\n",
            "         [[ 1.9558e-04,  5.3679e-05,  2.0417e-04],\n",
            "          [ 4.9594e-06,  4.4669e-05,  1.6176e-04],\n",
            "          [ 1.9889e-04, -3.7033e-05, -8.7941e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8133e-04,  2.8003e-04,  2.5572e-04],\n",
            "          [-2.9072e-05,  3.2444e-04,  3.1822e-04],\n",
            "          [ 1.3747e-04, -4.1010e-05,  3.8852e-04]],\n",
            "\n",
            "         [[ 2.2584e-04,  2.4099e-04,  1.0643e-04],\n",
            "          [ 1.5063e-04, -3.1311e-05,  6.8513e-05],\n",
            "          [ 7.9019e-05,  3.2861e-04,  1.3920e-04]],\n",
            "\n",
            "         [[ 3.4287e-05, -2.1314e-04, -1.5263e-04],\n",
            "          [ 8.7133e-05, -3.7468e-05, -4.4290e-05],\n",
            "          [ 2.3260e-04, -2.1181e-05,  8.9343e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.0440e-04,  1.3721e-04, -8.5524e-05],\n",
            "          [-1.1695e-04,  2.6830e-04,  5.0381e-05],\n",
            "          [ 2.4991e-04,  1.0715e-04,  2.2194e-04]],\n",
            "\n",
            "         [[-2.9121e-04, -3.8429e-04, -2.5521e-04],\n",
            "          [-1.4584e-04, -1.5209e-04, -2.0525e-04],\n",
            "          [-4.9295e-05,  8.7938e-05, -9.4901e-05]],\n",
            "\n",
            "         [[ 1.1075e-05, -3.1397e-04, -2.1630e-04],\n",
            "          [-1.5129e-04, -3.4563e-04, -3.9894e-04],\n",
            "          [-1.6414e-04, -2.7149e-04, -4.8834e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9803e-05,  3.1473e-04,  2.5984e-04],\n",
            "          [ 1.3651e-04,  1.3089e-04,  3.7245e-05],\n",
            "          [ 2.1411e-04,  2.2811e-04,  4.7909e-04]],\n",
            "\n",
            "         [[-5.4124e-06, -1.4189e-04, -6.0705e-05],\n",
            "          [-1.7975e-04, -2.9451e-04, -1.9423e-04],\n",
            "          [-1.9121e-04, -1.3986e-04,  8.0651e-06]],\n",
            "\n",
            "         [[-1.2147e-05,  1.0611e-04,  2.6743e-04],\n",
            "          [ 1.2939e-04,  9.5699e-05,  1.0476e-05],\n",
            "          [ 2.0267e-04,  1.9148e-04,  6.0494e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2778e-04,  3.8571e-05,  1.9741e-05],\n",
            "          [ 1.4973e-04, -7.5138e-07,  3.7101e-04],\n",
            "          [ 2.5009e-04,  5.8837e-05, -1.9118e-05]],\n",
            "\n",
            "         [[ 7.8866e-06, -1.2578e-04,  3.7006e-05],\n",
            "          [-7.2930e-05,  1.9878e-05,  6.8963e-05],\n",
            "          [-2.1393e-05,  2.4147e-04,  3.5268e-04]],\n",
            "\n",
            "         [[-8.6940e-05, -7.0559e-05, -1.8774e-04],\n",
            "          [-4.3165e-05, -4.0615e-05,  5.3731e-05],\n",
            "          [ 5.5583e-06, -1.3571e-04, -3.8249e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5429e-05,  2.4687e-04,  2.1268e-04],\n",
            "          [ 2.0318e-04,  1.6475e-04,  2.6600e-04],\n",
            "          [ 5.2711e-04,  4.0584e-04,  1.6800e-04]],\n",
            "\n",
            "         [[-1.4324e-04,  9.3164e-05,  2.7280e-04],\n",
            "          [-8.7584e-06,  2.5595e-04, -1.9582e-04],\n",
            "          [-1.8058e-04, -3.0487e-04, -1.7512e-04]],\n",
            "\n",
            "         [[ 7.0823e-05,  2.4562e-04,  8.2480e-05],\n",
            "          [ 8.9255e-05,  4.1734e-05,  3.7182e-05],\n",
            "          [-1.2265e-04, -1.3106e-04,  6.0247e-05]]],\n",
            "\n",
            "\n",
            "        [[[-4.6810e-04, -1.5012e-04, -2.0462e-04],\n",
            "          [-3.7549e-04, -2.6992e-04, -3.0651e-05],\n",
            "          [-5.4213e-05,  7.6361e-05, -2.3858e-04]],\n",
            "\n",
            "         [[ 1.1846e-04,  6.7401e-05,  5.5116e-05],\n",
            "          [-6.7835e-05, -1.2010e-04, -1.5503e-04],\n",
            "          [-3.7232e-05, -1.2709e-04, -2.5731e-04]],\n",
            "\n",
            "         [[ 9.3844e-05,  4.5442e-05, -7.1504e-05],\n",
            "          [-7.4889e-05, -2.6884e-05, -1.7416e-04],\n",
            "          [ 7.9041e-05,  1.0038e-04,  8.9101e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1593e-04,  1.0133e-04, -3.1639e-04],\n",
            "          [-2.5099e-04, -2.0484e-04, -1.9347e-04],\n",
            "          [-1.9114e-04,  9.1962e-05, -7.6876e-05]],\n",
            "\n",
            "         [[-7.0964e-05, -5.4459e-05,  2.2030e-04],\n",
            "          [ 8.4100e-06, -1.6015e-04, -9.2786e-05],\n",
            "          [-6.6245e-05, -2.5277e-04, -3.0462e-04]],\n",
            "\n",
            "         [[-2.9345e-05, -1.7998e-04, -1.8713e-04],\n",
            "          [-1.1233e-04, -3.7937e-05, -6.5900e-05],\n",
            "          [-1.4199e-05, -2.5763e-04,  1.0186e-04]]],\n",
            "\n",
            "\n",
            "        [[[-9.1397e-05, -2.1818e-05, -4.2971e-05],\n",
            "          [ 1.5814e-05, -3.0252e-05,  1.1041e-05],\n",
            "          [-1.3825e-04,  4.2012e-05, -6.6605e-05]],\n",
            "\n",
            "         [[-3.4816e-05, -7.7352e-05, -6.4702e-05],\n",
            "          [-1.2349e-05, -2.1757e-04, -2.4656e-05],\n",
            "          [-7.4727e-05, -6.8007e-05,  7.3142e-05]],\n",
            "\n",
            "         [[-2.0873e-05, -5.4419e-05,  6.2337e-05],\n",
            "          [ 1.1082e-05,  1.8200e-06, -3.2870e-05],\n",
            "          [-1.5121e-04, -7.5775e-05, -7.5567e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.7109e-05, -8.5085e-05, -1.0225e-04],\n",
            "          [-4.3292e-06,  5.9739e-05,  5.4218e-05],\n",
            "          [-8.4296e-05, -1.1558e-04,  3.0934e-06]],\n",
            "\n",
            "         [[-1.5027e-05, -4.6036e-05, -5.9147e-05],\n",
            "          [-3.0205e-05, -3.7014e-05, -6.4870e-05],\n",
            "          [ 6.6118e-05, -9.3784e-05,  7.9978e-05]],\n",
            "\n",
            "         [[-5.9326e-06,  4.2657e-05,  9.1725e-05],\n",
            "          [-6.5199e-05, -1.5224e-05, -5.6186e-05],\n",
            "          [-1.3734e-05, -5.8660e-05, -2.4288e-04]]]])}, 106: {'momentum_buffer': tensor([0.0012, 0.0011, 0.0006, 0.0011, 0.0007, 0.0010, 0.0012, 0.0008, 0.0011,\n",
            "        0.0010, 0.0014, 0.0008, 0.0011, 0.0009, 0.0007, 0.0009, 0.0011, 0.0011,\n",
            "        0.0011, 0.0008, 0.0009, 0.0009, 0.0010, 0.0011, 0.0011, 0.0013, 0.0012,\n",
            "        0.0012, 0.0009, 0.0009, 0.0012, 0.0008, 0.0007, 0.0009, 0.0009, 0.0010,\n",
            "        0.0011, 0.0009, 0.0011, 0.0010, 0.0009, 0.0012, 0.0012, 0.0013, 0.0011,\n",
            "        0.0013, 0.0009, 0.0009, 0.0009, 0.0007, 0.0013, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0007, 0.0010, 0.0008, 0.0010, 0.0008, 0.0008, 0.0008, 0.0008,\n",
            "        0.0011, 0.0008, 0.0012, 0.0010, 0.0011, 0.0006, 0.0009, 0.0008, 0.0011,\n",
            "        0.0011, 0.0012, 0.0012, 0.0010, 0.0007, 0.0009, 0.0011, 0.0011, 0.0010,\n",
            "        0.0006, 0.0011, 0.0008, 0.0005, 0.0008, 0.0012, 0.0007, 0.0010, 0.0013,\n",
            "        0.0012, 0.0011, 0.0011, 0.0008, 0.0014, 0.0010, 0.0010, 0.0007, 0.0008,\n",
            "        0.0010, 0.0011, 0.0009, 0.0008, 0.0009, 0.0017, 0.0010, 0.0012, 0.0007,\n",
            "        0.0012, 0.0012, 0.0011, 0.0011, 0.0013, 0.0007, 0.0010, 0.0009, 0.0010,\n",
            "        0.0013, 0.0015, 0.0010, 0.0009, 0.0010, 0.0006, 0.0011, 0.0013, 0.0011,\n",
            "        0.0012, 0.0012, 0.0011, 0.0010, 0.0008, 0.0012, 0.0010, 0.0011, 0.0011,\n",
            "        0.0010, 0.0010, 0.0011, 0.0009, 0.0011, 0.0012, 0.0009, 0.0012, 0.0006,\n",
            "        0.0014, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0013,\n",
            "        0.0015, 0.0014, 0.0009, 0.0011, 0.0012, 0.0012, 0.0012, 0.0006, 0.0013,\n",
            "        0.0011, 0.0010, 0.0009, 0.0012, 0.0009, 0.0012, 0.0007, 0.0009, 0.0010,\n",
            "        0.0012, 0.0009, 0.0007, 0.0009, 0.0006, 0.0013, 0.0011, 0.0009, 0.0013,\n",
            "        0.0009, 0.0006, 0.0010, 0.0011, 0.0009, 0.0011, 0.0016, 0.0011, 0.0007,\n",
            "        0.0008, 0.0003, 0.0010, 0.0008, 0.0010, 0.0011, 0.0012, 0.0008, 0.0010,\n",
            "        0.0006, 0.0009, 0.0008, 0.0011, 0.0007, 0.0006, 0.0008, 0.0012, 0.0010,\n",
            "        0.0010, 0.0009, 0.0008, 0.0008, 0.0010, 0.0009, 0.0010, 0.0010, 0.0013,\n",
            "        0.0012, 0.0010, 0.0011, 0.0009, 0.0008, 0.0009, 0.0011, 0.0008, 0.0006,\n",
            "        0.0012, 0.0010, 0.0012, 0.0007, 0.0009, 0.0011, 0.0011, 0.0012, 0.0010,\n",
            "        0.0008, 0.0009, 0.0008, 0.0013, 0.0010, 0.0006, 0.0011, 0.0010, 0.0009,\n",
            "        0.0011, 0.0010, 0.0008, 0.0010, 0.0005, 0.0012, 0.0009, 0.0009, 0.0010,\n",
            "        0.0009, 0.0008, 0.0013, 0.0009])}, 107: {'momentum_buffer': tensor([ 6.6758e-05,  5.4951e-05, -2.5351e-04,  1.9065e-04, -1.3430e-04,\n",
            "        -4.7725e-04,  7.0334e-05, -3.1052e-04, -3.3515e-06, -1.0905e-04,\n",
            "         1.3848e-04,  1.1593e-04,  5.4746e-05, -1.9940e-04,  6.8816e-05,\n",
            "        -2.0709e-04,  7.9499e-05, -3.4822e-05, -1.7805e-04, -1.3380e-04,\n",
            "         1.1119e-04, -1.3593e-04,  3.3261e-05, -2.5994e-04,  6.9737e-05,\n",
            "         2.8035e-04, -9.3280e-05,  1.2435e-04,  1.2047e-05,  5.6694e-05,\n",
            "         3.7127e-05, -8.8595e-05, -2.7909e-04, -2.4018e-05, -3.4950e-05,\n",
            "        -8.4630e-05,  2.9674e-05,  5.0807e-06, -9.4847e-05, -4.5920e-05,\n",
            "        -2.1809e-04,  8.3592e-05, -1.4917e-04,  1.1165e-04, -3.2731e-05,\n",
            "         2.5167e-04,  5.2389e-05,  2.1324e-04, -1.4024e-04, -2.6867e-04,\n",
            "         3.5384e-04, -1.7212e-05,  2.7873e-04, -1.8800e-05,  2.5566e-04,\n",
            "        -4.5590e-04,  2.5898e-04, -1.2672e-04,  2.0057e-04, -2.3891e-04,\n",
            "        -5.6285e-05, -1.2855e-04, -2.5861e-04,  2.2589e-05, -1.7035e-04,\n",
            "         1.9603e-04,  6.3144e-05,  4.3190e-05, -7.1485e-05, -1.0837e-05,\n",
            "        -1.1352e-04,  1.4745e-04,  6.1492e-06,  8.4562e-05,  1.7480e-04,\n",
            "         1.7021e-04, -6.6920e-05,  1.4443e-05, -4.3938e-05,  1.6828e-04,\n",
            "         4.0771e-05, -2.4576e-04, -1.0193e-04,  3.7754e-05, -1.9093e-04,\n",
            "        -1.3064e-04,  2.5299e-05, -1.8673e-04, -4.1906e-05, -2.3902e-04,\n",
            "        -4.3614e-05, -1.7948e-04,  1.9522e-04, -1.6034e-04,  2.2773e-04,\n",
            "         9.6797e-05, -1.0785e-04, -2.5923e-04, -1.8696e-04, -1.1037e-04,\n",
            "         2.1535e-04, -4.0860e-05, -3.2017e-04,  5.3296e-05,  3.4369e-04,\n",
            "        -1.4262e-04,  1.1852e-04, -1.6027e-04,  2.9045e-04,  2.4934e-05,\n",
            "        -1.0755e-04, -7.5830e-06,  7.4483e-05, -3.6211e-04,  4.7287e-05,\n",
            "        -8.6205e-05,  8.5660e-05,  5.7740e-04,  3.8090e-04, -2.6603e-05,\n",
            "         6.1809e-05,  2.9747e-04, -4.3810e-04,  7.4607e-05,  2.0061e-04,\n",
            "        -9.6449e-05, -4.5005e-05,  1.7030e-05,  2.0797e-04,  1.0870e-04,\n",
            "        -3.0543e-04,  2.6372e-04,  8.5091e-05,  1.1071e-04, -8.6095e-05,\n",
            "         4.1704e-05, -1.8151e-05,  5.7871e-05,  1.1219e-04,  6.0146e-05,\n",
            "         1.8667e-04, -1.0547e-04,  4.0114e-04, -8.5469e-05, -9.8896e-05,\n",
            "         6.1276e-05, -1.4817e-04, -2.4235e-05,  5.1948e-06, -2.4170e-05,\n",
            "         1.0551e-05, -1.1848e-04, -5.4491e-05,  8.9725e-05, -6.7178e-05,\n",
            "        -1.9497e-04,  1.5105e-04,  1.5124e-04, -1.0741e-04,  8.4217e-05,\n",
            "        -2.3938e-04,  2.3098e-04, -2.5528e-04,  7.3745e-05, -7.9889e-05,\n",
            "         2.1692e-04, -9.8198e-05,  4.2604e-04, -2.1405e-04,  2.5552e-05,\n",
            "         8.8772e-05, -9.7422e-05, -1.3834e-05, -3.3548e-05, -6.5488e-05,\n",
            "        -1.2219e-04,  2.0959e-04, -9.3567e-05, -1.2373e-04,  2.1776e-04,\n",
            "        -1.8783e-06, -3.4011e-04,  1.3565e-04,  3.8324e-05,  1.6083e-05,\n",
            "         4.5883e-05,  4.3568e-05,  1.4866e-04, -2.2010e-04, -1.4484e-04,\n",
            "        -3.9450e-04,  2.8575e-04, -6.8928e-05,  1.4990e-04,  2.9902e-04,\n",
            "        -2.3297e-04, -1.4622e-04,  1.0510e-04, -9.5651e-05,  1.0857e-05,\n",
            "         7.9591e-05,  1.1333e-05, -1.1007e-04, -2.4053e-04,  8.5389e-05,\n",
            "         2.3655e-04,  1.7195e-04, -1.5801e-04, -2.1720e-05, -1.4623e-04,\n",
            "        -8.4874e-05, -1.2526e-04, -1.4971e-04, -8.1869e-05,  1.5796e-04,\n",
            "         4.8909e-04,  1.9898e-04, -4.6716e-05,  1.4084e-05,  6.0347e-05,\n",
            "        -7.3754e-06,  7.3188e-05,  7.1570e-05, -1.7772e-04, -2.1902e-04,\n",
            "         1.2587e-04, -1.3005e-04,  2.8008e-04, -2.1251e-04, -2.5155e-04,\n",
            "         2.8989e-04, -3.1293e-06,  2.2682e-04,  7.5968e-05,  7.7441e-07,\n",
            "         5.6874e-05, -1.0390e-04,  1.2224e-05,  1.2646e-05, -3.1852e-04,\n",
            "         5.1746e-05, -1.2503e-04, -2.7580e-04,  1.2734e-04,  1.0288e-04,\n",
            "        -9.0727e-05, -3.7443e-05, -3.0140e-04, -2.3469e-04,  1.6073e-04,\n",
            "        -8.4767e-05,  2.6434e-04, -3.2568e-04, -8.4690e-05, -1.2005e-04,\n",
            "        -6.2977e-05])}, 108: {'momentum_buffer': tensor([[[[ 4.5763e-05]],\n",
            "\n",
            "         [[-4.0392e-05]],\n",
            "\n",
            "         [[-1.4669e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.9631e-05]],\n",
            "\n",
            "         [[-1.0093e-04]],\n",
            "\n",
            "         [[ 7.5820e-05]]],\n",
            "\n",
            "\n",
            "        [[[-7.4704e-05]],\n",
            "\n",
            "         [[ 6.2569e-05]],\n",
            "\n",
            "         [[ 1.0593e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2837e-04]],\n",
            "\n",
            "         [[ 3.0844e-04]],\n",
            "\n",
            "         [[ 3.6365e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2486e-05]],\n",
            "\n",
            "         [[-1.8588e-04]],\n",
            "\n",
            "         [[-1.5036e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.1039e-05]],\n",
            "\n",
            "         [[-1.4421e-04]],\n",
            "\n",
            "         [[ 8.1391e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.0519e-05]],\n",
            "\n",
            "         [[-2.9357e-04]],\n",
            "\n",
            "         [[-3.0635e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3667e-05]],\n",
            "\n",
            "         [[ 3.2743e-04]],\n",
            "\n",
            "         [[ 3.6165e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0524e-05]],\n",
            "\n",
            "         [[ 1.6821e-04]],\n",
            "\n",
            "         [[-2.1977e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.0720e-05]],\n",
            "\n",
            "         [[-1.4073e-04]],\n",
            "\n",
            "         [[-1.2822e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1514e-04]],\n",
            "\n",
            "         [[ 5.2795e-05]],\n",
            "\n",
            "         [[ 1.7404e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4896e-05]],\n",
            "\n",
            "         [[-4.5883e-05]],\n",
            "\n",
            "         [[ 1.0750e-06]]]])}, 109: {'momentum_buffer': tensor([0.0011, 0.0011, 0.0010,  ..., 0.0009, 0.0011, 0.0011])}, 110: {'momentum_buffer': tensor([ 6.3500e-05, -8.2342e-05, -5.9494e-05,  ..., -5.9188e-06,\n",
            "        -4.2860e-05,  7.8421e-05])}, 111: {'momentum_buffer': tensor([[[[ 1.3739e-04]],\n",
            "\n",
            "         [[-7.1689e-05]],\n",
            "\n",
            "         [[-5.0476e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7602e-05]],\n",
            "\n",
            "         [[-4.8177e-05]],\n",
            "\n",
            "         [[-5.8312e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4122e-04]],\n",
            "\n",
            "         [[-4.4575e-06]],\n",
            "\n",
            "         [[ 6.8539e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.2759e-05]],\n",
            "\n",
            "         [[-9.4557e-05]],\n",
            "\n",
            "         [[-2.6998e-04]]],\n",
            "\n",
            "\n",
            "        [[[-8.2406e-05]],\n",
            "\n",
            "         [[ 8.2058e-05]],\n",
            "\n",
            "         [[ 9.6289e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.2595e-05]],\n",
            "\n",
            "         [[-2.5071e-05]],\n",
            "\n",
            "         [[ 2.1061e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.1624e-05]],\n",
            "\n",
            "         [[-3.5701e-05]],\n",
            "\n",
            "         [[ 2.4044e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.5743e-05]],\n",
            "\n",
            "         [[-6.2123e-06]],\n",
            "\n",
            "         [[ 1.1860e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.1066e-05]],\n",
            "\n",
            "         [[ 1.3507e-04]],\n",
            "\n",
            "         [[-5.9374e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.4010e-05]],\n",
            "\n",
            "         [[ 2.9755e-05]],\n",
            "\n",
            "         [[-1.1904e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2672e-05]],\n",
            "\n",
            "         [[-4.7531e-05]],\n",
            "\n",
            "         [[-3.0537e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6289e-05]],\n",
            "\n",
            "         [[ 2.9475e-05]],\n",
            "\n",
            "         [[ 2.6372e-04]]]])}, 112: {'momentum_buffer': tensor([0.0012, 0.0008, 0.0009, 0.0010, 0.0012, 0.0011, 0.0011, 0.0011, 0.0009,\n",
            "        0.0010, 0.0007, 0.0008, 0.0010, 0.0008, 0.0006, 0.0010, 0.0009, 0.0009,\n",
            "        0.0007, 0.0012, 0.0010, 0.0012, 0.0010, 0.0010, 0.0010, 0.0012, 0.0010,\n",
            "        0.0008, 0.0010, 0.0010, 0.0009, 0.0013, 0.0007, 0.0012, 0.0012, 0.0010,\n",
            "        0.0011, 0.0009, 0.0008, 0.0007, 0.0008, 0.0009, 0.0013, 0.0010, 0.0011,\n",
            "        0.0011, 0.0005, 0.0007, 0.0009, 0.0009, 0.0007, 0.0010, 0.0011, 0.0011,\n",
            "        0.0012, 0.0010, 0.0009, 0.0009, 0.0012, 0.0009, 0.0013, 0.0012, 0.0012,\n",
            "        0.0010, 0.0010, 0.0012, 0.0010, 0.0011, 0.0011, 0.0009, 0.0013, 0.0010,\n",
            "        0.0011, 0.0012, 0.0013, 0.0011, 0.0006, 0.0010, 0.0012, 0.0008, 0.0011,\n",
            "        0.0011, 0.0010, 0.0009, 0.0011, 0.0009, 0.0010, 0.0012, 0.0011, 0.0014,\n",
            "        0.0009, 0.0010, 0.0014, 0.0008, 0.0012, 0.0011, 0.0008, 0.0006, 0.0009,\n",
            "        0.0010, 0.0009, 0.0007, 0.0009, 0.0010, 0.0012, 0.0008, 0.0009, 0.0009,\n",
            "        0.0012, 0.0009, 0.0010, 0.0008, 0.0011, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0012, 0.0008, 0.0011, 0.0008, 0.0011, 0.0012, 0.0008, 0.0012,\n",
            "        0.0007, 0.0008, 0.0012, 0.0012, 0.0009, 0.0012, 0.0010, 0.0011, 0.0012,\n",
            "        0.0009, 0.0009, 0.0009, 0.0006, 0.0013, 0.0010, 0.0009, 0.0013, 0.0008,\n",
            "        0.0014, 0.0010, 0.0011, 0.0009, 0.0006, 0.0008, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0013, 0.0009, 0.0011, 0.0010, 0.0011, 0.0010,\n",
            "        0.0011, 0.0009, 0.0012, 0.0010, 0.0009, 0.0010, 0.0010, 0.0007, 0.0008,\n",
            "        0.0011, 0.0009, 0.0006, 0.0011, 0.0012, 0.0009, 0.0008, 0.0006, 0.0016,\n",
            "        0.0012, 0.0008, 0.0009, 0.0011, 0.0015, 0.0013, 0.0007, 0.0008, 0.0012,\n",
            "        0.0008, 0.0009, 0.0009, 0.0008, 0.0010, 0.0012, 0.0013, 0.0012, 0.0011,\n",
            "        0.0012, 0.0011, 0.0009, 0.0011, 0.0011, 0.0006, 0.0009, 0.0009, 0.0008,\n",
            "        0.0012, 0.0012, 0.0010, 0.0007, 0.0010, 0.0011, 0.0012, 0.0011, 0.0011,\n",
            "        0.0010, 0.0011, 0.0011, 0.0009, 0.0011, 0.0010, 0.0011, 0.0012, 0.0008,\n",
            "        0.0009, 0.0010, 0.0006, 0.0009, 0.0009, 0.0010, 0.0014, 0.0009, 0.0012,\n",
            "        0.0009, 0.0009, 0.0013, 0.0008, 0.0008, 0.0010, 0.0009, 0.0008, 0.0007,\n",
            "        0.0008, 0.0007, 0.0007, 0.0010, 0.0012, 0.0012, 0.0008, 0.0011, 0.0007,\n",
            "        0.0009, 0.0012, 0.0009, 0.0013])}, 113: {'momentum_buffer': tensor([-3.1614e-04,  3.8746e-05, -1.4034e-04, -1.0961e-04,  2.3539e-06,\n",
            "        -9.5095e-05, -1.6270e-04, -3.1295e-05, -1.8048e-05, -1.5912e-04,\n",
            "        -2.5269e-04, -1.9759e-04,  2.3659e-04, -1.4389e-04, -2.1441e-04,\n",
            "         1.5969e-05, -1.2263e-04, -1.5066e-04, -2.8981e-04, -8.7869e-06,\n",
            "        -3.6827e-05,  5.6854e-05,  6.1415e-05, -1.6873e-04,  2.2531e-04,\n",
            "        -1.0555e-04,  5.2023e-05,  1.7305e-05,  1.6872e-04, -2.5388e-04,\n",
            "        -1.4800e-04,  6.0913e-05, -1.5778e-04,  6.9606e-05, -1.9503e-04,\n",
            "         2.0419e-04, -8.8582e-06, -1.6067e-04,  2.4952e-04, -3.6544e-04,\n",
            "        -1.3788e-05, -1.0992e-04,  4.1967e-04,  1.7793e-04,  1.5909e-04,\n",
            "        -3.3263e-04, -2.4396e-04, -2.0638e-04, -4.6112e-04,  1.1863e-05,\n",
            "        -1.4996e-04,  3.7215e-05,  5.9244e-05, -6.7357e-05,  3.2175e-05,\n",
            "        -8.2620e-05,  2.1461e-05,  1.8678e-04,  1.3363e-04, -5.4654e-05,\n",
            "         1.7691e-04,  8.3654e-05,  8.4490e-05,  9.0315e-05,  2.7402e-04,\n",
            "        -4.4886e-05,  1.6597e-04,  1.8119e-04,  2.5526e-04,  1.0021e-04,\n",
            "        -2.6508e-05,  6.6209e-05, -3.8127e-06,  1.6177e-04,  1.3045e-04,\n",
            "         1.1407e-04, -1.7343e-04,  1.2217e-04, -9.8296e-05, -1.2725e-04,\n",
            "        -1.1971e-04,  2.9216e-04, -1.7471e-04, -2.1516e-04, -5.3010e-05,\n",
            "        -5.0352e-05,  2.6481e-04,  5.7854e-05,  1.1010e-04,  4.3023e-04,\n",
            "        -2.0176e-05,  2.4951e-04,  1.2630e-04, -1.3256e-04,  1.5969e-04,\n",
            "        -1.8972e-05, -1.3647e-04, -4.7840e-04, -1.0528e-04, -5.3535e-05,\n",
            "         1.6034e-04, -1.2805e-04,  1.7938e-05,  9.4127e-05,  1.3619e-05,\n",
            "         1.0897e-04, -9.9330e-05, -1.5050e-04, -2.7793e-05, -4.6876e-05,\n",
            "        -1.1508e-04, -3.4492e-04,  2.0851e-04, -4.8457e-05, -8.6426e-05,\n",
            "        -2.3353e-04, -7.3716e-05,  2.1420e-04,  1.4194e-04, -1.9630e-04,\n",
            "         1.0961e-04, -6.6064e-05, -1.6390e-04,  2.5802e-04,  2.9527e-06,\n",
            "         5.3110e-05, -1.5360e-04,  2.5020e-05,  2.9884e-04,  2.7810e-04,\n",
            "        -3.0054e-06,  6.4891e-05,  1.8730e-05, -4.9534e-05,  1.6679e-04,\n",
            "         1.1437e-04, -1.5752e-04,  2.4607e-04, -6.4671e-05,  7.2278e-05,\n",
            "         1.3487e-04,  1.4585e-04,  1.6143e-04, -4.1901e-04,  1.8573e-04,\n",
            "         8.4536e-05, -1.6905e-04, -2.0915e-04, -4.4054e-04, -1.3449e-04,\n",
            "        -2.8698e-05,  1.1593e-04,  1.2009e-04,  1.1729e-04, -1.0384e-04,\n",
            "        -2.0591e-05, -2.1587e-04, -3.0518e-04,  5.6356e-05, -1.8155e-04,\n",
            "         2.1537e-04,  3.0282e-05,  1.0816e-04, -2.0339e-04,  2.3163e-04,\n",
            "         5.6396e-05,  4.1415e-05,  7.1346e-05, -1.1947e-04, -4.1491e-04,\n",
            "        -2.3753e-05,  1.0724e-04, -1.7921e-04, -1.6699e-04,  1.0935e-04,\n",
            "         2.9254e-04, -3.3331e-04, -7.5959e-05, -1.0138e-05,  2.3764e-04,\n",
            "         1.2957e-04,  8.2562e-06, -4.6059e-05, -1.9856e-04,  1.6989e-04,\n",
            "        -1.5189e-04, -2.1021e-04, -1.9376e-04, -4.2332e-06, -2.6027e-04,\n",
            "        -4.9374e-04, -1.3531e-04, -2.2666e-04,  2.5358e-05, -5.4962e-05,\n",
            "         1.7756e-04,  2.0676e-04,  1.8774e-04,  3.0869e-04, -4.5923e-05,\n",
            "        -7.0789e-05,  1.8952e-04,  2.1483e-04,  1.7239e-04,  5.8142e-05,\n",
            "         6.3688e-05,  8.1771e-06,  2.8083e-04,  8.5717e-05, -1.5530e-04,\n",
            "        -8.6081e-05,  2.6998e-05,  2.2340e-05,  2.9603e-04,  1.8239e-04,\n",
            "         2.6303e-04,  1.4813e-04, -1.2801e-04,  1.3990e-04,  3.9524e-05,\n",
            "         4.1072e-05,  2.8953e-05, -1.5557e-04,  5.9672e-05,  8.7473e-05,\n",
            "        -1.2303e-04,  3.0725e-05, -1.3451e-04,  9.4470e-05,  2.3274e-05,\n",
            "         3.3986e-05,  2.1923e-04, -9.8311e-05,  1.5305e-04, -7.9851e-06,\n",
            "        -1.5120e-04,  2.0597e-04, -3.6587e-05, -5.8696e-05, -1.4101e-04,\n",
            "        -8.9496e-05,  9.4501e-05, -1.6798e-04, -1.1912e-04, -2.4739e-04,\n",
            "        -2.1712e-05, -8.0094e-05, -2.7750e-05, -1.7582e-06, -2.3389e-04,\n",
            "         5.7021e-05, -1.1721e-05, -3.0725e-05, -4.3640e-05, -2.0669e-04,\n",
            "         2.2067e-04])}, 114: {'momentum_buffer': tensor([[[[-1.3145e-04, -5.9946e-05,  7.8132e-05],\n",
            "          [-1.7835e-05, -4.6522e-05,  1.0925e-05],\n",
            "          [-1.4894e-04,  9.6817e-05,  1.0920e-05]],\n",
            "\n",
            "         [[-2.8412e-04, -5.7930e-05, -6.7524e-06],\n",
            "          [-9.4028e-05, -1.1139e-04, -1.0744e-04],\n",
            "          [-3.1900e-04, -2.2765e-05, -1.3519e-04]],\n",
            "\n",
            "         [[-1.9921e-04, -1.2492e-04, -1.8882e-04],\n",
            "          [-4.1598e-05, -5.3875e-05,  1.0301e-04],\n",
            "          [ 2.3332e-05, -6.4894e-05,  1.9197e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5081e-04, -1.7019e-04, -3.6990e-04],\n",
            "          [-1.5999e-04, -1.1234e-04, -3.6476e-04],\n",
            "          [-2.7837e-04, -3.5506e-04, -2.0878e-04]],\n",
            "\n",
            "         [[ 4.1944e-05,  2.9763e-05,  2.3860e-05],\n",
            "          [ 1.2603e-05, -2.3812e-05, -9.9944e-05],\n",
            "          [-1.4524e-05, -2.5133e-05, -6.7398e-05]],\n",
            "\n",
            "         [[-7.5170e-05, -9.4269e-05, -1.5197e-04],\n",
            "          [ 7.4617e-05,  5.2161e-08, -7.2875e-05],\n",
            "          [-2.1649e-04, -1.3149e-04, -2.8632e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4394e-04,  3.1237e-04,  2.9708e-04],\n",
            "          [ 1.8818e-04,  3.7672e-05,  7.9931e-05],\n",
            "          [ 8.1415e-05,  1.2618e-04,  2.5904e-05]],\n",
            "\n",
            "         [[ 1.5086e-04,  1.1850e-04,  1.6326e-04],\n",
            "          [-1.4987e-04,  5.4774e-05,  9.5911e-05],\n",
            "          [ 4.6532e-05, -1.3741e-04,  1.0911e-04]],\n",
            "\n",
            "         [[ 1.7596e-06, -1.1135e-04, -5.1198e-05],\n",
            "          [-1.3017e-04, -5.5729e-05, -6.3658e-05],\n",
            "          [-1.6383e-04, -1.2698e-04, -1.0082e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4856e-04,  2.6820e-04,  5.1062e-04],\n",
            "          [ 2.3900e-04,  9.4258e-05,  5.0756e-04],\n",
            "          [ 1.8842e-04,  1.6165e-04,  3.3904e-04]],\n",
            "\n",
            "         [[ 2.8319e-04,  1.9193e-04,  3.5375e-04],\n",
            "          [ 1.8493e-04,  2.2354e-04,  1.2771e-04],\n",
            "          [ 1.9596e-04,  3.4431e-05,  2.0757e-04]],\n",
            "\n",
            "         [[ 2.9784e-04,  3.3738e-04,  2.0940e-04],\n",
            "          [ 2.3265e-04,  4.0288e-04,  2.6454e-04],\n",
            "          [ 1.5593e-04,  1.1213e-04,  1.1250e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 6.2759e-05, -6.1124e-05, -5.7412e-05],\n",
            "          [ 3.8112e-06,  6.1711e-05,  5.5864e-05],\n",
            "          [-4.2383e-06,  1.3350e-04, -1.3668e-05]],\n",
            "\n",
            "         [[-2.0928e-04, -1.2240e-04, -2.0414e-04],\n",
            "          [-1.5121e-04, -1.6794e-04, -8.3536e-05],\n",
            "          [-2.0434e-04, -2.8864e-04, -2.1074e-04]],\n",
            "\n",
            "         [[-6.8600e-05, -8.9808e-05, -1.6989e-04],\n",
            "          [-2.1085e-04, -1.1839e-04, -9.6534e-05],\n",
            "          [-4.2739e-05, -3.7609e-05, -1.1891e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7476e-04, -1.0639e-04, -2.1764e-04],\n",
            "          [-3.7270e-05, -1.5668e-04, -5.8805e-04],\n",
            "          [-1.5485e-05, -1.4605e-04, -1.8447e-04]],\n",
            "\n",
            "         [[-1.3350e-04,  9.4414e-05,  8.7959e-05],\n",
            "          [ 1.0463e-04,  1.2452e-05,  1.7619e-04],\n",
            "          [ 9.3733e-05,  2.0263e-04,  2.5445e-04]],\n",
            "\n",
            "         [[-7.5250e-05, -1.7254e-05, -1.3460e-04],\n",
            "          [-9.6422e-05, -9.0547e-05, -6.6455e-05],\n",
            "          [-3.8063e-05, -1.1148e-04,  2.7893e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.6369e-04, -1.4059e-04, -1.6116e-04],\n",
            "          [-9.1532e-05, -8.8187e-05, -4.3798e-05],\n",
            "          [-3.2887e-05,  1.5262e-04, -6.4713e-05]],\n",
            "\n",
            "         [[-1.1213e-04, -1.0154e-04, -4.3972e-05],\n",
            "          [-1.0903e-05,  3.2817e-05, -3.1751e-05],\n",
            "          [-4.5300e-06, -1.3973e-05, -1.0441e-04]],\n",
            "\n",
            "         [[ 1.9549e-04,  6.6241e-05,  1.3456e-06],\n",
            "          [ 2.5972e-05, -4.2447e-05, -6.3584e-05],\n",
            "          [-5.6082e-06, -1.3783e-04, -7.5451e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.2251e-05,  5.4006e-06, -3.8629e-05],\n",
            "          [ 2.5922e-05,  1.6782e-04,  1.5217e-04],\n",
            "          [ 1.8017e-04,  1.4727e-04, -4.7543e-05]],\n",
            "\n",
            "         [[ 7.2665e-05,  5.5999e-05, -4.8225e-05],\n",
            "          [ 8.5868e-05,  1.5228e-04, -3.7966e-06],\n",
            "          [-2.2357e-04,  1.4167e-05,  6.9677e-05]],\n",
            "\n",
            "         [[-1.2776e-05, -1.4079e-04, -2.0598e-04],\n",
            "          [-8.1264e-05, -1.1653e-04, -1.1542e-04],\n",
            "          [ 8.0134e-05, -1.3407e-04, -2.7270e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4417e-06,  2.1027e-04, -8.9813e-05],\n",
            "          [-6.1918e-05,  7.2080e-06, -6.7111e-05],\n",
            "          [-4.6923e-05,  6.0898e-05,  4.3585e-05]],\n",
            "\n",
            "         [[ 8.4479e-05,  4.1824e-05,  1.6784e-04],\n",
            "          [ 1.4349e-04,  2.3824e-04,  5.1644e-05],\n",
            "          [-9.8080e-05, -2.5207e-06, -1.5577e-04]],\n",
            "\n",
            "         [[-1.7708e-04,  4.2899e-05, -2.8907e-05],\n",
            "          [-7.4502e-05,  6.9492e-05, -2.1485e-04],\n",
            "          [-2.9541e-05, -2.0823e-04, -7.0882e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2904e-04,  3.6911e-04, -2.7874e-05],\n",
            "          [ 3.7824e-04,  1.0384e-04,  1.1705e-04],\n",
            "          [ 2.0570e-04,  7.0439e-05,  2.0837e-04]],\n",
            "\n",
            "         [[ 3.0442e-05, -1.5555e-04,  4.6882e-06],\n",
            "          [-2.0701e-05,  2.4164e-04,  7.4180e-05],\n",
            "          [ 1.7433e-04, -9.0842e-06, -8.5047e-05]],\n",
            "\n",
            "         [[ 1.3847e-04,  2.2096e-04,  1.8257e-04],\n",
            "          [ 3.5592e-05, -4.3512e-05,  3.5370e-05],\n",
            "          [-1.9824e-04, -4.1372e-05,  1.3078e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5841e-04,  4.8867e-04,  3.3758e-04],\n",
            "          [ 2.0725e-04,  1.8208e-04,  1.9227e-04],\n",
            "          [ 1.6367e-04,  2.6433e-04,  6.9453e-05]],\n",
            "\n",
            "         [[ 1.4398e-04,  6.5370e-06,  1.6039e-04],\n",
            "          [-1.8544e-05,  1.1362e-04, -1.3545e-04],\n",
            "          [-1.4370e-04, -1.6526e-04,  1.7864e-05]],\n",
            "\n",
            "         [[ 1.9748e-05,  1.1030e-04,  9.0595e-05],\n",
            "          [-7.5218e-05,  1.3381e-04,  1.1128e-04],\n",
            "          [-5.9722e-05,  7.9056e-06,  6.1482e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0550e-05,  1.9853e-05, -3.9792e-05],\n",
            "          [ 5.9871e-05,  2.6720e-05, -8.2595e-05],\n",
            "          [ 1.2227e-05,  1.4601e-04, -5.7313e-05]],\n",
            "\n",
            "         [[ 3.0908e-04,  2.8524e-04,  2.3670e-04],\n",
            "          [ 1.8235e-04,  1.3320e-04,  3.2902e-04],\n",
            "          [ 2.0809e-04,  1.3588e-04,  1.1208e-04]],\n",
            "\n",
            "         [[ 8.0443e-05,  2.1689e-04,  4.0507e-04],\n",
            "          [ 2.7746e-05, -1.0008e-04,  2.8379e-04],\n",
            "          [ 1.0653e-04,  1.5224e-05,  1.6777e-04]]]])}, 115: {'momentum_buffer': tensor([0.0009, 0.0009, 0.0011, 0.0010, 0.0009, 0.0006, 0.0007, 0.0010, 0.0011,\n",
            "        0.0009, 0.0008, 0.0012, 0.0012, 0.0012, 0.0009, 0.0008, 0.0009, 0.0011,\n",
            "        0.0011, 0.0011, 0.0008, 0.0011, 0.0010, 0.0007, 0.0011, 0.0012, 0.0010,\n",
            "        0.0009, 0.0011, 0.0011, 0.0010, 0.0010, 0.0011, 0.0009, 0.0009, 0.0008,\n",
            "        0.0008, 0.0007, 0.0009, 0.0009, 0.0011, 0.0013, 0.0008, 0.0012, 0.0008,\n",
            "        0.0009, 0.0010, 0.0010, 0.0009, 0.0011, 0.0012, 0.0010, 0.0010, 0.0012,\n",
            "        0.0011, 0.0009, 0.0014, 0.0013, 0.0009, 0.0011, 0.0012, 0.0012, 0.0010,\n",
            "        0.0010, 0.0011, 0.0012, 0.0010, 0.0010, 0.0008, 0.0011, 0.0009, 0.0010,\n",
            "        0.0010, 0.0012, 0.0008, 0.0012, 0.0010, 0.0012, 0.0009, 0.0010, 0.0010,\n",
            "        0.0012, 0.0010, 0.0010, 0.0010, 0.0009, 0.0012, 0.0010, 0.0011, 0.0010,\n",
            "        0.0011, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0007, 0.0008, 0.0011,\n",
            "        0.0010, 0.0012, 0.0007, 0.0007, 0.0008, 0.0008, 0.0011, 0.0007, 0.0007,\n",
            "        0.0011, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0008,\n",
            "        0.0010, 0.0009, 0.0011, 0.0009, 0.0010, 0.0011, 0.0010, 0.0008, 0.0014,\n",
            "        0.0010, 0.0012, 0.0011, 0.0009, 0.0008, 0.0012, 0.0008, 0.0011, 0.0009,\n",
            "        0.0011, 0.0010, 0.0009, 0.0009, 0.0010, 0.0012, 0.0009, 0.0009, 0.0010,\n",
            "        0.0010, 0.0013, 0.0011, 0.0010, 0.0009, 0.0011, 0.0008, 0.0009, 0.0010,\n",
            "        0.0011, 0.0012, 0.0012, 0.0009, 0.0008, 0.0008, 0.0007, 0.0011, 0.0009,\n",
            "        0.0008, 0.0012, 0.0009, 0.0010, 0.0008, 0.0010, 0.0011, 0.0008, 0.0009,\n",
            "        0.0010, 0.0012, 0.0008, 0.0010, 0.0009, 0.0010, 0.0012, 0.0011, 0.0012,\n",
            "        0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0012, 0.0012, 0.0011, 0.0010,\n",
            "        0.0012, 0.0010, 0.0009, 0.0011, 0.0010, 0.0008, 0.0011, 0.0013, 0.0011,\n",
            "        0.0013, 0.0011, 0.0010, 0.0007, 0.0010, 0.0011, 0.0008, 0.0008, 0.0008,\n",
            "        0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0008, 0.0010, 0.0010, 0.0006,\n",
            "        0.0013, 0.0007, 0.0012, 0.0010, 0.0011, 0.0013, 0.0012, 0.0009, 0.0009,\n",
            "        0.0007, 0.0007, 0.0008, 0.0012, 0.0010, 0.0010, 0.0008, 0.0010, 0.0007,\n",
            "        0.0013, 0.0011, 0.0008, 0.0007, 0.0011, 0.0007, 0.0011, 0.0008, 0.0008,\n",
            "        0.0014, 0.0005, 0.0012, 0.0009, 0.0011, 0.0008, 0.0010, 0.0009, 0.0012,\n",
            "        0.0009, 0.0010, 0.0011, 0.0011])}, 116: {'momentum_buffer': tensor([ 2.2090e-05,  7.2934e-05,  4.3413e-05,  2.8643e-05, -1.5793e-06,\n",
            "        -1.9302e-04, -9.0714e-05,  8.1476e-05,  1.5207e-04, -2.8583e-04,\n",
            "        -9.7997e-05,  1.3261e-04,  1.8388e-04, -1.4638e-05, -2.8892e-04,\n",
            "        -1.2507e-04, -1.6883e-04,  1.3205e-04,  1.6540e-05,  7.8203e-06,\n",
            "         1.0478e-04,  1.6277e-05,  1.1896e-04, -1.9944e-04,  2.8540e-04,\n",
            "         2.4903e-04, -1.1976e-04,  3.5928e-05,  6.7967e-05,  4.3054e-05,\n",
            "        -1.5319e-05,  4.9294e-05,  1.3463e-04, -1.3280e-04, -1.7285e-04,\n",
            "        -2.8428e-04, -1.1138e-04, -1.1885e-04,  7.3747e-05, -1.5465e-04,\n",
            "         1.6181e-04,  4.5206e-04, -9.6522e-05,  1.7409e-04, -1.8195e-04,\n",
            "        -8.8147e-05, -4.7329e-05, -1.2631e-04, -1.9400e-04, -1.1272e-04,\n",
            "         1.4117e-04, -6.9645e-05,  4.5151e-06, -8.0464e-05,  1.3678e-04,\n",
            "        -1.5226e-04, -5.8897e-05,  3.4303e-04, -5.3519e-05, -3.1657e-06,\n",
            "         1.2933e-04,  1.9971e-04,  1.4950e-04,  1.4823e-04,  1.8869e-05,\n",
            "         2.2169e-04, -6.9631e-05,  1.5503e-04, -1.4357e-04,  7.0660e-05,\n",
            "        -6.7384e-05,  3.7170e-04,  1.5817e-05, -1.1667e-05, -1.2519e-04,\n",
            "         1.4490e-05,  5.0595e-05,  3.6849e-05, -9.4070e-05, -2.3667e-04,\n",
            "        -1.0597e-04, -6.3757e-06,  1.3304e-04,  5.2117e-05, -3.3103e-05,\n",
            "        -8.7018e-05,  7.1944e-05, -1.4284e-04,  1.2771e-04,  2.7695e-05,\n",
            "         7.6600e-05, -1.2651e-04, -2.9115e-04,  1.4012e-05, -1.0427e-05,\n",
            "         6.9024e-06, -1.9588e-04, -1.6477e-04, -5.2383e-05, -1.0423e-04,\n",
            "        -1.2087e-04, -3.3302e-04, -1.6229e-04,  1.7748e-05, -1.7053e-04,\n",
            "         5.2979e-05,  5.2677e-05, -2.3642e-04,  1.0364e-04, -3.7868e-05,\n",
            "         1.6605e-04, -5.4632e-05, -2.5277e-04, -2.6763e-05, -1.0297e-04,\n",
            "        -8.5190e-05, -3.6461e-05, -7.3190e-05, -1.1549e-04,  8.5712e-05,\n",
            "        -1.4497e-04,  2.4814e-05,  7.9430e-05,  2.9149e-05, -1.3995e-04,\n",
            "         3.5487e-04,  7.7862e-05,  1.7310e-04, -1.3402e-04, -9.2169e-05,\n",
            "        -2.0410e-04,  1.0206e-04, -1.8652e-04,  5.0279e-05,  1.0622e-04,\n",
            "         1.5669e-04,  1.5847e-04, -2.9499e-04, -2.3749e-04,  2.5255e-06,\n",
            "         1.3070e-04, -1.1472e-04, -1.1428e-04, -2.6895e-04, -1.7367e-04,\n",
            "         1.0352e-04, -9.8057e-05, -1.2650e-04,  1.8943e-05, -4.6642e-04,\n",
            "        -2.5734e-04,  3.1527e-05, -1.3436e-04,  1.1269e-04,  3.8708e-05,\n",
            "         4.3507e-05, -9.5987e-05, -1.9572e-04,  1.0612e-04, -3.0409e-04,\n",
            "         1.8009e-04, -5.0815e-05, -5.8578e-05,  2.4756e-04,  5.5269e-06,\n",
            "         1.2825e-05,  3.1929e-06,  9.5710e-05,  1.0811e-04, -1.7598e-04,\n",
            "        -4.2157e-06,  9.3522e-05,  3.3519e-05, -2.5532e-04, -1.9190e-05,\n",
            "        -8.4726e-06, -2.0727e-05,  1.2369e-04,  1.8209e-04,  1.3868e-04,\n",
            "         2.4925e-05, -3.1541e-04,  1.1066e-04, -5.2054e-05,  6.1903e-05,\n",
            "         1.2656e-04,  2.0213e-04,  2.6728e-04, -2.1157e-04,  1.8377e-04,\n",
            "        -1.2600e-04, -3.0495e-06, -4.1716e-05, -1.7135e-04, -1.9231e-04,\n",
            "         2.5332e-04,  3.1182e-04,  2.4636e-04,  9.2775e-05, -1.3807e-04,\n",
            "        -7.6252e-05, -2.9495e-05,  3.8323e-06,  1.0409e-04,  1.6578e-04,\n",
            "        -1.9985e-04, -2.0209e-04, -1.3213e-04, -1.3421e-04, -1.7647e-04,\n",
            "        -3.6899e-06,  1.0930e-04, -7.7323e-05, -3.1139e-04,  3.9440e-05,\n",
            "        -1.8491e-04,  1.2984e-04, -2.3286e-04, -2.4493e-04,  2.3870e-04,\n",
            "         8.7299e-05,  1.8353e-05,  3.5506e-05, -1.4431e-04,  4.6974e-05,\n",
            "        -1.5993e-04,  6.0209e-05, -1.4752e-04,  1.2856e-04, -1.3602e-04,\n",
            "         5.2275e-05, -7.9132e-05, -6.9865e-06, -2.6628e-04,  1.2617e-04,\n",
            "         1.1967e-04, -1.8599e-05, -2.1864e-04,  1.4220e-04, -2.5105e-04,\n",
            "         7.0271e-05, -2.2186e-04, -3.9167e-04,  4.9259e-04, -9.2944e-05,\n",
            "         6.1458e-05, -1.6625e-04, -1.0030e-04, -8.5293e-06,  3.5790e-05,\n",
            "        -9.8236e-05,  1.4542e-04, -4.6004e-05,  1.3370e-04, -1.7126e-04,\n",
            "        -1.1603e-04])}, 117: {'momentum_buffer': tensor([[[[-1.1824e-05]],\n",
            "\n",
            "         [[ 2.2322e-05]],\n",
            "\n",
            "         [[-1.8071e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2405e-04]],\n",
            "\n",
            "         [[-6.3642e-05]],\n",
            "\n",
            "         [[ 2.3304e-06]]],\n",
            "\n",
            "\n",
            "        [[[-1.8493e-04]],\n",
            "\n",
            "         [[-4.9263e-05]],\n",
            "\n",
            "         [[ 2.7419e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7961e-05]],\n",
            "\n",
            "         [[-1.8953e-04]],\n",
            "\n",
            "         [[-4.3092e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5785e-04]],\n",
            "\n",
            "         [[-1.3445e-04]],\n",
            "\n",
            "         [[-1.5649e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3426e-04]],\n",
            "\n",
            "         [[-1.6123e-06]],\n",
            "\n",
            "         [[-2.0328e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.6672e-05]],\n",
            "\n",
            "         [[ 4.6534e-05]],\n",
            "\n",
            "         [[-2.6781e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7978e-04]],\n",
            "\n",
            "         [[-1.2907e-04]],\n",
            "\n",
            "         [[ 1.9008e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 4.3702e-05]],\n",
            "\n",
            "         [[-1.6207e-04]],\n",
            "\n",
            "         [[-5.7898e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7137e-05]],\n",
            "\n",
            "         [[ 1.1175e-04]],\n",
            "\n",
            "         [[-1.7640e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0979e-04]],\n",
            "\n",
            "         [[-2.8117e-05]],\n",
            "\n",
            "         [[ 9.1338e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5236e-06]],\n",
            "\n",
            "         [[ 1.5353e-05]],\n",
            "\n",
            "         [[-1.5545e-04]]]])}, 118: {'momentum_buffer': tensor([0.0010, 0.0008, 0.0009,  ..., 0.0009, 0.0010, 0.0010])}, 119: {'momentum_buffer': tensor([ 3.7887e-05, -7.8210e-05,  1.4036e-06,  ...,  2.5375e-05,\n",
            "        -4.3997e-06,  2.0972e-05])}, 120: {'momentum_buffer': tensor([[[[-1.1301e-04]],\n",
            "\n",
            "         [[ 1.9871e-04]],\n",
            "\n",
            "         [[ 5.9120e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2304e-04]],\n",
            "\n",
            "         [[ 1.0156e-04]],\n",
            "\n",
            "         [[ 2.8457e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.0405e-05]],\n",
            "\n",
            "         [[-3.5490e-05]],\n",
            "\n",
            "         [[ 5.2166e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3818e-04]],\n",
            "\n",
            "         [[ 1.5700e-04]],\n",
            "\n",
            "         [[-1.1796e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.4889e-05]],\n",
            "\n",
            "         [[ 1.0090e-04]],\n",
            "\n",
            "         [[-4.5488e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0701e-05]],\n",
            "\n",
            "         [[-1.3884e-04]],\n",
            "\n",
            "         [[ 6.5460e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.9673e-05]],\n",
            "\n",
            "         [[ 3.3546e-05]],\n",
            "\n",
            "         [[ 1.4880e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.0839e-05]],\n",
            "\n",
            "         [[ 2.7195e-04]],\n",
            "\n",
            "         [[-1.4846e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3366e-05]],\n",
            "\n",
            "         [[-2.1802e-04]],\n",
            "\n",
            "         [[ 1.7769e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9244e-05]],\n",
            "\n",
            "         [[-5.0339e-05]],\n",
            "\n",
            "         [[-9.3934e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8869e-05]],\n",
            "\n",
            "         [[-3.2377e-06]],\n",
            "\n",
            "         [[-9.2077e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6177e-04]],\n",
            "\n",
            "         [[-1.1333e-05]],\n",
            "\n",
            "         [[-7.4384e-05]]]])}, 121: {'momentum_buffer': tensor([0.0012, 0.0009, 0.0008, 0.0009, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010,\n",
            "        0.0009, 0.0008, 0.0014, 0.0011, 0.0011, 0.0012, 0.0008, 0.0007, 0.0011,\n",
            "        0.0010, 0.0010, 0.0015, 0.0009, 0.0012, 0.0012, 0.0010, 0.0010, 0.0012,\n",
            "        0.0012, 0.0013, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0011,\n",
            "        0.0009, 0.0010, 0.0008, 0.0011, 0.0008, 0.0010, 0.0010, 0.0012, 0.0011,\n",
            "        0.0009, 0.0011, 0.0009, 0.0010, 0.0010, 0.0009, 0.0013, 0.0009, 0.0009,\n",
            "        0.0012, 0.0011, 0.0010, 0.0009, 0.0006, 0.0009, 0.0011, 0.0009, 0.0009,\n",
            "        0.0008, 0.0010, 0.0010, 0.0009, 0.0009, 0.0008, 0.0006, 0.0011, 0.0011,\n",
            "        0.0012, 0.0009, 0.0011, 0.0008, 0.0008, 0.0009, 0.0011, 0.0011, 0.0008,\n",
            "        0.0012, 0.0006, 0.0011, 0.0007, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0008, 0.0012, 0.0009, 0.0012, 0.0009, 0.0009, 0.0012, 0.0011,\n",
            "        0.0008, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0008, 0.0010, 0.0012,\n",
            "        0.0012, 0.0010, 0.0009, 0.0008, 0.0012, 0.0011, 0.0009, 0.0011, 0.0008,\n",
            "        0.0009, 0.0008, 0.0012, 0.0011, 0.0011, 0.0009, 0.0010, 0.0009, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0006, 0.0007, 0.0008, 0.0006,\n",
            "        0.0011, 0.0007, 0.0009, 0.0009, 0.0009, 0.0009, 0.0008, 0.0013, 0.0012,\n",
            "        0.0011, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0011,\n",
            "        0.0012, 0.0009, 0.0010, 0.0010, 0.0007, 0.0011, 0.0010, 0.0011, 0.0011,\n",
            "        0.0007, 0.0009, 0.0011, 0.0008, 0.0008, 0.0008, 0.0011, 0.0013, 0.0010,\n",
            "        0.0011, 0.0012, 0.0010, 0.0007, 0.0010, 0.0009, 0.0013, 0.0010, 0.0010,\n",
            "        0.0013, 0.0006, 0.0012, 0.0011, 0.0010, 0.0009, 0.0009, 0.0010, 0.0013,\n",
            "        0.0010, 0.0012, 0.0010, 0.0008, 0.0010, 0.0009, 0.0009, 0.0010, 0.0011,\n",
            "        0.0009, 0.0010, 0.0013, 0.0010, 0.0009, 0.0009, 0.0007, 0.0010, 0.0010,\n",
            "        0.0009, 0.0009, 0.0009, 0.0013, 0.0013, 0.0010, 0.0011, 0.0008, 0.0009,\n",
            "        0.0008, 0.0009, 0.0009, 0.0010, 0.0008, 0.0010, 0.0009, 0.0010, 0.0009,\n",
            "        0.0014, 0.0011, 0.0009, 0.0011, 0.0010, 0.0011, 0.0010, 0.0008, 0.0010,\n",
            "        0.0013, 0.0014, 0.0011, 0.0008, 0.0009, 0.0012, 0.0008, 0.0011, 0.0011,\n",
            "        0.0009, 0.0010, 0.0009, 0.0008, 0.0009, 0.0011, 0.0007, 0.0010, 0.0010,\n",
            "        0.0012, 0.0010, 0.0010, 0.0007])}, 122: {'momentum_buffer': tensor([ 1.4088e-04, -1.6249e-04, -1.8606e-04, -1.0456e-04,  1.1324e-04,\n",
            "        -1.5756e-04,  1.0680e-04, -1.4205e-04, -1.9182e-04, -2.5517e-04,\n",
            "        -2.1806e-04,  1.0615e-04, -1.4565e-04, -4.2699e-05,  3.4473e-04,\n",
            "         1.0515e-05, -3.7814e-05,  1.7033e-05,  7.3016e-05, -5.9307e-05,\n",
            "         2.7535e-05, -2.2804e-04,  2.1382e-04,  2.0522e-05, -1.5925e-04,\n",
            "         3.0324e-05,  4.4762e-05, -7.0834e-05,  2.7191e-04,  1.6276e-04,\n",
            "        -3.4522e-05, -3.1053e-04,  3.0392e-05,  2.6985e-05, -3.8340e-05,\n",
            "         5.9518e-05, -3.7418e-05, -7.9533e-07, -2.1045e-04,  2.7035e-04,\n",
            "        -8.2611e-05, -1.0670e-04,  6.0626e-05, -5.1661e-05, -1.5911e-04,\n",
            "        -9.2591e-05,  4.5793e-06, -3.8513e-05, -1.9023e-04, -7.2097e-05,\n",
            "         7.1264e-05,  6.9246e-05, -4.6955e-05, -2.5172e-05,  1.7209e-04,\n",
            "         5.5478e-05, -6.4584e-05, -1.2931e-04, -3.9621e-04, -3.8239e-04,\n",
            "         3.2146e-04, -9.4427e-05, -2.3666e-04,  1.1899e-05,  2.3229e-04,\n",
            "         4.3895e-05, -6.8818e-05, -1.8903e-04, -1.7632e-04, -2.7771e-04,\n",
            "         7.2111e-05,  4.3240e-05, -8.1313e-05,  8.7588e-06,  5.7601e-05,\n",
            "         4.7885e-05,  9.5359e-05, -2.0701e-04,  1.1987e-04,  1.5475e-04,\n",
            "        -1.4640e-04,  2.6385e-04, -2.4086e-04, -1.5387e-04, -2.6121e-04,\n",
            "         6.0488e-05, -7.8013e-05,  1.1159e-04, -2.4687e-04,  1.7805e-05,\n",
            "         1.2932e-04,  9.2957e-05,  1.7646e-04, -2.9012e-05, -4.7153e-05,\n",
            "         1.0408e-04, -3.9203e-05,  2.0473e-04,  3.8114e-05, -1.2862e-04,\n",
            "        -2.8460e-05, -2.2025e-04, -2.8565e-05, -7.1943e-05, -2.5660e-05,\n",
            "        -4.0066e-05,  3.5405e-05,  2.6754e-05,  2.3734e-04,  1.1893e-04,\n",
            "        -1.2851e-04, -2.1179e-04,  2.4427e-04,  2.0229e-04,  3.0673e-05,\n",
            "         1.6241e-04,  3.4945e-05,  6.0376e-05, -7.6333e-05,  3.5145e-04,\n",
            "        -2.1175e-05,  1.4175e-04, -1.5703e-04, -1.6139e-04, -5.5019e-05,\n",
            "         1.4871e-04, -1.2168e-04,  2.2708e-05,  7.1153e-05,  9.0709e-05,\n",
            "         8.0529e-05, -2.0277e-04, -1.0806e-04, -4.0725e-05, -2.6849e-04,\n",
            "        -4.6579e-05, -1.2550e-04, -4.8444e-05,  1.2441e-04, -1.7850e-04,\n",
            "        -1.8660e-04, -3.0153e-04,  1.9989e-04,  1.0908e-04,  1.5398e-04,\n",
            "        -4.0730e-06,  2.9096e-05, -2.0434e-05,  4.8493e-05,  1.1836e-04,\n",
            "         2.1370e-04,  1.3577e-05, -1.8963e-05,  8.1312e-05, -6.7845e-05,\n",
            "         1.8442e-05, -1.7667e-04, -1.2940e-04,  1.1918e-04, -7.1901e-05,\n",
            "         1.0520e-05, -1.1464e-04, -2.7507e-04, -1.4169e-04, -2.3127e-04,\n",
            "        -3.8310e-04,  8.5374e-05, -2.0224e-04,  7.6536e-05,  9.3366e-05,\n",
            "        -7.0778e-05,  6.3197e-05,  3.1302e-04,  1.4031e-04, -8.0621e-05,\n",
            "         9.0289e-05,  9.1187e-05,  1.3786e-04, -2.0165e-04, -1.4037e-04,\n",
            "         2.2290e-04, -5.0894e-04, -2.6158e-05,  1.8956e-04, -8.1963e-05,\n",
            "        -3.4459e-05,  1.6813e-04,  1.7934e-04,  1.0258e-04,  7.5478e-05,\n",
            "         4.0291e-04, -2.3276e-05, -4.4641e-05, -2.3915e-05, -1.1158e-04,\n",
            "        -1.9023e-05,  4.2395e-05,  7.0058e-05, -7.5590e-05, -8.9647e-05,\n",
            "         9.1083e-05, -1.2024e-05, -1.9904e-04, -4.6608e-05, -2.3503e-04,\n",
            "        -8.3728e-05, -1.8610e-05, -3.3289e-05,  6.4762e-06,  2.3433e-04,\n",
            "         1.8816e-04,  1.7342e-04,  1.2614e-04,  8.1183e-05, -8.5450e-06,\n",
            "         2.5902e-05, -1.8167e-04,  8.9198e-05, -4.4593e-05, -2.5219e-04,\n",
            "        -6.9349e-05,  5.9640e-05,  1.0911e-06,  9.5905e-06,  7.6209e-05,\n",
            "         3.2468e-04,  1.9612e-05, -1.1038e-04,  1.5058e-04, -3.2500e-05,\n",
            "        -3.8248e-05,  9.2681e-05,  6.7258e-05,  7.9915e-05,  3.4014e-04,\n",
            "         3.4202e-05,  1.7861e-04, -1.0983e-04, -1.0267e-04, -1.0814e-04,\n",
            "        -2.7814e-04, -2.2567e-05, -3.9777e-05, -2.6931e-04,  3.4477e-05,\n",
            "        -1.4297e-04, -1.3894e-04, -4.7413e-05,  1.5954e-04, -1.5845e-04,\n",
            "        -9.0433e-05, -1.0559e-04,  1.7184e-04,  1.3430e-04,  7.0787e-05,\n",
            "        -8.6479e-05])}, 123: {'momentum_buffer': tensor([[[[ 1.6612e-04,  8.7213e-05,  2.8039e-04],\n",
            "          [ 1.1725e-04,  2.3355e-04,  1.1122e-04],\n",
            "          [-8.9550e-05,  2.4525e-04, -1.4140e-06]],\n",
            "\n",
            "         [[ 3.0409e-05, -2.3158e-05,  4.5023e-05],\n",
            "          [ 3.0041e-04, -5.6806e-06, -2.7916e-04],\n",
            "          [ 1.1280e-04,  2.3839e-05,  2.0279e-04]],\n",
            "\n",
            "         [[-6.4809e-05, -1.1475e-05, -2.2086e-05],\n",
            "          [-9.6061e-05,  1.0398e-04, -8.3203e-05],\n",
            "          [ 4.7363e-05,  7.5175e-05,  1.3715e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7086e-05,  7.2313e-05, -8.7505e-05],\n",
            "          [-4.5441e-05,  1.1938e-05, -5.0987e-05],\n",
            "          [ 9.2328e-07,  1.0817e-05,  2.7214e-05]],\n",
            "\n",
            "         [[-7.2698e-06,  8.6242e-07, -1.9407e-06],\n",
            "          [ 7.2770e-05,  4.1038e-05, -1.1652e-05],\n",
            "          [-7.9698e-05,  7.4935e-05, -4.3034e-06]],\n",
            "\n",
            "         [[-1.1279e-04, -9.9404e-06, -1.5601e-04],\n",
            "          [-6.3980e-05, -1.6203e-05,  9.5504e-05],\n",
            "          [ 3.4992e-05,  9.3885e-06, -1.6893e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.0110e-05, -1.8219e-04, -3.1278e-04],\n",
            "          [-8.6310e-05, -1.3975e-04, -1.0467e-04],\n",
            "          [-1.0492e-04,  1.2156e-04, -3.6880e-05]],\n",
            "\n",
            "         [[-1.2965e-04, -7.4783e-05, -7.9734e-05],\n",
            "          [ 1.9601e-05,  5.0970e-05,  9.6624e-05],\n",
            "          [-1.3205e-04,  1.6013e-04, -1.3916e-04]],\n",
            "\n",
            "         [[ 1.4858e-04,  7.1393e-06, -1.3342e-04],\n",
            "          [ 2.4987e-05, -1.5677e-04, -7.3798e-06],\n",
            "          [ 1.4309e-04,  5.8796e-05, -2.4807e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2776e-04, -2.8328e-04, -1.3510e-04],\n",
            "          [ 1.0700e-05, -2.9858e-04, -2.3499e-04],\n",
            "          [-1.6100e-04, -2.3876e-04, -1.0459e-04]],\n",
            "\n",
            "         [[ 3.0074e-05,  8.6306e-06, -1.7582e-06],\n",
            "          [-1.7683e-05,  8.1398e-06, -4.7301e-06],\n",
            "          [ 2.5561e-05, -1.1451e-04, -1.0888e-04]],\n",
            "\n",
            "         [[ 3.5437e-05, -7.3245e-05, -6.9545e-05],\n",
            "          [ 7.1033e-05,  2.1519e-04,  2.4520e-04],\n",
            "          [ 2.3921e-04,  2.6623e-04,  9.6300e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.0875e-05, -1.3461e-04,  2.8878e-05],\n",
            "          [-2.8479e-05, -1.1972e-04, -1.2628e-04],\n",
            "          [-1.5703e-04, -3.2883e-05, -8.6399e-05]],\n",
            "\n",
            "         [[-8.8019e-05, -1.5175e-04, -5.8460e-05],\n",
            "          [-5.8779e-06, -4.2311e-05,  6.2979e-05],\n",
            "          [-1.7693e-05,  6.8254e-05, -5.7951e-05]],\n",
            "\n",
            "         [[ 4.6828e-05,  7.9183e-05,  1.2274e-05],\n",
            "          [ 5.3255e-05, -9.4945e-05, -1.0668e-04],\n",
            "          [ 1.3128e-04, -7.7402e-05,  1.5564e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5360e-05,  1.5832e-04, -5.2102e-05],\n",
            "          [ 2.6376e-04,  1.4433e-04, -2.8839e-05],\n",
            "          [ 4.2829e-05,  1.7447e-04, -1.2442e-04]],\n",
            "\n",
            "         [[ 6.3107e-05,  2.1917e-05, -4.1231e-05],\n",
            "          [ 4.1619e-06,  9.3439e-05, -1.1922e-04],\n",
            "          [-3.2467e-05, -8.7056e-05, -6.5850e-05]],\n",
            "\n",
            "         [[ 7.3111e-05, -7.8512e-06,  3.1905e-05],\n",
            "          [-1.6175e-04, -1.6805e-06, -1.5250e-04],\n",
            "          [ 9.1954e-05,  3.3116e-05,  3.9313e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.5028e-04,  1.5343e-04,  1.3824e-04],\n",
            "          [-9.7585e-05, -1.0854e-04, -3.5337e-05],\n",
            "          [-1.6164e-04, -1.0280e-04,  2.2153e-05]],\n",
            "\n",
            "         [[-1.0040e-04,  1.7011e-05, -5.5639e-05],\n",
            "          [-1.2063e-04,  6.0439e-05, -4.1758e-05],\n",
            "          [-2.4013e-04,  2.8480e-06, -3.7152e-05]],\n",
            "\n",
            "         [[ 1.3324e-05, -9.6592e-05, -4.0310e-05],\n",
            "          [-6.9627e-05, -5.8883e-06, -8.6450e-05],\n",
            "          [-1.7169e-04, -9.6989e-05, -1.0326e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.1870e-05, -9.5204e-05, -9.7995e-05],\n",
            "          [-8.8186e-05,  9.7038e-05, -3.3531e-05],\n",
            "          [-2.4904e-04, -7.0724e-05, -4.7004e-05]],\n",
            "\n",
            "         [[-6.8503e-05,  3.8073e-05,  5.5263e-05],\n",
            "          [ 7.7493e-06,  8.3812e-05,  8.7713e-05],\n",
            "          [-3.7090e-05,  9.0713e-05, -3.4397e-05]],\n",
            "\n",
            "         [[-8.8558e-05, -7.7329e-05, -1.6202e-04],\n",
            "          [-3.4892e-05,  5.9029e-06, -3.9190e-05],\n",
            "          [-9.3610e-05, -1.3765e-04, -9.7874e-05]]],\n",
            "\n",
            "\n",
            "        [[[-7.6791e-05, -8.8962e-05,  4.0822e-05],\n",
            "          [-6.7793e-06,  6.8489e-05,  1.7006e-05],\n",
            "          [-1.6717e-04, -1.3989e-04, -8.3513e-05]],\n",
            "\n",
            "         [[ 9.9425e-05,  9.5415e-05, -5.0192e-06],\n",
            "          [-6.9615e-05,  8.0201e-05,  8.2605e-05],\n",
            "          [ 3.4327e-05, -1.3918e-04,  5.4701e-08]],\n",
            "\n",
            "         [[ 9.1485e-05,  5.2539e-05,  5.0072e-05],\n",
            "          [ 1.2196e-04,  9.6272e-05, -2.1865e-05],\n",
            "          [ 8.6337e-05, -2.2378e-05, -4.4599e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2536e-05,  1.5987e-05, -1.0444e-05],\n",
            "          [-8.0884e-05,  6.8027e-05, -4.4342e-05],\n",
            "          [-2.2005e-05,  2.3546e-05,  5.8759e-05]],\n",
            "\n",
            "         [[ 6.8894e-05, -4.1186e-05,  1.2595e-05],\n",
            "          [ 1.3744e-05,  4.5716e-05, -7.0734e-05],\n",
            "          [ 7.8787e-05,  6.4670e-06, -2.0580e-07]],\n",
            "\n",
            "         [[-8.4401e-06,  4.9169e-05,  1.2125e-05],\n",
            "          [ 5.2538e-05, -4.0519e-05,  3.3081e-05],\n",
            "          [-1.6812e-04, -5.5092e-05, -8.9195e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5519e-05, -4.4009e-05, -9.3520e-05],\n",
            "          [ 3.5159e-05, -6.3908e-05, -1.6100e-05],\n",
            "          [-6.0224e-05, -6.9860e-05,  3.4387e-06]],\n",
            "\n",
            "         [[ 5.4339e-05, -6.3786e-05,  3.3259e-07],\n",
            "          [-3.2572e-05, -6.5312e-05, -5.2070e-05],\n",
            "          [-6.7773e-05,  7.0522e-06, -1.5074e-04]],\n",
            "\n",
            "         [[ 4.6078e-05,  1.8864e-04, -5.9353e-06],\n",
            "          [ 8.2269e-05,  3.8048e-05,  8.6298e-05],\n",
            "          [-9.3218e-05,  8.1906e-05, -2.9176e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.1313e-05, -8.8769e-05, -3.6707e-05],\n",
            "          [ 1.0785e-04,  9.4889e-05,  1.1296e-04],\n",
            "          [-6.8699e-05,  9.9319e-05, -3.8761e-05]],\n",
            "\n",
            "         [[ 5.0205e-05, -7.1264e-05, -8.4776e-06],\n",
            "          [-1.4637e-05, -4.0833e-05,  1.3649e-05],\n",
            "          [-4.8044e-05, -7.3938e-05, -1.1769e-04]],\n",
            "\n",
            "         [[-2.5314e-04, -1.3583e-04, -7.2566e-05],\n",
            "          [-2.5652e-04, -8.5906e-05,  9.3874e-05],\n",
            "          [-6.2576e-05, -4.2142e-05, -3.2592e-05]]]])}, 124: {'momentum_buffer': tensor([0.0011, 0.0011, 0.0012, 0.0010, 0.0010, 0.0009, 0.0008, 0.0011, 0.0009,\n",
            "        0.0009, 0.0008, 0.0010, 0.0008, 0.0010, 0.0008, 0.0011, 0.0010, 0.0007,\n",
            "        0.0009, 0.0010, 0.0009, 0.0011, 0.0011, 0.0009, 0.0010, 0.0012, 0.0010,\n",
            "        0.0008, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0011, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0008, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0012,\n",
            "        0.0011, 0.0009, 0.0012, 0.0013, 0.0010, 0.0011, 0.0008, 0.0009, 0.0010,\n",
            "        0.0009, 0.0012, 0.0011, 0.0009, 0.0009, 0.0013, 0.0011, 0.0010, 0.0013,\n",
            "        0.0009, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0012, 0.0011,\n",
            "        0.0012, 0.0010, 0.0007, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009,\n",
            "        0.0010, 0.0011, 0.0009, 0.0009, 0.0011, 0.0010, 0.0012, 0.0009, 0.0011,\n",
            "        0.0008, 0.0010, 0.0006, 0.0010, 0.0013, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0011, 0.0011, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0011, 0.0008, 0.0011, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0011, 0.0010, 0.0012, 0.0010, 0.0010, 0.0013, 0.0009,\n",
            "        0.0009, 0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0008, 0.0011, 0.0012,\n",
            "        0.0011, 0.0009, 0.0010, 0.0009, 0.0008, 0.0012, 0.0009, 0.0010, 0.0010,\n",
            "        0.0009, 0.0009, 0.0008, 0.0010, 0.0008, 0.0010, 0.0010, 0.0012, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0008, 0.0010, 0.0008, 0.0007,\n",
            "        0.0009, 0.0008, 0.0009, 0.0008, 0.0011, 0.0011, 0.0012, 0.0011, 0.0009,\n",
            "        0.0009, 0.0012, 0.0009, 0.0011, 0.0010, 0.0012, 0.0008, 0.0010, 0.0013,\n",
            "        0.0010, 0.0013, 0.0011, 0.0006, 0.0009, 0.0009, 0.0011, 0.0009, 0.0011,\n",
            "        0.0011, 0.0010, 0.0007, 0.0010, 0.0012, 0.0013, 0.0008, 0.0008, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0012, 0.0009, 0.0011, 0.0010, 0.0011, 0.0008, 0.0008, 0.0010,\n",
            "        0.0009, 0.0012, 0.0010, 0.0006, 0.0010, 0.0010, 0.0010, 0.0009, 0.0007,\n",
            "        0.0007, 0.0011, 0.0008, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0011, 0.0008, 0.0011,\n",
            "        0.0011, 0.0009, 0.0011, 0.0009])}, 125: {'momentum_buffer': tensor([ 7.5809e-05,  8.6883e-05,  2.4732e-04, -1.1018e-04, -1.0208e-04,\n",
            "         2.4956e-05,  2.2262e-05,  3.3394e-05, -4.7250e-06, -8.5902e-05,\n",
            "        -1.4665e-05, -8.3410e-05, -4.5348e-05, -1.5832e-04, -2.3366e-04,\n",
            "         5.9653e-05,  4.8599e-05, -2.4306e-04, -2.5590e-05,  7.6478e-05,\n",
            "        -1.2726e-04,  3.4869e-05,  4.1507e-05,  5.7631e-05,  5.2045e-05,\n",
            "        -2.7977e-06,  5.9710e-06, -1.7144e-04,  1.1607e-04,  8.0913e-05,\n",
            "         3.6621e-05,  3.7524e-05, -1.6292e-04, -3.1054e-05, -2.6463e-05,\n",
            "         1.0697e-04, -1.3939e-05, -1.6061e-04, -2.9335e-05, -1.2115e-04,\n",
            "        -5.4745e-05, -2.5589e-04,  3.3994e-05,  8.2612e-06,  2.6703e-04,\n",
            "         1.3773e-04, -1.6370e-04,  2.3365e-04,  9.5600e-06,  1.8915e-06,\n",
            "         2.4683e-04, -6.0242e-05, -1.3296e-04,  9.4501e-05,  1.0851e-04,\n",
            "         1.1956e-04,  4.8491e-05, -1.3692e-04, -3.2230e-05, -1.0698e-04,\n",
            "         2.4099e-04, -1.0310e-04,  1.3932e-04,  2.8147e-04, -6.3249e-05,\n",
            "         9.6136e-05, -6.7419e-05,  4.3961e-05, -1.8279e-04, -1.4165e-04,\n",
            "        -3.8737e-05, -8.4054e-05,  1.7406e-04, -6.0649e-05, -2.4811e-04,\n",
            "        -1.1578e-05, -9.1363e-05, -6.2078e-05,  1.1695e-04,  5.3581e-06,\n",
            "        -1.4576e-04,  1.0092e-04,  6.4602e-05, -5.4757e-05,  1.9621e-05,\n",
            "         1.2239e-04,  1.5272e-05,  1.5518e-04, -2.1014e-04, -9.6380e-05,\n",
            "        -2.5825e-04, -6.9806e-05, -1.9330e-04,  3.0832e-05,  1.5834e-04,\n",
            "         7.7813e-05, -5.0599e-05, -2.4483e-04, -1.2205e-04, -1.8679e-04,\n",
            "         1.9493e-04,  1.2926e-04, -4.4428e-06, -1.5632e-04, -3.2767e-06,\n",
            "         9.8057e-05,  9.2514e-05, -8.4162e-05,  1.3600e-06, -9.6065e-05,\n",
            "         4.6336e-05,  9.9860e-05, -7.2864e-05,  3.2098e-05, -4.9013e-05,\n",
            "         4.8345e-06, -2.2665e-05,  4.2255e-05, -9.0118e-05, -2.4650e-05,\n",
            "         1.1387e-04,  1.0387e-04, -3.4947e-04,  1.3360e-05,  1.1761e-04,\n",
            "         1.1942e-04, -3.8384e-06, -6.2640e-05, -1.4125e-05, -7.2412e-05,\n",
            "         2.9900e-04,  1.0509e-04, -1.1158e-04,  1.1477e-04, -2.3993e-04,\n",
            "        -5.8786e-05, -8.6444e-05,  5.4511e-05, -1.4970e-04, -1.0548e-04,\n",
            "         7.1401e-06, -2.0625e-04,  2.0524e-04,  1.4152e-04, -3.0518e-05,\n",
            "        -1.5158e-04,  1.2427e-04, -8.1992e-05, -1.2360e-04,  3.4682e-04,\n",
            "        -2.3886e-04,  1.5193e-04,  1.1945e-04, -2.2309e-04,  2.8965e-05,\n",
            "        -6.9824e-05,  1.4751e-04, -1.6951e-04, -1.0711e-04,  3.4152e-05,\n",
            "         1.9528e-04, -1.1288e-04,  2.1403e-04, -1.8355e-04,  1.1772e-04,\n",
            "         1.1310e-04, -6.7117e-05, -1.5838e-04, -4.3158e-05, -2.8066e-04,\n",
            "         9.4793e-05, -1.0809e-04, -1.3869e-05, -9.6321e-06, -6.2360e-06,\n",
            "         6.4377e-06,  3.6933e-06,  2.2776e-04,  1.7182e-04,  2.8635e-05,\n",
            "         9.6006e-06,  4.7062e-05,  1.0644e-04, -1.1043e-04,  6.2709e-05,\n",
            "         1.1486e-04, -1.7113e-04,  8.2701e-05,  2.0355e-04,  9.7217e-05,\n",
            "         8.8459e-05,  1.6786e-04, -2.2227e-04, -4.9993e-06, -2.1799e-07,\n",
            "        -8.8759e-05,  1.6116e-06,  5.5875e-05,  7.2434e-05,  2.0484e-05,\n",
            "        -2.0132e-04,  6.9787e-05,  9.4006e-05,  2.0513e-05, -1.6862e-04,\n",
            "         2.6411e-05, -5.1126e-05, -1.1449e-04,  1.0667e-04,  9.8418e-05,\n",
            "         1.4757e-04, -1.0520e-04,  4.0912e-05, -6.3768e-05, -7.2138e-05,\n",
            "         1.3107e-04, -1.3798e-05,  1.8501e-04, -7.3945e-05,  1.7726e-04,\n",
            "         8.6377e-06,  2.6563e-05, -1.2585e-04,  1.1209e-04, -1.5856e-04,\n",
            "        -9.8043e-05,  8.9561e-05,  9.3637e-05, -2.8497e-04,  1.5356e-05,\n",
            "         8.2301e-05, -4.4651e-05,  3.5493e-05, -1.4126e-05, -1.6844e-04,\n",
            "         7.9164e-05, -1.7766e-04, -4.0143e-05,  6.3209e-05, -2.3255e-05,\n",
            "        -2.5866e-04,  2.6918e-05,  8.3191e-05,  1.7657e-04, -1.3444e-04,\n",
            "         7.1233e-05,  1.8080e-05, -7.2265e-05,  1.9836e-04, -1.1599e-04,\n",
            "        -1.6138e-04, -4.1699e-06, -9.3731e-05,  5.4984e-05,  1.0621e-04,\n",
            "         1.3243e-04])}, 126: {'momentum_buffer': tensor([[[[-2.9627e-05]],\n",
            "\n",
            "         [[-6.8448e-05]],\n",
            "\n",
            "         [[-1.4330e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.0808e-05]],\n",
            "\n",
            "         [[-7.8370e-05]],\n",
            "\n",
            "         [[ 6.3163e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 3.2111e-05]],\n",
            "\n",
            "         [[ 1.0349e-04]],\n",
            "\n",
            "         [[ 5.8353e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9903e-05]],\n",
            "\n",
            "         [[-8.5792e-05]],\n",
            "\n",
            "         [[-1.9357e-04]]],\n",
            "\n",
            "\n",
            "        [[[-2.3564e-05]],\n",
            "\n",
            "         [[-9.1938e-05]],\n",
            "\n",
            "         [[-3.0535e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2669e-05]],\n",
            "\n",
            "         [[-1.7987e-05]],\n",
            "\n",
            "         [[-1.2778e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.6868e-04]],\n",
            "\n",
            "         [[-2.8231e-06]],\n",
            "\n",
            "         [[-1.6200e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5076e-05]],\n",
            "\n",
            "         [[-1.3212e-05]],\n",
            "\n",
            "         [[-1.2318e-04]]],\n",
            "\n",
            "\n",
            "        [[[-3.9388e-05]],\n",
            "\n",
            "         [[ 2.4261e-04]],\n",
            "\n",
            "         [[ 5.9389e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1978e-04]],\n",
            "\n",
            "         [[ 1.7334e-05]],\n",
            "\n",
            "         [[ 2.5029e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.1068e-04]],\n",
            "\n",
            "         [[-3.0225e-05]],\n",
            "\n",
            "         [[-1.8158e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0368e-05]],\n",
            "\n",
            "         [[ 2.2355e-05]],\n",
            "\n",
            "         [[ 1.2970e-05]]]])}, 127: {'momentum_buffer': tensor([0.0010, 0.0009, 0.0010,  ..., 0.0010, 0.0010, 0.0010])}, 128: {'momentum_buffer': tensor([ 4.3908e-05, -7.1717e-05,  2.4065e-06,  ...,  2.2908e-05,\n",
            "         1.0660e-05,  3.4897e-07])}, 129: {'momentum_buffer': tensor([[[[-6.7091e-05]],\n",
            "\n",
            "         [[ 4.9035e-05]],\n",
            "\n",
            "         [[ 4.7757e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.9335e-05]],\n",
            "\n",
            "         [[-4.9527e-06]],\n",
            "\n",
            "         [[-1.5859e-04]]],\n",
            "\n",
            "\n",
            "        [[[-7.1871e-05]],\n",
            "\n",
            "         [[-3.2485e-05]],\n",
            "\n",
            "         [[-1.4374e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.9199e-05]],\n",
            "\n",
            "         [[ 1.4268e-04]],\n",
            "\n",
            "         [[ 1.1850e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 7.6216e-05]],\n",
            "\n",
            "         [[-9.7551e-05]],\n",
            "\n",
            "         [[-9.4499e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.3411e-05]],\n",
            "\n",
            "         [[ 1.7526e-04]],\n",
            "\n",
            "         [[ 3.4494e-06]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.6887e-06]],\n",
            "\n",
            "         [[-5.7269e-05]],\n",
            "\n",
            "         [[ 6.7472e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3817e-04]],\n",
            "\n",
            "         [[ 2.0646e-04]],\n",
            "\n",
            "         [[-1.7001e-04]]],\n",
            "\n",
            "\n",
            "        [[[-9.9917e-06]],\n",
            "\n",
            "         [[-7.0922e-05]],\n",
            "\n",
            "         [[-8.7681e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4799e-04]],\n",
            "\n",
            "         [[-9.3108e-05]],\n",
            "\n",
            "         [[-1.2198e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0959e-04]],\n",
            "\n",
            "         [[ 9.9173e-05]],\n",
            "\n",
            "         [[ 2.1025e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9890e-05]],\n",
            "\n",
            "         [[ 2.2767e-04]],\n",
            "\n",
            "         [[-2.4237e-05]]]])}, 130: {'momentum_buffer': tensor([0.0011, 0.0010, 0.0011, 0.0010, 0.0009, 0.0008, 0.0010, 0.0009, 0.0011,\n",
            "        0.0011, 0.0011, 0.0009, 0.0010, 0.0008, 0.0009, 0.0010, 0.0014, 0.0010,\n",
            "        0.0008, 0.0010, 0.0010, 0.0013, 0.0011, 0.0011, 0.0010, 0.0011, 0.0010,\n",
            "        0.0012, 0.0010, 0.0008, 0.0010, 0.0008, 0.0008, 0.0011, 0.0011, 0.0011,\n",
            "        0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0008, 0.0009,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009,\n",
            "        0.0011, 0.0010, 0.0012, 0.0012, 0.0010, 0.0010, 0.0010, 0.0010, 0.0007,\n",
            "        0.0009, 0.0009, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0012,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0007, 0.0009, 0.0012, 0.0011, 0.0011,\n",
            "        0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0008,\n",
            "        0.0010, 0.0009, 0.0010, 0.0012, 0.0011, 0.0008, 0.0013, 0.0008, 0.0013,\n",
            "        0.0010, 0.0009, 0.0011, 0.0008, 0.0010, 0.0008, 0.0009, 0.0011, 0.0010,\n",
            "        0.0011, 0.0011, 0.0007, 0.0009, 0.0011, 0.0009, 0.0009, 0.0007, 0.0009,\n",
            "        0.0009, 0.0011, 0.0012, 0.0014, 0.0007, 0.0010, 0.0011, 0.0010, 0.0009,\n",
            "        0.0010, 0.0009, 0.0007, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0013,\n",
            "        0.0010, 0.0008, 0.0011, 0.0012, 0.0010, 0.0008, 0.0011, 0.0010, 0.0013,\n",
            "        0.0008, 0.0011, 0.0013, 0.0010, 0.0008, 0.0009, 0.0010, 0.0008, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0011, 0.0009, 0.0010, 0.0012, 0.0010,\n",
            "        0.0009, 0.0010, 0.0012, 0.0009, 0.0011, 0.0009, 0.0010, 0.0008, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0011, 0.0007, 0.0012, 0.0010, 0.0009, 0.0010,\n",
            "        0.0011, 0.0011, 0.0010, 0.0011, 0.0014, 0.0008, 0.0011, 0.0011, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0011, 0.0009, 0.0010, 0.0011, 0.0007,\n",
            "        0.0011, 0.0012, 0.0011, 0.0010, 0.0010, 0.0009, 0.0012, 0.0010, 0.0012,\n",
            "        0.0008, 0.0012, 0.0010, 0.0009, 0.0011, 0.0010, 0.0008, 0.0012, 0.0009,\n",
            "        0.0009, 0.0010, 0.0011, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0012, 0.0008, 0.0011, 0.0009, 0.0007, 0.0010, 0.0009, 0.0009,\n",
            "        0.0008, 0.0011, 0.0008, 0.0010, 0.0009, 0.0008, 0.0010, 0.0010, 0.0008,\n",
            "        0.0011, 0.0009, 0.0008, 0.0009, 0.0010, 0.0011, 0.0010, 0.0013, 0.0009,\n",
            "        0.0011, 0.0010, 0.0008, 0.0011, 0.0010, 0.0012, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0008, 0.0010, 0.0011, 0.0011, 0.0010,\n",
            "        0.0008, 0.0009, 0.0011, 0.0011, 0.0012, 0.0011, 0.0009, 0.0010, 0.0009,\n",
            "        0.0007, 0.0010, 0.0012, 0.0009, 0.0008, 0.0010, 0.0009, 0.0011, 0.0009,\n",
            "        0.0008, 0.0010, 0.0009, 0.0012, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0008, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0012,\n",
            "        0.0012, 0.0011, 0.0011, 0.0009, 0.0013, 0.0009, 0.0009, 0.0010, 0.0010,\n",
            "        0.0011, 0.0009, 0.0009, 0.0012, 0.0012, 0.0009, 0.0010, 0.0010, 0.0009,\n",
            "        0.0008, 0.0009, 0.0010, 0.0007, 0.0009, 0.0010, 0.0011, 0.0013, 0.0011,\n",
            "        0.0008, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0011,\n",
            "        0.0010, 0.0007, 0.0009, 0.0010, 0.0010, 0.0010, 0.0012, 0.0010, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0008, 0.0010,\n",
            "        0.0007, 0.0011, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0010, 0.0008,\n",
            "        0.0011, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0009,\n",
            "        0.0010, 0.0012, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0011,\n",
            "        0.0010, 0.0008, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0007, 0.0010,\n",
            "        0.0012, 0.0011, 0.0008, 0.0010, 0.0010, 0.0010, 0.0008, 0.0009, 0.0009,\n",
            "        0.0009, 0.0011, 0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011,\n",
            "        0.0011, 0.0012, 0.0011, 0.0010, 0.0011, 0.0008, 0.0011, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0012, 0.0012, 0.0008, 0.0009, 0.0008,\n",
            "        0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0011, 0.0011, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0012, 0.0011, 0.0010, 0.0011, 0.0011, 0.0008,\n",
            "        0.0011, 0.0010, 0.0012, 0.0012, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0011, 0.0010, 0.0009, 0.0011, 0.0010, 0.0011, 0.0010, 0.0009, 0.0011,\n",
            "        0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0012, 0.0008,\n",
            "        0.0010, 0.0010, 0.0010, 0.0008, 0.0013, 0.0010, 0.0011, 0.0011, 0.0008,\n",
            "        0.0012, 0.0007, 0.0009, 0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0009,\n",
            "        0.0008, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0011, 0.0011])}, 131: {'momentum_buffer': tensor([ 4.9991e-05,  1.7948e-04,  3.8443e-05, -9.0569e-06, -9.3119e-05,\n",
            "        -3.5621e-04,  1.0284e-05, -2.2032e-04,  2.6711e-05,  1.1630e-04,\n",
            "        -3.8585e-05, -1.0711e-04, -8.0215e-05, -3.3681e-04, -4.6102e-05,\n",
            "         4.6472e-05,  1.2182e-04,  9.6942e-05, -1.7016e-04,  7.5991e-05,\n",
            "         1.1462e-04,  1.9244e-04, -2.6240e-05, -4.0749e-05, -1.9750e-04,\n",
            "         9.2932e-05, -9.8582e-06,  2.2842e-04, -1.5007e-05, -1.6356e-04,\n",
            "        -6.8461e-05, -1.5500e-04, -8.6223e-05,  2.2230e-05, -6.0656e-06,\n",
            "         8.8899e-05, -2.4345e-05,  6.8848e-05, -1.1945e-04,  2.7207e-05,\n",
            "        -9.1830e-05, -3.4255e-05, -1.1266e-04, -8.8214e-05, -1.0107e-05,\n",
            "        -1.0339e-04,  7.7764e-05,  5.0696e-05, -2.1317e-05, -1.2300e-05,\n",
            "        -1.7058e-04,  8.0876e-05, -2.3977e-04, -8.9714e-05, -3.8872e-05,\n",
            "         5.3773e-05,  8.8050e-05,  9.7290e-05, -2.5806e-05, -4.7272e-05,\n",
            "         6.4791e-05, -8.5327e-05, -1.9054e-04, -9.5735e-05, -2.9179e-04,\n",
            "        -9.6716e-07, -1.0817e-04,  1.0270e-04,  9.8422e-05,  1.8250e-04,\n",
            "        -1.2868e-04,  3.6398e-05, -2.1470e-04,  9.4819e-05, -6.8041e-05,\n",
            "        -1.0940e-05, -9.7123e-05, -2.5483e-04, -5.2975e-05,  9.8151e-05,\n",
            "         2.9371e-05, -2.0902e-05,  5.4293e-05,  6.7742e-05, -6.4995e-05,\n",
            "        -2.9351e-05,  1.2933e-07, -1.3848e-05,  2.7138e-05, -1.8660e-04,\n",
            "        -5.2955e-07, -3.8341e-05,  1.1989e-04,  5.5910e-05,  1.0835e-04,\n",
            "        -1.0405e-04,  1.3045e-04, -5.5255e-05,  1.6297e-04,  3.0614e-05,\n",
            "        -6.2363e-05,  4.2682e-05, -1.2500e-04, -1.1863e-04, -1.8992e-04,\n",
            "         2.3288e-05,  1.9137e-04, -9.7917e-05,  1.4273e-04,  7.3228e-05,\n",
            "        -1.9034e-04, -5.0303e-05,  1.7884e-04,  3.0358e-05, -7.6973e-05,\n",
            "        -1.7266e-04, -1.2172e-04, -3.1146e-05,  1.4330e-04, -5.5668e-05,\n",
            "         2.4648e-04, -2.4607e-04,  5.9117e-06, -3.6245e-05, -9.9569e-05,\n",
            "        -8.5035e-05, -4.2433e-06,  1.3111e-04, -3.4797e-04, -5.5954e-05,\n",
            "         2.8608e-04, -3.7858e-05, -5.2932e-05, -1.7818e-04,  2.2269e-04,\n",
            "        -3.3267e-05,  3.7250e-05, -6.1994e-05, -1.1405e-06,  1.1879e-04,\n",
            "        -2.5890e-04, -2.7809e-05, -3.0515e-05, -2.3967e-05, -1.4987e-04,\n",
            "         1.0490e-04,  7.5442e-05,  5.4623e-05, -4.0110e-04,  2.0690e-05,\n",
            "        -1.4332e-05, -1.1851e-04,  1.7691e-04, -1.0582e-04,  3.9941e-05,\n",
            "        -9.7051e-05, -7.4026e-06,  6.8630e-05,  1.1767e-04,  5.5826e-05,\n",
            "         2.8470e-05, -3.2679e-05, -1.0693e-04,  1.4205e-04,  8.6494e-05,\n",
            "        -5.1579e-05, -1.1713e-04, -2.5965e-05,  2.1622e-04, -1.3699e-04,\n",
            "        -4.4539e-05, -1.1813e-04,  1.4082e-04, -3.2133e-05,  3.8864e-05,\n",
            "        -3.2376e-04,  7.9873e-05,  6.4755e-05, -1.1889e-04, -2.8864e-05,\n",
            "         7.2384e-05,  5.4048e-05,  6.5337e-05,  2.1632e-04,  9.6768e-05,\n",
            "        -2.2002e-04,  1.2957e-04,  1.1411e-04,  1.2187e-04,  5.2648e-05,\n",
            "         1.1200e-04, -8.6846e-05,  8.2170e-05, -9.9311e-05, -2.3263e-04,\n",
            "        -1.1469e-05, -1.2062e-04, -2.2022e-04,  2.6829e-06,  2.2683e-04,\n",
            "        -1.7384e-04,  4.8482e-05, -1.7034e-04,  4.4769e-05, -2.1093e-05,\n",
            "        -2.6581e-06, -5.8525e-06,  8.2037e-05,  1.1274e-04,  8.2292e-05,\n",
            "         2.9641e-06,  3.2254e-05, -1.6049e-04, -2.0245e-04,  2.6722e-04,\n",
            "        -1.4981e-04, -2.6751e-04,  2.5329e-05, -4.1422e-05, -6.3523e-05,\n",
            "        -2.7931e-04,  7.8847e-05,  5.2761e-06, -5.7555e-05,  9.8488e-05,\n",
            "        -2.6574e-04,  1.7195e-04, -2.2018e-04,  1.2015e-04, -6.2860e-05,\n",
            "        -2.0523e-04, -1.0076e-04, -1.8963e-04, -1.8127e-04, -2.2196e-04,\n",
            "         7.4877e-05, -2.7270e-04, -4.0149e-06,  8.8212e-05, -1.6714e-04,\n",
            "        -5.3436e-06,  2.8023e-05, -1.8554e-04,  1.9703e-04,  4.8499e-05,\n",
            "        -2.8105e-04, -1.1915e-04,  6.7086e-05,  7.3331e-05,  1.2478e-05,\n",
            "         1.6463e-04, -2.5042e-05,  1.3880e-04, -1.5192e-04, -1.0688e-04,\n",
            "         7.5262e-05,  7.1074e-05,  2.9617e-05,  8.9455e-05, -1.6110e-04,\n",
            "        -4.9517e-05, -2.1044e-04, -1.3059e-04, -4.2235e-05, -2.5708e-05,\n",
            "        -1.0283e-04,  1.4448e-04,  3.0666e-06,  4.5409e-05,  3.0773e-05,\n",
            "        -7.5873e-05, -7.8593e-07,  9.3203e-05,  2.1688e-05,  3.5975e-05,\n",
            "         8.9650e-05, -1.0668e-04,  5.7021e-05,  1.0223e-05, -1.4040e-04,\n",
            "        -1.4031e-04,  1.9563e-04, -6.6513e-05,  2.1881e-06,  1.2249e-04,\n",
            "        -8.8924e-05,  9.9032e-05, -5.7954e-05, -1.7698e-04,  3.9109e-05,\n",
            "        -2.1486e-05,  2.9082e-04, -1.0018e-04, -1.8214e-04, -7.5880e-05,\n",
            "        -1.2817e-04, -1.4112e-04, -3.1821e-05, -2.1923e-05,  1.1623e-05,\n",
            "         2.6660e-04,  2.0872e-06,  6.6153e-05,  9.9824e-06, -1.4945e-05,\n",
            "         7.3592e-05,  3.2609e-05,  1.1414e-04,  2.0437e-05,  1.7615e-04,\n",
            "         1.9448e-04, -2.0815e-04,  1.3026e-06,  1.9793e-05,  2.4038e-04,\n",
            "         2.6259e-08, -4.8851e-05, -1.6012e-04,  1.8688e-06,  2.2594e-04,\n",
            "         8.4435e-05, -8.7225e-06, -3.8915e-05,  8.9692e-05, -1.3419e-04,\n",
            "        -7.9698e-05, -1.1877e-04, -6.5939e-05, -5.0355e-05, -4.6090e-05,\n",
            "         1.4885e-04,  1.4014e-04,  2.4675e-04, -3.5084e-05,  6.2716e-05,\n",
            "         1.7675e-05, -1.1291e-04,  4.0248e-06, -6.9989e-05,  6.6152e-05,\n",
            "         8.7594e-05, -8.3039e-05, -9.3909e-06, -2.4047e-05, -1.6035e-05,\n",
            "         3.7491e-05,  5.2238e-05, -4.1037e-05,  1.4392e-04,  5.2730e-05,\n",
            "         1.8252e-04, -7.3443e-05,  8.1773e-06, -1.7579e-05, -1.6015e-04,\n",
            "        -1.9124e-05, -9.8625e-05, -1.6447e-04, -1.1480e-04, -1.4024e-04,\n",
            "        -2.0942e-04, -3.2465e-05, -4.7863e-05, -1.7172e-04, -8.3961e-05,\n",
            "        -2.3656e-05, -8.5212e-05,  1.6538e-05, -1.9345e-04, -5.6316e-05,\n",
            "        -9.5292e-06, -3.1499e-05,  8.4336e-05, -2.3287e-05,  1.3564e-05,\n",
            "         3.6847e-05, -2.0064e-04, -1.3500e-04, -1.7690e-04,  1.9506e-04,\n",
            "         7.9745e-05, -1.4037e-04, -1.9731e-04, -7.4661e-05, -7.7434e-05,\n",
            "        -2.1372e-04, -7.5619e-05, -5.3164e-05, -9.9556e-05, -5.9581e-05,\n",
            "         1.0448e-04, -1.2478e-04, -2.4404e-04,  5.6734e-06, -3.6315e-04,\n",
            "         1.1916e-05,  8.9942e-05, -2.4539e-05, -1.2341e-04, -1.8597e-05,\n",
            "         5.0870e-05,  8.7051e-05, -1.5555e-04,  8.0881e-05, -1.5624e-04,\n",
            "        -1.9094e-05,  6.7458e-05,  1.7320e-04, -1.4453e-04,  6.3452e-05,\n",
            "         1.3878e-04, -2.7210e-05, -7.8873e-05,  4.2589e-05, -5.9115e-05,\n",
            "         1.1172e-04, -4.0929e-05,  2.1489e-05,  9.1261e-05,  1.0618e-04,\n",
            "         2.7584e-05, -1.2253e-04,  7.4612e-05, -4.1049e-05,  5.2155e-05,\n",
            "         2.6036e-05, -4.6424e-05,  1.3613e-05,  8.1409e-05, -1.6434e-04,\n",
            "        -1.4574e-04, -7.5899e-05, -1.2281e-04,  1.2084e-05, -4.7291e-05,\n",
            "        -2.0491e-05, -3.8231e-05, -8.7502e-06, -4.1050e-05, -4.6423e-05,\n",
            "         1.8354e-04, -9.7315e-05,  3.6084e-05, -3.4821e-05, -1.7938e-04,\n",
            "         8.6676e-05,  1.1451e-04, -9.4394e-05, -3.0232e-05,  2.1266e-05,\n",
            "         1.3013e-04, -1.0720e-05,  2.1352e-06,  4.3011e-05, -2.0135e-04,\n",
            "         3.3210e-05,  2.3905e-04,  1.7682e-04, -2.4473e-04, -6.9500e-05,\n",
            "         1.0032e-04,  1.1377e-04,  2.7233e-04, -1.5042e-04, -2.7998e-04,\n",
            "        -6.5293e-05,  1.3336e-05,  1.4168e-05,  7.4153e-05, -1.1533e-04,\n",
            "        -1.0351e-04,  1.8959e-04, -1.5245e-05, -7.5737e-05,  5.9425e-05,\n",
            "         6.3709e-05,  6.5164e-05,  1.9489e-05, -9.3206e-05,  5.5813e-05,\n",
            "        -7.5632e-06,  1.8419e-04, -2.6849e-05,  8.2989e-05, -1.2323e-04,\n",
            "        -1.3823e-04,  8.0070e-05, -6.6742e-05, -5.7156e-05, -5.0497e-06,\n",
            "        -5.7941e-05, -1.3918e-04,  1.3884e-04,  7.3828e-05, -3.7195e-04,\n",
            "        -4.6993e-05, -6.7625e-05, -7.5561e-05,  6.5765e-05,  8.5526e-05,\n",
            "        -3.0951e-04, -6.8685e-05, -2.0210e-05, -1.5773e-04, -1.7029e-04,\n",
            "         1.2745e-04, -1.1572e-06,  1.8230e-04, -1.1701e-04,  1.9769e-04,\n",
            "         1.3580e-04,  5.0837e-05])}, 132: {'momentum_buffer': tensor([[[[ 2.0833e-05, -1.7843e-05, -1.3615e-06],\n",
            "          [ 1.2093e-04,  6.3993e-05,  6.8600e-05],\n",
            "          [ 1.3964e-04,  1.0581e-04,  6.7006e-05]],\n",
            "\n",
            "         [[-1.4570e-05,  3.6898e-05,  3.4880e-05],\n",
            "          [-3.8488e-05,  1.1997e-05, -5.7929e-05],\n",
            "          [-1.2275e-04, -1.8674e-04, -1.0515e-04]],\n",
            "\n",
            "         [[-1.9055e-05,  8.6889e-05,  5.1633e-05],\n",
            "          [-7.0214e-06,  2.5781e-05, -2.1929e-06],\n",
            "          [ 1.6677e-05, -4.8971e-05, -9.4789e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1768e-05, -6.9995e-06,  1.4056e-05],\n",
            "          [ 4.7539e-06,  6.1496e-05,  1.1298e-05],\n",
            "          [-3.0789e-05, -5.5123e-05, -1.7281e-05]],\n",
            "\n",
            "         [[-3.2326e-05,  3.1340e-05,  3.5823e-05],\n",
            "          [ 3.4386e-06,  2.9965e-05, -3.7589e-05],\n",
            "          [-5.7767e-05,  1.1640e-06, -4.1670e-05]],\n",
            "\n",
            "         [[ 1.1319e-04,  6.0717e-05,  5.6755e-05],\n",
            "          [ 4.0462e-05, -3.4289e-05,  4.6339e-05],\n",
            "          [ 5.7243e-05, -2.7199e-05,  5.1454e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.0120e-04, -1.5454e-06,  5.7377e-05],\n",
            "          [ 3.6862e-06, -4.1647e-05, -7.3741e-05],\n",
            "          [ 1.9895e-05, -2.5877e-05,  6.0844e-05]],\n",
            "\n",
            "         [[-5.7102e-05, -1.3351e-04, -4.9919e-06],\n",
            "          [ 1.3457e-05, -4.2070e-05,  1.5490e-05],\n",
            "          [-7.5314e-05, -2.1354e-05,  3.9430e-05]],\n",
            "\n",
            "         [[ 8.8143e-05,  1.1216e-04,  8.4816e-06],\n",
            "          [ 5.4709e-05,  1.0591e-04,  3.2246e-05],\n",
            "          [ 5.3411e-05,  7.2718e-05,  9.8625e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1575e-04, -1.7791e-04, -6.1129e-05],\n",
            "          [-1.2466e-04, -5.7071e-05, -1.4759e-04],\n",
            "          [-3.6244e-05, -1.7697e-04,  1.1295e-05]],\n",
            "\n",
            "         [[ 4.2648e-05, -8.2871e-05, -1.9711e-05],\n",
            "          [-1.0087e-04, -3.5442e-05,  4.4507e-05],\n",
            "          [-1.5811e-05,  1.2624e-04,  8.9435e-05]],\n",
            "\n",
            "         [[-2.2666e-05, -1.7669e-04,  6.5146e-05],\n",
            "          [ 8.2447e-05,  4.6847e-05, -6.4025e-05],\n",
            "          [-2.5011e-06, -9.9281e-05,  4.3486e-05]]],\n",
            "\n",
            "\n",
            "        [[[-7.8707e-05, -8.4416e-05, -1.0304e-06],\n",
            "          [-7.3973e-05, -9.5679e-06, -2.9831e-05],\n",
            "          [-9.6916e-05, -1.1717e-04,  4.7247e-05]],\n",
            "\n",
            "         [[ 7.7288e-05,  3.0598e-05, -6.3812e-05],\n",
            "          [-4.4798e-05,  1.7414e-04,  7.4576e-06],\n",
            "          [-2.0720e-05,  7.7139e-05,  5.5665e-05]],\n",
            "\n",
            "         [[ 1.6192e-04,  9.2164e-05,  5.0911e-05],\n",
            "          [ 3.6249e-05,  1.8437e-04,  5.6501e-05],\n",
            "          [ 5.2376e-05,  5.0839e-05, -2.1757e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2737e-05, -1.3801e-04,  5.9423e-05],\n",
            "          [ 3.7763e-05,  7.6521e-05,  9.7853e-05],\n",
            "          [-6.1492e-05, -4.3452e-05, -1.9577e-05]],\n",
            "\n",
            "         [[ 2.1333e-04,  2.0454e-04,  1.2178e-06],\n",
            "          [ 1.0131e-04,  1.9027e-04,  1.4688e-04],\n",
            "          [ 1.4079e-04,  9.0041e-05,  1.0680e-04]],\n",
            "\n",
            "         [[ 1.8332e-04,  1.8337e-04,  8.2094e-05],\n",
            "          [ 1.4286e-04,  1.2134e-04,  1.5857e-04],\n",
            "          [ 9.1885e-05,  9.7003e-05,  2.3122e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-9.9377e-06, -1.0975e-05,  3.4122e-05],\n",
            "          [-9.1920e-06, -3.9414e-05,  4.2496e-05],\n",
            "          [-6.3552e-05,  7.6605e-06, -2.0150e-05]],\n",
            "\n",
            "         [[-1.8690e-05, -7.2080e-05, -5.2050e-05],\n",
            "          [-2.1519e-05,  2.9382e-06, -5.5410e-05],\n",
            "          [-6.3231e-05, -2.8255e-05, -2.9055e-05]],\n",
            "\n",
            "         [[ 5.0762e-05,  6.1009e-05, -4.5277e-05],\n",
            "          [ 3.5801e-05,  1.2776e-05,  2.3199e-06],\n",
            "          [ 4.3725e-05, -2.1300e-05, -1.9264e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6719e-05,  1.3154e-05, -6.3701e-05],\n",
            "          [ 1.6204e-05, -2.5817e-05, -4.3323e-05],\n",
            "          [-6.0147e-05, -6.0113e-07,  1.6566e-05]],\n",
            "\n",
            "         [[ 5.0300e-05,  4.3106e-05, -1.9036e-06],\n",
            "          [-3.9249e-05,  2.4784e-05,  6.1939e-06],\n",
            "          [-1.3328e-06, -1.0131e-04,  3.4852e-05]],\n",
            "\n",
            "         [[-4.0075e-06,  9.1107e-07, -2.9924e-05],\n",
            "          [ 6.1392e-05,  6.8288e-05,  2.7679e-06],\n",
            "          [ 6.2094e-05,  6.3685e-05,  4.1481e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0370e-04,  1.6415e-05,  1.7694e-05],\n",
            "          [ 4.1362e-05, -1.5634e-04,  4.0832e-05],\n",
            "          [-6.9830e-05,  1.0736e-06,  2.9660e-05]],\n",
            "\n",
            "         [[ 8.8187e-05, -6.2472e-05, -1.4946e-06],\n",
            "          [ 6.5280e-05,  1.0149e-04, -6.9328e-06],\n",
            "          [ 1.7406e-04, -9.0243e-06, -9.7392e-06]],\n",
            "\n",
            "         [[ 1.2624e-05, -7.4265e-05, -1.4857e-04],\n",
            "          [ 6.4056e-05,  1.6265e-05, -4.0945e-05],\n",
            "          [-7.9786e-05, -7.3860e-05, -1.3868e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9545e-05, -5.3123e-05,  2.5812e-05],\n",
            "          [-4.3078e-05, -1.4408e-04,  2.8583e-05],\n",
            "          [-8.3725e-05,  2.1504e-05, -3.4755e-05]],\n",
            "\n",
            "         [[-2.1439e-06, -6.8925e-05,  8.6404e-05],\n",
            "          [-9.7753e-05,  3.2461e-05, -1.3174e-04],\n",
            "          [-1.0398e-04,  7.0416e-05,  1.5454e-05]],\n",
            "\n",
            "         [[ 2.8191e-05, -1.4096e-04, -1.1541e-04],\n",
            "          [-7.8080e-05, -1.0797e-04, -1.0445e-04],\n",
            "          [-3.7446e-05, -9.5012e-05, -9.6784e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.2338e-04, -7.8953e-05, -2.3073e-05],\n",
            "          [-6.5353e-05, -1.2704e-05, -7.2063e-05],\n",
            "          [-1.2000e-04, -3.6194e-05,  8.3493e-05]],\n",
            "\n",
            "         [[-4.0535e-05,  1.9845e-05, -3.5090e-05],\n",
            "          [-2.0230e-04, -2.1433e-04, -2.5010e-05],\n",
            "          [-5.0614e-05, -7.8564e-05, -4.6446e-05]],\n",
            "\n",
            "         [[ 1.4270e-04,  7.2305e-05,  1.9703e-05],\n",
            "          [ 8.5363e-05,  1.2113e-04,  2.5325e-05],\n",
            "          [ 7.0860e-05,  1.6807e-04,  1.6515e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6632e-05, -1.0059e-04,  2.6263e-05],\n",
            "          [-2.2047e-05,  6.7127e-05,  2.8592e-05],\n",
            "          [-1.1339e-05, -6.3513e-05,  9.8427e-05]],\n",
            "\n",
            "         [[ 4.9709e-05,  7.3357e-05, -1.7146e-05],\n",
            "          [ 2.2812e-05,  1.3856e-04,  1.9653e-05],\n",
            "          [ 4.2244e-05,  1.3205e-04, -7.7567e-05]],\n",
            "\n",
            "         [[-1.0172e-05, -3.3290e-05,  6.6410e-06],\n",
            "          [ 6.5260e-05,  1.5746e-05,  6.1675e-05],\n",
            "          [ 6.7763e-05,  1.1309e-05,  4.2745e-06]]]])}, 133: {'momentum_buffer': tensor([0.0010, 0.0011, 0.0011, 0.0008, 0.0010, 0.0008, 0.0011, 0.0012, 0.0009,\n",
            "        0.0010, 0.0008, 0.0009, 0.0011, 0.0009, 0.0010, 0.0011, 0.0009, 0.0008,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0012, 0.0009, 0.0010, 0.0008,\n",
            "        0.0011, 0.0010, 0.0009, 0.0007, 0.0009, 0.0009, 0.0012, 0.0009, 0.0011,\n",
            "        0.0010, 0.0011, 0.0009, 0.0009, 0.0007, 0.0011, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0008, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0013, 0.0009, 0.0011, 0.0011, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0007, 0.0009, 0.0009, 0.0010, 0.0011, 0.0008,\n",
            "        0.0010, 0.0007, 0.0010, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010, 0.0012,\n",
            "        0.0008, 0.0010, 0.0010, 0.0009, 0.0011, 0.0011, 0.0012, 0.0010, 0.0010,\n",
            "        0.0011, 0.0009, 0.0007, 0.0010, 0.0009, 0.0006, 0.0012, 0.0010, 0.0010,\n",
            "        0.0009, 0.0009, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0009,\n",
            "        0.0011, 0.0009, 0.0011, 0.0007, 0.0010, 0.0012, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0008,\n",
            "        0.0011, 0.0010, 0.0011, 0.0009, 0.0009, 0.0011, 0.0010, 0.0011, 0.0009,\n",
            "        0.0010, 0.0009, 0.0011, 0.0011, 0.0009, 0.0007, 0.0011, 0.0010, 0.0009,\n",
            "        0.0009, 0.0010, 0.0011, 0.0011, 0.0008, 0.0011, 0.0009, 0.0009, 0.0008,\n",
            "        0.0011, 0.0008, 0.0009, 0.0011, 0.0010, 0.0010, 0.0008, 0.0010, 0.0011,\n",
            "        0.0009, 0.0009, 0.0013, 0.0010, 0.0010, 0.0012, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0009, 0.0011, 0.0011, 0.0011, 0.0010, 0.0009, 0.0010, 0.0009,\n",
            "        0.0011, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0010, 0.0009, 0.0009, 0.0009, 0.0011, 0.0008, 0.0011, 0.0011, 0.0010,\n",
            "        0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0012, 0.0009, 0.0011, 0.0010,\n",
            "        0.0009, 0.0011, 0.0012, 0.0011, 0.0010, 0.0009, 0.0008, 0.0011, 0.0009,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0012, 0.0009, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0012, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0009, 0.0010, 0.0012, 0.0009, 0.0011, 0.0009, 0.0011, 0.0009,\n",
            "        0.0009, 0.0010, 0.0011, 0.0011, 0.0012, 0.0012, 0.0012, 0.0010, 0.0007,\n",
            "        0.0013, 0.0009, 0.0011, 0.0010, 0.0009, 0.0013, 0.0009, 0.0008, 0.0010,\n",
            "        0.0009, 0.0011, 0.0011, 0.0008, 0.0007, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0012, 0.0012, 0.0009, 0.0011, 0.0011, 0.0010,\n",
            "        0.0009, 0.0010, 0.0008, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0009,\n",
            "        0.0011, 0.0010, 0.0011, 0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0011, 0.0011, 0.0010, 0.0010, 0.0009, 0.0008, 0.0009, 0.0009,\n",
            "        0.0011, 0.0011, 0.0011, 0.0008, 0.0010, 0.0010, 0.0009, 0.0010, 0.0011,\n",
            "        0.0009, 0.0009, 0.0010, 0.0011, 0.0012, 0.0010, 0.0007, 0.0011, 0.0011,\n",
            "        0.0011, 0.0010, 0.0009, 0.0011, 0.0009, 0.0010, 0.0011, 0.0010, 0.0009,\n",
            "        0.0011, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010, 0.0011, 0.0011, 0.0009,\n",
            "        0.0011, 0.0010, 0.0011, 0.0011, 0.0010, 0.0011, 0.0012, 0.0008, 0.0010,\n",
            "        0.0012, 0.0012, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0012, 0.0009,\n",
            "        0.0008, 0.0009, 0.0008, 0.0008, 0.0007, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0012, 0.0011, 0.0009, 0.0008, 0.0011, 0.0009, 0.0011,\n",
            "        0.0010, 0.0009, 0.0009, 0.0008, 0.0012, 0.0011, 0.0013, 0.0009, 0.0008,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0008, 0.0011, 0.0009, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0011, 0.0008, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0011, 0.0012, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0009, 0.0011, 0.0009, 0.0009, 0.0008, 0.0011,\n",
            "        0.0008, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0012, 0.0009, 0.0009,\n",
            "        0.0010, 0.0010, 0.0011, 0.0013, 0.0009, 0.0011, 0.0011, 0.0010, 0.0011,\n",
            "        0.0009, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0007, 0.0009, 0.0011,\n",
            "        0.0010, 0.0007, 0.0009, 0.0010, 0.0010, 0.0009, 0.0011, 0.0009, 0.0009,\n",
            "        0.0010, 0.0011, 0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0009,\n",
            "        0.0008, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0008, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0012, 0.0010, 0.0012, 0.0009,\n",
            "        0.0011, 0.0011, 0.0010, 0.0008, 0.0009, 0.0010, 0.0010, 0.0010])}, 134: {'momentum_buffer': tensor([-2.1294e-06,  1.5944e-04, -4.4456e-08, -3.0212e-05, -6.6686e-05,\n",
            "        -2.9254e-04,  9.6168e-05,  8.8812e-05, -7.2189e-05, -4.4180e-05,\n",
            "        -1.3262e-04, -1.8090e-05,  8.4820e-05, -7.0889e-06, -4.2029e-05,\n",
            "        -1.3606e-05,  9.3843e-05, -1.2212e-04,  3.0451e-05, -1.9127e-05,\n",
            "        -1.8802e-04,  2.9368e-05, -4.0690e-05, -6.7291e-05, -1.6239e-04,\n",
            "         2.7656e-05, -1.8668e-04,  8.0834e-05, -7.1337e-05, -1.8215e-04,\n",
            "        -2.1333e-04,  2.7048e-05, -2.1759e-04,  1.6192e-05, -5.4489e-06,\n",
            "         9.8150e-05, -2.8854e-05,  1.1532e-04, -8.4955e-05, -2.0505e-04,\n",
            "        -2.3041e-04,  8.6133e-05,  3.0133e-05,  1.8255e-05, -5.9509e-05,\n",
            "        -6.3259e-05, -6.4856e-05, -1.6636e-04,  7.2388e-05,  3.3369e-05,\n",
            "        -6.2774e-05, -4.2808e-05, -4.1885e-05, -3.0295e-05,  7.7766e-05,\n",
            "        -1.2419e-04, -1.9163e-06, -3.0327e-05, -1.1308e-04, -1.1311e-04,\n",
            "         3.5964e-05, -8.3642e-05,  1.8431e-05,  3.8164e-06, -1.4926e-04,\n",
            "         1.3452e-04, -5.9880e-05, -5.7689e-06,  7.8268e-05, -4.4773e-05,\n",
            "         4.0333e-05, -1.0581e-04,  9.6080e-06, -5.7621e-05, -2.4854e-05,\n",
            "        -3.6923e-04,  4.9201e-05, -2.2753e-04,  7.2102e-05,  7.8213e-05,\n",
            "        -3.8508e-05,  4.6087e-05, -1.8130e-04,  2.7106e-04,  1.7118e-05,\n",
            "        -1.4635e-04, -1.7827e-04,  2.0836e-05, -5.8155e-05,  1.0392e-04,\n",
            "        -2.5158e-04, -4.1304e-05, -7.3394e-05, -1.7143e-04,  5.4740e-05,\n",
            "         2.0225e-05,  9.0303e-05, -3.4603e-05, -4.3957e-05,  5.3503e-05,\n",
            "        -1.7232e-04, -1.8247e-04, -2.6609e-05, -8.9675e-05, -1.6771e-04,\n",
            "         1.5973e-04, -2.9527e-05,  6.2489e-06, -8.7879e-05,  1.9716e-05,\n",
            "        -1.7129e-04, -1.5258e-05,  2.8071e-05,  4.4434e-05,  2.2308e-04,\n",
            "        -2.6673e-05,  2.8199e-05,  1.2220e-06,  4.0966e-05, -1.9568e-05,\n",
            "        -9.7828e-05,  8.3564e-06, -7.8010e-05, -4.9030e-05,  8.0443e-06,\n",
            "         1.0321e-05,  7.6358e-05,  4.6359e-05, -1.4298e-04, -1.2719e-04,\n",
            "         2.1651e-04, -2.4188e-04, -1.4764e-04,  2.7930e-05,  3.9071e-05,\n",
            "         2.2564e-04,  4.8341e-05,  2.4094e-04,  1.6963e-05, -9.1578e-05,\n",
            "         3.2998e-05, -1.1900e-05, -4.1070e-05, -2.0916e-05, -4.1126e-05,\n",
            "        -1.0031e-04,  1.3339e-04,  1.3109e-04, -1.8253e-04, -7.3139e-05,\n",
            "         2.6092e-05, -4.5560e-05, -6.5259e-05, -2.4979e-04, -1.2092e-04,\n",
            "         2.8790e-05, -1.2607e-04, -1.9887e-04, -3.0454e-05, -6.5586e-05,\n",
            "        -2.0546e-05, -6.7152e-05, -2.2478e-05, -2.0421e-04, -1.0533e-04,\n",
            "        -2.2132e-05, -1.1233e-05, -1.0341e-05, -8.3730e-05, -3.7678e-05,\n",
            "         4.8070e-05, -5.9348e-05,  6.3900e-05,  3.7692e-05,  9.6405e-05,\n",
            "        -1.1227e-04,  1.1961e-04, -9.8658e-05,  2.4331e-04, -1.9095e-04,\n",
            "        -9.3396e-05,  1.0839e-05,  3.7580e-05,  1.7954e-05,  6.3135e-05,\n",
            "         5.8157e-06, -9.8572e-05,  3.8617e-05, -8.5110e-05,  1.1820e-04,\n",
            "        -1.9393e-04, -3.6518e-05, -6.8933e-05, -1.0922e-04,  3.4321e-05,\n",
            "         1.1419e-04, -8.1747e-05, -7.4386e-06, -3.4285e-05, -6.6204e-05,\n",
            "        -7.8867e-05, -5.3167e-05, -8.1594e-05,  3.1909e-05,  1.3469e-04,\n",
            "         1.0512e-05, -4.1848e-05, -7.1349e-05, -7.2025e-05,  1.8017e-04,\n",
            "        -1.4566e-04, -5.9389e-05,  1.2294e-04, -2.0866e-05,  7.7868e-05,\n",
            "        -1.0635e-04, -3.7938e-05, -4.4914e-05,  1.5170e-04,  7.5597e-05,\n",
            "         9.1714e-05, -8.2887e-05, -1.0033e-04, -3.2963e-05, -2.7789e-05,\n",
            "        -1.1552e-04, -5.4051e-05, -1.0425e-04, -1.5542e-06,  1.0988e-04,\n",
            "        -8.0618e-05,  4.3979e-05, -1.7137e-04,  4.6962e-05, -6.7282e-05,\n",
            "         1.2918e-04, -1.6096e-05,  1.7884e-04, -6.2916e-05,  1.5557e-04,\n",
            "        -1.4385e-05,  6.7679e-05, -1.2566e-04, -1.5590e-04, -4.3826e-05,\n",
            "         2.0579e-04,  1.3064e-04,  8.4730e-06,  4.3213e-05, -5.4974e-05,\n",
            "         2.7344e-05, -9.4126e-05, -2.5056e-05, -5.8723e-05, -3.4821e-05,\n",
            "         1.0585e-05,  3.4742e-05,  1.1125e-04,  1.3675e-04, -1.9217e-04,\n",
            "        -2.3587e-04,  1.3850e-04, -1.8698e-04,  6.2266e-05,  3.1234e-07,\n",
            "        -5.4372e-05,  1.4239e-04,  2.1550e-04, -1.2429e-04, -9.8885e-05,\n",
            "        -2.6176e-04,  4.7477e-05,  4.2344e-05,  4.8172e-05, -1.9677e-04,\n",
            "         5.8881e-06, -5.8521e-05, -8.5477e-05, -3.9507e-05, -7.8877e-05,\n",
            "         8.6109e-05,  2.0538e-05,  8.1630e-05,  1.2979e-05,  4.5381e-06,\n",
            "         6.2842e-05,  4.5528e-05,  1.3815e-05, -2.6445e-05,  1.3725e-05,\n",
            "        -2.1881e-04, -3.1197e-05, -1.7794e-04, -1.3549e-04,  2.7573e-05,\n",
            "         2.4966e-04, -1.7583e-04,  1.0497e-04, -7.3349e-05,  9.4704e-05,\n",
            "        -3.6289e-05,  2.5003e-05, -3.2110e-05, -7.2522e-05,  4.2062e-06,\n",
            "         1.7427e-05, -5.7058e-06, -8.6689e-05,  3.7497e-05, -8.9212e-05,\n",
            "        -3.1623e-05, -2.9768e-05, -1.4639e-04,  1.0265e-04, -1.0678e-04,\n",
            "         3.3537e-05,  7.5407e-05, -3.7630e-05, -9.9025e-05,  6.6697e-05,\n",
            "         2.1991e-05, -6.8481e-05,  5.5409e-05,  4.5029e-05, -1.0568e-04,\n",
            "        -1.5643e-04,  9.8709e-05,  1.1552e-04,  1.5703e-07,  3.3208e-05,\n",
            "        -1.2583e-04,  1.0253e-04,  3.3841e-05, -2.5870e-05,  5.5391e-05,\n",
            "        -1.8509e-05,  1.4527e-04, -1.0941e-04,  6.9051e-05, -1.9317e-05,\n",
            "        -4.7046e-05,  7.0918e-05, -8.6363e-06, -5.6518e-06, -1.7341e-04,\n",
            "         5.2612e-05,  6.1375e-05, -5.6587e-05,  5.2915e-05, -5.6785e-06,\n",
            "        -3.8877e-05, -1.3917e-04, -5.4074e-05,  1.1383e-04,  8.8072e-05,\n",
            "        -1.1332e-04,  8.0834e-05,  1.6549e-04, -1.2988e-05, -1.0331e-04,\n",
            "         7.0175e-05,  4.6768e-05, -7.9186e-05, -1.5865e-04, -6.1920e-05,\n",
            "        -4.5722e-05,  2.6537e-05,  2.6680e-04, -9.4058e-07,  9.4197e-05,\n",
            "        -3.2506e-07, -1.5638e-04, -1.4687e-04, -1.5404e-04, -1.4513e-05,\n",
            "        -8.1077e-05, -4.2599e-05, -8.1987e-05,  1.3208e-05, -2.4433e-06,\n",
            "         6.2541e-05,  1.0422e-04,  7.2158e-05, -1.0390e-04,  1.0793e-04,\n",
            "        -1.8797e-04,  1.7883e-05, -4.3130e-05, -5.9506e-05,  1.7381e-07,\n",
            "        -3.8306e-04,  9.9245e-05, -1.1638e-04,  9.6649e-05, -6.1362e-05,\n",
            "        -1.1716e-04,  5.7279e-05, -1.0843e-04, -1.9174e-05,  7.7945e-05,\n",
            "        -1.3282e-05, -1.0169e-04, -7.0279e-05,  2.7949e-05, -9.2471e-05,\n",
            "        -8.5527e-06, -1.0453e-04,  9.3114e-05, -1.5762e-04, -3.7531e-05,\n",
            "        -5.2834e-05, -1.6754e-04, -1.5754e-05,  4.2266e-06, -1.0196e-05,\n",
            "         2.5030e-05,  9.8493e-06, -1.1011e-05,  1.2308e-04,  1.9000e-05,\n",
            "         1.9360e-05,  9.9274e-05, -3.0742e-05, -1.6554e-04,  7.1469e-05,\n",
            "         3.0258e-05, -1.0418e-04,  8.4885e-05, -1.9064e-05, -2.6209e-05,\n",
            "        -1.8557e-04,  8.3556e-05, -1.0412e-04,  5.0343e-05, -2.0805e-05,\n",
            "        -3.1034e-05, -4.5133e-06, -3.1555e-06,  1.6391e-04, -2.0943e-04,\n",
            "        -6.6221e-05, -5.9078e-05, -1.2091e-04,  4.9524e-06,  2.3127e-04,\n",
            "         1.8791e-05,  2.0404e-04, -2.8526e-04, -3.7453e-05,  5.7121e-05,\n",
            "         1.1679e-05, -1.2073e-04,  5.1175e-06,  1.6877e-04,  2.8637e-05,\n",
            "        -7.3518e-05, -7.4605e-05, -7.5841e-05, -3.5941e-05,  1.1097e-05,\n",
            "        -2.4738e-04, -3.5664e-05,  1.5795e-04, -4.0477e-05, -1.0731e-04,\n",
            "        -9.0420e-05, -1.1024e-04,  4.3387e-05,  2.1020e-05,  1.1689e-04,\n",
            "        -3.6489e-05,  6.1301e-05,  5.7555e-05, -3.8729e-06, -7.9296e-05,\n",
            "         1.7466e-06, -3.9846e-05, -5.1658e-05,  2.1806e-05,  2.6220e-04,\n",
            "         7.1315e-05,  1.7232e-06,  1.6939e-04, -1.2079e-04,  8.9511e-05,\n",
            "         3.0370e-05,  1.9335e-04,  8.5095e-05,  1.8337e-05, -2.2577e-05,\n",
            "         1.2056e-04,  1.7715e-05, -2.2263e-04, -6.3570e-05,  1.3978e-04,\n",
            "        -1.1579e-04, -1.8240e-05, -3.0116e-05,  1.6146e-04, -4.4114e-05,\n",
            "         2.1644e-04, -8.2766e-05,  1.3695e-04, -8.2605e-05,  1.3857e-04,\n",
            "        -1.5180e-05, -1.6971e-04, -1.9139e-04, -3.7828e-06, -1.2898e-05,\n",
            "        -5.3998e-05,  1.8566e-05])}, 135: {'momentum_buffer': tensor([[[[ 1.1046e-04]],\n",
            "\n",
            "         [[-8.9131e-05]],\n",
            "\n",
            "         [[ 4.9187e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0840e-05]],\n",
            "\n",
            "         [[-1.0567e-05]],\n",
            "\n",
            "         [[-2.8346e-05]]],\n",
            "\n",
            "\n",
            "        [[[-6.4625e-05]],\n",
            "\n",
            "         [[ 4.9906e-05]],\n",
            "\n",
            "         [[ 1.8508e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.3138e-06]],\n",
            "\n",
            "         [[ 2.2707e-06]],\n",
            "\n",
            "         [[-2.2053e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.0997e-05]],\n",
            "\n",
            "         [[-5.4111e-05]],\n",
            "\n",
            "         [[-1.3698e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.5037e-05]],\n",
            "\n",
            "         [[-2.1010e-04]],\n",
            "\n",
            "         [[ 3.8177e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.2739e-07]],\n",
            "\n",
            "         [[-7.4402e-05]],\n",
            "\n",
            "         [[-1.4399e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7572e-05]],\n",
            "\n",
            "         [[ 1.1222e-04]],\n",
            "\n",
            "         [[-7.7516e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9615e-05]],\n",
            "\n",
            "         [[-1.0114e-04]],\n",
            "\n",
            "         [[-1.5272e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5665e-05]],\n",
            "\n",
            "         [[ 1.4640e-04]],\n",
            "\n",
            "         [[-8.8773e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.0937e-05]],\n",
            "\n",
            "         [[-6.5594e-05]],\n",
            "\n",
            "         [[-8.7711e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.0054e-05]],\n",
            "\n",
            "         [[-8.9660e-06]],\n",
            "\n",
            "         [[ 9.4622e-05]]]])}, 136: {'momentum_buffer': tensor([0.0011, 0.0010, 0.0010,  ..., 0.0011, 0.0009, 0.0010])}, 137: {'momentum_buffer': tensor([ 8.6106e-05, -8.0144e-05,  1.2289e-05,  ...,  2.5152e-05,\n",
            "        -7.8224e-05,  6.9450e-05])}, 138: {'momentum_buffer': tensor([[[[-4.5598e-05]],\n",
            "\n",
            "         [[ 5.2521e-05]],\n",
            "\n",
            "         [[-4.3755e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3775e-05]],\n",
            "\n",
            "         [[-6.0834e-05]],\n",
            "\n",
            "         [[ 1.4427e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6027e-05]],\n",
            "\n",
            "         [[ 2.6063e-05]],\n",
            "\n",
            "         [[-5.0966e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.6451e-05]],\n",
            "\n",
            "         [[ 5.0698e-05]],\n",
            "\n",
            "         [[ 1.1843e-04]]],\n",
            "\n",
            "\n",
            "        [[[-1.9332e-05]],\n",
            "\n",
            "         [[-1.2528e-04]],\n",
            "\n",
            "         [[-2.4819e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2252e-05]],\n",
            "\n",
            "         [[-1.4094e-04]],\n",
            "\n",
            "         [[-9.6677e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.9240e-05]],\n",
            "\n",
            "         [[ 5.8787e-05]],\n",
            "\n",
            "         [[ 7.5033e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9125e-05]],\n",
            "\n",
            "         [[-1.0761e-05]],\n",
            "\n",
            "         [[-4.2508e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.5844e-05]],\n",
            "\n",
            "         [[ 8.4863e-05]],\n",
            "\n",
            "         [[-4.8549e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3054e-04]],\n",
            "\n",
            "         [[ 7.0723e-05]],\n",
            "\n",
            "         [[ 9.4690e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 7.8996e-05]],\n",
            "\n",
            "         [[ 3.3206e-05]],\n",
            "\n",
            "         [[-4.2819e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0141e-05]],\n",
            "\n",
            "         [[-7.4604e-06]],\n",
            "\n",
            "         [[ 1.0751e-04]]]])}, 139: {'momentum_buffer': tensor([0.0010, 0.0010, 0.0009,  ..., 0.0010, 0.0009, 0.0011])}, 140: {'momentum_buffer': tensor([ 8.6106e-05, -8.0144e-05,  1.2289e-05,  ...,  2.5152e-05,\n",
            "        -7.8224e-05,  6.9450e-05])}, 141: {'momentum_buffer': tensor([[[[ 1.0607e-04]],\n",
            "\n",
            "         [[ 6.2713e-06]],\n",
            "\n",
            "         [[-8.0806e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0418e-04]],\n",
            "\n",
            "         [[-3.6635e-05]],\n",
            "\n",
            "         [[-4.5144e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.0988e-04]],\n",
            "\n",
            "         [[ 9.3622e-05]],\n",
            "\n",
            "         [[ 6.3624e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7661e-04]],\n",
            "\n",
            "         [[-5.4584e-06]],\n",
            "\n",
            "         [[-1.5951e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 8.3557e-05]],\n",
            "\n",
            "         [[ 1.0703e-04]],\n",
            "\n",
            "         [[ 6.6601e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.2983e-06]],\n",
            "\n",
            "         [[ 1.6803e-04]],\n",
            "\n",
            "         [[-2.4310e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.5439e-05]],\n",
            "\n",
            "         [[ 1.4498e-04]],\n",
            "\n",
            "         [[-6.7323e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.1582e-04]],\n",
            "\n",
            "         [[ 1.2469e-04]],\n",
            "\n",
            "         [[ 1.5167e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8539e-06]],\n",
            "\n",
            "         [[-8.9916e-05]],\n",
            "\n",
            "         [[-5.3911e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2271e-05]],\n",
            "\n",
            "         [[ 1.6378e-05]],\n",
            "\n",
            "         [[-4.5260e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 7.4528e-05]],\n",
            "\n",
            "         [[ 1.3523e-04]],\n",
            "\n",
            "         [[-1.4701e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7956e-05]],\n",
            "\n",
            "         [[ 1.0228e-05]],\n",
            "\n",
            "         [[-8.7260e-05]]]])}, 142: {'momentum_buffer': tensor([0.0010, 0.0010, 0.0010, 0.0013, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0011, 0.0010, 0.0008, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009,\n",
            "        0.0011, 0.0008, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0011, 0.0010, 0.0009, 0.0011, 0.0009, 0.0009, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0008, 0.0010, 0.0010, 0.0007, 0.0009, 0.0011,\n",
            "        0.0009, 0.0008, 0.0010, 0.0008, 0.0009, 0.0010, 0.0010, 0.0009, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0007, 0.0009, 0.0009,\n",
            "        0.0010, 0.0010, 0.0009, 0.0008, 0.0009, 0.0012, 0.0008, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0012, 0.0011, 0.0010, 0.0008, 0.0011, 0.0009, 0.0011,\n",
            "        0.0012, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0012, 0.0010,\n",
            "        0.0012, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009, 0.0011, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0008, 0.0010, 0.0011, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0012, 0.0011, 0.0010, 0.0010, 0.0010, 0.0011, 0.0012, 0.0010,\n",
            "        0.0008, 0.0010, 0.0009, 0.0009, 0.0010, 0.0011, 0.0009, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0008, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0008,\n",
            "        0.0009, 0.0010, 0.0008, 0.0010, 0.0010, 0.0011, 0.0009, 0.0011, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0012, 0.0009,\n",
            "        0.0009, 0.0011, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0009, 0.0011,\n",
            "        0.0011, 0.0010, 0.0011, 0.0010, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010,\n",
            "        0.0009, 0.0010, 0.0008, 0.0010, 0.0009, 0.0008, 0.0010, 0.0009, 0.0010,\n",
            "        0.0012, 0.0011, 0.0008, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0012,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0012, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0012, 0.0011, 0.0010, 0.0011, 0.0012, 0.0010, 0.0008, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009,\n",
            "        0.0010, 0.0008, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0007,\n",
            "        0.0010, 0.0009, 0.0009, 0.0012, 0.0009, 0.0011, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0011,\n",
            "        0.0009, 0.0009, 0.0010, 0.0011, 0.0009, 0.0008, 0.0010, 0.0011, 0.0009,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0011, 0.0009, 0.0011, 0.0009,\n",
            "        0.0014, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0011, 0.0012,\n",
            "        0.0010, 0.0011, 0.0010, 0.0011, 0.0011, 0.0009, 0.0011, 0.0009, 0.0008,\n",
            "        0.0010, 0.0012, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0009, 0.0011, 0.0009, 0.0009, 0.0013, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0012,\n",
            "        0.0010, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0011,\n",
            "        0.0010, 0.0009, 0.0012, 0.0011, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0009, 0.0011,\n",
            "        0.0011, 0.0008, 0.0013, 0.0010, 0.0012, 0.0008, 0.0011, 0.0009, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011, 0.0009, 0.0008,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0011, 0.0010, 0.0009,\n",
            "        0.0012, 0.0011, 0.0010, 0.0010, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010,\n",
            "        0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0011, 0.0009, 0.0009,\n",
            "        0.0012, 0.0011, 0.0011, 0.0011, 0.0009, 0.0011, 0.0012, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0008, 0.0011, 0.0011, 0.0009, 0.0010, 0.0009, 0.0011, 0.0009, 0.0011,\n",
            "        0.0010, 0.0009, 0.0011, 0.0008, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010,\n",
            "        0.0011, 0.0009, 0.0011, 0.0009, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0007, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0007, 0.0011, 0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0009, 0.0011, 0.0009, 0.0011, 0.0010, 0.0010,\n",
            "        0.0009, 0.0010, 0.0011, 0.0010, 0.0012, 0.0010, 0.0011, 0.0009, 0.0009,\n",
            "        0.0011, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0009, 0.0011])}, 143: {'momentum_buffer': tensor([-2.1169e-05,  9.4693e-05,  6.9080e-06,  1.2062e-04, -8.1199e-06,\n",
            "        -1.2328e-05, -7.6433e-05, -5.7139e-05, -2.3579e-05, -8.8940e-05,\n",
            "         4.4837e-05, -1.0432e-04, -1.0575e-04,  2.9372e-05, -1.1332e-04,\n",
            "        -6.2109e-05, -8.7552e-06, -1.8865e-05,  1.0129e-04,  1.1949e-04,\n",
            "        -2.6390e-05,  3.1987e-05, -9.7313e-05, -1.7423e-05, -6.7139e-05,\n",
            "         1.1133e-04, -3.8704e-05,  1.1150e-04, -2.2747e-04, -2.8470e-05,\n",
            "        -4.6701e-06,  1.3023e-04,  4.9497e-05, -6.6150e-05,  4.7160e-05,\n",
            "        -5.6033e-05,  3.3070e-05,  1.5459e-04, -1.6413e-04,  1.0256e-04,\n",
            "        -1.1260e-04,  1.5493e-04, -9.2112e-05, -7.1248e-05,  4.6076e-05,\n",
            "        -1.6114e-05, -3.6145e-05,  4.0394e-05, -1.5568e-04, -1.9254e-05,\n",
            "        -3.3953e-05, -6.3726e-05, -3.1386e-05,  2.9075e-06, -9.0510e-05,\n",
            "        -1.3916e-04, -7.5005e-05, -1.9883e-04, -7.6413e-05, -3.5878e-05,\n",
            "         4.2791e-05, -5.9363e-05, -8.1915e-05, -3.0778e-05, -1.7072e-05,\n",
            "        -1.9673e-04,  1.8502e-04, -1.0482e-04, -9.7241e-06, -3.0604e-04,\n",
            "        -1.9288e-04,  2.5078e-06, -2.9383e-05, -1.1714e-04, -1.9525e-04,\n",
            "        -1.7060e-04, -5.1103e-05,  5.4626e-05, -5.5816e-05, -7.6354e-05,\n",
            "        -1.1931e-04, -2.3555e-05,  1.7993e-04,  9.6130e-05, -3.6578e-05,\n",
            "        -6.3743e-06, -1.1013e-04,  7.0013e-05, -1.5747e-04,  1.6264e-04,\n",
            "        -1.2210e-05, -1.1720e-04, -7.2081e-05,  1.0294e-05,  4.2529e-05,\n",
            "         3.2107e-05, -3.6800e-05,  6.9071e-05,  9.6928e-05,  6.8967e-05,\n",
            "        -1.6391e-04, -3.0574e-05, -1.4505e-05, -1.2412e-04,  1.1069e-04,\n",
            "         7.8716e-06,  5.3662e-05,  7.1388e-05, -3.6484e-05, -3.2918e-05,\n",
            "         8.2175e-05, -3.4281e-05, -1.2421e-04, -5.9498e-05,  8.5492e-06,\n",
            "         1.2740e-04,  1.0585e-04, -1.3828e-04,  5.4961e-05,  3.2501e-05,\n",
            "        -8.4298e-05, -1.0287e-04,  2.1873e-05,  1.6637e-04, -3.8052e-05,\n",
            "        -8.6030e-05,  6.1363e-05,  2.4301e-05, -4.2519e-05, -5.6984e-05,\n",
            "         1.3002e-04, -1.9683e-05,  9.4062e-06,  1.6308e-04, -1.2171e-05,\n",
            "        -6.2604e-05,  6.4965e-05, -4.8925e-05, -4.1024e-05, -1.0458e-05,\n",
            "        -7.2668e-06, -1.5448e-04, -4.4450e-05,  1.1030e-04, -2.6653e-05,\n",
            "        -7.3935e-05, -3.3721e-05,  7.6229e-05, -3.8661e-06, -3.0750e-05,\n",
            "        -3.4971e-05, -1.9709e-04,  5.3647e-05, -6.7435e-05, -4.9181e-05,\n",
            "        -4.4698e-05, -2.9008e-05, -6.2326e-05,  9.3225e-06,  5.6223e-06,\n",
            "        -7.5881e-05, -1.0323e-04, -6.6245e-05, -1.0218e-05, -1.7845e-04,\n",
            "        -8.0082e-05, -9.0878e-06, -2.4495e-05, -3.3573e-05,  1.9913e-05,\n",
            "        -1.0390e-04,  1.3301e-05,  5.3042e-05, -8.2642e-05, -1.4214e-04,\n",
            "         1.9560e-04,  2.2644e-05, -1.0401e-04,  8.5489e-05, -1.1931e-04,\n",
            "        -5.5530e-05,  1.8022e-05, -9.2587e-05,  4.7048e-05, -8.5937e-05,\n",
            "        -1.0630e-05,  5.3910e-05, -6.4142e-05, -4.4587e-05, -4.6603e-05,\n",
            "         1.3326e-05,  1.1484e-04, -6.8865e-05, -7.0769e-05, -1.4801e-05,\n",
            "        -1.3985e-04, -1.5480e-05,  1.8051e-05,  1.8095e-05, -2.6721e-06,\n",
            "        -2.3530e-04, -1.9486e-05,  6.4042e-05, -1.3690e-04,  1.4130e-04,\n",
            "        -1.2762e-04, -2.3351e-05,  7.2213e-05,  7.0300e-05, -1.7139e-04,\n",
            "        -2.2838e-07, -2.9352e-05,  9.1019e-05, -7.2294e-06, -2.8049e-05,\n",
            "        -2.2935e-05,  5.6799e-05, -4.0649e-05, -8.7377e-05, -4.0967e-05,\n",
            "         7.9356e-05,  9.1635e-06,  6.6119e-05, -9.9381e-05,  7.1137e-05,\n",
            "         4.4374e-05, -2.1475e-05,  1.1323e-04,  1.2076e-04,  9.9731e-05,\n",
            "        -2.1980e-05, -2.4467e-04,  3.9541e-05,  1.3002e-04,  5.6525e-05,\n",
            "         3.9239e-05,  9.7790e-05, -2.2747e-05, -6.8191e-05, -1.8143e-04,\n",
            "        -6.1574e-05,  1.0618e-04,  6.1316e-06,  1.2781e-04, -1.0759e-04,\n",
            "        -2.3758e-05, -1.3361e-04, -9.7358e-06, -1.4813e-04,  8.9480e-05,\n",
            "        -1.2277e-04, -4.1534e-05, -7.8051e-05, -1.0254e-04, -2.9006e-05,\n",
            "         1.7752e-05,  2.0894e-05,  6.7848e-05,  6.3243e-05, -8.0432e-06,\n",
            "        -1.3517e-04, -1.2978e-04, -1.7860e-04, -1.9303e-04,  2.3925e-04,\n",
            "         4.4297e-06, -1.6882e-05, -1.3108e-05,  8.3470e-05,  6.5359e-05,\n",
            "        -6.8946e-05, -2.4640e-05, -3.6474e-05, -1.6002e-04, -3.0566e-05,\n",
            "         3.4608e-05, -2.1325e-05,  4.8924e-05,  1.3271e-04, -7.0385e-05,\n",
            "         2.2997e-05, -2.9520e-05,  1.6550e-04, -8.0139e-05, -1.8039e-04,\n",
            "         1.6799e-05,  6.0191e-06,  5.7262e-05, -2.9303e-05, -8.8013e-05,\n",
            "        -6.6047e-05, -9.3527e-05,  1.6347e-05,  2.2936e-05,  5.1879e-05,\n",
            "         1.5434e-05, -7.8081e-05,  2.0946e-04, -1.9588e-05, -1.2672e-04,\n",
            "        -1.4324e-05,  1.3188e-05, -5.2765e-05,  9.5837e-05,  3.3168e-05,\n",
            "         1.0923e-04,  2.8903e-05,  4.1339e-05,  7.7712e-05, -6.4088e-05,\n",
            "         5.6533e-05, -4.1214e-05,  7.5213e-05, -1.5630e-04, -2.4042e-04,\n",
            "         8.4714e-05,  7.1941e-05,  6.5564e-05, -1.7579e-04, -2.0154e-05,\n",
            "         4.7520e-05, -1.0900e-04,  3.9894e-07, -1.5137e-04,  4.2168e-05,\n",
            "        -1.8010e-06,  3.8100e-05, -7.0357e-05,  1.8833e-04,  4.1281e-05,\n",
            "        -5.1031e-05, -1.7390e-05, -2.5957e-05, -4.1907e-05, -3.6700e-06,\n",
            "        -3.5477e-05,  9.9506e-06,  2.1710e-05,  9.7887e-06, -1.9450e-05,\n",
            "         2.1357e-05, -2.0893e-05,  1.0852e-04, -1.3892e-04,  6.2694e-06,\n",
            "        -5.4683e-05, -2.0985e-04, -9.6537e-05, -3.7602e-05,  1.0020e-04,\n",
            "        -4.5176e-05, -3.7757e-05, -3.0473e-05, -3.0298e-05,  6.1049e-05,\n",
            "        -2.0293e-05, -8.6632e-05, -6.8390e-06, -1.1406e-04,  2.5039e-05,\n",
            "         7.7855e-06, -3.5425e-05,  1.5367e-05,  1.1306e-05, -1.1728e-04,\n",
            "         1.0038e-04,  2.0340e-05, -5.9305e-05,  2.6803e-05,  1.7631e-04,\n",
            "        -8.3710e-05,  8.3217e-05, -8.9646e-05,  5.9162e-05, -1.5512e-04,\n",
            "         2.0615e-04,  5.0696e-05,  1.9117e-05, -1.0446e-04,  2.3141e-05,\n",
            "        -8.4233e-05, -2.4014e-05,  3.5538e-05,  3.9143e-05,  7.0614e-05,\n",
            "        -8.7016e-05, -5.7914e-05,  9.3790e-05,  1.0835e-04, -1.7779e-04,\n",
            "         1.8405e-05,  2.8604e-05,  3.3847e-05,  8.0002e-05,  2.7483e-05,\n",
            "         7.9693e-05, -1.3079e-04, -6.4890e-05, -7.8653e-05, -5.5179e-05,\n",
            "         9.1497e-05,  4.5074e-05,  6.0313e-06, -8.3576e-05, -4.6545e-05,\n",
            "         8.8193e-05,  3.6070e-05, -6.7452e-05, -8.0212e-05, -6.5256e-05,\n",
            "         4.6317e-05,  2.5262e-05, -2.8091e-05,  8.9521e-05,  6.2816e-05,\n",
            "        -1.2308e-05, -9.5200e-06, -5.1460e-05,  1.3634e-06, -2.9689e-05,\n",
            "        -5.0566e-05, -8.7366e-05,  6.2330e-05,  3.7338e-06, -3.5044e-07,\n",
            "         2.0900e-05,  9.5298e-05, -4.3447e-05,  7.5150e-05,  4.6863e-05,\n",
            "        -6.2377e-05, -1.1746e-05,  9.4270e-05, -8.2627e-06,  1.5544e-05,\n",
            "        -5.8921e-05, -9.4577e-05,  7.6635e-05, -5.5714e-05,  1.7347e-05,\n",
            "        -3.5761e-05, -1.1558e-04, -4.9745e-05,  8.7476e-05,  2.2271e-05,\n",
            "        -9.0981e-05, -9.2388e-05,  1.8382e-04, -2.2985e-04,  4.6152e-05,\n",
            "        -7.4143e-05,  2.8881e-05,  1.3768e-04, -1.2733e-04, -6.5677e-05,\n",
            "        -9.8742e-05,  8.6551e-05,  1.9436e-06, -3.6540e-05,  4.5692e-05,\n",
            "        -8.4807e-05,  2.5659e-06, -7.9502e-05, -1.0610e-04, -1.3099e-04,\n",
            "         1.2576e-04,  2.6952e-05,  2.4090e-05, -1.5448e-04, -2.4380e-04,\n",
            "        -8.7351e-05, -8.0817e-05, -9.0661e-05,  3.4592e-06, -6.4931e-05,\n",
            "        -4.0996e-05, -4.3747e-05, -1.9303e-04,  6.4960e-05,  3.7083e-05,\n",
            "        -9.3147e-05, -3.8167e-05, -1.6079e-05, -2.3968e-05,  1.3079e-04,\n",
            "         3.4203e-05, -3.2524e-05, -8.1462e-05,  1.0854e-04, -3.3456e-05,\n",
            "         5.8738e-05, -1.8520e-05,  8.9898e-05, -9.1041e-05,  2.9539e-05,\n",
            "        -2.4505e-05,  1.9720e-05, -2.8528e-05, -3.3104e-05,  1.0203e-05,\n",
            "         1.7644e-05,  9.1533e-05, -1.1096e-04, -1.4132e-04, -1.1796e-04,\n",
            "         6.6627e-06, -1.0880e-04, -1.2692e-04,  9.9812e-07,  3.8454e-05,\n",
            "        -9.6069e-05,  6.5621e-05])}, 144: {'momentum_buffer': tensor([[[[-2.0061e-07, -6.7928e-06,  6.9462e-05],\n",
            "          [ 1.1086e-05, -2.4318e-05,  1.9227e-05],\n",
            "          [ 5.8508e-05,  2.9371e-05,  1.2506e-04]],\n",
            "\n",
            "         [[-1.8428e-05,  4.1512e-06, -4.7663e-05],\n",
            "          [-3.1326e-05, -4.1792e-05, -1.9703e-05],\n",
            "          [ 7.7919e-06, -1.0571e-04,  1.7306e-05]],\n",
            "\n",
            "         [[-9.8515e-06, -3.6533e-05,  3.8614e-05],\n",
            "          [ 1.1782e-04,  8.0800e-05,  1.0475e-04],\n",
            "          [ 1.3420e-04,  1.0547e-04,  6.9686e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4026e-05, -3.7722e-05,  1.3730e-05],\n",
            "          [ 3.8604e-05, -1.1968e-05, -2.0891e-06],\n",
            "          [ 1.9712e-05,  2.8540e-05,  9.3465e-05]],\n",
            "\n",
            "         [[-2.5416e-05, -1.8265e-04, -8.5912e-05],\n",
            "          [ 1.2947e-05, -1.8048e-05, -7.4159e-05],\n",
            "          [ 3.1612e-05,  4.7270e-05, -4.0972e-05]],\n",
            "\n",
            "         [[-5.6047e-05,  3.0924e-05,  5.4556e-05],\n",
            "          [ 2.9518e-05,  1.7261e-06,  1.2262e-04],\n",
            "          [-6.5445e-05,  1.6052e-05,  3.0118e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.6709e-06,  2.5093e-05,  6.2723e-05],\n",
            "          [ 7.6728e-05,  6.1136e-05,  6.8896e-06],\n",
            "          [ 7.8836e-06,  3.9208e-06, -2.0324e-05]],\n",
            "\n",
            "         [[-7.5907e-05, -1.5242e-05,  5.7521e-05],\n",
            "          [-1.5980e-05,  3.5266e-05,  1.1489e-04],\n",
            "          [-4.3089e-05, -4.0361e-05, -6.2077e-05]],\n",
            "\n",
            "         [[ 4.4269e-05,  1.4966e-05,  8.1168e-05],\n",
            "          [ 4.9473e-05,  4.2776e-05,  8.6108e-06],\n",
            "          [-8.3503e-06, -3.8373e-06,  3.5425e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.0133e-05,  1.1050e-04,  2.0957e-05],\n",
            "          [ 6.8971e-05,  3.6149e-05,  6.5314e-05],\n",
            "          [ 2.9354e-05, -3.9784e-06,  4.9457e-05]],\n",
            "\n",
            "         [[-4.6763e-06,  7.0567e-06, -2.7416e-05],\n",
            "          [ 9.0245e-05,  9.9776e-05,  1.0106e-04],\n",
            "          [ 7.0205e-05, -3.8233e-06,  2.3369e-06]],\n",
            "\n",
            "         [[-6.4713e-05,  2.8105e-05,  1.8420e-06],\n",
            "          [ 5.9825e-05, -3.6217e-05,  9.2175e-06],\n",
            "          [-3.5240e-05, -7.9367e-05,  3.4801e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.0946e-05,  6.6652e-05,  9.6594e-05],\n",
            "          [ 5.1290e-05,  3.2686e-05,  5.3117e-05],\n",
            "          [ 1.2508e-05,  3.1714e-05,  9.3245e-05]],\n",
            "\n",
            "         [[ 1.3057e-05,  4.4251e-05,  3.2988e-05],\n",
            "          [ 1.8388e-05, -3.7572e-05,  5.5118e-05],\n",
            "          [ 3.2791e-05, -2.6417e-05,  1.8428e-05]],\n",
            "\n",
            "         [[ 1.5302e-05,  8.2003e-05,  2.6181e-05],\n",
            "          [ 1.9255e-05, -1.4302e-05, -1.4447e-06],\n",
            "          [ 1.1041e-05,  5.8331e-05,  8.0001e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7700e-05,  4.5077e-05,  5.9277e-05],\n",
            "          [ 2.1732e-05, -3.5680e-05,  1.2222e-05],\n",
            "          [ 5.1443e-05,  4.3590e-05,  7.7409e-05]],\n",
            "\n",
            "         [[ 6.6251e-05,  2.7226e-05,  2.8242e-06],\n",
            "          [ 4.2682e-05,  6.7243e-05,  5.7230e-05],\n",
            "          [ 3.0732e-05,  3.6216e-05,  1.5265e-05]],\n",
            "\n",
            "         [[ 1.0234e-04,  4.1292e-05,  7.0398e-05],\n",
            "          [ 3.0715e-05,  6.6357e-05,  2.4474e-06],\n",
            "          [-1.9835e-05,  6.3544e-05,  6.3104e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.4157e-05, -1.6387e-05,  7.6161e-06],\n",
            "          [ 1.6037e-05,  2.2221e-05,  3.5605e-05],\n",
            "          [-1.4085e-05, -6.6664e-05,  4.4304e-05]],\n",
            "\n",
            "         [[-5.9877e-05, -4.2444e-05, -9.2458e-05],\n",
            "          [-4.8476e-05, -1.5091e-04, -7.0135e-05],\n",
            "          [-1.2410e-04, -1.0065e-04, -6.7810e-05]],\n",
            "\n",
            "         [[-6.1509e-05, -8.9407e-05, -9.2372e-05],\n",
            "          [-4.4559e-05, -5.5291e-05, -1.0141e-04],\n",
            "          [-3.4982e-05, -2.5816e-05,  5.9161e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.2780e-05, -5.8008e-05,  4.8760e-05],\n",
            "          [ 3.4866e-06, -2.2262e-05,  6.2855e-05],\n",
            "          [ 2.5664e-05, -4.4437e-05,  3.8644e-05]],\n",
            "\n",
            "         [[-1.0837e-05,  1.2207e-05,  6.2051e-05],\n",
            "          [-3.1380e-05,  1.1650e-06,  3.4974e-05],\n",
            "          [ 7.0602e-05,  5.2098e-05,  4.1798e-05]],\n",
            "\n",
            "         [[ 3.7955e-05,  5.0853e-05,  8.1549e-06],\n",
            "          [-1.4038e-05, -4.6112e-06,  1.3501e-06],\n",
            "          [ 9.8941e-06,  3.6455e-05,  6.5901e-05]]],\n",
            "\n",
            "\n",
            "        [[[-2.6935e-05, -5.0653e-05, -4.7932e-05],\n",
            "          [-7.3310e-05, -3.3489e-05,  8.6705e-06],\n",
            "          [ 5.6012e-05,  2.0842e-06,  2.6015e-05]],\n",
            "\n",
            "         [[ 1.5135e-05, -1.8103e-05,  1.0719e-06],\n",
            "          [-3.5197e-07,  9.7308e-07,  2.2427e-05],\n",
            "          [-2.6970e-05,  2.1691e-05, -2.1038e-05]],\n",
            "\n",
            "         [[ 3.4780e-05,  1.1485e-04,  7.4669e-05],\n",
            "          [ 2.2738e-05, -7.8043e-06, -2.3248e-06],\n",
            "          [ 6.8274e-05, -5.6118e-06, -1.2784e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.5927e-06, -3.0826e-06, -4.5551e-05],\n",
            "          [-3.4939e-05, -5.8008e-05, -1.8052e-05],\n",
            "          [ 1.8310e-05, -3.8049e-06,  8.1205e-06]],\n",
            "\n",
            "         [[-3.3916e-06, -7.7002e-05,  1.0474e-05],\n",
            "          [ 3.8401e-06, -9.1698e-05, -2.7951e-05],\n",
            "          [ 1.8516e-06,  2.7535e-06,  7.0793e-05]],\n",
            "\n",
            "         [[-7.5340e-06,  4.5791e-05,  2.7873e-05],\n",
            "          [ 3.0663e-05,  5.3234e-05, -6.6794e-05],\n",
            "          [ 7.0899e-05,  5.7145e-05,  1.8443e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8305e-05, -8.8683e-05, -7.1491e-06],\n",
            "          [-2.4453e-05, -4.6081e-05, -2.8597e-05],\n",
            "          [ 3.6388e-05, -1.3167e-05,  4.0745e-05]],\n",
            "\n",
            "         [[ 3.4134e-05, -2.7206e-05,  4.8861e-05],\n",
            "          [ 4.1168e-05,  5.4511e-05,  6.2068e-05],\n",
            "          [ 5.3371e-05,  4.5602e-05,  6.8268e-05]],\n",
            "\n",
            "         [[ 1.4282e-05, -4.0149e-05, -4.9313e-05],\n",
            "          [ 9.4983e-05,  4.1409e-05,  7.3045e-05],\n",
            "          [ 1.1064e-04,  2.2110e-05,  2.7073e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.6595e-06,  1.9610e-05, -3.5642e-05],\n",
            "          [ 5.8506e-06,  5.7111e-06, -4.9503e-07],\n",
            "          [-1.1580e-05, -2.6330e-05,  2.7135e-05]],\n",
            "\n",
            "         [[-1.1434e-05,  6.0543e-07,  2.2450e-05],\n",
            "          [-5.4444e-06, -5.8699e-05,  4.0974e-05],\n",
            "          [-1.5073e-05, -2.0965e-05, -2.9747e-05]],\n",
            "\n",
            "         [[ 8.5691e-05,  5.7380e-05,  2.4555e-05],\n",
            "          [ 6.8508e-05,  2.4607e-07, -1.4103e-06],\n",
            "          [ 6.2623e-05,  2.3939e-05, -1.6059e-05]]]])}, 145: {'momentum_buffer': tensor([0.0010, 0.0011, 0.0011, 0.0009, 0.0009, 0.0011, 0.0009, 0.0010, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0011, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0010, 0.0011,\n",
            "        0.0009, 0.0012, 0.0009, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0008, 0.0010, 0.0009, 0.0012, 0.0009, 0.0012, 0.0010, 0.0010,\n",
            "        0.0011, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0012, 0.0010, 0.0011,\n",
            "        0.0009, 0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0011, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0009, 0.0011, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0012, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0011, 0.0010, 0.0011, 0.0011, 0.0009, 0.0010,\n",
            "        0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0011, 0.0009,\n",
            "        0.0008, 0.0011, 0.0013, 0.0009, 0.0010, 0.0008, 0.0011, 0.0009, 0.0010,\n",
            "        0.0011, 0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0009, 0.0009, 0.0013,\n",
            "        0.0009, 0.0010, 0.0010, 0.0011, 0.0008, 0.0009, 0.0009, 0.0012, 0.0009,\n",
            "        0.0011, 0.0008, 0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0009, 0.0009,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009,\n",
            "        0.0011, 0.0012, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0011, 0.0009,\n",
            "        0.0010, 0.0010, 0.0012, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0011,\n",
            "        0.0009, 0.0010, 0.0011, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010,\n",
            "        0.0009, 0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0011, 0.0011, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0011, 0.0013, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0009, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0009, 0.0012, 0.0009,\n",
            "        0.0011, 0.0010, 0.0011, 0.0011, 0.0009, 0.0010, 0.0010, 0.0008, 0.0010,\n",
            "        0.0009, 0.0009, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009, 0.0011, 0.0009,\n",
            "        0.0010, 0.0011, 0.0009, 0.0011, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0008, 0.0012, 0.0010, 0.0010, 0.0012, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0011, 0.0008, 0.0009, 0.0010, 0.0012, 0.0011, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0012, 0.0009, 0.0010, 0.0008,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0011, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0009, 0.0010, 0.0011, 0.0009, 0.0009, 0.0009, 0.0010, 0.0011, 0.0009,\n",
            "        0.0010, 0.0008, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0012, 0.0011,\n",
            "        0.0008, 0.0011, 0.0011, 0.0008, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0012, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0008, 0.0011, 0.0009,\n",
            "        0.0009, 0.0009, 0.0009, 0.0012, 0.0009, 0.0010, 0.0010, 0.0009, 0.0012,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0009, 0.0011, 0.0010, 0.0010, 0.0011, 0.0009, 0.0011, 0.0009, 0.0010,\n",
            "        0.0011, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0011, 0.0008, 0.0009, 0.0009, 0.0009, 0.0009, 0.0011, 0.0009,\n",
            "        0.0009, 0.0011, 0.0009, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010,\n",
            "        0.0009, 0.0008, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009,\n",
            "        0.0011, 0.0011, 0.0010, 0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0012, 0.0010, 0.0009, 0.0009, 0.0009, 0.0010, 0.0011,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010])}, 146: {'momentum_buffer': tensor([ 6.5326e-05,  6.8817e-05,  1.0942e-04,  2.2071e-06, -2.3822e-05,\n",
            "         5.3459e-05, -1.9867e-04, -7.6746e-05, -9.1372e-05,  1.2275e-05,\n",
            "        -1.0785e-04, -2.6357e-05, -1.4633e-04,  1.1140e-04, -5.4495e-05,\n",
            "        -8.1357e-05, -5.7593e-07, -6.3194e-05,  1.5702e-04, -2.5787e-05,\n",
            "        -4.2469e-05, -1.1921e-04, -2.5347e-05,  5.5381e-05, -2.9826e-05,\n",
            "        -8.4832e-05,  6.8011e-05, -1.4023e-05,  3.0525e-05,  1.0723e-06,\n",
            "        -1.1421e-05, -1.6752e-05,  7.4345e-05,  5.6973e-05,  1.1377e-05,\n",
            "         3.0023e-05, -6.3916e-05,  2.2591e-04, -1.5964e-04, -2.5834e-05,\n",
            "        -5.9603e-05,  4.4175e-05, -1.9189e-04,  3.0425e-06,  2.0935e-05,\n",
            "         5.2179e-05, -1.4834e-04, -2.5021e-05, -1.5709e-05, -6.6288e-06,\n",
            "        -6.1625e-05, -2.4059e-04, -5.7637e-05, -1.0830e-04, -3.8975e-06,\n",
            "         6.3966e-05, -2.1496e-05, -2.4867e-05, -1.3607e-05, -1.2963e-04,\n",
            "         2.3133e-04,  2.8405e-05, -3.0091e-05,  4.0309e-05, -1.8512e-04,\n",
            "        -4.6097e-05, -7.3625e-05,  9.8880e-05, -4.0336e-05,  9.5046e-05,\n",
            "        -1.8444e-06,  7.4257e-06,  1.4420e-06, -2.6945e-06,  7.1890e-05,\n",
            "         3.2040e-05, -8.7819e-05,  8.0829e-06,  8.9725e-05, -2.9575e-05,\n",
            "        -6.6185e-05,  5.7893e-05, -1.0913e-04,  2.5614e-05, -1.3086e-04,\n",
            "        -1.0261e-05, -7.1406e-05, -4.3795e-07, -8.4074e-05, -4.4337e-05,\n",
            "        -1.0477e-04, -1.5804e-05, -1.6063e-04, -1.2523e-04,  1.0654e-05,\n",
            "        -3.5089e-05,  1.7771e-04, -4.0133e-05,  1.0246e-04, -1.7765e-04,\n",
            "        -4.6883e-05,  9.8959e-06,  5.1887e-05,  1.7666e-05, -1.2495e-04,\n",
            "        -8.8854e-05,  2.7676e-04,  5.4918e-05,  1.2890e-04, -8.0585e-05,\n",
            "        -9.2463e-05,  5.5819e-05, -1.1169e-04, -3.7206e-05, -8.7056e-05,\n",
            "         7.2784e-05,  3.7003e-05, -1.6987e-04,  9.9162e-05,  5.3008e-05,\n",
            "         3.4334e-05,  5.6131e-05,  1.3902e-04,  4.2282e-05,  1.5883e-05,\n",
            "        -2.2905e-05, -1.3435e-04, -4.0693e-05, -4.7198e-05, -2.4431e-05,\n",
            "        -3.6069e-05, -3.1507e-05,  7.8006e-05, -1.9310e-05,  6.5057e-06,\n",
            "         1.1112e-04,  9.0488e-05,  2.1425e-04, -8.3843e-05,  1.7629e-05,\n",
            "         4.1861e-06, -2.0822e-05, -1.8997e-05,  8.5617e-05, -2.8894e-05,\n",
            "        -1.0781e-04,  8.2298e-05, -3.4657e-05, -5.0744e-05,  1.1032e-04,\n",
            "         4.6945e-06, -1.4740e-04,  3.8900e-05, -7.6796e-05, -6.5393e-05,\n",
            "         8.0862e-05,  3.1889e-05, -8.8831e-05, -9.8787e-06, -8.9376e-05,\n",
            "        -1.7261e-05, -1.3621e-04, -9.6259e-05, -3.1587e-05,  3.7277e-05,\n",
            "        -7.1446e-05,  1.3073e-05, -5.9483e-05,  8.1992e-05, -1.4264e-05,\n",
            "        -2.0963e-05,  2.2658e-05,  1.5884e-04, -5.7873e-05,  9.1609e-05,\n",
            "        -1.0169e-05, -3.5544e-05, -3.5014e-05,  2.0058e-05,  1.5963e-04,\n",
            "        -6.2972e-05, -3.7011e-05, -1.7069e-05,  7.1987e-05, -9.8402e-05,\n",
            "        -2.2284e-05,  7.6594e-05,  5.0826e-05, -1.4830e-04, -5.2051e-07,\n",
            "        -1.3119e-04,  9.8662e-05,  5.5256e-05, -9.0700e-05, -6.4258e-05,\n",
            "         3.0274e-05, -1.5604e-04, -8.5782e-06, -3.4812e-05, -1.9698e-05,\n",
            "         1.3228e-05, -7.5248e-06, -6.3279e-06, -7.2073e-05, -4.5050e-05,\n",
            "        -1.9017e-06, -6.3002e-05, -3.7092e-05, -1.0605e-05,  7.1634e-05,\n",
            "         1.1663e-04,  2.1401e-05,  3.8223e-06, -8.7043e-06, -3.5318e-05,\n",
            "        -1.1064e-04,  2.0673e-05,  1.2712e-04, -2.5200e-05,  1.9686e-05,\n",
            "        -5.1173e-05, -5.0474e-05, -9.1055e-05,  2.0566e-05, -1.5780e-04,\n",
            "         2.5280e-05,  2.4533e-05,  1.2694e-04, -1.6672e-04, -7.7857e-05,\n",
            "         5.3733e-05, -6.0462e-05, -2.2765e-05,  1.1738e-04, -2.8663e-06,\n",
            "        -9.6298e-05,  7.8520e-05,  2.7869e-05, -1.1844e-05, -4.6882e-05,\n",
            "        -2.5823e-05, -6.0342e-05, -1.5154e-05, -1.0101e-04, -4.6609e-05,\n",
            "         2.6923e-05,  4.9608e-05, -2.1208e-05, -6.2078e-05,  7.4323e-05,\n",
            "         2.7874e-05,  5.7289e-05,  3.1679e-05, -1.4238e-05,  1.9367e-05,\n",
            "         1.0740e-05, -1.2193e-04,  1.2974e-04,  1.7277e-04,  3.4660e-06,\n",
            "         7.3026e-06, -8.8465e-05, -3.2574e-05, -3.6464e-06, -9.0680e-05,\n",
            "        -5.4504e-05,  5.0906e-05, -3.9627e-05, -7.8219e-05, -3.8735e-05,\n",
            "        -4.6580e-05,  1.1661e-04,  2.8332e-05,  1.1926e-04, -2.7513e-05,\n",
            "         8.3825e-05, -3.9938e-05,  1.5898e-04, -1.8632e-04,  8.5250e-05,\n",
            "         1.2745e-05,  5.0728e-05,  7.4278e-05, -1.9928e-04,  3.2441e-05,\n",
            "        -3.6522e-05, -3.9403e-05, -2.5409e-05, -3.1866e-05, -5.8895e-05,\n",
            "        -8.5393e-05, -1.2252e-04, -1.7272e-05,  3.0828e-05,  2.8106e-05,\n",
            "         1.2038e-04, -1.7503e-04,  4.7269e-05, -2.7983e-05, -4.7874e-05,\n",
            "         2.2741e-05, -1.6478e-05, -1.5357e-04, -1.8789e-06, -2.4063e-04,\n",
            "        -1.2827e-05, -2.1456e-05, -3.4809e-05, -3.1864e-05, -2.6035e-05,\n",
            "         1.6607e-05, -7.8905e-05,  3.6871e-05, -1.0352e-04, -1.3761e-04,\n",
            "        -6.4130e-05,  8.2113e-05,  1.9081e-06,  5.3855e-05, -5.7886e-07,\n",
            "        -1.1404e-04, -8.4770e-05,  1.8271e-04, -5.2997e-05,  3.0178e-05,\n",
            "        -9.0526e-05,  8.8270e-05,  1.8407e-05, -6.5872e-05,  1.3501e-04,\n",
            "        -9.3291e-07, -1.0967e-04, -1.1196e-04, -5.7371e-06,  3.7728e-05,\n",
            "        -1.1823e-05, -1.0346e-04, -5.9226e-05, -3.9779e-05, -3.5339e-05,\n",
            "         4.1130e-05, -5.9577e-05,  6.6314e-05,  4.6576e-05, -6.5756e-05,\n",
            "         6.0182e-05, -7.3518e-05,  1.1082e-04, -9.2269e-05, -5.7591e-05,\n",
            "        -2.8323e-05, -6.3139e-05, -9.2124e-05, -3.1835e-05, -1.0805e-04,\n",
            "        -5.3014e-06,  7.7230e-05, -1.1686e-04, -1.4989e-04, -2.8186e-05,\n",
            "        -1.2700e-04,  7.7771e-05,  6.9414e-05, -6.3338e-05, -3.8305e-05,\n",
            "        -5.6054e-05, -5.4446e-05,  7.4815e-06, -1.1618e-05,  3.6447e-05,\n",
            "        -1.2033e-04, -4.0970e-05, -7.8451e-05,  3.2679e-05,  3.2556e-05,\n",
            "         7.5530e-05,  6.2802e-05, -9.8444e-05,  1.1324e-04, -1.3912e-05,\n",
            "        -1.2461e-05, -2.5167e-05, -2.1492e-05, -6.4418e-06,  7.7856e-06,\n",
            "         2.6738e-05,  7.3644e-06,  2.9021e-05,  8.2430e-05,  7.7460e-05,\n",
            "        -1.1034e-04, -6.9774e-05,  2.4813e-05,  1.1493e-04,  2.3589e-05,\n",
            "        -5.8442e-06,  1.2778e-04,  4.1529e-05,  1.6780e-06, -4.6213e-06,\n",
            "        -2.1677e-05, -6.0966e-06, -4.8754e-05,  3.9291e-05,  5.2506e-05,\n",
            "        -8.7179e-05, -5.6708e-07, -2.5129e-05,  2.6887e-04, -4.9923e-05,\n",
            "        -7.1689e-05,  1.0163e-04, -9.7829e-05,  4.1888e-05, -1.2045e-04,\n",
            "        -9.7079e-05,  1.2666e-04, -3.2220e-05,  5.2397e-05,  5.9810e-06,\n",
            "        -3.3734e-05, -3.0385e-05, -9.6602e-06, -9.3508e-05,  1.0011e-04,\n",
            "         7.6240e-05, -3.6311e-05, -5.0732e-05,  1.9952e-05,  5.8444e-05,\n",
            "        -6.1142e-05, -1.3034e-04,  3.1830e-05, -6.3622e-05, -1.7642e-04,\n",
            "        -1.8405e-04, -1.0471e-04,  1.1382e-04, -4.2128e-05, -4.4117e-05,\n",
            "         4.4384e-05, -5.2647e-05, -4.4243e-06, -1.0752e-04, -9.8372e-06,\n",
            "        -8.3812e-05, -1.5713e-04,  9.1101e-06,  4.7857e-05, -1.1068e-04,\n",
            "         2.4571e-05,  9.1135e-05, -1.1204e-04, -1.2237e-04, -2.9072e-05,\n",
            "        -1.0848e-04, -1.3186e-04,  1.0845e-05, -1.1515e-04, -1.7461e-04,\n",
            "         9.5281e-05, -1.9658e-04, -2.4344e-05,  1.2086e-04, -4.5550e-05,\n",
            "        -5.1609e-05,  3.7904e-05, -6.2454e-05, -2.9678e-05,  3.5745e-05,\n",
            "         1.5231e-05,  2.8523e-06, -6.9977e-05, -1.7163e-05, -5.5448e-05,\n",
            "        -1.1811e-04,  4.5286e-05, -2.2747e-05, -5.6026e-05, -4.0121e-05,\n",
            "        -1.9312e-04, -4.1387e-05,  5.9763e-06,  4.9724e-05,  3.5703e-05,\n",
            "         3.5850e-05, -1.6314e-05,  9.9149e-07, -7.1489e-05, -5.1420e-05,\n",
            "        -1.1987e-04,  3.8863e-05, -7.1756e-06, -6.3457e-05, -1.1298e-04,\n",
            "         3.6239e-05,  9.8457e-05,  9.7702e-05, -5.2889e-05, -4.6754e-05,\n",
            "         2.8721e-05, -1.5404e-04, -9.8408e-06,  5.2911e-05, -6.1973e-05,\n",
            "        -5.0637e-05,  9.0877e-05,  1.8466e-05, -1.8693e-05,  9.3868e-06,\n",
            "        -8.1852e-07,  5.6322e-05])}, 147: {'momentum_buffer': tensor([[[[ 6.7329e-05]],\n",
            "\n",
            "         [[-1.4081e-05]],\n",
            "\n",
            "         [[ 1.2803e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.3919e-05]],\n",
            "\n",
            "         [[ 6.6129e-05]],\n",
            "\n",
            "         [[ 1.3656e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 5.0453e-05]],\n",
            "\n",
            "         [[ 6.2703e-05]],\n",
            "\n",
            "         [[-4.2768e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5827e-06]],\n",
            "\n",
            "         [[ 1.2164e-04]],\n",
            "\n",
            "         [[ 1.5797e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 9.0955e-05]],\n",
            "\n",
            "         [[-1.8263e-05]],\n",
            "\n",
            "         [[ 7.1563e-08]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.8090e-05]],\n",
            "\n",
            "         [[-6.5256e-06]],\n",
            "\n",
            "         [[-8.9371e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.6689e-06]],\n",
            "\n",
            "         [[-9.3517e-06]],\n",
            "\n",
            "         [[-2.2208e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.9567e-07]],\n",
            "\n",
            "         [[-1.3688e-06]],\n",
            "\n",
            "         [[ 1.7771e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6660e-05]],\n",
            "\n",
            "         [[ 9.3032e-05]],\n",
            "\n",
            "         [[ 8.3274e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.2217e-05]],\n",
            "\n",
            "         [[ 3.2082e-05]],\n",
            "\n",
            "         [[ 4.2023e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 7.3774e-05]],\n",
            "\n",
            "         [[-3.8533e-05]],\n",
            "\n",
            "         [[-4.9289e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.3386e-07]],\n",
            "\n",
            "         [[ 4.3342e-05]],\n",
            "\n",
            "         [[ 3.5022e-06]]]])}, 148: {'momentum_buffer': tensor([0.0011, 0.0009, 0.0011,  ..., 0.0011, 0.0009, 0.0011])}, 149: {'momentum_buffer': tensor([ 7.0797e-05, -1.9177e-04,  9.2965e-05,  ...,  1.3442e-04,\n",
            "        -1.2171e-04,  5.9735e-05])}, 150: {'momentum_buffer': tensor([[[[ 3.4434e-05]],\n",
            "\n",
            "         [[ 2.0853e-05]],\n",
            "\n",
            "         [[-3.2450e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.0081e-05]],\n",
            "\n",
            "         [[ 8.3292e-05]],\n",
            "\n",
            "         [[ 5.5976e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 6.8581e-05]],\n",
            "\n",
            "         [[ 1.0175e-04]],\n",
            "\n",
            "         [[-4.6616e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3733e-05]],\n",
            "\n",
            "         [[-7.2442e-05]],\n",
            "\n",
            "         [[-5.8735e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 3.4318e-05]],\n",
            "\n",
            "         [[ 9.3555e-05]],\n",
            "\n",
            "         [[-1.7567e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6449e-06]],\n",
            "\n",
            "         [[ 2.8818e-05]],\n",
            "\n",
            "         [[ 4.8919e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.3705e-05]],\n",
            "\n",
            "         [[-8.7804e-05]],\n",
            "\n",
            "         [[ 2.0331e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0380e-05]],\n",
            "\n",
            "         [[-3.2234e-05]],\n",
            "\n",
            "         [[-4.2914e-05]]],\n",
            "\n",
            "\n",
            "        [[[-3.5559e-05]],\n",
            "\n",
            "         [[-1.8284e-05]],\n",
            "\n",
            "         [[ 1.0491e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.4647e-05]],\n",
            "\n",
            "         [[-6.8722e-05]],\n",
            "\n",
            "         [[ 7.0110e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 5.4922e-06]],\n",
            "\n",
            "         [[ 8.0814e-05]],\n",
            "\n",
            "         [[-1.5904e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.7550e-06]],\n",
            "\n",
            "         [[ 2.0415e-05]],\n",
            "\n",
            "         [[-5.4981e-06]]]])}, 151: {'momentum_buffer': tensor([0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0011, 0.0011, 0.0010, 0.0009,\n",
            "        0.0011, 0.0011, 0.0009, 0.0010, 0.0009, 0.0010, 0.0012, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0012, 0.0011, 0.0011, 0.0009, 0.0011, 0.0010,\n",
            "        0.0009, 0.0009, 0.0011, 0.0009, 0.0012, 0.0011, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0012, 0.0009, 0.0010, 0.0008, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0008, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0012, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0010, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010, 0.0009, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0011, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0008, 0.0010, 0.0010, 0.0009, 0.0008, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0009, 0.0010, 0.0009, 0.0011, 0.0010, 0.0011, 0.0011,\n",
            "        0.0010, 0.0009, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0009, 0.0011, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0011, 0.0011, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0012, 0.0010, 0.0009, 0.0011, 0.0009, 0.0011, 0.0010, 0.0010, 0.0011,\n",
            "        0.0009, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010,\n",
            "        0.0009, 0.0011, 0.0009, 0.0009, 0.0008, 0.0010, 0.0009, 0.0009, 0.0011,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0011, 0.0010, 0.0008, 0.0011, 0.0010, 0.0011, 0.0009, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0011, 0.0009, 0.0010, 0.0008,\n",
            "        0.0010, 0.0010, 0.0011, 0.0008, 0.0009, 0.0010, 0.0010, 0.0011, 0.0009,\n",
            "        0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0012, 0.0010, 0.0010, 0.0008,\n",
            "        0.0010, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0012, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0009, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0011, 0.0012, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0012, 0.0011, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0011, 0.0012, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0011, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0009, 0.0011, 0.0009,\n",
            "        0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0008, 0.0009, 0.0011, 0.0010, 0.0008, 0.0012, 0.0010,\n",
            "        0.0010, 0.0009, 0.0009, 0.0009, 0.0011, 0.0013, 0.0011, 0.0010, 0.0012,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0008, 0.0010, 0.0009,\n",
            "        0.0009, 0.0009, 0.0011, 0.0009, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0012, 0.0011, 0.0010, 0.0011, 0.0009, 0.0010,\n",
            "        0.0008, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0008, 0.0009, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0009, 0.0011, 0.0011, 0.0011, 0.0009,\n",
            "        0.0010, 0.0010, 0.0011, 0.0011, 0.0009, 0.0010, 0.0010, 0.0007, 0.0010,\n",
            "        0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009])}, 152: {'momentum_buffer': tensor([-3.2184e-05, -2.3115e-06, -1.2093e-04, -1.8876e-05, -2.0717e-05,\n",
            "         1.4050e-04,  5.6095e-05,  7.2565e-05, -1.2432e-04,  4.1523e-05,\n",
            "        -1.7725e-05, -5.8147e-05, -4.4458e-05,  1.0233e-05, -1.9765e-05,\n",
            "         7.8301e-05, -3.4270e-05,  3.3977e-06, -3.8141e-05,  4.2741e-05,\n",
            "        -8.2632e-05,  1.3085e-04, -7.7835e-05, -3.1966e-05,  3.7808e-05,\n",
            "         1.1280e-06, -4.5261e-05,  2.6603e-06,  4.1411e-05, -1.9405e-05,\n",
            "        -3.3507e-05, -6.3543e-05,  1.1068e-05, -4.0030e-05, -4.9412e-05,\n",
            "        -1.1927e-05, -5.8680e-06, -1.5964e-04,  6.8244e-05, -4.0609e-05,\n",
            "         9.7077e-05,  6.0365e-05, -1.3858e-04, -6.2141e-06, -7.6162e-05,\n",
            "         3.8290e-05,  8.0703e-05, -1.0101e-04,  7.1517e-05, -1.0213e-04,\n",
            "        -3.6053e-05, -1.2256e-04,  2.9078e-05,  6.2839e-07,  1.3422e-06,\n",
            "        -2.9950e-05,  6.0643e-05, -5.7287e-05, -8.1314e-05, -3.7676e-05,\n",
            "        -2.8054e-05,  7.9400e-05, -1.1363e-04, -2.3556e-05,  1.4914e-05,\n",
            "        -3.8595e-05,  1.0520e-05,  1.1424e-04,  9.3871e-06, -1.1262e-04,\n",
            "        -1.6814e-05, -5.6126e-06, -1.8755e-05, -5.2452e-05,  5.7718e-05,\n",
            "        -1.1445e-05, -3.0605e-05, -2.4973e-05, -6.6105e-05, -1.5929e-05,\n",
            "        -4.9356e-05, -6.2905e-05, -1.4754e-04, -1.1915e-04, -4.0399e-05,\n",
            "         3.0882e-05, -2.5844e-05, -9.5730e-05,  4.2517e-05, -2.4060e-06,\n",
            "         1.1145e-05, -7.7808e-05, -2.9164e-05, -1.2396e-04,  3.0625e-05,\n",
            "        -7.3006e-05, -8.3546e-05, -2.3265e-05, -8.9050e-05, -2.7092e-05,\n",
            "         2.4445e-05, -2.2585e-04,  3.5854e-06,  6.4174e-05,  1.9155e-05,\n",
            "         1.8711e-05, -3.0143e-05,  5.4477e-05,  3.5921e-05,  4.7502e-06,\n",
            "        -5.1977e-05,  5.3702e-05,  7.4424e-05, -1.2837e-04,  3.3814e-06,\n",
            "        -6.6899e-05, -4.8318e-05, -1.1883e-04, -1.1724e-05, -6.5939e-05,\n",
            "        -3.9585e-05,  3.6080e-05,  7.5541e-06,  1.1345e-04, -2.6167e-05,\n",
            "        -1.0468e-05, -1.0920e-04,  1.6106e-05, -1.2798e-04, -1.0511e-04,\n",
            "         2.4306e-06,  2.9454e-07,  4.6198e-05, -4.3736e-06,  2.4909e-05,\n",
            "        -4.8548e-05,  4.9258e-06,  4.4896e-05, -3.0175e-05, -3.6248e-05,\n",
            "        -3.3535e-06, -1.8055e-04,  8.3197e-05,  9.1130e-05, -1.9153e-05,\n",
            "        -1.3394e-06, -1.1566e-04, -1.5721e-04, -9.9068e-05, -3.4233e-05,\n",
            "        -1.6948e-04,  5.4112e-05, -7.6950e-05, -3.7828e-05, -1.7409e-05,\n",
            "        -6.3120e-05, -4.6968e-05,  1.3170e-04, -1.8478e-04, -2.3749e-04,\n",
            "        -4.3260e-05, -4.9451e-05,  2.0714e-05, -4.9385e-06, -4.2942e-05,\n",
            "         5.6945e-05, -4.2922e-05,  4.8185e-05,  2.2472e-05,  1.1081e-05,\n",
            "         5.2475e-05,  1.3297e-06, -3.1324e-06, -5.9322e-05, -1.7746e-04,\n",
            "        -4.5285e-05,  1.1627e-05, -1.7515e-05,  3.5288e-05,  3.6295e-05,\n",
            "        -8.9396e-06,  8.6005e-05,  8.4809e-06, -1.0209e-05, -2.1272e-05,\n",
            "         3.0647e-05, -4.3038e-05,  2.1436e-05, -8.1431e-05, -3.3101e-05,\n",
            "         8.2314e-05, -2.0413e-05,  2.4422e-08, -4.2165e-05, -6.5136e-05,\n",
            "        -8.6102e-05, -8.8873e-05, -1.6785e-05,  8.9518e-05, -1.7158e-05,\n",
            "        -2.5332e-05, -5.9493e-06, -1.7869e-05,  1.1526e-04, -7.8085e-05,\n",
            "         4.3864e-05,  7.0676e-05,  6.6732e-05, -1.0869e-04, -3.4581e-05,\n",
            "        -4.0533e-05, -3.7632e-05, -1.2027e-05, -3.4645e-05,  2.5495e-05,\n",
            "         6.5261e-05, -5.1457e-05, -1.5336e-05, -3.1346e-05, -1.3151e-04,\n",
            "         6.0531e-05,  6.4126e-05,  4.3241e-05, -1.8651e-05, -2.6087e-06,\n",
            "        -1.6651e-04, -3.7848e-05, -1.4938e-04, -3.5392e-05, -6.2528e-05,\n",
            "        -5.1406e-05, -2.8251e-05, -5.2174e-05,  5.2389e-05, -1.1853e-04,\n",
            "        -7.2338e-05, -3.2696e-05, -6.8742e-05, -9.5382e-05, -3.0044e-05,\n",
            "         1.5993e-05, -6.7654e-06,  1.7943e-04,  1.1128e-05, -6.3758e-05,\n",
            "         1.2211e-05, -1.4215e-04,  6.0656e-05,  4.7965e-05,  5.7730e-05,\n",
            "        -5.2444e-05, -3.6479e-05, -9.7863e-05, -2.5622e-05, -5.2621e-05,\n",
            "         1.7170e-04, -1.2819e-04,  5.1745e-05, -5.6081e-05,  5.8905e-05,\n",
            "        -1.4113e-04,  4.6424e-05,  6.8587e-06, -6.5786e-07, -1.2683e-04,\n",
            "        -1.3368e-04, -4.8542e-05, -1.6506e-05,  6.5580e-05, -5.1877e-05,\n",
            "        -4.4375e-05,  3.0241e-05,  7.4687e-05, -1.3154e-05, -1.2079e-04,\n",
            "         1.4337e-05, -6.9044e-05, -1.3118e-04, -1.5621e-05,  3.9961e-05,\n",
            "        -4.7048e-05, -7.0158e-05, -5.5380e-05,  1.5089e-05,  1.3735e-04,\n",
            "        -4.3447e-05, -5.8585e-05, -1.0815e-04, -9.6897e-05, -4.5021e-05,\n",
            "        -1.4625e-04,  8.8625e-05,  9.7681e-06, -3.8822e-05, -1.4553e-05,\n",
            "         8.5238e-05,  3.3844e-05, -2.2839e-05,  5.2920e-05, -4.2067e-05,\n",
            "        -1.0530e-04, -5.3421e-05,  7.8163e-05,  3.3661e-07, -5.1802e-05,\n",
            "         4.7431e-05,  3.1775e-05, -8.5461e-05, -1.2228e-05, -1.1548e-04,\n",
            "         9.5205e-05, -4.2724e-05, -1.2214e-04, -1.4947e-05, -1.5769e-04,\n",
            "        -2.7997e-05,  8.6907e-05,  6.4866e-05,  5.5746e-05, -5.4297e-06,\n",
            "         4.1888e-05, -3.4206e-05, -2.5310e-05,  1.0512e-05, -4.0051e-05,\n",
            "        -6.2159e-05, -6.1322e-06,  9.0412e-06, -4.6010e-05,  4.4424e-05,\n",
            "         1.3013e-04, -3.3157e-05, -6.4969e-05, -1.4508e-05, -6.2253e-05,\n",
            "         8.2113e-05,  1.6371e-04, -7.6610e-05,  2.0499e-05, -8.7321e-05,\n",
            "         4.7940e-05, -4.4191e-05, -8.8978e-05, -1.1432e-05,  1.0075e-04,\n",
            "         9.1862e-05,  2.3491e-05, -3.1240e-05,  1.8213e-05,  2.1712e-05,\n",
            "        -1.6619e-05, -7.3999e-05, -3.3952e-05, -5.6919e-05,  4.9308e-06,\n",
            "        -3.9866e-05,  1.7501e-05, -2.8127e-05, -2.6037e-05, -5.9734e-05,\n",
            "        -1.6045e-04, -1.1109e-04, -1.8365e-05,  2.5408e-05, -3.3306e-05,\n",
            "         2.9830e-06, -5.4570e-05,  1.3639e-05, -9.1054e-06,  1.0945e-04,\n",
            "        -3.7590e-05,  1.3503e-06,  2.9061e-05, -5.0144e-05, -2.1506e-05,\n",
            "        -1.2852e-04, -2.6905e-05, -5.3088e-06,  1.3295e-04, -9.1792e-05,\n",
            "        -1.2120e-04, -2.7812e-05,  8.9541e-06, -1.0118e-04, -9.9503e-05,\n",
            "         1.9128e-04, -1.3558e-04, -4.1994e-05, -9.4387e-05, -4.9933e-05,\n",
            "        -7.4346e-05, -1.7704e-06,  1.6136e-04, -5.5034e-05,  2.9392e-05,\n",
            "         1.5733e-04,  2.4581e-05,  3.7974e-05,  3.6762e-05, -2.9209e-05,\n",
            "         6.5034e-05,  8.9851e-06, -1.6380e-04, -1.5963e-06, -6.0029e-05,\n",
            "        -5.1940e-05, -1.0403e-04,  2.4581e-05, -5.6344e-05, -6.8662e-06,\n",
            "         2.6774e-05, -9.4875e-05,  6.5312e-05, -1.8900e-05, -1.1900e-04,\n",
            "         2.1049e-05,  2.9068e-05, -4.1391e-05, -4.3639e-05, -1.6029e-04,\n",
            "        -6.1179e-05, -1.9867e-05, -4.7458e-06, -1.4523e-04,  9.2330e-06,\n",
            "        -2.8341e-05,  1.2234e-04,  1.5391e-05,  1.8348e-05,  4.7666e-05,\n",
            "        -1.5208e-05,  6.6651e-05, -2.7060e-04, -5.8547e-05, -8.3018e-05,\n",
            "         3.4904e-05, -1.6119e-04,  8.8474e-05, -4.7599e-05, -4.0435e-05,\n",
            "        -1.0255e-04, -1.0170e-04,  1.0276e-06,  6.0711e-05,  1.2344e-04,\n",
            "        -8.4820e-05,  9.7151e-05, -2.1513e-05, -5.4267e-05,  2.3460e-06,\n",
            "         2.5201e-05, -1.1727e-05,  4.6886e-05, -7.6046e-05, -1.8182e-04,\n",
            "         7.0782e-07, -3.9194e-05,  8.1574e-06,  3.7137e-06,  2.8699e-05,\n",
            "        -1.0062e-04, -2.3729e-05,  6.5721e-05,  8.3830e-05,  1.8000e-04,\n",
            "        -1.8175e-05,  4.9622e-05,  5.5275e-07,  3.2932e-05,  3.6680e-05,\n",
            "        -5.5715e-07,  1.5307e-06, -5.4807e-05,  1.2121e-05,  4.3913e-05,\n",
            "         8.1102e-05, -3.3678e-05,  4.0404e-06, -8.9305e-05, -3.1647e-05,\n",
            "         1.3221e-06,  3.6734e-05, -1.3608e-05, -1.1761e-04, -2.4183e-05,\n",
            "         4.0210e-05, -2.2719e-06,  6.3851e-05,  1.2939e-04, -6.9270e-05,\n",
            "        -1.0275e-04, -4.0315e-05, -4.7179e-06,  1.9252e-05, -1.9952e-04,\n",
            "        -1.0157e-05,  2.4741e-05,  4.3181e-05,  7.4699e-05, -5.2124e-05,\n",
            "        -1.3175e-04,  1.7369e-06, -1.7685e-04,  1.2716e-04,  3.6447e-05,\n",
            "         2.0172e-05, -1.9201e-05,  1.0367e-06, -2.8305e-05,  1.3975e-05,\n",
            "        -1.2055e-05, -7.7323e-05])}, 153: {'momentum_buffer': tensor([[[[-1.1198e-05, -4.4891e-06, -3.2585e-05],\n",
            "          [ 3.4268e-06, -1.5459e-05, -1.6514e-05],\n",
            "          [-2.7045e-05,  8.4980e-06,  7.5292e-06]],\n",
            "\n",
            "         [[ 1.5014e-05,  3.3127e-05,  1.7825e-05],\n",
            "          [-4.2179e-06,  9.9126e-06,  3.3386e-05],\n",
            "          [ 2.8202e-05,  1.4656e-05,  9.3660e-06]],\n",
            "\n",
            "         [[ 1.7823e-05,  3.0502e-05, -1.9013e-06],\n",
            "          [ 1.9382e-05, -1.0650e-05,  1.0605e-05],\n",
            "          [-2.3139e-05,  2.4583e-05,  4.2645e-07]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1830e-05, -3.0280e-05, -8.2885e-06],\n",
            "          [ 4.6324e-05,  9.3290e-06, -2.8116e-05],\n",
            "          [ 5.4245e-07, -3.3486e-05, -2.9230e-05]],\n",
            "\n",
            "         [[-1.9999e-05,  1.4555e-05, -6.1045e-06],\n",
            "          [-5.6016e-06, -3.2124e-05, -3.6022e-05],\n",
            "          [-1.2570e-05, -4.8937e-06, -2.0341e-05]],\n",
            "\n",
            "         [[ 2.8199e-05,  2.5169e-05,  5.1651e-06],\n",
            "          [ 9.6588e-06,  2.8646e-05,  8.6571e-05],\n",
            "          [ 7.2975e-05,  2.3129e-05,  2.0175e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7781e-05,  2.5438e-05, -6.0645e-06],\n",
            "          [-2.7397e-07,  1.0690e-05,  3.4560e-05],\n",
            "          [ 4.2268e-05,  3.7614e-05,  2.9683e-05]],\n",
            "\n",
            "         [[ 7.5323e-06,  3.0260e-05,  2.9245e-05],\n",
            "          [ 1.0769e-05, -2.0962e-05,  3.5770e-05],\n",
            "          [-2.2848e-06, -2.3914e-06, -3.4269e-05]],\n",
            "\n",
            "         [[-8.2627e-06,  3.6189e-05, -7.5127e-06],\n",
            "          [-1.6861e-05,  2.2283e-05,  1.1847e-05],\n",
            "          [ 1.3713e-05,  3.3799e-06,  3.8836e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8821e-05, -5.9794e-05,  3.7738e-05],\n",
            "          [-2.8870e-05, -2.4780e-05, -2.0558e-05],\n",
            "          [-4.1467e-05, -6.1443e-06,  2.8814e-06]],\n",
            "\n",
            "         [[-6.4261e-06,  2.0126e-05,  6.6029e-06],\n",
            "          [-1.7148e-05, -1.2006e-05, -5.7223e-05],\n",
            "          [ 3.6530e-06,  1.4201e-05, -2.6110e-05]],\n",
            "\n",
            "         [[ 9.2899e-05,  3.8430e-05,  2.3036e-05],\n",
            "          [ 3.2740e-05,  2.6680e-06,  3.5957e-06],\n",
            "          [ 9.0175e-05,  1.7651e-05,  7.7278e-06]]],\n",
            "\n",
            "\n",
            "        [[[-5.0169e-05, -1.3225e-05,  3.1938e-05],\n",
            "          [-1.1063e-05, -2.5298e-05,  2.6769e-05],\n",
            "          [-5.9950e-05, -3.1422e-05,  9.2411e-05]],\n",
            "\n",
            "         [[ 9.4572e-05,  1.0410e-04,  2.2209e-05],\n",
            "          [ 2.7610e-05, -1.6761e-06,  4.9532e-05],\n",
            "          [-2.5530e-05,  5.3951e-06,  1.0384e-05]],\n",
            "\n",
            "         [[-2.4861e-05,  4.9721e-08,  5.2151e-06],\n",
            "          [-5.4833e-05,  3.9282e-05, -6.7192e-05],\n",
            "          [-5.4377e-05, -4.7948e-05,  3.0303e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0833e-04, -6.1071e-05, -4.5690e-05],\n",
            "          [-2.1636e-05, -5.2876e-05, -4.6408e-05],\n",
            "          [ 3.8202e-05, -1.4279e-05, -4.2459e-06]],\n",
            "\n",
            "         [[-7.9863e-05, -8.0705e-06, -1.9114e-05],\n",
            "          [-9.0606e-05, -6.5161e-05, -3.2611e-05],\n",
            "          [-6.6748e-05, -7.0502e-05,  8.9735e-06]],\n",
            "\n",
            "         [[ 7.9088e-05,  1.0379e-04,  1.1424e-04],\n",
            "          [ 9.2738e-05,  7.6201e-05,  1.0119e-04],\n",
            "          [ 3.8150e-05,  4.7845e-05,  1.5494e-04]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 9.1524e-06, -2.0009e-05,  1.7808e-05],\n",
            "          [-1.5163e-05, -3.2234e-05,  1.0587e-05],\n",
            "          [-4.3855e-05, -4.4663e-05, -7.2500e-06]],\n",
            "\n",
            "         [[-3.5537e-05,  3.1373e-05,  3.5210e-05],\n",
            "          [-4.2131e-05, -9.3510e-06,  2.1035e-05],\n",
            "          [ 1.3319e-05, -2.0833e-05, -1.7452e-05]],\n",
            "\n",
            "         [[-2.5619e-05, -1.1684e-05, -2.1888e-05],\n",
            "          [-6.6176e-05, -5.5126e-05,  1.2220e-05],\n",
            "          [-1.0283e-04, -6.0254e-05, -1.3440e-06]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.2600e-06,  4.7243e-07,  1.1614e-05],\n",
            "          [-1.4917e-05, -1.0449e-05,  1.8243e-05],\n",
            "          [-3.4311e-05, -3.3455e-05, -1.8311e-05]],\n",
            "\n",
            "         [[-4.7636e-05, -5.8920e-05,  3.1123e-05],\n",
            "          [-3.0322e-05, -4.2673e-05, -3.2180e-05],\n",
            "          [ 7.7205e-08, -2.4023e-06, -2.6045e-05]],\n",
            "\n",
            "         [[ 7.5116e-05,  1.3478e-04,  1.3701e-04],\n",
            "          [ 6.9976e-05,  1.0916e-04,  1.7753e-04],\n",
            "          [ 4.4964e-05,  1.1029e-04,  8.2826e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1281e-05,  3.9571e-05,  3.1457e-06],\n",
            "          [-8.8978e-06, -1.2742e-05,  2.4435e-05],\n",
            "          [-3.6601e-05, -3.2959e-05, -2.6348e-05]],\n",
            "\n",
            "         [[ 1.5585e-05, -6.2153e-06,  4.2850e-05],\n",
            "          [-2.2407e-05, -1.4476e-05,  4.3717e-05],\n",
            "          [-3.9318e-05,  1.7910e-05, -4.6788e-05]],\n",
            "\n",
            "         [[ 1.3072e-05, -2.5157e-05,  3.9857e-06],\n",
            "          [-1.4721e-05, -1.2200e-05,  3.3188e-06],\n",
            "          [-8.2417e-05, -9.4535e-06,  4.1933e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8544e-06, -2.9696e-05, -1.3136e-05],\n",
            "          [ 2.3409e-05,  1.1943e-05, -2.2616e-05],\n",
            "          [-1.4466e-05,  1.5138e-05,  3.3347e-05]],\n",
            "\n",
            "         [[ 5.9570e-06,  1.1079e-05, -3.9525e-05],\n",
            "          [ 6.4247e-06,  6.8872e-07, -1.5456e-05],\n",
            "          [-1.3728e-05, -3.9205e-05, -8.1060e-05]],\n",
            "\n",
            "         [[ 2.0729e-05, -1.6815e-05, -1.2016e-05],\n",
            "          [-4.9917e-05, -2.2074e-05, -1.6269e-05],\n",
            "          [-9.8946e-06,  3.5077e-05,  2.7623e-06]]],\n",
            "\n",
            "\n",
            "        [[[-1.4663e-05, -1.6386e-05, -3.7667e-05],\n",
            "          [ 3.4561e-05, -1.2281e-05, -2.1653e-05],\n",
            "          [-1.1381e-05, -6.4262e-05, -2.8562e-05]],\n",
            "\n",
            "         [[-1.5818e-05,  1.9227e-06,  1.9180e-05],\n",
            "          [-5.7213e-05,  9.2766e-07,  6.8122e-06],\n",
            "          [ 3.5459e-05,  7.6225e-05, -1.4672e-05]],\n",
            "\n",
            "         [[-1.2200e-05, -1.9999e-05, -3.0606e-05],\n",
            "          [ 2.1448e-05, -2.7847e-05, -2.0875e-05],\n",
            "          [-6.9141e-05, -6.5162e-05, -7.9885e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2051e-05,  1.3705e-05,  3.8764e-05],\n",
            "          [-1.0239e-05, -1.4382e-05,  1.4165e-05],\n",
            "          [ 3.5132e-05, -2.7238e-05,  1.7587e-05]],\n",
            "\n",
            "         [[ 4.8711e-05,  9.0823e-06, -1.0410e-05],\n",
            "          [-3.8144e-06, -1.8032e-05, -2.7213e-05],\n",
            "          [ 2.1780e-05, -1.0629e-05, -1.1919e-05]],\n",
            "\n",
            "         [[ 3.1778e-05, -9.4050e-06, -1.8452e-05],\n",
            "          [ 2.0069e-05,  2.6160e-05,  2.4863e-05],\n",
            "          [-1.2478e-05,  7.3179e-05,  6.8022e-05]]]])}, 154: {'momentum_buffer': tensor([0.0011, 0.0011, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0008, 0.0009, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0012, 0.0010, 0.0009, 0.0009, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0012, 0.0010, 0.0010, 0.0009,\n",
            "        0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0012, 0.0010, 0.0012,\n",
            "        0.0010, 0.0010, 0.0012, 0.0011, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0009, 0.0009, 0.0012, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0009,\n",
            "        0.0010, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0008,\n",
            "        0.0009, 0.0011, 0.0011, 0.0010, 0.0011, 0.0009, 0.0011, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0011, 0.0009, 0.0009, 0.0010, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0012, 0.0011, 0.0009, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0009, 0.0011, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0008, 0.0009, 0.0011, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0008, 0.0010, 0.0010, 0.0010, 0.0010, 0.0008, 0.0009, 0.0010,\n",
            "        0.0009, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0012,\n",
            "        0.0010, 0.0009, 0.0009, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0013, 0.0008, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0009, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010,\n",
            "        0.0011, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011,\n",
            "        0.0011, 0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0008, 0.0009, 0.0010, 0.0011, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0009, 0.0009, 0.0010, 0.0010,\n",
            "        0.0009, 0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0009, 0.0011, 0.0010,\n",
            "        0.0010, 0.0009, 0.0011, 0.0010, 0.0011, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0009, 0.0010,\n",
            "        0.0011, 0.0010, 0.0011, 0.0009, 0.0013, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0008, 0.0010, 0.0011, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0009,\n",
            "        0.0010, 0.0011, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009,\n",
            "        0.0011, 0.0009, 0.0009, 0.0011, 0.0011, 0.0010, 0.0011, 0.0011, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009,\n",
            "        0.0011, 0.0010, 0.0010, 0.0011, 0.0010, 0.0011, 0.0009, 0.0009, 0.0011,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010,\n",
            "        0.0010, 0.0009, 0.0008, 0.0007, 0.0010, 0.0011, 0.0009, 0.0010, 0.0009,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0010, 0.0011, 0.0010, 0.0009, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011, 0.0009, 0.0010, 0.0010,\n",
            "        0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0010, 0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0011, 0.0008, 0.0009,\n",
            "        0.0011, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0009, 0.0010, 0.0009,\n",
            "        0.0009, 0.0009, 0.0012, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0009, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010, 0.0010,\n",
            "        0.0010, 0.0009, 0.0010, 0.0009, 0.0009, 0.0012, 0.0010, 0.0010, 0.0009,\n",
            "        0.0011, 0.0009, 0.0007, 0.0010, 0.0011, 0.0010, 0.0010, 0.0011, 0.0010,\n",
            "        0.0011, 0.0010, 0.0010, 0.0010, 0.0011, 0.0011, 0.0010, 0.0010])}, 155: {'momentum_buffer': tensor([ 7.3300e-05,  5.3157e-05, -1.5027e-04, -1.7469e-04, -5.7074e-05,\n",
            "        -7.1187e-05, -3.8740e-06, -6.4953e-05,  7.4363e-06,  1.2019e-04,\n",
            "        -2.3304e-05, -5.9110e-05, -1.2403e-04,  4.3674e-05,  1.6499e-05,\n",
            "         2.9235e-06,  9.0195e-06,  1.5139e-05, -3.2262e-05, -1.7165e-04,\n",
            "        -8.3447e-05, -4.7223e-05,  5.0376e-05,  1.1785e-04, -1.8171e-05,\n",
            "         5.2262e-05, -3.6725e-05, -6.0568e-05,  1.0157e-04,  3.9979e-05,\n",
            "         1.6727e-05,  3.1625e-05, -1.5987e-05, -6.6804e-06, -1.1948e-05,\n",
            "        -1.8485e-05,  1.3654e-05, -8.4077e-05, -1.1092e-05, -4.3883e-05,\n",
            "         1.3135e-05, -5.6777e-05, -5.4212e-05, -7.3520e-05, -2.3491e-05,\n",
            "        -6.1859e-05, -4.1164e-05, -6.2327e-05, -1.2598e-04, -6.3797e-05,\n",
            "        -1.0435e-04, -1.3988e-04, -7.2050e-05, -3.0955e-05, -4.7219e-07,\n",
            "        -1.7933e-05,  7.0124e-05, -2.2517e-05, -4.1401e-05, -1.3168e-05,\n",
            "         2.6433e-05, -2.4724e-05,  2.3130e-05,  8.4465e-05, -2.2667e-05,\n",
            "        -6.5743e-06, -5.1176e-05,  8.0817e-06, -9.3846e-05, -1.3708e-04,\n",
            "         9.6860e-06, -6.0811e-05,  7.5528e-06,  2.9619e-05,  2.7302e-06,\n",
            "         4.0554e-05, -1.5476e-05,  6.9303e-06,  9.0034e-05, -1.7222e-05,\n",
            "        -1.9605e-04, -9.8743e-05,  9.4352e-05, -5.8764e-05, -9.8558e-05,\n",
            "        -9.8724e-06,  1.0497e-05,  3.4321e-05, -2.2739e-05,  4.4830e-05,\n",
            "         6.6661e-05, -1.2157e-04,  1.0120e-04, -7.9701e-05,  5.1924e-05,\n",
            "         3.8956e-05, -4.9630e-05, -5.6994e-05, -5.7774e-05, -8.8473e-05,\n",
            "        -2.3935e-05,  1.1737e-04, -3.5491e-05, -2.4457e-05, -7.4874e-06,\n",
            "         1.0456e-04, -2.7086e-05, -1.2393e-04,  2.7938e-05, -3.5957e-05,\n",
            "         5.0411e-05,  7.1795e-06,  2.2998e-05,  7.6743e-05, -9.3655e-05,\n",
            "         1.2152e-05, -1.1116e-04,  1.1547e-05,  2.0920e-05, -3.3279e-05,\n",
            "         1.5956e-05,  3.6352e-05,  3.2722e-05, -1.3067e-04, -4.5959e-05,\n",
            "         6.7666e-05, -5.8382e-05, -1.1410e-04, -9.5910e-05, -1.9012e-05,\n",
            "        -5.9460e-05, -8.4579e-05, -4.2037e-05,  6.7281e-05, -2.2530e-04,\n",
            "        -4.3520e-05, -3.9054e-05, -1.6520e-06,  2.3068e-05,  8.1044e-05,\n",
            "        -1.1297e-04,  3.5325e-05, -4.5773e-05, -1.2723e-05,  3.5452e-05,\n",
            "        -2.9250e-05,  3.9842e-05,  4.9258e-05, -5.8948e-05, -6.3729e-05,\n",
            "        -1.0451e-04,  1.7026e-06, -3.3722e-05, -5.1564e-05, -4.5866e-05,\n",
            "         5.0969e-06,  3.4208e-05,  1.2569e-04,  1.4880e-04, -6.6743e-05,\n",
            "        -1.3421e-04, -6.4804e-05,  4.5747e-05,  4.7463e-05, -2.1422e-05,\n",
            "        -4.3692e-05, -3.0154e-05,  1.3597e-06, -3.2648e-05, -4.4080e-05,\n",
            "        -2.2925e-05, -5.3507e-05,  7.9530e-06, -1.5969e-05,  4.8216e-05,\n",
            "        -1.8830e-04, -1.8287e-05,  4.8428e-05,  1.0188e-05, -1.0268e-05,\n",
            "         7.2791e-05,  6.8891e-05, -4.5389e-05, -5.7973e-05,  6.3357e-05,\n",
            "        -4.9789e-05,  7.8618e-05, -1.9239e-06,  2.4090e-05,  1.1918e-06,\n",
            "        -1.6791e-06, -3.1167e-05, -8.8915e-05, -1.7616e-05, -9.6470e-06,\n",
            "        -7.9451e-05,  1.7203e-04, -1.3397e-04, -9.9451e-05, -3.6051e-05,\n",
            "         1.7582e-05, -7.3532e-05, -2.3364e-05,  6.0203e-05, -8.1611e-05,\n",
            "        -4.7693e-05, -2.3971e-05, -3.9234e-05, -1.5742e-04, -1.3272e-06,\n",
            "        -8.9361e-06, -1.0523e-04,  8.4289e-05, -1.6819e-04,  1.1406e-05,\n",
            "        -2.3443e-05, -5.1903e-05,  1.4814e-05,  9.1886e-05, -7.5428e-05,\n",
            "        -1.6009e-05, -1.7362e-06, -5.6382e-05, -6.1214e-05,  1.4083e-04,\n",
            "         3.4475e-06, -1.5058e-04,  2.6937e-05,  1.0712e-04,  3.6054e-05,\n",
            "        -1.1283e-04,  7.7742e-07,  7.9553e-05,  4.5672e-05,  4.2527e-05,\n",
            "         1.5516e-04, -1.4471e-04,  8.9774e-05,  1.6359e-05, -7.6749e-05,\n",
            "         1.3360e-05, -2.9524e-05,  5.2830e-06, -9.1166e-05, -5.5064e-05,\n",
            "        -8.6315e-05, -2.1803e-05,  7.8679e-06,  1.1735e-05, -4.5029e-05,\n",
            "         2.2459e-05, -1.7181e-05,  4.9416e-06,  3.6355e-05, -1.2742e-04,\n",
            "         1.2700e-05, -2.3930e-07, -5.9307e-06, -5.7106e-05,  3.1636e-05,\n",
            "        -2.4746e-05,  1.9416e-06, -7.7322e-05,  3.6658e-05,  8.2503e-05,\n",
            "        -3.7544e-05,  3.7876e-05,  7.7741e-06,  3.0417e-06, -2.2165e-05,\n",
            "         7.6012e-05, -2.0427e-05,  2.2366e-05, -6.3411e-05,  1.1514e-05,\n",
            "         1.2600e-06,  3.1217e-05,  1.5905e-05, -2.0063e-05, -1.4300e-05,\n",
            "         2.7625e-06, -1.0576e-05, -3.3812e-05, -3.9429e-05,  4.5457e-05,\n",
            "        -2.5973e-06, -3.7957e-05, -2.0495e-05,  6.2485e-05, -6.9103e-05,\n",
            "        -1.2193e-04,  3.6973e-06, -5.9385e-06,  1.4334e-04,  1.2628e-04,\n",
            "        -5.7517e-05,  4.6061e-05, -6.7795e-05, -2.9059e-05, -4.0694e-05,\n",
            "        -4.0448e-05,  9.5460e-06, -1.8173e-04, -6.0436e-05, -2.6639e-05,\n",
            "        -4.6399e-05, -1.9291e-04,  2.2835e-04,  7.8790e-05,  6.5913e-05,\n",
            "         4.7771e-05,  2.5743e-05, -6.6951e-05,  2.7902e-05, -2.7691e-05,\n",
            "        -9.0508e-05, -9.2782e-06,  7.4188e-05, -6.2148e-06,  1.0426e-04,\n",
            "        -1.1357e-04,  4.1988e-05,  9.5236e-06,  1.2743e-05,  6.8813e-05,\n",
            "        -1.2036e-04,  5.9238e-05,  5.1705e-05, -2.3543e-05, -1.7142e-04,\n",
            "        -1.6685e-05, -1.0933e-04, -7.3955e-05,  5.7364e-06,  3.5090e-05,\n",
            "        -8.0012e-06, -6.6128e-05,  1.3753e-04, -2.0041e-05,  1.9215e-05,\n",
            "        -6.6836e-06,  2.0806e-05, -3.6140e-05,  3.1745e-05, -5.1128e-05,\n",
            "         4.5685e-05, -1.9585e-04,  2.9752e-05,  2.5633e-05,  1.0926e-05,\n",
            "        -3.0723e-05,  1.1216e-06, -3.4249e-05, -1.3138e-04, -6.3924e-05,\n",
            "        -8.2299e-06, -7.5899e-05, -3.1921e-05,  7.6020e-05, -1.2299e-04,\n",
            "         7.8002e-05, -7.7965e-05, -2.7861e-05, -5.4898e-06,  9.8647e-05,\n",
            "         6.9327e-06, -7.3132e-05,  2.0924e-05, -6.9125e-06,  1.0056e-05,\n",
            "         5.2693e-05, -5.6344e-05, -1.2816e-04, -5.5467e-05, -1.0539e-04,\n",
            "         6.0017e-05, -2.7603e-05, -4.1729e-05, -2.3735e-05, -5.8086e-05,\n",
            "        -1.2733e-04,  3.8494e-05, -7.1342e-05, -3.7100e-05,  3.4263e-05,\n",
            "         1.2915e-04,  2.2068e-05,  6.8688e-05, -1.2005e-04, -5.1107e-05,\n",
            "         4.8976e-06, -3.1962e-05, -1.9721e-05,  8.5384e-06, -9.9740e-05,\n",
            "        -1.2001e-04,  1.3303e-05,  1.1082e-04,  2.3865e-05,  1.3613e-04,\n",
            "        -9.6400e-05,  3.6971e-05, -1.0935e-05, -9.9917e-05,  3.3315e-05,\n",
            "        -3.0399e-05, -4.0990e-05, -5.6353e-05,  2.4829e-05, -9.0223e-06,\n",
            "         1.8052e-05,  8.0700e-05, -3.0118e-05, -2.9520e-05,  3.8318e-05,\n",
            "        -2.8471e-06, -1.2678e-04, -1.8307e-04,  1.6798e-05,  2.5274e-05,\n",
            "         4.2729e-05,  4.9796e-05, -8.3480e-06,  2.2716e-05, -6.3972e-05,\n",
            "        -1.5800e-06, -1.0612e-04,  3.9545e-05,  1.3222e-04,  8.6505e-06,\n",
            "        -1.1170e-04, -1.3233e-04, -2.7698e-05, -5.8648e-05, -1.8570e-05,\n",
            "        -2.5476e-05,  2.7919e-05,  3.4594e-05, -2.2112e-05, -2.2866e-04,\n",
            "        -5.1270e-05,  3.7185e-05, -3.8971e-05, -2.0405e-05,  2.9194e-06,\n",
            "        -1.2958e-04,  3.7251e-05, -1.7525e-05,  6.9278e-05,  2.8073e-05,\n",
            "        -2.7744e-05,  4.6666e-05,  5.9115e-05,  8.9554e-06,  4.6756e-07,\n",
            "        -4.1242e-06, -9.4262e-05, -2.2473e-04, -2.0874e-05,  1.2250e-04,\n",
            "         4.0920e-05,  2.8149e-06, -1.4476e-05,  4.0073e-05,  3.4213e-05,\n",
            "        -8.5718e-06,  1.0501e-04, -8.4765e-05,  2.9649e-06, -2.8522e-05,\n",
            "         4.8024e-05, -6.8467e-05,  3.9414e-05, -6.1182e-05, -1.8232e-05,\n",
            "        -1.3517e-05,  4.7407e-05,  3.6030e-05, -1.4342e-04, -1.2016e-04,\n",
            "         3.0441e-06, -5.8271e-06,  1.0038e-04, -4.4144e-05,  5.3106e-05,\n",
            "         3.3389e-05, -7.5526e-05, -1.6768e-04,  9.1155e-06, -5.4223e-05,\n",
            "        -2.3775e-05,  1.1939e-05, -6.8970e-05, -8.3717e-06, -7.4465e-05,\n",
            "         8.7547e-05, -5.1961e-05, -2.4912e-04,  6.9882e-06,  1.1228e-04,\n",
            "        -3.0753e-05, -1.7583e-05,  1.1503e-04,  4.5891e-05, -1.7773e-05,\n",
            "        -5.4528e-05, -1.6774e-06,  8.2277e-05,  8.4595e-05,  5.3170e-05,\n",
            "         4.4399e-05, -6.1644e-05])}, 156: {'momentum_buffer': tensor([[[[ 1.4003e-05]],\n",
            "\n",
            "         [[ 1.2065e-05]],\n",
            "\n",
            "         [[-7.1053e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.8185e-05]],\n",
            "\n",
            "         [[-8.8296e-05]],\n",
            "\n",
            "         [[ 7.3202e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.8267e-04]],\n",
            "\n",
            "         [[ 9.4632e-05]],\n",
            "\n",
            "         [[ 2.2150e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1316e-04]],\n",
            "\n",
            "         [[ 1.0331e-05]],\n",
            "\n",
            "         [[-5.4590e-06]]],\n",
            "\n",
            "\n",
            "        [[[ 5.8182e-05]],\n",
            "\n",
            "         [[-6.8015e-05]],\n",
            "\n",
            "         [[-1.1349e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5884e-06]],\n",
            "\n",
            "         [[-4.1651e-05]],\n",
            "\n",
            "         [[-1.8183e-05]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3134e-05]],\n",
            "\n",
            "         [[-5.3247e-05]],\n",
            "\n",
            "         [[-1.2783e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.8651e-05]],\n",
            "\n",
            "         [[-4.2159e-05]],\n",
            "\n",
            "         [[ 4.4600e-05]]],\n",
            "\n",
            "\n",
            "        [[[-1.4455e-05]],\n",
            "\n",
            "         [[ 4.0296e-05]],\n",
            "\n",
            "         [[-8.2770e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6971e-05]],\n",
            "\n",
            "         [[ 4.9675e-05]],\n",
            "\n",
            "         [[ 3.2567e-05]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4184e-05]],\n",
            "\n",
            "         [[ 4.5132e-05]],\n",
            "\n",
            "         [[-2.8354e-05]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1779e-05]],\n",
            "\n",
            "         [[ 1.1385e-05]],\n",
            "\n",
            "         [[ 7.7614e-05]]]])}, 157: {'momentum_buffer': tensor([0.0010, 0.0009, 0.0010,  ..., 0.0010, 0.0009, 0.0010])}, 158: {'momentum_buffer': tensor([ 1.2563e-04, -2.3291e-04,  1.1171e-04,  ...,  1.6451e-04,\n",
            "        -1.7365e-04,  5.6180e-05])}, 159: {'momentum_buffer': tensor([[-0.0029, -0.0030, -0.0032,  ..., -0.0030, -0.0027, -0.0026],\n",
            "        [ 0.0006,  0.0010,  0.0008,  ...,  0.0010,  0.0009,  0.0007],\n",
            "        [ 0.0017,  0.0014,  0.0016,  ...,  0.0014,  0.0013,  0.0014],\n",
            "        ...,\n",
            "        [-0.0021, -0.0017, -0.0017,  ..., -0.0017, -0.0013, -0.0014],\n",
            "        [ 0.0033,  0.0031,  0.0031,  ...,  0.0031,  0.0025,  0.0024],\n",
            "        [ 0.0027,  0.0024,  0.0024,  ...,  0.0024,  0.0022,  0.0022]])}, 160: {'momentum_buffer': tensor([-4.1675e-03,  1.0872e-03,  2.1087e-03, -1.9689e-03, -2.4646e-03,\n",
            "        -2.8514e-03,  6.8550e-04, -3.2538e-04, -1.3947e-05,  4.0094e-03,\n",
            "         1.2617e-03, -1.3500e-03, -7.9582e-04, -7.1532e-04,  3.2005e-04,\n",
            "        -1.9202e-03,  2.0784e-03, -3.0203e-03, -2.4067e-03, -1.4583e-03,\n",
            "        -1.4915e-03,  3.4766e-03,  6.5557e-04, -1.3874e-03,  1.4136e-03,\n",
            "         1.4661e-03, -5.0829e-04, -1.3689e-03, -8.6825e-05, -1.6263e-03,\n",
            "         1.8710e-03,  4.1231e-04, -8.8036e-04, -3.5071e-03,  4.2881e-03,\n",
            "         3.2841e-04,  1.1623e-03,  8.9168e-04, -2.7283e-03,  3.5091e-03,\n",
            "         7.2746e-05,  1.0154e-03,  3.3017e-03,  3.0438e-04,  3.5091e-04,\n",
            "         3.1990e-03, -9.0921e-04, -2.0463e-03,  8.8055e-04,  1.3850e-03,\n",
            "         1.1785e-03, -1.5114e-03,  3.6684e-03, -4.5637e-04, -1.2594e-03,\n",
            "        -6.1916e-04,  4.8880e-04, -3.4113e-03, -1.3359e-03,  7.1759e-04,\n",
            "         6.6631e-04,  1.5376e-03,  6.2695e-04,  2.4790e-05, -1.7163e-03,\n",
            "         2.7745e-03,  2.8825e-03,  9.8122e-04, -6.8849e-04, -1.8501e-03,\n",
            "        -3.1534e-03, -3.7853e-03, -2.2687e-03, -1.2212e-03,  1.2024e-03,\n",
            "        -2.8592e-03,  7.1389e-04,  2.5635e-03, -6.9487e-04, -2.7331e-03,\n",
            "        -1.2216e-03,  9.6616e-04,  6.2461e-04, -4.5402e-04, -2.5156e-03,\n",
            "         1.9261e-03,  1.2171e-03, -2.0423e-03, -1.8120e-03,  5.2534e-03,\n",
            "         1.5103e-03, -2.0324e-03, -1.8892e-03,  2.4108e-03, -3.7625e-04,\n",
            "         2.3286e-03, -2.3739e-03, -2.1420e-03,  4.8147e-04,  1.7839e-03,\n",
            "         1.2726e-03, -3.0828e-03, -4.3035e-04, -3.0911e-03, -3.2329e-04,\n",
            "         6.4849e-04, -9.0928e-04,  3.6149e-03,  1.1856e-03, -8.9251e-04,\n",
            "        -1.8660e-03,  2.8825e-03,  2.4465e-03,  4.9275e-03, -2.8353e-04,\n",
            "         2.6133e-04, -5.4016e-04,  3.6187e-03,  2.8835e-03,  1.0550e-03,\n",
            "         1.3568e-03,  2.3949e-03, -2.2867e-04, -2.3651e-04,  2.3016e-03,\n",
            "        -2.7293e-03,  4.4792e-03,  3.3966e-03])}}, 'param_groups': [{'lr': 0.03, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321]}]}}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "model = torch.load('/content/checkpoint_0000.pth.tar', map_location='cpu')\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!python /content/Master_Thesis/downstream_task.py "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzMhq2pY1NU_",
        "outputId": "8705c313-ee40-4bbc-ea4a-0374dc071345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['2023-04-06 15:06:57.465182: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.',\n",
              " 'To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.',\n",
              " '2023-04-06 15:06:58.429304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT',\n",
              " 'Traceback (most recent call last):',\n",
              " '  File \"/content/Master_Thesis/downstream_task.py\", line 128, in <module>',\n",
              " '    my_object.process_images_train()',\n",
              " '  File \"/content/Master_Thesis/data.py\", line 82, in process_images_train',\n",
              " '    plt.imsave(directory + image_num, image)',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py\", line 2200, in imsave',\n",
              " '    return matplotlib.image.imsave(fname, arr, **kwargs)',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/matplotlib/image.py\", line 1689, in imsave',\n",
              " '    image.save(fname, **pil_kwargs)',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/PIL/Image.py\", line 2240, in save',\n",
              " '    save_handler(self, fp, filename)',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/PIL/JpegImagePlugin.py\", line 782, in _save',\n",
              " '    ImageFile._save(im, fp, [(\"jpeg\", (0, 0) + im.size, 0, rawmode)], bufsize)',\n",
              " '  File \"/usr/local/lib/python3.9/dist-packages/PIL/ImageFile.py\", line 536, in _save',\n",
              " '    s = e.encode_to_file(fh, bufsize)',\n",
              " 'KeyboardInterrupt']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  --lr 0.015 \\\n",
        "  --batch-size 64 \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqunGWWDCxo_",
        "outputId": "c0d93c19-f35f-4d88-9995-a8c58fb4fc88"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-19 11:38:54.093953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-19 11:38:55.286956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 11:39:00.664994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'SmaAt_UNet_pre(\n",
            "  (inc): DoubleConvDS(\n",
            "    (double_conv): Sequential(\n",
            "      (0): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
            "        (pointwise): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU(inplace=True)\n",
            "      (3): DepthwiseSeparableConv(\n",
            "        (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "        (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      )\n",
            "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (5): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (down1): DownDS(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConvDS(\n",
            "        (double_conv): Sequential(\n",
            "          (0): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "            (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down2): DownDS(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConvDS(\n",
            "        (double_conv): Sequential(\n",
            "          (0): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "            (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "            (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down3): DownDS(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConvDS(\n",
            "        (double_conv): Sequential(\n",
            "          (0): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "            (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (down4): DownDS(\n",
            "    (maxpool_conv): Sequential(\n",
            "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (1): DoubleConvDS(\n",
            "        (double_conv): Sequential(\n",
            "          (0): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "          (3): DepthwiseSeparableConv(\n",
            "            (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "            (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "          )\n",
            "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (5): ReLU(inplace=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cbam5): CBAM(\n",
            "    (channel_att): ChannelAttention(\n",
            "      (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "      (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "      (MLP): Sequential(\n",
            "        (0): Flatten()\n",
            "        (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "        (2): ReLU()\n",
            "        (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (spatial_att): SpatialAttention(\n",
            "      (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "      (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            ")'\n",
            "MoCo(\n",
            "  (encoder_q): SmaAt_UNet_pre(\n",
            "    (inc): DoubleConvDS(\n",
            "      (double_conv): Sequential(\n",
            "        (0): DepthwiseSeparableConv(\n",
            "          (depthwise): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
            "          (pointwise): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): DepthwiseSeparableConv(\n",
            "          (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "          (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (down1): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "              (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down2): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "              (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down3): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "              (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down4): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cbam5): CBAM(\n",
            "      (channel_att): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (MLP): Sequential(\n",
            "          (0): Flatten()\n",
            "          (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "          (2): ReLU()\n",
            "          (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (spatial_att): SpatialAttention(\n",
            "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            "  (encoder_k): SmaAt_UNet_pre(\n",
            "    (inc): DoubleConvDS(\n",
            "      (double_conv): Sequential(\n",
            "        (0): DepthwiseSeparableConv(\n",
            "          (depthwise): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3)\n",
            "          (pointwise): Conv2d(6, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): ReLU(inplace=True)\n",
            "        (3): DepthwiseSeparableConv(\n",
            "          (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "          (pointwise): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        )\n",
            "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (down1): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
            "              (pointwise): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (pointwise): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down2): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
            "              (pointwise): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "              (pointwise): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down3): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
            "              (pointwise): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (down4): DownDS(\n",
            "      (maxpool_conv): Sequential(\n",
            "        (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "        (1): DoubleConvDS(\n",
            "          (double_conv): Sequential(\n",
            "            (0): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): DepthwiseSeparableConv(\n",
            "              (depthwise): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
            "              (pointwise): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "            )\n",
            "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (5): ReLU(inplace=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (cbam5): CBAM(\n",
            "      (channel_att): ChannelAttention(\n",
            "        (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "        (max_pool): AdaptiveMaxPool2d(output_size=1)\n",
            "        (MLP): Sequential(\n",
            "          (0): Flatten()\n",
            "          (1): Linear(in_features=512, out_features=32, bias=True)\n",
            "          (2): ReLU()\n",
            "          (3): Linear(in_features=32, out_features=512, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (spatial_att): SpatialAttention(\n",
            "        (conv): Conv2d(2, 1, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
            "        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "2023-04-19 11:46:50.660860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 11:46:55.595191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [0][   0/1075]\tTime 17.197 (17.197)\tData 11.013 (11.013)\tLoss 9.7892e-01 (9.7892e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][  10/1075]\tTime  0.509 ( 2.086)\tData  0.000 ( 1.133)\tLoss 4.9143e+00 (3.7537e+00)\tAcc@1  65.62 ( 69.32)\tAcc@5  70.31 ( 76.70)\n",
            "Epoch: [0][  20/1075]\tTime  0.492 ( 1.367)\tData  0.000 ( 0.677)\tLoss 6.0718e+00 (4.6611e+00)\tAcc@1  17.19 ( 53.27)\tAcc@5  29.69 ( 62.80)\n",
            "Epoch: [0][  30/1075]\tTime  0.538 ( 1.145)\tData  0.221 ( 0.579)\tLoss 6.4864e+00 (5.1998e+00)\tAcc@1  25.00 ( 42.04)\tAcc@5  37.50 ( 52.57)\n",
            "Epoch: [0][  40/1075]\tTime  0.737 ( 1.024)\tData  0.445 ( 0.505)\tLoss 6.6576e+00 (5.5396e+00)\tAcc@1  10.94 ( 35.40)\tAcc@5  23.44 ( 46.68)\n",
            "Epoch: [0][  50/1075]\tTime  0.954 ( 0.960)\tData  0.645 ( 0.467)\tLoss 6.6711e+00 (5.7598e+00)\tAcc@1  14.06 ( 31.25)\tAcc@5  25.00 ( 42.52)\n",
            "Epoch: [0][  60/1075]\tTime  0.743 ( 0.911)\tData  0.443 ( 0.437)\tLoss 6.6327e+00 (5.9051e+00)\tAcc@1  18.75 ( 28.43)\tAcc@5  23.44 ( 39.32)\n",
            "Epoch: [0][  70/1075]\tTime  0.971 ( 0.879)\tData  0.662 ( 0.418)\tLoss 6.6190e+00 (6.0057e+00)\tAcc@1  18.75 ( 26.58)\tAcc@5  35.94 ( 37.70)\n",
            "Epoch: [0][  80/1075]\tTime  0.752 ( 0.850)\tData  0.460 ( 0.399)\tLoss 6.6135e+00 (6.0809e+00)\tAcc@1   7.81 ( 25.29)\tAcc@5  23.44 ( 36.46)\n",
            "Epoch: [0][  90/1075]\tTime  1.138 ( 0.831)\tData  0.844 ( 0.387)\tLoss 6.6479e+00 (6.1426e+00)\tAcc@1  12.50 ( 24.16)\tAcc@5  21.88 ( 35.34)\n",
            "Epoch: [0][ 100/1075]\tTime  0.714 ( 0.808)\tData  0.423 ( 0.371)\tLoss 6.6567e+00 (6.1934e+00)\tAcc@1  12.50 ( 23.21)\tAcc@5  25.00 ( 34.47)\n",
            "Epoch: [0][ 110/1075]\tTime  1.086 ( 0.801)\tData  0.773 ( 0.369)\tLoss 6.6345e+00 (6.2346e+00)\tAcc@1  12.50 ( 22.23)\tAcc@5  26.56 ( 33.23)\n",
            "Epoch: [0][ 120/1075]\tTime  0.774 ( 0.788)\tData  0.481 ( 0.361)\tLoss 6.5990e+00 (6.2660e+00)\tAcc@1   6.25 ( 21.49)\tAcc@5  21.88 ( 32.22)\n",
            "Epoch: [0][ 130/1075]\tTime  1.000 ( 0.778)\tData  0.693 ( 0.355)\tLoss 6.5660e+00 (6.2901e+00)\tAcc@1  15.62 ( 20.91)\tAcc@5  25.00 ( 31.69)\n",
            "Epoch: [0][ 140/1075]\tTime  0.688 ( 0.771)\tData  0.377 ( 0.351)\tLoss 6.3776e+00 (6.3024e+00)\tAcc@1   6.25 ( 20.32)\tAcc@5   7.81 ( 30.77)\n",
            "Epoch: [0][ 150/1075]\tTime  1.075 ( 0.764)\tData  0.781 ( 0.346)\tLoss 6.1863e+00 (6.3038e+00)\tAcc@1  23.44 ( 19.73)\tAcc@5  28.12 ( 30.09)\n",
            "Epoch: [0][ 160/1075]\tTime  0.623 ( 0.758)\tData  0.313 ( 0.341)\tLoss 4.8731e+00 (6.2370e+00)\tAcc@1  31.25 ( 20.12)\tAcc@5  42.19 ( 30.37)\n",
            "Epoch: [0][ 170/1075]\tTime  0.622 ( 0.748)\tData  0.312 ( 0.334)\tLoss 6.1710e+00 (6.2069e+00)\tAcc@1   0.00 ( 19.62)\tAcc@5   4.69 ( 29.80)\n",
            "Epoch: [0][ 180/1075]\tTime  0.805 ( 0.745)\tData  0.494 ( 0.332)\tLoss 6.5613e+00 (6.2158e+00)\tAcc@1  18.75 ( 19.21)\tAcc@5  25.00 ( 29.22)\n",
            "Epoch: [0][ 190/1075]\tTime  0.660 ( 0.737)\tData  0.365 ( 0.326)\tLoss 6.6020e+00 (6.2363e+00)\tAcc@1   9.38 ( 18.68)\tAcc@5  17.19 ( 28.58)\n",
            "Epoch: [0][ 200/1075]\tTime  0.688 ( 0.734)\tData  0.377 ( 0.327)\tLoss 6.3962e+00 (6.2494e+00)\tAcc@1  21.88 ( 18.57)\tAcc@5  31.25 ( 28.30)\n",
            "Epoch: [0][ 210/1075]\tTime  0.502 ( 0.727)\tData  0.178 ( 0.324)\tLoss 6.2617e+00 (6.2520e+00)\tAcc@1  12.50 ( 18.76)\tAcc@5  15.62 ( 28.36)\n",
            "Epoch: [0][ 220/1075]\tTime  0.495 ( 0.725)\tData  0.162 ( 0.325)\tLoss 6.2458e+00 (6.2508e+00)\tAcc@1  29.69 ( 19.34)\tAcc@5  35.94 ( 28.87)\n",
            "Epoch: [0][ 230/1075]\tTime  0.739 ( 0.720)\tData  0.444 ( 0.324)\tLoss 6.3515e+00 (6.2531e+00)\tAcc@1  29.69 ( 19.86)\tAcc@5  37.50 ( 29.35)\n",
            "Epoch: [0][ 240/1075]\tTime  0.553 ( 0.718)\tData  0.243 ( 0.326)\tLoss 6.4798e+00 (6.2602e+00)\tAcc@1  43.75 ( 20.33)\tAcc@5  50.00 ( 29.64)\n",
            "Epoch: [0][ 250/1075]\tTime  0.727 ( 0.714)\tData  0.419 ( 0.324)\tLoss 6.6633e+00 (6.2729e+00)\tAcc@1  15.62 ( 20.35)\tAcc@5  23.44 ( 29.51)\n",
            "Epoch: [0][ 260/1075]\tTime  1.045 ( 0.714)\tData  0.736 ( 0.324)\tLoss 6.9424e+00 (6.2935e+00)\tAcc@1  10.94 ( 20.11)\tAcc@5  17.19 ( 29.21)\n",
            "Epoch: [0][ 270/1075]\tTime  0.498 ( 0.709)\tData  0.065 ( 0.321)\tLoss 7.1382e+00 (6.3207e+00)\tAcc@1  14.06 ( 19.83)\tAcc@5  23.44 ( 28.86)\n",
            "Epoch: [0][ 280/1075]\tTime  0.494 ( 0.708)\tData  0.023 ( 0.320)\tLoss 7.2281e+00 (6.3522e+00)\tAcc@1   9.38 ( 19.50)\tAcc@5  17.19 ( 28.58)\n",
            "Epoch: [0][ 290/1075]\tTime  0.497 ( 0.706)\tData  0.000 ( 0.318)\tLoss 7.1426e+00 (6.3815e+00)\tAcc@1  26.56 ( 19.27)\tAcc@5  31.25 ( 28.34)\n",
            "Epoch: [0][ 300/1075]\tTime  0.495 ( 0.705)\tData  0.000 ( 0.316)\tLoss 6.8994e+00 (6.4027e+00)\tAcc@1  14.06 ( 19.30)\tAcc@5  25.00 ( 28.33)\n",
            "Epoch: [0][ 310/1075]\tTime  0.493 ( 0.704)\tData  0.000 ( 0.315)\tLoss 6.6861e+00 (6.4155e+00)\tAcc@1  21.88 ( 19.18)\tAcc@5  32.81 ( 28.24)\n",
            "Epoch: [0][ 320/1075]\tTime  0.504 ( 0.700)\tData  0.000 ( 0.311)\tLoss 6.6796e+00 (6.4238e+00)\tAcc@1  17.19 ( 19.31)\tAcc@5  17.19 ( 28.38)\n",
            "Epoch: [0][ 330/1075]\tTime  0.681 ( 0.700)\tData  0.369 ( 0.313)\tLoss 6.4876e+00 (6.4361e+00)\tAcc@1  17.19 ( 19.24)\tAcc@5  26.56 ( 28.28)\n",
            "Epoch: [0][ 340/1075]\tTime  0.788 ( 0.698)\tData  0.492 ( 0.312)\tLoss 6.1987e+00 (6.4355e+00)\tAcc@1  17.19 ( 19.37)\tAcc@5  23.44 ( 28.34)\n",
            "Epoch: [0][ 350/1075]\tTime  0.701 ( 0.698)\tData  0.405 ( 0.312)\tLoss 6.4055e+00 (6.4304e+00)\tAcc@1   6.25 ( 19.15)\tAcc@5  14.06 ( 28.02)\n",
            "Epoch: [0][ 360/1075]\tTime  0.731 ( 0.695)\tData  0.413 ( 0.311)\tLoss 6.8361e+00 (6.4370e+00)\tAcc@1   7.81 ( 18.81)\tAcc@5  12.50 ( 27.57)\n",
            "Epoch: [0][ 370/1075]\tTime  0.659 ( 0.695)\tData  0.365 ( 0.312)\tLoss 7.2295e+00 (6.4541e+00)\tAcc@1   4.69 ( 18.42)\tAcc@5   7.81 ( 27.08)\n",
            "Epoch: [0][ 380/1075]\tTime  0.637 ( 0.693)\tData  0.339 ( 0.310)\tLoss 7.4097e+00 (6.4764e+00)\tAcc@1   1.56 ( 18.03)\tAcc@5   4.69 ( 26.62)\n",
            "Epoch: [0][ 390/1075]\tTime  0.791 ( 0.694)\tData  0.481 ( 0.311)\tLoss 7.0272e+00 (6.4961e+00)\tAcc@1  12.50 ( 17.73)\tAcc@5  23.44 ( 26.32)\n",
            "Epoch: [0][ 400/1075]\tTime  0.831 ( 0.692)\tData  0.537 ( 0.310)\tLoss 6.0573e+00 (6.4972e+00)\tAcc@1   7.81 ( 17.53)\tAcc@5  20.31 ( 26.17)\n",
            "Epoch: [0][ 410/1075]\tTime  0.750 ( 0.693)\tData  0.441 ( 0.310)\tLoss 5.3795e+00 (6.4732e+00)\tAcc@1  20.31 ( 17.48)\tAcc@5  31.25 ( 26.31)\n",
            "Epoch: [0][ 420/1075]\tTime  0.809 ( 0.691)\tData  0.515 ( 0.308)\tLoss 6.2420e+00 (6.4579e+00)\tAcc@1  18.75 ( 17.51)\tAcc@5  37.50 ( 26.53)\n",
            "Epoch: [0][ 430/1075]\tTime  0.649 ( 0.690)\tData  0.354 ( 0.307)\tLoss 6.9543e+00 (6.4614e+00)\tAcc@1  14.06 ( 17.54)\tAcc@5  23.44 ( 26.52)\n",
            "Epoch: [0][ 440/1075]\tTime  0.804 ( 0.689)\tData  0.492 ( 0.306)\tLoss 6.9784e+00 (6.4741e+00)\tAcc@1  32.81 ( 17.50)\tAcc@5  40.62 ( 26.42)\n",
            "Epoch: [0][ 450/1075]\tTime  0.729 ( 0.688)\tData  0.438 ( 0.306)\tLoss 5.1799e+00 (6.4649e+00)\tAcc@1  57.81 ( 17.72)\tAcc@5  62.50 ( 26.66)\n",
            "Epoch: [0][ 460/1075]\tTime  0.748 ( 0.686)\tData  0.439 ( 0.306)\tLoss 6.1809e+00 (6.4564e+00)\tAcc@1  23.44 ( 17.73)\tAcc@5  32.81 ( 26.64)\n",
            "Epoch: [0][ 470/1075]\tTime  0.975 ( 0.686)\tData  0.673 ( 0.306)\tLoss 6.0357e+00 (6.4471e+00)\tAcc@1   7.81 ( 17.63)\tAcc@5  26.56 ( 26.55)\n",
            "Epoch: [0][ 480/1075]\tTime  0.669 ( 0.685)\tData  0.373 ( 0.306)\tLoss 6.2382e+00 (6.4403e+00)\tAcc@1   7.81 ( 17.41)\tAcc@5  10.94 ( 26.33)\n",
            "Epoch: [0][ 490/1075]\tTime  1.127 ( 0.684)\tData  0.792 ( 0.306)\tLoss 6.6482e+00 (6.4405e+00)\tAcc@1   6.25 ( 17.15)\tAcc@5  10.94 ( 26.06)\n",
            "Epoch: [0][ 500/1075]\tTime  0.823 ( 0.684)\tData  0.513 ( 0.306)\tLoss 7.0035e+00 (6.4489e+00)\tAcc@1   6.25 ( 16.91)\tAcc@5  15.62 ( 25.77)\n",
            "Epoch: [0][ 510/1075]\tTime  0.738 ( 0.683)\tData  0.411 ( 0.305)\tLoss 7.1766e+00 (6.4622e+00)\tAcc@1   6.25 ( 16.66)\tAcc@5  15.62 ( 25.47)\n",
            "Epoch: [0][ 520/1075]\tTime  0.864 ( 0.683)\tData  0.553 ( 0.305)\tLoss 7.0327e+00 (6.4758e+00)\tAcc@1   4.69 ( 16.42)\tAcc@5  10.94 ( 25.19)\n",
            "Epoch: [0][ 530/1075]\tTime  0.771 ( 0.682)\tData  0.449 ( 0.304)\tLoss 6.3881e+00 (6.4823e+00)\tAcc@1   7.81 ( 16.19)\tAcc@5  14.06 ( 24.94)\n",
            "Epoch: [0][ 540/1075]\tTime  0.703 ( 0.682)\tData  0.410 ( 0.304)\tLoss 5.7812e+00 (6.4749e+00)\tAcc@1  23.44 ( 16.09)\tAcc@5  39.06 ( 24.89)\n",
            "Epoch: [0][ 550/1075]\tTime  0.804 ( 0.681)\tData  0.510 ( 0.303)\tLoss 6.4113e+00 (6.4677e+00)\tAcc@1  17.19 ( 16.21)\tAcc@5  18.75 ( 25.01)\n",
            "Epoch: [0][ 560/1075]\tTime  0.608 ( 0.681)\tData  0.315 ( 0.303)\tLoss 5.3229e+00 (6.4608e+00)\tAcc@1  29.69 ( 16.48)\tAcc@5  32.81 ( 25.23)\n",
            "Epoch: [0][ 570/1075]\tTime  0.824 ( 0.680)\tData  0.529 ( 0.302)\tLoss 5.7602e+00 (6.4413e+00)\tAcc@1  23.44 ( 16.66)\tAcc@5  32.81 ( 25.43)\n",
            "Epoch: [0][ 580/1075]\tTime  0.911 ( 0.681)\tData  0.615 ( 0.302)\tLoss 6.3373e+00 (6.4354e+00)\tAcc@1  26.56 ( 16.61)\tAcc@5  31.25 ( 25.34)\n",
            "Epoch: [0][ 590/1075]\tTime  0.619 ( 0.680)\tData  0.324 ( 0.301)\tLoss 6.7052e+00 (6.4378e+00)\tAcc@1   4.69 ( 16.45)\tAcc@5   7.81 ( 25.17)\n",
            "Epoch: [0][ 600/1075]\tTime  0.910 ( 0.680)\tData  0.598 ( 0.302)\tLoss 6.2974e+00 (6.4364e+00)\tAcc@1   0.00 ( 16.47)\tAcc@5   1.56 ( 25.23)\n",
            "Epoch: [0][ 610/1075]\tTime  0.852 ( 0.679)\tData  0.556 ( 0.300)\tLoss 6.2328e+00 (6.4286e+00)\tAcc@1   3.12 ( 16.63)\tAcc@5  65.62 ( 25.50)\n",
            "Epoch: [0][ 620/1075]\tTime  1.017 ( 0.679)\tData  0.722 ( 0.301)\tLoss 6.8555e+00 (6.4312e+00)\tAcc@1   0.00 ( 16.70)\tAcc@5   0.00 ( 25.50)\n",
            "Epoch: [0][ 630/1075]\tTime  0.803 ( 0.678)\tData  0.505 ( 0.300)\tLoss 7.1322e+00 (6.4401e+00)\tAcc@1  45.31 ( 16.94)\tAcc@5  48.44 ( 25.64)\n",
            "Epoch: [0][ 640/1075]\tTime  1.159 ( 0.679)\tData  0.873 ( 0.300)\tLoss 7.3363e+00 (6.4526e+00)\tAcc@1   0.00 ( 17.29)\tAcc@5   0.00 ( 25.95)\n",
            "Epoch: [0][ 650/1075]\tTime  0.801 ( 0.679)\tData  0.492 ( 0.300)\tLoss 7.3866e+00 (6.4668e+00)\tAcc@1  81.25 ( 17.65)\tAcc@5  84.38 ( 26.24)\n",
            "Epoch: [0][ 660/1075]\tTime  0.891 ( 0.679)\tData  0.571 ( 0.300)\tLoss 7.4014e+00 (6.4811e+00)\tAcc@1  54.69 ( 18.00)\tAcc@5  60.94 ( 26.53)\n",
            "Epoch: [0][ 670/1075]\tTime  0.755 ( 0.679)\tData  0.461 ( 0.300)\tLoss 7.3613e+00 (6.4946e+00)\tAcc@1  56.25 ( 18.50)\tAcc@5  57.81 ( 26.98)\n",
            "Epoch: [0][ 680/1075]\tTime  0.864 ( 0.679)\tData  0.548 ( 0.300)\tLoss 7.2456e+00 (6.5063e+00)\tAcc@1  59.38 ( 19.14)\tAcc@5  75.00 ( 27.61)\n",
            "Epoch: [0][ 690/1075]\tTime  0.654 ( 0.678)\tData  0.346 ( 0.299)\tLoss 7.2167e+00 (6.5169e+00)\tAcc@1  39.06 ( 19.25)\tAcc@5  45.31 ( 27.68)\n",
            "Epoch: [0][ 700/1075]\tTime  1.097 ( 0.678)\tData  0.803 ( 0.299)\tLoss 7.3367e+00 (6.5270e+00)\tAcc@1   1.56 ( 19.16)\tAcc@5   1.56 ( 27.57)\n",
            "Epoch: [0][ 710/1075]\tTime  0.573 ( 0.678)\tData  0.290 ( 0.299)\tLoss 6.2070e+00 (6.5265e+00)\tAcc@1  12.50 ( 19.00)\tAcc@5  17.19 ( 27.39)\n",
            "Epoch: [0][ 720/1075]\tTime  0.853 ( 0.677)\tData  0.551 ( 0.297)\tLoss 5.0872e+00 (6.5133e+00)\tAcc@1   7.81 ( 18.90)\tAcc@5  15.62 ( 27.37)\n",
            "Epoch: [0][ 730/1075]\tTime  0.783 ( 0.677)\tData  0.490 ( 0.298)\tLoss 6.0162e+00 (6.5022e+00)\tAcc@1   6.25 ( 18.76)\tAcc@5  15.62 ( 27.23)\n",
            "Epoch: [0][ 740/1075]\tTime  0.817 ( 0.676)\tData  0.520 ( 0.297)\tLoss 6.4364e+00 (6.4989e+00)\tAcc@1   6.25 ( 18.60)\tAcc@5  18.75 ( 27.10)\n",
            "Epoch: [0][ 750/1075]\tTime  0.508 ( 0.676)\tData  0.175 ( 0.297)\tLoss 5.1049e+00 (6.4945e+00)\tAcc@1  37.50 ( 18.59)\tAcc@5  50.00 ( 27.08)\n",
            "Epoch: [0][ 760/1075]\tTime  0.496 ( 0.675)\tData  0.005 ( 0.297)\tLoss 5.9224e+00 (6.4830e+00)\tAcc@1   7.81 ( 18.57)\tAcc@5  21.88 ( 27.16)\n",
            "Epoch: [0][ 770/1075]\tTime  0.495 ( 0.675)\tData  0.051 ( 0.297)\tLoss 5.6471e+00 (6.4742e+00)\tAcc@1  34.38 ( 18.58)\tAcc@5  45.31 ( 27.25)\n",
            "Epoch: [0][ 780/1075]\tTime  0.491 ( 0.674)\tData  0.174 ( 0.297)\tLoss 6.2694e+00 (6.4686e+00)\tAcc@1   9.38 ( 18.65)\tAcc@5  17.19 ( 27.33)\n",
            "Epoch: [0][ 790/1075]\tTime  0.831 ( 0.674)\tData  0.505 ( 0.298)\tLoss 6.7752e+00 (6.4700e+00)\tAcc@1   9.38 ( 18.53)\tAcc@5  12.50 ( 27.23)\n",
            "Epoch: [0][ 800/1075]\tTime  0.511 ( 0.673)\tData  0.156 ( 0.298)\tLoss 7.1331e+00 (6.4765e+00)\tAcc@1   4.69 ( 18.45)\tAcc@5  15.62 ( 27.12)\n",
            "Epoch: [0][ 810/1075]\tTime  0.903 ( 0.672)\tData  0.609 ( 0.298)\tLoss 7.3363e+00 (6.4861e+00)\tAcc@1   9.38 ( 18.32)\tAcc@5  29.69 ( 26.99)\n",
            "Epoch: [0][ 820/1075]\tTime  0.704 ( 0.672)\tData  0.394 ( 0.299)\tLoss 7.4532e+00 (6.4974e+00)\tAcc@1   7.81 ( 18.18)\tAcc@5  23.44 ( 26.87)\n",
            "Epoch: [0][ 830/1075]\tTime  1.027 ( 0.672)\tData  0.703 ( 0.298)\tLoss 7.3729e+00 (6.5088e+00)\tAcc@1  14.06 ( 18.11)\tAcc@5  21.88 ( 26.78)\n",
            "Epoch: [0][ 840/1075]\tTime  0.840 ( 0.672)\tData  0.545 ( 0.298)\tLoss 7.2151e+00 (6.5184e+00)\tAcc@1  10.94 ( 18.04)\tAcc@5  21.88 ( 26.68)\n",
            "Epoch: [0][ 850/1075]\tTime  0.659 ( 0.671)\tData  0.364 ( 0.297)\tLoss 7.1114e+00 (6.5260e+00)\tAcc@1  23.44 ( 17.96)\tAcc@5  29.69 ( 26.58)\n",
            "Epoch: [0][ 860/1075]\tTime  0.758 ( 0.672)\tData  0.447 ( 0.297)\tLoss 6.5276e+00 (6.5291e+00)\tAcc@1  20.31 ( 17.92)\tAcc@5  32.81 ( 26.56)\n",
            "Epoch: [0][ 870/1075]\tTime  0.674 ( 0.671)\tData  0.378 ( 0.297)\tLoss 5.3951e+00 (6.5220e+00)\tAcc@1  14.06 ( 17.90)\tAcc@5  20.31 ( 26.55)\n",
            "Epoch: [0][ 880/1075]\tTime  0.645 ( 0.671)\tData  0.335 ( 0.297)\tLoss 6.0105e+00 (6.5102e+00)\tAcc@1  64.06 ( 18.16)\tAcc@5  65.62 ( 26.76)\n",
            "Epoch: [0][ 890/1075]\tTime  0.641 ( 0.671)\tData  0.358 ( 0.296)\tLoss 6.7745e+00 (6.5100e+00)\tAcc@1  64.06 ( 18.32)\tAcc@5  67.19 ( 26.89)\n",
            "Epoch: [0][ 900/1075]\tTime  0.825 ( 0.672)\tData  0.516 ( 0.297)\tLoss 7.1332e+00 (6.5153e+00)\tAcc@1  50.00 ( 18.46)\tAcc@5  53.12 ( 27.00)\n",
            "Epoch: [0][ 910/1075]\tTime  0.912 ( 0.672)\tData  0.616 ( 0.297)\tLoss 7.3371e+00 (6.5234e+00)\tAcc@1  75.00 ( 18.83)\tAcc@5  78.12 ( 27.33)\n",
            "Epoch: [0][ 920/1075]\tTime  0.819 ( 0.672)\tData  0.523 ( 0.297)\tLoss 7.4324e+00 (6.5330e+00)\tAcc@1  40.62 ( 19.11)\tAcc@5  53.12 ( 27.59)\n",
            "Epoch: [0][ 930/1075]\tTime  0.596 ( 0.671)\tData  0.302 ( 0.296)\tLoss 7.4354e+00 (6.5427e+00)\tAcc@1  42.19 ( 19.42)\tAcc@5  56.25 ( 27.90)\n",
            "Epoch: [0][ 940/1075]\tTime  0.693 ( 0.672)\tData  0.400 ( 0.297)\tLoss 7.3655e+00 (6.5517e+00)\tAcc@1  67.19 ( 19.98)\tAcc@5  76.56 ( 28.41)\n",
            "Epoch: [0][ 950/1075]\tTime  0.571 ( 0.671)\tData  0.278 ( 0.296)\tLoss 7.2691e+00 (6.5598e+00)\tAcc@1  40.62 ( 20.40)\tAcc@5  51.56 ( 28.81)\n",
            "Epoch: [0][ 960/1075]\tTime  0.888 ( 0.671)\tData  0.595 ( 0.296)\tLoss 5.5895e+00 (6.5554e+00)\tAcc@1   3.12 ( 20.46)\tAcc@5  14.06 ( 28.88)\n",
            "Epoch: [0][ 970/1075]\tTime  0.587 ( 0.670)\tData  0.278 ( 0.295)\tLoss 6.0262e+00 (6.5491e+00)\tAcc@1   4.69 ( 20.34)\tAcc@5  21.88 ( 28.79)\n",
            "Epoch: [0][ 980/1075]\tTime  1.135 ( 0.671)\tData  0.845 ( 0.296)\tLoss 6.1768e+00 (6.5452e+00)\tAcc@1   4.69 ( 20.20)\tAcc@5  10.94 ( 28.66)\n",
            "Epoch: [0][ 990/1075]\tTime  0.632 ( 0.670)\tData  0.323 ( 0.295)\tLoss 6.2390e+00 (6.5415e+00)\tAcc@1   6.25 ( 20.06)\tAcc@5  18.75 ( 28.54)\n",
            "Epoch: [0][1000/1075]\tTime  1.161 ( 0.670)\tData  0.865 ( 0.295)\tLoss 5.1255e+00 (6.5352e+00)\tAcc@1  31.25 ( 20.06)\tAcc@5  57.81 ( 28.60)\n",
            "Epoch: [0][1010/1075]\tTime  0.601 ( 0.670)\tData  0.305 ( 0.294)\tLoss 6.1997e+00 (6.5258e+00)\tAcc@1  10.94 ( 20.07)\tAcc@5  15.62 ( 28.65)\n",
            "Epoch: [0][1020/1075]\tTime  1.032 ( 0.669)\tData  0.727 ( 0.294)\tLoss 6.6196e+00 (6.5245e+00)\tAcc@1   4.69 ( 19.94)\tAcc@5  12.50 ( 28.52)\n",
            "Epoch: [0][1030/1075]\tTime  0.677 ( 0.669)\tData  0.368 ( 0.294)\tLoss 6.1481e+00 (6.5235e+00)\tAcc@1   6.25 ( 19.79)\tAcc@5  14.06 ( 28.36)\n",
            "Epoch: [0][1040/1075]\tTime  0.651 ( 0.669)\tData  0.352 ( 0.294)\tLoss 6.2383e+00 (6.5182e+00)\tAcc@1   0.00 ( 19.65)\tAcc@5  10.94 ( 28.23)\n",
            "Epoch: [0][1050/1075]\tTime  0.556 ( 0.669)\tData  0.246 ( 0.294)\tLoss 6.4611e+00 (6.5167e+00)\tAcc@1  10.94 ( 19.53)\tAcc@5  25.00 ( 28.15)\n",
            "Epoch: [0][1060/1075]\tTime  0.674 ( 0.669)\tData  0.379 ( 0.293)\tLoss 6.5260e+00 (6.5164e+00)\tAcc@1  12.50 ( 19.44)\tAcc@5  21.88 ( 28.10)\n",
            "Epoch: [0][1070/1075]\tTime  0.740 ( 0.669)\tData  0.445 ( 0.293)\tLoss 6.4211e+00 (6.5154e+00)\tAcc@1   4.69 ( 19.37)\tAcc@5  14.06 ( 28.06)\n",
            "epoch: 0\n",
            "2023-04-19 11:58:50.523735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 11:58:55.580701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [1][   0/1075]\tTime 11.481 (11.481)\tData 11.170 (11.170)\tLoss 6.3663e+00 (6.3663e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  25.00 ( 25.00)\n",
            "Epoch: [1][  10/1075]\tTime  1.103 ( 1.691)\tData  0.805 ( 1.311)\tLoss 5.4727e+00 (6.1405e+00)\tAcc@1  17.19 (  9.09)\tAcc@5  29.69 ( 22.59)\n",
            "Epoch: [1][  20/1075]\tTime  0.855 ( 1.202)\tData  0.545 ( 0.821)\tLoss 5.6194e+00 (5.7833e+00)\tAcc@1  10.94 ( 10.71)\tAcc@5  17.19 ( 23.88)\n",
            "Epoch: [1][  30/1075]\tTime  0.939 ( 1.015)\tData  0.621 ( 0.633)\tLoss 6.0229e+00 (5.8017e+00)\tAcc@1   9.38 ( 10.03)\tAcc@5  26.56 ( 23.19)\n",
            "Epoch: [1][  40/1075]\tTime  0.622 ( 0.929)\tData  0.327 ( 0.552)\tLoss 6.3275e+00 (5.8875e+00)\tAcc@1  10.94 ( 10.44)\tAcc@5  20.31 ( 23.67)\n",
            "Epoch: [1][  50/1075]\tTime  0.662 ( 0.860)\tData  0.354 ( 0.496)\tLoss 5.7893e+00 (5.9388e+00)\tAcc@1   9.38 ( 10.29)\tAcc@5  21.88 ( 22.89)\n",
            "Epoch: [1][  60/1075]\tTime  0.622 ( 0.832)\tData  0.328 ( 0.470)\tLoss 6.0231e+00 (5.9063e+00)\tAcc@1   1.56 (  9.89)\tAcc@5   6.25 ( 22.52)\n",
            "Epoch: [1][  70/1075]\tTime  0.634 ( 0.804)\tData  0.324 ( 0.439)\tLoss 6.5279e+00 (5.9634e+00)\tAcc@1   4.69 (  9.57)\tAcc@5  12.50 ( 21.76)\n",
            "Epoch: [1][  80/1075]\tTime  0.677 ( 0.789)\tData  0.383 ( 0.422)\tLoss 6.7841e+00 (6.0538e+00)\tAcc@1   3.12 (  9.26)\tAcc@5   9.38 ( 21.05)\n",
            "Epoch: [1][  90/1075]\tTime  0.681 ( 0.768)\tData  0.388 ( 0.399)\tLoss 6.5935e+00 (6.1262e+00)\tAcc@1   9.38 (  9.01)\tAcc@5  20.31 ( 20.52)\n",
            "Epoch: [1][ 100/1075]\tTime  0.759 ( 0.764)\tData  0.453 ( 0.394)\tLoss 6.9279e+00 (6.1711e+00)\tAcc@1   4.69 (  8.59)\tAcc@5   7.81 ( 19.76)\n",
            "Epoch: [1][ 110/1075]\tTime  0.637 ( 0.746)\tData  0.342 ( 0.375)\tLoss 6.4884e+00 (6.2224e+00)\tAcc@1   3.12 (  8.31)\tAcc@5  14.06 ( 19.02)\n",
            "Epoch: [1][ 120/1075]\tTime  1.085 ( 0.738)\tData  0.778 ( 0.370)\tLoss 6.4624e+00 (6.2339e+00)\tAcc@1  12.50 (  8.41)\tAcc@5  18.75 ( 18.96)\n",
            "Epoch: [1][ 130/1075]\tTime  0.612 ( 0.726)\tData  0.316 ( 0.359)\tLoss 5.9105e+00 (6.2397e+00)\tAcc@1  12.50 (  8.41)\tAcc@5  23.44 ( 18.83)\n",
            "Epoch: [1][ 140/1075]\tTime  0.510 ( 0.720)\tData  0.000 ( 0.354)\tLoss 6.3518e+00 (6.2194e+00)\tAcc@1  14.06 (  8.83)\tAcc@5  32.81 ( 19.25)\n",
            "Epoch: [1][ 150/1075]\tTime  0.510 ( 0.716)\tData  0.000 ( 0.347)\tLoss 6.3578e+00 (6.2169e+00)\tAcc@1  12.50 (  9.03)\tAcc@5  28.12 ( 19.58)\n",
            "Epoch: [1][ 160/1075]\tTime  0.621 ( 0.707)\tData  0.302 ( 0.342)\tLoss 6.5791e+00 (6.2331e+00)\tAcc@1  10.94 (  8.99)\tAcc@5  20.31 ( 19.56)\n",
            "Epoch: [1][ 170/1075]\tTime  0.497 ( 0.705)\tData  0.145 ( 0.343)\tLoss 6.3516e+00 (6.2634e+00)\tAcc@1   6.25 (  8.89)\tAcc@5  18.75 ( 19.35)\n",
            "Epoch: [1][ 180/1075]\tTime  0.514 ( 0.699)\tData  0.078 ( 0.337)\tLoss 6.0904e+00 (6.2423e+00)\tAcc@1   9.38 (  8.79)\tAcc@5  28.12 ( 19.28)\n",
            "Epoch: [1][ 190/1075]\tTime  0.637 ( 0.698)\tData  0.343 ( 0.339)\tLoss 5.8196e+00 (6.2268e+00)\tAcc@1  17.19 (  9.17)\tAcc@5  42.19 ( 20.10)\n",
            "Epoch: [1][ 200/1075]\tTime  0.683 ( 0.693)\tData  0.371 ( 0.337)\tLoss 6.0394e+00 (6.2157e+00)\tAcc@1  21.88 (  9.55)\tAcc@5  28.12 ( 20.55)\n",
            "Epoch: [1][ 210/1075]\tTime  0.492 ( 0.692)\tData  0.000 ( 0.336)\tLoss 6.2704e+00 (6.2103e+00)\tAcc@1   4.69 (  9.73)\tAcc@5  10.94 ( 20.58)\n",
            "Epoch: [1][ 220/1075]\tTime  0.509 ( 0.688)\tData  0.167 ( 0.331)\tLoss 6.1299e+00 (6.2200e+00)\tAcc@1  17.19 (  9.84)\tAcc@5  25.00 ( 20.58)\n",
            "Epoch: [1][ 230/1075]\tTime  0.504 ( 0.685)\tData  0.108 ( 0.329)\tLoss 6.4270e+00 (6.2258e+00)\tAcc@1   7.81 (  9.84)\tAcc@5  15.62 ( 20.35)\n",
            "Epoch: [1][ 240/1075]\tTime  0.510 ( 0.683)\tData  0.000 ( 0.326)\tLoss 6.5817e+00 (6.2343e+00)\tAcc@1  15.62 ( 10.05)\tAcc@5  21.88 ( 20.45)\n",
            "Epoch: [1][ 250/1075]\tTime  0.506 ( 0.681)\tData  0.000 ( 0.322)\tLoss 5.9186e+00 (6.2320e+00)\tAcc@1  25.00 ( 10.57)\tAcc@5  34.38 ( 21.02)\n",
            "Epoch: [1][ 260/1075]\tTime  0.495 ( 0.680)\tData  0.000 ( 0.319)\tLoss 5.6904e+00 (6.2156e+00)\tAcc@1   1.56 ( 10.57)\tAcc@5  10.94 ( 21.07)\n",
            "Epoch: [1][ 270/1075]\tTime  0.512 ( 0.677)\tData  0.000 ( 0.315)\tLoss 6.5482e+00 (6.2157e+00)\tAcc@1   1.56 ( 10.37)\tAcc@5   9.38 ( 20.70)\n",
            "Epoch: [1][ 280/1075]\tTime  0.620 ( 0.677)\tData  0.325 ( 0.316)\tLoss 6.8018e+00 (6.2334e+00)\tAcc@1   9.38 ( 10.25)\tAcc@5  21.88 ( 20.52)\n",
            "Epoch: [1][ 290/1075]\tTime  0.724 ( 0.674)\tData  0.429 ( 0.314)\tLoss 6.1722e+00 (6.2453e+00)\tAcc@1  21.88 ( 10.55)\tAcc@5  32.81 ( 20.83)\n",
            "Epoch: [1][ 300/1075]\tTime  0.716 ( 0.674)\tData  0.422 ( 0.315)\tLoss 6.2486e+00 (6.2361e+00)\tAcc@1   0.00 ( 10.85)\tAcc@5   3.12 ( 21.13)\n",
            "Epoch: [1][ 310/1075]\tTime  0.584 ( 0.672)\tData  0.274 ( 0.312)\tLoss 6.9647e+00 (6.2489e+00)\tAcc@1   9.38 ( 10.97)\tAcc@5  15.62 ( 21.14)\n",
            "Epoch: [1][ 320/1075]\tTime  0.799 ( 0.672)\tData  0.506 ( 0.312)\tLoss 6.8899e+00 (6.2668e+00)\tAcc@1  15.62 ( 10.89)\tAcc@5  23.44 ( 21.01)\n",
            "Epoch: [1][ 330/1075]\tTime  0.646 ( 0.669)\tData  0.334 ( 0.310)\tLoss 7.1358e+00 (6.2911e+00)\tAcc@1  12.50 ( 11.00)\tAcc@5  18.75 ( 20.99)\n",
            "Epoch: [1][ 340/1075]\tTime  0.512 ( 0.670)\tData  0.000 ( 0.310)\tLoss 7.2601e+00 (6.3192e+00)\tAcc@1   9.38 ( 11.12)\tAcc@5  10.94 ( 21.02)\n",
            "Epoch: [1][ 350/1075]\tTime  0.497 ( 0.668)\tData  0.000 ( 0.307)\tLoss 7.3196e+00 (6.3458e+00)\tAcc@1  14.06 ( 11.21)\tAcc@5  25.00 ( 21.02)\n",
            "Epoch: [1][ 360/1075]\tTime  0.520 ( 0.667)\tData  0.192 ( 0.305)\tLoss 7.2289e+00 (6.3723e+00)\tAcc@1  18.75 ( 11.38)\tAcc@5  20.31 ( 21.09)\n",
            "Epoch: [1][ 370/1075]\tTime  0.514 ( 0.666)\tData  0.000 ( 0.305)\tLoss 7.2102e+00 (6.3952e+00)\tAcc@1  17.19 ( 11.48)\tAcc@5  26.56 ( 21.18)\n",
            "Epoch: [1][ 380/1075]\tTime  0.517 ( 0.665)\tData  0.000 ( 0.303)\tLoss 6.9690e+00 (6.4141e+00)\tAcc@1   7.81 ( 11.64)\tAcc@5   7.81 ( 21.27)\n",
            "Epoch: [1][ 390/1075]\tTime  0.509 ( 0.666)\tData  0.000 ( 0.303)\tLoss 6.9194e+00 (6.4295e+00)\tAcc@1  15.62 ( 11.66)\tAcc@5  21.88 ( 21.26)\n",
            "Epoch: [1][ 400/1075]\tTime  0.549 ( 0.664)\tData  0.000 ( 0.300)\tLoss 6.5525e+00 (6.4370e+00)\tAcc@1   6.25 ( 11.54)\tAcc@5  18.75 ( 21.06)\n",
            "Epoch: [1][ 410/1075]\tTime  0.510 ( 0.665)\tData  0.000 ( 0.299)\tLoss 6.7170e+00 (6.4418e+00)\tAcc@1   4.69 ( 11.34)\tAcc@5   6.25 ( 20.76)\n",
            "Epoch: [1][ 420/1075]\tTime  0.495 ( 0.662)\tData  0.164 ( 0.296)\tLoss 6.8603e+00 (6.4492e+00)\tAcc@1   3.12 ( 11.25)\tAcc@5  12.50 ( 20.65)\n",
            "Epoch: [1][ 430/1075]\tTime  0.508 ( 0.663)\tData  0.000 ( 0.297)\tLoss 6.8039e+00 (6.4581e+00)\tAcc@1   6.25 ( 11.12)\tAcc@5  10.94 ( 20.52)\n",
            "Epoch: [1][ 440/1075]\tTime  0.509 ( 0.661)\tData  0.000 ( 0.294)\tLoss 6.6878e+00 (6.4642e+00)\tAcc@1   3.12 ( 10.97)\tAcc@5   7.81 ( 20.33)\n",
            "Epoch: [1][ 450/1075]\tTime  0.507 ( 0.662)\tData  0.000 ( 0.294)\tLoss 6.7298e+00 (6.4696e+00)\tAcc@1  10.94 ( 10.81)\tAcc@5  15.62 ( 20.15)\n",
            "Epoch: [1][ 460/1075]\tTime  0.509 ( 0.660)\tData  0.000 ( 0.292)\tLoss 7.1284e+00 (6.4798e+00)\tAcc@1   7.81 ( 10.64)\tAcc@5  10.94 ( 19.91)\n",
            "Epoch: [1][ 470/1075]\tTime  0.512 ( 0.660)\tData  0.138 ( 0.291)\tLoss 7.2142e+00 (6.4932e+00)\tAcc@1   6.25 ( 10.52)\tAcc@5  18.75 ( 19.74)\n",
            "Epoch: [1][ 480/1075]\tTime  0.511 ( 0.659)\tData  0.000 ( 0.291)\tLoss 7.3505e+00 (6.5109e+00)\tAcc@1   7.81 ( 10.42)\tAcc@5  12.50 ( 19.56)\n",
            "Epoch: [1][ 490/1075]\tTime  0.490 ( 0.659)\tData  0.044 ( 0.290)\tLoss 7.4383e+00 (6.5288e+00)\tAcc@1   4.69 ( 10.27)\tAcc@5  14.06 ( 19.38)\n",
            "Epoch: [1][ 500/1075]\tTime  0.498 ( 0.659)\tData  0.000 ( 0.291)\tLoss 7.3849e+00 (6.5469e+00)\tAcc@1   3.12 ( 10.18)\tAcc@5  12.50 ( 19.25)\n",
            "Epoch: [1][ 510/1075]\tTime  0.494 ( 0.659)\tData  0.000 ( 0.290)\tLoss 7.2775e+00 (6.5625e+00)\tAcc@1   6.25 ( 10.10)\tAcc@5  14.06 ( 19.16)\n",
            "Epoch: [1][ 520/1075]\tTime  0.517 ( 0.660)\tData  0.000 ( 0.290)\tLoss 6.5705e+00 (6.5701e+00)\tAcc@1   7.81 ( 10.15)\tAcc@5  20.31 ( 19.19)\n",
            "Epoch: [1][ 530/1075]\tTime  0.530 ( 0.660)\tData  0.000 ( 0.290)\tLoss 5.9051e+00 (6.5603e+00)\tAcc@1  12.50 ( 10.11)\tAcc@5  25.00 ( 19.26)\n",
            "Epoch: [1][ 540/1075]\tTime  0.507 ( 0.660)\tData  0.000 ( 0.289)\tLoss 6.5584e+00 (6.5558e+00)\tAcc@1   6.25 ( 10.03)\tAcc@5  15.62 ( 19.17)\n",
            "Epoch: [1][ 550/1075]\tTime  0.508 ( 0.660)\tData  0.000 ( 0.288)\tLoss 6.9669e+00 (6.5602e+00)\tAcc@1   3.12 (  9.93)\tAcc@5   7.81 ( 19.05)\n",
            "Epoch: [1][ 560/1075]\tTime  0.495 ( 0.660)\tData  0.000 ( 0.288)\tLoss 6.8024e+00 (6.5653e+00)\tAcc@1  10.94 (  9.85)\tAcc@5  21.88 ( 18.96)\n",
            "Epoch: [1][ 570/1075]\tTime  0.513 ( 0.659)\tData  0.176 ( 0.287)\tLoss 6.8217e+00 (6.5680e+00)\tAcc@1   4.69 (  9.77)\tAcc@5  20.31 ( 18.88)\n",
            "Epoch: [1][ 580/1075]\tTime  0.681 ( 0.659)\tData  0.382 ( 0.289)\tLoss 6.9435e+00 (6.5728e+00)\tAcc@1   3.12 (  9.72)\tAcc@5  12.50 ( 18.82)\n",
            "Epoch: [1][ 590/1075]\tTime  0.511 ( 0.659)\tData  0.000 ( 0.289)\tLoss 6.9980e+00 (6.5798e+00)\tAcc@1  14.06 (  9.64)\tAcc@5  31.25 ( 18.72)\n",
            "Epoch: [1][ 600/1075]\tTime  0.509 ( 0.659)\tData  0.000 ( 0.289)\tLoss 6.8471e+00 (6.5854e+00)\tAcc@1   3.12 (  9.56)\tAcc@5   9.38 ( 18.64)\n",
            "Epoch: [1][ 610/1075]\tTime  0.496 ( 0.658)\tData  0.063 ( 0.287)\tLoss 6.5614e+00 (6.5875e+00)\tAcc@1   9.38 (  9.52)\tAcc@5  21.88 ( 18.60)\n",
            "Epoch: [1][ 620/1075]\tTime  0.493 ( 0.659)\tData  0.000 ( 0.288)\tLoss 6.7808e+00 (6.5888e+00)\tAcc@1   6.25 (  9.51)\tAcc@5  21.88 ( 18.62)\n",
            "Epoch: [1][ 630/1075]\tTime  0.497 ( 0.659)\tData  0.000 ( 0.287)\tLoss 6.8337e+00 (6.5922e+00)\tAcc@1   7.81 (  9.49)\tAcc@5  17.19 ( 18.67)\n",
            "Epoch: [1][ 640/1075]\tTime  0.496 ( 0.660)\tData  0.000 ( 0.287)\tLoss 6.3311e+00 (6.5917e+00)\tAcc@1  21.88 (  9.50)\tAcc@5  31.25 ( 18.70)\n",
            "Epoch: [1][ 650/1075]\tTime  0.492 ( 0.658)\tData  0.000 ( 0.286)\tLoss 6.1790e+00 (6.5868e+00)\tAcc@1  25.00 (  9.55)\tAcc@5  35.94 ( 18.77)\n",
            "Epoch: [1][ 660/1075]\tTime  0.492 ( 0.659)\tData  0.000 ( 0.286)\tLoss 5.5220e+00 (6.5726e+00)\tAcc@1   7.81 (  9.54)\tAcc@5  23.44 ( 18.80)\n",
            "Epoch: [1][ 670/1075]\tTime  0.497 ( 0.658)\tData  0.000 ( 0.285)\tLoss 6.2212e+00 (6.5589e+00)\tAcc@1   1.56 (  9.56)\tAcc@5  14.06 ( 18.82)\n",
            "Epoch: [1][ 680/1075]\tTime  0.963 ( 0.658)\tData  0.666 ( 0.286)\tLoss 6.4514e+00 (6.5561e+00)\tAcc@1   0.00 (  9.52)\tAcc@5   6.25 ( 18.73)\n",
            "Epoch: [1][ 690/1075]\tTime  0.543 ( 0.657)\tData  0.259 ( 0.285)\tLoss 6.7930e+00 (6.5586e+00)\tAcc@1   4.69 (  9.45)\tAcc@5  14.06 ( 18.63)\n",
            "Epoch: [1][ 700/1075]\tTime  0.550 ( 0.657)\tData  0.255 ( 0.286)\tLoss 6.9537e+00 (6.5641e+00)\tAcc@1   4.69 (  9.38)\tAcc@5  15.62 ( 18.53)\n",
            "Epoch: [1][ 710/1075]\tTime  0.566 ( 0.657)\tData  0.256 ( 0.287)\tLoss 6.8859e+00 (6.5692e+00)\tAcc@1   7.81 (  9.32)\tAcc@5  12.50 ( 18.44)\n",
            "Epoch: [1][ 720/1075]\tTime  0.845 ( 0.657)\tData  0.541 ( 0.287)\tLoss 6.7665e+00 (6.5724e+00)\tAcc@1  12.50 (  9.29)\tAcc@5  17.19 ( 18.42)\n",
            "Epoch: [1][ 730/1075]\tTime  0.624 ( 0.657)\tData  0.313 ( 0.287)\tLoss 6.8211e+00 (6.5750e+00)\tAcc@1   7.81 (  9.29)\tAcc@5  15.62 ( 18.42)\n",
            "Epoch: [1][ 740/1075]\tTime  0.922 ( 0.657)\tData  0.598 ( 0.287)\tLoss 6.8186e+00 (6.5781e+00)\tAcc@1   3.12 (  9.27)\tAcc@5  17.19 ( 18.40)\n",
            "Epoch: [1][ 750/1075]\tTime  0.648 ( 0.657)\tData  0.338 ( 0.287)\tLoss 6.6763e+00 (6.5820e+00)\tAcc@1   6.25 (  9.23)\tAcc@5  15.62 ( 18.33)\n",
            "Epoch: [1][ 760/1075]\tTime  0.513 ( 0.657)\tData  0.217 ( 0.287)\tLoss 6.3320e+00 (6.5831e+00)\tAcc@1   7.81 (  9.19)\tAcc@5  12.50 ( 18.28)\n",
            "Epoch: [1][ 770/1075]\tTime  0.495 ( 0.658)\tData  0.000 ( 0.288)\tLoss 6.6185e+00 (6.5811e+00)\tAcc@1   6.25 (  9.14)\tAcc@5  14.06 ( 18.21)\n",
            "Epoch: [1][ 780/1075]\tTime  0.499 ( 0.657)\tData  0.000 ( 0.287)\tLoss 6.2127e+00 (6.5811e+00)\tAcc@1   1.56 (  9.08)\tAcc@5   9.38 ( 18.18)\n",
            "Epoch: [1][ 790/1075]\tTime  0.507 ( 0.658)\tData  0.000 ( 0.287)\tLoss 5.9392e+00 (6.5753e+00)\tAcc@1   3.12 (  9.04)\tAcc@5  12.50 ( 18.14)\n",
            "Epoch: [1][ 800/1075]\tTime  0.511 ( 0.657)\tData  0.000 ( 0.286)\tLoss 5.9480e+00 (6.5666e+00)\tAcc@1  15.62 (  9.05)\tAcc@5  23.44 ( 18.18)\n",
            "Epoch: [1][ 810/1075]\tTime  0.511 ( 0.657)\tData  0.000 ( 0.286)\tLoss 6.5882e+00 (6.5622e+00)\tAcc@1   0.00 (  9.06)\tAcc@5   4.69 ( 18.18)\n",
            "Epoch: [1][ 820/1075]\tTime  0.494 ( 0.657)\tData  0.000 ( 0.285)\tLoss 6.6245e+00 (6.5613e+00)\tAcc@1   9.38 (  9.11)\tAcc@5  20.31 ( 18.23)\n",
            "Epoch: [1][ 830/1075]\tTime  0.508 ( 0.658)\tData  0.000 ( 0.285)\tLoss 6.7485e+00 (6.5627e+00)\tAcc@1  21.88 (  9.11)\tAcc@5  26.56 ( 18.18)\n",
            "Epoch: [1][ 840/1075]\tTime  0.508 ( 0.657)\tData  0.000 ( 0.285)\tLoss 6.7481e+00 (6.5637e+00)\tAcc@1  14.06 (  9.24)\tAcc@5  20.31 ( 18.32)\n",
            "Epoch: [1][ 850/1075]\tTime  0.491 ( 0.658)\tData  0.000 ( 0.285)\tLoss 7.1510e+00 (6.5677e+00)\tAcc@1  12.50 (  9.31)\tAcc@5  21.88 ( 18.36)\n",
            "Epoch: [1][ 860/1075]\tTime  0.507 ( 0.657)\tData  0.000 ( 0.284)\tLoss 7.5465e+00 (6.5758e+00)\tAcc@1   7.81 (  9.28)\tAcc@5  10.94 ( 18.30)\n",
            "Epoch: [1][ 870/1075]\tTime  0.503 ( 0.658)\tData  0.000 ( 0.284)\tLoss 7.5764e+00 (6.5869e+00)\tAcc@1   9.38 (  9.28)\tAcc@5  12.50 ( 18.26)\n",
            "Epoch: [1][ 880/1075]\tTime  0.510 ( 0.657)\tData  0.000 ( 0.283)\tLoss 7.8054e+00 (6.5997e+00)\tAcc@1  14.06 (  9.29)\tAcc@5  23.44 ( 18.24)\n",
            "Epoch: [1][ 890/1075]\tTime  0.501 ( 0.657)\tData  0.000 ( 0.282)\tLoss 7.7056e+00 (6.6123e+00)\tAcc@1  12.50 (  9.33)\tAcc@5  18.75 ( 18.25)\n",
            "Epoch: [1][ 900/1075]\tTime  0.508 ( 0.656)\tData  0.000 ( 0.282)\tLoss 7.4775e+00 (6.6228e+00)\tAcc@1  23.44 (  9.42)\tAcc@5  26.56 ( 18.33)\n",
            "Epoch: [1][ 910/1075]\tTime  0.510 ( 0.656)\tData  0.000 ( 0.281)\tLoss 5.7363e+00 (6.6222e+00)\tAcc@1  18.75 (  9.50)\tAcc@5  28.12 ( 18.46)\n",
            "Epoch: [1][ 920/1075]\tTime  0.491 ( 0.656)\tData  0.000 ( 0.281)\tLoss 5.7129e+00 (6.6120e+00)\tAcc@1   6.25 (  9.52)\tAcc@5  18.75 ( 18.56)\n",
            "Epoch: [1][ 930/1075]\tTime  0.495 ( 0.656)\tData  0.002 ( 0.280)\tLoss 6.4194e+00 (6.6065e+00)\tAcc@1  34.38 (  9.60)\tAcc@5  46.88 ( 18.68)\n",
            "Epoch: [1][ 940/1075]\tTime  0.512 ( 0.656)\tData  0.000 ( 0.281)\tLoss 6.6761e+00 (6.6057e+00)\tAcc@1  17.19 (  9.63)\tAcc@5  23.44 ( 18.76)\n",
            "Epoch: [1][ 950/1075]\tTime  0.487 ( 0.656)\tData  0.000 ( 0.280)\tLoss 6.3187e+00 (6.6039e+00)\tAcc@1   1.56 (  9.60)\tAcc@5   6.25 ( 18.74)\n",
            "Epoch: [1][ 960/1075]\tTime  0.505 ( 0.656)\tData  0.000 ( 0.280)\tLoss 6.5301e+00 (6.6022e+00)\tAcc@1   4.69 (  9.53)\tAcc@5  12.50 ( 18.63)\n",
            "Epoch: [1][ 970/1075]\tTime  0.517 ( 0.656)\tData  0.000 ( 0.280)\tLoss 6.4990e+00 (6.5992e+00)\tAcc@1   1.56 (  9.48)\tAcc@5   6.25 ( 18.57)\n",
            "Epoch: [1][ 980/1075]\tTime  0.510 ( 0.657)\tData  0.000 ( 0.280)\tLoss 6.9397e+00 (6.6002e+00)\tAcc@1   1.56 (  9.42)\tAcc@5   7.81 ( 18.50)\n",
            "Epoch: [1][ 990/1075]\tTime  0.494 ( 0.657)\tData  0.000 ( 0.280)\tLoss 6.5842e+00 (6.6019e+00)\tAcc@1  10.94 (  9.37)\tAcc@5  26.56 ( 18.44)\n",
            "Epoch: [1][1000/1075]\tTime  0.510 ( 0.657)\tData  0.000 ( 0.280)\tLoss 5.9165e+00 (6.5968e+00)\tAcc@1   7.81 (  9.40)\tAcc@5  21.88 ( 18.52)\n",
            "Epoch: [1][1010/1075]\tTime  0.493 ( 0.657)\tData  0.000 ( 0.279)\tLoss 6.3463e+00 (6.5926e+00)\tAcc@1   3.12 (  9.38)\tAcc@5  15.62 ( 18.48)\n",
            "Epoch: [1][1020/1075]\tTime  0.512 ( 0.657)\tData  0.000 ( 0.279)\tLoss 6.3903e+00 (6.5898e+00)\tAcc@1   1.56 (  9.35)\tAcc@5  14.06 ( 18.47)\n",
            "Epoch: [1][1030/1075]\tTime  0.499 ( 0.656)\tData  0.000 ( 0.278)\tLoss 6.3305e+00 (6.5876e+00)\tAcc@1   6.25 (  9.34)\tAcc@5  14.06 ( 18.43)\n",
            "Epoch: [1][1040/1075]\tTime  0.505 ( 0.657)\tData  0.000 ( 0.279)\tLoss 6.4101e+00 (6.5857e+00)\tAcc@1  10.94 (  9.30)\tAcc@5  18.75 ( 18.38)\n",
            "Epoch: [1][1050/1075]\tTime  0.509 ( 0.657)\tData  0.000 ( 0.278)\tLoss 6.1948e+00 (6.5838e+00)\tAcc@1   7.81 (  9.28)\tAcc@5  23.44 ( 18.35)\n",
            "Epoch: [1][1060/1075]\tTime  0.492 ( 0.657)\tData  0.000 ( 0.279)\tLoss 5.7359e+00 (6.5776e+00)\tAcc@1  17.19 (  9.36)\tAcc@5  32.81 ( 18.42)\n",
            "Epoch: [1][1070/1075]\tTime  0.491 ( 0.657)\tData  0.000 ( 0.278)\tLoss 5.8503e+00 (6.5706e+00)\tAcc@1  14.06 (  9.38)\tAcc@5  29.69 ( 18.43)\n",
            "epoch: 1\n",
            "2023-04-19 12:10:37.951589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 12:10:42.783066: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [2][   0/1075]\tTime 11.286 (11.286)\tData 10.976 (10.976)\tLoss 5.9525e+00 (5.9525e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  29.69 ( 29.69)\n",
            "Epoch: [2][  10/1075]\tTime  0.895 ( 1.686)\tData  0.600 ( 1.309)\tLoss 6.1543e+00 (6.0271e+00)\tAcc@1   7.81 ( 16.62)\tAcc@5  25.00 ( 32.67)\n",
            "Epoch: [2][  20/1075]\tTime  0.738 ( 1.186)\tData  0.443 ( 0.809)\tLoss 6.0538e+00 (6.0787e+00)\tAcc@1  12.50 ( 16.07)\tAcc@5  28.12 ( 30.95)\n",
            "Epoch: [2][  30/1075]\tTime  0.791 ( 1.018)\tData  0.480 ( 0.646)\tLoss 5.9259e+00 (6.0428e+00)\tAcc@1  32.81 ( 18.75)\tAcc@5  42.19 ( 33.42)\n",
            "Epoch: [2][  40/1075]\tTime  0.515 ( 0.914)\tData  0.000 ( 0.552)\tLoss 6.1832e+00 (6.0202e+00)\tAcc@1   4.69 ( 20.58)\tAcc@5  25.00 ( 34.76)\n",
            "Epoch: [2][  50/1075]\tTime  0.614 ( 0.869)\tData  0.305 ( 0.516)\tLoss 5.9384e+00 (6.0411e+00)\tAcc@1   7.81 ( 19.94)\tAcc@5  20.31 ( 33.39)\n",
            "Epoch: [2][  60/1075]\tTime  0.497 ( 0.833)\tData  0.000 ( 0.471)\tLoss 6.2966e+00 (6.0428e+00)\tAcc@1   9.38 ( 18.39)\tAcc@5  15.62 ( 31.15)\n",
            "Epoch: [2][  70/1075]\tTime  0.586 ( 0.809)\tData  0.286 ( 0.449)\tLoss 6.2090e+00 (6.0762e+00)\tAcc@1  10.94 ( 16.97)\tAcc@5  21.88 ( 29.71)\n",
            "Epoch: [2][  80/1075]\tTime  0.497 ( 0.790)\tData  0.000 ( 0.427)\tLoss 6.3243e+00 (6.0926e+00)\tAcc@1  12.50 ( 16.22)\tAcc@5  26.56 ( 29.36)\n",
            "Epoch: [2][  90/1075]\tTime  1.122 ( 0.781)\tData  0.821 ( 0.420)\tLoss 6.7913e+00 (6.1501e+00)\tAcc@1  14.06 ( 15.26)\tAcc@5  23.44 ( 28.18)\n",
            "Epoch: [2][ 100/1075]\tTime  0.679 ( 0.766)\tData  0.368 ( 0.405)\tLoss 6.9713e+00 (6.2254e+00)\tAcc@1   6.25 ( 14.70)\tAcc@5  18.75 ( 27.20)\n",
            "Epoch: [2][ 110/1075]\tTime  1.181 ( 0.761)\tData  0.868 ( 0.403)\tLoss 7.0937e+00 (6.2986e+00)\tAcc@1  14.06 ( 14.47)\tAcc@5  26.56 ( 26.70)\n",
            "Epoch: [2][ 120/1075]\tTime  0.816 ( 0.751)\tData  0.521 ( 0.394)\tLoss 7.0933e+00 (6.3630e+00)\tAcc@1  14.06 ( 14.37)\tAcc@5  20.31 ( 26.18)\n",
            "Epoch: [2][ 130/1075]\tTime  0.835 ( 0.743)\tData  0.521 ( 0.390)\tLoss 7.0414e+00 (6.4122e+00)\tAcc@1  10.94 ( 13.82)\tAcc@5  18.75 ( 25.41)\n",
            "Epoch: [2][ 140/1075]\tTime  0.729 ( 0.737)\tData  0.432 ( 0.386)\tLoss 7.0552e+00 (6.4588e+00)\tAcc@1   7.81 ( 13.40)\tAcc@5   7.81 ( 24.59)\n",
            "Epoch: [2][ 150/1075]\tTime  0.879 ( 0.731)\tData  0.582 ( 0.379)\tLoss 6.9072e+00 (6.4932e+00)\tAcc@1   6.25 ( 12.99)\tAcc@5  10.94 ( 23.91)\n",
            "Epoch: [2][ 160/1075]\tTime  0.783 ( 0.729)\tData  0.474 ( 0.375)\tLoss 6.6978e+00 (6.5208e+00)\tAcc@1   7.81 ( 12.57)\tAcc@5  12.50 ( 23.21)\n",
            "Epoch: [2][ 170/1075]\tTime  0.940 ( 0.724)\tData  0.636 ( 0.369)\tLoss 5.6748e+00 (6.5100e+00)\tAcc@1   9.38 ( 12.41)\tAcc@5  20.31 ( 23.04)\n",
            "Epoch: [2][ 180/1075]\tTime  0.786 ( 0.722)\tData  0.477 ( 0.366)\tLoss 5.8066e+00 (6.4482e+00)\tAcc@1   6.25 ( 12.23)\tAcc@5  15.62 ( 23.01)\n",
            "Epoch: [2][ 190/1075]\tTime  0.776 ( 0.718)\tData  0.456 ( 0.360)\tLoss 5.4959e+00 (6.3990e+00)\tAcc@1  28.12 ( 12.40)\tAcc@5  42.19 ( 23.27)\n",
            "Epoch: [2][ 200/1075]\tTime  0.762 ( 0.715)\tData  0.468 ( 0.356)\tLoss 5.8532e+00 (6.3660e+00)\tAcc@1  10.94 ( 12.83)\tAcc@5  28.12 ( 23.71)\n",
            "Epoch: [2][ 210/1075]\tTime  0.648 ( 0.709)\tData  0.354 ( 0.349)\tLoss 6.3054e+00 (6.3564e+00)\tAcc@1  10.94 ( 12.83)\tAcc@5  18.75 ( 23.50)\n",
            "Epoch: [2][ 220/1075]\tTime  0.664 ( 0.708)\tData  0.354 ( 0.349)\tLoss 6.5167e+00 (6.3635e+00)\tAcc@1   9.38 ( 12.68)\tAcc@5  14.06 ( 23.26)\n",
            "Epoch: [2][ 230/1075]\tTime  0.526 ( 0.703)\tData  0.233 ( 0.346)\tLoss 6.4336e+00 (6.3692e+00)\tAcc@1  18.75 ( 12.65)\tAcc@5  25.00 ( 23.12)\n",
            "Epoch: [2][ 240/1075]\tTime  0.617 ( 0.703)\tData  0.319 ( 0.348)\tLoss 6.8932e+00 (6.3781e+00)\tAcc@1  28.12 ( 12.62)\tAcc@5  37.50 ( 23.11)\n",
            "Epoch: [2][ 250/1075]\tTime  0.666 ( 0.700)\tData  0.370 ( 0.346)\tLoss 7.0112e+00 (6.3957e+00)\tAcc@1  21.88 ( 12.64)\tAcc@5  28.12 ( 23.23)\n",
            "Epoch: [2][ 260/1075]\tTime  0.895 ( 0.699)\tData  0.585 ( 0.347)\tLoss 7.5928e+00 (6.4269e+00)\tAcc@1   9.38 ( 12.60)\tAcc@5  21.88 ( 23.17)\n",
            "Epoch: [2][ 270/1075]\tTime  0.730 ( 0.696)\tData  0.437 ( 0.344)\tLoss 7.5048e+00 (6.4598e+00)\tAcc@1  12.50 ( 12.42)\tAcc@5  18.75 ( 22.90)\n",
            "Epoch: [2][ 280/1075]\tTime  0.973 ( 0.698)\tData  0.662 ( 0.344)\tLoss 7.1833e+00 (6.4871e+00)\tAcc@1  12.50 ( 12.41)\tAcc@5  15.62 ( 22.79)\n",
            "Epoch: [2][ 290/1075]\tTime  0.692 ( 0.695)\tData  0.394 ( 0.341)\tLoss 5.9548e+00 (6.4898e+00)\tAcc@1  18.75 ( 12.58)\tAcc@5  31.25 ( 23.01)\n",
            "Epoch: [2][ 300/1075]\tTime  1.028 ( 0.695)\tData  0.710 ( 0.340)\tLoss 5.7115e+00 (6.4602e+00)\tAcc@1  12.50 ( 12.84)\tAcc@5  23.44 ( 23.30)\n",
            "Epoch: [2][ 310/1075]\tTime  0.891 ( 0.693)\tData  0.594 ( 0.337)\tLoss 6.2399e+00 (6.4479e+00)\tAcc@1   9.38 ( 12.62)\tAcc@5  25.00 ( 23.00)\n",
            "Epoch: [2][ 320/1075]\tTime  0.988 ( 0.693)\tData  0.664 ( 0.336)\tLoss 6.6854e+00 (6.4509e+00)\tAcc@1   7.81 ( 12.48)\tAcc@5  20.31 ( 22.81)\n",
            "Epoch: [2][ 330/1075]\tTime  0.679 ( 0.691)\tData  0.387 ( 0.333)\tLoss 6.8087e+00 (6.4615e+00)\tAcc@1   1.56 ( 12.25)\tAcc@5   6.25 ( 22.45)\n",
            "Epoch: [2][ 340/1075]\tTime  0.923 ( 0.690)\tData  0.624 ( 0.332)\tLoss 6.7160e+00 (6.4700e+00)\tAcc@1  10.94 ( 12.10)\tAcc@5  17.19 ( 22.16)\n",
            "Epoch: [2][ 350/1075]\tTime  0.817 ( 0.690)\tData  0.519 ( 0.332)\tLoss 6.9338e+00 (6.4794e+00)\tAcc@1   3.12 ( 11.92)\tAcc@5   9.38 ( 21.91)\n",
            "Epoch: [2][ 360/1075]\tTime  1.066 ( 0.689)\tData  0.771 ( 0.330)\tLoss 7.1610e+00 (6.4935e+00)\tAcc@1   4.69 ( 11.76)\tAcc@5  10.94 ( 21.64)\n",
            "Epoch: [2][ 370/1075]\tTime  0.718 ( 0.690)\tData  0.423 ( 0.330)\tLoss 6.9668e+00 (6.5101e+00)\tAcc@1   9.38 ( 11.71)\tAcc@5  23.44 ( 21.53)\n",
            "Epoch: [2][ 380/1075]\tTime  1.181 ( 0.689)\tData  0.886 ( 0.329)\tLoss 7.0161e+00 (6.5240e+00)\tAcc@1  15.62 ( 11.85)\tAcc@5  28.12 ( 21.65)\n",
            "Epoch: [2][ 390/1075]\tTime  0.838 ( 0.688)\tData  0.543 ( 0.327)\tLoss 6.3330e+00 (6.5253e+00)\tAcc@1  18.75 ( 12.12)\tAcc@5  34.38 ( 21.93)\n",
            "Epoch: [2][ 400/1075]\tTime  1.000 ( 0.687)\tData  0.697 ( 0.326)\tLoss 6.3738e+00 (6.5196e+00)\tAcc@1   3.12 ( 12.27)\tAcc@5  15.62 ( 22.09)\n",
            "Epoch: [2][ 410/1075]\tTime  0.813 ( 0.687)\tData  0.514 ( 0.326)\tLoss 6.4876e+00 (6.5203e+00)\tAcc@1  14.06 ( 12.23)\tAcc@5  21.88 ( 22.04)\n",
            "Epoch: [2][ 420/1075]\tTime  0.935 ( 0.686)\tData  0.630 ( 0.324)\tLoss 6.4673e+00 (6.5201e+00)\tAcc@1   1.56 ( 12.13)\tAcc@5  12.50 ( 21.90)\n",
            "Epoch: [2][ 430/1075]\tTime  0.717 ( 0.686)\tData  0.409 ( 0.324)\tLoss 6.2288e+00 (6.5152e+00)\tAcc@1   7.81 ( 12.04)\tAcc@5  18.75 ( 21.84)\n",
            "Epoch: [2][ 440/1075]\tTime  0.698 ( 0.685)\tData  0.395 ( 0.322)\tLoss 6.3831e+00 (6.5112e+00)\tAcc@1   6.25 ( 11.95)\tAcc@5  20.31 ( 21.83)\n",
            "Epoch: [2][ 450/1075]\tTime  0.544 ( 0.685)\tData  0.247 ( 0.321)\tLoss 5.8935e+00 (6.5050e+00)\tAcc@1   7.81 ( 11.92)\tAcc@5  20.31 ( 21.86)\n",
            "Epoch: [2][ 460/1075]\tTime  0.814 ( 0.683)\tData  0.503 ( 0.320)\tLoss 6.4117e+00 (6.4966e+00)\tAcc@1   7.81 ( 11.84)\tAcc@5  20.31 ( 21.77)\n",
            "Epoch: [2][ 470/1075]\tTime  0.822 ( 0.684)\tData  0.512 ( 0.320)\tLoss 6.5289e+00 (6.4947e+00)\tAcc@1   3.12 ( 11.70)\tAcc@5   6.25 ( 21.60)\n",
            "Epoch: [2][ 480/1075]\tTime  0.639 ( 0.682)\tData  0.329 ( 0.318)\tLoss 6.6248e+00 (6.4948e+00)\tAcc@1   1.56 ( 11.55)\tAcc@5   4.69 ( 21.36)\n",
            "Epoch: [2][ 490/1075]\tTime  0.701 ( 0.683)\tData  0.407 ( 0.318)\tLoss 6.7557e+00 (6.4978e+00)\tAcc@1   6.25 ( 11.41)\tAcc@5  10.94 ( 21.13)\n",
            "Epoch: [2][ 500/1075]\tTime  0.859 ( 0.682)\tData  0.564 ( 0.317)\tLoss 6.2513e+00 (6.4997e+00)\tAcc@1   6.25 ( 11.32)\tAcc@5  14.06 ( 20.97)\n",
            "Epoch: [2][ 510/1075]\tTime  0.953 ( 0.682)\tData  0.657 ( 0.316)\tLoss 5.8357e+00 (6.4912e+00)\tAcc@1   6.25 ( 11.26)\tAcc@5  17.19 ( 20.96)\n",
            "Epoch: [2][ 520/1075]\tTime  0.904 ( 0.682)\tData  0.595 ( 0.316)\tLoss 6.1709e+00 (6.4843e+00)\tAcc@1   4.69 ( 11.17)\tAcc@5  14.06 ( 20.87)\n",
            "Epoch: [2][ 530/1075]\tTime  0.896 ( 0.682)\tData  0.584 ( 0.316)\tLoss 6.4144e+00 (6.4805e+00)\tAcc@1   6.25 ( 11.11)\tAcc@5  17.19 ( 20.82)\n",
            "Epoch: [2][ 540/1075]\tTime  0.843 ( 0.681)\tData  0.547 ( 0.314)\tLoss 6.1476e+00 (6.4802e+00)\tAcc@1   7.81 ( 11.05)\tAcc@5  20.31 ( 20.79)\n",
            "Epoch: [2][ 550/1075]\tTime  1.085 ( 0.681)\tData  0.777 ( 0.314)\tLoss 6.2170e+00 (6.4761e+00)\tAcc@1   9.38 ( 11.00)\tAcc@5  17.19 ( 20.72)\n",
            "Epoch: [2][ 560/1075]\tTime  0.744 ( 0.680)\tData  0.445 ( 0.313)\tLoss 6.6311e+00 (6.4770e+00)\tAcc@1   6.25 ( 10.90)\tAcc@5  10.94 ( 20.59)\n",
            "Epoch: [2][ 570/1075]\tTime  0.884 ( 0.680)\tData  0.586 ( 0.313)\tLoss 6.6053e+00 (6.4798e+00)\tAcc@1   0.00 ( 10.81)\tAcc@5   7.81 ( 20.48)\n",
            "Epoch: [2][ 580/1075]\tTime  0.728 ( 0.680)\tData  0.417 ( 0.312)\tLoss 6.2675e+00 (6.4803e+00)\tAcc@1  10.94 ( 10.78)\tAcc@5  18.75 ( 20.42)\n",
            "Epoch: [2][ 590/1075]\tTime  1.186 ( 0.680)\tData  0.891 ( 0.312)\tLoss 5.0253e+00 (6.4694e+00)\tAcc@1  32.81 ( 10.95)\tAcc@5  50.00 ( 20.57)\n",
            "Epoch: [2][ 600/1075]\tTime  0.697 ( 0.679)\tData  0.403 ( 0.311)\tLoss 5.9998e+00 (6.4528e+00)\tAcc@1  10.94 ( 11.12)\tAcc@5  17.19 ( 20.81)\n",
            "Epoch: [2][ 610/1075]\tTime  0.823 ( 0.679)\tData  0.530 ( 0.311)\tLoss 6.0307e+00 (6.4473e+00)\tAcc@1  17.19 ( 11.17)\tAcc@5  21.88 ( 20.85)\n",
            "Epoch: [2][ 620/1075]\tTime  0.783 ( 0.679)\tData  0.490 ( 0.310)\tLoss 5.5289e+00 (6.4342e+00)\tAcc@1  18.75 ( 11.28)\tAcc@5  32.81 ( 20.93)\n",
            "Epoch: [2][ 630/1075]\tTime  0.806 ( 0.678)\tData  0.498 ( 0.310)\tLoss 5.6044e+00 (6.4195e+00)\tAcc@1   6.25 ( 11.39)\tAcc@5  18.75 ( 21.09)\n",
            "Epoch: [2][ 640/1075]\tTime  0.608 ( 0.678)\tData  0.300 ( 0.309)\tLoss 6.1431e+00 (6.4127e+00)\tAcc@1  21.88 ( 11.39)\tAcc@5  34.38 ( 21.13)\n",
            "Epoch: [2][ 650/1075]\tTime  0.748 ( 0.676)\tData  0.446 ( 0.308)\tLoss 6.3058e+00 (6.4103e+00)\tAcc@1   6.25 ( 11.38)\tAcc@5  17.19 ( 21.12)\n",
            "Epoch: [2][ 660/1075]\tTime  0.646 ( 0.677)\tData  0.346 ( 0.308)\tLoss 6.8008e+00 (6.4115e+00)\tAcc@1   4.69 ( 11.33)\tAcc@5  14.06 ( 21.05)\n",
            "Epoch: [2][ 670/1075]\tTime  0.701 ( 0.676)\tData  0.409 ( 0.307)\tLoss 6.2396e+00 (6.4076e+00)\tAcc@1  18.75 ( 11.56)\tAcc@5  23.44 ( 21.24)\n",
            "Epoch: [2][ 680/1075]\tTime  0.642 ( 0.676)\tData  0.334 ( 0.307)\tLoss 6.5454e+00 (6.4082e+00)\tAcc@1   6.25 ( 11.48)\tAcc@5  25.00 ( 21.19)\n",
            "Epoch: [2][ 690/1075]\tTime  0.615 ( 0.675)\tData  0.321 ( 0.306)\tLoss 6.4815e+00 (6.4070e+00)\tAcc@1   4.69 ( 11.42)\tAcc@5  14.06 ( 21.18)\n",
            "Epoch: [2][ 700/1075]\tTime  0.849 ( 0.675)\tData  0.556 ( 0.307)\tLoss 6.2790e+00 (6.4071e+00)\tAcc@1  12.50 ( 11.43)\tAcc@5  18.75 ( 21.20)\n",
            "Epoch: [2][ 710/1075]\tTime  0.842 ( 0.675)\tData  0.547 ( 0.306)\tLoss 6.0511e+00 (6.4045e+00)\tAcc@1  10.94 ( 11.42)\tAcc@5  29.69 ( 21.21)\n",
            "Epoch: [2][ 720/1075]\tTime  1.078 ( 0.675)\tData  0.784 ( 0.307)\tLoss 6.0809e+00 (6.3997e+00)\tAcc@1   6.25 ( 11.36)\tAcc@5  14.06 ( 21.16)\n",
            "Epoch: [2][ 730/1075]\tTime  0.687 ( 0.674)\tData  0.377 ( 0.306)\tLoss 6.3394e+00 (6.3958e+00)\tAcc@1   6.25 ( 11.31)\tAcc@5  20.31 ( 21.10)\n",
            "Epoch: [2][ 740/1075]\tTime  0.848 ( 0.673)\tData  0.551 ( 0.307)\tLoss 5.7242e+00 (6.3875e+00)\tAcc@1  12.50 ( 11.31)\tAcc@5  23.44 ( 21.15)\n",
            "Epoch: [2][ 750/1075]\tTime  0.762 ( 0.673)\tData  0.452 ( 0.306)\tLoss 6.0555e+00 (6.3800e+00)\tAcc@1  14.06 ( 11.34)\tAcc@5  26.56 ( 21.23)\n",
            "Epoch: [2][ 760/1075]\tTime  1.120 ( 0.673)\tData  0.811 ( 0.306)\tLoss 6.1895e+00 (6.3757e+00)\tAcc@1   7.81 ( 11.35)\tAcc@5  26.56 ( 21.27)\n",
            "Epoch: [2][ 770/1075]\tTime  0.802 ( 0.673)\tData  0.509 ( 0.306)\tLoss 6.2175e+00 (6.3736e+00)\tAcc@1   9.38 ( 11.34)\tAcc@5  18.75 ( 21.27)\n",
            "Epoch: [2][ 780/1075]\tTime  1.154 ( 0.673)\tData  0.856 ( 0.306)\tLoss 5.8632e+00 (6.3703e+00)\tAcc@1   9.38 ( 11.30)\tAcc@5  31.25 ( 21.29)\n",
            "Epoch: [2][ 790/1075]\tTime  0.586 ( 0.673)\tData  0.278 ( 0.305)\tLoss 5.9365e+00 (6.3624e+00)\tAcc@1   7.81 ( 11.27)\tAcc@5  17.19 ( 21.27)\n",
            "Epoch: [2][ 800/1075]\tTime  1.030 ( 0.672)\tData  0.720 ( 0.305)\tLoss 6.0045e+00 (6.3573e+00)\tAcc@1   3.12 ( 11.21)\tAcc@5  10.94 ( 21.20)\n",
            "Epoch: [2][ 810/1075]\tTime  0.862 ( 0.672)\tData  0.553 ( 0.305)\tLoss 5.9301e+00 (6.3532e+00)\tAcc@1   6.25 ( 11.13)\tAcc@5  26.56 ( 21.10)\n",
            "Epoch: [2][ 820/1075]\tTime  1.063 ( 0.672)\tData  0.750 ( 0.305)\tLoss 6.1426e+00 (6.3493e+00)\tAcc@1   4.69 ( 11.04)\tAcc@5  15.62 ( 21.03)\n",
            "Epoch: [2][ 830/1075]\tTime  0.642 ( 0.673)\tData  0.349 ( 0.305)\tLoss 6.1844e+00 (6.3471e+00)\tAcc@1   4.69 ( 11.00)\tAcc@5  20.31 ( 21.02)\n",
            "Epoch: [2][ 840/1075]\tTime  0.637 ( 0.672)\tData  0.322 ( 0.304)\tLoss 6.6511e+00 (6.3479e+00)\tAcc@1   6.25 ( 10.96)\tAcc@5  20.31 ( 21.00)\n",
            "Epoch: [2][ 850/1075]\tTime  0.856 ( 0.673)\tData  0.559 ( 0.305)\tLoss 7.1145e+00 (6.3545e+00)\tAcc@1   4.69 ( 10.93)\tAcc@5  14.06 ( 21.00)\n",
            "Epoch: [2][ 860/1075]\tTime  0.906 ( 0.672)\tData  0.612 ( 0.304)\tLoss 6.4009e+00 (6.3579e+00)\tAcc@1   3.12 ( 10.91)\tAcc@5  17.19 ( 21.01)\n",
            "Epoch: [2][ 870/1075]\tTime  0.704 ( 0.672)\tData  0.410 ( 0.304)\tLoss 6.8010e+00 (6.3576e+00)\tAcc@1   9.38 ( 10.86)\tAcc@5  14.06 ( 20.96)\n",
            "Epoch: [2][ 880/1075]\tTime  0.712 ( 0.672)\tData  0.383 ( 0.303)\tLoss 6.7748e+00 (6.3613e+00)\tAcc@1  10.94 ( 10.85)\tAcc@5  15.62 ( 20.92)\n",
            "Epoch: [2][ 890/1075]\tTime  0.720 ( 0.672)\tData  0.411 ( 0.303)\tLoss 6.1033e+00 (6.3607e+00)\tAcc@1  12.50 ( 10.88)\tAcc@5  20.31 ( 20.94)\n",
            "Epoch: [2][ 900/1075]\tTime  0.633 ( 0.671)\tData  0.341 ( 0.303)\tLoss 5.7313e+00 (6.3563e+00)\tAcc@1   9.38 ( 10.97)\tAcc@5  26.56 ( 21.07)\n",
            "Epoch: [2][ 910/1075]\tTime  0.732 ( 0.672)\tData  0.420 ( 0.303)\tLoss 6.5462e+00 (6.3547e+00)\tAcc@1  12.50 ( 10.95)\tAcc@5  17.19 ( 21.04)\n",
            "Epoch: [2][ 920/1075]\tTime  0.640 ( 0.671)\tData  0.345 ( 0.302)\tLoss 7.2373e+00 (6.3610e+00)\tAcc@1   0.00 ( 10.88)\tAcc@5   0.00 ( 20.94)\n",
            "Epoch: [2][ 930/1075]\tTime  0.813 ( 0.671)\tData  0.502 ( 0.302)\tLoss 5.6649e+00 (6.3626e+00)\tAcc@1  14.06 ( 10.84)\tAcc@5  26.56 ( 20.90)\n",
            "Epoch: [2][ 940/1075]\tTime  0.860 ( 0.671)\tData  0.549 ( 0.302)\tLoss 5.7477e+00 (6.3587e+00)\tAcc@1  18.75 ( 10.84)\tAcc@5  29.69 ( 20.91)\n",
            "Epoch: [2][ 950/1075]\tTime  0.797 ( 0.671)\tData  0.488 ( 0.302)\tLoss 6.3756e+00 (6.3539e+00)\tAcc@1   7.81 ( 10.85)\tAcc@5  12.50 ( 20.92)\n",
            "Epoch: [2][ 960/1075]\tTime  0.778 ( 0.671)\tData  0.483 ( 0.301)\tLoss 6.0464e+00 (6.3510e+00)\tAcc@1   9.38 ( 10.83)\tAcc@5  15.62 ( 20.88)\n",
            "Epoch: [2][ 970/1075]\tTime  1.027 ( 0.671)\tData  0.732 ( 0.301)\tLoss 6.4702e+00 (6.3506e+00)\tAcc@1   9.38 ( 10.83)\tAcc@5  18.75 ( 20.86)\n",
            "Epoch: [2][ 980/1075]\tTime  0.682 ( 0.670)\tData  0.388 ( 0.301)\tLoss 6.2066e+00 (6.3507e+00)\tAcc@1   7.81 ( 10.84)\tAcc@5  17.19 ( 20.85)\n",
            "Epoch: [2][ 990/1075]\tTime  1.001 ( 0.670)\tData  0.687 ( 0.301)\tLoss 6.3556e+00 (6.3492e+00)\tAcc@1  14.06 ( 10.81)\tAcc@5  20.31 ( 20.81)\n",
            "Epoch: [2][1000/1075]\tTime  0.663 ( 0.670)\tData  0.379 ( 0.300)\tLoss 6.7227e+00 (6.3517e+00)\tAcc@1  17.19 ( 10.79)\tAcc@5  28.12 ( 20.80)\n",
            "Epoch: [2][1010/1075]\tTime  1.200 ( 0.670)\tData  0.914 ( 0.300)\tLoss 6.7512e+00 (6.3555e+00)\tAcc@1  18.75 ( 10.88)\tAcc@5  32.81 ( 20.90)\n",
            "Epoch: [2][1020/1075]\tTime  0.670 ( 0.670)\tData  0.377 ( 0.300)\tLoss 6.9805e+00 (6.3602e+00)\tAcc@1   3.12 ( 10.92)\tAcc@5  15.62 ( 20.97)\n",
            "Epoch: [2][1030/1075]\tTime  0.910 ( 0.669)\tData  0.590 ( 0.299)\tLoss 7.0129e+00 (6.3664e+00)\tAcc@1  20.31 ( 10.96)\tAcc@5  31.25 ( 21.02)\n",
            "Epoch: [2][1040/1075]\tTime  0.814 ( 0.669)\tData  0.503 ( 0.299)\tLoss 7.0130e+00 (6.3726e+00)\tAcc@1  20.31 ( 11.04)\tAcc@5  32.81 ( 21.13)\n",
            "Epoch: [2][1050/1075]\tTime  0.823 ( 0.669)\tData  0.515 ( 0.298)\tLoss 6.6621e+00 (6.3764e+00)\tAcc@1  20.31 ( 11.17)\tAcc@5  35.94 ( 21.29)\n",
            "Epoch: [2][1060/1075]\tTime  0.745 ( 0.669)\tData  0.449 ( 0.298)\tLoss 6.5718e+00 (6.3786e+00)\tAcc@1  23.44 ( 11.26)\tAcc@5  32.81 ( 21.38)\n",
            "Epoch: [2][1070/1075]\tTime  0.619 ( 0.669)\tData  0.318 ( 0.298)\tLoss 6.8044e+00 (6.3815e+00)\tAcc@1   7.81 ( 11.34)\tAcc@5  23.44 ( 21.45)\n",
            "epoch: 2\n",
            "2023-04-19 12:22:37.891102: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 12:22:42.730720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [3][   0/1075]\tTime 11.824 (11.824)\tData 11.500 (11.500)\tLoss 6.8302e+00 (6.8302e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   4.69 (  4.69)\n",
            "Epoch: [3][  10/1075]\tTime  0.658 ( 1.592)\tData  0.363 ( 1.223)\tLoss 7.1529e+00 (6.9675e+00)\tAcc@1  17.19 ( 13.35)\tAcc@5  29.69 ( 22.30)\n",
            "Epoch: [3][  20/1075]\tTime  0.918 ( 1.132)\tData  0.593 ( 0.756)\tLoss 6.8278e+00 (6.9550e+00)\tAcc@1  17.19 ( 12.57)\tAcc@5  25.00 ( 20.83)\n",
            "Epoch: [3][  30/1075]\tTime  0.793 ( 0.975)\tData  0.498 ( 0.598)\tLoss 6.2831e+00 (6.8442e+00)\tAcc@1  25.00 ( 14.47)\tAcc@5  39.06 ( 22.88)\n",
            "Epoch: [3][  40/1075]\tTime  0.657 ( 0.877)\tData  0.348 ( 0.506)\tLoss 5.2672e+00 (6.5273e+00)\tAcc@1  32.81 ( 17.57)\tAcc@5  40.62 ( 26.98)\n",
            "Epoch: [3][  50/1075]\tTime  0.494 ( 0.839)\tData  0.000 ( 0.472)\tLoss 5.6389e+00 (6.3057e+00)\tAcc@1  12.50 ( 17.89)\tAcc@5  25.00 ( 27.73)\n",
            "Epoch: [3][  60/1075]\tTime  0.507 ( 0.796)\tData  0.039 ( 0.427)\tLoss 6.2425e+00 (6.2623e+00)\tAcc@1   1.56 ( 16.85)\tAcc@5   7.81 ( 26.87)\n",
            "Epoch: [3][  70/1075]\tTime  0.494 ( 0.783)\tData  0.000 ( 0.410)\tLoss 5.9203e+00 (6.2395e+00)\tAcc@1  17.19 ( 16.62)\tAcc@5  29.69 ( 26.85)\n",
            "Epoch: [3][  80/1075]\tTime  0.501 ( 0.760)\tData  0.000 ( 0.384)\tLoss 6.1993e+00 (6.2130e+00)\tAcc@1  17.19 ( 16.18)\tAcc@5  34.38 ( 26.64)\n",
            "Epoch: [3][  90/1075]\tTime  0.493 ( 0.751)\tData  0.000 ( 0.373)\tLoss 6.4716e+00 (6.2321e+00)\tAcc@1  14.06 ( 15.76)\tAcc@5  25.00 ( 26.06)\n",
            "Epoch: [3][ 100/1075]\tTime  0.655 ( 0.733)\tData  0.359 ( 0.358)\tLoss 6.5894e+00 (6.2563e+00)\tAcc@1   9.38 ( 15.32)\tAcc@5  20.31 ( 25.85)\n",
            "Epoch: [3][ 110/1075]\tTime  0.862 ( 0.724)\tData  0.569 ( 0.350)\tLoss 6.6522e+00 (6.2811e+00)\tAcc@1  12.50 ( 15.16)\tAcc@5  21.88 ( 25.83)\n",
            "Epoch: [3][ 120/1075]\tTime  0.604 ( 0.713)\tData  0.313 ( 0.345)\tLoss 6.3876e+00 (6.2994e+00)\tAcc@1   7.81 ( 14.73)\tAcc@5  14.06 ( 25.39)\n",
            "Epoch: [3][ 130/1075]\tTime  0.973 ( 0.706)\tData  0.659 ( 0.339)\tLoss 6.4646e+00 (6.3103e+00)\tAcc@1   9.38 ( 14.31)\tAcc@5  21.88 ( 24.96)\n",
            "Epoch: [3][ 140/1075]\tTime  0.513 ( 0.698)\tData  0.219 ( 0.335)\tLoss 6.5916e+00 (6.3242e+00)\tAcc@1   6.25 ( 13.84)\tAcc@5  18.75 ( 24.40)\n",
            "Epoch: [3][ 150/1075]\tTime  0.685 ( 0.691)\tData  0.370 ( 0.331)\tLoss 6.3433e+00 (6.3323e+00)\tAcc@1  20.31 ( 13.82)\tAcc@5  32.81 ( 24.39)\n",
            "Epoch: [3][ 160/1075]\tTime  0.493 ( 0.688)\tData  0.078 ( 0.329)\tLoss 5.7341e+00 (6.3133e+00)\tAcc@1   7.81 ( 13.84)\tAcc@5  25.00 ( 24.73)\n",
            "Epoch: [3][ 170/1075]\tTime  0.729 ( 0.684)\tData  0.437 ( 0.324)\tLoss 5.9102e+00 (6.2953e+00)\tAcc@1  17.19 ( 13.81)\tAcc@5  37.50 ( 25.09)\n",
            "Epoch: [3][ 180/1075]\tTime  0.596 ( 0.684)\tData  0.301 ( 0.323)\tLoss 5.9428e+00 (6.2749e+00)\tAcc@1   9.38 ( 13.41)\tAcc@5  21.88 ( 24.65)\n",
            "Epoch: [3][ 190/1075]\tTime  0.549 ( 0.678)\tData  0.255 ( 0.317)\tLoss 6.4452e+00 (6.2768e+00)\tAcc@1   6.25 ( 13.06)\tAcc@5  14.06 ( 24.27)\n",
            "Epoch: [3][ 200/1075]\tTime  0.629 ( 0.678)\tData  0.320 ( 0.315)\tLoss 6.6583e+00 (6.2923e+00)\tAcc@1   6.25 ( 12.82)\tAcc@5  14.06 ( 24.00)\n",
            "Epoch: [3][ 210/1075]\tTime  0.753 ( 0.675)\tData  0.460 ( 0.311)\tLoss 6.4389e+00 (6.3045e+00)\tAcc@1  14.06 ( 12.68)\tAcc@5  23.44 ( 23.88)\n",
            "Epoch: [3][ 220/1075]\tTime  1.132 ( 0.672)\tData  0.824 ( 0.308)\tLoss 6.3163e+00 (6.3053e+00)\tAcc@1   7.81 ( 12.56)\tAcc@5  21.88 ( 23.77)\n",
            "Epoch: [3][ 230/1075]\tTime  0.525 ( 0.667)\tData  0.227 ( 0.306)\tLoss 6.2579e+00 (6.3008e+00)\tAcc@1   4.69 ( 12.37)\tAcc@5  14.06 ( 23.49)\n",
            "Epoch: [3][ 240/1075]\tTime  0.495 ( 0.664)\tData  0.108 ( 0.304)\tLoss 5.8091e+00 (6.2879e+00)\tAcc@1  10.94 ( 12.29)\tAcc@5  23.44 ( 23.44)\n",
            "Epoch: [3][ 250/1075]\tTime  0.557 ( 0.662)\tData  0.263 ( 0.305)\tLoss 6.3914e+00 (6.2818e+00)\tAcc@1   4.69 ( 12.10)\tAcc@5  17.19 ( 23.22)\n",
            "Epoch: [3][ 260/1075]\tTime  0.644 ( 0.659)\tData  0.349 ( 0.302)\tLoss 6.0603e+00 (6.2813e+00)\tAcc@1  17.19 ( 12.10)\tAcc@5  20.31 ( 23.04)\n",
            "Epoch: [3][ 270/1075]\tTime  0.580 ( 0.659)\tData  0.269 ( 0.301)\tLoss 6.6298e+00 (6.2785e+00)\tAcc@1  14.06 ( 12.14)\tAcc@5  23.44 ( 22.97)\n",
            "Epoch: [3][ 280/1075]\tTime  0.711 ( 0.656)\tData  0.405 ( 0.300)\tLoss 5.9459e+00 (6.2762e+00)\tAcc@1  23.44 ( 12.29)\tAcc@5  35.94 ( 23.10)\n",
            "Epoch: [3][ 290/1075]\tTime  0.804 ( 0.658)\tData  0.493 ( 0.302)\tLoss 6.4024e+00 (6.2650e+00)\tAcc@1   7.81 ( 12.33)\tAcc@5  14.06 ( 23.14)\n",
            "Epoch: [3][ 300/1075]\tTime  0.639 ( 0.654)\tData  0.345 ( 0.298)\tLoss 6.6457e+00 (6.2763e+00)\tAcc@1   9.38 ( 12.12)\tAcc@5  17.19 ( 22.85)\n",
            "Epoch: [3][ 310/1075]\tTime  0.759 ( 0.656)\tData  0.451 ( 0.299)\tLoss 6.3451e+00 (6.2798e+00)\tAcc@1   6.25 ( 12.09)\tAcc@5  15.62 ( 22.80)\n",
            "Epoch: [3][ 320/1075]\tTime  0.657 ( 0.654)\tData  0.358 ( 0.297)\tLoss 6.8717e+00 (6.2906e+00)\tAcc@1   3.12 ( 11.96)\tAcc@5  12.50 ( 22.55)\n",
            "Epoch: [3][ 330/1075]\tTime  0.915 ( 0.656)\tData  0.604 ( 0.298)\tLoss 7.1795e+00 (6.3132e+00)\tAcc@1   1.56 ( 11.76)\tAcc@5   7.81 ( 22.20)\n",
            "Epoch: [3][ 340/1075]\tTime  0.623 ( 0.653)\tData  0.315 ( 0.294)\tLoss 7.4027e+00 (6.3407e+00)\tAcc@1   1.56 ( 11.63)\tAcc@5   3.12 ( 21.92)\n",
            "Epoch: [3][ 350/1075]\tTime  0.965 ( 0.654)\tData  0.654 ( 0.294)\tLoss 7.0328e+00 (6.3637e+00)\tAcc@1   3.12 ( 11.46)\tAcc@5   9.38 ( 21.60)\n",
            "Epoch: [3][ 360/1075]\tTime  0.776 ( 0.653)\tData  0.484 ( 0.293)\tLoss 6.9858e+00 (6.3790e+00)\tAcc@1  17.19 ( 11.51)\tAcc@5  18.75 ( 21.59)\n",
            "Epoch: [3][ 370/1075]\tTime  1.102 ( 0.653)\tData  0.815 ( 0.293)\tLoss 7.1450e+00 (6.3965e+00)\tAcc@1  20.31 ( 11.83)\tAcc@5  25.00 ( 21.89)\n",
            "Epoch: [3][ 380/1075]\tTime  0.723 ( 0.653)\tData  0.431 ( 0.292)\tLoss 7.3346e+00 (6.4188e+00)\tAcc@1  18.75 ( 12.16)\tAcc@5  23.44 ( 22.38)\n",
            "Epoch: [3][ 390/1075]\tTime  0.719 ( 0.652)\tData  0.410 ( 0.290)\tLoss 7.4705e+00 (6.4444e+00)\tAcc@1  45.31 ( 12.51)\tAcc@5  56.25 ( 22.81)\n",
            "Epoch: [3][ 400/1075]\tTime  0.882 ( 0.653)\tData  0.571 ( 0.291)\tLoss 7.5092e+00 (6.4709e+00)\tAcc@1  28.12 ( 12.99)\tAcc@5  35.94 ( 23.27)\n",
            "Epoch: [3][ 410/1075]\tTime  0.612 ( 0.651)\tData  0.311 ( 0.288)\tLoss 7.4580e+00 (6.4956e+00)\tAcc@1  20.31 ( 13.35)\tAcc@5  48.44 ( 23.62)\n",
            "Epoch: [3][ 420/1075]\tTime  0.552 ( 0.651)\tData  0.258 ( 0.288)\tLoss 7.3531e+00 (6.5171e+00)\tAcc@1  21.88 ( 13.67)\tAcc@5  28.12 ( 23.92)\n",
            "Epoch: [3][ 430/1075]\tTime  0.513 ( 0.649)\tData  0.217 ( 0.288)\tLoss 7.2084e+00 (6.5346e+00)\tAcc@1   4.69 ( 13.94)\tAcc@5   6.25 ( 24.14)\n",
            "Epoch: [3][ 440/1075]\tTime  0.495 ( 0.650)\tData  0.000 ( 0.288)\tLoss 7.0737e+00 (6.5489e+00)\tAcc@1  40.62 ( 14.22)\tAcc@5  42.19 ( 24.34)\n",
            "Epoch: [3][ 450/1075]\tTime  0.493 ( 0.649)\tData  0.096 ( 0.287)\tLoss 6.7683e+00 (6.5570e+00)\tAcc@1  12.50 ( 14.35)\tAcc@5  20.31 ( 24.36)\n",
            "Epoch: [3][ 460/1075]\tTime  1.022 ( 0.650)\tData  0.728 ( 0.288)\tLoss 6.7338e+00 (6.5594e+00)\tAcc@1   1.56 ( 14.26)\tAcc@5   1.56 ( 24.14)\n",
            "Epoch: [3][ 470/1075]\tTime  0.768 ( 0.650)\tData  0.459 ( 0.288)\tLoss 6.7109e+00 (6.5634e+00)\tAcc@1  17.19 ( 14.25)\tAcc@5  20.31 ( 23.99)\n",
            "Epoch: [3][ 480/1075]\tTime  0.823 ( 0.649)\tData  0.529 ( 0.287)\tLoss 6.8953e+00 (6.5697e+00)\tAcc@1   6.25 ( 14.05)\tAcc@5  10.94 ( 23.70)\n",
            "Epoch: [3][ 490/1075]\tTime  0.560 ( 0.649)\tData  0.251 ( 0.287)\tLoss 6.5247e+00 (6.5761e+00)\tAcc@1   4.69 ( 13.88)\tAcc@5  14.06 ( 23.47)\n",
            "Epoch: [3][ 500/1075]\tTime  0.489 ( 0.648)\tData  0.000 ( 0.287)\tLoss 6.4753e+00 (6.5712e+00)\tAcc@1  10.94 ( 13.81)\tAcc@5  31.25 ( 23.40)\n",
            "Epoch: [3][ 510/1075]\tTime  0.492 ( 0.649)\tData  0.000 ( 0.286)\tLoss 5.9746e+00 (6.5661e+00)\tAcc@1   9.38 ( 13.82)\tAcc@5  18.75 ( 23.40)\n",
            "Epoch: [3][ 520/1075]\tTime  0.491 ( 0.647)\tData  0.000 ( 0.284)\tLoss 6.2019e+00 (6.5561e+00)\tAcc@1   3.12 ( 13.73)\tAcc@5  15.62 ( 23.32)\n",
            "Epoch: [3][ 530/1075]\tTime  0.493 ( 0.648)\tData  0.000 ( 0.284)\tLoss 6.5131e+00 (6.5506e+00)\tAcc@1  15.62 ( 13.70)\tAcc@5  18.75 ( 23.23)\n",
            "Epoch: [3][ 540/1075]\tTime  0.512 ( 0.648)\tData  0.000 ( 0.283)\tLoss 6.3555e+00 (6.5481e+00)\tAcc@1  10.94 ( 13.65)\tAcc@5  21.88 ( 23.16)\n",
            "Epoch: [3][ 550/1075]\tTime  0.494 ( 0.648)\tData  0.000 ( 0.283)\tLoss 6.3021e+00 (6.5452e+00)\tAcc@1   4.69 ( 13.59)\tAcc@5  12.50 ( 23.14)\n",
            "Epoch: [3][ 560/1075]\tTime  0.508 ( 0.647)\tData  0.000 ( 0.282)\tLoss 6.6928e+00 (6.5409e+00)\tAcc@1   4.69 ( 13.51)\tAcc@5  15.62 ( 23.05)\n",
            "Epoch: [3][ 570/1075]\tTime  0.663 ( 0.648)\tData  0.366 ( 0.282)\tLoss 6.6651e+00 (6.5430e+00)\tAcc@1   6.25 ( 13.38)\tAcc@5   9.38 ( 22.87)\n",
            "Epoch: [3][ 580/1075]\tTime  0.618 ( 0.647)\tData  0.307 ( 0.282)\tLoss 6.4733e+00 (6.5398e+00)\tAcc@1   6.25 ( 13.27)\tAcc@5  10.94 ( 22.74)\n",
            "Epoch: [3][ 590/1075]\tTime  0.512 ( 0.648)\tData  0.000 ( 0.282)\tLoss 6.2363e+00 (6.5354e+00)\tAcc@1   7.81 ( 13.15)\tAcc@5  14.06 ( 22.62)\n",
            "Epoch: [3][ 600/1075]\tTime  0.509 ( 0.647)\tData  0.000 ( 0.281)\tLoss 6.4629e+00 (6.5328e+00)\tAcc@1  15.62 ( 13.10)\tAcc@5  34.38 ( 22.63)\n",
            "Epoch: [3][ 610/1075]\tTime  0.499 ( 0.648)\tData  0.000 ( 0.281)\tLoss 6.6200e+00 (6.5331e+00)\tAcc@1   3.12 ( 12.99)\tAcc@5  17.19 ( 22.58)\n",
            "Epoch: [3][ 620/1075]\tTime  0.501 ( 0.648)\tData  0.000 ( 0.281)\tLoss 6.5087e+00 (6.5341e+00)\tAcc@1   4.69 ( 12.92)\tAcc@5  14.06 ( 22.48)\n",
            "Epoch: [3][ 630/1075]\tTime  0.496 ( 0.648)\tData  0.000 ( 0.280)\tLoss 6.4212e+00 (6.5300e+00)\tAcc@1   4.69 ( 12.79)\tAcc@5  10.94 ( 22.35)\n",
            "Epoch: [3][ 640/1075]\tTime  0.505 ( 0.648)\tData  0.000 ( 0.279)\tLoss 6.5600e+00 (6.5281e+00)\tAcc@1   6.25 ( 12.69)\tAcc@5  10.94 ( 22.22)\n",
            "Epoch: [3][ 650/1075]\tTime  0.494 ( 0.647)\tData  0.000 ( 0.279)\tLoss 6.8217e+00 (6.5287e+00)\tAcc@1   1.56 ( 12.60)\tAcc@5  10.94 ( 22.12)\n",
            "Epoch: [3][ 660/1075]\tTime  0.494 ( 0.648)\tData  0.000 ( 0.279)\tLoss 6.0900e+00 (6.5250e+00)\tAcc@1   9.38 ( 12.56)\tAcc@5  20.31 ( 22.07)\n",
            "Epoch: [3][ 670/1075]\tTime  0.517 ( 0.647)\tData  0.000 ( 0.278)\tLoss 6.0925e+00 (6.5216e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  23.44 ( 22.04)\n",
            "Epoch: [3][ 680/1075]\tTime  0.506 ( 0.648)\tData  0.000 ( 0.278)\tLoss 5.7974e+00 (6.5181e+00)\tAcc@1  26.56 ( 12.52)\tAcc@5  39.06 ( 22.10)\n",
            "Epoch: [3][ 690/1075]\tTime  0.501 ( 0.647)\tData  0.000 ( 0.277)\tLoss 5.6347e+00 (6.5067e+00)\tAcc@1  15.62 ( 12.56)\tAcc@5  31.25 ( 22.23)\n",
            "Epoch: [3][ 700/1075]\tTime  0.504 ( 0.648)\tData  0.000 ( 0.277)\tLoss 6.3790e+00 (6.5001e+00)\tAcc@1  12.50 ( 12.49)\tAcc@5  25.00 ( 22.20)\n",
            "Epoch: [3][ 710/1075]\tTime  0.493 ( 0.647)\tData  0.000 ( 0.275)\tLoss 6.6763e+00 (6.5016e+00)\tAcc@1   4.69 ( 12.43)\tAcc@5  15.62 ( 22.12)\n",
            "Epoch: [3][ 720/1075]\tTime  0.496 ( 0.647)\tData  0.000 ( 0.276)\tLoss 6.2122e+00 (6.5023e+00)\tAcc@1   9.38 ( 12.34)\tAcc@5  23.44 ( 22.01)\n",
            "Epoch: [3][ 730/1075]\tTime  0.492 ( 0.646)\tData  0.130 ( 0.274)\tLoss 6.1170e+00 (6.4987e+00)\tAcc@1   3.12 ( 12.26)\tAcc@5  15.62 ( 21.96)\n",
            "Epoch: [3][ 740/1075]\tTime  0.492 ( 0.646)\tData  0.088 ( 0.274)\tLoss 6.2078e+00 (6.4946e+00)\tAcc@1   1.56 ( 12.16)\tAcc@5  10.94 ( 21.82)\n",
            "Epoch: [3][ 750/1075]\tTime  0.753 ( 0.645)\tData  0.446 ( 0.274)\tLoss 6.1845e+00 (6.4909e+00)\tAcc@1   4.69 ( 12.11)\tAcc@5  15.62 ( 21.75)\n",
            "Epoch: [3][ 760/1075]\tTime  1.036 ( 0.645)\tData  0.741 ( 0.274)\tLoss 6.2787e+00 (6.4863e+00)\tAcc@1   9.38 ( 12.07)\tAcc@5  20.31 ( 21.74)\n",
            "Epoch: [3][ 770/1075]\tTime  0.656 ( 0.645)\tData  0.347 ( 0.274)\tLoss 6.5301e+00 (6.4872e+00)\tAcc@1   9.38 ( 12.02)\tAcc@5  15.62 ( 21.67)\n",
            "Epoch: [3][ 780/1075]\tTime  0.759 ( 0.644)\tData  0.451 ( 0.273)\tLoss 7.1610e+00 (6.4928e+00)\tAcc@1  10.94 ( 11.96)\tAcc@5  20.31 ( 21.59)\n",
            "Epoch: [3][ 790/1075]\tTime  0.632 ( 0.645)\tData  0.324 ( 0.273)\tLoss 7.2963e+00 (6.5000e+00)\tAcc@1   7.81 ( 11.95)\tAcc@5  14.06 ( 21.59)\n",
            "Epoch: [3][ 800/1075]\tTime  0.507 ( 0.644)\tData  0.210 ( 0.272)\tLoss 5.3707e+00 (6.4995e+00)\tAcc@1  32.81 ( 12.07)\tAcc@5  48.44 ( 21.75)\n",
            "Epoch: [3][ 810/1075]\tTime  0.590 ( 0.644)\tData  0.296 ( 0.273)\tLoss 7.0069e+00 (6.4940e+00)\tAcc@1   9.38 ( 12.11)\tAcc@5  17.19 ( 21.79)\n",
            "Epoch: [3][ 820/1075]\tTime  0.770 ( 0.644)\tData  0.475 ( 0.272)\tLoss 6.6478e+00 (6.4982e+00)\tAcc@1   7.81 ( 12.08)\tAcc@5  18.75 ( 21.74)\n",
            "Epoch: [3][ 830/1075]\tTime  0.825 ( 0.644)\tData  0.516 ( 0.272)\tLoss 6.8199e+00 (6.5020e+00)\tAcc@1  15.62 ( 12.04)\tAcc@5  21.88 ( 21.70)\n",
            "Epoch: [3][ 840/1075]\tTime  0.712 ( 0.643)\tData  0.416 ( 0.271)\tLoss 6.4706e+00 (6.5051e+00)\tAcc@1   3.12 ( 11.97)\tAcc@5  14.06 ( 21.63)\n",
            "Epoch: [3][ 850/1075]\tTime  0.833 ( 0.644)\tData  0.539 ( 0.272)\tLoss 6.4071e+00 (6.5062e+00)\tAcc@1   1.56 ( 11.86)\tAcc@5   9.38 ( 21.49)\n",
            "Epoch: [3][ 860/1075]\tTime  0.641 ( 0.643)\tData  0.349 ( 0.271)\tLoss 6.2942e+00 (6.5061e+00)\tAcc@1   6.25 ( 11.77)\tAcc@5   9.38 ( 21.36)\n",
            "Epoch: [3][ 870/1075]\tTime  0.990 ( 0.644)\tData  0.697 ( 0.272)\tLoss 6.2446e+00 (6.5026e+00)\tAcc@1   1.56 ( 11.72)\tAcc@5  12.50 ( 21.31)\n",
            "Epoch: [3][ 880/1075]\tTime  0.577 ( 0.643)\tData  0.285 ( 0.271)\tLoss 6.2513e+00 (6.4999e+00)\tAcc@1  20.31 ( 11.74)\tAcc@5  34.38 ( 21.36)\n",
            "Epoch: [3][ 890/1075]\tTime  1.162 ( 0.644)\tData  0.854 ( 0.271)\tLoss 6.4364e+00 (6.4976e+00)\tAcc@1  14.06 ( 11.75)\tAcc@5  23.44 ( 21.34)\n",
            "Epoch: [3][ 900/1075]\tTime  0.595 ( 0.643)\tData  0.287 ( 0.271)\tLoss 6.2726e+00 (6.4948e+00)\tAcc@1  34.38 ( 11.87)\tAcc@5  42.19 ( 21.43)\n",
            "Epoch: [3][ 910/1075]\tTime  0.988 ( 0.643)\tData  0.680 ( 0.270)\tLoss 6.3993e+00 (6.4922e+00)\tAcc@1  23.44 ( 11.98)\tAcc@5  42.19 ( 21.56)\n",
            "Epoch: [3][ 920/1075]\tTime  0.712 ( 0.643)\tData  0.404 ( 0.270)\tLoss 6.6983e+00 (6.4929e+00)\tAcc@1  17.19 ( 12.03)\tAcc@5  29.69 ( 21.61)\n",
            "Epoch: [3][ 930/1075]\tTime  0.900 ( 0.642)\tData  0.603 ( 0.269)\tLoss 7.1667e+00 (6.4974e+00)\tAcc@1   6.25 ( 12.03)\tAcc@5  14.06 ( 21.60)\n",
            "Epoch: [3][ 940/1075]\tTime  0.757 ( 0.643)\tData  0.449 ( 0.270)\tLoss 7.3901e+00 (6.5058e+00)\tAcc@1   7.81 ( 11.97)\tAcc@5  14.06 ( 21.50)\n",
            "Epoch: [3][ 950/1075]\tTime  0.629 ( 0.642)\tData  0.336 ( 0.269)\tLoss 7.6756e+00 (6.5176e+00)\tAcc@1  10.94 ( 11.92)\tAcc@5  15.62 ( 21.40)\n",
            "Epoch: [3][ 960/1075]\tTime  0.732 ( 0.642)\tData  0.446 ( 0.269)\tLoss 7.8626e+00 (6.5303e+00)\tAcc@1   1.56 ( 11.87)\tAcc@5   6.25 ( 21.30)\n",
            "Epoch: [3][ 970/1075]\tTime  0.640 ( 0.642)\tData  0.328 ( 0.269)\tLoss 7.9470e+00 (6.5441e+00)\tAcc@1   9.38 ( 11.78)\tAcc@5  14.06 ( 21.17)\n",
            "Epoch: [3][ 980/1075]\tTime  0.712 ( 0.642)\tData  0.419 ( 0.269)\tLoss 7.7928e+00 (6.5576e+00)\tAcc@1  15.62 ( 11.77)\tAcc@5  29.69 ( 21.16)\n",
            "Epoch: [3][ 990/1075]\tTime  0.587 ( 0.642)\tData  0.279 ( 0.268)\tLoss 7.6250e+00 (6.5692e+00)\tAcc@1  14.06 ( 11.76)\tAcc@5  18.75 ( 21.13)\n",
            "Epoch: [3][1000/1075]\tTime  0.860 ( 0.642)\tData  0.578 ( 0.268)\tLoss 7.4347e+00 (6.5782e+00)\tAcc@1   1.56 ( 11.71)\tAcc@5  10.94 ( 21.11)\n",
            "Epoch: [3][1010/1075]\tTime  0.754 ( 0.642)\tData  0.445 ( 0.268)\tLoss 7.2675e+00 (6.5860e+00)\tAcc@1   6.25 ( 11.67)\tAcc@5  10.94 ( 21.05)\n",
            "Epoch: [3][1020/1075]\tTime  0.871 ( 0.642)\tData  0.573 ( 0.268)\tLoss 7.0711e+00 (6.5918e+00)\tAcc@1  14.06 ( 11.71)\tAcc@5  20.31 ( 21.07)\n",
            "Epoch: [3][1030/1075]\tTime  0.709 ( 0.641)\tData  0.415 ( 0.268)\tLoss 7.1430e+00 (6.5965e+00)\tAcc@1  21.88 ( 11.69)\tAcc@5  25.00 ( 21.02)\n",
            "Epoch: [3][1040/1075]\tTime  0.942 ( 0.642)\tData  0.648 ( 0.268)\tLoss 7.0361e+00 (6.6010e+00)\tAcc@1   3.12 ( 11.68)\tAcc@5  10.94 ( 21.00)\n",
            "Epoch: [3][1050/1075]\tTime  0.703 ( 0.642)\tData  0.414 ( 0.268)\tLoss 7.0982e+00 (6.6055e+00)\tAcc@1  18.75 ( 11.69)\tAcc@5  28.12 ( 20.98)\n",
            "Epoch: [3][1060/1075]\tTime  1.109 ( 0.642)\tData  0.814 ( 0.268)\tLoss 6.5839e+00 (6.6079e+00)\tAcc@1  17.19 ( 11.67)\tAcc@5  25.00 ( 20.96)\n",
            "Epoch: [3][1070/1075]\tTime  0.669 ( 0.641)\tData  0.350 ( 0.268)\tLoss 6.0780e+00 (6.6051e+00)\tAcc@1  10.94 ( 11.69)\tAcc@5  31.25 ( 21.03)\n",
            "epoch: 3\n",
            "2023-04-19 12:34:08.118640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 12:34:12.837318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [4][   0/1075]\tTime 10.855 (10.855)\tData 10.550 (10.550)\tLoss 6.1961e+00 (6.1961e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  17.19 ( 17.19)\n",
            "Epoch: [4][  10/1075]\tTime  0.490 ( 1.532)\tData  0.000 ( 1.175)\tLoss 6.3725e+00 (6.2639e+00)\tAcc@1  10.94 (  9.52)\tAcc@5  15.62 ( 22.30)\n",
            "Epoch: [4][  20/1075]\tTime  0.491 ( 1.107)\tData  0.072 ( 0.745)\tLoss 5.9021e+00 (6.2811e+00)\tAcc@1  14.06 ( 11.09)\tAcc@5  28.12 ( 23.44)\n",
            "Epoch: [4][  30/1075]\tTime  0.495 ( 0.941)\tData  0.000 ( 0.587)\tLoss 5.9246e+00 (6.0935e+00)\tAcc@1   6.25 ( 10.18)\tAcc@5  10.94 ( 22.23)\n",
            "Epoch: [4][  40/1075]\tTime  0.498 ( 0.875)\tData  0.000 ( 0.510)\tLoss 6.4091e+00 (6.1219e+00)\tAcc@1   6.25 (  9.03)\tAcc@5  14.06 ( 19.93)\n",
            "Epoch: [4][  50/1075]\tTime  0.497 ( 0.821)\tData  0.000 ( 0.449)\tLoss 6.5353e+00 (6.2032e+00)\tAcc@1   6.25 (  8.33)\tAcc@5  18.75 ( 18.69)\n",
            "Epoch: [4][  60/1075]\tTime  0.506 ( 0.797)\tData  0.000 ( 0.421)\tLoss 6.1804e+00 (6.1756e+00)\tAcc@1  20.31 ( 10.99)\tAcc@5  25.00 ( 21.70)\n",
            "Epoch: [4][  70/1075]\tTime  0.485 ( 0.776)\tData  0.000 ( 0.398)\tLoss 6.6951e+00 (6.2219e+00)\tAcc@1   3.12 ( 10.72)\tAcc@5  10.94 ( 21.13)\n",
            "Epoch: [4][  80/1075]\tTime  0.495 ( 0.765)\tData  0.000 ( 0.384)\tLoss 7.0070e+00 (6.3046e+00)\tAcc@1   0.00 ( 10.40)\tAcc@5   3.12 ( 20.62)\n",
            "Epoch: [4][  90/1075]\tTime  0.497 ( 0.744)\tData  0.000 ( 0.360)\tLoss 6.5015e+00 (6.3690e+00)\tAcc@1  14.06 ( 10.34)\tAcc@5  21.88 ( 20.40)\n",
            "Epoch: [4][ 100/1075]\tTime  0.491 ( 0.736)\tData  0.000 ( 0.351)\tLoss 5.8436e+00 (6.3154e+00)\tAcc@1   9.38 ( 10.29)\tAcc@5  21.88 ( 20.95)\n",
            "Epoch: [4][ 110/1075]\tTime  0.510 ( 0.720)\tData  0.000 ( 0.334)\tLoss 6.1755e+00 (6.2892e+00)\tAcc@1   4.69 ( 10.33)\tAcc@5  12.50 ( 20.97)\n",
            "Epoch: [4][ 120/1075]\tTime  0.494 ( 0.713)\tData  0.000 ( 0.326)\tLoss 6.6238e+00 (6.3024e+00)\tAcc@1   3.12 ( 10.12)\tAcc@5  10.94 ( 20.64)\n",
            "Epoch: [4][ 130/1075]\tTime  0.497 ( 0.705)\tData  0.000 ( 0.317)\tLoss 6.4257e+00 (6.3270e+00)\tAcc@1  17.19 ( 10.44)\tAcc@5  25.00 ( 20.69)\n",
            "Epoch: [4][ 140/1075]\tTime  0.507 ( 0.699)\tData  0.000 ( 0.310)\tLoss 6.1220e+00 (6.3256e+00)\tAcc@1   9.38 ( 10.41)\tAcc@5  23.44 ( 20.66)\n",
            "Epoch: [4][ 150/1075]\tTime  0.505 ( 0.694)\tData  0.045 ( 0.305)\tLoss 6.1199e+00 (6.3062e+00)\tAcc@1  14.06 ( 10.79)\tAcc@5  23.44 ( 21.06)\n",
            "Epoch: [4][ 160/1075]\tTime  0.509 ( 0.688)\tData  0.001 ( 0.299)\tLoss 6.7361e+00 (6.3165e+00)\tAcc@1  10.94 ( 10.96)\tAcc@5  23.44 ( 21.15)\n",
            "Epoch: [4][ 170/1075]\tTime  0.494 ( 0.687)\tData  0.000 ( 0.299)\tLoss 7.1682e+00 (6.3565e+00)\tAcc@1  10.94 ( 10.70)\tAcc@5  23.44 ( 20.89)\n",
            "Epoch: [4][ 180/1075]\tTime  0.486 ( 0.683)\tData  0.000 ( 0.295)\tLoss 7.3409e+00 (6.4087e+00)\tAcc@1   4.69 ( 10.59)\tAcc@5  14.06 ( 20.69)\n",
            "Epoch: [4][ 190/1075]\tTime  0.513 ( 0.684)\tData  0.000 ( 0.295)\tLoss 7.3774e+00 (6.4591e+00)\tAcc@1  12.50 ( 10.71)\tAcc@5  23.44 ( 20.86)\n",
            "Epoch: [4][ 200/1075]\tTime  0.489 ( 0.680)\tData  0.000 ( 0.290)\tLoss 7.0441e+00 (6.4959e+00)\tAcc@1  14.06 ( 10.98)\tAcc@5  20.31 ( 21.07)\n",
            "Epoch: [4][ 210/1075]\tTime  0.506 ( 0.681)\tData  0.000 ( 0.291)\tLoss 6.6243e+00 (6.5078e+00)\tAcc@1  10.94 ( 10.99)\tAcc@5  26.56 ( 21.08)\n",
            "Epoch: [4][ 220/1075]\tTime  0.494 ( 0.677)\tData  0.000 ( 0.286)\tLoss 5.6526e+00 (6.4857e+00)\tAcc@1  15.62 ( 11.19)\tAcc@5  21.88 ( 21.25)\n",
            "Epoch: [4][ 230/1075]\tTime  0.504 ( 0.675)\tData  0.000 ( 0.284)\tLoss 5.3990e+00 (6.4401e+00)\tAcc@1  20.31 ( 11.58)\tAcc@5  28.12 ( 21.69)\n",
            "Epoch: [4][ 240/1075]\tTime  0.492 ( 0.671)\tData  0.000 ( 0.280)\tLoss 6.0422e+00 (6.4113e+00)\tAcc@1  14.06 ( 11.76)\tAcc@5  26.56 ( 21.90)\n",
            "Epoch: [4][ 250/1075]\tTime  0.654 ( 0.669)\tData  0.357 ( 0.280)\tLoss 6.4694e+00 (6.4039e+00)\tAcc@1   7.81 ( 11.72)\tAcc@5  20.31 ( 21.89)\n",
            "Epoch: [4][ 260/1075]\tTime  0.680 ( 0.667)\tData  0.369 ( 0.281)\tLoss 5.7644e+00 (6.3756e+00)\tAcc@1   3.12 ( 11.71)\tAcc@5   9.38 ( 22.05)\n",
            "Epoch: [4][ 270/1075]\tTime  0.553 ( 0.664)\tData  0.254 ( 0.281)\tLoss 5.4904e+00 (6.3525e+00)\tAcc@1  21.88 ( 11.71)\tAcc@5  29.69 ( 22.16)\n",
            "Epoch: [4][ 280/1075]\tTime  0.492 ( 0.663)\tData  0.166 ( 0.281)\tLoss 5.9748e+00 (6.3222e+00)\tAcc@1   9.38 ( 11.85)\tAcc@5  18.75 ( 22.50)\n",
            "Epoch: [4][ 290/1075]\tTime  0.693 ( 0.660)\tData  0.381 ( 0.281)\tLoss 5.7210e+00 (6.3082e+00)\tAcc@1  10.94 ( 11.81)\tAcc@5  25.00 ( 22.52)\n",
            "Epoch: [4][ 300/1075]\tTime  0.506 ( 0.660)\tData  0.020 ( 0.282)\tLoss 6.2506e+00 (6.2985e+00)\tAcc@1   4.69 ( 11.83)\tAcc@5  15.62 ( 22.55)\n",
            "Epoch: [4][ 310/1075]\tTime  0.508 ( 0.658)\tData  0.000 ( 0.279)\tLoss 6.2557e+00 (6.2996e+00)\tAcc@1  10.94 ( 11.80)\tAcc@5  25.00 ( 22.56)\n",
            "Epoch: [4][ 320/1075]\tTime  0.494 ( 0.659)\tData  0.000 ( 0.279)\tLoss 6.2181e+00 (6.2920e+00)\tAcc@1   9.38 ( 11.88)\tAcc@5  18.75 ( 22.66)\n",
            "Epoch: [4][ 330/1075]\tTime  0.499 ( 0.656)\tData  0.000 ( 0.276)\tLoss 6.5045e+00 (6.2907e+00)\tAcc@1   9.38 ( 11.90)\tAcc@5  12.50 ( 22.65)\n",
            "Epoch: [4][ 340/1075]\tTime  0.508 ( 0.657)\tData  0.000 ( 0.276)\tLoss 6.5966e+00 (6.2969e+00)\tAcc@1  15.62 ( 11.87)\tAcc@5  28.12 ( 22.53)\n",
            "Epoch: [4][ 350/1075]\tTime  0.495 ( 0.655)\tData  0.000 ( 0.274)\tLoss 6.1151e+00 (6.2953e+00)\tAcc@1   7.81 ( 11.81)\tAcc@5  12.50 ( 22.39)\n",
            "Epoch: [4][ 360/1075]\tTime  0.523 ( 0.655)\tData  0.216 ( 0.274)\tLoss 6.1086e+00 (6.2907e+00)\tAcc@1  10.94 ( 11.74)\tAcc@5  23.44 ( 22.35)\n",
            "Epoch: [4][ 370/1075]\tTime  0.631 ( 0.653)\tData  0.322 ( 0.274)\tLoss 6.1516e+00 (6.2841e+00)\tAcc@1   4.69 ( 11.74)\tAcc@5  14.06 ( 22.47)\n",
            "Epoch: [4][ 380/1075]\tTime  0.887 ( 0.653)\tData  0.592 ( 0.274)\tLoss 6.6487e+00 (6.2897e+00)\tAcc@1   3.12 ( 11.58)\tAcc@5  17.19 ( 22.30)\n",
            "Epoch: [4][ 390/1075]\tTime  0.781 ( 0.653)\tData  0.470 ( 0.273)\tLoss 6.6272e+00 (6.2996e+00)\tAcc@1  20.31 ( 11.55)\tAcc@5  31.25 ( 22.23)\n",
            "Epoch: [4][ 400/1075]\tTime  0.879 ( 0.652)\tData  0.577 ( 0.272)\tLoss 6.3862e+00 (6.3044e+00)\tAcc@1  17.19 ( 11.65)\tAcc@5  20.31 ( 22.30)\n",
            "Epoch: [4][ 410/1075]\tTime  0.735 ( 0.652)\tData  0.428 ( 0.273)\tLoss 6.5018e+00 (6.3069e+00)\tAcc@1  10.94 ( 11.66)\tAcc@5  21.88 ( 22.29)\n",
            "Epoch: [4][ 420/1075]\tTime  0.745 ( 0.651)\tData  0.435 ( 0.271)\tLoss 5.1194e+00 (6.2991e+00)\tAcc@1  32.81 ( 11.82)\tAcc@5  43.75 ( 22.50)\n",
            "Epoch: [4][ 430/1075]\tTime  0.569 ( 0.651)\tData  0.276 ( 0.271)\tLoss 6.1178e+00 (6.2851e+00)\tAcc@1   6.25 ( 11.94)\tAcc@5  20.31 ( 22.66)\n",
            "Epoch: [4][ 440/1075]\tTime  0.601 ( 0.649)\tData  0.291 ( 0.269)\tLoss 5.3813e+00 (6.2773e+00)\tAcc@1  20.31 ( 12.09)\tAcc@5  45.31 ( 22.80)\n",
            "Epoch: [4][ 450/1075]\tTime  0.492 ( 0.649)\tData  0.000 ( 0.270)\tLoss 6.0155e+00 (6.2607e+00)\tAcc@1  12.50 ( 12.11)\tAcc@5  20.31 ( 22.92)\n",
            "Epoch: [4][ 460/1075]\tTime  0.495 ( 0.648)\tData  0.000 ( 0.269)\tLoss 6.6576e+00 (6.2637e+00)\tAcc@1   7.81 ( 11.97)\tAcc@5  10.94 ( 22.69)\n",
            "Epoch: [4][ 470/1075]\tTime  0.493 ( 0.648)\tData  0.048 ( 0.269)\tLoss 6.8532e+00 (6.2743e+00)\tAcc@1   1.56 ( 11.83)\tAcc@5   6.25 ( 22.48)\n",
            "Epoch: [4][ 480/1075]\tTime  0.490 ( 0.647)\tData  0.026 ( 0.268)\tLoss 6.6599e+00 (6.2850e+00)\tAcc@1   9.38 ( 11.73)\tAcc@5  28.12 ( 22.38)\n",
            "Epoch: [4][ 490/1075]\tTime  0.488 ( 0.648)\tData  0.190 ( 0.269)\tLoss 5.6350e+00 (6.2828e+00)\tAcc@1  34.38 ( 11.80)\tAcc@5  48.44 ( 22.47)\n",
            "Epoch: [4][ 500/1075]\tTime  0.753 ( 0.647)\tData  0.460 ( 0.269)\tLoss 5.8197e+00 (6.2729e+00)\tAcc@1  15.62 ( 11.83)\tAcc@5  29.69 ( 22.53)\n",
            "Epoch: [4][ 510/1075]\tTime  1.137 ( 0.647)\tData  0.837 ( 0.269)\tLoss 5.8470e+00 (6.2622e+00)\tAcc@1   7.81 ( 11.84)\tAcc@5  15.62 ( 22.61)\n",
            "Epoch: [4][ 520/1075]\tTime  0.654 ( 0.646)\tData  0.362 ( 0.269)\tLoss 5.8414e+00 (6.2556e+00)\tAcc@1   4.69 ( 11.74)\tAcc@5  17.19 ( 22.51)\n",
            "Epoch: [4][ 530/1075]\tTime  0.987 ( 0.645)\tData  0.693 ( 0.268)\tLoss 5.8908e+00 (6.2533e+00)\tAcc@1   4.69 ( 11.69)\tAcc@5  17.19 ( 22.43)\n",
            "Epoch: [4][ 540/1075]\tTime  0.701 ( 0.645)\tData  0.391 ( 0.267)\tLoss 5.9353e+00 (6.2476e+00)\tAcc@1   7.81 ( 11.62)\tAcc@5  25.00 ( 22.35)\n",
            "Epoch: [4][ 550/1075]\tTime  0.508 ( 0.644)\tData  0.184 ( 0.267)\tLoss 5.8962e+00 (6.2404e+00)\tAcc@1   7.81 ( 11.60)\tAcc@5  26.56 ( 22.48)\n",
            "Epoch: [4][ 560/1075]\tTime  0.720 ( 0.644)\tData  0.424 ( 0.269)\tLoss 6.4041e+00 (6.2399e+00)\tAcc@1  15.62 ( 11.63)\tAcc@5  21.88 ( 22.57)\n",
            "Epoch: [4][ 570/1075]\tTime  0.608 ( 0.643)\tData  0.299 ( 0.268)\tLoss 6.5862e+00 (6.2433e+00)\tAcc@1   7.81 ( 11.64)\tAcc@5  23.44 ( 22.65)\n",
            "Epoch: [4][ 580/1075]\tTime  0.496 ( 0.643)\tData  0.165 ( 0.270)\tLoss 6.6936e+00 (6.2497e+00)\tAcc@1   9.38 ( 11.64)\tAcc@5  17.19 ( 22.67)\n",
            "Epoch: [4][ 590/1075]\tTime  0.491 ( 0.642)\tData  0.000 ( 0.269)\tLoss 6.6483e+00 (6.2567e+00)\tAcc@1  15.62 ( 11.67)\tAcc@5  28.12 ( 22.74)\n",
            "Epoch: [4][ 600/1075]\tTime  0.492 ( 0.643)\tData  0.001 ( 0.270)\tLoss 6.4502e+00 (6.2611e+00)\tAcc@1  14.06 ( 11.73)\tAcc@5  28.12 ( 22.88)\n",
            "Epoch: [4][ 610/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.269)\tLoss 6.5279e+00 (6.2653e+00)\tAcc@1  12.50 ( 11.76)\tAcc@5  21.88 ( 22.94)\n",
            "Epoch: [4][ 620/1075]\tTime  0.492 ( 0.643)\tData  0.000 ( 0.269)\tLoss 6.5664e+00 (6.2695e+00)\tAcc@1   4.69 ( 11.76)\tAcc@5   7.81 ( 22.90)\n",
            "Epoch: [4][ 630/1075]\tTime  0.496 ( 0.644)\tData  0.000 ( 0.269)\tLoss 6.6187e+00 (6.2739e+00)\tAcc@1  14.06 ( 11.73)\tAcc@5  26.56 ( 22.89)\n",
            "Epoch: [4][ 640/1075]\tTime  0.490 ( 0.644)\tData  0.000 ( 0.269)\tLoss 6.6993e+00 (6.2793e+00)\tAcc@1  14.06 ( 11.73)\tAcc@5  20.31 ( 22.86)\n",
            "Epoch: [4][ 650/1075]\tTime  0.507 ( 0.644)\tData  0.000 ( 0.268)\tLoss 6.2436e+00 (6.2829e+00)\tAcc@1  14.06 ( 11.74)\tAcc@5  17.19 ( 22.82)\n",
            "Epoch: [4][ 660/1075]\tTime  0.514 ( 0.643)\tData  0.000 ( 0.267)\tLoss 5.8541e+00 (6.2786e+00)\tAcc@1   9.38 ( 11.84)\tAcc@5  20.31 ( 22.90)\n",
            "Epoch: [4][ 670/1075]\tTime  0.495 ( 0.643)\tData  0.000 ( 0.267)\tLoss 5.9290e+00 (6.2730e+00)\tAcc@1   7.81 ( 11.86)\tAcc@5  14.06 ( 22.90)\n",
            "Epoch: [4][ 680/1075]\tTime  0.492 ( 0.642)\tData  0.000 ( 0.266)\tLoss 6.2835e+00 (6.2688e+00)\tAcc@1   7.81 ( 11.91)\tAcc@5  20.31 ( 22.95)\n",
            "Epoch: [4][ 690/1075]\tTime  0.489 ( 0.643)\tData  0.000 ( 0.266)\tLoss 6.2003e+00 (6.2693e+00)\tAcc@1   7.81 ( 11.87)\tAcc@5  29.69 ( 22.89)\n",
            "Epoch: [4][ 700/1075]\tTime  0.513 ( 0.642)\tData  0.000 ( 0.265)\tLoss 5.2902e+00 (6.2582e+00)\tAcc@1  34.38 ( 11.94)\tAcc@5  46.88 ( 23.00)\n",
            "Epoch: [4][ 710/1075]\tTime  0.505 ( 0.642)\tData  0.073 ( 0.266)\tLoss 5.8954e+00 (6.2488e+00)\tAcc@1   7.81 ( 11.92)\tAcc@5  15.62 ( 22.95)\n",
            "Epoch: [4][ 720/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.265)\tLoss 6.3547e+00 (6.2486e+00)\tAcc@1  10.94 ( 11.90)\tAcc@5  17.19 ( 22.89)\n",
            "Epoch: [4][ 730/1075]\tTime  0.507 ( 0.642)\tData  0.000 ( 0.266)\tLoss 6.4567e+00 (6.2511e+00)\tAcc@1   7.81 ( 11.85)\tAcc@5  15.62 ( 22.79)\n",
            "Epoch: [4][ 740/1075]\tTime  0.493 ( 0.642)\tData  0.000 ( 0.265)\tLoss 6.5950e+00 (6.2549e+00)\tAcc@1   4.69 ( 11.80)\tAcc@5   9.38 ( 22.68)\n",
            "Epoch: [4][ 750/1075]\tTime  0.494 ( 0.643)\tData  0.000 ( 0.266)\tLoss 6.4516e+00 (6.2589e+00)\tAcc@1   1.56 ( 11.74)\tAcc@5   6.25 ( 22.56)\n",
            "Epoch: [4][ 760/1075]\tTime  0.493 ( 0.642)\tData  0.000 ( 0.265)\tLoss 5.7691e+00 (6.2574e+00)\tAcc@1   0.00 ( 11.74)\tAcc@5   9.38 ( 22.58)\n",
            "Epoch: [4][ 770/1075]\tTime  0.505 ( 0.643)\tData  0.003 ( 0.265)\tLoss 6.4108e+00 (6.2534e+00)\tAcc@1   0.00 ( 11.80)\tAcc@5   4.69 ( 22.61)\n",
            "Epoch: [4][ 780/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.264)\tLoss 6.4516e+00 (6.2568e+00)\tAcc@1  14.06 ( 11.73)\tAcc@5  15.62 ( 22.48)\n",
            "Epoch: [4][ 790/1075]\tTime  0.514 ( 0.642)\tData  0.000 ( 0.264)\tLoss 6.5441e+00 (6.2603e+00)\tAcc@1   1.56 ( 11.73)\tAcc@5   9.38 ( 22.38)\n",
            "Epoch: [4][ 800/1075]\tTime  0.512 ( 0.642)\tData  0.000 ( 0.264)\tLoss 6.7309e+00 (6.2664e+00)\tAcc@1  14.06 ( 11.88)\tAcc@5  14.06 ( 22.45)\n",
            "Epoch: [4][ 810/1075]\tTime  0.500 ( 0.641)\tData  0.000 ( 0.263)\tLoss 7.0345e+00 (6.2742e+00)\tAcc@1  12.50 ( 11.89)\tAcc@5  21.88 ( 22.43)\n",
            "Epoch: [4][ 820/1075]\tTime  0.508 ( 0.642)\tData  0.000 ( 0.263)\tLoss 6.3666e+00 (6.2798e+00)\tAcc@1   0.00 ( 11.83)\tAcc@5  28.12 ( 22.38)\n",
            "Epoch: [4][ 830/1075]\tTime  0.494 ( 0.641)\tData  0.000 ( 0.263)\tLoss 6.8562e+00 (6.2835e+00)\tAcc@1   7.81 ( 12.04)\tAcc@5  10.94 ( 22.60)\n",
            "Epoch: [4][ 840/1075]\tTime  0.492 ( 0.642)\tData  0.000 ( 0.263)\tLoss 7.2412e+00 (6.2930e+00)\tAcc@1  68.75 ( 12.54)\tAcc@5  71.88 ( 23.08)\n",
            "Epoch: [4][ 850/1075]\tTime  0.506 ( 0.642)\tData  0.000 ( 0.262)\tLoss 7.4896e+00 (6.3058e+00)\tAcc@1  50.00 ( 12.80)\tAcc@5  57.81 ( 23.30)\n",
            "Epoch: [4][ 860/1075]\tTime  0.483 ( 0.642)\tData  0.000 ( 0.263)\tLoss 7.6428e+00 (6.3206e+00)\tAcc@1  54.69 ( 13.40)\tAcc@5  59.38 ( 23.85)\n",
            "Epoch: [4][ 870/1075]\tTime  0.510 ( 0.642)\tData  0.000 ( 0.262)\tLoss 7.7255e+00 (6.3363e+00)\tAcc@1  73.44 ( 14.05)\tAcc@5  79.69 ( 24.43)\n",
            "Epoch: [4][ 880/1075]\tTime  0.502 ( 0.642)\tData  0.000 ( 0.262)\tLoss 7.7295e+00 (6.3522e+00)\tAcc@1  76.56 ( 14.80)\tAcc@5  89.06 ( 25.11)\n",
            "Epoch: [4][ 890/1075]\tTime  0.513 ( 0.641)\tData  0.000 ( 0.261)\tLoss 7.6888e+00 (6.3674e+00)\tAcc@1  76.56 ( 15.58)\tAcc@5  79.69 ( 25.78)\n",
            "Epoch: [4][ 900/1075]\tTime  0.509 ( 0.642)\tData  0.047 ( 0.261)\tLoss 7.6049e+00 (6.3817e+00)\tAcc@1  62.50 ( 16.27)\tAcc@5  67.19 ( 26.40)\n",
            "Epoch: [4][ 910/1075]\tTime  0.511 ( 0.641)\tData  0.000 ( 0.261)\tLoss 7.5268e+00 (6.3946e+00)\tAcc@1  90.62 ( 17.05)\tAcc@5  92.19 ( 27.09)\n",
            "Epoch: [4][ 920/1075]\tTime  0.489 ( 0.642)\tData  0.000 ( 0.261)\tLoss 7.4696e+00 (6.4066e+00)\tAcc@1  96.88 ( 17.79)\tAcc@5  96.88 ( 27.75)\n",
            "Epoch: [4][ 930/1075]\tTime  0.506 ( 0.641)\tData  0.000 ( 0.261)\tLoss 7.4509e+00 (6.4179e+00)\tAcc@1  92.19 ( 18.47)\tAcc@5  95.31 ( 28.36)\n",
            "Epoch: [4][ 940/1075]\tTime  0.511 ( 0.642)\tData  0.004 ( 0.261)\tLoss 7.4617e+00 (6.4289e+00)\tAcc@1  96.88 ( 19.26)\tAcc@5  96.88 ( 29.05)\n",
            "Epoch: [4][ 950/1075]\tTime  0.495 ( 0.642)\tData  0.000 ( 0.261)\tLoss 7.4923e+00 (6.4399e+00)\tAcc@1  90.62 ( 19.99)\tAcc@5  90.62 ( 29.70)\n",
            "Epoch: [4][ 960/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.260)\tLoss 7.5305e+00 (6.4511e+00)\tAcc@1  75.00 ( 20.71)\tAcc@5  75.00 ( 30.33)\n",
            "Epoch: [4][ 970/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.260)\tLoss 7.5701e+00 (6.4625e+00)\tAcc@1  93.75 ( 21.43)\tAcc@5  95.31 ( 30.97)\n",
            "Epoch: [4][ 980/1075]\tTime  0.515 ( 0.641)\tData  0.000 ( 0.260)\tLoss 7.6056e+00 (6.4739e+00)\tAcc@1  81.25 ( 22.02)\tAcc@5  87.50 ( 31.51)\n",
            "Epoch: [4][ 990/1075]\tTime  0.494 ( 0.642)\tData  0.000 ( 0.260)\tLoss 7.6356e+00 (6.4855e+00)\tAcc@1  90.62 ( 22.65)\tAcc@5  93.75 ( 32.09)\n",
            "Epoch: [4][1000/1075]\tTime  0.505 ( 0.641)\tData  0.000 ( 0.259)\tLoss 7.6601e+00 (6.4972e+00)\tAcc@1  93.75 ( 23.19)\tAcc@5  93.75 ( 32.58)\n",
            "Epoch: [4][1010/1075]\tTime  0.489 ( 0.642)\tData  0.000 ( 0.259)\tLoss 7.6801e+00 (6.5088e+00)\tAcc@1  71.88 ( 23.69)\tAcc@5  81.25 ( 33.06)\n",
            "Epoch: [4][1020/1075]\tTime  0.485 ( 0.642)\tData  0.000 ( 0.259)\tLoss 7.6974e+00 (6.5203e+00)\tAcc@1  90.62 ( 24.19)\tAcc@5  92.19 ( 33.56)\n",
            "Epoch: [4][1030/1075]\tTime  0.495 ( 0.642)\tData  0.000 ( 0.259)\tLoss 7.7017e+00 (6.5318e+00)\tAcc@1  89.06 ( 24.69)\tAcc@5  93.75 ( 34.02)\n",
            "Epoch: [4][1040/1075]\tTime  0.495 ( 0.642)\tData  0.000 ( 0.259)\tLoss 7.7094e+00 (6.5431e+00)\tAcc@1  71.88 ( 25.05)\tAcc@5  79.69 ( 34.36)\n",
            "Epoch: [4][1050/1075]\tTime  0.505 ( 0.642)\tData  0.000 ( 0.259)\tLoss 7.6943e+00 (6.5542e+00)\tAcc@1  73.44 ( 25.44)\tAcc@5  76.56 ( 34.70)\n",
            "Epoch: [4][1060/1075]\tTime  0.482 ( 0.641)\tData  0.000 ( 0.258)\tLoss 7.7223e+00 (6.5651e+00)\tAcc@1   7.81 ( 25.57)\tAcc@5  10.94 ( 34.80)\n",
            "Epoch: [4][1070/1075]\tTime  0.479 ( 0.642)\tData  0.000 ( 0.258)\tLoss 7.6338e+00 (6.5757e+00)\tAcc@1  43.75 ( 25.46)\tAcc@5  45.31 ( 34.67)\n",
            "epoch: 4\n",
            "2023-04-19 12:45:39.130751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 12:45:43.999913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [5][   0/1075]\tTime 11.109 (11.109)\tData 10.806 (10.806)\tLoss 7.4959e+00 (7.4959e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   1.56 (  1.56)\n",
            "Epoch: [5][  10/1075]\tTime  0.585 ( 1.540)\tData  0.276 ( 1.164)\tLoss 7.1406e+00 (7.3343e+00)\tAcc@1   3.12 ( 20.88)\tAcc@5  14.06 ( 25.14)\n",
            "Epoch: [5][  20/1075]\tTime  0.796 ( 1.134)\tData  0.503 ( 0.755)\tLoss 6.3427e+00 (7.0108e+00)\tAcc@1  37.50 ( 24.11)\tAcc@5  42.19 ( 28.42)\n",
            "Epoch: [5][  30/1075]\tTime  0.726 ( 0.968)\tData  0.444 ( 0.591)\tLoss 6.4633e+00 (6.8322e+00)\tAcc@1  28.12 ( 21.67)\tAcc@5  32.81 ( 26.21)\n",
            "Epoch: [5][  40/1075]\tTime  0.811 ( 0.895)\tData  0.517 ( 0.519)\tLoss 6.7815e+00 (6.7963e+00)\tAcc@1   3.12 ( 18.67)\tAcc@5   7.81 ( 23.86)\n",
            "Epoch: [5][  50/1075]\tTime  0.688 ( 0.837)\tData  0.393 ( 0.461)\tLoss 6.9413e+00 (6.8261e+00)\tAcc@1   7.81 ( 16.27)\tAcc@5  14.06 ( 21.60)\n",
            "Epoch: [5][  60/1075]\tTime  1.006 ( 0.809)\tData  0.713 ( 0.432)\tLoss 6.8663e+00 (6.8481e+00)\tAcc@1   6.25 ( 14.01)\tAcc@5  14.06 ( 19.49)\n",
            "Epoch: [5][  70/1075]\tTime  0.643 ( 0.777)\tData  0.334 ( 0.401)\tLoss 5.8121e+00 (6.7295e+00)\tAcc@1  21.88 ( 13.60)\tAcc@5  23.44 ( 19.74)\n",
            "Epoch: [5][  80/1075]\tTime  0.981 ( 0.760)\tData  0.689 ( 0.383)\tLoss 6.5048e+00 (6.6631e+00)\tAcc@1  12.50 ( 12.56)\tAcc@5  17.19 ( 18.40)\n",
            "Epoch: [5][  90/1075]\tTime  0.564 ( 0.742)\tData  0.271 ( 0.365)\tLoss 5.7967e+00 (6.6358e+00)\tAcc@1  25.00 ( 13.15)\tAcc@5  34.38 ( 19.37)\n",
            "Epoch: [5][ 100/1075]\tTime  0.537 ( 0.725)\tData  0.238 ( 0.348)\tLoss 6.4917e+00 (6.6044e+00)\tAcc@1  23.44 ( 12.53)\tAcc@5  28.12 ( 18.61)\n",
            "Epoch: [5][ 110/1075]\tTime  0.679 ( 0.720)\tData  0.390 ( 0.343)\tLoss 6.4427e+00 (6.6102e+00)\tAcc@1  15.62 ( 12.43)\tAcc@5  23.44 ( 18.45)\n",
            "Epoch: [5][ 120/1075]\tTime  0.633 ( 0.712)\tData  0.341 ( 0.334)\tLoss 6.8591e+00 (6.6091e+00)\tAcc@1   1.56 ( 12.91)\tAcc@5   1.56 ( 18.87)\n",
            "Epoch: [5][ 130/1075]\tTime  0.750 ( 0.708)\tData  0.455 ( 0.331)\tLoss 6.4633e+00 (6.6043e+00)\tAcc@1  14.06 ( 12.82)\tAcc@5  26.56 ( 19.11)\n",
            "Epoch: [5][ 140/1075]\tTime  0.581 ( 0.699)\tData  0.290 ( 0.322)\tLoss 7.0625e+00 (6.6099e+00)\tAcc@1   6.25 ( 12.80)\tAcc@5   9.38 ( 19.15)\n",
            "Epoch: [5][ 150/1075]\tTime  0.595 ( 0.697)\tData  0.304 ( 0.320)\tLoss 7.4122e+00 (6.6360e+00)\tAcc@1   7.81 ( 12.49)\tAcc@5  14.06 ( 18.89)\n",
            "Epoch: [5][ 160/1075]\tTime  0.701 ( 0.691)\tData  0.393 ( 0.314)\tLoss 6.9830e+00 (6.6548e+00)\tAcc@1  10.94 ( 12.22)\tAcc@5  23.44 ( 18.65)\n",
            "Epoch: [5][ 170/1075]\tTime  0.737 ( 0.692)\tData  0.444 ( 0.314)\tLoss 6.9171e+00 (6.6739e+00)\tAcc@1   7.81 ( 11.93)\tAcc@5  15.62 ( 18.50)\n",
            "Epoch: [5][ 180/1075]\tTime  0.709 ( 0.684)\tData  0.416 ( 0.306)\tLoss 6.9722e+00 (6.6854e+00)\tAcc@1   1.56 ( 11.60)\tAcc@5  10.94 ( 18.28)\n",
            "Epoch: [5][ 190/1075]\tTime  1.027 ( 0.684)\tData  0.734 ( 0.305)\tLoss 7.2117e+00 (6.7044e+00)\tAcc@1   1.56 ( 11.26)\tAcc@5   9.38 ( 17.97)\n",
            "Epoch: [5][ 200/1075]\tTime  0.742 ( 0.680)\tData  0.450 ( 0.303)\tLoss 7.1374e+00 (6.7259e+00)\tAcc@1   7.81 ( 10.91)\tAcc@5   9.38 ( 17.61)\n",
            "Epoch: [5][ 210/1075]\tTime  0.934 ( 0.677)\tData  0.631 ( 0.299)\tLoss 7.1682e+00 (6.7489e+00)\tAcc@1   0.00 ( 10.55)\tAcc@5   9.38 ( 17.29)\n",
            "Epoch: [5][ 220/1075]\tTime  0.611 ( 0.675)\tData  0.317 ( 0.297)\tLoss 6.9882e+00 (6.7667e+00)\tAcc@1  18.75 ( 10.41)\tAcc@5  28.12 ( 17.14)\n",
            "Epoch: [5][ 230/1075]\tTime  0.719 ( 0.672)\tData  0.427 ( 0.294)\tLoss 5.8145e+00 (6.7504e+00)\tAcc@1   7.81 ( 10.63)\tAcc@5  15.62 ( 17.49)\n",
            "Epoch: [5][ 240/1075]\tTime  0.595 ( 0.672)\tData  0.301 ( 0.294)\tLoss 6.0197e+00 (6.7172e+00)\tAcc@1  12.50 ( 10.54)\tAcc@5  23.44 ( 17.47)\n",
            "Epoch: [5][ 250/1075]\tTime  0.752 ( 0.669)\tData  0.462 ( 0.291)\tLoss 6.4151e+00 (6.6959e+00)\tAcc@1   0.00 ( 10.60)\tAcc@5  10.94 ( 17.47)\n",
            "Epoch: [5][ 260/1075]\tTime  0.654 ( 0.668)\tData  0.345 ( 0.290)\tLoss 6.6657e+00 (6.6916e+00)\tAcc@1   4.69 ( 10.61)\tAcc@5  10.94 ( 17.43)\n",
            "Epoch: [5][ 270/1075]\tTime  0.660 ( 0.666)\tData  0.352 ( 0.288)\tLoss 7.0182e+00 (6.6980e+00)\tAcc@1   7.81 ( 10.74)\tAcc@5  18.75 ( 17.53)\n",
            "Epoch: [5][ 280/1075]\tTime  0.779 ( 0.666)\tData  0.486 ( 0.288)\tLoss 6.9997e+00 (6.7079e+00)\tAcc@1  10.94 ( 10.88)\tAcc@5  17.19 ( 17.66)\n",
            "Epoch: [5][ 290/1075]\tTime  0.756 ( 0.663)\tData  0.463 ( 0.286)\tLoss 7.0755e+00 (6.7201e+00)\tAcc@1  15.62 ( 10.94)\tAcc@5  26.56 ( 17.68)\n",
            "Epoch: [5][ 300/1075]\tTime  0.611 ( 0.663)\tData  0.319 ( 0.286)\tLoss 6.9510e+00 (6.7310e+00)\tAcc@1   9.38 ( 11.05)\tAcc@5  17.19 ( 17.79)\n",
            "Epoch: [5][ 310/1075]\tTime  0.689 ( 0.661)\tData  0.397 ( 0.283)\tLoss 5.1376e+00 (6.7170e+00)\tAcc@1  32.81 ( 11.34)\tAcc@5  59.38 ( 18.43)\n",
            "Epoch: [5][ 320/1075]\tTime  0.862 ( 0.660)\tData  0.560 ( 0.282)\tLoss 5.8890e+00 (6.6859e+00)\tAcc@1   6.25 ( 11.43)\tAcc@5  26.56 ( 18.62)\n",
            "Epoch: [5][ 330/1075]\tTime  0.661 ( 0.658)\tData  0.366 ( 0.282)\tLoss 6.6093e+00 (6.6757e+00)\tAcc@1  14.06 ( 11.30)\tAcc@5  17.19 ( 18.58)\n",
            "Epoch: [5][ 340/1075]\tTime  0.924 ( 0.657)\tData  0.632 ( 0.281)\tLoss 6.7186e+00 (6.6772e+00)\tAcc@1  28.12 ( 11.34)\tAcc@5  35.94 ( 18.74)\n",
            "Epoch: [5][ 350/1075]\tTime  0.666 ( 0.657)\tData  0.372 ( 0.281)\tLoss 6.7501e+00 (6.6794e+00)\tAcc@1   6.25 ( 11.45)\tAcc@5  12.50 ( 18.87)\n",
            "Epoch: [5][ 360/1075]\tTime  1.041 ( 0.656)\tData  0.736 ( 0.279)\tLoss 6.8200e+00 (6.6821e+00)\tAcc@1  31.25 ( 11.80)\tAcc@5  37.50 ( 19.27)\n",
            "Epoch: [5][ 370/1075]\tTime  0.850 ( 0.657)\tData  0.541 ( 0.281)\tLoss 6.1268e+00 (6.6595e+00)\tAcc@1   3.12 ( 12.07)\tAcc@5   6.25 ( 19.62)\n",
            "Epoch: [5][ 380/1075]\tTime  0.553 ( 0.655)\tData  0.261 ( 0.279)\tLoss 6.1767e+00 (6.6504e+00)\tAcc@1  31.25 ( 12.12)\tAcc@5  37.50 ( 19.61)\n",
            "Epoch: [5][ 390/1075]\tTime  0.587 ( 0.655)\tData  0.278 ( 0.279)\tLoss 5.9426e+00 (6.6382e+00)\tAcc@1  10.94 ( 11.98)\tAcc@5  15.62 ( 19.41)\n",
            "Epoch: [5][ 400/1075]\tTime  0.685 ( 0.653)\tData  0.377 ( 0.278)\tLoss 6.3165e+00 (6.6295e+00)\tAcc@1   9.38 ( 12.02)\tAcc@5  17.19 ( 19.41)\n",
            "Epoch: [5][ 410/1075]\tTime  0.777 ( 0.653)\tData  0.482 ( 0.280)\tLoss 6.4612e+00 (6.6296e+00)\tAcc@1  15.62 ( 11.93)\tAcc@5  21.88 ( 19.28)\n",
            "Epoch: [5][ 420/1075]\tTime  0.631 ( 0.652)\tData  0.335 ( 0.278)\tLoss 6.5854e+00 (6.6326e+00)\tAcc@1  18.75 ( 11.79)\tAcc@5  31.25 ( 19.16)\n",
            "Epoch: [5][ 430/1075]\tTime  0.867 ( 0.652)\tData  0.558 ( 0.279)\tLoss 6.7347e+00 (6.6330e+00)\tAcc@1  15.62 ( 11.70)\tAcc@5  25.00 ( 19.05)\n",
            "Epoch: [5][ 440/1075]\tTime  0.493 ( 0.650)\tData  0.000 ( 0.277)\tLoss 6.6235e+00 (6.6344e+00)\tAcc@1  17.19 ( 11.55)\tAcc@5  28.12 ( 18.92)\n",
            "Epoch: [5][ 450/1075]\tTime  0.510 ( 0.651)\tData  0.000 ( 0.277)\tLoss 6.8895e+00 (6.6384e+00)\tAcc@1   0.00 ( 11.40)\tAcc@5   1.56 ( 18.74)\n",
            "Epoch: [5][ 460/1075]\tTime  0.495 ( 0.650)\tData  0.000 ( 0.276)\tLoss 6.9114e+00 (6.6456e+00)\tAcc@1   6.25 ( 11.25)\tAcc@5  28.12 ( 18.56)\n",
            "Epoch: [5][ 470/1075]\tTime  0.790 ( 0.649)\tData  0.497 ( 0.275)\tLoss 6.9948e+00 (6.6535e+00)\tAcc@1  12.50 ( 11.26)\tAcc@5  23.44 ( 18.54)\n",
            "Epoch: [5][ 480/1075]\tTime  0.646 ( 0.649)\tData  0.346 ( 0.276)\tLoss 6.9810e+00 (6.6604e+00)\tAcc@1   4.69 ( 11.24)\tAcc@5  20.31 ( 18.57)\n",
            "Epoch: [5][ 490/1075]\tTime  0.499 ( 0.648)\tData  0.018 ( 0.275)\tLoss 7.0057e+00 (6.6670e+00)\tAcc@1  34.38 ( 11.25)\tAcc@5  51.56 ( 18.64)\n",
            "Epoch: [5][ 500/1075]\tTime  0.493 ( 0.648)\tData  0.057 ( 0.275)\tLoss 7.0477e+00 (6.6740e+00)\tAcc@1  45.31 ( 11.53)\tAcc@5  46.88 ( 18.93)\n",
            "Epoch: [5][ 510/1075]\tTime  0.489 ( 0.647)\tData  0.000 ( 0.274)\tLoss 7.0132e+00 (6.6812e+00)\tAcc@1   1.56 ( 11.75)\tAcc@5   4.69 ( 19.14)\n",
            "Epoch: [5][ 520/1075]\tTime  0.490 ( 0.648)\tData  0.000 ( 0.274)\tLoss 6.6606e+00 (6.6831e+00)\tAcc@1  75.00 ( 12.27)\tAcc@5  79.69 ( 19.84)\n",
            "Epoch: [5][ 530/1075]\tTime  0.498 ( 0.647)\tData  0.000 ( 0.273)\tLoss 6.7193e+00 (6.6802e+00)\tAcc@1   3.12 ( 12.34)\tAcc@5   9.38 ( 19.99)\n",
            "Epoch: [5][ 540/1075]\tTime  0.508 ( 0.647)\tData  0.000 ( 0.273)\tLoss 7.1835e+00 (6.6860e+00)\tAcc@1  28.12 ( 12.36)\tAcc@5  54.69 ( 20.07)\n",
            "Epoch: [5][ 550/1075]\tTime  0.491 ( 0.646)\tData  0.000 ( 0.271)\tLoss 7.3062e+00 (6.6965e+00)\tAcc@1  59.38 ( 12.62)\tAcc@5  67.19 ( 20.55)\n",
            "Epoch: [5][ 560/1075]\tTime  0.494 ( 0.646)\tData  0.000 ( 0.270)\tLoss 7.2179e+00 (6.7066e+00)\tAcc@1  48.44 ( 12.89)\tAcc@5  59.38 ( 20.80)\n",
            "Epoch: [5][ 570/1075]\tTime  0.664 ( 0.645)\tData  0.373 ( 0.270)\tLoss 7.3518e+00 (6.7165e+00)\tAcc@1  50.00 ( 13.44)\tAcc@5  54.69 ( 21.33)\n",
            "Epoch: [5][ 580/1075]\tTime  0.910 ( 0.645)\tData  0.616 ( 0.271)\tLoss 7.5360e+00 (6.7292e+00)\tAcc@1   9.38 ( 13.75)\tAcc@5  18.75 ( 21.60)\n",
            "Epoch: [5][ 590/1075]\tTime  0.492 ( 0.644)\tData  0.189 ( 0.272)\tLoss 7.6783e+00 (6.7443e+00)\tAcc@1  32.81 ( 14.17)\tAcc@5  37.50 ( 21.98)\n",
            "Epoch: [5][ 600/1075]\tTime  1.036 ( 0.644)\tData  0.741 ( 0.272)\tLoss 7.7526e+00 (6.7605e+00)\tAcc@1  60.94 ( 14.71)\tAcc@5  64.06 ( 22.49)\n",
            "Epoch: [5][ 610/1075]\tTime  0.631 ( 0.644)\tData  0.337 ( 0.272)\tLoss 7.6960e+00 (6.7763e+00)\tAcc@1  62.50 ( 15.18)\tAcc@5  65.62 ( 22.92)\n",
            "Epoch: [5][ 620/1075]\tTime  0.723 ( 0.643)\tData  0.417 ( 0.271)\tLoss 7.6033e+00 (6.7904e+00)\tAcc@1  56.25 ( 15.85)\tAcc@5  57.81 ( 23.52)\n",
            "Epoch: [5][ 630/1075]\tTime  0.746 ( 0.643)\tData  0.437 ( 0.271)\tLoss 7.4567e+00 (6.8020e+00)\tAcc@1  59.38 ( 16.59)\tAcc@5  64.06 ( 24.20)\n",
            "Epoch: [5][ 640/1075]\tTime  0.771 ( 0.643)\tData  0.474 ( 0.270)\tLoss 7.3228e+00 (6.8110e+00)\tAcc@1  54.69 ( 17.23)\tAcc@5  56.25 ( 24.77)\n",
            "Epoch: [5][ 650/1075]\tTime  0.711 ( 0.643)\tData  0.417 ( 0.271)\tLoss 7.1984e+00 (6.8178e+00)\tAcc@1  68.75 ( 17.85)\tAcc@5  70.31 ( 25.36)\n",
            "Epoch: [5][ 660/1075]\tTime  0.597 ( 0.643)\tData  0.305 ( 0.270)\tLoss 7.1421e+00 (6.8227e+00)\tAcc@1  46.88 ( 18.30)\tAcc@5  56.25 ( 25.85)\n",
            "Epoch: [5][ 670/1075]\tTime  0.900 ( 0.643)\tData  0.608 ( 0.270)\tLoss 7.0520e+00 (6.8259e+00)\tAcc@1  12.50 ( 18.65)\tAcc@5  26.56 ( 26.21)\n",
            "Epoch: [5][ 680/1075]\tTime  0.570 ( 0.642)\tData  0.277 ( 0.269)\tLoss 6.9628e+00 (6.8285e+00)\tAcc@1  39.06 ( 18.76)\tAcc@5  45.31 ( 26.28)\n",
            "Epoch: [5][ 690/1075]\tTime  0.998 ( 0.642)\tData  0.701 ( 0.269)\tLoss 6.9822e+00 (6.8309e+00)\tAcc@1  40.62 ( 18.88)\tAcc@5  46.88 ( 26.40)\n",
            "Epoch: [5][ 700/1075]\tTime  0.734 ( 0.641)\tData  0.452 ( 0.269)\tLoss 6.9381e+00 (6.8328e+00)\tAcc@1  29.69 ( 18.99)\tAcc@5  37.50 ( 26.45)\n",
            "Epoch: [5][ 710/1075]\tTime  1.059 ( 0.642)\tData  0.749 ( 0.270)\tLoss 6.8884e+00 (6.8340e+00)\tAcc@1  32.81 ( 19.07)\tAcc@5  37.50 ( 26.48)\n",
            "Epoch: [5][ 720/1075]\tTime  0.611 ( 0.642)\tData  0.317 ( 0.270)\tLoss 6.9041e+00 (6.8349e+00)\tAcc@1  50.00 ( 19.26)\tAcc@5  54.69 ( 26.60)\n",
            "Epoch: [5][ 730/1075]\tTime  0.828 ( 0.641)\tData  0.519 ( 0.269)\tLoss 6.7865e+00 (6.8347e+00)\tAcc@1  39.06 ( 19.51)\tAcc@5  39.06 ( 26.79)\n",
            "Epoch: [5][ 740/1075]\tTime  0.730 ( 0.642)\tData  0.435 ( 0.270)\tLoss 6.6185e+00 (6.8325e+00)\tAcc@1  37.50 ( 19.76)\tAcc@5  37.50 ( 26.99)\n",
            "Epoch: [5][ 750/1075]\tTime  0.781 ( 0.641)\tData  0.487 ( 0.269)\tLoss 6.7905e+00 (6.8308e+00)\tAcc@1  28.12 ( 19.89)\tAcc@5  40.62 ( 27.11)\n",
            "Epoch: [5][ 760/1075]\tTime  0.677 ( 0.642)\tData  0.373 ( 0.270)\tLoss 6.8937e+00 (6.8311e+00)\tAcc@1  10.94 ( 19.85)\tAcc@5  26.56 ( 27.11)\n",
            "Epoch: [5][ 770/1075]\tTime  0.770 ( 0.641)\tData  0.478 ( 0.268)\tLoss 6.7867e+00 (6.8313e+00)\tAcc@1   0.00 ( 19.82)\tAcc@5   4.69 ( 27.07)\n",
            "Epoch: [5][ 780/1075]\tTime  0.756 ( 0.641)\tData  0.463 ( 0.269)\tLoss 6.7481e+00 (6.8309e+00)\tAcc@1  17.19 ( 19.70)\tAcc@5  23.44 ( 26.97)\n",
            "Epoch: [5][ 790/1075]\tTime  0.713 ( 0.641)\tData  0.422 ( 0.268)\tLoss 6.5990e+00 (6.8286e+00)\tAcc@1   4.69 ( 19.61)\tAcc@5  21.88 ( 26.95)\n",
            "Epoch: [5][ 800/1075]\tTime  0.793 ( 0.641)\tData  0.500 ( 0.269)\tLoss 6.2380e+00 (6.8234e+00)\tAcc@1   6.25 ( 19.57)\tAcc@5  23.44 ( 26.97)\n",
            "Epoch: [5][ 810/1075]\tTime  0.507 ( 0.640)\tData  0.187 ( 0.267)\tLoss 6.8677e+00 (6.8206e+00)\tAcc@1   1.56 ( 19.37)\tAcc@5   3.12 ( 26.75)\n",
            "Epoch: [5][ 820/1075]\tTime  0.997 ( 0.640)\tData  0.691 ( 0.268)\tLoss 7.2299e+00 (6.8233e+00)\tAcc@1  17.19 ( 19.29)\tAcc@5  26.56 ( 26.66)\n",
            "Epoch: [5][ 830/1075]\tTime  0.756 ( 0.640)\tData  0.462 ( 0.267)\tLoss 7.4545e+00 (6.8297e+00)\tAcc@1   7.81 ( 19.15)\tAcc@5  20.31 ( 26.55)\n",
            "Epoch: [5][ 840/1075]\tTime  0.985 ( 0.640)\tData  0.678 ( 0.267)\tLoss 7.6342e+00 (6.8384e+00)\tAcc@1   3.12 ( 19.03)\tAcc@5   7.81 ( 26.43)\n",
            "Epoch: [5][ 850/1075]\tTime  0.763 ( 0.640)\tData  0.469 ( 0.267)\tLoss 7.7242e+00 (6.8484e+00)\tAcc@1  23.44 ( 18.93)\tAcc@5  37.50 ( 26.37)\n",
            "Epoch: [5][ 860/1075]\tTime  0.926 ( 0.640)\tData  0.632 ( 0.267)\tLoss 7.7267e+00 (6.8588e+00)\tAcc@1  29.69 ( 18.80)\tAcc@5  45.31 ( 26.23)\n",
            "Epoch: [5][ 870/1075]\tTime  0.774 ( 0.640)\tData  0.479 ( 0.267)\tLoss 7.6483e+00 (6.8686e+00)\tAcc@1  46.88 ( 18.71)\tAcc@5  73.44 ( 26.17)\n",
            "Epoch: [5][ 880/1075]\tTime  0.572 ( 0.639)\tData  0.264 ( 0.266)\tLoss 7.3827e+00 (6.8761e+00)\tAcc@1   3.12 ( 18.66)\tAcc@5   6.25 ( 26.12)\n",
            "Epoch: [5][ 890/1075]\tTime  0.711 ( 0.640)\tData  0.401 ( 0.267)\tLoss 6.3903e+00 (6.8755e+00)\tAcc@1   3.12 ( 18.62)\tAcc@5   4.69 ( 26.11)\n",
            "Epoch: [5][ 900/1075]\tTime  0.814 ( 0.639)\tData  0.503 ( 0.267)\tLoss 5.8975e+00 (6.8638e+00)\tAcc@1   4.69 ( 18.67)\tAcc@5   6.25 ( 26.13)\n",
            "Epoch: [5][ 910/1075]\tTime  0.607 ( 0.640)\tData  0.313 ( 0.267)\tLoss 6.2798e+00 (6.8561e+00)\tAcc@1  25.00 ( 18.66)\tAcc@5  28.12 ( 26.09)\n",
            "Epoch: [5][ 920/1075]\tTime  0.806 ( 0.639)\tData  0.496 ( 0.266)\tLoss 6.4153e+00 (6.8513e+00)\tAcc@1   3.12 ( 18.69)\tAcc@5   9.38 ( 26.12)\n",
            "Epoch: [5][ 930/1075]\tTime  0.808 ( 0.640)\tData  0.511 ( 0.267)\tLoss 6.5997e+00 (6.8474e+00)\tAcc@1  45.31 ( 18.75)\tAcc@5  57.81 ( 26.17)\n",
            "Epoch: [5][ 940/1075]\tTime  0.732 ( 0.639)\tData  0.439 ( 0.266)\tLoss 6.8676e+00 (6.8465e+00)\tAcc@1  45.31 ( 18.86)\tAcc@5  50.00 ( 26.28)\n",
            "Epoch: [5][ 950/1075]\tTime  0.755 ( 0.640)\tData  0.447 ( 0.266)\tLoss 6.9626e+00 (6.8475e+00)\tAcc@1  17.19 ( 19.02)\tAcc@5  34.38 ( 26.45)\n",
            "Epoch: [5][ 960/1075]\tTime  0.695 ( 0.639)\tData  0.403 ( 0.266)\tLoss 6.9597e+00 (6.8484e+00)\tAcc@1  50.00 ( 19.27)\tAcc@5  56.25 ( 26.69)\n",
            "Epoch: [5][ 970/1075]\tTime  0.818 ( 0.640)\tData  0.527 ( 0.266)\tLoss 6.9441e+00 (6.8485e+00)\tAcc@1  39.06 ( 19.50)\tAcc@5  46.88 ( 26.92)\n",
            "Epoch: [5][ 980/1075]\tTime  0.519 ( 0.639)\tData  0.226 ( 0.266)\tLoss 6.7448e+00 (6.8466e+00)\tAcc@1  15.62 ( 19.62)\tAcc@5  32.81 ( 27.10)\n",
            "Epoch: [5][ 990/1075]\tTime  0.837 ( 0.639)\tData  0.524 ( 0.266)\tLoss 6.7415e+00 (6.8454e+00)\tAcc@1  10.94 ( 19.61)\tAcc@5  34.38 ( 27.16)\n",
            "Epoch: [5][1000/1075]\tTime  0.679 ( 0.639)\tData  0.385 ( 0.265)\tLoss 7.0210e+00 (6.8464e+00)\tAcc@1  26.56 ( 19.60)\tAcc@5  34.38 ( 27.15)\n",
            "Epoch: [5][1010/1075]\tTime  0.760 ( 0.638)\tData  0.467 ( 0.265)\tLoss 5.5609e+00 (6.8399e+00)\tAcc@1  35.94 ( 19.69)\tAcc@5  40.62 ( 27.32)\n",
            "Epoch: [5][1020/1075]\tTime  0.494 ( 0.638)\tData  0.071 ( 0.265)\tLoss 5.9550e+00 (6.8287e+00)\tAcc@1  34.38 ( 19.72)\tAcc@5  40.62 ( 27.32)\n",
            "Epoch: [5][1030/1075]\tTime  0.728 ( 0.638)\tData  0.435 ( 0.265)\tLoss 6.4175e+00 (6.8226e+00)\tAcc@1  14.06 ( 19.73)\tAcc@5  23.44 ( 27.30)\n",
            "Epoch: [5][1040/1075]\tTime  0.629 ( 0.638)\tData  0.335 ( 0.265)\tLoss 6.6593e+00 (6.8194e+00)\tAcc@1  15.62 ( 19.68)\tAcc@5  20.31 ( 27.23)\n",
            "Epoch: [5][1050/1075]\tTime  0.706 ( 0.638)\tData  0.413 ( 0.265)\tLoss 6.8554e+00 (6.8188e+00)\tAcc@1   7.81 ( 19.59)\tAcc@5  14.06 ( 27.14)\n",
            "Epoch: [5][1060/1075]\tTime  0.805 ( 0.638)\tData  0.498 ( 0.265)\tLoss 6.6295e+00 (6.8179e+00)\tAcc@1  29.69 ( 19.61)\tAcc@5  50.00 ( 27.17)\n",
            "Epoch: [5][1070/1075]\tTime  0.576 ( 0.637)\tData  0.282 ( 0.265)\tLoss 6.4773e+00 (6.8154e+00)\tAcc@1   0.00 ( 19.60)\tAcc@5   1.56 ( 27.17)\n",
            "epoch: 5\n",
            "2023-04-19 12:57:05.154743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 12:57:09.806678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [6][   0/1075]\tTime 10.930 (10.930)\tData 10.619 (10.619)\tLoss 6.3646e+00 (6.3646e+00)\tAcc@1   3.12 (  3.12)\tAcc@5   7.81 (  7.81)\n",
            "Epoch: [6][  10/1075]\tTime  0.613 ( 1.614)\tData  0.321 ( 1.241)\tLoss 6.6181e+00 (6.4884e+00)\tAcc@1  37.50 ( 24.57)\tAcc@5  40.62 ( 30.54)\n",
            "Epoch: [6][  20/1075]\tTime  0.621 ( 1.119)\tData  0.328 ( 0.743)\tLoss 4.6583e+00 (6.4117e+00)\tAcc@1  48.44 ( 28.20)\tAcc@5  98.44 ( 40.10)\n",
            "Epoch: [6][  30/1075]\tTime  0.766 ( 0.985)\tData  0.473 ( 0.610)\tLoss 6.3131e+00 (6.1537e+00)\tAcc@1   3.12 ( 28.02)\tAcc@5   9.38 ( 37.85)\n",
            "Epoch: [6][  40/1075]\tTime  0.810 ( 0.889)\tData  0.505 ( 0.513)\tLoss 6.4036e+00 (6.2805e+00)\tAcc@1  20.31 ( 24.66)\tAcc@5  21.88 ( 33.12)\n",
            "Epoch: [6][  50/1075]\tTime  0.889 ( 0.840)\tData  0.578 ( 0.464)\tLoss 6.7674e+00 (6.3753e+00)\tAcc@1   1.56 ( 21.35)\tAcc@5   6.25 ( 28.86)\n",
            "Epoch: [6][  60/1075]\tTime  0.680 ( 0.798)\tData  0.389 ( 0.422)\tLoss 6.2680e+00 (6.3736e+00)\tAcc@1   1.56 ( 20.31)\tAcc@5  12.50 ( 28.87)\n",
            "Epoch: [6][  70/1075]\tTime  0.892 ( 0.775)\tData  0.593 ( 0.399)\tLoss 6.6581e+00 (6.3961e+00)\tAcc@1   7.81 ( 18.68)\tAcc@5  15.62 ( 27.31)\n",
            "Epoch: [6][  80/1075]\tTime  0.618 ( 0.757)\tData  0.323 ( 0.381)\tLoss 6.4405e+00 (6.4147e+00)\tAcc@1  12.50 ( 17.52)\tAcc@5  29.69 ( 26.54)\n",
            "Epoch: [6][  90/1075]\tTime  0.893 ( 0.743)\tData  0.585 ( 0.367)\tLoss 6.3775e+00 (6.4307e+00)\tAcc@1   9.38 ( 16.33)\tAcc@5  26.56 ( 25.81)\n",
            "Epoch: [6][ 100/1075]\tTime  0.714 ( 0.733)\tData  0.421 ( 0.356)\tLoss 6.2013e+00 (6.4172e+00)\tAcc@1  12.50 ( 16.06)\tAcc@5  20.31 ( 25.76)\n",
            "Epoch: [6][ 110/1075]\tTime  0.720 ( 0.719)\tData  0.429 ( 0.342)\tLoss 6.0005e+00 (6.3964e+00)\tAcc@1  21.88 ( 15.85)\tAcc@5  26.56 ( 25.66)\n",
            "Epoch: [6][ 120/1075]\tTime  0.731 ( 0.717)\tData  0.438 ( 0.340)\tLoss 5.8907e+00 (6.3365e+00)\tAcc@1  10.94 ( 15.95)\tAcc@5  20.31 ( 25.77)\n",
            "Epoch: [6][ 130/1075]\tTime  0.701 ( 0.709)\tData  0.393 ( 0.331)\tLoss 6.3700e+00 (6.3205e+00)\tAcc@1   4.69 ( 15.51)\tAcc@5  10.94 ( 25.42)\n",
            "Epoch: [6][ 140/1075]\tTime  0.726 ( 0.705)\tData  0.433 ( 0.327)\tLoss 6.5977e+00 (6.3309e+00)\tAcc@1  18.75 ( 15.64)\tAcc@5  20.31 ( 25.60)\n",
            "Epoch: [6][ 150/1075]\tTime  0.604 ( 0.694)\tData  0.311 ( 0.316)\tLoss 6.5271e+00 (6.3486e+00)\tAcc@1  12.50 ( 15.38)\tAcc@5  21.88 ( 25.35)\n",
            "Epoch: [6][ 160/1075]\tTime  0.625 ( 0.690)\tData  0.331 ( 0.317)\tLoss 6.4122e+00 (6.3270e+00)\tAcc@1   9.38 ( 15.34)\tAcc@5  14.06 ( 25.37)\n",
            "Epoch: [6][ 170/1075]\tTime  0.525 ( 0.684)\tData  0.215 ( 0.312)\tLoss 6.6393e+00 (6.3430e+00)\tAcc@1   1.56 ( 14.69)\tAcc@5  12.50 ( 24.50)\n",
            "Epoch: [6][ 180/1075]\tTime  0.748 ( 0.680)\tData  0.450 ( 0.312)\tLoss 6.3822e+00 (6.3496e+00)\tAcc@1   3.12 ( 14.39)\tAcc@5  10.94 ( 24.21)\n",
            "Epoch: [6][ 190/1075]\tTime  0.731 ( 0.677)\tData  0.437 ( 0.311)\tLoss 6.6743e+00 (6.3644e+00)\tAcc@1   9.38 ( 14.01)\tAcc@5  21.88 ( 23.75)\n",
            "Epoch: [6][ 200/1075]\tTime  0.562 ( 0.671)\tData  0.251 ( 0.308)\tLoss 6.3662e+00 (6.3744e+00)\tAcc@1   6.25 ( 13.76)\tAcc@5  15.62 ( 23.44)\n",
            "Epoch: [6][ 210/1075]\tTime  0.555 ( 0.671)\tData  0.261 ( 0.309)\tLoss 6.1670e+00 (6.3649e+00)\tAcc@1  12.50 ( 13.76)\tAcc@5  20.31 ( 23.42)\n",
            "Epoch: [6][ 220/1075]\tTime  0.492 ( 0.667)\tData  0.198 ( 0.307)\tLoss 6.3565e+00 (6.3611e+00)\tAcc@1  15.62 ( 13.65)\tAcc@5  23.44 ( 23.25)\n",
            "Epoch: [6][ 230/1075]\tTime  0.594 ( 0.666)\tData  0.303 ( 0.309)\tLoss 6.2825e+00 (6.3625e+00)\tAcc@1  15.62 ( 13.53)\tAcc@5  25.00 ( 23.09)\n",
            "Epoch: [6][ 240/1075]\tTime  0.669 ( 0.662)\tData  0.377 ( 0.306)\tLoss 6.4196e+00 (6.3602e+00)\tAcc@1   9.38 ( 13.36)\tAcc@5  17.19 ( 22.89)\n",
            "Epoch: [6][ 250/1075]\tTime  0.562 ( 0.663)\tData  0.253 ( 0.307)\tLoss 6.8925e+00 (6.3744e+00)\tAcc@1   7.81 ( 13.18)\tAcc@5  10.94 ( 22.59)\n",
            "Epoch: [6][ 260/1075]\tTime  0.640 ( 0.661)\tData  0.331 ( 0.305)\tLoss 7.0858e+00 (6.3989e+00)\tAcc@1   3.12 ( 12.98)\tAcc@5   9.38 ( 22.27)\n",
            "Epoch: [6][ 270/1075]\tTime  0.799 ( 0.662)\tData  0.505 ( 0.305)\tLoss 6.9380e+00 (6.4221e+00)\tAcc@1   9.38 ( 12.82)\tAcc@5  14.06 ( 22.02)\n",
            "Epoch: [6][ 280/1075]\tTime  0.596 ( 0.659)\tData  0.286 ( 0.302)\tLoss 6.6543e+00 (6.4321e+00)\tAcc@1  14.06 ( 12.99)\tAcc@5  18.75 ( 22.10)\n",
            "Epoch: [6][ 290/1075]\tTime  0.892 ( 0.660)\tData  0.601 ( 0.301)\tLoss 6.7617e+00 (6.4389e+00)\tAcc@1  21.88 ( 13.05)\tAcc@5  29.69 ( 22.23)\n",
            "Epoch: [6][ 300/1075]\tTime  0.792 ( 0.658)\tData  0.500 ( 0.299)\tLoss 7.2456e+00 (6.4539e+00)\tAcc@1  10.94 ( 12.96)\tAcc@5  14.06 ( 22.11)\n",
            "Epoch: [6][ 310/1075]\tTime  0.866 ( 0.658)\tData  0.550 ( 0.298)\tLoss 6.0210e+00 (6.4715e+00)\tAcc@1  23.44 ( 12.91)\tAcc@5  32.81 ( 22.00)\n",
            "Epoch: [6][ 320/1075]\tTime  0.883 ( 0.657)\tData  0.592 ( 0.297)\tLoss 6.5897e+00 (6.4469e+00)\tAcc@1   9.38 ( 13.34)\tAcc@5  21.88 ( 22.58)\n",
            "Epoch: [6][ 330/1075]\tTime  0.865 ( 0.657)\tData  0.550 ( 0.296)\tLoss 6.2340e+00 (6.4371e+00)\tAcc@1   3.12 ( 13.37)\tAcc@5   3.12 ( 22.65)\n",
            "Epoch: [6][ 340/1075]\tTime  0.752 ( 0.656)\tData  0.457 ( 0.295)\tLoss 6.5027e+00 (6.4399e+00)\tAcc@1   3.12 ( 13.15)\tAcc@5  15.62 ( 22.44)\n",
            "Epoch: [6][ 350/1075]\tTime  0.728 ( 0.655)\tData  0.435 ( 0.293)\tLoss 6.0562e+00 (6.4377e+00)\tAcc@1  18.75 ( 13.13)\tAcc@5  25.00 ( 22.43)\n",
            "Epoch: [6][ 360/1075]\tTime  0.600 ( 0.655)\tData  0.293 ( 0.293)\tLoss 6.3400e+00 (6.4304e+00)\tAcc@1  17.19 ( 13.04)\tAcc@5  28.12 ( 22.29)\n",
            "Epoch: [6][ 370/1075]\tTime  0.555 ( 0.654)\tData  0.261 ( 0.291)\tLoss 6.8605e+00 (6.4390e+00)\tAcc@1   7.81 ( 12.85)\tAcc@5  15.62 ( 22.05)\n",
            "Epoch: [6][ 380/1075]\tTime  0.505 ( 0.654)\tData  0.213 ( 0.290)\tLoss 6.9651e+00 (6.4537e+00)\tAcc@1   1.56 ( 12.77)\tAcc@5   7.81 ( 21.91)\n",
            "Epoch: [6][ 390/1075]\tTime  0.754 ( 0.653)\tData  0.443 ( 0.289)\tLoss 6.7815e+00 (6.4656e+00)\tAcc@1   1.56 ( 12.77)\tAcc@5  23.44 ( 21.99)\n",
            "Epoch: [6][ 400/1075]\tTime  0.804 ( 0.654)\tData  0.499 ( 0.290)\tLoss 6.2237e+00 (6.4652e+00)\tAcc@1  32.81 ( 12.92)\tAcc@5  45.31 ( 22.30)\n",
            "Epoch: [6][ 410/1075]\tTime  0.768 ( 0.653)\tData  0.473 ( 0.288)\tLoss 6.1102e+00 (6.4594e+00)\tAcc@1  32.81 ( 13.11)\tAcc@5  45.31 ( 22.68)\n",
            "Epoch: [6][ 420/1075]\tTime  0.724 ( 0.653)\tData  0.432 ( 0.288)\tLoss 6.2951e+00 (6.4563e+00)\tAcc@1  10.94 ( 13.18)\tAcc@5  26.56 ( 22.76)\n",
            "Epoch: [6][ 430/1075]\tTime  0.615 ( 0.652)\tData  0.305 ( 0.286)\tLoss 5.7260e+00 (6.4347e+00)\tAcc@1  10.94 ( 13.28)\tAcc@5  21.88 ( 22.95)\n",
            "Epoch: [6][ 440/1075]\tTime  1.000 ( 0.652)\tData  0.690 ( 0.287)\tLoss 6.3133e+00 (6.4264e+00)\tAcc@1   4.69 ( 13.24)\tAcc@5  15.62 ( 22.95)\n",
            "Epoch: [6][ 450/1075]\tTime  0.934 ( 0.651)\tData  0.626 ( 0.287)\tLoss 6.7338e+00 (6.4305e+00)\tAcc@1   4.69 ( 13.13)\tAcc@5  12.50 ( 22.80)\n",
            "Epoch: [6][ 460/1075]\tTime  0.939 ( 0.652)\tData  0.647 ( 0.287)\tLoss 6.9583e+00 (6.4403e+00)\tAcc@1  10.94 ( 13.07)\tAcc@5  18.75 ( 22.72)\n",
            "Epoch: [6][ 470/1075]\tTime  0.730 ( 0.651)\tData  0.421 ( 0.286)\tLoss 6.7103e+00 (6.4491e+00)\tAcc@1  34.38 ( 13.32)\tAcc@5  35.94 ( 22.96)\n",
            "Epoch: [6][ 480/1075]\tTime  1.112 ( 0.651)\tData  0.807 ( 0.286)\tLoss 5.9778e+00 (6.4461e+00)\tAcc@1  56.25 ( 13.93)\tAcc@5  64.06 ( 23.55)\n",
            "Epoch: [6][ 490/1075]\tTime  0.581 ( 0.651)\tData  0.271 ( 0.285)\tLoss 6.3683e+00 (6.4414e+00)\tAcc@1  15.62 ( 14.43)\tAcc@5  23.44 ( 24.02)\n",
            "Epoch: [6][ 500/1075]\tTime  0.824 ( 0.649)\tData  0.515 ( 0.283)\tLoss 6.3651e+00 (6.4461e+00)\tAcc@1  18.75 ( 14.41)\tAcc@5  28.12 ( 23.97)\n",
            "Epoch: [6][ 510/1075]\tTime  0.765 ( 0.649)\tData  0.456 ( 0.283)\tLoss 6.4189e+00 (6.4461e+00)\tAcc@1  25.00 ( 14.52)\tAcc@5  32.81 ( 24.06)\n",
            "Epoch: [6][ 520/1075]\tTime  0.717 ( 0.648)\tData  0.423 ( 0.281)\tLoss 6.2667e+00 (6.4417e+00)\tAcc@1  14.06 ( 14.58)\tAcc@5  23.44 ( 24.06)\n",
            "Epoch: [6][ 530/1075]\tTime  0.621 ( 0.648)\tData  0.326 ( 0.282)\tLoss 5.5394e+00 (6.4321e+00)\tAcc@1  18.75 ( 14.55)\tAcc@5  23.44 ( 23.98)\n",
            "Epoch: [6][ 540/1075]\tTime  0.772 ( 0.648)\tData  0.482 ( 0.281)\tLoss 6.4665e+00 (6.4256e+00)\tAcc@1   1.56 ( 14.39)\tAcc@5  14.06 ( 23.80)\n",
            "Epoch: [6][ 550/1075]\tTime  0.645 ( 0.649)\tData  0.334 ( 0.281)\tLoss 6.7631e+00 (6.4293e+00)\tAcc@1   4.69 ( 14.28)\tAcc@5  15.62 ( 23.64)\n",
            "Epoch: [6][ 560/1075]\tTime  0.772 ( 0.648)\tData  0.479 ( 0.280)\tLoss 6.9358e+00 (6.4369e+00)\tAcc@1  10.94 ( 14.19)\tAcc@5  14.06 ( 23.51)\n",
            "Epoch: [6][ 570/1075]\tTime  0.682 ( 0.648)\tData  0.389 ( 0.280)\tLoss 7.0418e+00 (6.4467e+00)\tAcc@1  14.06 ( 14.08)\tAcc@5  18.75 ( 23.36)\n",
            "Epoch: [6][ 580/1075]\tTime  0.540 ( 0.647)\tData  0.248 ( 0.279)\tLoss 6.4399e+00 (6.4517e+00)\tAcc@1  17.19 ( 14.19)\tAcc@5  25.00 ( 23.42)\n",
            "Epoch: [6][ 590/1075]\tTime  0.986 ( 0.647)\tData  0.675 ( 0.279)\tLoss 5.7272e+00 (6.4458e+00)\tAcc@1  39.06 ( 14.49)\tAcc@5  40.62 ( 23.70)\n",
            "Epoch: [6][ 600/1075]\tTime  0.758 ( 0.646)\tData  0.467 ( 0.278)\tLoss 6.5436e+00 (6.4421e+00)\tAcc@1   6.25 ( 14.39)\tAcc@5  18.75 ( 23.61)\n",
            "Epoch: [6][ 610/1075]\tTime  1.110 ( 0.647)\tData  0.819 ( 0.279)\tLoss 6.9285e+00 (6.4464e+00)\tAcc@1   1.56 ( 14.35)\tAcc@5   3.12 ( 23.52)\n",
            "Epoch: [6][ 620/1075]\tTime  0.837 ( 0.647)\tData  0.529 ( 0.279)\tLoss 6.6349e+00 (6.4517e+00)\tAcc@1  26.56 ( 14.28)\tAcc@5  39.06 ( 23.41)\n",
            "Epoch: [6][ 630/1075]\tTime  0.841 ( 0.646)\tData  0.541 ( 0.278)\tLoss 6.8441e+00 (6.4564e+00)\tAcc@1  20.31 ( 14.24)\tAcc@5  31.25 ( 23.33)\n",
            "Epoch: [6][ 640/1075]\tTime  0.785 ( 0.647)\tData  0.491 ( 0.279)\tLoss 7.0902e+00 (6.4642e+00)\tAcc@1   3.12 ( 14.35)\tAcc@5   9.38 ( 23.51)\n",
            "Epoch: [6][ 650/1075]\tTime  1.078 ( 0.647)\tData  0.768 ( 0.279)\tLoss 7.2221e+00 (6.4750e+00)\tAcc@1  37.50 ( 14.29)\tAcc@5  79.69 ( 23.49)\n",
            "Epoch: [6][ 660/1075]\tTime  0.657 ( 0.648)\tData  0.365 ( 0.280)\tLoss 7.2751e+00 (6.4870e+00)\tAcc@1   7.81 ( 14.21)\tAcc@5  21.88 ( 23.44)\n",
            "Epoch: [6][ 670/1075]\tTime  0.651 ( 0.647)\tData  0.350 ( 0.279)\tLoss 6.5216e+00 (6.4930e+00)\tAcc@1  12.50 ( 14.15)\tAcc@5  18.75 ( 23.42)\n",
            "Epoch: [6][ 680/1075]\tTime  0.620 ( 0.648)\tData  0.311 ( 0.279)\tLoss 6.6221e+00 (6.4924e+00)\tAcc@1   3.12 ( 14.07)\tAcc@5   6.25 ( 23.30)\n",
            "Epoch: [6][ 690/1075]\tTime  0.593 ( 0.647)\tData  0.299 ( 0.278)\tLoss 6.7585e+00 (6.4942e+00)\tAcc@1   1.56 ( 13.92)\tAcc@5   6.25 ( 23.11)\n",
            "Epoch: [6][ 700/1075]\tTime  0.807 ( 0.648)\tData  0.498 ( 0.279)\tLoss 6.5510e+00 (6.4947e+00)\tAcc@1   9.38 ( 13.79)\tAcc@5  10.94 ( 22.95)\n",
            "Epoch: [6][ 710/1075]\tTime  0.762 ( 0.648)\tData  0.468 ( 0.278)\tLoss 6.6644e+00 (6.4964e+00)\tAcc@1   1.56 ( 13.64)\tAcc@5   6.25 ( 22.79)\n",
            "Epoch: [6][ 720/1075]\tTime  0.804 ( 0.648)\tData  0.491 ( 0.279)\tLoss 6.8171e+00 (6.5000e+00)\tAcc@1   6.25 ( 13.49)\tAcc@5  20.31 ( 22.61)\n",
            "Epoch: [6][ 730/1075]\tTime  0.661 ( 0.648)\tData  0.349 ( 0.279)\tLoss 7.0370e+00 (6.5059e+00)\tAcc@1   9.38 ( 13.35)\tAcc@5  17.19 ( 22.48)\n",
            "Epoch: [6][ 740/1075]\tTime  0.684 ( 0.648)\tData  0.390 ( 0.279)\tLoss 7.2254e+00 (6.5145e+00)\tAcc@1  14.06 ( 13.34)\tAcc@5  25.00 ( 22.49)\n",
            "Epoch: [6][ 750/1075]\tTime  0.813 ( 0.648)\tData  0.519 ( 0.279)\tLoss 6.8760e+00 (6.5203e+00)\tAcc@1  10.94 ( 13.34)\tAcc@5  18.75 ( 22.51)\n",
            "Epoch: [6][ 760/1075]\tTime  0.709 ( 0.649)\tData  0.417 ( 0.279)\tLoss 6.7459e+00 (6.5219e+00)\tAcc@1  23.44 ( 13.29)\tAcc@5  39.06 ( 22.47)\n",
            "Epoch: [6][ 770/1075]\tTime  0.624 ( 0.648)\tData  0.328 ( 0.278)\tLoss 5.9386e+00 (6.5223e+00)\tAcc@1  34.38 ( 13.28)\tAcc@5  62.50 ( 22.48)\n",
            "Epoch: [6][ 780/1075]\tTime  0.874 ( 0.649)\tData  0.584 ( 0.278)\tLoss 6.4296e+00 (6.5177e+00)\tAcc@1  10.94 ( 13.28)\tAcc@5  17.19 ( 22.47)\n",
            "Epoch: [6][ 790/1075]\tTime  0.738 ( 0.648)\tData  0.431 ( 0.278)\tLoss 6.8244e+00 (6.5195e+00)\tAcc@1   3.12 ( 13.21)\tAcc@5  10.94 ( 22.38)\n",
            "Epoch: [6][ 800/1075]\tTime  0.640 ( 0.649)\tData  0.339 ( 0.278)\tLoss 6.3494e+00 (6.5215e+00)\tAcc@1  12.50 ( 13.19)\tAcc@5  26.56 ( 22.36)\n",
            "Epoch: [6][ 810/1075]\tTime  0.578 ( 0.648)\tData  0.283 ( 0.277)\tLoss 6.1246e+00 (6.5159e+00)\tAcc@1   7.81 ( 13.18)\tAcc@5  29.69 ( 22.45)\n",
            "Epoch: [6][ 820/1075]\tTime  1.008 ( 0.649)\tData  0.698 ( 0.278)\tLoss 6.3371e+00 (6.5136e+00)\tAcc@1  18.75 ( 13.15)\tAcc@5  35.94 ( 22.44)\n",
            "Epoch: [6][ 830/1075]\tTime  0.677 ( 0.648)\tData  0.369 ( 0.277)\tLoss 6.5470e+00 (6.5127e+00)\tAcc@1  18.75 ( 13.07)\tAcc@5  21.88 ( 22.36)\n",
            "Epoch: [6][ 840/1075]\tTime  1.055 ( 0.649)\tData  0.756 ( 0.278)\tLoss 6.3264e+00 (6.5109e+00)\tAcc@1   9.38 ( 13.03)\tAcc@5  14.06 ( 22.31)\n",
            "Epoch: [6][ 850/1075]\tTime  0.706 ( 0.649)\tData  0.399 ( 0.278)\tLoss 6.6432e+00 (6.5116e+00)\tAcc@1   6.25 ( 12.98)\tAcc@5  18.75 ( 22.21)\n",
            "Epoch: [6][ 860/1075]\tTime  1.147 ( 0.649)\tData  0.830 ( 0.278)\tLoss 7.0799e+00 (6.5149e+00)\tAcc@1  12.50 ( 12.98)\tAcc@5  15.62 ( 22.17)\n",
            "Epoch: [6][ 870/1075]\tTime  0.595 ( 0.649)\tData  0.301 ( 0.277)\tLoss 6.9794e+00 (6.5214e+00)\tAcc@1  14.06 ( 12.94)\tAcc@5  20.31 ( 22.14)\n",
            "Epoch: [6][ 880/1075]\tTime  0.884 ( 0.648)\tData  0.582 ( 0.277)\tLoss 6.5053e+00 (6.5261e+00)\tAcc@1   4.69 ( 12.90)\tAcc@5  15.62 ( 22.12)\n",
            "Epoch: [6][ 890/1075]\tTime  0.636 ( 0.648)\tData  0.319 ( 0.277)\tLoss 6.5005e+00 (6.5254e+00)\tAcc@1   4.69 ( 12.82)\tAcc@5  10.94 ( 22.03)\n",
            "Epoch: [6][ 900/1075]\tTime  0.630 ( 0.648)\tData  0.329 ( 0.277)\tLoss 6.8640e+00 (6.5254e+00)\tAcc@1   3.12 ( 12.69)\tAcc@5   6.25 ( 21.86)\n",
            "Epoch: [6][ 910/1075]\tTime  0.494 ( 0.648)\tData  0.000 ( 0.277)\tLoss 6.6798e+00 (6.5279e+00)\tAcc@1   6.25 ( 12.59)\tAcc@5  10.94 ( 21.73)\n",
            "Epoch: [6][ 920/1075]\tTime  0.616 ( 0.647)\tData  0.322 ( 0.277)\tLoss 7.2534e+00 (6.5328e+00)\tAcc@1   3.12 ( 12.48)\tAcc@5  10.94 ( 21.58)\n",
            "Epoch: [6][ 930/1075]\tTime  0.493 ( 0.647)\tData  0.150 ( 0.278)\tLoss 6.9308e+00 (6.5380e+00)\tAcc@1   1.56 ( 12.38)\tAcc@5  12.50 ( 21.45)\n",
            "Epoch: [6][ 940/1075]\tTime  0.492 ( 0.647)\tData  0.084 ( 0.277)\tLoss 6.8321e+00 (6.5422e+00)\tAcc@1   4.69 ( 12.29)\tAcc@5   9.38 ( 21.33)\n",
            "Epoch: [6][ 950/1075]\tTime  0.675 ( 0.647)\tData  0.384 ( 0.278)\tLoss 6.7269e+00 (6.5444e+00)\tAcc@1   3.12 ( 12.20)\tAcc@5   9.38 ( 21.23)\n",
            "Epoch: [6][ 960/1075]\tTime  0.491 ( 0.646)\tData  0.000 ( 0.278)\tLoss 6.5373e+00 (6.5463e+00)\tAcc@1   7.81 ( 12.11)\tAcc@5  15.62 ( 21.14)\n",
            "Epoch: [6][ 970/1075]\tTime  0.495 ( 0.647)\tData  0.000 ( 0.277)\tLoss 6.1907e+00 (6.5449e+00)\tAcc@1  40.62 ( 12.09)\tAcc@5  42.19 ( 21.13)\n",
            "Epoch: [6][ 980/1075]\tTime  0.509 ( 0.646)\tData  0.029 ( 0.277)\tLoss 6.2716e+00 (6.5400e+00)\tAcc@1  12.50 ( 12.07)\tAcc@5  18.75 ( 21.13)\n",
            "Epoch: [6][ 990/1075]\tTime  0.742 ( 0.646)\tData  0.443 ( 0.277)\tLoss 6.9875e+00 (6.5411e+00)\tAcc@1   0.00 ( 11.99)\tAcc@5   9.38 ( 21.04)\n",
            "Epoch: [6][1000/1075]\tTime  0.576 ( 0.646)\tData  0.267 ( 0.277)\tLoss 7.0427e+00 (6.5448e+00)\tAcc@1   4.69 ( 11.92)\tAcc@5  20.31 ( 21.00)\n",
            "Epoch: [6][1010/1075]\tTime  0.876 ( 0.645)\tData  0.576 ( 0.277)\tLoss 6.0402e+00 (6.5445e+00)\tAcc@1  18.75 ( 12.00)\tAcc@5  40.62 ( 21.15)\n",
            "Epoch: [6][1020/1075]\tTime  0.678 ( 0.646)\tData  0.385 ( 0.278)\tLoss 6.5240e+00 (6.5423e+00)\tAcc@1  10.94 ( 11.96)\tAcc@5  21.88 ( 21.13)\n",
            "Epoch: [6][1030/1075]\tTime  0.611 ( 0.645)\tData  0.314 ( 0.277)\tLoss 7.0412e+00 (6.5449e+00)\tAcc@1   6.25 ( 11.92)\tAcc@5  17.19 ( 21.08)\n",
            "Epoch: [6][1040/1075]\tTime  0.507 ( 0.645)\tData  0.000 ( 0.278)\tLoss 6.8678e+00 (6.5490e+00)\tAcc@1  14.06 ( 11.87)\tAcc@5  21.88 ( 21.00)\n",
            "Epoch: [6][1050/1075]\tTime  0.482 ( 0.645)\tData  0.000 ( 0.277)\tLoss 6.8868e+00 (6.5530e+00)\tAcc@1   3.12 ( 11.81)\tAcc@5  10.94 ( 20.92)\n",
            "Epoch: [6][1060/1075]\tTime  0.496 ( 0.645)\tData  0.117 ( 0.278)\tLoss 6.6926e+00 (6.5557e+00)\tAcc@1   3.12 ( 11.74)\tAcc@5   9.38 ( 20.85)\n",
            "Epoch: [6][1070/1075]\tTime  0.511 ( 0.644)\tData  0.000 ( 0.277)\tLoss 6.6822e+00 (6.5562e+00)\tAcc@1   1.56 ( 11.66)\tAcc@5   3.12 ( 20.75)\n",
            "epoch: 6\n",
            "2023-04-19 13:08:39.431484: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 13:08:44.153826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [7][   0/1075]\tTime 11.058 (11.058)\tData 10.745 (10.745)\tLoss 6.6185e+00 (6.6185e+00)\tAcc@1   4.69 (  4.69)\tAcc@5   6.25 (  6.25)\n",
            "Epoch: [7][  10/1075]\tTime  0.824 ( 1.650)\tData  0.531 ( 1.279)\tLoss 6.8708e+00 (6.8356e+00)\tAcc@1   0.00 (  2.70)\tAcc@5   3.12 (  7.81)\n",
            "Epoch: [7][  20/1075]\tTime  0.981 ( 1.177)\tData  0.676 ( 0.805)\tLoss 6.6639e+00 (6.8279e+00)\tAcc@1   6.25 (  3.05)\tAcc@5  14.06 (  9.75)\n",
            "Epoch: [7][  30/1075]\tTime  0.637 ( 1.009)\tData  0.328 ( 0.635)\tLoss 6.8737e+00 (6.8131e+00)\tAcc@1   9.38 (  3.63)\tAcc@5  15.62 ( 10.43)\n",
            "Epoch: [7][  40/1075]\tTime  0.750 ( 0.909)\tData  0.461 ( 0.534)\tLoss 6.9222e+00 (6.8386e+00)\tAcc@1   4.69 (  3.58)\tAcc@5  12.50 ( 10.56)\n",
            "Epoch: [7][  50/1075]\tTime  0.756 ( 0.863)\tData  0.463 ( 0.487)\tLoss 6.9639e+00 (6.8687e+00)\tAcc@1  10.94 (  3.74)\tAcc@5  25.00 ( 11.15)\n",
            "Epoch: [7][  60/1075]\tTime  0.683 ( 0.820)\tData  0.375 ( 0.443)\tLoss 7.1327e+00 (6.8988e+00)\tAcc@1   1.56 (  3.64)\tAcc@5   9.38 ( 10.84)\n",
            "Epoch: [7][  70/1075]\tTime  0.603 ( 0.798)\tData  0.294 ( 0.420)\tLoss 6.9131e+00 (6.9195e+00)\tAcc@1   3.12 (  3.68)\tAcc@5  10.94 ( 10.85)\n",
            "Epoch: [7][  80/1075]\tTime  0.715 ( 0.775)\tData  0.421 ( 0.397)\tLoss 7.4000e+00 (6.9255e+00)\tAcc@1   3.12 (  3.74)\tAcc@5  17.19 ( 11.01)\n",
            "Epoch: [7][  90/1075]\tTime  0.839 ( 0.764)\tData  0.546 ( 0.386)\tLoss 8.5697e+00 (6.9443e+00)\tAcc@1   3.12 (  4.05)\tAcc@5  10.94 ( 11.40)\n",
            "Epoch: [7][ 100/1075]\tTime  0.580 ( 0.746)\tData  0.288 ( 0.367)\tLoss 7.3335e+00 (6.9615e+00)\tAcc@1   0.00 (  3.87)\tAcc@5   1.56 ( 10.91)\n",
            "Epoch: [7][ 110/1075]\tTime  1.059 ( 0.741)\tData  0.750 ( 0.363)\tLoss 7.1209e+00 (6.9766e+00)\tAcc@1   6.25 (  3.80)\tAcc@5   9.38 ( 10.66)\n",
            "Epoch: [7][ 120/1075]\tTime  0.724 ( 0.729)\tData  0.426 ( 0.350)\tLoss 6.5125e+00 (6.9786e+00)\tAcc@1   1.56 (  3.82)\tAcc@5  14.06 ( 10.74)\n",
            "Epoch: [7][ 130/1075]\tTime  0.950 ( 0.725)\tData  0.642 ( 0.345)\tLoss 6.2776e+00 (6.9444e+00)\tAcc@1   4.69 (  3.89)\tAcc@5  17.19 ( 10.96)\n",
            "Epoch: [7][ 140/1075]\tTime  0.725 ( 0.720)\tData  0.430 ( 0.340)\tLoss 6.1717e+00 (6.8886e+00)\tAcc@1  12.50 (  4.19)\tAcc@5  23.44 ( 11.50)\n",
            "Epoch: [7][ 150/1075]\tTime  1.065 ( 0.714)\tData  0.761 ( 0.335)\tLoss 6.8067e+00 (6.8728e+00)\tAcc@1   6.25 (  4.01)\tAcc@5  14.06 ( 11.29)\n",
            "Epoch: [7][ 160/1075]\tTime  0.848 ( 0.711)\tData  0.543 ( 0.332)\tLoss 6.8746e+00 (6.8777e+00)\tAcc@1   6.25 (  4.24)\tAcc@5  21.88 ( 11.71)\n",
            "Epoch: [7][ 170/1075]\tTime  0.892 ( 0.706)\tData  0.570 ( 0.327)\tLoss 6.4197e+00 (6.8695e+00)\tAcc@1   7.81 (  4.31)\tAcc@5  25.00 ( 11.98)\n",
            "Epoch: [7][ 180/1075]\tTime  0.588 ( 0.702)\tData  0.279 ( 0.323)\tLoss 6.0388e+00 (6.8257e+00)\tAcc@1  10.94 (  4.75)\tAcc@5  18.75 ( 12.84)\n",
            "Epoch: [7][ 190/1075]\tTime  0.544 ( 0.695)\tData  0.251 ( 0.316)\tLoss 5.7543e+00 (6.7808e+00)\tAcc@1   6.25 (  5.06)\tAcc@5  12.50 ( 13.30)\n",
            "Epoch: [7][ 200/1075]\tTime  0.607 ( 0.693)\tData  0.309 ( 0.314)\tLoss 6.2669e+00 (6.7561e+00)\tAcc@1   4.69 (  5.01)\tAcc@5  14.06 ( 13.32)\n",
            "Epoch: [7][ 210/1075]\tTime  0.511 ( 0.687)\tData  0.099 ( 0.310)\tLoss 6.3418e+00 (6.7366e+00)\tAcc@1   3.12 (  5.04)\tAcc@5  12.50 ( 13.43)\n",
            "Epoch: [7][ 220/1075]\tTime  0.828 ( 0.687)\tData  0.532 ( 0.313)\tLoss 6.2114e+00 (6.7176e+00)\tAcc@1   3.12 (  5.22)\tAcc@5   3.12 ( 13.59)\n",
            "Epoch: [7][ 230/1075]\tTime  0.578 ( 0.683)\tData  0.285 ( 0.309)\tLoss 6.3218e+00 (6.6829e+00)\tAcc@1  17.19 (  5.45)\tAcc@5  21.88 ( 13.98)\n",
            "Epoch: [7][ 240/1075]\tTime  0.898 ( 0.683)\tData  0.589 ( 0.308)\tLoss 6.5698e+00 (6.6714e+00)\tAcc@1  10.94 (  5.68)\tAcc@5  23.44 ( 14.37)\n",
            "Epoch: [7][ 250/1075]\tTime  0.556 ( 0.680)\tData  0.263 ( 0.305)\tLoss 6.7818e+00 (6.6679e+00)\tAcc@1   7.81 (  5.96)\tAcc@5  17.19 ( 14.78)\n",
            "Epoch: [7][ 260/1075]\tTime  0.954 ( 0.679)\tData  0.655 ( 0.304)\tLoss 6.9804e+00 (6.6765e+00)\tAcc@1  10.94 (  6.00)\tAcc@5  18.75 ( 14.92)\n",
            "Epoch: [7][ 270/1075]\tTime  0.729 ( 0.678)\tData  0.433 ( 0.302)\tLoss 5.8761e+00 (6.6702e+00)\tAcc@1   4.69 (  6.04)\tAcc@5  15.62 ( 15.11)\n",
            "Epoch: [7][ 280/1075]\tTime  0.815 ( 0.677)\tData  0.511 ( 0.301)\tLoss 6.0867e+00 (6.6478e+00)\tAcc@1   4.69 (  6.11)\tAcc@5  12.50 ( 15.28)\n",
            "Epoch: [7][ 290/1075]\tTime  0.729 ( 0.675)\tData  0.437 ( 0.300)\tLoss 6.4553e+00 (6.6405e+00)\tAcc@1   1.56 (  6.05)\tAcc@5   6.25 ( 15.21)\n",
            "Epoch: [7][ 300/1075]\tTime  1.120 ( 0.675)\tData  0.828 ( 0.300)\tLoss 6.3526e+00 (6.6310e+00)\tAcc@1   9.38 (  6.03)\tAcc@5  12.50 ( 15.10)\n",
            "Epoch: [7][ 310/1075]\tTime  0.627 ( 0.674)\tData  0.333 ( 0.298)\tLoss 6.3523e+00 (6.6181e+00)\tAcc@1  12.50 (  6.16)\tAcc@5  17.19 ( 15.28)\n",
            "Epoch: [7][ 320/1075]\tTime  0.997 ( 0.673)\tData  0.700 ( 0.297)\tLoss 6.6111e+00 (6.6168e+00)\tAcc@1  10.94 (  6.15)\tAcc@5  17.19 ( 15.22)\n",
            "Epoch: [7][ 330/1075]\tTime  0.748 ( 0.673)\tData  0.447 ( 0.297)\tLoss 5.2701e+00 (6.6010e+00)\tAcc@1  18.75 (  6.46)\tAcc@5  40.62 ( 15.72)\n",
            "Epoch: [7][ 340/1075]\tTime  0.897 ( 0.671)\tData  0.598 ( 0.295)\tLoss 6.3278e+00 (6.5843e+00)\tAcc@1   7.81 (  6.58)\tAcc@5  12.50 ( 15.93)\n",
            "Epoch: [7][ 350/1075]\tTime  0.776 ( 0.672)\tData  0.470 ( 0.296)\tLoss 6.6494e+00 (6.5835e+00)\tAcc@1   4.69 (  6.52)\tAcc@5  21.88 ( 15.90)\n",
            "Epoch: [7][ 360/1075]\tTime  0.762 ( 0.670)\tData  0.456 ( 0.294)\tLoss 6.5272e+00 (6.5858e+00)\tAcc@1  10.94 (  6.58)\tAcc@5  32.81 ( 16.05)\n",
            "Epoch: [7][ 370/1075]\tTime  0.641 ( 0.671)\tData  0.353 ( 0.295)\tLoss 6.3423e+00 (6.5784e+00)\tAcc@1   7.81 (  6.65)\tAcc@5  15.62 ( 16.17)\n",
            "Epoch: [7][ 380/1075]\tTime  0.723 ( 0.669)\tData  0.417 ( 0.293)\tLoss 6.5413e+00 (6.5760e+00)\tAcc@1   4.69 (  6.63)\tAcc@5   9.38 ( 16.10)\n",
            "Epoch: [7][ 390/1075]\tTime  0.510 ( 0.669)\tData  0.215 ( 0.293)\tLoss 6.4217e+00 (6.5765e+00)\tAcc@1   6.25 (  6.63)\tAcc@5  25.00 ( 16.10)\n",
            "Epoch: [7][ 400/1075]\tTime  0.806 ( 0.667)\tData  0.522 ( 0.291)\tLoss 5.8924e+00 (6.5608e+00)\tAcc@1  14.06 (  6.70)\tAcc@5  32.81 ( 16.33)\n",
            "Epoch: [7][ 410/1075]\tTime  0.834 ( 0.667)\tData  0.542 ( 0.291)\tLoss 6.4993e+00 (6.5563e+00)\tAcc@1  10.94 (  6.69)\tAcc@5  17.19 ( 16.31)\n",
            "Epoch: [7][ 420/1075]\tTime  0.805 ( 0.666)\tData  0.500 ( 0.290)\tLoss 6.9286e+00 (6.5589e+00)\tAcc@1   6.25 (  6.80)\tAcc@5  14.06 ( 16.37)\n",
            "Epoch: [7][ 430/1075]\tTime  0.747 ( 0.667)\tData  0.448 ( 0.290)\tLoss 6.7877e+00 (6.5664e+00)\tAcc@1   9.38 (  6.86)\tAcc@5  20.31 ( 16.48)\n",
            "Epoch: [7][ 440/1075]\tTime  0.664 ( 0.665)\tData  0.356 ( 0.288)\tLoss 6.9028e+00 (6.5707e+00)\tAcc@1   1.56 (  6.80)\tAcc@5   7.81 ( 16.44)\n",
            "Epoch: [7][ 450/1075]\tTime  1.003 ( 0.665)\tData  0.714 ( 0.288)\tLoss 7.2365e+00 (6.5828e+00)\tAcc@1   3.12 (  6.79)\tAcc@5  10.94 ( 16.38)\n",
            "Epoch: [7][ 460/1075]\tTime  0.542 ( 0.663)\tData  0.249 ( 0.287)\tLoss 7.4833e+00 (6.5999e+00)\tAcc@1   9.38 (  6.78)\tAcc@5  20.31 ( 16.32)\n",
            "Epoch: [7][ 470/1075]\tTime  1.063 ( 0.662)\tData  0.730 ( 0.285)\tLoss 7.3595e+00 (6.6174e+00)\tAcc@1  10.94 (  6.77)\tAcc@5  21.88 ( 16.30)\n",
            "Epoch: [7][ 480/1075]\tTime  0.723 ( 0.661)\tData  0.416 ( 0.284)\tLoss 5.5879e+00 (6.6109e+00)\tAcc@1  15.62 (  6.93)\tAcc@5  26.56 ( 16.61)\n",
            "Epoch: [7][ 490/1075]\tTime  0.854 ( 0.660)\tData  0.547 ( 0.283)\tLoss 5.8171e+00 (6.5938e+00)\tAcc@1  17.19 (  7.09)\tAcc@5  31.25 ( 16.85)\n",
            "Epoch: [7][ 500/1075]\tTime  0.564 ( 0.659)\tData  0.273 ( 0.282)\tLoss 6.1553e+00 (6.5828e+00)\tAcc@1  10.94 (  7.16)\tAcc@5  25.00 ( 16.91)\n",
            "Epoch: [7][ 510/1075]\tTime  0.589 ( 0.657)\tData  0.299 ( 0.280)\tLoss 6.3626e+00 (6.5781e+00)\tAcc@1  12.50 (  7.26)\tAcc@5  23.44 ( 17.03)\n",
            "Epoch: [7][ 520/1075]\tTime  0.755 ( 0.658)\tData  0.448 ( 0.281)\tLoss 6.5205e+00 (6.5773e+00)\tAcc@1   7.81 (  7.35)\tAcc@5  18.75 ( 17.09)\n",
            "Epoch: [7][ 530/1075]\tTime  0.636 ( 0.656)\tData  0.348 ( 0.279)\tLoss 6.2817e+00 (6.5724e+00)\tAcc@1  18.75 (  7.45)\tAcc@5  26.56 ( 17.23)\n",
            "Epoch: [7][ 540/1075]\tTime  0.805 ( 0.656)\tData  0.511 ( 0.279)\tLoss 6.1713e+00 (6.5627e+00)\tAcc@1   6.25 (  7.51)\tAcc@5  18.75 ( 17.31)\n",
            "Epoch: [7][ 550/1075]\tTime  0.564 ( 0.655)\tData  0.273 ( 0.278)\tLoss 6.2490e+00 (6.5574e+00)\tAcc@1   9.38 (  7.54)\tAcc@5  15.62 ( 17.34)\n",
            "Epoch: [7][ 560/1075]\tTime  1.020 ( 0.656)\tData  0.714 ( 0.279)\tLoss 6.4114e+00 (6.5558e+00)\tAcc@1   9.38 (  7.56)\tAcc@5  15.62 ( 17.34)\n",
            "Epoch: [7][ 570/1075]\tTime  0.560 ( 0.654)\tData  0.268 ( 0.277)\tLoss 6.0289e+00 (6.5535e+00)\tAcc@1  29.69 (  7.67)\tAcc@5  40.62 ( 17.43)\n",
            "Epoch: [7][ 580/1075]\tTime  1.091 ( 0.654)\tData  0.798 ( 0.277)\tLoss 6.0964e+00 (6.5395e+00)\tAcc@1   4.69 (  7.78)\tAcc@5  15.62 ( 17.57)\n",
            "Epoch: [7][ 590/1075]\tTime  0.767 ( 0.653)\tData  0.486 ( 0.277)\tLoss 6.3883e+00 (6.5359e+00)\tAcc@1  20.31 (  7.86)\tAcc@5  31.25 ( 17.63)\n",
            "Epoch: [7][ 600/1075]\tTime  1.209 ( 0.654)\tData  0.902 ( 0.277)\tLoss 6.8461e+00 (6.5364e+00)\tAcc@1   7.81 (  7.99)\tAcc@5  20.31 ( 17.77)\n",
            "Epoch: [7][ 610/1075]\tTime  0.786 ( 0.654)\tData  0.480 ( 0.277)\tLoss 6.7337e+00 (6.5415e+00)\tAcc@1  10.94 (  8.12)\tAcc@5  15.62 ( 17.93)\n",
            "Epoch: [7][ 620/1075]\tTime  0.688 ( 0.653)\tData  0.397 ( 0.276)\tLoss 7.4553e+00 (6.5507e+00)\tAcc@1   4.69 (  8.16)\tAcc@5  14.06 ( 17.99)\n",
            "Epoch: [7][ 630/1075]\tTime  0.841 ( 0.653)\tData  0.544 ( 0.276)\tLoss 6.2854e+00 (6.5540e+00)\tAcc@1  45.31 (  8.36)\tAcc@5  53.12 ( 18.19)\n",
            "Epoch: [7][ 640/1075]\tTime  0.704 ( 0.652)\tData  0.393 ( 0.275)\tLoss 5.7662e+00 (6.5457e+00)\tAcc@1  46.88 (  8.65)\tAcc@5  62.50 ( 18.53)\n",
            "Epoch: [7][ 650/1075]\tTime  0.517 ( 0.652)\tData  0.225 ( 0.275)\tLoss 6.3461e+00 (6.5405e+00)\tAcc@1   3.12 (  8.68)\tAcc@5   9.38 ( 18.59)\n",
            "Epoch: [7][ 660/1075]\tTime  0.756 ( 0.652)\tData  0.448 ( 0.274)\tLoss 6.3674e+00 (6.5381e+00)\tAcc@1  23.44 (  8.67)\tAcc@5  32.81 ( 18.52)\n",
            "Epoch: [7][ 670/1075]\tTime  0.773 ( 0.652)\tData  0.484 ( 0.275)\tLoss 6.2349e+00 (6.5332e+00)\tAcc@1   1.56 (  8.76)\tAcc@5   7.81 ( 18.65)\n",
            "Epoch: [7][ 680/1075]\tTime  0.646 ( 0.651)\tData  0.351 ( 0.274)\tLoss 6.6734e+00 (6.5328e+00)\tAcc@1  23.44 (  8.84)\tAcc@5  25.00 ( 18.72)\n",
            "Epoch: [7][ 690/1075]\tTime  0.984 ( 0.652)\tData  0.677 ( 0.274)\tLoss 6.9456e+00 (6.5373e+00)\tAcc@1  15.62 (  8.91)\tAcc@5  23.44 ( 18.74)\n",
            "Epoch: [7][ 700/1075]\tTime  0.574 ( 0.651)\tData  0.281 ( 0.273)\tLoss 7.1057e+00 (6.5451e+00)\tAcc@1  17.19 (  8.99)\tAcc@5  23.44 ( 18.77)\n",
            "Epoch: [7][ 710/1075]\tTime  0.928 ( 0.650)\tData  0.638 ( 0.273)\tLoss 7.2590e+00 (6.5548e+00)\tAcc@1  17.19 (  9.05)\tAcc@5  25.00 ( 18.81)\n",
            "Epoch: [7][ 720/1075]\tTime  0.703 ( 0.649)\tData  0.409 ( 0.272)\tLoss 6.9607e+00 (6.5624e+00)\tAcc@1  10.94 (  9.14)\tAcc@5  18.75 ( 18.83)\n",
            "Epoch: [7][ 730/1075]\tTime  0.975 ( 0.649)\tData  0.667 ( 0.272)\tLoss 6.8851e+00 (6.5672e+00)\tAcc@1   9.38 (  9.17)\tAcc@5  14.06 ( 18.79)\n",
            "Epoch: [7][ 740/1075]\tTime  0.715 ( 0.649)\tData  0.424 ( 0.272)\tLoss 7.0256e+00 (6.5733e+00)\tAcc@1  12.50 (  9.20)\tAcc@5  20.31 ( 18.77)\n",
            "Epoch: [7][ 750/1075]\tTime  0.760 ( 0.648)\tData  0.470 ( 0.271)\tLoss 7.0641e+00 (6.5801e+00)\tAcc@1  10.94 (  9.16)\tAcc@5  20.31 ( 18.72)\n",
            "Epoch: [7][ 760/1075]\tTime  0.684 ( 0.648)\tData  0.377 ( 0.271)\tLoss 6.9124e+00 (6.5857e+00)\tAcc@1  15.62 (  9.25)\tAcc@5  23.44 ( 18.77)\n",
            "Epoch: [7][ 770/1075]\tTime  0.711 ( 0.648)\tData  0.414 ( 0.270)\tLoss 6.3056e+00 (6.5839e+00)\tAcc@1  18.75 (  9.37)\tAcc@5  26.56 ( 18.90)\n",
            "Epoch: [7][ 780/1075]\tTime  0.694 ( 0.648)\tData  0.403 ( 0.271)\tLoss 6.1285e+00 (6.5789e+00)\tAcc@1  15.62 (  9.48)\tAcc@5  25.00 ( 19.05)\n",
            "Epoch: [7][ 790/1075]\tTime  0.793 ( 0.648)\tData  0.484 ( 0.270)\tLoss 6.2911e+00 (6.5735e+00)\tAcc@1  21.88 (  9.64)\tAcc@5  31.25 ( 19.26)\n",
            "Epoch: [7][ 800/1075]\tTime  0.769 ( 0.648)\tData  0.464 ( 0.271)\tLoss 6.2154e+00 (6.5687e+00)\tAcc@1   6.25 (  9.73)\tAcc@5  15.62 ( 19.37)\n",
            "Epoch: [7][ 810/1075]\tTime  0.812 ( 0.647)\tData  0.509 ( 0.270)\tLoss 6.5247e+00 (6.5672e+00)\tAcc@1  14.06 (  9.74)\tAcc@5  29.69 ( 19.40)\n",
            "Epoch: [7][ 820/1075]\tTime  1.075 ( 0.648)\tData  0.778 ( 0.271)\tLoss 6.7773e+00 (6.5689e+00)\tAcc@1   3.12 (  9.71)\tAcc@5  12.50 ( 19.35)\n",
            "Epoch: [7][ 830/1075]\tTime  0.715 ( 0.647)\tData  0.420 ( 0.270)\tLoss 6.7267e+00 (6.5712e+00)\tAcc@1  12.50 (  9.66)\tAcc@5  15.62 ( 19.29)\n",
            "Epoch: [7][ 840/1075]\tTime  1.228 ( 0.648)\tData  0.944 ( 0.270)\tLoss 6.6377e+00 (6.5728e+00)\tAcc@1   0.00 (  9.66)\tAcc@5   4.69 ( 19.26)\n",
            "Epoch: [7][ 850/1075]\tTime  0.659 ( 0.648)\tData  0.353 ( 0.270)\tLoss 6.5352e+00 (6.5733e+00)\tAcc@1   0.00 (  9.71)\tAcc@5   4.69 ( 19.26)\n",
            "Epoch: [7][ 860/1075]\tTime  0.931 ( 0.647)\tData  0.634 ( 0.270)\tLoss 6.3882e+00 (6.5723e+00)\tAcc@1  18.75 (  9.81)\tAcc@5  29.69 ( 19.32)\n",
            "Epoch: [7][ 870/1075]\tTime  0.682 ( 0.647)\tData  0.389 ( 0.270)\tLoss 6.2917e+00 (6.5693e+00)\tAcc@1  15.62 (  9.93)\tAcc@5  25.00 ( 19.44)\n",
            "Epoch: [7][ 880/1075]\tTime  0.701 ( 0.646)\tData  0.412 ( 0.269)\tLoss 6.6226e+00 (6.5680e+00)\tAcc@1  15.62 ( 10.04)\tAcc@5  17.19 ( 19.55)\n",
            "Epoch: [7][ 890/1075]\tTime  0.515 ( 0.646)\tData  0.207 ( 0.269)\tLoss 5.6033e+00 (6.5642e+00)\tAcc@1  15.62 ( 10.07)\tAcc@5  26.56 ( 19.61)\n",
            "Epoch: [7][ 900/1075]\tTime  0.648 ( 0.646)\tData  0.341 ( 0.269)\tLoss 5.8319e+00 (6.5523e+00)\tAcc@1   4.69 ( 10.16)\tAcc@5  17.19 ( 19.69)\n",
            "Epoch: [7][ 910/1075]\tTime  0.550 ( 0.646)\tData  0.256 ( 0.269)\tLoss 6.2836e+00 (6.5477e+00)\tAcc@1  15.62 ( 10.26)\tAcc@5  28.12 ( 19.80)\n",
            "Epoch: [7][ 920/1075]\tTime  0.823 ( 0.645)\tData  0.512 ( 0.268)\tLoss 6.2439e+00 (6.5442e+00)\tAcc@1   6.25 ( 10.36)\tAcc@5  31.25 ( 19.91)\n",
            "Epoch: [7][ 930/1075]\tTime  0.740 ( 0.646)\tData  0.430 ( 0.268)\tLoss 6.3508e+00 (6.5412e+00)\tAcc@1  35.94 ( 10.53)\tAcc@5  42.19 ( 20.07)\n",
            "Epoch: [7][ 940/1075]\tTime  0.632 ( 0.645)\tData  0.340 ( 0.267)\tLoss 6.5980e+00 (6.5405e+00)\tAcc@1  12.50 ( 10.65)\tAcc@5  26.56 ( 20.20)\n",
            "Epoch: [7][ 950/1075]\tTime  1.029 ( 0.645)\tData  0.737 ( 0.268)\tLoss 6.7879e+00 (6.5424e+00)\tAcc@1  17.19 ( 10.67)\tAcc@5  26.56 ( 20.21)\n",
            "Epoch: [7][ 960/1075]\tTime  0.765 ( 0.645)\tData  0.456 ( 0.267)\tLoss 6.9261e+00 (6.5460e+00)\tAcc@1  15.62 ( 10.70)\tAcc@5  28.12 ( 20.22)\n",
            "Epoch: [7][ 970/1075]\tTime  0.964 ( 0.644)\tData  0.644 ( 0.267)\tLoss 6.8043e+00 (6.5504e+00)\tAcc@1   3.12 ( 10.65)\tAcc@5   7.81 ( 20.15)\n",
            "Epoch: [7][ 980/1075]\tTime  0.616 ( 0.644)\tData  0.324 ( 0.267)\tLoss 6.0647e+00 (6.5470e+00)\tAcc@1  10.94 ( 10.65)\tAcc@5  29.69 ( 20.15)\n",
            "Epoch: [7][ 990/1075]\tTime  0.613 ( 0.643)\tData  0.321 ( 0.266)\tLoss 6.7665e+00 (6.5466e+00)\tAcc@1  28.12 ( 10.70)\tAcc@5  40.62 ( 20.24)\n",
            "Epoch: [7][1000/1075]\tTime  0.689 ( 0.643)\tData  0.398 ( 0.267)\tLoss 7.1074e+00 (6.5510e+00)\tAcc@1  43.75 ( 11.06)\tAcc@5  56.25 ( 20.61)\n",
            "Epoch: [7][1010/1075]\tTime  0.538 ( 0.642)\tData  0.230 ( 0.266)\tLoss 7.2007e+00 (6.5573e+00)\tAcc@1  34.38 ( 11.55)\tAcc@5  71.88 ( 21.11)\n",
            "Epoch: [7][1020/1075]\tTime  0.653 ( 0.643)\tData  0.361 ( 0.266)\tLoss 7.1820e+00 (6.5637e+00)\tAcc@1  96.88 ( 12.17)\tAcc@5  98.44 ( 21.70)\n",
            "Epoch: [7][1030/1075]\tTime  0.741 ( 0.642)\tData  0.449 ( 0.266)\tLoss 7.1148e+00 (6.5694e+00)\tAcc@1  98.44 ( 12.98)\tAcc@5  98.44 ( 22.42)\n",
            "Epoch: [7][1040/1075]\tTime  0.770 ( 0.643)\tData  0.466 ( 0.266)\tLoss 7.0682e+00 (6.5744e+00)\tAcc@1  98.44 ( 13.73)\tAcc@5  98.44 ( 23.10)\n",
            "Epoch: [7][1050/1075]\tTime  0.758 ( 0.642)\tData  0.449 ( 0.266)\tLoss 7.0838e+00 (6.5791e+00)\tAcc@1  96.88 ( 14.53)\tAcc@5  98.44 ( 23.81)\n",
            "Epoch: [7][1060/1075]\tTime  0.897 ( 0.643)\tData  0.589 ( 0.266)\tLoss 7.1180e+00 (6.5840e+00)\tAcc@1  98.44 ( 15.33)\tAcc@5  98.44 ( 24.52)\n",
            "Epoch: [7][1070/1075]\tTime  0.749 ( 0.642)\tData  0.456 ( 0.265)\tLoss 7.1750e+00 (6.5893e+00)\tAcc@1  96.88 ( 16.09)\tAcc@5  96.88 ( 25.21)\n",
            "epoch: 7\n",
            "2023-04-19 13:20:10.475895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 13:20:14.986596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [8][   0/1075]\tTime 10.693 (10.693)\tData 10.371 (10.371)\tLoss 7.1975e+00 (7.1975e+00)\tAcc@1  98.44 ( 98.44)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [8][  10/1075]\tTime  0.751 ( 1.562)\tData  0.456 ( 1.192)\tLoss 7.2560e+00 (7.2284e+00)\tAcc@1  98.44 ( 98.72)\tAcc@5 100.00 ( 99.01)\n",
            "Epoch: [8][  20/1075]\tTime  0.583 ( 1.089)\tData  0.290 ( 0.716)\tLoss 7.3118e+00 (7.2568e+00)\tAcc@1 100.00 ( 98.88)\tAcc@5 100.00 ( 99.18)\n",
            "Epoch: [8][  30/1075]\tTime  0.510 ( 0.940)\tData  0.002 ( 0.574)\tLoss 7.3572e+00 (7.2827e+00)\tAcc@1 100.00 ( 99.14)\tAcc@5 100.00 ( 99.40)\n",
            "Epoch: [8][  40/1075]\tTime  0.544 ( 0.856)\tData  0.236 ( 0.488)\tLoss 7.3951e+00 (7.3061e+00)\tAcc@1  98.44 ( 99.09)\tAcc@5  98.44 ( 99.35)\n",
            "Epoch: [8][  50/1075]\tTime  0.488 ( 0.806)\tData  0.000 ( 0.444)\tLoss 7.4233e+00 (7.3267e+00)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 ( 99.30)\n",
            "Epoch: [8][  60/1075]\tTime  0.506 ( 0.779)\tData  0.000 ( 0.410)\tLoss 7.4479e+00 (7.3448e+00)\tAcc@1  98.44 ( 99.03)\tAcc@5  98.44 ( 99.26)\n",
            "Epoch: [8][  70/1075]\tTime  0.513 ( 0.750)\tData  0.000 ( 0.377)\tLoss 7.4652e+00 (7.3608e+00)\tAcc@1  98.44 ( 99.01)\tAcc@5  98.44 ( 99.25)\n",
            "Epoch: [8][  80/1075]\tTime  0.507 ( 0.740)\tData  0.000 ( 0.364)\tLoss 7.4844e+00 (7.3751e+00)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 ( 99.17)\n",
            "Epoch: [8][  90/1075]\tTime  0.497 ( 0.724)\tData  0.000 ( 0.345)\tLoss 7.5068e+00 (7.3882e+00)\tAcc@1  98.44 ( 98.94)\tAcc@5  98.44 ( 99.14)\n",
            "Epoch: [8][ 100/1075]\tTime  0.506 ( 0.721)\tData  0.000 ( 0.340)\tLoss 7.5151e+00 (7.4004e+00)\tAcc@1  98.44 ( 98.98)\tAcc@5  98.44 ( 99.16)\n",
            "Epoch: [8][ 110/1075]\tTime  0.510 ( 0.711)\tData  0.000 ( 0.328)\tLoss 7.5257e+00 (7.4118e+00)\tAcc@1 100.00 ( 97.82)\tAcc@5 100.00 ( 98.10)\n",
            "Epoch: [8][ 120/1075]\tTime  0.502 ( 0.706)\tData  0.000 ( 0.322)\tLoss 7.5565e+00 (7.4225e+00)\tAcc@1  68.75 ( 96.51)\tAcc@5  68.75 ( 96.82)\n",
            "Epoch: [8][ 130/1075]\tTime  0.498 ( 0.697)\tData  0.000 ( 0.312)\tLoss 7.5674e+00 (7.4332e+00)\tAcc@1  62.50 ( 93.63)\tAcc@5  64.06 ( 94.16)\n",
            "Epoch: [8][ 140/1075]\tTime  0.501 ( 0.697)\tData  0.000 ( 0.311)\tLoss 7.5631e+00 (7.4426e+00)\tAcc@1  60.94 ( 92.13)\tAcc@5  62.50 ( 92.71)\n",
            "Epoch: [8][ 150/1075]\tTime  0.494 ( 0.691)\tData  0.000 ( 0.304)\tLoss 7.5871e+00 (7.4518e+00)\tAcc@1  75.00 ( 89.94)\tAcc@5  75.00 ( 90.78)\n",
            "Epoch: [8][ 160/1075]\tTime  0.499 ( 0.687)\tData  0.000 ( 0.300)\tLoss 7.5715e+00 (7.4603e+00)\tAcc@1  21.88 ( 87.31)\tAcc@5  25.00 ( 88.34)\n",
            "Epoch: [8][ 170/1075]\tTime  0.510 ( 0.684)\tData  0.000 ( 0.296)\tLoss 7.5521e+00 (7.4663e+00)\tAcc@1  56.25 ( 83.79)\tAcc@5  60.94 ( 85.06)\n",
            "Epoch: [8][ 180/1075]\tTime  0.494 ( 0.677)\tData  0.000 ( 0.289)\tLoss 7.5470e+00 (7.4713e+00)\tAcc@1  26.56 ( 80.19)\tAcc@5  40.62 ( 82.09)\n",
            "Epoch: [8][ 190/1075]\tTime  0.506 ( 0.677)\tData  0.000 ( 0.288)\tLoss 7.3979e+00 (7.4715e+00)\tAcc@1   1.56 ( 76.83)\tAcc@5   4.69 ( 78.91)\n",
            "Epoch: [8][ 200/1075]\tTime  0.495 ( 0.674)\tData  0.004 ( 0.285)\tLoss 6.8367e+00 (7.4531e+00)\tAcc@1   3.12 ( 73.34)\tAcc@5   4.69 ( 75.51)\n",
            "Epoch: [8][ 210/1075]\tTime  0.483 ( 0.674)\tData  0.000 ( 0.284)\tLoss 6.5499e+00 (7.3962e+00)\tAcc@1   0.00 ( 70.45)\tAcc@5   6.25 ( 72.82)\n",
            "Epoch: [8][ 220/1075]\tTime  0.506 ( 0.670)\tData  0.000 ( 0.280)\tLoss 6.9327e+00 (7.3679e+00)\tAcc@1  20.31 ( 67.76)\tAcc@5  20.31 ( 70.33)\n",
            "Epoch: [8][ 230/1075]\tTime  0.483 ( 0.671)\tData  0.000 ( 0.280)\tLoss 7.1980e+00 (7.3578e+00)\tAcc@1   4.69 ( 65.29)\tAcc@5   6.25 ( 67.97)\n",
            "Epoch: [8][ 240/1075]\tTime  0.503 ( 0.668)\tData  0.000 ( 0.277)\tLoss 7.2882e+00 (7.3553e+00)\tAcc@1  17.19 ( 63.03)\tAcc@5  25.00 ( 65.80)\n",
            "Epoch: [8][ 250/1075]\tTime  0.495 ( 0.668)\tData  0.000 ( 0.277)\tLoss 7.3416e+00 (7.3568e+00)\tAcc@1  10.94 ( 60.85)\tAcc@5  17.19 ( 63.75)\n",
            "Epoch: [8][ 260/1075]\tTime  0.499 ( 0.666)\tData  0.000 ( 0.275)\tLoss 7.4779e+00 (7.3610e+00)\tAcc@1   7.81 ( 58.90)\tAcc@5  12.50 ( 61.89)\n",
            "Epoch: [8][ 270/1075]\tTime  0.484 ( 0.666)\tData  0.000 ( 0.275)\tLoss 7.4820e+00 (7.3662e+00)\tAcc@1   7.81 ( 57.13)\tAcc@5  12.50 ( 60.21)\n",
            "Epoch: [8][ 280/1075]\tTime  0.498 ( 0.662)\tData  0.000 ( 0.271)\tLoss 7.5205e+00 (7.3725e+00)\tAcc@1   7.81 ( 55.52)\tAcc@5  12.50 ( 58.72)\n",
            "Epoch: [8][ 290/1075]\tTime  0.525 ( 0.663)\tData  0.000 ( 0.270)\tLoss 7.5528e+00 (7.3810e+00)\tAcc@1   4.69 ( 53.99)\tAcc@5  14.06 ( 57.27)\n",
            "Epoch: [8][ 300/1075]\tTime  0.503 ( 0.660)\tData  0.000 ( 0.267)\tLoss 7.6130e+00 (7.3877e+00)\tAcc@1   4.69 ( 52.56)\tAcc@5  10.94 ( 55.97)\n",
            "Epoch: [8][ 310/1075]\tTime  0.500 ( 0.659)\tData  0.000 ( 0.266)\tLoss 7.6841e+00 (7.3925e+00)\tAcc@1   9.38 ( 51.25)\tAcc@5  20.31 ( 54.76)\n",
            "Epoch: [8][ 320/1075]\tTime  0.491 ( 0.659)\tData  0.000 ( 0.265)\tLoss 7.4172e+00 (7.3965e+00)\tAcc@1  14.06 ( 50.13)\tAcc@5  21.88 ( 53.76)\n",
            "Epoch: [8][ 330/1075]\tTime  0.496 ( 0.657)\tData  0.000 ( 0.264)\tLoss 7.4309e+00 (7.3953e+00)\tAcc@1  17.19 ( 49.12)\tAcc@5  25.00 ( 52.91)\n",
            "Epoch: [8][ 340/1075]\tTime  0.494 ( 0.658)\tData  0.001 ( 0.265)\tLoss 7.2322e+00 (7.3925e+00)\tAcc@1  10.94 ( 48.19)\tAcc@5  23.44 ( 52.19)\n",
            "Epoch: [8][ 350/1075]\tTime  0.496 ( 0.656)\tData  0.000 ( 0.263)\tLoss 7.2975e+00 (7.3879e+00)\tAcc@1  10.94 ( 47.38)\tAcc@5  25.00 ( 51.49)\n",
            "Epoch: [8][ 360/1075]\tTime  0.494 ( 0.657)\tData  0.000 ( 0.263)\tLoss 6.7704e+00 (7.3765e+00)\tAcc@1  17.19 ( 46.62)\tAcc@5  21.88 ( 50.77)\n",
            "Epoch: [8][ 370/1075]\tTime  0.509 ( 0.654)\tData  0.059 ( 0.261)\tLoss 6.8171e+00 (7.3620e+00)\tAcc@1  20.31 ( 45.87)\tAcc@5  26.56 ( 50.11)\n",
            "Epoch: [8][ 380/1075]\tTime  0.507 ( 0.654)\tData  0.113 ( 0.261)\tLoss 5.9821e+00 (7.3383e+00)\tAcc@1  34.38 ( 45.15)\tAcc@5  35.94 ( 49.57)\n",
            "Epoch: [8][ 390/1075]\tTime  0.511 ( 0.652)\tData  0.104 ( 0.261)\tLoss 5.8913e+00 (7.3006e+00)\tAcc@1  18.75 ( 44.43)\tAcc@5  29.69 ( 49.00)\n",
            "Epoch: [8][ 400/1075]\tTime  0.899 ( 0.653)\tData  0.599 ( 0.263)\tLoss 6.9935e+00 (7.2814e+00)\tAcc@1  12.50 ( 43.50)\tAcc@5  20.31 ( 48.20)\n",
            "Epoch: [8][ 410/1075]\tTime  0.505 ( 0.651)\tData  0.133 ( 0.262)\tLoss 6.9697e+00 (7.2717e+00)\tAcc@1   1.56 ( 42.53)\tAcc@5  10.94 ( 47.30)\n",
            "Epoch: [8][ 420/1075]\tTime  0.489 ( 0.650)\tData  0.070 ( 0.262)\tLoss 6.9952e+00 (7.2671e+00)\tAcc@1   4.69 ( 41.66)\tAcc@5   7.81 ( 46.50)\n",
            "Epoch: [8][ 430/1075]\tTime  0.507 ( 0.649)\tData  0.044 ( 0.262)\tLoss 6.6891e+00 (7.2574e+00)\tAcc@1   3.12 ( 40.83)\tAcc@5  14.06 ( 45.79)\n",
            "Epoch: [8][ 440/1075]\tTime  0.505 ( 0.649)\tData  0.000 ( 0.261)\tLoss 6.6902e+00 (7.2420e+00)\tAcc@1   9.38 ( 40.10)\tAcc@5  14.06 ( 45.21)\n",
            "Epoch: [8][ 450/1075]\tTime  0.488 ( 0.649)\tData  0.000 ( 0.261)\tLoss 6.6381e+00 (7.2281e+00)\tAcc@1  25.00 ( 39.51)\tAcc@5  28.12 ( 44.73)\n",
            "Epoch: [8][ 460/1075]\tTime  0.495 ( 0.648)\tData  0.000 ( 0.260)\tLoss 6.8207e+00 (7.2177e+00)\tAcc@1  35.94 ( 39.05)\tAcc@5  40.62 ( 44.30)\n",
            "Epoch: [8][ 470/1075]\tTime  0.509 ( 0.649)\tData  0.000 ( 0.261)\tLoss 7.0796e+00 (7.2122e+00)\tAcc@1   1.56 ( 38.46)\tAcc@5   3.12 ( 43.72)\n",
            "Epoch: [8][ 480/1075]\tTime  0.511 ( 0.648)\tData  0.000 ( 0.260)\tLoss 7.1969e+00 (7.2109e+00)\tAcc@1  35.94 ( 37.89)\tAcc@5  40.62 ( 43.15)\n",
            "Epoch: [8][ 490/1075]\tTime  0.513 ( 0.649)\tData  0.000 ( 0.260)\tLoss 7.0840e+00 (7.2102e+00)\tAcc@1  68.75 ( 37.61)\tAcc@5  78.12 ( 42.94)\n",
            "Epoch: [8][ 500/1075]\tTime  0.486 ( 0.648)\tData  0.000 ( 0.259)\tLoss 7.2063e+00 (7.2086e+00)\tAcc@1   0.00 ( 37.13)\tAcc@5   1.56 ( 42.51)\n",
            "Epoch: [8][ 510/1075]\tTime  0.500 ( 0.649)\tData  0.000 ( 0.260)\tLoss 7.3410e+00 (7.2096e+00)\tAcc@1   9.38 ( 36.88)\tAcc@5  23.44 ( 42.36)\n",
            "Epoch: [8][ 520/1075]\tTime  0.492 ( 0.649)\tData  0.000 ( 0.260)\tLoss 7.4005e+00 (7.2132e+00)\tAcc@1  68.75 ( 36.84)\tAcc@5  84.38 ( 42.42)\n",
            "Epoch: [8][ 530/1075]\tTime  0.494 ( 0.649)\tData  0.000 ( 0.260)\tLoss 7.3796e+00 (7.2168e+00)\tAcc@1   4.69 ( 36.59)\tAcc@5  34.38 ( 42.26)\n",
            "Epoch: [8][ 540/1075]\tTime  0.493 ( 0.648)\tData  0.000 ( 0.259)\tLoss 7.3427e+00 (7.2197e+00)\tAcc@1  18.75 ( 36.59)\tAcc@5  26.56 ( 42.29)\n",
            "Epoch: [8][ 550/1075]\tTime  0.496 ( 0.649)\tData  0.000 ( 0.259)\tLoss 7.2971e+00 (7.2217e+00)\tAcc@1  43.75 ( 36.73)\tAcc@5  45.31 ( 42.50)\n",
            "Epoch: [8][ 560/1075]\tTime  0.507 ( 0.648)\tData  0.000 ( 0.258)\tLoss 7.0161e+00 (7.2210e+00)\tAcc@1  39.06 ( 36.73)\tAcc@5  43.75 ( 42.50)\n",
            "Epoch: [8][ 570/1075]\tTime  0.535 ( 0.648)\tData  0.000 ( 0.258)\tLoss 6.9023e+00 (7.2151e+00)\tAcc@1  28.12 ( 36.68)\tAcc@5  37.50 ( 42.51)\n",
            "Epoch: [8][ 580/1075]\tTime  0.510 ( 0.648)\tData  0.000 ( 0.258)\tLoss 7.1669e+00 (7.2123e+00)\tAcc@1  23.44 ( 36.31)\tAcc@5  29.69 ( 42.13)\n",
            "Epoch: [8][ 590/1075]\tTime  0.507 ( 0.647)\tData  0.000 ( 0.256)\tLoss 7.0860e+00 (7.2117e+00)\tAcc@1  17.19 ( 35.94)\tAcc@5  23.44 ( 41.82)\n",
            "Epoch: [8][ 600/1075]\tTime  0.507 ( 0.647)\tData  0.000 ( 0.257)\tLoss 6.6224e+00 (7.2062e+00)\tAcc@1   3.12 ( 35.49)\tAcc@5  12.50 ( 41.40)\n",
            "Epoch: [8][ 610/1075]\tTime  0.501 ( 0.647)\tData  0.000 ( 0.256)\tLoss 6.5193e+00 (7.1933e+00)\tAcc@1  20.31 ( 35.10)\tAcc@5  34.38 ( 41.04)\n",
            "Epoch: [8][ 620/1075]\tTime  0.505 ( 0.647)\tData  0.000 ( 0.256)\tLoss 6.9028e+00 (7.1874e+00)\tAcc@1  29.69 ( 34.72)\tAcc@5  37.50 ( 40.69)\n",
            "Epoch: [8][ 630/1075]\tTime  0.493 ( 0.646)\tData  0.000 ( 0.255)\tLoss 6.9853e+00 (7.1838e+00)\tAcc@1   9.38 ( 34.29)\tAcc@5  18.75 ( 40.27)\n",
            "Epoch: [8][ 640/1075]\tTime  0.503 ( 0.647)\tData  0.007 ( 0.255)\tLoss 7.2547e+00 (7.1819e+00)\tAcc@1  10.94 ( 33.93)\tAcc@5  25.00 ( 39.95)\n",
            "Epoch: [8][ 650/1075]\tTime  0.480 ( 0.646)\tData  0.000 ( 0.255)\tLoss 6.8683e+00 (7.1783e+00)\tAcc@1  23.44 ( 33.57)\tAcc@5  29.69 ( 39.62)\n",
            "Epoch: [8][ 660/1075]\tTime  0.493 ( 0.647)\tData  0.000 ( 0.255)\tLoss 6.7852e+00 (7.1724e+00)\tAcc@1  23.44 ( 33.31)\tAcc@5  28.12 ( 39.38)\n",
            "Epoch: [8][ 670/1075]\tTime  0.491 ( 0.646)\tData  0.000 ( 0.254)\tLoss 7.0814e+00 (7.1676e+00)\tAcc@1   7.81 ( 33.06)\tAcc@5  12.50 ( 39.14)\n",
            "Epoch: [8][ 680/1075]\tTime  0.489 ( 0.647)\tData  0.000 ( 0.255)\tLoss 7.0529e+00 (7.1654e+00)\tAcc@1  17.19 ( 32.80)\tAcc@5  23.44 ( 38.89)\n",
            "Epoch: [8][ 690/1075]\tTime  0.510 ( 0.646)\tData  0.000 ( 0.254)\tLoss 7.2441e+00 (7.1664e+00)\tAcc@1  26.56 ( 32.55)\tAcc@5  28.12 ( 38.62)\n",
            "Epoch: [8][ 700/1075]\tTime  0.523 ( 0.646)\tData  0.000 ( 0.254)\tLoss 7.2099e+00 (7.1678e+00)\tAcc@1  26.56 ( 32.31)\tAcc@5  31.25 ( 38.35)\n",
            "Epoch: [8][ 710/1075]\tTime  0.496 ( 0.645)\tData  0.000 ( 0.253)\tLoss 7.3942e+00 (7.1695e+00)\tAcc@1  34.38 ( 32.15)\tAcc@5  39.06 ( 38.18)\n",
            "Epoch: [8][ 720/1075]\tTime  0.506 ( 0.646)\tData  0.000 ( 0.253)\tLoss 7.3911e+00 (7.1722e+00)\tAcc@1   0.00 ( 32.00)\tAcc@5   3.12 ( 38.01)\n",
            "Epoch: [8][ 730/1075]\tTime  0.482 ( 0.646)\tData  0.000 ( 0.253)\tLoss 7.3560e+00 (7.1750e+00)\tAcc@1  23.44 ( 31.76)\tAcc@5  29.69 ( 37.75)\n",
            "Epoch: [8][ 740/1075]\tTime  0.516 ( 0.645)\tData  0.000 ( 0.253)\tLoss 7.3620e+00 (7.1785e+00)\tAcc@1  39.06 ( 31.54)\tAcc@5  45.31 ( 37.52)\n",
            "Epoch: [8][ 750/1075]\tTime  0.504 ( 0.645)\tData  0.000 ( 0.252)\tLoss 7.2757e+00 (7.1810e+00)\tAcc@1   1.56 ( 31.37)\tAcc@5   4.69 ( 37.37)\n",
            "Epoch: [8][ 760/1075]\tTime  0.496 ( 0.644)\tData  0.000 ( 0.251)\tLoss 6.6521e+00 (7.1781e+00)\tAcc@1   0.00 ( 31.28)\tAcc@5   4.69 ( 37.26)\n",
            "Epoch: [8][ 770/1075]\tTime  0.492 ( 0.645)\tData  0.000 ( 0.252)\tLoss 6.8277e+00 (7.1713e+00)\tAcc@1   0.00 ( 31.11)\tAcc@5   1.56 ( 37.09)\n",
            "Epoch: [8][ 780/1075]\tTime  0.507 ( 0.644)\tData  0.000 ( 0.251)\tLoss 7.0088e+00 (7.1678e+00)\tAcc@1   0.00 ( 30.96)\tAcc@5   0.00 ( 37.00)\n",
            "Epoch: [8][ 790/1075]\tTime  0.492 ( 0.644)\tData  0.000 ( 0.252)\tLoss 6.6647e+00 (7.1616e+00)\tAcc@1   1.56 ( 30.64)\tAcc@5   3.12 ( 36.65)\n",
            "Epoch: [8][ 800/1075]\tTime  0.511 ( 0.644)\tData  0.000 ( 0.251)\tLoss 6.6595e+00 (7.1538e+00)\tAcc@1  35.94 ( 30.46)\tAcc@5  35.94 ( 36.47)\n",
            "Epoch: [8][ 810/1075]\tTime  0.492 ( 0.644)\tData  0.000 ( 0.252)\tLoss 6.7484e+00 (7.1490e+00)\tAcc@1  31.25 ( 30.35)\tAcc@5  37.50 ( 36.35)\n",
            "Epoch: [8][ 820/1075]\tTime  0.496 ( 0.644)\tData  0.000 ( 0.251)\tLoss 6.8502e+00 (7.1444e+00)\tAcc@1   0.00 ( 30.28)\tAcc@5   7.81 ( 36.28)\n",
            "Epoch: [8][ 830/1075]\tTime  0.482 ( 0.645)\tData  0.000 ( 0.252)\tLoss 6.4266e+00 (7.1389e+00)\tAcc@1  29.69 ( 30.20)\tAcc@5  42.19 ( 36.25)\n",
            "Epoch: [8][ 840/1075]\tTime  0.497 ( 0.644)\tData  0.000 ( 0.251)\tLoss 5.8138e+00 (7.1235e+00)\tAcc@1   1.56 ( 30.30)\tAcc@5  10.94 ( 36.39)\n",
            "Epoch: [8][ 850/1075]\tTime  0.496 ( 0.646)\tData  0.000 ( 0.252)\tLoss 6.6045e+00 (7.1140e+00)\tAcc@1  39.06 ( 30.36)\tAcc@5  45.31 ( 36.41)\n",
            "Epoch: [8][ 860/1075]\tTime  0.508 ( 0.646)\tData  0.000 ( 0.252)\tLoss 6.6004e+00 (7.1085e+00)\tAcc@1  31.25 ( 30.45)\tAcc@5  34.38 ( 36.46)\n",
            "Epoch: [8][ 870/1075]\tTime  0.499 ( 0.646)\tData  0.000 ( 0.253)\tLoss 6.8442e+00 (7.1032e+00)\tAcc@1   9.38 ( 30.47)\tAcc@5  46.88 ( 36.48)\n",
            "Epoch: [8][ 880/1075]\tTime  0.499 ( 0.647)\tData  0.000 ( 0.253)\tLoss 7.3162e+00 (7.1035e+00)\tAcc@1   9.38 ( 30.32)\tAcc@5  54.69 ( 36.41)\n",
            "Epoch: [8][ 890/1075]\tTime  0.483 ( 0.648)\tData  0.000 ( 0.254)\tLoss 7.5310e+00 (7.1076e+00)\tAcc@1   7.81 ( 30.21)\tAcc@5  26.56 ( 36.32)\n",
            "Epoch: [8][ 900/1075]\tTime  0.514 ( 0.648)\tData  0.000 ( 0.254)\tLoss 7.6137e+00 (7.1134e+00)\tAcc@1  37.50 ( 30.11)\tAcc@5  40.62 ( 36.20)\n",
            "Epoch: [8][ 910/1075]\tTime  0.489 ( 0.649)\tData  0.001 ( 0.255)\tLoss 7.5308e+00 (7.1178e+00)\tAcc@1  43.75 ( 30.00)\tAcc@5  46.88 ( 36.07)\n",
            "Epoch: [8][ 920/1075]\tTime  0.508 ( 0.649)\tData  0.000 ( 0.255)\tLoss 5.7774e+00 (7.1064e+00)\tAcc@1  23.44 ( 30.09)\tAcc@5  34.38 ( 36.33)\n",
            "Epoch: [8][ 930/1075]\tTime  0.500 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.5573e+00 (7.0979e+00)\tAcc@1   1.56 ( 29.98)\tAcc@5   1.56 ( 36.28)\n",
            "Epoch: [8][ 940/1075]\tTime  0.482 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.4130e+00 (7.0903e+00)\tAcc@1   1.56 ( 29.97)\tAcc@5   3.12 ( 36.30)\n",
            "Epoch: [8][ 950/1075]\tTime  0.490 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.3815e+00 (7.0802e+00)\tAcc@1   6.25 ( 30.05)\tAcc@5  42.19 ( 36.42)\n",
            "Epoch: [8][ 960/1075]\tTime  0.507 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.8151e+00 (7.0758e+00)\tAcc@1  34.38 ( 29.86)\tAcc@5  46.88 ( 36.25)\n",
            "Epoch: [8][ 970/1075]\tTime  0.512 ( 0.649)\tData  0.000 ( 0.255)\tLoss 7.0297e+00 (7.0748e+00)\tAcc@1   0.00 ( 29.63)\tAcc@5   6.25 ( 36.01)\n",
            "Epoch: [8][ 980/1075]\tTime  0.496 ( 0.649)\tData  0.000 ( 0.255)\tLoss 7.0717e+00 (7.0745e+00)\tAcc@1   3.12 ( 29.58)\tAcc@5   4.69 ( 35.96)\n",
            "Epoch: [8][ 990/1075]\tTime  0.487 ( 0.648)\tData  0.000 ( 0.254)\tLoss 7.0544e+00 (7.0746e+00)\tAcc@1   1.56 ( 29.51)\tAcc@5   6.25 ( 35.92)\n",
            "Epoch: [8][1000/1075]\tTime  0.495 ( 0.649)\tData  0.000 ( 0.255)\tLoss 7.0305e+00 (7.0744e+00)\tAcc@1  23.44 ( 29.41)\tAcc@5  31.25 ( 35.87)\n",
            "Epoch: [8][1010/1075]\tTime  0.499 ( 0.649)\tData  0.000 ( 0.254)\tLoss 6.9235e+00 (7.0728e+00)\tAcc@1  25.00 ( 29.31)\tAcc@5  26.56 ( 35.78)\n",
            "Epoch: [8][1020/1075]\tTime  0.489 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.8451e+00 (7.0707e+00)\tAcc@1  25.00 ( 29.25)\tAcc@5  31.25 ( 35.75)\n",
            "Epoch: [8][1030/1075]\tTime  0.521 ( 0.649)\tData  0.001 ( 0.254)\tLoss 6.3365e+00 (7.0666e+00)\tAcc@1  31.25 ( 29.12)\tAcc@5  39.06 ( 35.64)\n",
            "Epoch: [8][1040/1075]\tTime  0.491 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.1609e+00 (7.0582e+00)\tAcc@1  15.62 ( 28.99)\tAcc@5  21.88 ( 35.50)\n",
            "Epoch: [8][1050/1075]\tTime  0.493 ( 0.649)\tData  0.000 ( 0.254)\tLoss 6.3531e+00 (7.0486e+00)\tAcc@1  14.06 ( 28.83)\tAcc@5  15.62 ( 35.33)\n",
            "Epoch: [8][1060/1075]\tTime  0.507 ( 0.649)\tData  0.000 ( 0.255)\tLoss 6.8804e+00 (7.0449e+00)\tAcc@1   0.00 ( 28.67)\tAcc@5   7.81 ( 35.15)\n",
            "Epoch: [8][1070/1075]\tTime  0.505 ( 0.649)\tData  0.000 ( 0.254)\tLoss 7.3172e+00 (7.0444e+00)\tAcc@1  14.06 ( 28.52)\tAcc@5  23.44 ( 35.00)\n",
            "epoch: 8\n",
            "2023-04-19 13:31:49.348080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 13:31:54.118159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [9][   0/1075]\tTime 11.340 (11.340)\tData 11.023 (11.023)\tLoss 7.2361e+00 (7.2361e+00)\tAcc@1   9.38 (  9.38)\tAcc@5  23.44 ( 23.44)\n",
            "Epoch: [9][  10/1075]\tTime  0.750 ( 1.636)\tData  0.441 ( 1.266)\tLoss 7.3533e+00 (7.3359e+00)\tAcc@1  25.00 ( 16.90)\tAcc@5  32.81 ( 25.43)\n",
            "Epoch: [9][  20/1075]\tTime  0.607 ( 1.129)\tData  0.309 ( 0.764)\tLoss 7.0215e+00 (7.2245e+00)\tAcc@1  21.88 ( 17.34)\tAcc@5  34.38 ( 25.52)\n",
            "Epoch: [9][  30/1075]\tTime  0.496 ( 0.974)\tData  0.165 ( 0.627)\tLoss 6.6263e+00 (7.0808e+00)\tAcc@1  14.06 ( 16.23)\tAcc@5  17.19 ( 24.75)\n",
            "Epoch: [9][  40/1075]\tTime  0.487 ( 0.883)\tData  0.000 ( 0.533)\tLoss 6.2613e+00 (6.9184e+00)\tAcc@1   1.56 ( 14.71)\tAcc@5   9.38 ( 23.25)\n",
            "Epoch: [9][  50/1075]\tTime  0.495 ( 0.849)\tData  0.000 ( 0.489)\tLoss 6.0873e+00 (6.7825e+00)\tAcc@1   9.38 ( 13.60)\tAcc@5  25.00 ( 22.52)\n",
            "Epoch: [9][  60/1075]\tTime  0.489 ( 0.813)\tData  0.000 ( 0.447)\tLoss 6.3156e+00 (6.6812e+00)\tAcc@1  34.38 ( 14.55)\tAcc@5  43.75 ( 23.57)\n",
            "Epoch: [9][  70/1075]\tTime  0.503 ( 0.799)\tData  0.000 ( 0.428)\tLoss 6.7543e+00 (6.6706e+00)\tAcc@1  29.69 ( 14.90)\tAcc@5  45.31 ( 23.61)\n",
            "Epoch: [9][  80/1075]\tTime  0.487 ( 0.773)\tData  0.000 ( 0.399)\tLoss 6.9997e+00 (6.6923e+00)\tAcc@1  20.31 ( 15.88)\tAcc@5  21.88 ( 24.00)\n",
            "Epoch: [9][  90/1075]\tTime  0.501 ( 0.767)\tData  0.000 ( 0.390)\tLoss 7.0064e+00 (6.7249e+00)\tAcc@1  15.62 ( 15.75)\tAcc@5  18.75 ( 23.52)\n",
            "Epoch: [9][ 100/1075]\tTime  0.511 ( 0.751)\tData  0.000 ( 0.372)\tLoss 7.2209e+00 (6.7658e+00)\tAcc@1  31.25 ( 16.27)\tAcc@5  35.94 ( 23.78)\n",
            "Epoch: [9][ 110/1075]\tTime  0.496 ( 0.744)\tData  0.000 ( 0.363)\tLoss 7.4723e+00 (6.8191e+00)\tAcc@1  28.12 ( 16.50)\tAcc@5  37.50 ( 23.75)\n",
            "Epoch: [9][ 120/1075]\tTime  0.485 ( 0.732)\tData  0.000 ( 0.350)\tLoss 7.5720e+00 (6.8752e+00)\tAcc@1   9.38 ( 16.52)\tAcc@5  17.19 ( 23.61)\n",
            "Epoch: [9][ 130/1075]\tTime  0.506 ( 0.728)\tData  0.000 ( 0.344)\tLoss 7.6382e+00 (6.9300e+00)\tAcc@1  15.62 ( 16.77)\tAcc@5  21.88 ( 23.78)\n",
            "Epoch: [9][ 140/1075]\tTime  0.492 ( 0.720)\tData  0.000 ( 0.335)\tLoss 7.6276e+00 (6.9797e+00)\tAcc@1  29.69 ( 16.73)\tAcc@5  40.62 ( 23.63)\n",
            "Epoch: [9][ 150/1075]\tTime  0.500 ( 0.715)\tData  0.000 ( 0.329)\tLoss 7.5636e+00 (7.0194e+00)\tAcc@1  35.94 ( 16.90)\tAcc@5  35.94 ( 23.89)\n",
            "Epoch: [9][ 160/1075]\tTime  0.510 ( 0.712)\tData  0.000 ( 0.325)\tLoss 7.4666e+00 (7.0503e+00)\tAcc@1  25.00 ( 16.84)\tAcc@5  31.25 ( 23.71)\n",
            "Epoch: [9][ 170/1075]\tTime  0.510 ( 0.707)\tData  0.000 ( 0.319)\tLoss 7.3816e+00 (7.0728e+00)\tAcc@1   9.38 ( 17.05)\tAcc@5  15.62 ( 23.85)\n",
            "Epoch: [9][ 180/1075]\tTime  0.495 ( 0.705)\tData  0.000 ( 0.317)\tLoss 7.3278e+00 (7.0893e+00)\tAcc@1   0.00 ( 17.06)\tAcc@5  10.94 ( 23.77)\n",
            "Epoch: [9][ 190/1075]\tTime  0.500 ( 0.701)\tData  0.000 ( 0.312)\tLoss 7.2488e+00 (7.1002e+00)\tAcc@1  14.06 ( 17.14)\tAcc@5  21.88 ( 23.86)\n",
            "Epoch: [9][ 200/1075]\tTime  0.492 ( 0.698)\tData  0.000 ( 0.309)\tLoss 7.0098e+00 (7.1050e+00)\tAcc@1  17.19 ( 17.02)\tAcc@5  25.00 ( 23.91)\n",
            "Epoch: [9][ 210/1075]\tTime  0.506 ( 0.693)\tData  0.000 ( 0.303)\tLoss 6.2533e+00 (7.0791e+00)\tAcc@1  15.62 ( 16.78)\tAcc@5  23.44 ( 23.83)\n",
            "Epoch: [9][ 220/1075]\tTime  0.496 ( 0.693)\tData  0.000 ( 0.303)\tLoss 6.1684e+00 (7.0426e+00)\tAcc@1   6.25 ( 16.39)\tAcc@5  17.19 ( 23.47)\n",
            "Epoch: [9][ 230/1075]\tTime  0.504 ( 0.687)\tData  0.052 ( 0.297)\tLoss 6.0627e+00 (7.0055e+00)\tAcc@1   9.38 ( 16.02)\tAcc@5  18.75 ( 23.15)\n",
            "Epoch: [9][ 240/1075]\tTime  0.496 ( 0.688)\tData  0.000 ( 0.298)\tLoss 6.2721e+00 (6.9727e+00)\tAcc@1   7.81 ( 15.63)\tAcc@5  12.50 ( 22.74)\n",
            "Epoch: [9][ 250/1075]\tTime  0.494 ( 0.685)\tData  0.000 ( 0.294)\tLoss 6.3823e+00 (6.9473e+00)\tAcc@1  17.19 ( 15.43)\tAcc@5  21.88 ( 22.52)\n",
            "Epoch: [9][ 260/1075]\tTime  0.480 ( 0.685)\tData  0.000 ( 0.294)\tLoss 6.4835e+00 (6.9277e+00)\tAcc@1  10.94 ( 15.35)\tAcc@5  15.62 ( 22.44)\n",
            "Epoch: [9][ 270/1075]\tTime  0.492 ( 0.682)\tData  0.000 ( 0.291)\tLoss 4.7135e+00 (6.8888e+00)\tAcc@1   3.12 ( 15.79)\tAcc@5   6.25 ( 22.94)\n",
            "Epoch: [9][ 280/1075]\tTime  0.480 ( 0.682)\tData  0.000 ( 0.290)\tLoss 5.4403e+00 (6.8399e+00)\tAcc@1  70.31 ( 16.56)\tAcc@5  87.50 ( 23.99)\n",
            "Epoch: [9][ 290/1075]\tTime  0.505 ( 0.681)\tData  0.000 ( 0.289)\tLoss 5.8492e+00 (6.8030e+00)\tAcc@1  76.56 ( 17.15)\tAcc@5  79.69 ( 24.59)\n",
            "Epoch: [9][ 300/1075]\tTime  0.492 ( 0.682)\tData  0.000 ( 0.289)\tLoss 6.8182e+00 (6.7990e+00)\tAcc@1  71.88 ( 17.35)\tAcc@5  71.88 ( 24.72)\n",
            "Epoch: [9][ 310/1075]\tTime  0.496 ( 0.679)\tData  0.001 ( 0.286)\tLoss 6.7130e+00 (6.8005e+00)\tAcc@1  68.75 ( 17.97)\tAcc@5  68.75 ( 25.17)\n",
            "Epoch: [9][ 320/1075]\tTime  0.515 ( 0.678)\tData  0.000 ( 0.284)\tLoss 6.4803e+00 (6.7949e+00)\tAcc@1  26.56 ( 18.72)\tAcc@5  40.62 ( 25.82)\n",
            "Epoch: [9][ 330/1075]\tTime  0.626 ( 0.676)\tData  0.331 ( 0.284)\tLoss 6.1092e+00 (6.7746e+00)\tAcc@1  79.69 ( 19.52)\tAcc@5  81.25 ( 26.49)\n",
            "Epoch: [9][ 340/1075]\tTime  0.565 ( 0.674)\tData  0.258 ( 0.283)\tLoss 6.5179e+00 (6.7643e+00)\tAcc@1   0.00 ( 19.95)\tAcc@5   0.00 ( 26.83)\n",
            "Epoch: [9][ 350/1075]\tTime  0.655 ( 0.674)\tData  0.347 ( 0.285)\tLoss 6.7951e+00 (6.7628e+00)\tAcc@1   0.00 ( 20.25)\tAcc@5   3.12 ( 27.08)\n",
            "Epoch: [9][ 360/1075]\tTime  0.852 ( 0.672)\tData  0.522 ( 0.284)\tLoss 7.1573e+00 (6.7717e+00)\tAcc@1   4.69 ( 20.28)\tAcc@5   4.69 ( 27.01)\n",
            "Epoch: [9][ 370/1075]\tTime  0.657 ( 0.673)\tData  0.366 ( 0.284)\tLoss 7.2706e+00 (6.7877e+00)\tAcc@1   0.00 ( 20.04)\tAcc@5   0.00 ( 26.68)\n",
            "Epoch: [9][ 380/1075]\tTime  0.864 ( 0.671)\tData  0.570 ( 0.283)\tLoss 7.0202e+00 (6.7973e+00)\tAcc@1  28.12 ( 19.93)\tAcc@5  32.81 ( 26.58)\n",
            "Epoch: [9][ 390/1075]\tTime  0.655 ( 0.672)\tData  0.362 ( 0.284)\tLoss 6.8323e+00 (6.8031e+00)\tAcc@1   1.56 ( 19.71)\tAcc@5   4.69 ( 26.33)\n",
            "Epoch: [9][ 400/1075]\tTime  0.735 ( 0.670)\tData  0.425 ( 0.283)\tLoss 6.8158e+00 (6.8071e+00)\tAcc@1  14.06 ( 19.36)\tAcc@5  26.56 ( 25.97)\n",
            "Epoch: [9][ 410/1075]\tTime  0.672 ( 0.671)\tData  0.378 ( 0.283)\tLoss 6.6023e+00 (6.8055e+00)\tAcc@1   0.00 ( 19.05)\tAcc@5   0.00 ( 25.70)\n",
            "Epoch: [9][ 420/1075]\tTime  0.834 ( 0.669)\tData  0.539 ( 0.281)\tLoss 6.8140e+00 (6.8032e+00)\tAcc@1  10.94 ( 18.87)\tAcc@5  14.06 ( 25.49)\n",
            "Epoch: [9][ 430/1075]\tTime  0.985 ( 0.669)\tData  0.686 ( 0.281)\tLoss 6.9895e+00 (6.8065e+00)\tAcc@1  17.19 ( 19.00)\tAcc@5  20.31 ( 25.53)\n",
            "Epoch: [9][ 440/1075]\tTime  0.702 ( 0.668)\tData  0.408 ( 0.281)\tLoss 7.2154e+00 (6.8134e+00)\tAcc@1  20.31 ( 19.01)\tAcc@5  25.00 ( 25.50)\n",
            "Epoch: [9][ 450/1075]\tTime  0.846 ( 0.668)\tData  0.531 ( 0.281)\tLoss 7.3192e+00 (6.8232e+00)\tAcc@1  39.06 ( 19.49)\tAcc@5  43.75 ( 25.97)\n",
            "Epoch: [9][ 460/1075]\tTime  0.771 ( 0.667)\tData  0.462 ( 0.281)\tLoss 7.4198e+00 (6.8350e+00)\tAcc@1   4.69 ( 19.99)\tAcc@5   6.25 ( 26.59)\n",
            "Epoch: [9][ 470/1075]\tTime  0.974 ( 0.666)\tData  0.663 ( 0.280)\tLoss 7.4869e+00 (6.8483e+00)\tAcc@1   0.00 ( 20.26)\tAcc@5   0.00 ( 26.83)\n",
            "Epoch: [9][ 480/1075]\tTime  0.695 ( 0.666)\tData  0.381 ( 0.280)\tLoss 7.5137e+00 (6.8617e+00)\tAcc@1  18.75 ( 20.81)\tAcc@5  25.00 ( 27.50)\n",
            "Epoch: [9][ 490/1075]\tTime  1.008 ( 0.665)\tData  0.710 ( 0.280)\tLoss 7.4828e+00 (6.8743e+00)\tAcc@1  45.31 ( 21.36)\tAcc@5  54.69 ( 28.11)\n",
            "Epoch: [9][ 500/1075]\tTime  0.582 ( 0.665)\tData  0.273 ( 0.281)\tLoss 7.4633e+00 (6.8873e+00)\tAcc@1   9.38 ( 21.56)\tAcc@5  14.06 ( 28.35)\n",
            "Epoch: [9][ 510/1075]\tTime  0.841 ( 0.664)\tData  0.523 ( 0.282)\tLoss 7.4523e+00 (6.8985e+00)\tAcc@1  45.31 ( 22.31)\tAcc@5  56.25 ( 29.12)\n",
            "Epoch: [9][ 520/1075]\tTime  0.610 ( 0.664)\tData  0.317 ( 0.282)\tLoss 7.4075e+00 (6.9089e+00)\tAcc@1   9.38 ( 22.73)\tAcc@5  17.19 ( 29.51)\n",
            "Epoch: [9][ 530/1075]\tTime  0.775 ( 0.663)\tData  0.465 ( 0.282)\tLoss 7.5900e+00 (6.9173e+00)\tAcc@1   4.69 ( 22.41)\tAcc@5   6.25 ( 29.11)\n",
            "Epoch: [9][ 540/1075]\tTime  0.730 ( 0.664)\tData  0.434 ( 0.282)\tLoss 7.3150e+00 (6.9230e+00)\tAcc@1   1.56 ( 22.09)\tAcc@5   6.25 ( 28.75)\n",
            "Epoch: [9][ 550/1075]\tTime  0.654 ( 0.662)\tData  0.361 ( 0.281)\tLoss 7.2073e+00 (6.9281e+00)\tAcc@1   3.12 ( 21.74)\tAcc@5   6.25 ( 28.34)\n",
            "Epoch: [9][ 560/1075]\tTime  0.617 ( 0.663)\tData  0.323 ( 0.282)\tLoss 7.1844e+00 (6.9333e+00)\tAcc@1   0.00 ( 21.39)\tAcc@5   6.25 ( 27.95)\n",
            "Epoch: [9][ 570/1075]\tTime  0.890 ( 0.662)\tData  0.577 ( 0.281)\tLoss 7.0391e+00 (6.9366e+00)\tAcc@1   1.56 ( 21.10)\tAcc@5   9.38 ( 27.67)\n",
            "Epoch: [9][ 580/1075]\tTime  0.805 ( 0.663)\tData  0.509 ( 0.282)\tLoss 6.7144e+00 (6.9353e+00)\tAcc@1   0.00 ( 20.80)\tAcc@5   6.25 ( 27.36)\n",
            "Epoch: [9][ 590/1075]\tTime  0.777 ( 0.662)\tData  0.468 ( 0.281)\tLoss 6.8616e+00 (6.9324e+00)\tAcc@1   1.56 ( 20.48)\tAcc@5   3.12 ( 27.00)\n",
            "Epoch: [9][ 600/1075]\tTime  0.996 ( 0.663)\tData  0.700 ( 0.281)\tLoss 6.8318e+00 (6.9303e+00)\tAcc@1   3.12 ( 20.17)\tAcc@5   4.69 ( 26.65)\n",
            "Epoch: [9][ 610/1075]\tTime  0.613 ( 0.662)\tData  0.320 ( 0.280)\tLoss 6.8084e+00 (6.9289e+00)\tAcc@1   4.69 ( 19.87)\tAcc@5  12.50 ( 26.30)\n",
            "Epoch: [9][ 620/1075]\tTime  1.000 ( 0.662)\tData  0.708 ( 0.281)\tLoss 6.6184e+00 (6.9243e+00)\tAcc@1   1.56 ( 19.59)\tAcc@5  14.06 ( 26.01)\n",
            "Epoch: [9][ 630/1075]\tTime  0.761 ( 0.661)\tData  0.466 ( 0.280)\tLoss 6.4948e+00 (6.9176e+00)\tAcc@1   3.12 ( 19.32)\tAcc@5   6.25 ( 25.73)\n",
            "Epoch: [9][ 640/1075]\tTime  0.968 ( 0.661)\tData  0.657 ( 0.280)\tLoss 6.6707e+00 (6.9131e+00)\tAcc@1   3.12 ( 19.08)\tAcc@5   9.38 ( 25.46)\n",
            "Epoch: [9][ 650/1075]\tTime  0.783 ( 0.661)\tData  0.478 ( 0.280)\tLoss 6.6053e+00 (6.9087e+00)\tAcc@1   3.12 ( 18.85)\tAcc@5   7.81 ( 25.23)\n",
            "Epoch: [9][ 660/1075]\tTime  1.021 ( 0.661)\tData  0.713 ( 0.280)\tLoss 6.5677e+00 (6.9036e+00)\tAcc@1   3.12 ( 18.62)\tAcc@5   7.81 ( 24.98)\n",
            "Epoch: [9][ 670/1075]\tTime  0.797 ( 0.661)\tData  0.487 ( 0.280)\tLoss 6.7654e+00 (6.8998e+00)\tAcc@1   4.69 ( 18.39)\tAcc@5   4.69 ( 24.75)\n",
            "Epoch: [9][ 680/1075]\tTime  0.653 ( 0.660)\tData  0.359 ( 0.279)\tLoss 6.9112e+00 (6.8989e+00)\tAcc@1   7.81 ( 18.18)\tAcc@5   9.38 ( 24.53)\n",
            "Epoch: [9][ 690/1075]\tTime  0.630 ( 0.660)\tData  0.335 ( 0.279)\tLoss 7.1954e+00 (6.9013e+00)\tAcc@1   0.00 ( 17.97)\tAcc@5   9.38 ( 24.29)\n",
            "Epoch: [9][ 700/1075]\tTime  0.896 ( 0.660)\tData  0.603 ( 0.279)\tLoss 5.3552e+00 (6.8927e+00)\tAcc@1   1.56 ( 17.79)\tAcc@5  14.06 ( 24.16)\n",
            "Epoch: [9][ 710/1075]\tTime  0.762 ( 0.661)\tData  0.452 ( 0.279)\tLoss 6.1707e+00 (6.8781e+00)\tAcc@1   0.00 ( 17.56)\tAcc@5   6.25 ( 23.91)\n",
            "Epoch: [9][ 720/1075]\tTime  0.732 ( 0.660)\tData  0.437 ( 0.279)\tLoss 6.5253e+00 (6.8713e+00)\tAcc@1   4.69 ( 17.37)\tAcc@5  18.75 ( 23.75)\n",
            "Epoch: [9][ 730/1075]\tTime  0.574 ( 0.660)\tData  0.266 ( 0.279)\tLoss 6.2763e+00 (6.8643e+00)\tAcc@1   7.81 ( 17.20)\tAcc@5  12.50 ( 23.60)\n",
            "Epoch: [9][ 740/1075]\tTime  0.761 ( 0.660)\tData  0.468 ( 0.279)\tLoss 6.4696e+00 (6.8579e+00)\tAcc@1   6.25 ( 17.03)\tAcc@5  12.50 ( 23.43)\n",
            "Epoch: [9][ 750/1075]\tTime  0.913 ( 0.661)\tData  0.603 ( 0.279)\tLoss 6.1433e+00 (6.8513e+00)\tAcc@1   3.12 ( 16.84)\tAcc@5  10.94 ( 23.24)\n",
            "Epoch: [9][ 760/1075]\tTime  0.676 ( 0.660)\tData  0.382 ( 0.279)\tLoss 6.1085e+00 (6.8405e+00)\tAcc@1   3.12 ( 16.70)\tAcc@5  12.50 ( 23.12)\n",
            "Epoch: [9][ 770/1075]\tTime  0.875 ( 0.659)\tData  0.565 ( 0.278)\tLoss 6.6688e+00 (6.8357e+00)\tAcc@1   4.69 ( 16.52)\tAcc@5   7.81 ( 22.92)\n",
            "Epoch: [9][ 780/1075]\tTime  0.709 ( 0.659)\tData  0.396 ( 0.278)\tLoss 6.8576e+00 (6.8353e+00)\tAcc@1   7.81 ( 16.35)\tAcc@5  10.94 ( 22.71)\n",
            "Epoch: [9][ 790/1075]\tTime  1.191 ( 0.659)\tData  0.875 ( 0.278)\tLoss 6.3365e+00 (6.8316e+00)\tAcc@1   4.69 ( 16.20)\tAcc@5  12.50 ( 22.59)\n",
            "Epoch: [9][ 800/1075]\tTime  0.757 ( 0.659)\tData  0.463 ( 0.278)\tLoss 6.2528e+00 (6.8247e+00)\tAcc@1   6.25 ( 16.08)\tAcc@5   9.38 ( 22.46)\n",
            "Epoch: [9][ 810/1075]\tTime  1.112 ( 0.659)\tData  0.800 ( 0.278)\tLoss 6.4818e+00 (6.8192e+00)\tAcc@1   4.69 ( 15.94)\tAcc@5  10.94 ( 22.31)\n",
            "Epoch: [9][ 820/1075]\tTime  0.791 ( 0.659)\tData  0.498 ( 0.278)\tLoss 6.9677e+00 (6.8176e+00)\tAcc@1   0.00 ( 15.79)\tAcc@5   6.25 ( 22.16)\n",
            "Epoch: [9][ 830/1075]\tTime  0.863 ( 0.659)\tData  0.546 ( 0.278)\tLoss 7.0155e+00 (6.8189e+00)\tAcc@1   7.81 ( 15.64)\tAcc@5  15.62 ( 22.02)\n",
            "Epoch: [9][ 840/1075]\tTime  0.604 ( 0.659)\tData  0.295 ( 0.278)\tLoss 7.1901e+00 (6.8227e+00)\tAcc@1  10.94 ( 15.51)\tAcc@5  18.75 ( 21.88)\n",
            "Epoch: [9][ 850/1075]\tTime  0.573 ( 0.658)\tData  0.265 ( 0.277)\tLoss 7.2581e+00 (6.8275e+00)\tAcc@1   1.56 ( 15.38)\tAcc@5   9.38 ( 21.76)\n",
            "Epoch: [9][ 860/1075]\tTime  0.841 ( 0.658)\tData  0.548 ( 0.277)\tLoss 7.2279e+00 (6.8321e+00)\tAcc@1   4.69 ( 15.26)\tAcc@5  15.62 ( 21.67)\n",
            "Epoch: [9][ 870/1075]\tTime  0.642 ( 0.658)\tData  0.348 ( 0.277)\tLoss 7.1097e+00 (6.8363e+00)\tAcc@1   4.69 ( 15.15)\tAcc@5  20.31 ( 21.58)\n",
            "Epoch: [9][ 880/1075]\tTime  0.755 ( 0.658)\tData  0.463 ( 0.277)\tLoss 7.1283e+00 (6.8396e+00)\tAcc@1   0.00 ( 15.02)\tAcc@5  12.50 ( 21.49)\n",
            "Epoch: [9][ 890/1075]\tTime  0.741 ( 0.658)\tData  0.445 ( 0.277)\tLoss 7.3371e+00 (6.8427e+00)\tAcc@1   9.38 ( 14.91)\tAcc@5  17.19 ( 21.42)\n",
            "Epoch: [9][ 900/1075]\tTime  0.688 ( 0.658)\tData  0.389 ( 0.277)\tLoss 6.6157e+00 (6.8426e+00)\tAcc@1   9.38 ( 14.80)\tAcc@5  14.06 ( 21.30)\n",
            "Epoch: [9][ 910/1075]\tTime  0.826 ( 0.657)\tData  0.512 ( 0.277)\tLoss 5.7425e+00 (6.8331e+00)\tAcc@1  15.62 ( 14.73)\tAcc@5  25.00 ( 21.27)\n",
            "Epoch: [9][ 920/1075]\tTime  0.966 ( 0.658)\tData  0.671 ( 0.277)\tLoss 6.4542e+00 (6.8260e+00)\tAcc@1   6.25 ( 14.64)\tAcc@5   9.38 ( 21.22)\n",
            "Epoch: [9][ 930/1075]\tTime  0.565 ( 0.657)\tData  0.256 ( 0.276)\tLoss 6.2191e+00 (6.8213e+00)\tAcc@1   9.38 ( 14.55)\tAcc@5  10.94 ( 21.15)\n",
            "Epoch: [9][ 940/1075]\tTime  0.964 ( 0.657)\tData  0.657 ( 0.276)\tLoss 5.7626e+00 (6.8110e+00)\tAcc@1   4.69 ( 14.48)\tAcc@5  10.94 ( 21.13)\n",
            "Epoch: [9][ 950/1075]\tTime  0.595 ( 0.657)\tData  0.285 ( 0.276)\tLoss 6.5565e+00 (6.8047e+00)\tAcc@1   1.56 ( 14.37)\tAcc@5   9.38 ( 21.03)\n",
            "Epoch: [9][ 960/1075]\tTime  1.080 ( 0.656)\tData  0.777 ( 0.275)\tLoss 6.3782e+00 (6.8017e+00)\tAcc@1   6.25 ( 14.27)\tAcc@5  17.19 ( 20.96)\n",
            "Epoch: [9][ 970/1075]\tTime  0.657 ( 0.656)\tData  0.366 ( 0.275)\tLoss 6.0456e+00 (6.7951e+00)\tAcc@1  12.50 ( 14.20)\tAcc@5  25.00 ( 20.92)\n",
            "Epoch: [9][ 980/1075]\tTime  0.490 ( 0.655)\tData  0.000 ( 0.275)\tLoss 6.2721e+00 (6.7890e+00)\tAcc@1   6.25 ( 14.11)\tAcc@5  10.94 ( 20.88)\n",
            "Epoch: [9][ 990/1075]\tTime  0.492 ( 0.656)\tData  0.000 ( 0.276)\tLoss 6.9231e+00 (6.7867e+00)\tAcc@1   3.12 ( 14.02)\tAcc@5  14.06 ( 20.79)\n",
            "Epoch: [9][1000/1075]\tTime  0.505 ( 0.655)\tData  0.000 ( 0.275)\tLoss 6.0642e+00 (6.7849e+00)\tAcc@1   4.69 ( 13.93)\tAcc@5  20.31 ( 20.72)\n",
            "Epoch: [9][1010/1075]\tTime  0.492 ( 0.655)\tData  0.000 ( 0.275)\tLoss 6.9972e+00 (6.7857e+00)\tAcc@1   6.25 ( 13.86)\tAcc@5  14.06 ( 20.68)\n",
            "Epoch: [9][1020/1075]\tTime  0.734 ( 0.655)\tData  0.426 ( 0.275)\tLoss 6.9948e+00 (6.7855e+00)\tAcc@1   1.56 ( 13.78)\tAcc@5  10.94 ( 20.60)\n",
            "Epoch: [9][1030/1075]\tTime  0.767 ( 0.655)\tData  0.473 ( 0.275)\tLoss 6.6818e+00 (6.7832e+00)\tAcc@1   1.56 ( 13.70)\tAcc@5   6.25 ( 20.50)\n",
            "Epoch: [9][1040/1075]\tTime  0.830 ( 0.654)\tData  0.538 ( 0.275)\tLoss 6.6984e+00 (6.7792e+00)\tAcc@1   4.69 ( 13.62)\tAcc@5   6.25 ( 20.44)\n",
            "Epoch: [9][1050/1075]\tTime  1.053 ( 0.654)\tData  0.743 ( 0.276)\tLoss 6.6697e+00 (6.7765e+00)\tAcc@1   4.69 ( 13.56)\tAcc@5  10.94 ( 20.38)\n",
            "Epoch: [9][1060/1075]\tTime  0.505 ( 0.654)\tData  0.113 ( 0.276)\tLoss 7.2903e+00 (6.7777e+00)\tAcc@1   1.56 ( 13.46)\tAcc@5   4.69 ( 20.27)\n",
            "Epoch: [9][1070/1075]\tTime  1.146 ( 0.654)\tData  0.806 ( 0.276)\tLoss 7.0493e+00 (6.7808e+00)\tAcc@1   4.69 ( 13.40)\tAcc@5   7.81 ( 20.20)\n",
            "epoch: 9\n",
            "2023-04-19 13:43:33.332283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-19 13:43:38.097739: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Epoch: [10][   0/1075]\tTime 11.456 (11.456)\tData 11.139 (11.139)\tLoss 7.3308e+00 (7.3308e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   1.56 (  1.56)\n",
            "Epoch: [10][  10/1075]\tTime  0.772 ( 1.591)\tData  0.462 ( 1.227)\tLoss 7.1057e+00 (7.3082e+00)\tAcc@1   1.56 (  1.85)\tAcc@5   7.81 (  7.95)\n",
            "Epoch: [10][  20/1075]\tTime  0.937 ( 1.157)\tData  0.644 ( 0.788)\tLoss 6.9223e+00 (7.1792e+00)\tAcc@1   3.12 (  3.65)\tAcc@5  12.50 ( 10.34)\n",
            "Epoch: [10][  30/1075]\tTime  0.636 ( 0.968)\tData  0.327 ( 0.613)\tLoss 6.7538e+00 (7.1231e+00)\tAcc@1   4.69 (  3.63)\tAcc@5   9.38 (  9.88)\n",
            "Epoch: [10][  40/1075]\tTime  1.189 ( 0.894)\tData  0.851 ( 0.548)\tLoss 6.6819e+00 (6.9702e+00)\tAcc@1   3.12 (  4.46)\tAcc@5  18.75 ( 12.00)\n",
            "Epoch: [10][  50/1075]\tTime  0.677 ( 0.840)\tData  0.385 ( 0.487)\tLoss 6.5312e+00 (6.8515e+00)\tAcc@1   6.25 (  4.35)\tAcc@5  14.06 ( 12.29)\n",
            "Epoch: [10][  60/1075]\tTime  1.137 ( 0.812)\tData  0.827 ( 0.454)\tLoss 6.5815e+00 (6.8189e+00)\tAcc@1   3.12 (  4.18)\tAcc@5  12.50 ( 11.83)\n",
            "Epoch: [10][  70/1075]\tTime  0.772 ( 0.789)\tData  0.464 ( 0.427)\tLoss 6.6295e+00 (6.7798e+00)\tAcc@1   6.25 (  4.45)\tAcc@5  15.62 ( 12.41)\n",
            "Epoch: [10][  80/1075]\tTime  0.742 ( 0.764)\tData  0.401 ( 0.400)\tLoss 6.6849e+00 (6.7575e+00)\tAcc@1  14.06 (  4.92)\tAcc@5  17.19 ( 13.02)\n",
            "Epoch: [10][  90/1075]\tTime  0.571 ( 0.752)\tData  0.277 ( 0.386)\tLoss 6.8009e+00 (6.7524e+00)\tAcc@1  10.94 (  5.25)\tAcc@5  21.88 ( 13.65)\n",
            "Epoch: [10][ 100/1075]\tTime  0.702 ( 0.736)\tData  0.405 ( 0.374)\tLoss 6.5610e+00 (6.7301e+00)\tAcc@1   4.69 (  5.85)\tAcc@5  17.19 ( 14.51)\n",
            "Epoch: [10][ 110/1075]\tTime  0.698 ( 0.730)\tData  0.406 ( 0.371)\tLoss 6.8956e+00 (6.7337e+00)\tAcc@1   3.12 (  5.74)\tAcc@5  10.94 ( 14.34)\n",
            "Epoch: [10][ 120/1075]\tTime  0.705 ( 0.719)\tData  0.412 ( 0.359)\tLoss 6.9022e+00 (6.7474e+00)\tAcc@1  12.50 (  6.03)\tAcc@5  21.88 ( 14.75)\n",
            "Epoch: [10][ 130/1075]\tTime  0.633 ( 0.716)\tData  0.332 ( 0.354)\tLoss 6.7193e+00 (6.7407e+00)\tAcc@1   7.81 (  6.29)\tAcc@5  18.75 ( 14.97)\n",
            "Epoch: [10][ 140/1075]\tTime  0.508 ( 0.707)\tData  0.196 ( 0.344)\tLoss 6.4061e+00 (6.7276e+00)\tAcc@1  12.50 (  6.41)\tAcc@5  15.62 ( 15.04)\n",
            "Epoch: [10][ 150/1075]\tTime  0.978 ( 0.706)\tData  0.667 ( 0.342)\tLoss 6.4685e+00 (6.7159e+00)\tAcc@1  20.31 (  6.60)\tAcc@5  26.56 ( 15.07)\n",
            "Epoch: [10][ 160/1075]\tTime  0.706 ( 0.700)\tData  0.409 ( 0.335)\tLoss 6.8875e+00 (6.6995e+00)\tAcc@1  21.88 (  7.09)\tAcc@5  31.25 ( 15.75)\n",
            "Epoch: [10][ 170/1075]\tTime  0.902 ( 0.697)\tData  0.578 ( 0.330)\tLoss 5.7763e+00 (6.6634e+00)\tAcc@1  29.69 (  7.95)\tAcc@5  42.19 ( 16.67)\n",
            "Epoch: [10][ 180/1075]\tTime  0.694 ( 0.693)\tData  0.384 ( 0.326)\tLoss 6.0441e+00 (6.6142e+00)\tAcc@1   7.81 (  9.01)\tAcc@5  20.31 ( 17.82)\n",
            "Epoch: [10][ 190/1075]\tTime  0.962 ( 0.689)\tData  0.651 ( 0.321)\tLoss 6.7516e+00 (6.6087e+00)\tAcc@1   4.69 (  9.04)\tAcc@5  12.50 ( 17.78)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 446, in <module>\n",
            "    main()\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 141, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 239, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 197, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 109, in join\n",
            "    ready = multiprocessing.connection.wait(\n",
            "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 931, in wait\n",
            "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f485d5cc550>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
            "Error in atexit._run_exitfuncs:\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.9/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.9/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.9/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.9/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrPC1CMTm2BL",
        "outputId": "9461c65a-3fe6-41db-df05-33b86131a926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaminguitvoer ingekort tot de laatste 5000 regels.\u001b[0m\n",
            "2023-03-25 02:24:40.346022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:40.346126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:40.346146: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:24:44.247293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:44.247388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:44.247406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:24:48.142188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:48.142289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:48.142308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:24:52.076620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:52.076728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:52.076746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:24:55.964061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:55.964157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:55.964175: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:24:59.839205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:59.839307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:24:59.839326: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:25:03.713512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:25:03.713606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:25:03.713625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:25:07.597105: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:25:07.597207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:25:07.597226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [122][  0/268]\tTime 54.225 (54.225)\tData 53.883 (53.883)\tLoss 2.1923e+00 (2.1923e+00)\tAcc@1  66.02 ( 66.02)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [122][ 10/268]\tTime  0.412 ( 5.310)\tData  0.000 ( 4.917)\tLoss 2.9198e+00 (2.8720e+00)\tAcc@1  26.17 ( 33.35)\tAcc@5  72.27 ( 73.15)\n",
            "Epoch: [122][ 20/268]\tTime  0.411 ( 3.080)\tData  0.000 ( 2.688)\tLoss 2.6991e+00 (2.7807e+00)\tAcc@1  30.08 ( 35.03)\tAcc@5  86.33 ( 76.92)\n",
            "Epoch: [122][ 30/268]\tTime  0.423 ( 2.302)\tData  0.010 ( 1.911)\tLoss 2.8131e+00 (2.7234e+00)\tAcc@1  27.34 ( 36.04)\tAcc@5  73.44 ( 78.26)\n",
            "Epoch: [122][ 40/268]\tTime  0.411 ( 1.893)\tData  0.001 ( 1.503)\tLoss 2.8730e+00 (2.7707e+00)\tAcc@1  25.00 ( 34.81)\tAcc@5  71.09 ( 76.29)\n",
            "Epoch: [122][ 50/268]\tTime  1.695 ( 1.638)\tData  1.377 ( 1.249)\tLoss 2.4241e+00 (2.7039e+00)\tAcc@1  52.73 ( 38.31)\tAcc@5  90.23 ( 78.45)\n",
            "Epoch: [122][ 60/268]\tTime  1.415 ( 1.455)\tData  1.079 ( 1.064)\tLoss 2.2437e+00 (2.6890e+00)\tAcc@1  52.34 ( 38.72)\tAcc@5  92.19 ( 79.07)\n",
            "Epoch: [122][ 70/268]\tTime  0.418 ( 1.325)\tData  0.000 ( 0.933)\tLoss 2.0105e+00 (2.6602e+00)\tAcc@1  72.66 ( 39.55)\tAcc@5  97.66 ( 80.04)\n",
            "Epoch: [122][ 80/268]\tTime  0.417 ( 1.236)\tData  0.000 ( 0.845)\tLoss 2.8490e+00 (2.6346e+00)\tAcc@1  25.39 ( 40.52)\tAcc@5  73.44 ( 80.78)\n",
            "Epoch: [122][ 90/268]\tTime  0.417 ( 1.173)\tData  0.012 ( 0.782)\tLoss 2.8148e+00 (2.6188e+00)\tAcc@1  26.95 ( 41.32)\tAcc@5  69.14 ( 81.13)\n",
            "Epoch: [122][100/268]\tTime  0.437 ( 1.115)\tData  0.012 ( 0.724)\tLoss 2.5614e+00 (2.6196e+00)\tAcc@1  51.95 ( 41.56)\tAcc@5  87.50 ( 81.43)\n",
            "Epoch: [122][110/268]\tTime  0.416 ( 1.075)\tData  0.012 ( 0.683)\tLoss 2.1699e+00 (2.6095e+00)\tAcc@1  65.23 ( 41.81)\tAcc@5  93.75 ( 81.73)\n",
            "Epoch: [122][120/268]\tTime  2.665 ( 1.039)\tData  2.332 ( 0.647)\tLoss 2.8756e+00 (2.6154e+00)\tAcc@1  23.05 ( 41.55)\tAcc@5  71.48 ( 81.62)\n",
            "Epoch: [122][130/268]\tTime  0.439 ( 0.992)\tData  0.000 ( 0.598)\tLoss 2.4477e+00 (2.6080e+00)\tAcc@1  44.14 ( 41.88)\tAcc@5  89.45 ( 81.87)\n",
            "Epoch: [122][140/268]\tTime  0.417 ( 0.965)\tData  0.001 ( 0.572)\tLoss 2.7351e+00 (2.6033e+00)\tAcc@1  30.47 ( 42.00)\tAcc@5  76.56 ( 81.97)\n",
            "Epoch: [122][150/268]\tTime  0.423 ( 0.942)\tData  0.009 ( 0.549)\tLoss 2.0838e+00 (2.6031e+00)\tAcc@1  64.06 ( 42.07)\tAcc@5  94.14 ( 82.06)\n",
            "Epoch: [122][160/268]\tTime  0.423 ( 0.921)\tData  0.000 ( 0.528)\tLoss 2.7638e+00 (2.5958e+00)\tAcc@1  40.62 ( 42.35)\tAcc@5  80.47 ( 82.39)\n",
            "Epoch: [122][170/268]\tTime  0.828 ( 0.903)\tData  0.510 ( 0.510)\tLoss 2.1186e+00 (2.5882e+00)\tAcc@1  58.98 ( 42.52)\tAcc@5  93.36 ( 82.56)\n",
            "Epoch: [122][180/268]\tTime  1.683 ( 0.883)\tData  1.359 ( 0.490)\tLoss 2.2055e+00 (2.5777e+00)\tAcc@1  61.72 ( 43.18)\tAcc@5  94.53 ( 82.83)\n",
            "Epoch: [122][190/268]\tTime  0.416 ( 0.862)\tData  0.013 ( 0.469)\tLoss 2.5230e+00 (2.5719e+00)\tAcc@1  41.41 ( 43.39)\tAcc@5  85.94 ( 83.01)\n",
            "Epoch: [122][200/268]\tTime  0.416 ( 0.854)\tData  0.013 ( 0.461)\tLoss 2.1623e+00 (2.5717e+00)\tAcc@1  62.89 ( 43.31)\tAcc@5  90.23 ( 82.98)\n",
            "Epoch: [122][210/268]\tTime  0.428 ( 0.841)\tData  0.000 ( 0.448)\tLoss 2.3327e+00 (2.5666e+00)\tAcc@1  59.77 ( 43.47)\tAcc@5  94.14 ( 83.13)\n",
            "Epoch: [122][220/268]\tTime  0.417 ( 0.833)\tData  0.000 ( 0.440)\tLoss 2.1752e+00 (2.5679e+00)\tAcc@1  59.38 ( 43.35)\tAcc@5  94.14 ( 83.04)\n",
            "Epoch: [122][230/268]\tTime  1.095 ( 0.823)\tData  0.746 ( 0.430)\tLoss 2.8425e+00 (2.5718e+00)\tAcc@1  30.47 ( 43.14)\tAcc@5  70.31 ( 82.93)\n",
            "Epoch: [122][240/268]\tTime  1.806 ( 0.811)\tData  1.482 ( 0.418)\tLoss 2.3024e+00 (2.5658e+00)\tAcc@1  53.12 ( 43.48)\tAcc@5  92.97 ( 83.15)\n",
            "Epoch: [122][250/268]\tTime  0.416 ( 0.799)\tData  0.000 ( 0.406)\tLoss 2.8262e+00 (2.5705e+00)\tAcc@1  26.17 ( 43.25)\tAcc@5  73.05 ( 83.03)\n",
            "Epoch: [122][260/268]\tTime  0.415 ( 0.788)\tData  0.000 ( 0.394)\tLoss 2.6772e+00 (2.5708e+00)\tAcc@1  31.64 ( 43.18)\tAcc@5  78.52 ( 83.02)\n",
            "epoch: 122\n",
            "2023-03-25 02:27:54.886393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:27:54.886490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:27:54.886508: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:27:58.766497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:27:58.766627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:27:58.766650: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:02.714834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:02.714934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:02.714951: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:06.604085: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:06.604180: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:06.604200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:10.557935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:10.558034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:10.558054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:14.525203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:14.525303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:14.525320: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:18.435110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:18.435202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:18.435221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:22.291640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:22.291756: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:22.291776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:26.204703: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:26.204801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:26.204819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:30.117368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:30.117463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:30.117481: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:33.992392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:33.992509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:33.992532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:28:37.886960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:37.887061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:28:37.887085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [123][  0/268]\tTime 54.894 (54.894)\tData 54.537 (54.537)\tLoss 2.8385e+00 (2.8385e+00)\tAcc@1  26.17 ( 26.17)\tAcc@5  67.19 ( 67.19)\n",
            "Epoch: [123][ 10/268]\tTime  0.419 ( 5.378)\tData  0.000 ( 4.974)\tLoss 2.2271e+00 (2.5143e+00)\tAcc@1  64.45 ( 45.38)\tAcc@5  94.92 ( 81.92)\n",
            "Epoch: [123][ 20/268]\tTime  0.417 ( 3.159)\tData  0.000 ( 2.755)\tLoss 2.1976e+00 (2.5833e+00)\tAcc@1  58.20 ( 40.61)\tAcc@5  92.97 ( 80.64)\n",
            "Epoch: [123][ 30/268]\tTime  0.417 ( 2.301)\tData  0.000 ( 1.903)\tLoss 2.5648e+00 (2.5837e+00)\tAcc@1  41.80 ( 40.02)\tAcc@5  88.67 ( 81.33)\n",
            "Epoch: [123][ 40/268]\tTime  0.416 ( 1.894)\tData  0.000 ( 1.498)\tLoss 1.8196e+00 (2.5759e+00)\tAcc@1  86.72 ( 41.08)\tAcc@5  97.27 ( 81.71)\n",
            "Epoch: [123][ 50/268]\tTime  0.423 ( 1.638)\tData  0.000 ( 1.242)\tLoss 2.7717e+00 (2.5515e+00)\tAcc@1  26.17 ( 42.69)\tAcc@5  77.34 ( 82.31)\n",
            "Epoch: [123][ 60/268]\tTime  1.523 ( 1.456)\tData  1.190 ( 1.060)\tLoss 2.4293e+00 (2.5529e+00)\tAcc@1  50.39 ( 42.45)\tAcc@5  89.06 ( 82.33)\n",
            "Epoch: [123][ 70/268]\tTime  0.433 ( 1.335)\tData  0.000 ( 0.936)\tLoss 2.8763e+00 (2.5654e+00)\tAcc@1  23.05 ( 41.66)\tAcc@5  72.27 ( 82.03)\n",
            "Epoch: [123][ 80/268]\tTime  0.416 ( 1.248)\tData  0.013 ( 0.850)\tLoss 2.3872e+00 (2.5433e+00)\tAcc@1  48.05 ( 42.49)\tAcc@5  92.19 ( 82.95)\n",
            "Epoch: [123][ 90/268]\tTime  0.416 ( 1.170)\tData  0.000 ( 0.772)\tLoss 2.3600e+00 (2.5522e+00)\tAcc@1  62.50 ( 42.33)\tAcc@5  91.80 ( 82.85)\n",
            "Epoch: [123][100/268]\tTime  0.418 ( 1.121)\tData  0.000 ( 0.725)\tLoss 2.6750e+00 (2.5457e+00)\tAcc@1  29.30 ( 43.24)\tAcc@5  85.94 ( 83.19)\n",
            "Epoch: [123][110/268]\tTime  0.411 ( 1.076)\tData  0.000 ( 0.681)\tLoss 2.0013e+00 (2.5326e+00)\tAcc@1  86.72 ( 44.20)\tAcc@5  96.48 ( 83.61)\n",
            "Epoch: [123][120/268]\tTime  0.582 ( 1.023)\tData  0.218 ( 0.627)\tLoss 2.2396e+00 (2.5332e+00)\tAcc@1  55.47 ( 44.19)\tAcc@5  92.19 ( 83.61)\n",
            "Epoch: [123][130/268]\tTime  0.448 ( 0.997)\tData  0.001 ( 0.600)\tLoss 2.3438e+00 (2.5353e+00)\tAcc@1  45.70 ( 43.98)\tAcc@5  92.97 ( 83.51)\n",
            "Epoch: [123][140/268]\tTime  0.436 ( 0.968)\tData  0.000 ( 0.570)\tLoss 2.8348e+00 (2.5608e+00)\tAcc@1  24.22 ( 43.45)\tAcc@5  69.92 ( 82.64)\n",
            "Epoch: [123][150/268]\tTime  0.421 ( 0.945)\tData  0.000 ( 0.548)\tLoss 2.3828e+00 (2.5642e+00)\tAcc@1  47.66 ( 43.27)\tAcc@5  90.23 ( 82.61)\n",
            "Epoch: [123][160/268]\tTime  0.418 ( 0.926)\tData  0.000 ( 0.528)\tLoss 2.0877e+00 (2.5707e+00)\tAcc@1  80.86 ( 42.82)\tAcc@5  94.14 ( 82.36)\n",
            "Epoch: [123][170/268]\tTime  0.413 ( 0.909)\tData  0.000 ( 0.511)\tLoss 2.4925e+00 (2.5647e+00)\tAcc@1  47.27 ( 43.24)\tAcc@5  88.28 ( 82.34)\n",
            "Epoch: [123][180/268]\tTime  0.411 ( 0.882)\tData  0.000 ( 0.483)\tLoss 2.9201e+00 (2.5664e+00)\tAcc@1  24.22 ( 43.22)\tAcc@5  66.41 ( 82.16)\n",
            "Epoch: [123][190/268]\tTime  0.416 ( 0.868)\tData  0.003 ( 0.469)\tLoss 2.0135e+00 (2.5655e+00)\tAcc@1  76.17 ( 43.47)\tAcc@5  96.09 ( 82.11)\n",
            "Epoch: [123][200/268]\tTime  0.416 ( 0.856)\tData  0.000 ( 0.457)\tLoss 2.3612e+00 (2.5616e+00)\tAcc@1  48.44 ( 43.67)\tAcc@5  92.97 ( 82.25)\n",
            "Epoch: [123][210/268]\tTime  0.423 ( 0.847)\tData  0.000 ( 0.448)\tLoss 3.2565e+00 (2.5713e+00)\tAcc@1  10.55 ( 43.05)\tAcc@5  62.89 ( 81.96)\n",
            "Epoch: [123][220/268]\tTime  0.415 ( 0.835)\tData  0.000 ( 0.436)\tLoss 1.9558e+00 (2.5666e+00)\tAcc@1  78.52 ( 43.15)\tAcc@5  95.70 ( 82.13)\n",
            "Epoch: [123][230/268]\tTime  0.417 ( 0.825)\tData  0.000 ( 0.426)\tLoss 2.9159e+00 (2.5656e+00)\tAcc@1  22.66 ( 43.28)\tAcc@5  67.58 ( 82.09)\n",
            "Epoch: [123][240/268]\tTime  0.426 ( 0.808)\tData  0.000 ( 0.409)\tLoss 2.2049e+00 (2.5597e+00)\tAcc@1  52.73 ( 43.54)\tAcc@5  94.53 ( 82.23)\n",
            "Epoch: [123][250/268]\tTime  0.409 ( 0.800)\tData  0.000 ( 0.400)\tLoss 2.8187e+00 (2.5586e+00)\tAcc@1  24.22 ( 43.48)\tAcc@5  71.88 ( 82.22)\n",
            "Epoch: [123][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.390)\tLoss 2.3668e+00 (2.5573e+00)\tAcc@1  47.66 ( 43.60)\tAcc@5  91.02 ( 82.30)\n",
            "epoch: 123\n",
            "2023-03-25 02:31:25.698227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:25.698332: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:25.698351: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:29.611869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:29.611970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:29.611990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:33.519167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:33.519269: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:33.519290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:37.489292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:37.489390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:37.489409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:41.408757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:41.408854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:41.408873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:45.310250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:45.310345: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:45.310362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:49.199158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:49.199251: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:49.199269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:53.106551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:53.106648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:53.106675: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:31:56.999466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:56.999578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:31:56.999597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:32:00.934823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:00.934919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:00.934936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:32:04.838820: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:04.838910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:04.838927: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:32:08.749174: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:08.749292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:32:08.749310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [124][  0/268]\tTime 56.269 (56.269)\tData 55.933 (55.933)\tLoss 3.1302e+00 (3.1302e+00)\tAcc@1  28.91 ( 28.91)\tAcc@5  64.45 ( 64.45)\n",
            "Epoch: [124][ 10/268]\tTime  0.416 ( 5.495)\tData  0.001 ( 5.094)\tLoss 3.0812e+00 (2.8826e+00)\tAcc@1  20.31 ( 31.21)\tAcc@5  62.50 ( 69.89)\n",
            "Epoch: [124][ 20/268]\tTime  0.411 ( 3.119)\tData  0.001 ( 2.720)\tLoss 2.1859e+00 (2.6738e+00)\tAcc@1  73.05 ( 40.31)\tAcc@5  94.53 ( 76.88)\n",
            "Epoch: [124][ 30/268]\tTime  0.416 ( 2.303)\tData  0.001 ( 1.904)\tLoss 2.4357e+00 (2.5881e+00)\tAcc@1  49.22 ( 43.18)\tAcc@5  89.45 ( 80.14)\n",
            "Epoch: [124][ 40/268]\tTime  0.424 ( 1.894)\tData  0.000 ( 1.495)\tLoss 2.3820e+00 (2.5516e+00)\tAcc@1  48.05 ( 45.50)\tAcc@5  90.23 ( 81.71)\n",
            "Epoch: [124][ 50/268]\tTime  0.415 ( 1.650)\tData  0.000 ( 1.250)\tLoss 2.0836e+00 (2.5337e+00)\tAcc@1  66.41 ( 45.73)\tAcc@5  95.70 ( 82.43)\n",
            "Epoch: [124][ 60/268]\tTime  2.059 ( 1.475)\tData  1.725 ( 1.075)\tLoss 2.7895e+00 (2.5449e+00)\tAcc@1  24.22 ( 45.29)\tAcc@5  73.05 ( 82.25)\n",
            "Epoch: [124][ 70/268]\tTime  0.423 ( 1.327)\tData  0.013 ( 0.926)\tLoss 2.3276e+00 (2.5357e+00)\tAcc@1  49.61 ( 45.10)\tAcc@5  91.80 ( 82.59)\n",
            "Epoch: [124][ 80/268]\tTime  0.417 ( 1.240)\tData  0.000 ( 0.839)\tLoss 2.9434e+00 (2.5499e+00)\tAcc@1  26.56 ( 44.36)\tAcc@5  71.48 ( 82.35)\n",
            "Epoch: [124][ 90/268]\tTime  0.424 ( 1.171)\tData  0.000 ( 0.770)\tLoss 2.8169e+00 (2.5452e+00)\tAcc@1  39.06 ( 44.43)\tAcc@5  74.22 ( 82.33)\n",
            "Epoch: [124][100/268]\tTime  0.416 ( 1.115)\tData  0.000 ( 0.715)\tLoss 2.1999e+00 (2.5392e+00)\tAcc@1  54.69 ( 44.69)\tAcc@5  93.36 ( 82.37)\n",
            "Epoch: [124][110/268]\tTime  0.420 ( 1.065)\tData  0.058 ( 0.666)\tLoss 3.0032e+00 (2.5480e+00)\tAcc@1  24.61 ( 44.10)\tAcc@5  70.31 ( 81.89)\n",
            "Epoch: [124][120/268]\tTime  2.075 ( 1.028)\tData  1.740 ( 0.629)\tLoss 2.1496e+00 (2.5427e+00)\tAcc@1  57.81 ( 44.35)\tAcc@5  94.53 ( 82.11)\n",
            "Epoch: [124][130/268]\tTime  0.416 ( 0.984)\tData  0.000 ( 0.586)\tLoss 2.9473e+00 (2.5543e+00)\tAcc@1  24.22 ( 43.86)\tAcc@5  67.19 ( 81.82)\n",
            "Epoch: [124][140/268]\tTime  0.431 ( 0.960)\tData  0.000 ( 0.562)\tLoss 2.8673e+00 (2.5536e+00)\tAcc@1  24.61 ( 43.58)\tAcc@5  67.58 ( 81.72)\n",
            "Epoch: [124][150/268]\tTime  0.420 ( 0.939)\tData  0.000 ( 0.543)\tLoss 2.3258e+00 (2.5422e+00)\tAcc@1  43.36 ( 44.33)\tAcc@5  92.19 ( 82.12)\n",
            "Epoch: [124][160/268]\tTime  1.068 ( 0.923)\tData  0.750 ( 0.528)\tLoss 2.9585e+00 (2.5559e+00)\tAcc@1  19.14 ( 43.81)\tAcc@5  68.36 ( 81.65)\n",
            "Epoch: [124][170/268]\tTime  1.733 ( 0.901)\tData  1.415 ( 0.506)\tLoss 2.1665e+00 (2.5423e+00)\tAcc@1  62.11 ( 44.52)\tAcc@5  94.14 ( 82.05)\n",
            "Epoch: [124][180/268]\tTime  0.417 ( 0.878)\tData  0.000 ( 0.482)\tLoss 2.2557e+00 (2.5251e+00)\tAcc@1  58.20 ( 45.42)\tAcc@5  92.97 ( 82.58)\n",
            "Epoch: [124][190/268]\tTime  0.416 ( 0.861)\tData  0.000 ( 0.466)\tLoss 2.7587e+00 (2.5224e+00)\tAcc@1  26.17 ( 45.53)\tAcc@5  86.33 ( 82.77)\n",
            "Epoch: [124][200/268]\tTime  0.424 ( 0.850)\tData  0.000 ( 0.455)\tLoss 2.3663e+00 (2.5162e+00)\tAcc@1  40.62 ( 45.64)\tAcc@5  93.75 ( 83.00)\n",
            "Epoch: [124][210/268]\tTime  0.427 ( 0.839)\tData  0.000 ( 0.444)\tLoss 2.3940e+00 (2.5133e+00)\tAcc@1  64.84 ( 45.67)\tAcc@5  92.19 ( 83.12)\n",
            "Epoch: [124][220/268]\tTime  1.176 ( 0.830)\tData  0.858 ( 0.436)\tLoss 2.2097e+00 (2.5056e+00)\tAcc@1  55.08 ( 45.97)\tAcc@5  94.92 ( 83.41)\n",
            "Epoch: [124][230/268]\tTime  1.420 ( 0.817)\tData  1.087 ( 0.422)\tLoss 2.5405e+00 (2.4973e+00)\tAcc@1  69.53 ( 46.53)\tAcc@5  90.23 ( 83.74)\n",
            "Epoch: [124][240/268]\tTime  0.822 ( 0.805)\tData  0.483 ( 0.411)\tLoss 2.2978e+00 (2.4983e+00)\tAcc@1  50.78 ( 46.45)\tAcc@5  91.80 ( 83.77)\n",
            "Epoch: [124][250/268]\tTime  0.416 ( 0.796)\tData  0.000 ( 0.402)\tLoss 2.7993e+00 (2.4992e+00)\tAcc@1  26.56 ( 46.36)\tAcc@5  71.48 ( 83.75)\n",
            "Epoch: [124][260/268]\tTime  0.416 ( 0.787)\tData  0.000 ( 0.394)\tLoss 2.8655e+00 (2.5016e+00)\tAcc@1  26.95 ( 46.31)\tAcc@5  72.66 ( 83.70)\n",
            "epoch: 124\n",
            "2023-03-25 02:34:55.768392: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:34:55.768500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:34:55.768518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:34:59.658080: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:34:59.658180: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:34:59.658200: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:03.566223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:03.566322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:03.566340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:07.466796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:07.466888: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:07.466908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:11.343643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:11.343751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:11.343769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:15.243791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:15.243881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:15.243899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:19.140468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:19.140579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:19.140597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:23.016826: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:23.016922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:23.016942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:26.892637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:26.892771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:26.892792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:30.786913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:30.787008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:30.787027: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:34.671563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:34.671674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:34.671695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:35:38.558620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:38.558727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:35:38.558746: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [125][  0/268]\tTime 54.642 (54.642)\tData 54.304 (54.304)\tLoss 2.7533e+00 (2.7533e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5  74.22 ( 74.22)\n",
            "Epoch: [125][ 10/268]\tTime  0.410 ( 5.350)\tData  0.000 ( 4.947)\tLoss 1.9577e+00 (2.3871e+00)\tAcc@1  74.22 ( 49.22)\tAcc@5  98.44 ( 87.61)\n",
            "Epoch: [125][ 20/268]\tTime  0.416 ( 3.139)\tData  0.000 ( 2.736)\tLoss 2.9121e+00 (2.5862e+00)\tAcc@1  25.78 ( 42.50)\tAcc@5  66.80 ( 81.85)\n",
            "Epoch: [125][ 30/268]\tTime  0.417 ( 2.318)\tData  0.000 ( 1.920)\tLoss 2.6387e+00 (2.5461e+00)\tAcc@1  35.55 ( 42.97)\tAcc@5  83.20 ( 82.62)\n",
            "Epoch: [125][ 40/268]\tTime  0.416 ( 1.899)\tData  0.000 ( 1.502)\tLoss 1.9998e+00 (2.5190e+00)\tAcc@1  67.19 ( 43.54)\tAcc@5  96.88 ( 83.13)\n",
            "Epoch: [125][ 50/268]\tTime  0.416 ( 1.649)\tData  0.000 ( 1.254)\tLoss 3.1713e+00 (2.5403e+00)\tAcc@1  18.36 ( 43.54)\tAcc@5  63.28 ( 82.64)\n",
            "Epoch: [125][ 60/268]\tTime  2.176 ( 1.476)\tData  1.838 ( 1.081)\tLoss 2.7644e+00 (2.5289e+00)\tAcc@1  26.56 ( 43.71)\tAcc@5  75.00 ( 83.16)\n",
            "Epoch: [125][ 70/268]\tTime  0.412 ( 1.330)\tData  0.001 ( 0.933)\tLoss 2.2656e+00 (2.5398e+00)\tAcc@1  50.39 ( 43.78)\tAcc@5  91.02 ( 82.60)\n",
            "Epoch: [125][ 80/268]\tTime  0.427 ( 1.243)\tData  0.000 ( 0.847)\tLoss 2.1795e+00 (2.5325e+00)\tAcc@1  72.66 ( 44.10)\tAcc@5  94.14 ( 82.88)\n",
            "Epoch: [125][ 90/268]\tTime  0.429 ( 1.176)\tData  0.000 ( 0.780)\tLoss 2.3634e+00 (2.5316e+00)\tAcc@1  54.69 ( 43.81)\tAcc@5  89.06 ( 83.05)\n",
            "Epoch: [125][100/268]\tTime  0.412 ( 1.120)\tData  0.010 ( 0.724)\tLoss 2.3298e+00 (2.5214e+00)\tAcc@1  66.02 ( 44.43)\tAcc@5  91.02 ( 83.37)\n",
            "Epoch: [125][110/268]\tTime  0.423 ( 1.070)\tData  0.000 ( 0.675)\tLoss 2.6659e+00 (2.5205e+00)\tAcc@1  28.91 ( 44.53)\tAcc@5  78.91 ( 83.45)\n",
            "Epoch: [125][120/268]\tTime  2.841 ( 1.036)\tData  2.506 ( 0.640)\tLoss 2.7338e+00 (2.5232e+00)\tAcc@1  33.98 ( 44.27)\tAcc@5  73.83 ( 83.30)\n",
            "Epoch: [125][130/268]\tTime  0.421 ( 0.989)\tData  0.001 ( 0.592)\tLoss 2.2985e+00 (2.5068e+00)\tAcc@1  51.17 ( 45.15)\tAcc@5  91.41 ( 83.79)\n",
            "Epoch: [125][140/268]\tTime  0.416 ( 0.966)\tData  0.000 ( 0.568)\tLoss 2.7375e+00 (2.5043e+00)\tAcc@1  39.45 ( 45.23)\tAcc@5  79.30 ( 83.85)\n",
            "Epoch: [125][150/268]\tTime  0.419 ( 0.941)\tData  0.000 ( 0.544)\tLoss 2.3913e+00 (2.5047e+00)\tAcc@1  48.05 ( 45.18)\tAcc@5  92.97 ( 83.96)\n",
            "Epoch: [125][160/268]\tTime  0.417 ( 0.921)\tData  0.000 ( 0.524)\tLoss 2.2918e+00 (2.5010e+00)\tAcc@1  51.56 ( 45.59)\tAcc@5  92.19 ( 84.15)\n",
            "Epoch: [125][170/268]\tTime  0.410 ( 0.905)\tData  0.000 ( 0.508)\tLoss 2.4292e+00 (2.4944e+00)\tAcc@1  47.66 ( 45.68)\tAcc@5  90.62 ( 84.36)\n",
            "Epoch: [125][180/268]\tTime  2.094 ( 0.887)\tData  1.757 ( 0.491)\tLoss 2.8305e+00 (2.4910e+00)\tAcc@1  28.91 ( 45.64)\tAcc@5  71.09 ( 84.47)\n",
            "Epoch: [125][190/268]\tTime  0.416 ( 0.863)\tData  0.000 ( 0.466)\tLoss 3.3156e+00 (2.4939e+00)\tAcc@1   5.47 ( 45.44)\tAcc@5  57.03 ( 84.36)\n",
            "Epoch: [125][200/268]\tTime  0.416 ( 0.853)\tData  0.000 ( 0.457)\tLoss 2.8234e+00 (2.5014e+00)\tAcc@1  28.91 ( 44.86)\tAcc@5  75.78 ( 84.12)\n",
            "Epoch: [125][210/268]\tTime  0.413 ( 0.841)\tData  0.000 ( 0.446)\tLoss 2.1051e+00 (2.4976e+00)\tAcc@1  77.34 ( 45.06)\tAcc@5  93.36 ( 84.10)\n",
            "Epoch: [125][220/268]\tTime  0.945 ( 0.832)\tData  0.625 ( 0.437)\tLoss 2.7010e+00 (2.4931e+00)\tAcc@1  28.91 ( 45.27)\tAcc@5  75.78 ( 84.25)\n",
            "Epoch: [125][230/268]\tTime  0.435 ( 0.821)\tData  0.000 ( 0.426)\tLoss 2.5198e+00 (2.4946e+00)\tAcc@1  44.14 ( 45.23)\tAcc@5  87.50 ( 84.19)\n",
            "Epoch: [125][240/268]\tTime  1.533 ( 0.813)\tData  1.215 ( 0.418)\tLoss 2.6794e+00 (2.4914e+00)\tAcc@1  24.22 ( 45.25)\tAcc@5  75.00 ( 84.25)\n",
            "Epoch: [125][250/268]\tTime  0.415 ( 0.800)\tData  0.000 ( 0.405)\tLoss 2.8199e+00 (2.4938e+00)\tAcc@1  28.12 ( 45.23)\tAcc@5  72.66 ( 84.08)\n",
            "Epoch: [125][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.395)\tLoss 2.0746e+00 (2.4989e+00)\tAcc@1  64.06 ( 44.95)\tAcc@5  95.31 ( 83.97)\n",
            "epoch: 125\n",
            "2023-03-25 02:38:26.401266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:26.401361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:26.401379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:30.355968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:30.356068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:30.356088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:34.304995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:34.305092: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:34.305109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:38.310431: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:38.310529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:38.310547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:42.227760: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:42.227866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:42.227885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:46.111844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:46.111940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:46.111958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:49.995373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:49.995471: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:49.995491: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:53.899013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:53.899114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:53.899132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:38:57.833807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:57.833896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:38:57.833914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:39:01.724843: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:01.724949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:01.724968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:39:05.681841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:05.681937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:05.681956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:39:09.559682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:09.559780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:39:09.559801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [126][  0/268]\tTime 54.634 (54.634)\tData 54.287 (54.287)\tLoss 2.4619e+00 (2.4619e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [126][ 10/268]\tTime  0.416 ( 5.387)\tData  0.000 ( 4.986)\tLoss 2.9180e+00 (2.5736e+00)\tAcc@1  20.70 ( 38.85)\tAcc@5  65.62 ( 81.82)\n",
            "Epoch: [126][ 20/268]\tTime  0.422 ( 3.124)\tData  0.000 ( 2.728)\tLoss 2.9277e+00 (2.5685e+00)\tAcc@1  28.12 ( 41.82)\tAcc@5  71.48 ( 82.55)\n",
            "Epoch: [126][ 30/268]\tTime  0.423 ( 2.313)\tData  0.000 ( 1.922)\tLoss 2.0995e+00 (2.5014e+00)\tAcc@1  60.94 ( 44.68)\tAcc@5  95.31 ( 84.45)\n",
            "Epoch: [126][ 40/268]\tTime  0.417 ( 1.901)\tData  0.000 ( 1.510)\tLoss 2.6229e+00 (2.4978e+00)\tAcc@1  38.28 ( 45.06)\tAcc@5  82.03 ( 84.67)\n",
            "Epoch: [126][ 50/268]\tTime  0.404 ( 1.655)\tData  0.000 ( 1.263)\tLoss 2.9402e+00 (2.5244e+00)\tAcc@1  17.97 ( 43.37)\tAcc@5  66.02 ( 83.39)\n",
            "Epoch: [126][ 60/268]\tTime  2.830 ( 1.492)\tData  2.506 ( 1.099)\tLoss 2.4717e+00 (2.5176e+00)\tAcc@1  42.58 ( 43.62)\tAcc@5  88.67 ( 83.61)\n",
            "Epoch: [126][ 70/268]\tTime  0.416 ( 1.341)\tData  0.001 ( 0.946)\tLoss 2.5768e+00 (2.4864e+00)\tAcc@1  41.02 ( 45.43)\tAcc@5  86.72 ( 84.15)\n",
            "Epoch: [126][ 80/268]\tTime  0.411 ( 1.249)\tData  0.000 ( 0.855)\tLoss 1.9710e+00 (2.4631e+00)\tAcc@1  70.31 ( 46.72)\tAcc@5  96.48 ( 84.78)\n",
            "Epoch: [126][ 90/268]\tTime  0.416 ( 1.184)\tData  0.001 ( 0.789)\tLoss 2.9697e+00 (2.4565e+00)\tAcc@1  34.77 ( 47.27)\tAcc@5  76.56 ( 85.00)\n",
            "Epoch: [126][100/268]\tTime  0.421 ( 1.125)\tData  0.000 ( 0.731)\tLoss 2.7747e+00 (2.4612e+00)\tAcc@1  25.39 ( 46.79)\tAcc@5  72.66 ( 84.99)\n",
            "Epoch: [126][110/268]\tTime  0.417 ( 1.078)\tData  0.013 ( 0.684)\tLoss 1.9032e+00 (2.4325e+00)\tAcc@1  63.28 ( 48.40)\tAcc@5  96.09 ( 85.71)\n",
            "Epoch: [126][120/268]\tTime  2.200 ( 1.038)\tData  1.856 ( 0.644)\tLoss 1.9577e+00 (2.4231e+00)\tAcc@1  72.27 ( 48.93)\tAcc@5  97.27 ( 85.86)\n",
            "Epoch: [126][130/268]\tTime  0.423 ( 0.991)\tData  0.000 ( 0.596)\tLoss 2.3140e+00 (2.4415e+00)\tAcc@1  57.03 ( 47.99)\tAcc@5  94.53 ( 85.37)\n",
            "Epoch: [126][140/268]\tTime  0.423 ( 0.965)\tData  0.013 ( 0.569)\tLoss 2.6850e+00 (2.4559e+00)\tAcc@1  26.95 ( 47.38)\tAcc@5  80.47 ( 84.80)\n",
            "Epoch: [126][150/268]\tTime  0.429 ( 0.943)\tData  0.000 ( 0.547)\tLoss 2.5750e+00 (2.4796e+00)\tAcc@1  36.72 ( 46.77)\tAcc@5  86.33 ( 84.15)\n",
            "Epoch: [126][160/268]\tTime  0.428 ( 0.921)\tData  0.000 ( 0.526)\tLoss 2.8566e+00 (2.4903e+00)\tAcc@1  31.25 ( 46.46)\tAcc@5  71.48 ( 83.71)\n",
            "Epoch: [126][170/268]\tTime  0.418 ( 0.903)\tData  0.000 ( 0.507)\tLoss 2.5051e+00 (2.4875e+00)\tAcc@1  41.41 ( 46.53)\tAcc@5  87.89 ( 83.90)\n",
            "Epoch: [126][180/268]\tTime  2.161 ( 0.886)\tData  1.820 ( 0.490)\tLoss 2.0122e+00 (2.4818e+00)\tAcc@1  68.36 ( 46.69)\tAcc@5  96.48 ( 83.98)\n",
            "Epoch: [126][190/268]\tTime  0.416 ( 0.863)\tData  0.000 ( 0.467)\tLoss 2.7643e+00 (2.4729e+00)\tAcc@1  25.78 ( 47.04)\tAcc@5  72.66 ( 84.18)\n",
            "Epoch: [126][200/268]\tTime  0.421 ( 0.851)\tData  0.001 ( 0.455)\tLoss 4.1431e+00 (2.4887e+00)\tAcc@1   0.78 ( 46.39)\tAcc@5  19.92 ( 83.63)\n",
            "Epoch: [126][210/268]\tTime  0.414 ( 0.838)\tData  0.000 ( 0.442)\tLoss 2.0199e+00 (2.4905e+00)\tAcc@1  71.09 ( 46.33)\tAcc@5  95.70 ( 83.53)\n",
            "Epoch: [126][220/268]\tTime  0.410 ( 0.828)\tData  0.000 ( 0.432)\tLoss 2.9647e+00 (2.4860e+00)\tAcc@1  23.83 ( 46.40)\tAcc@5  63.28 ( 83.63)\n",
            "Epoch: [126][230/268]\tTime  0.413 ( 0.817)\tData  0.000 ( 0.421)\tLoss 2.0493e+00 (2.4938e+00)\tAcc@1  61.33 ( 45.98)\tAcc@5  95.31 ( 83.39)\n",
            "Epoch: [126][240/268]\tTime  2.320 ( 0.810)\tData  1.986 ( 0.414)\tLoss 2.5852e+00 (2.4917e+00)\tAcc@1  37.50 ( 45.97)\tAcc@5  83.98 ( 83.43)\n",
            "Epoch: [126][250/268]\tTime  0.415 ( 0.798)\tData  0.000 ( 0.402)\tLoss 2.1123e+00 (2.4922e+00)\tAcc@1  68.36 ( 45.80)\tAcc@5  96.88 ( 83.36)\n",
            "Epoch: [126][260/268]\tTime  0.415 ( 0.787)\tData  0.000 ( 0.391)\tLoss 2.1155e+00 (2.4899e+00)\tAcc@1  59.38 ( 45.74)\tAcc@5  95.70 ( 83.43)\n",
            "epoch: 126\n",
            "2023-03-25 02:41:56.396145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:41:56.396245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:41:56.396265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:00.326262: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:00.326361: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:00.326379: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:04.280922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:04.281022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:04.281041: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:08.181321: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:08.181414: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:08.181432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:12.084249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:12.084352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:12.084371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:16.041774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:16.041880: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:16.041901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:19.935707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:19.935803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:19.935821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:23.840894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:23.840999: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:23.841019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:27.734591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:27.734706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:27.734726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:31.620731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:31.620829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:31.620848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:35.511824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:35.511922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:35.511941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:42:39.391061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:39.391154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:42:39.391174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [127][  0/268]\tTime 54.948 (54.948)\tData 54.608 (54.608)\tLoss 2.1860e+00 (2.1860e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5  94.92 ( 94.92)\n",
            "Epoch: [127][ 10/268]\tTime  0.417 ( 5.380)\tData  0.000 ( 4.974)\tLoss 3.6798e+00 (2.4730e+00)\tAcc@1   8.98 ( 46.84)\tAcc@5  64.84 ( 86.47)\n",
            "Epoch: [127][ 20/268]\tTime  0.412 ( 3.124)\tData  0.000 ( 2.726)\tLoss 1.9240e+00 (2.4222e+00)\tAcc@1  76.56 ( 49.53)\tAcc@5  96.48 ( 86.25)\n",
            "Epoch: [127][ 30/268]\tTime  0.417 ( 2.305)\tData  0.000 ( 1.910)\tLoss 2.7243e+00 (2.4014e+00)\tAcc@1  24.22 ( 48.85)\tAcc@5  75.00 ( 86.29)\n",
            "Epoch: [127][ 40/268]\tTime  0.422 ( 1.899)\tData  0.000 ( 1.505)\tLoss 2.8868e+00 (2.4338e+00)\tAcc@1  25.00 ( 47.22)\tAcc@5  72.27 ( 85.46)\n",
            "Epoch: [127][ 50/268]\tTime  0.407 ( 1.649)\tData  0.000 ( 1.256)\tLoss 2.1260e+00 (2.4243e+00)\tAcc@1  55.47 ( 47.42)\tAcc@5  96.09 ( 85.90)\n",
            "Epoch: [127][ 60/268]\tTime  0.421 ( 1.447)\tData  0.000 ( 1.052)\tLoss 2.7492e+00 (2.4812e+00)\tAcc@1  31.64 ( 45.27)\tAcc@5  74.22 ( 83.98)\n",
            "Epoch: [127][ 70/268]\tTime  0.411 ( 1.333)\tData  0.000 ( 0.935)\tLoss 2.6901e+00 (2.4608e+00)\tAcc@1  28.52 ( 46.43)\tAcc@5  77.34 ( 84.64)\n",
            "Epoch: [127][ 80/268]\tTime  0.423 ( 1.250)\tData  0.000 ( 0.852)\tLoss 2.5893e+00 (2.4724e+00)\tAcc@1  58.98 ( 46.01)\tAcc@5  83.59 ( 84.23)\n",
            "Epoch: [127][ 90/268]\tTime  0.414 ( 1.173)\tData  0.000 ( 0.776)\tLoss 1.9058e+00 (2.4626e+00)\tAcc@1  71.09 ( 46.40)\tAcc@5  96.09 ( 84.39)\n",
            "Epoch: [127][100/268]\tTime  0.416 ( 1.121)\tData  0.009 ( 0.725)\tLoss 2.3412e+00 (2.4630e+00)\tAcc@1  46.09 ( 46.50)\tAcc@5  89.06 ( 84.33)\n",
            "Epoch: [127][110/268]\tTime  0.416 ( 1.075)\tData  0.000 ( 0.680)\tLoss 1.9789e+00 (2.4639e+00)\tAcc@1  67.97 ( 46.33)\tAcc@5  94.53 ( 84.24)\n",
            "Epoch: [127][120/268]\tTime  0.916 ( 1.025)\tData  0.580 ( 0.630)\tLoss 2.1343e+00 (2.4524e+00)\tAcc@1  69.14 ( 46.89)\tAcc@5  97.27 ( 84.56)\n",
            "Epoch: [127][130/268]\tTime  0.428 ( 0.991)\tData  0.000 ( 0.595)\tLoss 2.4061e+00 (2.4515e+00)\tAcc@1  44.53 ( 46.99)\tAcc@5  90.62 ( 84.59)\n",
            "Epoch: [127][140/268]\tTime  0.413 ( 0.964)\tData  0.000 ( 0.568)\tLoss 2.0880e+00 (2.4462e+00)\tAcc@1  65.62 ( 47.33)\tAcc@5  94.53 ( 84.67)\n",
            "Epoch: [127][150/268]\tTime  0.419 ( 0.943)\tData  0.013 ( 0.547)\tLoss 2.8814e+00 (2.4515e+00)\tAcc@1  29.30 ( 47.10)\tAcc@5  74.22 ( 84.50)\n",
            "Epoch: [127][160/268]\tTime  0.412 ( 0.921)\tData  0.000 ( 0.524)\tLoss 2.8103e+00 (2.4527e+00)\tAcc@1  25.39 ( 47.01)\tAcc@5  71.09 ( 84.44)\n",
            "Epoch: [127][170/268]\tTime  0.425 ( 0.905)\tData  0.000 ( 0.508)\tLoss 2.1941e+00 (2.4612e+00)\tAcc@1  59.77 ( 46.79)\tAcc@5  94.53 ( 84.06)\n",
            "Epoch: [127][180/268]\tTime  0.413 ( 0.878)\tData  0.000 ( 0.481)\tLoss 1.9632e+00 (2.4612e+00)\tAcc@1  69.53 ( 46.80)\tAcc@5  96.88 ( 83.98)\n",
            "Epoch: [127][190/268]\tTime  0.422 ( 0.866)\tData  0.001 ( 0.468)\tLoss 2.7832e+00 (2.4643e+00)\tAcc@1  23.44 ( 46.66)\tAcc@5  67.97 ( 83.80)\n",
            "Epoch: [127][200/268]\tTime  0.417 ( 0.856)\tData  0.000 ( 0.458)\tLoss 2.8467e+00 (2.4603e+00)\tAcc@1  27.34 ( 46.82)\tAcc@5  73.83 ( 83.98)\n",
            "Epoch: [127][210/268]\tTime  0.414 ( 0.846)\tData  0.000 ( 0.448)\tLoss 2.1145e+00 (2.4588e+00)\tAcc@1  65.62 ( 46.72)\tAcc@5  94.53 ( 84.04)\n",
            "Epoch: [127][220/268]\tTime  0.426 ( 0.838)\tData  0.000 ( 0.440)\tLoss 1.8474e+00 (2.4688e+00)\tAcc@1  71.48 ( 46.32)\tAcc@5  98.44 ( 83.81)\n",
            "Epoch: [127][230/268]\tTime  0.416 ( 0.827)\tData  0.012 ( 0.429)\tLoss 2.2343e+00 (2.4635e+00)\tAcc@1  52.73 ( 46.35)\tAcc@5  90.23 ( 84.02)\n",
            "Epoch: [127][240/268]\tTime  0.423 ( 0.810)\tData  0.000 ( 0.412)\tLoss 1.8518e+00 (2.4539e+00)\tAcc@1  84.38 ( 46.81)\tAcc@5  95.70 ( 84.26)\n",
            "Epoch: [127][250/268]\tTime  0.416 ( 0.804)\tData  0.000 ( 0.405)\tLoss 2.2204e+00 (2.4571e+00)\tAcc@1  53.12 ( 46.48)\tAcc@5  91.80 ( 84.14)\n",
            "Epoch: [127][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.392)\tLoss 2.2859e+00 (2.4503e+00)\tAcc@1  53.91 ( 46.92)\tAcc@5  93.75 ( 84.41)\n",
            "epoch: 127\n",
            "2023-03-25 02:45:27.445642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:27.445779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:27.445802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:31.352626: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:31.352739: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:31.352759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:35.259115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:35.259221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:35.259241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:39.158068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:39.158164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:39.158181: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:43.031368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:43.031466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:43.031490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:46.901972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:46.902064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:46.902081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:50.795749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:50.795847: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:50.795865: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:54.703210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:54.703317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:54.703337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:45:58.586013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:58.586112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:45:58.586131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:46:02.464505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:02.464621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:02.464644: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:46:06.379410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:06.379540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:06.379564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:46:10.269733: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:10.269861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:46:10.269885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [128][  0/268]\tTime 54.387 (54.387)\tData 54.040 (54.040)\tLoss 2.2898e+00 (2.2898e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  90.23 ( 90.23)\n",
            "Epoch: [128][ 10/268]\tTime  0.416 ( 5.379)\tData  0.000 ( 4.985)\tLoss 1.9111e+00 (2.2515e+00)\tAcc@1  75.78 ( 54.94)\tAcc@5  96.88 ( 90.09)\n",
            "Epoch: [128][ 20/268]\tTime  0.411 ( 3.102)\tData  0.000 ( 2.710)\tLoss 2.8609e+00 (2.2962e+00)\tAcc@1  29.69 ( 54.50)\tAcc@5  69.14 ( 88.90)\n",
            "Epoch: [128][ 30/268]\tTime  0.418 ( 2.322)\tData  0.000 ( 1.931)\tLoss 1.8513e+00 (2.3127e+00)\tAcc@1  83.98 ( 52.71)\tAcc@5  96.88 ( 88.89)\n",
            "Epoch: [128][ 40/268]\tTime  0.415 ( 1.889)\tData  0.000 ( 1.498)\tLoss 2.8586e+00 (2.3651e+00)\tAcc@1  25.00 ( 49.66)\tAcc@5  70.31 ( 87.36)\n",
            "Epoch: [128][ 50/268]\tTime  0.492 ( 1.632)\tData  0.162 ( 1.243)\tLoss 2.8949e+00 (2.3758e+00)\tAcc@1  25.00 ( 48.96)\tAcc@5  70.70 ( 87.11)\n",
            "Epoch: [128][ 60/268]\tTime  1.932 ( 1.460)\tData  1.587 ( 1.069)\tLoss 2.8028e+00 (2.4301e+00)\tAcc@1  23.05 ( 45.84)\tAcc@5  72.66 ( 85.29)\n",
            "Epoch: [128][ 70/268]\tTime  0.437 ( 1.322)\tData  0.000 ( 0.930)\tLoss 2.1990e+00 (2.4393e+00)\tAcc@1  55.47 ( 45.00)\tAcc@5  94.14 ( 84.94)\n",
            "Epoch: [128][ 80/268]\tTime  0.425 ( 1.235)\tData  0.000 ( 0.844)\tLoss 1.8199e+00 (2.4701e+00)\tAcc@1  86.72 ( 43.54)\tAcc@5  97.66 ( 84.27)\n",
            "Epoch: [128][ 90/268]\tTime  0.416 ( 1.171)\tData  0.000 ( 0.780)\tLoss 2.0043e+00 (2.4731e+00)\tAcc@1  78.12 ( 43.96)\tAcc@5  95.31 ( 84.20)\n",
            "Epoch: [128][100/268]\tTime  0.417 ( 1.114)\tData  0.000 ( 0.724)\tLoss 2.2035e+00 (2.4537e+00)\tAcc@1  49.61 ( 44.93)\tAcc@5  94.92 ( 84.90)\n",
            "Epoch: [128][110/268]\tTime  1.741 ( 1.076)\tData  1.423 ( 0.685)\tLoss 2.6374e+00 (2.4686e+00)\tAcc@1  32.42 ( 44.42)\tAcc@5  78.52 ( 84.44)\n",
            "Epoch: [128][120/268]\tTime  0.736 ( 1.025)\tData  0.405 ( 0.633)\tLoss 2.7086e+00 (2.4747e+00)\tAcc@1  48.83 ( 44.54)\tAcc@5  82.03 ( 84.33)\n",
            "Epoch: [128][130/268]\tTime  0.447 ( 0.991)\tData  0.000 ( 0.599)\tLoss 2.1285e+00 (2.4896e+00)\tAcc@1  75.78 ( 43.98)\tAcc@5  93.75 ( 83.92)\n",
            "Epoch: [128][140/268]\tTime  0.417 ( 0.973)\tData  0.000 ( 0.581)\tLoss 2.8060e+00 (2.4850e+00)\tAcc@1  37.11 ( 44.31)\tAcc@5  73.83 ( 84.05)\n",
            "Epoch: [128][150/268]\tTime  0.418 ( 0.949)\tData  0.000 ( 0.556)\tLoss 1.9682e+00 (2.4759e+00)\tAcc@1  74.22 ( 44.86)\tAcc@5  95.31 ( 84.28)\n",
            "Epoch: [128][160/268]\tTime  0.414 ( 0.931)\tData  0.000 ( 0.537)\tLoss 2.2869e+00 (2.4640e+00)\tAcc@1  48.05 ( 45.31)\tAcc@5  91.41 ( 84.60)\n",
            "Epoch: [128][170/268]\tTime  2.358 ( 0.912)\tData  2.014 ( 0.518)\tLoss 2.4119e+00 (2.4606e+00)\tAcc@1  32.81 ( 45.41)\tAcc@5  91.02 ( 84.77)\n",
            "Epoch: [128][180/268]\tTime  0.435 ( 0.885)\tData  0.000 ( 0.490)\tLoss 2.3253e+00 (2.4518e+00)\tAcc@1  49.61 ( 45.80)\tAcc@5  91.80 ( 85.03)\n",
            "Epoch: [128][190/268]\tTime  0.419 ( 0.871)\tData  0.001 ( 0.475)\tLoss 2.2517e+00 (2.4500e+00)\tAcc@1  50.00 ( 45.87)\tAcc@5  93.36 ( 85.01)\n",
            "Epoch: [128][200/268]\tTime  0.416 ( 0.858)\tData  0.000 ( 0.462)\tLoss 1.7271e+00 (2.4556e+00)\tAcc@1  87.89 ( 45.58)\tAcc@5  97.66 ( 84.81)\n",
            "Epoch: [128][210/268]\tTime  0.408 ( 0.848)\tData  0.000 ( 0.452)\tLoss 2.1422e+00 (2.4479e+00)\tAcc@1  69.53 ( 45.99)\tAcc@5  94.92 ( 84.99)\n",
            "Epoch: [128][220/268]\tTime  0.415 ( 0.836)\tData  0.000 ( 0.440)\tLoss 2.8127e+00 (2.4446e+00)\tAcc@1  26.95 ( 46.24)\tAcc@5  77.73 ( 85.14)\n",
            "Epoch: [128][230/268]\tTime  2.538 ( 0.827)\tData  2.201 ( 0.431)\tLoss 2.1989e+00 (2.4433e+00)\tAcc@1  68.75 ( 46.20)\tAcc@5  95.31 ( 85.20)\n",
            "Epoch: [128][240/268]\tTime  0.433 ( 0.810)\tData  0.001 ( 0.413)\tLoss 2.7502e+00 (2.4330e+00)\tAcc@1  27.73 ( 46.74)\tAcc@5  71.48 ( 85.38)\n",
            "Epoch: [128][250/268]\tTime  0.416 ( 0.803)\tData  0.000 ( 0.406)\tLoss 2.3893e+00 (2.4298e+00)\tAcc@1  48.05 ( 46.75)\tAcc@5  92.58 ( 85.48)\n",
            "Epoch: [128][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.393)\tLoss 1.8745e+00 (2.4238e+00)\tAcc@1  75.39 ( 47.00)\tAcc@5  97.66 ( 85.66)\n",
            "epoch: 128\n",
            "2023-03-25 02:48:58.268940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:48:58.269035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:48:58.269054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:02.180864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:02.180965: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:02.180985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:06.083980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:06.084077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:06.084095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:09.971538: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:09.971697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:09.971716: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:13.882025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:13.882123: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:13.882141: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:17.818746: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:17.818840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:17.818857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:21.694267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:21.694368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:21.694387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:25.572272: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:25.572368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:25.572386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:29.461968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:29.462062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:29.462081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:33.383977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:33.384081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:33.384101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:37.265388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:37.265492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:37.265510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:49:41.170156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:41.170254: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:49:41.170273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [129][  0/268]\tTime 55.122 (55.122)\tData 54.786 (54.786)\tLoss 2.2971e+00 (2.2971e+00)\tAcc@1  56.64 ( 56.64)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [129][ 10/268]\tTime  0.423 ( 5.397)\tData  0.000 ( 4.992)\tLoss 2.0363e+00 (2.1893e+00)\tAcc@1  67.58 ( 59.09)\tAcc@5  98.05 ( 92.19)\n",
            "Epoch: [129][ 20/268]\tTime  0.409 ( 3.088)\tData  0.000 ( 2.685)\tLoss 2.8866e+00 (2.3170e+00)\tAcc@1  23.05 ( 52.10)\tAcc@5  69.92 ( 88.00)\n",
            "Epoch: [129][ 30/268]\tTime  0.410 ( 2.262)\tData  0.000 ( 1.860)\tLoss 2.2574e+00 (2.2985e+00)\tAcc@1  54.30 ( 52.90)\tAcc@5  91.02 ( 88.86)\n",
            "Epoch: [129][ 40/268]\tTime  0.424 ( 1.868)\tData  0.001 ( 1.469)\tLoss 2.6841e+00 (2.3311e+00)\tAcc@1  28.91 ( 51.04)\tAcc@5  77.34 ( 87.39)\n",
            "Epoch: [129][ 50/268]\tTime  0.824 ( 1.636)\tData  0.490 ( 1.240)\tLoss 2.2883e+00 (2.3445e+00)\tAcc@1  46.09 ( 49.65)\tAcc@5  92.19 ( 87.24)\n",
            "Epoch: [129][ 60/268]\tTime  1.544 ( 1.455)\tData  1.219 ( 1.059)\tLoss 2.0871e+00 (2.3656e+00)\tAcc@1  58.59 ( 48.34)\tAcc@5  96.88 ( 86.93)\n",
            "Epoch: [129][ 70/268]\tTime  0.411 ( 1.334)\tData  0.000 ( 0.936)\tLoss 2.0779e+00 (2.3799e+00)\tAcc@1  68.75 ( 47.71)\tAcc@5  94.92 ( 86.72)\n",
            "Epoch: [129][ 80/268]\tTime  0.412 ( 1.241)\tData  0.000 ( 0.845)\tLoss 1.9334e+00 (2.3661e+00)\tAcc@1  75.39 ( 48.82)\tAcc@5  96.09 ( 87.26)\n",
            "Epoch: [129][ 90/268]\tTime  0.417 ( 1.174)\tData  0.000 ( 0.780)\tLoss 1.8655e+00 (2.3592e+00)\tAcc@1  73.44 ( 49.18)\tAcc@5  98.05 ( 87.65)\n",
            "Epoch: [129][100/268]\tTime  0.420 ( 1.117)\tData  0.000 ( 0.724)\tLoss 2.5928e+00 (2.3490e+00)\tAcc@1  44.92 ( 50.10)\tAcc@5  80.08 ( 87.87)\n",
            "Epoch: [129][110/268]\tTime  0.418 ( 1.072)\tData  0.000 ( 0.679)\tLoss 2.3230e+00 (2.3472e+00)\tAcc@1  53.12 ( 50.62)\tAcc@5  91.41 ( 88.05)\n",
            "Epoch: [129][120/268]\tTime  1.091 ( 1.024)\tData  0.763 ( 0.631)\tLoss 2.0012e+00 (2.3530e+00)\tAcc@1  76.95 ( 50.58)\tAcc@5  96.88 ( 88.00)\n",
            "Epoch: [129][130/268]\tTime  0.417 ( 0.988)\tData  0.001 ( 0.594)\tLoss 2.0957e+00 (2.3528e+00)\tAcc@1  75.39 ( 50.50)\tAcc@5  96.48 ( 87.97)\n",
            "Epoch: [129][140/268]\tTime  0.425 ( 0.960)\tData  0.000 ( 0.566)\tLoss 2.6250e+00 (2.3613e+00)\tAcc@1  30.86 ( 50.18)\tAcc@5  73.83 ( 87.75)\n",
            "Epoch: [129][150/268]\tTime  0.418 ( 0.941)\tData  0.000 ( 0.548)\tLoss 2.4500e+00 (2.3585e+00)\tAcc@1  61.33 ( 50.36)\tAcc@5  85.94 ( 87.82)\n",
            "Epoch: [129][160/268]\tTime  0.419 ( 0.920)\tData  0.000 ( 0.528)\tLoss 2.0199e+00 (2.3598e+00)\tAcc@1  82.42 ( 50.21)\tAcc@5  96.48 ( 87.69)\n",
            "Epoch: [129][170/268]\tTime  1.714 ( 0.907)\tData  1.396 ( 0.516)\tLoss 2.4530e+00 (2.3665e+00)\tAcc@1  39.84 ( 49.90)\tAcc@5  87.11 ( 87.39)\n",
            "Epoch: [129][180/268]\tTime  0.417 ( 0.880)\tData  0.000 ( 0.488)\tLoss 2.5793e+00 (2.3746e+00)\tAcc@1  30.08 ( 49.38)\tAcc@5  79.69 ( 87.18)\n",
            "Epoch: [129][190/268]\tTime  0.429 ( 0.867)\tData  0.000 ( 0.475)\tLoss 2.6343e+00 (2.3792e+00)\tAcc@1  31.25 ( 49.04)\tAcc@5  78.12 ( 87.00)\n",
            "Epoch: [129][200/268]\tTime  0.417 ( 0.854)\tData  0.000 ( 0.462)\tLoss 2.2333e+00 (2.3796e+00)\tAcc@1  52.34 ( 48.80)\tAcc@5  93.36 ( 86.90)\n",
            "Epoch: [129][210/268]\tTime  0.434 ( 0.843)\tData  0.000 ( 0.450)\tLoss 2.6014e+00 (2.3797e+00)\tAcc@1  29.69 ( 48.78)\tAcc@5  77.73 ( 86.87)\n",
            "Epoch: [129][220/268]\tTime  0.422 ( 0.833)\tData  0.005 ( 0.441)\tLoss 1.9545e+00 (2.3793e+00)\tAcc@1  67.97 ( 48.81)\tAcc@5  96.88 ( 86.91)\n",
            "Epoch: [129][230/268]\tTime  1.755 ( 0.822)\tData  1.432 ( 0.430)\tLoss 2.6534e+00 (2.3738e+00)\tAcc@1  35.16 ( 49.13)\tAcc@5  78.12 ( 87.07)\n",
            "Epoch: [129][240/268]\tTime  0.814 ( 0.807)\tData  0.491 ( 0.415)\tLoss 2.7569e+00 (2.3772e+00)\tAcc@1  29.69 ( 48.90)\tAcc@5  78.12 ( 86.93)\n",
            "Epoch: [129][250/268]\tTime  0.425 ( 0.798)\tData  0.000 ( 0.405)\tLoss 2.1359e+00 (2.3790e+00)\tAcc@1  60.55 ( 48.78)\tAcc@5  91.80 ( 86.93)\n",
            "Epoch: [129][260/268]\tTime  0.415 ( 0.788)\tData  0.000 ( 0.396)\tLoss 3.9971e+00 (2.3864e+00)\tAcc@1   0.39 ( 48.52)\tAcc@5  27.34 ( 86.65)\n",
            "epoch: 129\n",
            "2023-03-25 02:52:28.570985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:28.571087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:28.571106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:32.501672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:32.501773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:32.501792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:36.421566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:36.421677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:36.421695: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:40.313667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:40.313764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:40.313782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:44.197804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:44.197898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:44.197916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:48.063207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:48.063307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:48.063325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:51.948436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:51.948542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:51.948561: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:55.873724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:55.873822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:55.873841: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:52:59.745973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:59.746079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:52:59.746097: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:53:03.634360: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:03.634458: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:03.634476: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:53:07.533401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:07.533500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:07.533519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:53:11.402051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:11.402149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:53:11.402168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [130][  0/268]\tTime 54.084 (54.084)\tData 53.750 (53.750)\tLoss 2.2230e+00 (2.2230e+00)\tAcc@1  44.92 ( 44.92)\tAcc@5  94.92 ( 94.92)\n",
            "Epoch: [130][ 10/268]\tTime  0.417 ( 5.359)\tData  0.000 ( 4.967)\tLoss 2.7116e+00 (2.4562e+00)\tAcc@1  30.47 ( 41.05)\tAcc@5  76.17 ( 85.48)\n",
            "Epoch: [130][ 20/268]\tTime  0.423 ( 3.094)\tData  0.000 ( 2.700)\tLoss 2.7702e+00 (2.4156e+00)\tAcc@1  28.91 ( 44.38)\tAcc@5  71.88 ( 85.90)\n",
            "Epoch: [130][ 30/268]\tTime  0.412 ( 2.294)\tData  0.000 ( 1.902)\tLoss 2.7659e+00 (2.4144e+00)\tAcc@1  30.47 ( 45.17)\tAcc@5  75.78 ( 86.05)\n",
            "Epoch: [130][ 40/268]\tTime  0.411 ( 1.887)\tData  0.000 ( 1.498)\tLoss 2.7598e+00 (2.4546e+00)\tAcc@1  26.17 ( 43.53)\tAcc@5  75.78 ( 84.70)\n",
            "Epoch: [130][ 50/268]\tTime  0.745 ( 1.633)\tData  0.416 ( 1.246)\tLoss 2.4940e+00 (2.4760e+00)\tAcc@1  67.19 ( 43.39)\tAcc@5  87.89 ( 83.98)\n",
            "Epoch: [130][ 60/268]\tTime  1.699 ( 1.454)\tData  1.381 ( 1.066)\tLoss 2.8819e+00 (2.4820e+00)\tAcc@1  26.95 ( 43.24)\tAcc@5  69.92 ( 83.73)\n",
            "Epoch: [130][ 70/268]\tTime  0.416 ( 1.319)\tData  0.000 ( 0.927)\tLoss 1.9176e+00 (2.4683e+00)\tAcc@1  75.78 ( 43.87)\tAcc@5  96.48 ( 84.02)\n",
            "Epoch: [130][ 80/268]\tTime  0.419 ( 1.228)\tData  0.013 ( 0.837)\tLoss 2.8647e+00 (2.4687e+00)\tAcc@1  23.05 ( 44.30)\tAcc@5  71.48 ( 84.04)\n",
            "Epoch: [130][ 90/268]\tTime  0.416 ( 1.160)\tData  0.000 ( 0.769)\tLoss 2.8663e+00 (2.4418e+00)\tAcc@1  26.17 ( 45.64)\tAcc@5  69.53 ( 84.59)\n",
            "Epoch: [130][100/268]\tTime  0.422 ( 1.105)\tData  0.000 ( 0.714)\tLoss 2.3607e+00 (2.4102e+00)\tAcc@1  47.66 ( 47.37)\tAcc@5  90.23 ( 85.53)\n",
            "Epoch: [130][110/268]\tTime  0.419 ( 1.062)\tData  0.000 ( 0.671)\tLoss 1.8860e+00 (2.3926e+00)\tAcc@1  78.91 ( 48.37)\tAcc@5  94.92 ( 85.89)\n",
            "Epoch: [130][120/268]\tTime  0.592 ( 1.011)\tData  0.272 ( 0.619)\tLoss 2.0998e+00 (2.3824e+00)\tAcc@1  59.38 ( 48.85)\tAcc@5  95.31 ( 86.05)\n",
            "Epoch: [130][130/268]\tTime  0.416 ( 0.976)\tData  0.000 ( 0.583)\tLoss 2.2685e+00 (2.3773e+00)\tAcc@1  51.95 ( 49.36)\tAcc@5  90.23 ( 86.27)\n",
            "Epoch: [130][140/268]\tTime  0.416 ( 0.949)\tData  0.000 ( 0.557)\tLoss 2.1763e+00 (2.3714e+00)\tAcc@1  53.91 ( 49.66)\tAcc@5  94.14 ( 86.40)\n",
            "Epoch: [130][150/268]\tTime  0.418 ( 0.928)\tData  0.000 ( 0.536)\tLoss 2.7857e+00 (2.3776e+00)\tAcc@1  26.56 ( 49.25)\tAcc@5  75.39 ( 86.34)\n",
            "Epoch: [130][160/268]\tTime  0.417 ( 0.911)\tData  0.000 ( 0.520)\tLoss 1.9793e+00 (2.3692e+00)\tAcc@1  67.19 ( 49.79)\tAcc@5  97.27 ( 86.58)\n",
            "Epoch: [130][170/268]\tTime  0.416 ( 0.894)\tData  0.001 ( 0.502)\tLoss 2.7543e+00 (2.3765e+00)\tAcc@1  29.30 ( 49.59)\tAcc@5  72.66 ( 86.33)\n",
            "Epoch: [130][180/268]\tTime  0.416 ( 0.868)\tData  0.000 ( 0.475)\tLoss 2.0511e+00 (2.3760e+00)\tAcc@1  60.55 ( 49.39)\tAcc@5  96.48 ( 86.40)\n",
            "Epoch: [130][190/268]\tTime  0.419 ( 0.856)\tData  0.001 ( 0.462)\tLoss 2.2487e+00 (2.3662e+00)\tAcc@1  71.48 ( 49.93)\tAcc@5  90.62 ( 86.62)\n",
            "Epoch: [130][200/268]\tTime  0.417 ( 0.845)\tData  0.008 ( 0.452)\tLoss 2.1505e+00 (2.3686e+00)\tAcc@1  57.03 ( 49.87)\tAcc@5  94.92 ( 86.70)\n",
            "Epoch: [130][210/268]\tTime  0.416 ( 0.833)\tData  0.000 ( 0.440)\tLoss 2.2842e+00 (2.3735e+00)\tAcc@1  55.86 ( 49.59)\tAcc@5  92.58 ( 86.54)\n",
            "Epoch: [130][220/268]\tTime  0.417 ( 0.823)\tData  0.000 ( 0.431)\tLoss 2.3356e+00 (2.3712e+00)\tAcc@1  53.91 ( 49.67)\tAcc@5  91.80 ( 86.62)\n",
            "Epoch: [130][230/268]\tTime  0.436 ( 0.814)\tData  0.001 ( 0.421)\tLoss 1.9457e+00 (2.3660e+00)\tAcc@1  72.27 ( 49.87)\tAcc@5  95.70 ( 86.82)\n",
            "Epoch: [130][240/268]\tTime  0.421 ( 0.806)\tData  0.000 ( 0.413)\tLoss 2.8261e+00 (2.3710e+00)\tAcc@1  28.52 ( 49.52)\tAcc@5  72.66 ( 86.73)\n",
            "Epoch: [130][250/268]\tTime  0.416 ( 0.799)\tData  0.000 ( 0.406)\tLoss 1.7977e+00 (2.3681e+00)\tAcc@1  83.20 ( 49.59)\tAcc@5  98.83 ( 86.78)\n",
            "Epoch: [130][260/268]\tTime  0.416 ( 0.785)\tData  0.000 ( 0.393)\tLoss 2.7671e+00 (2.3698e+00)\tAcc@1  29.69 ( 49.60)\tAcc@5  76.17 ( 86.78)\n",
            "epoch: 130\n",
            "2023-03-25 02:55:58.231205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:55:58.231324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:55:58.231345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:02.140687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:02.140809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:02.140832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:06.103057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:06.103184: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:06.103203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:09.995130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:09.995221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:09.995237: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:13.870901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:13.871003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:13.871022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:17.816706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:17.816807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:17.816826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:21.688155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:21.688253: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:21.688272: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:25.569886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:25.569989: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:25.570009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:29.520962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:29.521061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:29.521080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:33.399413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:33.399520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:33.399539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:37.276811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:37.276903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:37.276923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:56:41.200136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:41.200228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:56:41.200246: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [131][  0/268]\tTime 55.328 (55.328)\tData 55.000 (55.000)\tLoss 2.1651e+00 (2.1651e+00)\tAcc@1  55.86 ( 55.86)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [131][ 10/268]\tTime  0.416 ( 5.413)\tData  0.013 ( 5.011)\tLoss 2.6714e+00 (2.5360e+00)\tAcc@1  28.91 ( 39.56)\tAcc@5  75.78 ( 81.78)\n",
            "Epoch: [131][ 20/268]\tTime  0.423 ( 3.127)\tData  0.000 ( 2.730)\tLoss 2.7873e+00 (2.4552e+00)\tAcc@1  23.44 ( 44.49)\tAcc@5  71.48 ( 83.63)\n",
            "Epoch: [131][ 30/268]\tTime  0.430 ( 2.321)\tData  0.000 ( 1.923)\tLoss 2.3192e+00 (2.4210e+00)\tAcc@1  53.52 ( 47.06)\tAcc@5  91.02 ( 84.78)\n",
            "Epoch: [131][ 40/268]\tTime  0.416 ( 1.911)\tData  0.000 ( 1.512)\tLoss 2.1789e+00 (2.3963e+00)\tAcc@1  64.45 ( 48.32)\tAcc@5  94.92 ( 85.80)\n",
            "Epoch: [131][ 50/268]\tTime  0.417 ( 1.660)\tData  0.000 ( 1.261)\tLoss 2.2784e+00 (2.4048e+00)\tAcc@1  52.73 ( 46.90)\tAcc@5  91.80 ( 85.81)\n",
            "Epoch: [131][ 60/268]\tTime  2.266 ( 1.487)\tData  1.934 ( 1.087)\tLoss 2.6414e+00 (2.3986e+00)\tAcc@1  30.86 ( 46.83)\tAcc@5  79.69 ( 86.19)\n",
            "Epoch: [131][ 70/268]\tTime  0.414 ( 1.336)\tData  0.001 ( 0.936)\tLoss 4.3405e+00 (2.4175e+00)\tAcc@1   0.00 ( 46.54)\tAcc@5   6.25 ( 85.35)\n",
            "Epoch: [131][ 80/268]\tTime  0.423 ( 1.244)\tData  0.000 ( 0.844)\tLoss 1.9928e+00 (2.4233e+00)\tAcc@1  73.44 ( 46.64)\tAcc@5  96.88 ( 85.48)\n",
            "Epoch: [131][ 90/268]\tTime  0.417 ( 1.177)\tData  0.000 ( 0.777)\tLoss 1.8682e+00 (2.4110e+00)\tAcc@1  79.30 ( 47.91)\tAcc@5  98.05 ( 85.75)\n",
            "Epoch: [131][100/268]\tTime  0.416 ( 1.121)\tData  0.000 ( 0.721)\tLoss 1.9525e+00 (2.4205e+00)\tAcc@1  75.00 ( 47.28)\tAcc@5  97.66 ( 85.41)\n",
            "Epoch: [131][110/268]\tTime  0.422 ( 1.076)\tData  0.000 ( 0.676)\tLoss 2.6253e+00 (2.4125e+00)\tAcc@1  31.25 ( 47.35)\tAcc@5  77.73 ( 85.66)\n",
            "Epoch: [131][120/268]\tTime  2.238 ( 1.037)\tData  1.884 ( 0.637)\tLoss 1.9406e+00 (2.4104e+00)\tAcc@1  66.80 ( 47.31)\tAcc@5  96.48 ( 85.66)\n",
            "Epoch: [131][130/268]\tTime  0.412 ( 0.990)\tData  0.000 ( 0.589)\tLoss 2.3308e+00 (2.3967e+00)\tAcc@1  46.48 ( 48.11)\tAcc@5  92.19 ( 86.08)\n",
            "Epoch: [131][140/268]\tTime  0.422 ( 0.961)\tData  0.001 ( 0.560)\tLoss 2.1725e+00 (2.3994e+00)\tAcc@1  54.30 ( 48.21)\tAcc@5  96.48 ( 86.03)\n",
            "Epoch: [131][150/268]\tTime  0.408 ( 0.941)\tData  0.000 ( 0.539)\tLoss 2.6122e+00 (2.3873e+00)\tAcc@1  30.86 ( 48.85)\tAcc@5  76.56 ( 86.33)\n",
            "Epoch: [131][160/268]\tTime  0.410 ( 0.925)\tData  0.000 ( 0.524)\tLoss 2.4388e+00 (2.3722e+00)\tAcc@1  48.05 ( 49.88)\tAcc@5  84.38 ( 86.68)\n",
            "Epoch: [131][170/268]\tTime  0.423 ( 0.908)\tData  0.000 ( 0.507)\tLoss 2.0057e+00 (2.3729e+00)\tAcc@1  69.14 ( 49.61)\tAcc@5  96.48 ( 86.66)\n",
            "Epoch: [131][180/268]\tTime  2.350 ( 0.892)\tData  2.001 ( 0.490)\tLoss 2.7201e+00 (2.3722e+00)\tAcc@1  29.69 ( 49.62)\tAcc@5  75.39 ( 86.68)\n",
            "Epoch: [131][190/268]\tTime  0.427 ( 0.867)\tData  0.000 ( 0.465)\tLoss 2.7783e+00 (2.3743e+00)\tAcc@1  31.25 ( 49.30)\tAcc@5  86.33 ( 86.73)\n",
            "Epoch: [131][200/268]\tTime  0.416 ( 0.855)\tData  0.000 ( 0.453)\tLoss 2.3363e+00 (2.3703e+00)\tAcc@1  46.09 ( 49.56)\tAcc@5  87.89 ( 86.82)\n",
            "Epoch: [131][210/268]\tTime  0.417 ( 0.843)\tData  0.000 ( 0.441)\tLoss 2.1441e+00 (2.3711e+00)\tAcc@1  61.33 ( 49.55)\tAcc@5  92.97 ( 86.85)\n",
            "Epoch: [131][220/268]\tTime  0.421 ( 0.831)\tData  0.000 ( 0.430)\tLoss 1.8631e+00 (2.3707e+00)\tAcc@1  85.55 ( 49.63)\tAcc@5  96.88 ( 86.98)\n",
            "Epoch: [131][230/268]\tTime  0.417 ( 0.823)\tData  0.000 ( 0.421)\tLoss 2.2617e+00 (2.3689e+00)\tAcc@1  49.22 ( 49.59)\tAcc@5  92.97 ( 87.06)\n",
            "Epoch: [131][240/268]\tTime  2.042 ( 0.813)\tData  1.717 ( 0.412)\tLoss 2.3378e+00 (2.3722e+00)\tAcc@1  50.78 ( 49.27)\tAcc@5  89.84 ( 86.99)\n",
            "Epoch: [131][250/268]\tTime  0.411 ( 0.798)\tData  0.000 ( 0.396)\tLoss 1.8913e+00 (2.3699e+00)\tAcc@1  78.12 ( 49.33)\tAcc@5  97.27 ( 87.05)\n",
            "Epoch: [131][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.388)\tLoss 2.6928e+00 (2.3772e+00)\tAcc@1  25.78 ( 48.96)\tAcc@5  78.52 ( 86.78)\n",
            "epoch: 131\n",
            "2023-03-25 02:59:28.903081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:28.903179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:28.903197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:32.782506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:32.782601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:32.782619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:36.680684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:36.680786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:36.680806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:40.663625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:40.663728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:40.663745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:44.541699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:44.541796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:44.541816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:48.449294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:48.449395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:48.449413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:52.379008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:52.379108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:52.379126: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 02:59:56.278850: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:56.278949: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 02:59:56.278968: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:00:00.165071: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:00.165171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:00.165192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:00:04.074280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:04.074385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:04.074404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:00:07.949235: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:07.949328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:07.949346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:00:11.842095: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:11.842192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:00:11.842211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [132][  0/268]\tTime 54.269 (54.269)\tData 53.904 (53.904)\tLoss 2.2391e+00 (2.2391e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  94.14 ( 94.14)\n",
            "Epoch: [132][ 10/268]\tTime  0.409 ( 5.368)\tData  0.000 ( 4.963)\tLoss 2.3125e+00 (2.3563e+00)\tAcc@1  56.25 ( 47.62)\tAcc@5  89.84 ( 87.82)\n",
            "Epoch: [132][ 20/268]\tTime  0.415 ( 3.102)\tData  0.000 ( 2.708)\tLoss 2.3030e+00 (2.3515e+00)\tAcc@1  48.83 ( 49.50)\tAcc@5  92.97 ( 88.30)\n",
            "Epoch: [132][ 30/268]\tTime  0.417 ( 2.295)\tData  0.000 ( 1.905)\tLoss 2.1684e+00 (2.3472e+00)\tAcc@1  54.69 ( 49.19)\tAcc@5  94.14 ( 87.68)\n",
            "Epoch: [132][ 40/268]\tTime  0.416 ( 1.887)\tData  0.000 ( 1.499)\tLoss 2.6566e+00 (2.4225e+00)\tAcc@1  28.52 ( 46.72)\tAcc@5  76.95 ( 85.34)\n",
            "Epoch: [132][ 50/268]\tTime  0.434 ( 1.632)\tData  0.000 ( 1.241)\tLoss 1.9449e+00 (2.4248e+00)\tAcc@1  76.95 ( 47.94)\tAcc@5  96.48 ( 85.06)\n",
            "Epoch: [132][ 60/268]\tTime  2.848 ( 1.472)\tData  2.502 ( 1.080)\tLoss 1.8827e+00 (2.4223e+00)\tAcc@1  75.00 ( 48.25)\tAcc@5  96.88 ( 84.95)\n",
            "Epoch: [132][ 70/268]\tTime  0.416 ( 1.324)\tData  0.000 ( 0.930)\tLoss 1.7357e+00 (2.4048e+00)\tAcc@1  85.94 ( 49.33)\tAcc@5  98.44 ( 85.46)\n",
            "Epoch: [132][ 80/268]\tTime  0.426 ( 1.243)\tData  0.000 ( 0.849)\tLoss 2.6277e+00 (2.4030e+00)\tAcc@1  34.77 ( 48.78)\tAcc@5  78.91 ( 85.73)\n",
            "Epoch: [132][ 90/268]\tTime  0.423 ( 1.174)\tData  0.000 ( 0.780)\tLoss 2.4308e+00 (2.3873e+00)\tAcc@1  48.05 ( 49.51)\tAcc@5  91.02 ( 86.40)\n",
            "Epoch: [132][100/268]\tTime  0.416 ( 1.119)\tData  0.000 ( 0.725)\tLoss 2.2102e+00 (2.3801e+00)\tAcc@1  52.34 ( 49.27)\tAcc@5  92.58 ( 86.62)\n",
            "Epoch: [132][110/268]\tTime  1.332 ( 1.075)\tData  1.010 ( 0.682)\tLoss 2.2775e+00 (2.3785e+00)\tAcc@1  44.92 ( 49.11)\tAcc@5  92.19 ( 86.69)\n",
            "Epoch: [132][120/268]\tTime  1.349 ( 1.029)\tData  1.031 ( 0.635)\tLoss 2.3751e+00 (2.3865e+00)\tAcc@1  40.62 ( 48.46)\tAcc@5  89.84 ( 86.56)\n",
            "Epoch: [132][130/268]\tTime  0.434 ( 0.995)\tData  0.001 ( 0.601)\tLoss 1.9793e+00 (2.3792e+00)\tAcc@1  77.73 ( 49.17)\tAcc@5  95.70 ( 86.68)\n",
            "Epoch: [132][140/268]\tTime  0.421 ( 0.970)\tData  0.000 ( 0.577)\tLoss 2.2421e+00 (2.3798e+00)\tAcc@1  54.69 ( 49.03)\tAcc@5  93.75 ( 86.75)\n",
            "Epoch: [132][150/268]\tTime  0.416 ( 0.945)\tData  0.000 ( 0.553)\tLoss 2.6945e+00 (2.3826e+00)\tAcc@1  26.95 ( 48.79)\tAcc@5  76.17 ( 86.65)\n",
            "Epoch: [132][160/268]\tTime  0.427 ( 0.927)\tData  0.000 ( 0.534)\tLoss 2.2951e+00 (2.3764e+00)\tAcc@1  51.95 ( 49.10)\tAcc@5  92.19 ( 86.84)\n",
            "Epoch: [132][170/268]\tTime  1.590 ( 0.909)\tData  1.272 ( 0.516)\tLoss 2.2079e+00 (2.3753e+00)\tAcc@1  58.20 ( 49.17)\tAcc@5  94.53 ( 86.82)\n",
            "Epoch: [132][180/268]\tTime  0.418 ( 0.882)\tData  0.001 ( 0.488)\tLoss 2.6333e+00 (2.3715e+00)\tAcc@1  34.77 ( 49.32)\tAcc@5  78.91 ( 86.97)\n",
            "Epoch: [132][190/268]\tTime  0.418 ( 0.869)\tData  0.000 ( 0.475)\tLoss 2.6208e+00 (2.3715e+00)\tAcc@1  27.34 ( 49.25)\tAcc@5  82.03 ( 87.06)\n",
            "Epoch: [132][200/268]\tTime  0.425 ( 0.857)\tData  0.012 ( 0.463)\tLoss 3.1700e+00 (2.3778e+00)\tAcc@1  11.72 ( 48.93)\tAcc@5  80.47 ( 86.92)\n",
            "Epoch: [132][210/268]\tTime  0.411 ( 0.846)\tData  0.000 ( 0.453)\tLoss 1.8556e+00 (2.3665e+00)\tAcc@1  74.22 ( 49.43)\tAcc@5  98.44 ( 87.18)\n",
            "Epoch: [132][220/268]\tTime  0.416 ( 0.836)\tData  0.000 ( 0.442)\tLoss 2.6290e+00 (2.3709e+00)\tAcc@1  33.59 ( 49.17)\tAcc@5  79.30 ( 87.05)\n",
            "Epoch: [132][230/268]\tTime  1.901 ( 0.825)\tData  1.550 ( 0.432)\tLoss 1.8362e+00 (2.3634e+00)\tAcc@1  85.94 ( 49.59)\tAcc@5  96.88 ( 87.17)\n",
            "Epoch: [132][240/268]\tTime  0.416 ( 0.808)\tData  0.000 ( 0.415)\tLoss 2.9857e+00 (2.3682e+00)\tAcc@1  28.12 ( 49.34)\tAcc@5  73.83 ( 87.06)\n",
            "Epoch: [132][250/268]\tTime  0.417 ( 0.803)\tData  0.000 ( 0.409)\tLoss 2.1362e+00 (2.3642e+00)\tAcc@1  70.31 ( 49.67)\tAcc@5  94.14 ( 87.13)\n",
            "Epoch: [132][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.396)\tLoss 2.5592e+00 (2.3670e+00)\tAcc@1  33.20 ( 49.57)\tAcc@5  80.86 ( 86.98)\n",
            "epoch: 132\n",
            "2023-03-25 03:02:59.769445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:02:59.769551: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:02:59.769571: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:03.676203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:03.676300: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:03.676319: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:07.625324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:07.625422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:07.625442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:11.513829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:11.513929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:11.513947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:15.428437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:15.428566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:15.428587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:19.326062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:19.326156: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:19.326174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:23.207909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:23.208008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:23.208026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:27.096539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:27.096638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:27.096669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:31.012465: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:31.012573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:31.012592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:34.901004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:34.901100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:34.901119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:38.789020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:38.789115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:38.789133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:03:42.763829: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:42.763935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:03:42.763955: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [133][  0/268]\tTime 55.072 (55.072)\tData 54.715 (54.715)\tLoss 2.4268e+00 (2.4268e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [133][ 10/268]\tTime  0.417 ( 5.388)\tData  0.001 ( 4.986)\tLoss 2.7413e+00 (2.4675e+00)\tAcc@1  25.39 ( 40.70)\tAcc@5  76.56 ( 84.06)\n",
            "Epoch: [133][ 20/268]\tTime  0.411 ( 3.102)\tData  0.000 ( 2.705)\tLoss 2.5204e+00 (2.4399e+00)\tAcc@1  42.97 ( 43.45)\tAcc@5  87.89 ( 84.91)\n",
            "Epoch: [133][ 30/268]\tTime  0.421 ( 2.324)\tData  0.000 ( 1.925)\tLoss 1.7666e+00 (2.4093e+00)\tAcc@1  84.38 ( 45.99)\tAcc@5  96.09 ( 85.79)\n",
            "Epoch: [133][ 40/268]\tTime  0.417 ( 1.902)\tData  0.008 ( 1.503)\tLoss 2.0663e+00 (2.4714e+00)\tAcc@1  73.83 ( 44.56)\tAcc@5  94.14 ( 83.22)\n",
            "Epoch: [133][ 50/268]\tTime  0.417 ( 1.656)\tData  0.000 ( 1.257)\tLoss 1.8307e+00 (2.4201e+00)\tAcc@1  75.78 ( 47.49)\tAcc@5  97.66 ( 84.74)\n",
            "Epoch: [133][ 60/268]\tTime  2.192 ( 1.483)\tData  1.860 ( 1.083)\tLoss 2.6899e+00 (2.3893e+00)\tAcc@1  30.86 ( 49.28)\tAcc@5  77.34 ( 85.77)\n",
            "Epoch: [133][ 70/268]\tTime  0.419 ( 1.333)\tData  0.000 ( 0.932)\tLoss 2.3121e+00 (2.3835e+00)\tAcc@1  43.36 ( 48.71)\tAcc@5  90.62 ( 86.08)\n",
            "Epoch: [133][ 80/268]\tTime  0.416 ( 1.242)\tData  0.000 ( 0.841)\tLoss 2.3098e+00 (2.3578e+00)\tAcc@1  46.88 ( 50.17)\tAcc@5  90.62 ( 86.83)\n",
            "Epoch: [133][ 90/268]\tTime  0.416 ( 1.180)\tData  0.000 ( 0.780)\tLoss 2.1294e+00 (2.3606e+00)\tAcc@1  56.64 ( 49.86)\tAcc@5  92.97 ( 86.87)\n",
            "Epoch: [133][100/268]\tTime  0.410 ( 1.129)\tData  0.000 ( 0.728)\tLoss 3.0919e+00 (2.3559e+00)\tAcc@1  17.19 ( 50.11)\tAcc@5  60.94 ( 86.91)\n",
            "Epoch: [133][110/268]\tTime  0.434 ( 1.078)\tData  0.000 ( 0.678)\tLoss 1.8222e+00 (2.3499e+00)\tAcc@1  80.08 ( 50.53)\tAcc@5  97.27 ( 87.08)\n",
            "Epoch: [133][120/268]\tTime  2.709 ( 1.043)\tData  2.370 ( 0.642)\tLoss 2.2800e+00 (2.3469e+00)\tAcc@1  54.69 ( 50.60)\tAcc@5  92.58 ( 87.26)\n",
            "Epoch: [133][130/268]\tTime  0.423 ( 0.997)\tData  0.000 ( 0.596)\tLoss 2.0708e+00 (2.3457e+00)\tAcc@1  74.61 ( 50.71)\tAcc@5  95.31 ( 87.50)\n",
            "Epoch: [133][140/268]\tTime  0.425 ( 0.971)\tData  0.000 ( 0.571)\tLoss 2.4926e+00 (2.3508e+00)\tAcc@1  35.16 ( 50.52)\tAcc@5  82.03 ( 87.32)\n",
            "Epoch: [133][150/268]\tTime  0.423 ( 0.950)\tData  0.001 ( 0.550)\tLoss 2.9971e+00 (2.3549e+00)\tAcc@1  24.61 ( 50.54)\tAcc@5  68.75 ( 87.27)\n",
            "Epoch: [133][160/268]\tTime  0.425 ( 0.931)\tData  0.000 ( 0.532)\tLoss 2.2118e+00 (2.3566e+00)\tAcc@1  52.34 ( 50.25)\tAcc@5  93.36 ( 87.31)\n",
            "Epoch: [133][170/268]\tTime  0.416 ( 0.912)\tData  0.001 ( 0.513)\tLoss 2.4487e+00 (2.3501e+00)\tAcc@1  42.58 ( 50.51)\tAcc@5  89.84 ( 87.52)\n",
            "Epoch: [133][180/268]\tTime  1.252 ( 0.889)\tData  0.934 ( 0.491)\tLoss 2.3833e+00 (2.3433e+00)\tAcc@1  45.70 ( 50.92)\tAcc@5  89.45 ( 87.75)\n",
            "Epoch: [133][190/268]\tTime  0.422 ( 0.870)\tData  0.000 ( 0.471)\tLoss 2.6340e+00 (2.3425e+00)\tAcc@1  33.20 ( 50.81)\tAcc@5  79.30 ( 87.86)\n",
            "Epoch: [133][200/268]\tTime  0.421 ( 0.857)\tData  0.001 ( 0.458)\tLoss 2.6754e+00 (2.3459e+00)\tAcc@1  30.08 ( 50.74)\tAcc@5  77.73 ( 87.74)\n",
            "Epoch: [133][210/268]\tTime  0.425 ( 0.845)\tData  0.000 ( 0.446)\tLoss 2.0934e+00 (2.3446e+00)\tAcc@1  71.09 ( 50.89)\tAcc@5  94.92 ( 87.67)\n",
            "Epoch: [133][220/268]\tTime  0.424 ( 0.835)\tData  0.000 ( 0.437)\tLoss 1.7136e+00 (2.3438e+00)\tAcc@1  78.52 ( 50.98)\tAcc@5  98.05 ( 87.75)\n",
            "Epoch: [133][230/268]\tTime  0.421 ( 0.828)\tData  0.000 ( 0.430)\tLoss 2.6883e+00 (2.3462e+00)\tAcc@1  30.86 ( 50.77)\tAcc@5  82.42 ( 87.71)\n",
            "Epoch: [133][240/268]\tTime  0.417 ( 0.811)\tData  0.099 ( 0.413)\tLoss 1.8175e+00 (2.3391e+00)\tAcc@1  83.98 ( 51.05)\tAcc@5  95.70 ( 87.88)\n",
            "Epoch: [133][250/268]\tTime  0.416 ( 0.804)\tData  0.000 ( 0.406)\tLoss 2.3074e+00 (2.3337e+00)\tAcc@1  57.42 ( 51.27)\tAcc@5  92.97 ( 87.99)\n",
            "Epoch: [133][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.394)\tLoss 2.6270e+00 (2.3345e+00)\tAcc@1  37.89 ( 51.05)\tAcc@5  81.25 ( 87.97)\n",
            "epoch: 133\n",
            "2023-03-25 03:06:31.258776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:31.258871: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:31.258889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:35.178393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:35.178490: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:35.178510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:39.089290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:39.089391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:39.089409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:43.003577: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:43.003702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:43.003724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:46.898299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:46.898395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:46.898414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:50.782430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:50.782542: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:50.782562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:54.695556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:54.695667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:54.695687: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:06:58.558199: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:58.558293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:06:58.558313: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:07:02.472939: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:02.473037: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:02.473057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:07:06.388950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:06.389051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:06.389070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:07:10.268672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:10.268774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:10.268792: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:07:14.197402: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:14.197498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:07:14.197522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [134][  0/268]\tTime 54.950 (54.950)\tData 54.625 (54.625)\tLoss 2.6742e+00 (2.6742e+00)\tAcc@1  32.81 ( 32.81)\tAcc@5  75.39 ( 75.39)\n",
            "Epoch: [134][ 10/268]\tTime  0.416 ( 5.381)\tData  0.000 ( 4.977)\tLoss 2.2144e+00 (2.3478e+00)\tAcc@1  54.69 ( 46.66)\tAcc@5  92.58 ( 87.82)\n",
            "Epoch: [134][ 20/268]\tTime  0.428 ( 3.087)\tData  0.000 ( 2.689)\tLoss 2.6130e+00 (2.2983e+00)\tAcc@1  31.64 ( 51.95)\tAcc@5  78.52 ( 89.14)\n",
            "Epoch: [134][ 30/268]\tTime  0.427 ( 2.301)\tData  0.000 ( 1.906)\tLoss 1.8801e+00 (2.2810e+00)\tAcc@1  73.05 ( 52.32)\tAcc@5  96.88 ( 89.67)\n",
            "Epoch: [134][ 40/268]\tTime  0.424 ( 1.886)\tData  0.000 ( 1.493)\tLoss 1.9302e+00 (2.2597e+00)\tAcc@1  78.91 ( 54.57)\tAcc@5  97.66 ( 90.37)\n",
            "Epoch: [134][ 50/268]\tTime  0.432 ( 1.633)\tData  0.000 ( 1.239)\tLoss 2.2812e+00 (2.3115e+00)\tAcc@1  50.00 ( 51.99)\tAcc@5  91.80 ( 88.50)\n",
            "Epoch: [134][ 60/268]\tTime  1.327 ( 1.449)\tData  0.994 ( 1.054)\tLoss 2.2623e+00 (2.3460e+00)\tAcc@1  54.30 ( 52.00)\tAcc@5  90.62 ( 87.69)\n",
            "Epoch: [134][ 70/268]\tTime  0.416 ( 1.318)\tData  0.012 ( 0.922)\tLoss 2.4146e+00 (2.3224e+00)\tAcc@1  64.06 ( 53.30)\tAcc@5  88.28 ( 88.32)\n",
            "Epoch: [134][ 80/268]\tTime  0.417 ( 1.232)\tData  0.000 ( 0.836)\tLoss 1.9850e+00 (2.3285e+00)\tAcc@1  66.41 ( 52.33)\tAcc@5  96.48 ( 88.35)\n",
            "Epoch: [134][ 90/268]\tTime  0.417 ( 1.162)\tData  0.000 ( 0.767)\tLoss 2.5612e+00 (2.3335e+00)\tAcc@1  38.28 ( 51.98)\tAcc@5  82.03 ( 88.23)\n",
            "Epoch: [134][100/268]\tTime  0.435 ( 1.109)\tData  0.000 ( 0.714)\tLoss 1.8076e+00 (2.3379e+00)\tAcc@1  72.27 ( 51.77)\tAcc@5  98.83 ( 88.06)\n",
            "Epoch: [134][110/268]\tTime  0.431 ( 1.067)\tData  0.000 ( 0.672)\tLoss 2.2177e+00 (2.3184e+00)\tAcc@1  51.95 ( 52.82)\tAcc@5  94.92 ( 88.49)\n",
            "Epoch: [134][120/268]\tTime  1.517 ( 1.022)\tData  1.193 ( 0.627)\tLoss 2.3260e+00 (2.3161e+00)\tAcc@1  50.78 ( 53.12)\tAcc@5  92.19 ( 88.60)\n",
            "Epoch: [134][130/268]\tTime  0.417 ( 0.981)\tData  0.000 ( 0.584)\tLoss 2.2374e+00 (2.3174e+00)\tAcc@1  57.81 ( 52.82)\tAcc@5  92.97 ( 88.61)\n",
            "Epoch: [134][140/268]\tTime  0.411 ( 0.958)\tData  0.000 ( 0.561)\tLoss 2.4820e+00 (2.3150e+00)\tAcc@1  33.98 ( 52.61)\tAcc@5  83.59 ( 88.62)\n",
            "Epoch: [134][150/268]\tTime  0.422 ( 0.932)\tData  0.000 ( 0.535)\tLoss 2.5837e+00 (2.3252e+00)\tAcc@1  34.77 ( 52.04)\tAcc@5  83.59 ( 88.46)\n",
            "Epoch: [134][160/268]\tTime  0.418 ( 0.912)\tData  0.000 ( 0.515)\tLoss 2.5873e+00 (2.3221e+00)\tAcc@1  29.30 ( 51.94)\tAcc@5  79.30 ( 88.54)\n",
            "Epoch: [134][170/268]\tTime  0.437 ( 0.895)\tData  0.007 ( 0.498)\tLoss 1.9158e+00 (2.3195e+00)\tAcc@1  75.39 ( 52.15)\tAcc@5  97.66 ( 88.57)\n",
            "Epoch: [134][180/268]\tTime  1.135 ( 0.873)\tData  0.806 ( 0.476)\tLoss 2.0430e+00 (2.3273e+00)\tAcc@1  65.62 ( 51.61)\tAcc@5  97.27 ( 88.23)\n",
            "Epoch: [134][190/268]\tTime  0.421 ( 0.860)\tData  0.002 ( 0.462)\tLoss 2.4089e+00 (2.3273e+00)\tAcc@1  39.45 ( 51.55)\tAcc@5  88.67 ( 88.29)\n",
            "Epoch: [134][200/268]\tTime  0.420 ( 0.848)\tData  0.001 ( 0.450)\tLoss 2.2250e+00 (2.3212e+00)\tAcc@1  56.25 ( 52.12)\tAcc@5  92.58 ( 88.49)\n",
            "Epoch: [134][210/268]\tTime  0.417 ( 0.836)\tData  0.000 ( 0.439)\tLoss 2.5969e+00 (2.3211e+00)\tAcc@1  30.08 ( 52.19)\tAcc@5  78.12 ( 88.46)\n",
            "Epoch: [134][220/268]\tTime  0.411 ( 0.827)\tData  0.000 ( 0.430)\tLoss 2.4133e+00 (2.3264e+00)\tAcc@1  62.50 ( 51.79)\tAcc@5  89.45 ( 88.36)\n",
            "Epoch: [134][230/268]\tTime  0.416 ( 0.817)\tData  0.000 ( 0.420)\tLoss 2.0088e+00 (2.3252e+00)\tAcc@1  74.22 ( 51.96)\tAcc@5  96.48 ( 88.40)\n",
            "Epoch: [134][240/268]\tTime  2.946 ( 0.811)\tData  2.606 ( 0.414)\tLoss 1.7327e+00 (2.3188e+00)\tAcc@1  87.11 ( 52.22)\tAcc@5  97.66 ( 88.56)\n",
            "Epoch: [134][250/268]\tTime  0.417 ( 0.796)\tData  0.000 ( 0.398)\tLoss 2.5446e+00 (2.3224e+00)\tAcc@1  33.98 ( 52.05)\tAcc@5  83.20 ( 88.48)\n",
            "Epoch: [134][260/268]\tTime  0.415 ( 0.785)\tData  0.000 ( 0.388)\tLoss 2.0057e+00 (2.3217e+00)\tAcc@1  62.11 ( 52.01)\tAcc@5  96.09 ( 88.49)\n",
            "epoch: 134\n",
            "2023-03-25 03:10:00.924075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:00.924177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:00.924196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:04.816742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:04.816834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:04.816852: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:08.720422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:08.720536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:08.720555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:12.631154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:12.631245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:12.631263: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:16.525641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:16.525757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:16.525776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:20.431970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:20.432069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:20.432088: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:24.333242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:24.333339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:24.333359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:28.215644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:28.215755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:28.215775: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:32.151337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:32.151469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:32.151493: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:36.031761: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:36.031858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:36.031876: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:39.920067: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:39.920167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:39.920185: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:10:43.829511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:43.829607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:10:43.829626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [135][  0/268]\tTime 54.528 (54.528)\tData 54.191 (54.191)\tLoss 2.5576e+00 (2.5576e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [135][ 10/268]\tTime  0.416 ( 5.387)\tData  0.000 ( 4.985)\tLoss 2.6690e+00 (2.4077e+00)\tAcc@1  30.86 ( 44.60)\tAcc@5  75.39 ( 87.50)\n",
            "Epoch: [135][ 20/268]\tTime  0.416 ( 3.137)\tData  0.000 ( 2.736)\tLoss 2.3149e+00 (2.2775e+00)\tAcc@1  45.70 ( 52.55)\tAcc@5  90.62 ( 90.05)\n",
            "Epoch: [135][ 30/268]\tTime  0.418 ( 2.313)\tData  0.000 ( 1.913)\tLoss 2.5726e+00 (2.3173e+00)\tAcc@1  35.94 ( 49.68)\tAcc@5  80.47 ( 88.99)\n",
            "Epoch: [135][ 40/268]\tTime  0.407 ( 1.886)\tData  0.000 ( 1.487)\tLoss 2.6650e+00 (2.3193e+00)\tAcc@1  30.47 ( 50.49)\tAcc@5  77.73 ( 88.68)\n",
            "Epoch: [135][ 50/268]\tTime  0.477 ( 1.620)\tData  0.158 ( 1.223)\tLoss 2.1017e+00 (2.3333e+00)\tAcc@1  58.98 ( 49.79)\tAcc@5  94.53 ( 88.53)\n",
            "Epoch: [135][ 60/268]\tTime  2.219 ( 1.453)\tData  1.901 ( 1.056)\tLoss 2.7569e+00 (2.3637e+00)\tAcc@1  26.95 ( 47.95)\tAcc@5  75.00 ( 87.32)\n",
            "Epoch: [135][ 70/268]\tTime  0.417 ( 1.312)\tData  0.000 ( 0.913)\tLoss 2.6444e+00 (2.3851e+00)\tAcc@1  35.16 ( 47.28)\tAcc@5  79.69 ( 86.81)\n",
            "Epoch: [135][ 80/268]\tTime  0.417 ( 1.228)\tData  0.000 ( 0.830)\tLoss 1.9116e+00 (2.3586e+00)\tAcc@1  75.00 ( 48.66)\tAcc@5  96.48 ( 87.45)\n",
            "Epoch: [135][ 90/268]\tTime  0.425 ( 1.161)\tData  0.000 ( 0.763)\tLoss 2.6654e+00 (2.3559e+00)\tAcc@1  29.69 ( 48.98)\tAcc@5  77.73 ( 87.39)\n",
            "Epoch: [135][100/268]\tTime  0.428 ( 1.113)\tData  0.000 ( 0.714)\tLoss 2.0806e+00 (2.3457e+00)\tAcc@1  58.20 ( 49.23)\tAcc@5  94.92 ( 87.78)\n",
            "Epoch: [135][110/268]\tTime  0.430 ( 1.071)\tData  0.000 ( 0.673)\tLoss 1.9433e+00 (2.3239e+00)\tAcc@1  75.00 ( 50.45)\tAcc@5  95.70 ( 88.26)\n",
            "Epoch: [135][120/268]\tTime  2.368 ( 1.034)\tData  2.038 ( 0.635)\tLoss 2.4082e+00 (2.3178e+00)\tAcc@1  44.92 ( 50.85)\tAcc@5  87.89 ( 88.41)\n",
            "Epoch: [135][130/268]\tTime  0.415 ( 0.987)\tData  0.000 ( 0.587)\tLoss 2.8347e+00 (2.3198e+00)\tAcc@1  26.17 ( 50.74)\tAcc@5  73.05 ( 88.23)\n",
            "Epoch: [135][140/268]\tTime  0.425 ( 0.963)\tData  0.000 ( 0.564)\tLoss 2.6471e+00 (2.3232e+00)\tAcc@1  33.20 ( 50.47)\tAcc@5  79.69 ( 88.11)\n",
            "Epoch: [135][150/268]\tTime  0.416 ( 0.941)\tData  0.013 ( 0.542)\tLoss 1.9677e+00 (2.3360e+00)\tAcc@1  83.59 ( 50.07)\tAcc@5  94.14 ( 87.71)\n",
            "Epoch: [135][160/268]\tTime  0.413 ( 0.918)\tData  0.003 ( 0.519)\tLoss 2.7959e+00 (2.3432e+00)\tAcc@1  28.12 ( 49.63)\tAcc@5  76.17 ( 87.54)\n",
            "Epoch: [135][170/268]\tTime  0.423 ( 0.903)\tData  0.014 ( 0.505)\tLoss 1.9215e+00 (2.3383e+00)\tAcc@1  73.44 ( 49.92)\tAcc@5  97.27 ( 87.58)\n",
            "Epoch: [135][180/268]\tTime  1.909 ( 0.885)\tData  1.591 ( 0.487)\tLoss 2.8482e+00 (2.3458e+00)\tAcc@1  26.56 ( 49.69)\tAcc@5  73.44 ( 87.43)\n",
            "Epoch: [135][190/268]\tTime  0.426 ( 0.863)\tData  0.000 ( 0.464)\tLoss 1.9204e+00 (2.3326e+00)\tAcc@1  83.98 ( 50.35)\tAcc@5  94.53 ( 87.73)\n",
            "Epoch: [135][200/268]\tTime  0.411 ( 0.849)\tData  0.000 ( 0.451)\tLoss 2.0474e+00 (2.3336e+00)\tAcc@1  76.56 ( 50.44)\tAcc@5  96.09 ( 87.70)\n",
            "Epoch: [135][210/268]\tTime  0.422 ( 0.838)\tData  0.000 ( 0.440)\tLoss 2.7167e+00 (2.3409e+00)\tAcc@1  25.78 ( 50.02)\tAcc@5  77.34 ( 87.40)\n",
            "Epoch: [135][220/268]\tTime  0.430 ( 0.829)\tData  0.000 ( 0.431)\tLoss 2.6482e+00 (2.3459e+00)\tAcc@1  29.30 ( 49.61)\tAcc@5  82.42 ( 87.22)\n",
            "Epoch: [135][230/268]\tTime  0.408 ( 0.819)\tData  0.000 ( 0.422)\tLoss 1.7467e+00 (2.3365e+00)\tAcc@1  89.45 ( 50.08)\tAcc@5  98.83 ( 87.39)\n",
            "Epoch: [135][240/268]\tTime  2.395 ( 0.811)\tData  2.056 ( 0.413)\tLoss 2.4402e+00 (2.3357e+00)\tAcc@1  70.31 ( 50.19)\tAcc@5  87.50 ( 87.42)\n",
            "Epoch: [135][250/268]\tTime  0.417 ( 0.796)\tData  0.000 ( 0.397)\tLoss 2.3477e+00 (2.3365e+00)\tAcc@1  53.52 ( 50.15)\tAcc@5  93.36 ( 87.47)\n",
            "Epoch: [135][260/268]\tTime  0.416 ( 0.787)\tData  0.000 ( 0.389)\tLoss 2.0049e+00 (2.3349e+00)\tAcc@1  72.66 ( 50.31)\tAcc@5  97.66 ( 87.54)\n",
            "epoch: 135\n",
            "2023-03-25 03:13:31.126574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:31.126686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:31.126704: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:35.041749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:35.041853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:35.041872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:38.977495: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:38.977606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:38.977623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:42.885275: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:42.885375: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:42.885395: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:46.764744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:46.764844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:46.764862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:50.671068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:50.671162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:50.671179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:54.610718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:54.610813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:54.610830: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:13:58.524058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:58.524157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:13:58.524176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:14:02.402117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:02.402217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:02.402236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:14:06.339774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:06.339901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:06.339920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:14:10.219224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:10.219320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:10.219337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:14:14.122521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:14.122622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:14:14.122642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [136][  0/268]\tTime 55.120 (55.120)\tData 54.788 (54.788)\tLoss 2.7712e+00 (2.7712e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5  76.17 ( 76.17)\n",
            "Epoch: [136][ 10/268]\tTime  0.417 ( 5.392)\tData  0.000 ( 4.991)\tLoss 2.2297e+00 (2.3996e+00)\tAcc@1  46.09 ( 48.83)\tAcc@5  92.19 ( 85.94)\n",
            "Epoch: [136][ 20/268]\tTime  0.430 ( 3.144)\tData  0.000 ( 2.743)\tLoss 2.2957e+00 (2.3593e+00)\tAcc@1  48.83 ( 49.18)\tAcc@5  92.97 ( 87.09)\n",
            "Epoch: [136][ 30/268]\tTime  0.416 ( 2.343)\tData  0.000 ( 1.942)\tLoss 2.6405e+00 (2.3075e+00)\tAcc@1  44.92 ( 51.95)\tAcc@5  80.86 ( 88.68)\n",
            "Epoch: [136][ 40/268]\tTime  0.417 ( 1.914)\tData  0.000 ( 1.513)\tLoss 2.0524e+00 (2.2629e+00)\tAcc@1  78.91 ( 54.34)\tAcc@5  94.53 ( 89.92)\n",
            "Epoch: [136][ 50/268]\tTime  0.424 ( 1.658)\tData  0.001 ( 1.258)\tLoss 1.9527e+00 (2.2628e+00)\tAcc@1  67.97 ( 54.19)\tAcc@5  96.09 ( 89.61)\n",
            "Epoch: [136][ 60/268]\tTime  1.986 ( 1.481)\tData  1.641 ( 1.081)\tLoss 2.5914e+00 (2.2785e+00)\tAcc@1  36.72 ( 53.02)\tAcc@5  80.47 ( 89.40)\n",
            "Epoch: [136][ 70/268]\tTime  0.416 ( 1.335)\tData  0.006 ( 0.935)\tLoss 2.5753e+00 (2.2900e+00)\tAcc@1  26.17 ( 51.90)\tAcc@5  81.25 ( 89.01)\n",
            "Epoch: [136][ 80/268]\tTime  0.416 ( 1.254)\tData  0.012 ( 0.853)\tLoss 2.7411e+00 (2.2981e+00)\tAcc@1  30.47 ( 51.40)\tAcc@5  75.78 ( 88.65)\n",
            "Epoch: [136][ 90/268]\tTime  0.423 ( 1.180)\tData  0.001 ( 0.781)\tLoss 2.2299e+00 (2.2977e+00)\tAcc@1  45.70 ( 51.36)\tAcc@5  94.53 ( 88.73)\n",
            "Epoch: [136][100/268]\tTime  0.423 ( 1.121)\tData  0.000 ( 0.723)\tLoss 2.6837e+00 (2.3089e+00)\tAcc@1  32.42 ( 50.97)\tAcc@5  76.56 ( 88.44)\n",
            "Epoch: [136][110/268]\tTime  1.027 ( 1.078)\tData  0.708 ( 0.680)\tLoss 2.5975e+00 (2.2978e+00)\tAcc@1  33.20 ( 51.64)\tAcc@5  79.69 ( 88.77)\n",
            "Epoch: [136][120/268]\tTime  1.166 ( 1.029)\tData  0.842 ( 0.631)\tLoss 2.7287e+00 (2.3022e+00)\tAcc@1  39.84 ( 51.61)\tAcc@5  74.61 ( 88.58)\n",
            "Epoch: [136][130/268]\tTime  0.417 ( 0.991)\tData  0.000 ( 0.593)\tLoss 2.6254e+00 (2.2969e+00)\tAcc@1  32.03 ( 52.01)\tAcc@5  81.64 ( 88.71)\n",
            "Epoch: [136][140/268]\tTime  0.416 ( 0.967)\tData  0.011 ( 0.570)\tLoss 2.3016e+00 (2.2838e+00)\tAcc@1  43.75 ( 52.83)\tAcc@5  91.41 ( 89.08)\n",
            "Epoch: [136][150/268]\tTime  0.416 ( 0.943)\tData  0.000 ( 0.546)\tLoss 2.6137e+00 (2.2911e+00)\tAcc@1  29.30 ( 52.32)\tAcc@5  80.08 ( 88.91)\n",
            "Epoch: [136][160/268]\tTime  0.412 ( 0.921)\tData  0.000 ( 0.525)\tLoss 2.0260e+00 (2.2833e+00)\tAcc@1  67.97 ( 52.72)\tAcc@5  96.88 ( 89.07)\n",
            "Epoch: [136][170/268]\tTime  1.360 ( 0.906)\tData  1.043 ( 0.509)\tLoss 1.9403e+00 (2.2785e+00)\tAcc@1  74.61 ( 53.12)\tAcc@5  97.27 ( 89.25)\n",
            "Epoch: [136][180/268]\tTime  1.351 ( 0.884)\tData  0.997 ( 0.488)\tLoss 1.8289e+00 (2.2785e+00)\tAcc@1  89.06 ( 53.20)\tAcc@5  96.09 ( 89.22)\n",
            "Epoch: [136][190/268]\tTime  0.427 ( 0.867)\tData  0.000 ( 0.470)\tLoss 1.9479e+00 (2.2793e+00)\tAcc@1  76.95 ( 53.21)\tAcc@5  98.05 ( 89.27)\n",
            "Epoch: [136][200/268]\tTime  0.416 ( 0.851)\tData  0.000 ( 0.454)\tLoss 1.8077e+00 (2.2795e+00)\tAcc@1  84.77 ( 53.22)\tAcc@5  97.27 ( 89.36)\n",
            "Epoch: [136][210/268]\tTime  0.420 ( 0.842)\tData  0.000 ( 0.446)\tLoss 2.2813e+00 (2.2836e+00)\tAcc@1  46.88 ( 52.94)\tAcc@5  91.02 ( 89.26)\n",
            "Epoch: [136][220/268]\tTime  0.417 ( 0.831)\tData  0.010 ( 0.436)\tLoss 2.6844e+00 (2.2956e+00)\tAcc@1  30.47 ( 52.25)\tAcc@5  76.17 ( 88.94)\n",
            "Epoch: [136][230/268]\tTime  1.365 ( 0.822)\tData  1.036 ( 0.427)\tLoss 2.2581e+00 (2.3003e+00)\tAcc@1  44.53 ( 51.81)\tAcc@5  93.36 ( 88.80)\n",
            "Epoch: [136][240/268]\tTime  1.104 ( 0.809)\tData  0.785 ( 0.413)\tLoss 2.6330e+00 (2.2985e+00)\tAcc@1  29.69 ( 51.83)\tAcc@5  78.52 ( 88.84)\n",
            "Epoch: [136][250/268]\tTime  0.410 ( 0.800)\tData  0.000 ( 0.404)\tLoss 1.8525e+00 (2.3000e+00)\tAcc@1  73.83 ( 51.82)\tAcc@5  97.66 ( 88.87)\n",
            "Epoch: [136][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.393)\tLoss 1.9419e+00 (2.2956e+00)\tAcc@1  80.08 ( 52.10)\tAcc@5  96.88 ( 88.97)\n",
            "epoch: 136\n",
            "2023-03-25 03:17:01.754897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:01.754994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:01.755012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:05.724554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:05.724667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:05.724685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:09.633638: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:09.633740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:09.633760: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:13.544021: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:13.544113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:13.544133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:17.500740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:17.500833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:17.500851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:21.421447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:21.421554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:21.421575: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:25.303171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:25.303260: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:25.303277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:29.188607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:29.188711: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:29.188729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:33.081131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:33.081228: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:33.081247: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:36.982464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:36.982576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:36.982595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:40.900878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:40.900978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:40.900997: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:17:44.846479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:44.846594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:17:44.846612: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [137][  0/268]\tTime 55.280 (55.280)\tData 54.949 (54.949)\tLoss 2.5814e+00 (2.5814e+00)\tAcc@1  28.12 ( 28.12)\tAcc@5  81.64 ( 81.64)\n",
            "Epoch: [137][ 10/268]\tTime  0.410 ( 5.410)\tData  0.001 ( 5.008)\tLoss 2.6114e+00 (2.5392e+00)\tAcc@1  33.98 ( 44.21)\tAcc@5  80.86 ( 79.94)\n",
            "Epoch: [137][ 20/268]\tTime  0.416 ( 3.161)\tData  0.000 ( 2.759)\tLoss 2.1530e+00 (2.5305e+00)\tAcc@1  53.52 ( 43.32)\tAcc@5  95.70 ( 81.42)\n",
            "Epoch: [137][ 30/268]\tTime  0.416 ( 2.331)\tData  0.000 ( 1.931)\tLoss 2.7646e+00 (2.5327e+00)\tAcc@1  26.95 ( 41.42)\tAcc@5  74.61 ( 81.50)\n",
            "Epoch: [137][ 40/268]\tTime  0.422 ( 1.913)\tData  0.000 ( 1.512)\tLoss 2.2215e+00 (2.5489e+00)\tAcc@1  54.69 ( 41.53)\tAcc@5  93.75 ( 80.41)\n",
            "Epoch: [137][ 50/268]\tTime  0.416 ( 1.653)\tData  0.000 ( 1.253)\tLoss 1.9822e+00 (2.5084e+00)\tAcc@1  71.88 ( 43.01)\tAcc@5  96.88 ( 81.89)\n",
            "Epoch: [137][ 60/268]\tTime  2.825 ( 1.490)\tData  2.490 ( 1.090)\tLoss 2.7582e+00 (2.4675e+00)\tAcc@1  28.52 ( 45.07)\tAcc@5  74.61 ( 83.18)\n",
            "Epoch: [137][ 70/268]\tTime  0.416 ( 1.339)\tData  0.000 ( 0.938)\tLoss 2.6055e+00 (2.4497e+00)\tAcc@1  29.69 ( 45.67)\tAcc@5  82.42 ( 84.10)\n",
            "Epoch: [137][ 80/268]\tTime  0.425 ( 1.248)\tData  0.000 ( 0.846)\tLoss 2.0597e+00 (2.4277e+00)\tAcc@1  72.27 ( 46.56)\tAcc@5  96.09 ( 84.75)\n",
            "Epoch: [137][ 90/268]\tTime  0.422 ( 1.177)\tData  0.010 ( 0.775)\tLoss 2.3687e+00 (2.4126e+00)\tAcc@1  44.14 ( 47.72)\tAcc@5  87.50 ( 85.06)\n",
            "Epoch: [137][100/268]\tTime  0.417 ( 1.116)\tData  0.000 ( 0.715)\tLoss 2.6861e+00 (2.4068e+00)\tAcc@1  32.03 ( 48.33)\tAcc@5  78.91 ( 85.35)\n",
            "Epoch: [137][110/268]\tTime  0.410 ( 1.071)\tData  0.000 ( 0.669)\tLoss 2.0690e+00 (2.3973e+00)\tAcc@1  59.38 ( 48.54)\tAcc@5  94.92 ( 85.54)\n",
            "Epoch: [137][120/268]\tTime  2.727 ( 1.036)\tData  2.397 ( 0.634)\tLoss 2.0738e+00 (2.3771e+00)\tAcc@1  68.36 ( 49.23)\tAcc@5  94.53 ( 86.08)\n",
            "Epoch: [137][130/268]\tTime  0.413 ( 0.989)\tData  0.000 ( 0.588)\tLoss 2.6582e+00 (2.3767e+00)\tAcc@1  26.95 ( 49.30)\tAcc@5  81.25 ( 86.03)\n",
            "Epoch: [137][140/268]\tTime  0.421 ( 0.963)\tData  0.000 ( 0.563)\tLoss 1.9946e+00 (2.3871e+00)\tAcc@1  73.83 ( 48.60)\tAcc@5  94.14 ( 85.61)\n",
            "Epoch: [137][150/268]\tTime  0.413 ( 0.942)\tData  0.000 ( 0.541)\tLoss 2.3089e+00 (2.3819e+00)\tAcc@1  50.00 ( 48.90)\tAcc@5  90.23 ( 85.82)\n",
            "Epoch: [137][160/268]\tTime  0.419 ( 0.923)\tData  0.000 ( 0.522)\tLoss 2.0227e+00 (2.3690e+00)\tAcc@1  65.62 ( 49.63)\tAcc@5  96.09 ( 86.23)\n",
            "Epoch: [137][170/268]\tTime  0.626 ( 0.907)\tData  0.302 ( 0.507)\tLoss 2.6280e+00 (2.3637e+00)\tAcc@1  28.12 ( 49.90)\tAcc@5  78.91 ( 86.38)\n",
            "Epoch: [137][180/268]\tTime  1.928 ( 0.888)\tData  1.610 ( 0.488)\tLoss 2.1183e+00 (2.3505e+00)\tAcc@1  58.98 ( 50.36)\tAcc@5  93.36 ( 86.69)\n",
            "Epoch: [137][190/268]\tTime  0.443 ( 0.866)\tData  0.000 ( 0.466)\tLoss 1.6917e+00 (2.3459e+00)\tAcc@1  86.72 ( 50.53)\tAcc@5  97.66 ( 86.82)\n",
            "Epoch: [137][200/268]\tTime  0.418 ( 0.858)\tData  0.000 ( 0.458)\tLoss 2.6914e+00 (2.3473e+00)\tAcc@1  35.94 ( 50.29)\tAcc@5  80.08 ( 86.76)\n",
            "Epoch: [137][210/268]\tTime  0.419 ( 0.845)\tData  0.000 ( 0.445)\tLoss 2.6567e+00 (2.3525e+00)\tAcc@1  32.42 ( 49.98)\tAcc@5  78.52 ( 86.70)\n",
            "Epoch: [137][220/268]\tTime  0.410 ( 0.837)\tData  0.000 ( 0.437)\tLoss 1.6350e+00 (2.3475e+00)\tAcc@1  82.03 ( 50.12)\tAcc@5  97.66 ( 86.78)\n",
            "Epoch: [137][230/268]\tTime  0.526 ( 0.828)\tData  0.208 ( 0.428)\tLoss 2.2677e+00 (2.3506e+00)\tAcc@1  46.09 ( 49.91)\tAcc@5  90.62 ( 86.77)\n",
            "Epoch: [137][240/268]\tTime  2.797 ( 0.821)\tData  2.455 ( 0.421)\tLoss 2.0859e+00 (2.3528e+00)\tAcc@1  63.67 ( 49.91)\tAcc@5  95.31 ( 86.78)\n",
            "Epoch: [137][250/268]\tTime  0.416 ( 0.806)\tData  0.000 ( 0.407)\tLoss 1.9613e+00 (2.3459e+00)\tAcc@1  77.73 ( 50.24)\tAcc@5  95.31 ( 86.89)\n",
            "Epoch: [137][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.394)\tLoss 2.6166e+00 (2.3350e+00)\tAcc@1  37.11 ( 50.81)\tAcc@5  78.91 ( 87.13)\n",
            "epoch: 137\n",
            "2023-03-25 03:20:33.654057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:33.654150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:33.654168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:37.565208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:37.565312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:37.565331: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:41.486771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:41.486865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:41.486883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:45.464421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:45.464525: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:45.464545: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:49.368146: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:49.368241: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:49.368258: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:53.246929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:53.247028: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:53.247046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:20:57.174645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:57.174763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:20:57.174782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:21:01.065505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:01.065610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:01.065629: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:21:04.923815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:04.923907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:04.923925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:21:08.880763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:08.880861: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:08.880878: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:21:12.776750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:12.776851: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:12.776870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:21:16.660539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:16.660640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:21:16.660669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [138][  0/268]\tTime 56.223 (56.223)\tData 55.879 (55.879)\tLoss 1.9203e+00 (1.9203e+00)\tAcc@1  74.61 ( 74.61)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [138][ 10/268]\tTime  0.417 ( 5.491)\tData  0.000 ( 5.090)\tLoss 2.6588e+00 (2.3453e+00)\tAcc@1  30.47 ( 48.51)\tAcc@5  77.73 ( 86.47)\n",
            "Epoch: [138][ 20/268]\tTime  0.417 ( 3.150)\tData  0.000 ( 2.750)\tLoss 2.6076e+00 (2.3289e+00)\tAcc@1  33.20 ( 49.29)\tAcc@5  77.73 ( 87.03)\n",
            "Epoch: [138][ 30/268]\tTime  0.416 ( 2.308)\tData  0.000 ( 1.908)\tLoss 2.1550e+00 (2.3288e+00)\tAcc@1  64.06 ( 49.76)\tAcc@5  94.53 ( 87.61)\n",
            "Epoch: [138][ 40/268]\tTime  0.420 ( 1.883)\tData  0.000 ( 1.484)\tLoss 2.3196e+00 (2.3275e+00)\tAcc@1  43.36 ( 49.63)\tAcc@5  91.02 ( 87.76)\n",
            "Epoch: [138][ 50/268]\tTime  0.417 ( 1.637)\tData  0.000 ( 1.237)\tLoss 3.7749e+00 (2.3304e+00)\tAcc@1   0.00 ( 49.69)\tAcc@5  18.36 ( 86.96)\n",
            "Epoch: [138][ 60/268]\tTime  2.361 ( 1.469)\tData  2.018 ( 1.069)\tLoss 2.2585e+00 (2.3181e+00)\tAcc@1  55.08 ( 50.12)\tAcc@5  91.80 ( 87.44)\n",
            "Epoch: [138][ 70/268]\tTime  0.416 ( 1.323)\tData  0.000 ( 0.923)\tLoss 2.0359e+00 (2.3004e+00)\tAcc@1  74.61 ( 51.25)\tAcc@5  94.14 ( 88.09)\n",
            "Epoch: [138][ 80/268]\tTime  0.417 ( 1.238)\tData  0.000 ( 0.837)\tLoss 2.1668e+00 (2.3024e+00)\tAcc@1  50.78 ( 51.33)\tAcc@5  93.75 ( 88.23)\n",
            "Epoch: [138][ 90/268]\tTime  0.419 ( 1.168)\tData  0.000 ( 0.767)\tLoss 1.8849e+00 (2.3104e+00)\tAcc@1  82.81 ( 51.37)\tAcc@5  95.31 ( 88.04)\n",
            "Epoch: [138][100/268]\tTime  0.422 ( 1.113)\tData  0.000 ( 0.712)\tLoss 1.6663e+00 (2.3033e+00)\tAcc@1  84.38 ( 51.32)\tAcc@5  98.05 ( 88.21)\n",
            "Epoch: [138][110/268]\tTime  0.422 ( 1.073)\tData  0.000 ( 0.672)\tLoss 2.4476e+00 (2.2973e+00)\tAcc@1  44.92 ( 51.54)\tAcc@5  89.06 ( 88.36)\n",
            "Epoch: [138][120/268]\tTime  2.210 ( 1.034)\tData  1.881 ( 0.633)\tLoss 2.5924e+00 (2.3104e+00)\tAcc@1  30.08 ( 50.64)\tAcc@5  80.08 ( 87.96)\n",
            "Epoch: [138][130/268]\tTime  0.422 ( 0.988)\tData  0.000 ( 0.586)\tLoss 2.2069e+00 (2.2945e+00)\tAcc@1  57.42 ( 51.90)\tAcc@5  94.53 ( 88.41)\n",
            "Epoch: [138][140/268]\tTime  0.424 ( 0.962)\tData  0.013 ( 0.561)\tLoss 1.9987e+00 (2.2832e+00)\tAcc@1  61.72 ( 52.79)\tAcc@5  94.53 ( 88.66)\n",
            "Epoch: [138][150/268]\tTime  0.421 ( 0.942)\tData  0.000 ( 0.541)\tLoss 2.2946e+00 (2.2878e+00)\tAcc@1  54.69 ( 52.52)\tAcc@5  91.41 ( 88.58)\n",
            "Epoch: [138][160/268]\tTime  0.431 ( 0.925)\tData  0.000 ( 0.525)\tLoss 2.3445e+00 (2.2901e+00)\tAcc@1  51.95 ( 52.50)\tAcc@5  89.06 ( 88.57)\n",
            "Epoch: [138][170/268]\tTime  0.410 ( 0.903)\tData  0.000 ( 0.504)\tLoss 2.5749e+00 (2.2858e+00)\tAcc@1  43.75 ( 52.65)\tAcc@5  82.81 ( 88.75)\n",
            "Epoch: [138][180/268]\tTime  1.725 ( 0.884)\tData  1.400 ( 0.484)\tLoss 2.1693e+00 (2.2846e+00)\tAcc@1  71.48 ( 52.86)\tAcc@5  94.53 ( 88.76)\n",
            "Epoch: [138][190/268]\tTime  0.417 ( 0.864)\tData  0.001 ( 0.464)\tLoss 2.1498e+00 (2.2884e+00)\tAcc@1  55.86 ( 52.50)\tAcc@5  94.14 ( 88.72)\n",
            "Epoch: [138][200/268]\tTime  0.416 ( 0.852)\tData  0.000 ( 0.453)\tLoss 1.9872e+00 (2.2875e+00)\tAcc@1  79.30 ( 52.51)\tAcc@5  95.31 ( 88.69)\n",
            "Epoch: [138][210/268]\tTime  0.430 ( 0.842)\tData  0.013 ( 0.443)\tLoss 1.9834e+00 (2.2932e+00)\tAcc@1  68.36 ( 52.25)\tAcc@5  96.09 ( 88.66)\n",
            "Epoch: [138][220/268]\tTime  0.417 ( 0.833)\tData  0.000 ( 0.434)\tLoss 2.2785e+00 (2.2937e+00)\tAcc@1  47.66 ( 52.23)\tAcc@5  90.23 ( 88.68)\n",
            "Epoch: [138][230/268]\tTime  0.414 ( 0.820)\tData  0.086 ( 0.422)\tLoss 2.5772e+00 (2.2955e+00)\tAcc@1  28.12 ( 52.01)\tAcc@5  81.64 ( 88.69)\n",
            "Epoch: [138][240/268]\tTime  1.930 ( 0.810)\tData  1.602 ( 0.412)\tLoss 2.5875e+00 (2.2901e+00)\tAcc@1  33.98 ( 52.31)\tAcc@5  81.25 ( 88.85)\n",
            "Epoch: [138][250/268]\tTime  0.412 ( 0.796)\tData  0.000 ( 0.397)\tLoss 2.0210e+00 (2.2877e+00)\tAcc@1  62.11 ( 52.25)\tAcc@5  95.31 ( 88.91)\n",
            "Epoch: [138][260/268]\tTime  0.415 ( 0.788)\tData  0.000 ( 0.390)\tLoss 2.3204e+00 (2.2880e+00)\tAcc@1  47.66 ( 52.20)\tAcc@5  91.02 ( 88.93)\n",
            "epoch: 138\n",
            "2023-03-25 03:24:04.067211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:04.067313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:04.067332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:08.010181: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:08.010284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:08.010304: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:11.916371: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:11.916472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:11.916499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:15.810348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:15.810447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:15.810465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:19.722258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:19.722355: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:19.722374: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:23.647783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:23.647874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:23.647895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:27.555366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:27.555463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:27.555482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:31.481632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:31.481740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:31.481758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:35.424627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:35.424736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:35.424754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:39.330508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:39.330605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:39.330625: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:43.257772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:43.257873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:43.257892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:24:47.173165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:47.173264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:24:47.173283: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [139][  0/268]\tTime 55.392 (55.392)\tData 55.060 (55.060)\tLoss 2.3081e+00 (2.3081e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [139][ 10/268]\tTime  0.417 ( 5.446)\tData  0.000 ( 5.047)\tLoss 2.5993e+00 (2.2163e+00)\tAcc@1  33.98 ( 56.43)\tAcc@5  79.69 ( 90.55)\n",
            "Epoch: [139][ 20/268]\tTime  0.412 ( 3.142)\tData  0.000 ( 2.743)\tLoss 2.0272e+00 (2.0968e+00)\tAcc@1  73.83 ( 64.04)\tAcc@5  95.31 ( 93.23)\n",
            "Epoch: [139][ 30/268]\tTime  0.411 ( 2.303)\tData  0.013 ( 1.904)\tLoss 2.0402e+00 (2.1635e+00)\tAcc@1  69.53 ( 60.29)\tAcc@5  95.70 ( 92.12)\n",
            "Epoch: [139][ 40/268]\tTime  0.428 ( 1.891)\tData  0.013 ( 1.492)\tLoss 1.8811e+00 (2.1553e+00)\tAcc@1  79.30 ( 60.67)\tAcc@5  96.48 ( 92.16)\n",
            "Epoch: [139][ 50/268]\tTime  0.410 ( 1.635)\tData  0.001 ( 1.237)\tLoss 2.0855e+00 (2.1814e+00)\tAcc@1  58.98 ( 58.79)\tAcc@5  94.53 ( 91.45)\n",
            "Epoch: [139][ 60/268]\tTime  2.190 ( 1.465)\tData  1.848 ( 1.066)\tLoss 2.1301e+00 (2.1872e+00)\tAcc@1  56.25 ( 58.53)\tAcc@5  95.70 ( 91.22)\n",
            "Epoch: [139][ 70/268]\tTime  0.410 ( 1.325)\tData  0.000 ( 0.925)\tLoss 2.1820e+00 (2.1800e+00)\tAcc@1  56.64 ( 59.21)\tAcc@5  92.97 ( 91.46)\n",
            "Epoch: [139][ 80/268]\tTime  0.424 ( 1.241)\tData  0.000 ( 0.841)\tLoss 2.1438e+00 (2.1756e+00)\tAcc@1  54.30 ( 59.14)\tAcc@5  94.53 ( 91.57)\n",
            "Epoch: [139][ 90/268]\tTime  0.423 ( 1.168)\tData  0.000 ( 0.767)\tLoss 2.1998e+00 (2.1905e+00)\tAcc@1  46.48 ( 57.97)\tAcc@5  91.41 ( 91.26)\n",
            "Epoch: [139][100/268]\tTime  0.411 ( 1.114)\tData  0.000 ( 0.714)\tLoss 2.4778e+00 (2.1958e+00)\tAcc@1  67.19 ( 58.39)\tAcc@5  85.55 ( 91.21)\n",
            "Epoch: [139][110/268]\tTime  0.409 ( 1.067)\tData  0.000 ( 0.667)\tLoss 1.8182e+00 (2.1900e+00)\tAcc@1  78.91 ( 58.51)\tAcc@5  97.27 ( 91.39)\n",
            "Epoch: [139][120/268]\tTime  2.625 ( 1.031)\tData  2.292 ( 0.631)\tLoss 2.5112e+00 (2.1878e+00)\tAcc@1  58.59 ( 58.86)\tAcc@5  84.38 ( 91.43)\n",
            "Epoch: [139][130/268]\tTime  0.424 ( 0.984)\tData  0.000 ( 0.584)\tLoss 2.0490e+00 (2.2045e+00)\tAcc@1  61.33 ( 57.87)\tAcc@5  96.48 ( 91.05)\n",
            "Epoch: [139][140/268]\tTime  0.437 ( 0.954)\tData  0.000 ( 0.555)\tLoss 2.5216e+00 (2.2099e+00)\tAcc@1  55.08 ( 57.59)\tAcc@5  84.77 ( 90.96)\n",
            "Epoch: [139][150/268]\tTime  0.437 ( 0.935)\tData  0.000 ( 0.537)\tLoss 2.6059e+00 (2.2250e+00)\tAcc@1  35.16 ( 56.48)\tAcc@5  82.03 ( 90.61)\n",
            "Epoch: [139][160/268]\tTime  0.413 ( 0.916)\tData  0.000 ( 0.518)\tLoss 2.2190e+00 (2.2386e+00)\tAcc@1  65.23 ( 55.67)\tAcc@5  91.02 ( 90.31)\n",
            "Epoch: [139][170/268]\tTime  0.731 ( 0.900)\tData  0.389 ( 0.504)\tLoss 2.1853e+00 (2.2486e+00)\tAcc@1  63.67 ( 55.45)\tAcc@5  93.36 ( 89.94)\n",
            "Epoch: [139][180/268]\tTime  1.992 ( 0.882)\tData  1.664 ( 0.486)\tLoss 2.2533e+00 (2.2453e+00)\tAcc@1  56.64 ( 55.51)\tAcc@5  92.97 ( 90.05)\n",
            "Epoch: [139][190/268]\tTime  0.409 ( 0.862)\tData  0.000 ( 0.465)\tLoss 2.6561e+00 (2.2464e+00)\tAcc@1  35.16 ( 55.27)\tAcc@5  80.86 ( 90.02)\n",
            "Epoch: [139][200/268]\tTime  0.416 ( 0.852)\tData  0.000 ( 0.456)\tLoss 2.2120e+00 (2.2466e+00)\tAcc@1  55.08 ( 55.28)\tAcc@5  92.97 ( 90.01)\n",
            "Epoch: [139][210/268]\tTime  0.422 ( 0.842)\tData  0.005 ( 0.447)\tLoss 2.5006e+00 (2.2469e+00)\tAcc@1  38.28 ( 55.25)\tAcc@5  83.59 ( 89.99)\n",
            "Epoch: [139][220/268]\tTime  0.431 ( 0.835)\tData  0.000 ( 0.441)\tLoss 2.2393e+00 (2.2520e+00)\tAcc@1  45.70 ( 55.14)\tAcc@5  93.75 ( 89.90)\n",
            "Epoch: [139][230/268]\tTime  2.377 ( 0.826)\tData  2.034 ( 0.431)\tLoss 2.6374e+00 (2.2520e+00)\tAcc@1  33.20 ( 55.23)\tAcc@5  78.52 ( 89.90)\n",
            "Epoch: [139][240/268]\tTime  0.423 ( 0.809)\tData  0.000 ( 0.414)\tLoss 2.6079e+00 (2.2556e+00)\tAcc@1  30.47 ( 55.08)\tAcc@5  80.86 ( 89.80)\n",
            "Epoch: [139][250/268]\tTime  0.417 ( 0.802)\tData  0.000 ( 0.407)\tLoss 2.1991e+00 (2.2577e+00)\tAcc@1  53.52 ( 55.03)\tAcc@5  92.58 ( 89.65)\n",
            "Epoch: [139][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.394)\tLoss 2.5271e+00 (2.2614e+00)\tAcc@1  34.77 ( 54.61)\tAcc@5  82.42 ( 89.58)\n",
            "epoch: 139\n",
            "2023-03-25 03:27:34.882175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:34.882268: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:34.882286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:38.786582: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:38.786693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:38.786714: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:42.722814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:42.722911: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:42.722929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:46.649743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:46.649848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:46.649868: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:50.548402: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:50.548513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:50.548532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:54.460594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:54.460702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:54.460720: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:27:58.416735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:58.416833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:27:58.416850: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:28:02.351328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:02.351428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:02.351447: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:28:06.261565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:06.261673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:06.261692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:28:10.208866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:10.208972: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:10.208991: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:28:14.170323: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:14.170422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:14.170441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:28:18.110477: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:18.110578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:28:18.110597: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [140][  0/268]\tTime 54.416 (54.416)\tData 54.079 (54.079)\tLoss 2.2961e+00 (2.2961e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [140][ 10/268]\tTime  0.411 ( 5.442)\tData  0.000 ( 5.039)\tLoss 2.7076e+00 (2.2493e+00)\tAcc@1  28.91 ( 54.08)\tAcc@5  79.30 ( 90.09)\n",
            "Epoch: [140][ 20/268]\tTime  0.419 ( 3.140)\tData  0.013 ( 2.741)\tLoss 2.1011e+00 (2.2834e+00)\tAcc@1  60.16 ( 50.50)\tAcc@5  94.92 ( 89.79)\n",
            "Epoch: [140][ 30/268]\tTime  0.416 ( 2.334)\tData  0.000 ( 1.938)\tLoss 2.2843e+00 (2.3017e+00)\tAcc@1  40.62 ( 50.52)\tAcc@5  88.67 ( 88.72)\n",
            "Epoch: [140][ 40/268]\tTime  0.410 ( 1.899)\tData  0.000 ( 1.505)\tLoss 2.0283e+00 (2.2940e+00)\tAcc@1  74.61 ( 51.11)\tAcc@5  95.70 ( 89.01)\n",
            "Epoch: [140][ 50/268]\tTime  0.417 ( 1.648)\tData  0.000 ( 1.255)\tLoss 1.9976e+00 (2.2862e+00)\tAcc@1  64.84 ( 52.67)\tAcc@5  95.70 ( 89.21)\n",
            "Epoch: [140][ 60/268]\tTime  1.111 ( 1.459)\tData  0.793 ( 1.064)\tLoss 2.4027e+00 (2.2849e+00)\tAcc@1  60.16 ( 53.24)\tAcc@5  87.11 ( 89.17)\n",
            "Epoch: [140][ 70/268]\tTime  0.410 ( 1.325)\tData  0.000 ( 0.928)\tLoss 2.1341e+00 (2.2921e+00)\tAcc@1  54.30 ( 52.45)\tAcc@5  96.48 ( 89.00)\n",
            "Epoch: [140][ 80/268]\tTime  0.421 ( 1.250)\tData  0.000 ( 0.854)\tLoss 1.9477e+00 (2.2687e+00)\tAcc@1  71.09 ( 53.48)\tAcc@5  96.48 ( 89.54)\n",
            "Epoch: [140][ 90/268]\tTime  0.416 ( 1.175)\tData  0.000 ( 0.780)\tLoss 2.1963e+00 (2.2477e+00)\tAcc@1  53.52 ( 54.64)\tAcc@5  91.80 ( 89.92)\n",
            "Epoch: [140][100/268]\tTime  0.416 ( 1.119)\tData  0.001 ( 0.724)\tLoss 2.2622e+00 (2.2565e+00)\tAcc@1  73.05 ( 54.41)\tAcc@5  94.14 ( 89.75)\n",
            "Epoch: [140][110/268]\tTime  0.429 ( 1.073)\tData  0.001 ( 0.678)\tLoss 2.7391e+00 (2.2572e+00)\tAcc@1  26.17 ( 54.52)\tAcc@5  74.22 ( 89.65)\n",
            "Epoch: [140][120/268]\tTime  1.731 ( 1.030)\tData  1.411 ( 0.635)\tLoss 1.8044e+00 (2.2507e+00)\tAcc@1  78.12 ( 54.94)\tAcc@5  96.88 ( 89.93)\n",
            "Epoch: [140][130/268]\tTime  0.425 ( 0.988)\tData  0.000 ( 0.592)\tLoss 2.0527e+00 (2.2498e+00)\tAcc@1  83.98 ( 54.99)\tAcc@5  95.31 ( 89.95)\n",
            "Epoch: [140][140/268]\tTime  0.417 ( 0.964)\tData  0.000 ( 0.568)\tLoss 2.6740e+00 (2.2684e+00)\tAcc@1  33.59 ( 53.77)\tAcc@5  81.25 ( 89.51)\n",
            "Epoch: [140][150/268]\tTime  0.415 ( 0.939)\tData  0.000 ( 0.544)\tLoss 1.8725e+00 (2.2646e+00)\tAcc@1  73.83 ( 53.96)\tAcc@5  97.66 ( 89.60)\n",
            "Epoch: [140][160/268]\tTime  0.430 ( 0.918)\tData  0.000 ( 0.523)\tLoss 1.9895e+00 (2.2702e+00)\tAcc@1  65.23 ( 53.70)\tAcc@5  96.48 ( 89.52)\n",
            "Epoch: [140][170/268]\tTime  0.417 ( 0.903)\tData  0.009 ( 0.508)\tLoss 2.7088e+00 (2.2787e+00)\tAcc@1  27.34 ( 53.15)\tAcc@5  74.22 ( 89.35)\n",
            "Epoch: [140][180/268]\tTime  1.487 ( 0.882)\tData  1.168 ( 0.487)\tLoss 2.2452e+00 (2.2733e+00)\tAcc@1  44.53 ( 53.36)\tAcc@5  94.92 ( 89.47)\n",
            "Epoch: [140][190/268]\tTime  0.417 ( 0.863)\tData  0.006 ( 0.468)\tLoss 2.7096e+00 (2.2807e+00)\tAcc@1  26.95 ( 53.00)\tAcc@5  76.17 ( 89.28)\n",
            "Epoch: [140][200/268]\tTime  0.423 ( 0.852)\tData  0.000 ( 0.457)\tLoss 1.9000e+00 (2.2718e+00)\tAcc@1  76.95 ( 53.47)\tAcc@5  95.70 ( 89.46)\n",
            "Epoch: [140][210/268]\tTime  0.416 ( 0.843)\tData  0.000 ( 0.448)\tLoss 2.2581e+00 (2.2687e+00)\tAcc@1  51.56 ( 53.71)\tAcc@5  92.58 ( 89.56)\n",
            "Epoch: [140][220/268]\tTime  0.415 ( 0.834)\tData  0.000 ( 0.438)\tLoss 2.4951e+00 (2.2650e+00)\tAcc@1  37.89 ( 53.97)\tAcc@5  84.38 ( 89.61)\n",
            "Epoch: [140][230/268]\tTime  0.425 ( 0.823)\tData  0.000 ( 0.427)\tLoss 2.7063e+00 (2.2594e+00)\tAcc@1  35.16 ( 54.26)\tAcc@5  78.12 ( 89.68)\n",
            "Epoch: [140][240/268]\tTime  0.425 ( 0.806)\tData  0.000 ( 0.410)\tLoss 2.1955e+00 (2.2638e+00)\tAcc@1  52.34 ( 53.91)\tAcc@5  94.92 ( 89.58)\n",
            "Epoch: [140][250/268]\tTime  0.382 ( 0.799)\tData  0.000 ( 0.403)\tLoss 2.4156e+00 (2.2612e+00)\tAcc@1  68.75 ( 54.18)\tAcc@5  87.50 ( 89.64)\n",
            "Epoch: [140][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.395)\tLoss 2.7118e+00 (2.2642e+00)\tAcc@1  31.25 ( 54.04)\tAcc@5  78.12 ( 89.48)\n",
            "epoch: 140\n",
            "2023-03-25 03:31:06.284814: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:06.284913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:06.284931: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:10.341797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:10.341890: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:10.341908: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:14.309869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:14.309965: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:14.309983: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:18.227727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:18.227824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:18.227843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:22.199329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:22.199429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:22.199448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:26.088388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:26.088485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:26.088504: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:29.982290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:29.982383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:29.982404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:33.950729: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:33.950830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:33.950848: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:37.857391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:37.857500: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:37.857522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:41.772346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:41.772445: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:41.772464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:45.731966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:45.732065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:45.732083: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:31:49.633153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:49.633256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:31:49.633273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [141][  0/268]\tTime 55.785 (55.785)\tData 55.460 (55.460)\tLoss 2.2301e+00 (2.2301e+00)\tAcc@1  48.05 ( 48.05)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [141][ 10/268]\tTime  0.422 ( 5.453)\tData  0.001 ( 5.054)\tLoss 2.3014e+00 (2.4428e+00)\tAcc@1  48.83 ( 41.97)\tAcc@5  89.06 ( 84.80)\n",
            "Epoch: [141][ 20/268]\tTime  0.417 ( 3.115)\tData  0.000 ( 2.719)\tLoss 1.7650e+00 (2.3000e+00)\tAcc@1  78.12 ( 49.78)\tAcc@5  97.27 ( 87.78)\n",
            "Epoch: [141][ 30/268]\tTime  0.428 ( 2.307)\tData  0.000 ( 1.909)\tLoss 1.8874e+00 (2.2642e+00)\tAcc@1  76.17 ( 52.18)\tAcc@5  96.88 ( 89.11)\n",
            "Epoch: [141][ 40/268]\tTime  0.417 ( 1.898)\tData  0.000 ( 1.502)\tLoss 1.9483e+00 (2.2598e+00)\tAcc@1  78.52 ( 53.33)\tAcc@5  96.09 ( 89.35)\n",
            "Epoch: [141][ 50/268]\tTime  1.178 ( 1.642)\tData  0.847 ( 1.247)\tLoss 2.7517e+00 (2.2751e+00)\tAcc@1  29.69 ( 52.99)\tAcc@5  77.73 ( 88.95)\n",
            "Epoch: [141][ 60/268]\tTime  1.622 ( 1.462)\tData  1.296 ( 1.066)\tLoss 1.7947e+00 (2.2931e+00)\tAcc@1  80.08 ( 51.50)\tAcc@5  97.27 ( 88.45)\n",
            "Epoch: [141][ 70/268]\tTime  0.416 ( 1.328)\tData  0.000 ( 0.931)\tLoss 1.9547e+00 (2.2793e+00)\tAcc@1  75.39 ( 52.13)\tAcc@5  96.48 ( 89.03)\n",
            "Epoch: [141][ 80/268]\tTime  0.415 ( 1.240)\tData  0.000 ( 0.846)\tLoss 2.6635e+00 (2.2968e+00)\tAcc@1  32.81 ( 51.59)\tAcc@5  79.30 ( 88.66)\n",
            "Epoch: [141][ 90/268]\tTime  0.421 ( 1.180)\tData  0.012 ( 0.786)\tLoss 2.3940e+00 (2.3142e+00)\tAcc@1  42.58 ( 50.76)\tAcc@5  88.28 ( 88.23)\n",
            "Epoch: [141][100/268]\tTime  0.416 ( 1.121)\tData  0.000 ( 0.727)\tLoss 2.5855e+00 (2.3243e+00)\tAcc@1  29.69 ( 50.41)\tAcc@5  83.98 ( 87.95)\n",
            "Epoch: [141][110/268]\tTime  2.301 ( 1.079)\tData  1.965 ( 0.686)\tLoss 2.0270e+00 (2.3264e+00)\tAcc@1  60.55 ( 50.25)\tAcc@5  96.09 ( 88.03)\n",
            "Epoch: [141][120/268]\tTime  0.456 ( 1.025)\tData  0.126 ( 0.632)\tLoss 2.1292e+00 (2.3037e+00)\tAcc@1  58.98 ( 51.24)\tAcc@5  94.14 ( 88.39)\n",
            "Epoch: [141][130/268]\tTime  0.429 ( 0.993)\tData  0.000 ( 0.598)\tLoss 2.6446e+00 (2.3102e+00)\tAcc@1  35.55 ( 50.73)\tAcc@5  79.30 ( 88.19)\n",
            "Epoch: [141][140/268]\tTime  0.416 ( 0.965)\tData  0.013 ( 0.570)\tLoss 2.5528e+00 (2.3146e+00)\tAcc@1  58.98 ( 50.59)\tAcc@5  85.55 ( 88.08)\n",
            "Epoch: [141][150/268]\tTime  0.416 ( 0.943)\tData  0.000 ( 0.548)\tLoss 1.9122e+00 (2.3041e+00)\tAcc@1  83.59 ( 51.47)\tAcc@5  95.31 ( 88.33)\n",
            "Epoch: [141][160/268]\tTime  0.433 ( 0.920)\tData  0.000 ( 0.526)\tLoss 2.2605e+00 (2.2948e+00)\tAcc@1  51.56 ( 51.67)\tAcc@5  91.41 ( 88.56)\n",
            "Epoch: [141][170/268]\tTime  2.556 ( 0.905)\tData  2.208 ( 0.511)\tLoss 1.9195e+00 (2.2921e+00)\tAcc@1  66.02 ( 51.73)\tAcc@5  97.27 ( 88.63)\n",
            "Epoch: [141][180/268]\tTime  0.418 ( 0.878)\tData  0.000 ( 0.483)\tLoss 2.3253e+00 (2.2875e+00)\tAcc@1  44.14 ( 51.97)\tAcc@5  90.62 ( 88.78)\n",
            "Epoch: [141][190/268]\tTime  0.409 ( 0.867)\tData  0.000 ( 0.471)\tLoss 2.7190e+00 (2.2999e+00)\tAcc@1  28.52 ( 51.53)\tAcc@5  75.78 ( 88.54)\n",
            "Epoch: [141][200/268]\tTime  0.417 ( 0.856)\tData  0.000 ( 0.460)\tLoss 2.2863e+00 (2.2944e+00)\tAcc@1  43.75 ( 51.76)\tAcc@5  91.80 ( 88.64)\n",
            "Epoch: [141][210/268]\tTime  0.428 ( 0.842)\tData  0.018 ( 0.446)\tLoss 2.3780e+00 (2.2926e+00)\tAcc@1  48.83 ( 51.72)\tAcc@5  88.28 ( 88.73)\n",
            "Epoch: [141][220/268]\tTime  0.416 ( 0.833)\tData  0.000 ( 0.437)\tLoss 2.2250e+00 (2.2876e+00)\tAcc@1  52.73 ( 51.97)\tAcc@5  93.36 ( 88.82)\n",
            "Epoch: [141][230/268]\tTime  2.199 ( 0.823)\tData  1.866 ( 0.428)\tLoss 1.8056e+00 (2.2825e+00)\tAcc@1  79.69 ( 52.20)\tAcc@5  98.83 ( 88.94)\n",
            "Epoch: [141][240/268]\tTime  0.493 ( 0.807)\tData  0.168 ( 0.412)\tLoss 2.6038e+00 (2.2741e+00)\tAcc@1  68.75 ( 52.84)\tAcc@5  86.72 ( 89.12)\n",
            "Epoch: [141][250/268]\tTime  0.422 ( 0.799)\tData  0.000 ( 0.404)\tLoss 1.9666e+00 (2.2633e+00)\tAcc@1  66.41 ( 53.35)\tAcc@5  96.09 ( 89.30)\n",
            "Epoch: [141][260/268]\tTime  0.416 ( 0.788)\tData  0.000 ( 0.394)\tLoss 2.5361e+00 (2.2560e+00)\tAcc@1  35.16 ( 53.88)\tAcc@5  82.81 ( 89.48)\n",
            "epoch: 141\n",
            "2023-03-25 03:34:36.605357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:36.605499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:36.605517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:34:40.508883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:40.508984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:40.509004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:34:44.490421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:44.490520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:44.490541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:34:48.408866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:48.408970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:48.408990: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:34:52.309867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:52.309966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:52.309985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:34:56.233099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:56.233195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:34:56.233214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:00.101423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:00.101529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:00.101548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:03.992096: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:03.992193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:03.992214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:07.906827: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:07.906922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:07.906940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:11.790613: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:11.790721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:11.790741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:15.685995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:15.686093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:15.686112: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:35:19.587834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:19.587927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:35:19.587945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [142][  0/268]\tTime 54.798 (54.798)\tData 54.471 (54.471)\tLoss 2.6021e+00 (2.6021e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [142][ 10/268]\tTime  0.424 ( 5.365)\tData  0.001 ( 4.962)\tLoss 2.5682e+00 (2.3992e+00)\tAcc@1  39.45 ( 44.67)\tAcc@5  82.42 ( 86.97)\n",
            "Epoch: [142][ 20/268]\tTime  0.418 ( 3.118)\tData  0.013 ( 2.717)\tLoss 1.5569e+00 (2.3794e+00)\tAcc@1  91.80 ( 46.17)\tAcc@5  98.44 ( 86.05)\n",
            "Epoch: [142][ 30/268]\tTime  0.418 ( 2.331)\tData  0.000 ( 1.931)\tLoss 1.6214e+00 (2.3271e+00)\tAcc@1  94.14 ( 49.14)\tAcc@5  97.66 ( 87.21)\n",
            "Epoch: [142][ 40/268]\tTime  0.416 ( 1.902)\tData  0.000 ( 1.501)\tLoss 2.6989e+00 (2.3480e+00)\tAcc@1  32.81 ( 48.37)\tAcc@5  76.17 ( 86.51)\n",
            "Epoch: [142][ 50/268]\tTime  0.416 ( 1.653)\tData  0.001 ( 1.252)\tLoss 1.9538e+00 (2.3393e+00)\tAcc@1  78.12 ( 49.14)\tAcc@5  94.14 ( 86.84)\n",
            "Epoch: [142][ 60/268]\tTime  1.801 ( 1.474)\tData  1.482 ( 1.073)\tLoss 2.1739e+00 (2.2895e+00)\tAcc@1  55.47 ( 52.24)\tAcc@5  93.75 ( 88.05)\n",
            "Epoch: [142][ 70/268]\tTime  0.423 ( 1.325)\tData  0.000 ( 0.923)\tLoss 2.6378e+00 (2.2886e+00)\tAcc@1  26.95 ( 51.84)\tAcc@5  80.47 ( 88.37)\n",
            "Epoch: [142][ 80/268]\tTime  0.416 ( 1.238)\tData  0.000 ( 0.837)\tLoss 2.5943e+00 (2.2929e+00)\tAcc@1  34.77 ( 51.72)\tAcc@5  81.25 ( 88.30)\n",
            "Epoch: [142][ 90/268]\tTime  0.409 ( 1.168)\tData  0.000 ( 0.766)\tLoss 2.1256e+00 (2.2875e+00)\tAcc@1  59.38 ( 52.05)\tAcc@5  96.09 ( 88.38)\n",
            "Epoch: [142][100/268]\tTime  0.410 ( 1.121)\tData  0.000 ( 0.719)\tLoss 1.9204e+00 (2.2794e+00)\tAcc@1  80.08 ( 52.19)\tAcc@5  97.66 ( 88.54)\n",
            "Epoch: [142][110/268]\tTime  0.421 ( 1.079)\tData  0.004 ( 0.677)\tLoss 1.8556e+00 (2.2765e+00)\tAcc@1  80.08 ( 52.34)\tAcc@5  97.27 ( 88.57)\n",
            "Epoch: [142][120/268]\tTime  2.896 ( 1.046)\tData  2.559 ( 0.644)\tLoss 1.7059e+00 (2.2677e+00)\tAcc@1  89.84 ( 52.74)\tAcc@5  98.05 ( 88.75)\n",
            "Epoch: [142][130/268]\tTime  0.419 ( 0.998)\tData  0.000 ( 0.596)\tLoss 1.8113e+00 (2.2702e+00)\tAcc@1  80.08 ( 52.51)\tAcc@5  99.22 ( 88.77)\n",
            "Epoch: [142][140/268]\tTime  0.429 ( 0.970)\tData  0.001 ( 0.568)\tLoss 1.7294e+00 (2.2652e+00)\tAcc@1  87.11 ( 52.84)\tAcc@5  98.05 ( 88.92)\n",
            "Epoch: [142][150/268]\tTime  0.416 ( 0.948)\tData  0.000 ( 0.546)\tLoss 1.8519e+00 (2.2509e+00)\tAcc@1  82.81 ( 53.59)\tAcc@5  97.66 ( 89.21)\n",
            "Epoch: [142][160/268]\tTime  0.417 ( 0.928)\tData  0.012 ( 0.526)\tLoss 2.5530e+00 (2.2522e+00)\tAcc@1  58.20 ( 53.85)\tAcc@5  86.33 ( 89.23)\n",
            "Epoch: [142][170/268]\tTime  0.423 ( 0.911)\tData  0.000 ( 0.508)\tLoss 1.7296e+00 (2.2427e+00)\tAcc@1  85.16 ( 54.28)\tAcc@5  97.66 ( 89.42)\n",
            "Epoch: [142][180/268]\tTime  2.024 ( 0.892)\tData  1.698 ( 0.490)\tLoss 2.0735e+00 (2.2407e+00)\tAcc@1  61.72 ( 54.44)\tAcc@5  92.19 ( 89.45)\n",
            "Epoch: [142][190/268]\tTime  0.411 ( 0.867)\tData  0.000 ( 0.465)\tLoss 2.1558e+00 (2.2475e+00)\tAcc@1  67.58 ( 54.08)\tAcc@5  93.75 ( 89.34)\n",
            "Epoch: [142][200/268]\tTime  0.432 ( 0.854)\tData  0.000 ( 0.452)\tLoss 2.5741e+00 (2.2473e+00)\tAcc@1  41.41 ( 54.01)\tAcc@5  93.36 ( 89.44)\n",
            "Epoch: [142][210/268]\tTime  0.417 ( 0.844)\tData  0.000 ( 0.442)\tLoss 2.5455e+00 (2.2499e+00)\tAcc@1  34.77 ( 53.94)\tAcc@5  83.20 ( 89.38)\n",
            "Epoch: [142][220/268]\tTime  0.431 ( 0.834)\tData  0.000 ( 0.432)\tLoss 2.6699e+00 (2.2515e+00)\tAcc@1  29.69 ( 54.02)\tAcc@5  74.22 ( 89.31)\n",
            "Epoch: [142][230/268]\tTime  0.416 ( 0.824)\tData  0.000 ( 0.422)\tLoss 1.8616e+00 (2.2482e+00)\tAcc@1  72.27 ( 54.24)\tAcc@5  94.92 ( 89.33)\n",
            "Epoch: [142][240/268]\tTime  1.274 ( 0.813)\tData  0.956 ( 0.412)\tLoss 2.0140e+00 (2.2496e+00)\tAcc@1  58.59 ( 54.04)\tAcc@5  95.31 ( 89.32)\n",
            "Epoch: [142][250/268]\tTime  0.417 ( 0.802)\tData  0.000 ( 0.400)\tLoss 2.0811e+00 (2.2488e+00)\tAcc@1  58.59 ( 54.17)\tAcc@5  94.14 ( 89.33)\n",
            "Epoch: [142][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.389)\tLoss 2.4793e+00 (2.2477e+00)\tAcc@1  66.80 ( 54.41)\tAcc@5  89.84 ( 89.39)\n",
            "epoch: 142\n",
            "2023-03-25 03:38:07.410612: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:07.410728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:07.410749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:11.332320: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:11.332421: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:11.332439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:15.229443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:15.229549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:15.229568: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:19.154610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:19.154724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:19.154744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:23.083406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:23.083514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:23.083533: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:26.965436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:26.965529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:26.965550: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:30.868901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:30.868997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:30.869019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:34.744195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:34.744289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:34.744307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:38.634616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:38.634727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:38.634747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:42.603555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:42.603678: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:42.603707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:46.567958: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:46.568051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:46.568070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:38:50.465812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:50.465906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:38:50.465923: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [143][  0/268]\tTime 55.064 (55.064)\tData 54.730 (54.730)\tLoss 2.5807e+00 (2.5807e+00)\tAcc@1  30.08 ( 30.08)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [143][ 10/268]\tTime  0.440 ( 5.414)\tData  0.009 ( 5.015)\tLoss 1.8869e+00 (2.3393e+00)\tAcc@1  74.22 ( 53.87)\tAcc@5  96.48 ( 84.98)\n",
            "Epoch: [143][ 20/268]\tTime  0.417 ( 3.102)\tData  0.000 ( 2.708)\tLoss 2.1285e+00 (2.2687e+00)\tAcc@1  60.16 ( 55.32)\tAcc@5  95.70 ( 88.37)\n",
            "Epoch: [143][ 30/268]\tTime  0.421 ( 2.322)\tData  0.000 ( 1.925)\tLoss 1.8350e+00 (2.2847e+00)\tAcc@1  78.12 ( 52.31)\tAcc@5  96.88 ( 88.53)\n",
            "Epoch: [143][ 40/268]\tTime  0.416 ( 1.898)\tData  0.000 ( 1.500)\tLoss 2.1051e+00 (2.2683e+00)\tAcc@1  55.86 ( 52.86)\tAcc@5  92.97 ( 89.17)\n",
            "Epoch: [143][ 50/268]\tTime  0.416 ( 1.661)\tData  0.001 ( 1.263)\tLoss 2.4896e+00 (2.2630e+00)\tAcc@1  34.38 ( 52.56)\tAcc@5  84.77 ( 89.65)\n",
            "Epoch: [143][ 60/268]\tTime  2.430 ( 1.490)\tData  2.099 ( 1.092)\tLoss 1.9653e+00 (2.2414e+00)\tAcc@1  70.31 ( 54.64)\tAcc@5  96.48 ( 90.12)\n",
            "Epoch: [143][ 70/268]\tTime  0.416 ( 1.339)\tData  0.000 ( 0.940)\tLoss 2.3468e+00 (2.2400e+00)\tAcc@1  57.81 ( 54.72)\tAcc@5  93.36 ( 90.38)\n",
            "Epoch: [143][ 80/268]\tTime  0.417 ( 1.248)\tData  0.000 ( 0.848)\tLoss 2.0619e+00 (2.2584e+00)\tAcc@1  75.78 ( 53.76)\tAcc@5  94.53 ( 89.90)\n",
            "Epoch: [143][ 90/268]\tTime  0.418 ( 1.178)\tData  0.000 ( 0.779)\tLoss 1.9673e+00 (2.2593e+00)\tAcc@1  77.34 ( 53.91)\tAcc@5  96.88 ( 89.94)\n",
            "Epoch: [143][100/268]\tTime  0.417 ( 1.118)\tData  0.000 ( 0.720)\tLoss 1.9423e+00 (2.2584e+00)\tAcc@1  67.58 ( 53.75)\tAcc@5  97.27 ( 89.99)\n",
            "Epoch: [143][110/268]\tTime  0.419 ( 1.071)\tData  0.000 ( 0.673)\tLoss 2.1630e+00 (2.2646e+00)\tAcc@1  55.47 ( 53.28)\tAcc@5  90.62 ( 89.70)\n",
            "Epoch: [143][120/268]\tTime  2.557 ( 1.037)\tData  2.210 ( 0.639)\tLoss 2.0693e+00 (2.2559e+00)\tAcc@1  72.66 ( 53.79)\tAcc@5  94.92 ( 89.79)\n",
            "Epoch: [143][130/268]\tTime  0.422 ( 0.990)\tData  0.000 ( 0.591)\tLoss 2.5259e+00 (2.2546e+00)\tAcc@1  36.72 ( 53.58)\tAcc@5  85.55 ( 89.80)\n",
            "Epoch: [143][140/268]\tTime  0.430 ( 0.963)\tData  0.000 ( 0.563)\tLoss 2.1941e+00 (2.2494e+00)\tAcc@1  61.33 ( 53.98)\tAcc@5  93.75 ( 89.86)\n",
            "Epoch: [143][150/268]\tTime  0.415 ( 0.937)\tData  0.000 ( 0.539)\tLoss 2.0469e+00 (2.2482e+00)\tAcc@1  54.30 ( 54.03)\tAcc@5  94.53 ( 89.89)\n",
            "Epoch: [143][160/268]\tTime  0.429 ( 0.921)\tData  0.000 ( 0.523)\tLoss 2.0053e+00 (2.2560e+00)\tAcc@1  69.14 ( 53.78)\tAcc@5  96.48 ( 89.68)\n",
            "Epoch: [143][170/268]\tTime  0.433 ( 0.905)\tData  0.000 ( 0.506)\tLoss 2.6969e+00 (2.2599e+00)\tAcc@1  34.38 ( 53.82)\tAcc@5  77.73 ( 89.56)\n",
            "Epoch: [143][180/268]\tTime  3.057 ( 0.893)\tData  2.708 ( 0.494)\tLoss 1.8454e+00 (2.2611e+00)\tAcc@1  80.86 ( 53.80)\tAcc@5  98.44 ( 89.45)\n",
            "Epoch: [143][190/268]\tTime  0.431 ( 0.868)\tData  0.001 ( 0.469)\tLoss 2.1420e+00 (2.2548e+00)\tAcc@1  65.62 ( 54.10)\tAcc@5  93.36 ( 89.57)\n",
            "Epoch: [143][200/268]\tTime  0.417 ( 0.854)\tData  0.000 ( 0.454)\tLoss 2.0370e+00 (2.2549e+00)\tAcc@1  64.45 ( 54.05)\tAcc@5  94.92 ( 89.39)\n",
            "Epoch: [143][210/268]\tTime  0.417 ( 0.843)\tData  0.000 ( 0.444)\tLoss 2.5602e+00 (2.2514e+00)\tAcc@1  32.42 ( 54.42)\tAcc@5  81.64 ( 89.55)\n",
            "Epoch: [143][220/268]\tTime  0.424 ( 0.834)\tData  0.000 ( 0.435)\tLoss 2.5137e+00 (2.2519e+00)\tAcc@1  36.33 ( 54.54)\tAcc@5  81.25 ( 89.59)\n",
            "Epoch: [143][230/268]\tTime  0.427 ( 0.824)\tData  0.000 ( 0.425)\tLoss 2.1785e+00 (2.2465e+00)\tAcc@1  57.81 ( 54.83)\tAcc@5  94.92 ( 89.73)\n",
            "Epoch: [143][240/268]\tTime  2.738 ( 0.817)\tData  2.399 ( 0.417)\tLoss 1.8026e+00 (2.2454e+00)\tAcc@1  83.98 ( 55.02)\tAcc@5  97.66 ( 89.84)\n",
            "Epoch: [143][250/268]\tTime  0.411 ( 0.801)\tData  0.000 ( 0.401)\tLoss 1.8811e+00 (2.2443e+00)\tAcc@1  79.69 ( 54.89)\tAcc@5  95.70 ( 89.85)\n",
            "Epoch: [143][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.389)\tLoss 2.0460e+00 (2.2471e+00)\tAcc@1  65.23 ( 54.73)\tAcc@5  94.92 ( 89.80)\n",
            "epoch: 143\n",
            "2023-03-25 03:41:38.035842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:38.035941: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:38.035959: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:41:41.935945: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:41.936045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:41.936064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:41:45.856558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:45.856653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:45.856680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:41:49.741866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:49.741971: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:49.741992: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:41:53.713753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:53.713876: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:53.713895: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:41:57.694957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:57.695058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:41:57.695078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:01.585024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:01.585119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:01.585138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:05.475854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:05.475948: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:05.475966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:09.412563: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:09.412672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:09.412692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:13.325191: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:13.325290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:13.325309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:17.205641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:17.205747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:17.205765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:42:21.111565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:21.111673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:42:21.111693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [144][  0/268]\tTime 55.182 (55.182)\tData 54.847 (54.847)\tLoss 2.2435e+00 (2.2435e+00)\tAcc@1  52.73 ( 52.73)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [144][ 10/268]\tTime  0.417 ( 5.433)\tData  0.001 ( 5.032)\tLoss 1.8686e+00 (2.1137e+00)\tAcc@1  71.48 ( 61.04)\tAcc@5  96.48 ( 93.93)\n",
            "Epoch: [144][ 20/268]\tTime  0.417 ( 3.135)\tData  0.000 ( 2.739)\tLoss 2.6084e+00 (2.1422e+00)\tAcc@1  31.64 ( 60.08)\tAcc@5  79.30 ( 93.10)\n",
            "Epoch: [144][ 30/268]\tTime  0.431 ( 2.324)\tData  0.000 ( 1.930)\tLoss 2.6956e+00 (2.2022e+00)\tAcc@1  28.52 ( 57.25)\tAcc@5  71.09 ( 90.44)\n",
            "Epoch: [144][ 40/268]\tTime  0.417 ( 1.891)\tData  0.000 ( 1.497)\tLoss 2.4848e+00 (2.2028e+00)\tAcc@1  59.38 ( 57.59)\tAcc@5  87.50 ( 90.64)\n",
            "Epoch: [144][ 50/268]\tTime  0.422 ( 1.645)\tData  0.000 ( 1.252)\tLoss 2.5471e+00 (2.1916e+00)\tAcc@1  33.98 ( 58.26)\tAcc@5  82.42 ( 91.09)\n",
            "Epoch: [144][ 60/268]\tTime  0.612 ( 1.447)\tData  0.277 ( 1.053)\tLoss 2.5644e+00 (2.2125e+00)\tAcc@1  57.03 ( 57.51)\tAcc@5  88.67 ( 90.79)\n",
            "Epoch: [144][ 70/268]\tTime  0.417 ( 1.329)\tData  0.000 ( 0.932)\tLoss 2.5543e+00 (2.2009e+00)\tAcc@1  33.98 ( 57.50)\tAcc@5  82.42 ( 90.94)\n",
            "Epoch: [144][ 80/268]\tTime  0.423 ( 1.237)\tData  0.000 ( 0.841)\tLoss 1.8457e+00 (2.2039e+00)\tAcc@1  76.95 ( 57.43)\tAcc@5  98.44 ( 90.90)\n",
            "Epoch: [144][ 90/268]\tTime  0.411 ( 1.172)\tData  0.000 ( 0.777)\tLoss 2.5157e+00 (2.1914e+00)\tAcc@1  34.77 ( 57.99)\tAcc@5  83.20 ( 91.14)\n",
            "Epoch: [144][100/268]\tTime  0.416 ( 1.118)\tData  0.000 ( 0.723)\tLoss 2.0395e+00 (2.1857e+00)\tAcc@1  58.59 ( 58.34)\tAcc@5  95.31 ( 91.29)\n",
            "Epoch: [144][110/268]\tTime  0.413 ( 1.071)\tData  0.000 ( 0.676)\tLoss 2.3690e+00 (2.1852e+00)\tAcc@1  46.48 ( 58.52)\tAcc@5  89.84 ( 91.43)\n",
            "Epoch: [144][120/268]\tTime  1.749 ( 1.028)\tData  1.423 ( 0.633)\tLoss 2.5030e+00 (2.2007e+00)\tAcc@1  35.16 ( 57.84)\tAcc@5  82.03 ( 90.83)\n",
            "Epoch: [144][130/268]\tTime  0.430 ( 0.988)\tData  0.000 ( 0.593)\tLoss 2.5265e+00 (2.2097e+00)\tAcc@1  35.55 ( 57.62)\tAcc@5  83.98 ( 90.75)\n",
            "Epoch: [144][140/268]\tTime  0.431 ( 0.961)\tData  0.000 ( 0.566)\tLoss 1.7712e+00 (2.2085e+00)\tAcc@1  89.06 ( 57.38)\tAcc@5  97.66 ( 90.72)\n",
            "Epoch: [144][150/268]\tTime  0.409 ( 0.938)\tData  0.001 ( 0.543)\tLoss 2.1523e+00 (2.2063e+00)\tAcc@1  63.28 ( 57.43)\tAcc@5  96.48 ( 90.86)\n",
            "Epoch: [144][160/268]\tTime  0.418 ( 0.920)\tData  0.000 ( 0.524)\tLoss 1.8672e+00 (2.2043e+00)\tAcc@1  76.56 ( 57.62)\tAcc@5  97.27 ( 90.90)\n",
            "Epoch: [144][170/268]\tTime  0.416 ( 0.904)\tData  0.000 ( 0.509)\tLoss 2.4842e+00 (2.2113e+00)\tAcc@1  34.38 ( 56.95)\tAcc@5  82.03 ( 90.72)\n",
            "Epoch: [144][180/268]\tTime  1.946 ( 0.886)\tData  1.615 ( 0.490)\tLoss 2.3825e+00 (2.2126e+00)\tAcc@1  64.84 ( 56.67)\tAcc@5  88.67 ( 90.71)\n",
            "Epoch: [144][190/268]\tTime  0.442 ( 0.862)\tData  0.000 ( 0.466)\tLoss 2.2384e+00 (2.2106e+00)\tAcc@1  46.09 ( 56.60)\tAcc@5  91.02 ( 90.77)\n",
            "Epoch: [144][200/268]\tTime  0.417 ( 0.850)\tData  0.000 ( 0.454)\tLoss 2.0886e+00 (2.2078e+00)\tAcc@1  57.03 ( 56.70)\tAcc@5  94.14 ( 90.85)\n",
            "Epoch: [144][210/268]\tTime  0.417 ( 0.839)\tData  0.000 ( 0.443)\tLoss 2.1902e+00 (2.2069e+00)\tAcc@1  52.34 ( 56.68)\tAcc@5  93.75 ( 90.85)\n",
            "Epoch: [144][220/268]\tTime  0.532 ( 0.831)\tData  0.199 ( 0.436)\tLoss 2.3932e+00 (2.2109e+00)\tAcc@1  42.97 ( 56.38)\tAcc@5  87.50 ( 90.79)\n",
            "Epoch: [144][230/268]\tTime  0.434 ( 0.824)\tData  0.000 ( 0.429)\tLoss 1.7045e+00 (2.2142e+00)\tAcc@1  78.91 ( 56.34)\tAcc@5  97.66 ( 90.73)\n",
            "Epoch: [144][240/268]\tTime  1.615 ( 0.812)\tData  1.274 ( 0.417)\tLoss 2.4681e+00 (2.2190e+00)\tAcc@1  38.28 ( 56.23)\tAcc@5  82.03 ( 90.59)\n",
            "Epoch: [144][250/268]\tTime  0.417 ( 0.799)\tData  0.000 ( 0.404)\tLoss 2.4421e+00 (2.2251e+00)\tAcc@1  60.55 ( 55.86)\tAcc@5  89.06 ( 90.48)\n",
            "Epoch: [144][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.395)\tLoss 2.1974e+00 (2.2179e+00)\tAcc@1  66.02 ( 56.31)\tAcc@5  94.92 ( 90.62)\n",
            "epoch: 144\n",
            "2023-03-25 03:45:08.956705: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:08.956804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:08.956825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:12.878918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:12.879014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:12.879037: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:16.806372: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:16.806470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:16.806496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:20.713579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:20.713693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:20.713712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:24.581213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:24.581305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:24.581322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:28.470523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:28.470628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:28.470647: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:32.377617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:32.377757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:32.377776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:36.306834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:36.306927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:36.306945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:40.198433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:40.198546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:40.198567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:44.102783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:44.102874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:44.102892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:48.020108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:48.020204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:48.020224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:45:51.908573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:51.908691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:45:51.908711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [145][  0/268]\tTime 54.597 (54.597)\tData 54.255 (54.255)\tLoss 4.4356e+00 (4.4356e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   9.77 (  9.77)\n",
            "Epoch: [145][ 10/268]\tTime  0.420 ( 5.380)\tData  0.000 ( 4.977)\tLoss 1.8760e+00 (2.2988e+00)\tAcc@1  78.12 ( 57.39)\tAcc@5  96.88 ( 84.73)\n",
            "Epoch: [145][ 20/268]\tTime  0.413 ( 3.121)\tData  0.000 ( 2.726)\tLoss 1.7833e+00 (2.2638e+00)\tAcc@1  80.86 ( 56.44)\tAcc@5  98.05 ( 87.43)\n",
            "Epoch: [145][ 30/268]\tTime  0.430 ( 2.311)\tData  0.000 ( 1.918)\tLoss 3.0635e+00 (2.2994e+00)\tAcc@1   8.59 ( 52.27)\tAcc@5  60.55 ( 87.56)\n",
            "Epoch: [145][ 40/268]\tTime  0.448 ( 1.894)\tData  0.000 ( 1.500)\tLoss 2.0333e+00 (2.2662e+00)\tAcc@1  74.61 ( 53.78)\tAcc@5  94.92 ( 88.84)\n",
            "Epoch: [145][ 50/268]\tTime  0.422 ( 1.629)\tData  0.050 ( 1.237)\tLoss 2.3720e+00 (2.2736e+00)\tAcc@1  73.83 ( 53.73)\tAcc@5  89.45 ( 88.92)\n",
            "Epoch: [145][ 60/268]\tTime  1.395 ( 1.447)\tData  1.069 ( 1.054)\tLoss 1.9550e+00 (2.2580e+00)\tAcc@1  66.80 ( 54.35)\tAcc@5  96.48 ( 89.33)\n",
            "Epoch: [145][ 70/268]\tTime  0.422 ( 1.319)\tData  0.000 ( 0.927)\tLoss 1.5771e+00 (2.2594e+00)\tAcc@1  90.62 ( 53.98)\tAcc@5  98.44 ( 89.30)\n",
            "Epoch: [145][ 80/268]\tTime  0.437 ( 1.231)\tData  0.000 ( 0.840)\tLoss 2.2853e+00 (2.2555e+00)\tAcc@1  51.56 ( 54.21)\tAcc@5  91.41 ( 89.35)\n",
            "Epoch: [145][ 90/268]\tTime  0.411 ( 1.166)\tData  0.000 ( 0.774)\tLoss 2.6174e+00 (2.2526e+00)\tAcc@1  33.59 ( 54.40)\tAcc@5  80.08 ( 89.41)\n",
            "Epoch: [145][100/268]\tTime  0.422 ( 1.113)\tData  0.000 ( 0.721)\tLoss 2.4907e+00 (2.2360e+00)\tAcc@1  37.89 ( 54.96)\tAcc@5  86.72 ( 89.67)\n",
            "Epoch: [145][110/268]\tTime  0.723 ( 1.069)\tData  0.401 ( 0.678)\tLoss 2.5479e+00 (2.2238e+00)\tAcc@1  60.16 ( 55.91)\tAcc@5  87.11 ( 89.90)\n",
            "Epoch: [145][120/268]\tTime  0.687 ( 1.018)\tData  0.367 ( 0.625)\tLoss 1.9838e+00 (2.2190e+00)\tAcc@1  64.45 ( 55.87)\tAcc@5  95.31 ( 90.03)\n",
            "Epoch: [145][130/268]\tTime  0.416 ( 0.983)\tData  0.000 ( 0.590)\tLoss 2.3087e+00 (2.2230e+00)\tAcc@1  47.66 ( 55.43)\tAcc@5  90.23 ( 90.03)\n",
            "Epoch: [145][140/268]\tTime  0.418 ( 0.962)\tData  0.000 ( 0.570)\tLoss 1.9883e+00 (2.2191e+00)\tAcc@1  66.02 ( 55.60)\tAcc@5  96.48 ( 90.16)\n",
            "Epoch: [145][150/268]\tTime  0.421 ( 0.941)\tData  0.000 ( 0.549)\tLoss 1.8751e+00 (2.2133e+00)\tAcc@1  71.88 ( 56.04)\tAcc@5  98.44 ( 90.28)\n",
            "Epoch: [145][160/268]\tTime  0.422 ( 0.925)\tData  0.000 ( 0.533)\tLoss 2.2246e+00 (2.2319e+00)\tAcc@1  46.09 ( 55.05)\tAcc@5  93.36 ( 89.92)\n",
            "Epoch: [145][170/268]\tTime  1.239 ( 0.907)\tData  0.913 ( 0.515)\tLoss 2.3157e+00 (2.2205e+00)\tAcc@1  71.48 ( 55.94)\tAcc@5  89.84 ( 90.22)\n",
            "Epoch: [145][180/268]\tTime  0.416 ( 0.880)\tData  0.000 ( 0.487)\tLoss 2.2605e+00 (2.2205e+00)\tAcc@1  49.61 ( 55.83)\tAcc@5  91.80 ( 90.31)\n",
            "Epoch: [145][190/268]\tTime  0.423 ( 0.865)\tData  0.000 ( 0.472)\tLoss 1.8810e+00 (2.2127e+00)\tAcc@1  75.00 ( 56.25)\tAcc@5  97.66 ( 90.49)\n",
            "Epoch: [145][200/268]\tTime  0.417 ( 0.854)\tData  0.000 ( 0.460)\tLoss 2.3103e+00 (2.2108e+00)\tAcc@1  49.61 ( 56.21)\tAcc@5  87.11 ( 90.55)\n",
            "Epoch: [145][210/268]\tTime  0.426 ( 0.842)\tData  0.000 ( 0.449)\tLoss 2.6794e+00 (2.2144e+00)\tAcc@1  31.64 ( 55.91)\tAcc@5  81.64 ( 90.42)\n",
            "Epoch: [145][220/268]\tTime  0.424 ( 0.831)\tData  0.000 ( 0.438)\tLoss 2.2745e+00 (2.2150e+00)\tAcc@1  53.52 ( 55.93)\tAcc@5  92.97 ( 90.42)\n",
            "Epoch: [145][230/268]\tTime  0.938 ( 0.821)\tData  0.594 ( 0.428)\tLoss 2.6798e+00 (2.2129e+00)\tAcc@1  28.52 ( 56.04)\tAcc@5  81.25 ( 90.56)\n",
            "Epoch: [145][240/268]\tTime  0.425 ( 0.804)\tData  0.000 ( 0.411)\tLoss 2.1813e+00 (2.2147e+00)\tAcc@1  51.95 ( 55.93)\tAcc@5  94.53 ( 90.50)\n",
            "Epoch: [145][250/268]\tTime  0.413 ( 0.798)\tData  0.000 ( 0.404)\tLoss 2.3268e+00 (2.2114e+00)\tAcc@1  47.66 ( 56.04)\tAcc@5  95.70 ( 90.64)\n",
            "Epoch: [145][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.395)\tLoss 1.6809e+00 (2.2042e+00)\tAcc@1  89.45 ( 56.48)\tAcc@5  97.66 ( 90.74)\n",
            "epoch: 145\n",
            "2023-03-25 03:48:39.363645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:39.363757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:39.363776: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:48:43.308737: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:43.308835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:43.308855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:48:47.236139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:47.236236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:47.236254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:48:51.153682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:51.153782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:51.153802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:48:55.056212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:55.056305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:55.056322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:48:58.971940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:58.972033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:48:58.972054: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:02.877222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:02.877322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:02.877356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:06.759166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:06.759262: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:06.759282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:10.702855: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:10.702955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:10.702974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:14.615647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:14.615762: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:14.615780: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:18.544303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:18.544404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:18.544422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:49:22.455349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:22.455444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:49:22.455462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [146][  0/268]\tTime 54.617 (54.617)\tData 54.286 (54.286)\tLoss 1.9635e+00 (1.9635e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  97.27 ( 97.27)\n",
            "Epoch: [146][ 10/268]\tTime  0.417 ( 5.348)\tData  0.000 ( 4.945)\tLoss 1.9225e+00 (2.2248e+00)\tAcc@1  73.83 ( 53.80)\tAcc@5  97.27 ( 90.02)\n",
            "Epoch: [146][ 20/268]\tTime  0.416 ( 3.107)\tData  0.000 ( 2.709)\tLoss 1.9996e+00 (2.2110e+00)\tAcc@1  66.80 ( 56.25)\tAcc@5  97.27 ( 90.62)\n",
            "Epoch: [146][ 30/268]\tTime  0.416 ( 2.305)\tData  0.000 ( 1.909)\tLoss 2.0148e+00 (2.2515e+00)\tAcc@1  77.73 ( 54.57)\tAcc@5  95.31 ( 89.57)\n",
            "Epoch: [146][ 40/268]\tTime  0.416 ( 1.891)\tData  0.000 ( 1.495)\tLoss 2.5425e+00 (2.2172e+00)\tAcc@1  32.81 ( 55.99)\tAcc@5  84.38 ( 90.33)\n",
            "Epoch: [146][ 50/268]\tTime  0.428 ( 1.638)\tData  0.000 ( 1.241)\tLoss 2.3406e+00 (2.2382e+00)\tAcc@1  71.09 ( 55.15)\tAcc@5  89.84 ( 89.91)\n",
            "Epoch: [146][ 60/268]\tTime  2.553 ( 1.474)\tData  2.200 ( 1.076)\tLoss 1.9308e+00 (2.2630e+00)\tAcc@1  86.33 ( 53.94)\tAcc@5  95.31 ( 89.11)\n",
            "Epoch: [146][ 70/268]\tTime  0.427 ( 1.326)\tData  0.000 ( 0.926)\tLoss 2.0522e+00 (2.2930e+00)\tAcc@1  73.44 ( 53.38)\tAcc@5  96.48 ( 88.25)\n",
            "Epoch: [146][ 80/268]\tTime  0.416 ( 1.245)\tData  0.000 ( 0.845)\tLoss 2.2031e+00 (2.2789e+00)\tAcc@1  42.58 ( 53.46)\tAcc@5  95.70 ( 88.64)\n",
            "Epoch: [146][ 90/268]\tTime  0.417 ( 1.172)\tData  0.000 ( 0.772)\tLoss 2.4970e+00 (2.2463e+00)\tAcc@1  32.03 ( 54.88)\tAcc@5  83.59 ( 89.22)\n",
            "Epoch: [146][100/268]\tTime  0.417 ( 1.124)\tData  0.000 ( 0.724)\tLoss 1.8428e+00 (2.2346e+00)\tAcc@1  79.30 ( 55.36)\tAcc@5  96.09 ( 89.59)\n",
            "Epoch: [146][110/268]\tTime  0.420 ( 1.085)\tData  0.000 ( 0.685)\tLoss 1.9599e+00 (2.2345e+00)\tAcc@1  64.45 ( 55.04)\tAcc@5  98.05 ( 89.72)\n",
            "Epoch: [146][120/268]\tTime  1.934 ( 1.042)\tData  1.611 ( 0.643)\tLoss 2.2417e+00 (2.2386e+00)\tAcc@1  53.12 ( 54.91)\tAcc@5  92.19 ( 89.62)\n",
            "Epoch: [146][130/268]\tTime  0.421 ( 0.995)\tData  0.001 ( 0.594)\tLoss 2.3295e+00 (2.2362e+00)\tAcc@1  45.70 ( 55.13)\tAcc@5  92.58 ( 89.76)\n",
            "Epoch: [146][140/268]\tTime  0.416 ( 0.966)\tData  0.013 ( 0.566)\tLoss 1.7901e+00 (2.2324e+00)\tAcc@1  86.72 ( 55.28)\tAcc@5  97.27 ( 89.81)\n",
            "Epoch: [146][150/268]\tTime  0.437 ( 0.945)\tData  0.013 ( 0.544)\tLoss 2.1145e+00 (2.2319e+00)\tAcc@1  57.42 ( 55.03)\tAcc@5  94.53 ( 89.82)\n",
            "Epoch: [146][160/268]\tTime  0.423 ( 0.927)\tData  0.000 ( 0.527)\tLoss 2.5718e+00 (2.2294e+00)\tAcc@1  34.77 ( 55.13)\tAcc@5  81.64 ( 89.80)\n",
            "Epoch: [146][170/268]\tTime  0.434 ( 0.909)\tData  0.000 ( 0.509)\tLoss 1.9099e+00 (2.2173e+00)\tAcc@1  79.30 ( 55.79)\tAcc@5  95.70 ( 90.04)\n",
            "Epoch: [146][180/268]\tTime  2.305 ( 0.893)\tData  1.954 ( 0.492)\tLoss 2.0222e+00 (2.2408e+00)\tAcc@1  73.05 ( 55.34)\tAcc@5  94.92 ( 89.40)\n",
            "Epoch: [146][190/268]\tTime  0.416 ( 0.868)\tData  0.000 ( 0.467)\tLoss 2.5891e+00 (2.2410e+00)\tAcc@1  31.25 ( 55.17)\tAcc@5  80.08 ( 89.45)\n",
            "Epoch: [146][200/268]\tTime  0.417 ( 0.860)\tData  0.003 ( 0.459)\tLoss 2.0295e+00 (2.2320e+00)\tAcc@1  71.88 ( 55.70)\tAcc@5  95.31 ( 89.66)\n",
            "Epoch: [146][210/268]\tTime  0.417 ( 0.850)\tData  0.001 ( 0.449)\tLoss 1.5847e+00 (2.2290e+00)\tAcc@1  89.45 ( 55.74)\tAcc@5  99.61 ( 89.75)\n",
            "Epoch: [146][220/268]\tTime  0.425 ( 0.841)\tData  0.000 ( 0.440)\tLoss 2.5685e+00 (2.2327e+00)\tAcc@1  33.98 ( 55.64)\tAcc@5  81.64 ( 89.76)\n",
            "Epoch: [146][230/268]\tTime  0.417 ( 0.831)\tData  0.000 ( 0.430)\tLoss 1.8158e+00 (2.2219e+00)\tAcc@1  75.39 ( 56.31)\tAcc@5  97.27 ( 89.95)\n",
            "Epoch: [146][240/268]\tTime  1.815 ( 0.820)\tData  1.485 ( 0.419)\tLoss 1.9692e+00 (2.2160e+00)\tAcc@1  62.50 ( 56.54)\tAcc@5  94.53 ( 90.07)\n",
            "Epoch: [146][250/268]\tTime  0.416 ( 0.804)\tData  0.000 ( 0.403)\tLoss 1.6240e+00 (2.2129e+00)\tAcc@1  86.72 ( 56.59)\tAcc@5  98.44 ( 90.13)\n",
            "Epoch: [146][260/268]\tTime  0.416 ( 0.793)\tData  0.000 ( 0.393)\tLoss 1.8281e+00 (2.2060e+00)\tAcc@1  81.25 ( 57.00)\tAcc@5  98.05 ( 90.30)\n",
            "epoch: 146\n",
            "2023-03-25 03:52:11.093574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:11.093686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:11.093707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:15.005946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:15.006046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:15.006065: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:18.907883: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:18.907975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:18.907994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:22.850007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:22.850108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:22.850128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:26.739468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:26.739573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:26.739592: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:30.631894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:30.631993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:30.632014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:34.533012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:34.533100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:34.533117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:38.442697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:38.442792: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:38.442813: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:42.391717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:42.391885: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:42.391907: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:46.304056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:46.304152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:46.304173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:50.253398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:50.253497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:50.253523: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:52:54.252350: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:54.252450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:52:54.252470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [147][  0/268]\tTime 55.680 (55.680)\tData 55.336 (55.336)\tLoss 1.6338e+00 (1.6338e+00)\tAcc@1  83.20 ( 83.20)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [147][ 10/268]\tTime  0.417 ( 5.441)\tData  0.000 ( 5.045)\tLoss 1.9409e+00 (2.2280e+00)\tAcc@1  66.41 ( 53.76)\tAcc@5  96.48 ( 91.30)\n",
            "Epoch: [147][ 20/268]\tTime  0.417 ( 3.131)\tData  0.000 ( 2.734)\tLoss 2.5432e+00 (2.2065e+00)\tAcc@1  34.38 ( 54.87)\tAcc@5  79.69 ( 91.00)\n",
            "Epoch: [147][ 30/268]\tTime  0.416 ( 2.326)\tData  0.000 ( 1.929)\tLoss 2.4430e+00 (2.2471e+00)\tAcc@1  60.55 ( 54.16)\tAcc@5  87.50 ( 89.00)\n",
            "Epoch: [147][ 40/268]\tTime  0.422 ( 1.916)\tData  0.000 ( 1.517)\tLoss 2.0055e+00 (2.2228e+00)\tAcc@1  61.33 ( 55.35)\tAcc@5  96.88 ( 89.98)\n",
            "Epoch: [147][ 50/268]\tTime  0.418 ( 1.662)\tData  0.001 ( 1.263)\tLoss 2.1679e+00 (2.2206e+00)\tAcc@1  70.70 ( 56.48)\tAcc@5  92.97 ( 89.90)\n",
            "Epoch: [147][ 60/268]\tTime  2.502 ( 1.493)\tData  2.177 ( 1.094)\tLoss 1.9624e+00 (2.2267e+00)\tAcc@1  75.39 ( 56.06)\tAcc@5  95.70 ( 90.18)\n",
            "Epoch: [147][ 70/268]\tTime  0.435 ( 1.342)\tData  0.000 ( 0.942)\tLoss 1.9784e+00 (2.1959e+00)\tAcc@1  77.73 ( 58.27)\tAcc@5  96.48 ( 90.80)\n",
            "Epoch: [147][ 80/268]\tTime  0.417 ( 1.254)\tData  0.000 ( 0.854)\tLoss 2.5418e+00 (2.1931e+00)\tAcc@1  41.02 ( 58.19)\tAcc@5  83.20 ( 90.93)\n",
            "Epoch: [147][ 90/268]\tTime  0.411 ( 1.183)\tData  0.000 ( 0.784)\tLoss 2.2015e+00 (2.1898e+00)\tAcc@1  71.88 ( 58.59)\tAcc@5  92.19 ( 91.01)\n",
            "Epoch: [147][100/268]\tTime  0.417 ( 1.127)\tData  0.013 ( 0.728)\tLoss 2.3726e+00 (2.1807e+00)\tAcc@1  45.31 ( 58.86)\tAcc@5  89.84 ( 91.23)\n",
            "Epoch: [147][110/268]\tTime  0.417 ( 1.081)\tData  0.000 ( 0.681)\tLoss 1.8335e+00 (2.1792e+00)\tAcc@1  83.59 ( 58.55)\tAcc@5  95.31 ( 91.22)\n",
            "Epoch: [147][120/268]\tTime  2.190 ( 1.041)\tData  1.858 ( 0.641)\tLoss 1.8842e+00 (2.1735e+00)\tAcc@1  72.66 ( 59.13)\tAcc@5  96.88 ( 91.40)\n",
            "Epoch: [147][130/268]\tTime  0.416 ( 0.994)\tData  0.000 ( 0.593)\tLoss 1.9026e+00 (2.1711e+00)\tAcc@1  83.98 ( 59.22)\tAcc@5  96.09 ( 91.41)\n",
            "Epoch: [147][140/268]\tTime  0.427 ( 0.972)\tData  0.013 ( 0.570)\tLoss 2.0301e+00 (2.1683e+00)\tAcc@1  57.81 ( 59.53)\tAcc@5  94.92 ( 91.51)\n",
            "Epoch: [147][150/268]\tTime  0.418 ( 0.949)\tData  0.003 ( 0.548)\tLoss 2.4508e+00 (2.1681e+00)\tAcc@1  39.84 ( 59.28)\tAcc@5  82.42 ( 91.53)\n",
            "Epoch: [147][160/268]\tTime  0.416 ( 0.930)\tData  0.000 ( 0.529)\tLoss 2.1231e+00 (2.1653e+00)\tAcc@1  51.17 ( 59.22)\tAcc@5  92.58 ( 91.69)\n",
            "Epoch: [147][170/268]\tTime  0.429 ( 0.913)\tData  0.000 ( 0.513)\tLoss 2.4754e+00 (2.1652e+00)\tAcc@1  27.73 ( 59.04)\tAcc@5  85.16 ( 91.70)\n",
            "Epoch: [147][180/268]\tTime  2.526 ( 0.898)\tData  2.195 ( 0.497)\tLoss 2.3768e+00 (2.1620e+00)\tAcc@1  42.58 ( 59.14)\tAcc@5  86.72 ( 91.80)\n",
            "Epoch: [147][190/268]\tTime  0.416 ( 0.873)\tData  0.000 ( 0.472)\tLoss 2.3755e+00 (2.1666e+00)\tAcc@1  38.67 ( 58.74)\tAcc@5  85.55 ( 91.71)\n",
            "Epoch: [147][200/268]\tTime  0.422 ( 0.858)\tData  0.000 ( 0.457)\tLoss 1.8679e+00 (2.1655e+00)\tAcc@1  61.33 ( 58.78)\tAcc@5  96.88 ( 91.72)\n",
            "Epoch: [147][210/268]\tTime  0.419 ( 0.847)\tData  0.000 ( 0.445)\tLoss 2.2642e+00 (2.1615e+00)\tAcc@1  71.09 ( 59.01)\tAcc@5  90.62 ( 91.82)\n",
            "Epoch: [147][220/268]\tTime  0.410 ( 0.836)\tData  0.000 ( 0.435)\tLoss 2.1619e+00 (2.1647e+00)\tAcc@1  52.73 ( 58.59)\tAcc@5  92.58 ( 91.75)\n",
            "Epoch: [147][230/268]\tTime  0.416 ( 0.827)\tData  0.000 ( 0.426)\tLoss 2.1295e+00 (2.1651e+00)\tAcc@1  56.25 ( 58.66)\tAcc@5  92.58 ( 91.72)\n",
            "Epoch: [147][240/268]\tTime  1.999 ( 0.817)\tData  1.681 ( 0.416)\tLoss 2.1826e+00 (2.1672e+00)\tAcc@1  55.08 ( 58.49)\tAcc@5  92.19 ( 91.68)\n",
            "Epoch: [147][250/268]\tTime  0.416 ( 0.801)\tData  0.000 ( 0.400)\tLoss 2.2583e+00 (2.1680e+00)\tAcc@1  61.33 ( 58.42)\tAcc@5  93.75 ( 91.70)\n",
            "Epoch: [147][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.389)\tLoss 2.2256e+00 (2.1704e+00)\tAcc@1  75.00 ( 58.37)\tAcc@5  91.80 ( 91.65)\n",
            "epoch: 147\n",
            "2023-03-25 03:55:41.833492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:41.833593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:41.833613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:55:45.773442: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:45.773549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:45.773570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:55:49.674771: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:49.674889: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:49.674912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:55:53.573259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:53.573366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:53.573386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:55:57.480816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:57.480922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:55:57.480941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:01.384787: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:01.384882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:01.384901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:05.284169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:05.284266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:05.284284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:09.193307: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:09.193403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:09.193421: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:13.095865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:13.095955: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:13.095973: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:17.021178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:17.021316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:17.021336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:20.921355: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:20.921455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:20.921473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:56:24.826794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:24.826891: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:56:24.826909: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [148][  0/268]\tTime 55.158 (55.158)\tData 54.813 (54.813)\tLoss 2.0010e+00 (2.0010e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.70 ( 95.70)\n",
            "Epoch: [148][ 10/268]\tTime  0.429 ( 5.399)\tData  0.000 ( 4.994)\tLoss 2.4361e+00 (2.1935e+00)\tAcc@1  33.20 ( 57.35)\tAcc@5  85.55 ( 92.05)\n",
            "Epoch: [148][ 20/268]\tTime  0.416 ( 3.120)\tData  0.000 ( 2.718)\tLoss 3.1790e+00 (2.2014e+00)\tAcc@1   4.69 ( 57.46)\tAcc@5  62.89 ( 91.80)\n",
            "Epoch: [148][ 30/268]\tTime  0.416 ( 2.307)\tData  0.000 ( 1.906)\tLoss 2.0489e+00 (2.1817e+00)\tAcc@1  74.22 ( 57.90)\tAcc@5  95.70 ( 92.16)\n",
            "Epoch: [148][ 40/268]\tTime  0.417 ( 1.892)\tData  0.000 ( 1.492)\tLoss 2.0515e+00 (2.1429e+00)\tAcc@1  67.58 ( 59.80)\tAcc@5  96.09 ( 92.78)\n",
            "Epoch: [148][ 50/268]\tTime  0.930 ( 1.640)\tData  0.592 ( 1.241)\tLoss 2.3350e+00 (2.1252e+00)\tAcc@1  49.22 ( 60.61)\tAcc@5  89.06 ( 92.82)\n",
            "Epoch: [148][ 60/268]\tTime  2.238 ( 1.470)\tData  1.913 ( 1.071)\tLoss 2.4966e+00 (2.1195e+00)\tAcc@1  37.50 ( 60.46)\tAcc@5  84.77 ( 92.73)\n",
            "Epoch: [148][ 70/268]\tTime  0.423 ( 1.322)\tData  0.000 ( 0.924)\tLoss 2.1426e+00 (2.1145e+00)\tAcc@1  43.36 ( 61.03)\tAcc@5  94.53 ( 92.93)\n",
            "Epoch: [148][ 80/268]\tTime  0.425 ( 1.239)\tData  0.000 ( 0.841)\tLoss 1.9368e+00 (2.1310e+00)\tAcc@1  76.95 ( 60.61)\tAcc@5  98.05 ( 92.60)\n",
            "Epoch: [148][ 90/268]\tTime  0.416 ( 1.169)\tData  0.013 ( 0.773)\tLoss 1.9526e+00 (2.1329e+00)\tAcc@1  70.31 ( 60.68)\tAcc@5  97.66 ( 92.53)\n",
            "Epoch: [148][100/268]\tTime  0.417 ( 1.111)\tData  0.000 ( 0.715)\tLoss 2.4963e+00 (2.1553e+00)\tAcc@1  38.67 ( 59.54)\tAcc@5  85.55 ( 91.78)\n",
            "Epoch: [148][110/268]\tTime  1.413 ( 1.066)\tData  1.087 ( 0.671)\tLoss 2.0475e+00 (2.1527e+00)\tAcc@1  80.47 ( 59.95)\tAcc@5  92.58 ( 91.75)\n",
            "Epoch: [148][120/268]\tTime  1.456 ( 1.021)\tData  1.131 ( 0.626)\tLoss 1.6474e+00 (2.1510e+00)\tAcc@1  89.84 ( 59.88)\tAcc@5  99.22 ( 91.76)\n",
            "Epoch: [148][130/268]\tTime  0.418 ( 0.988)\tData  0.000 ( 0.592)\tLoss 2.6346e+00 (2.1498e+00)\tAcc@1  50.00 ( 60.18)\tAcc@5  84.38 ( 91.84)\n",
            "Epoch: [148][140/268]\tTime  0.422 ( 0.962)\tData  0.000 ( 0.566)\tLoss 1.8288e+00 (2.1517e+00)\tAcc@1  87.89 ( 59.96)\tAcc@5  96.09 ( 91.67)\n",
            "Epoch: [148][150/268]\tTime  0.416 ( 0.945)\tData  0.000 ( 0.550)\tLoss 2.0468e+00 (2.1554e+00)\tAcc@1  76.56 ( 59.85)\tAcc@5  94.14 ( 91.66)\n",
            "Epoch: [148][160/268]\tTime  0.409 ( 0.929)\tData  0.000 ( 0.533)\tLoss 2.1471e+00 (2.1589e+00)\tAcc@1  51.95 ( 59.52)\tAcc@5  94.14 ( 91.62)\n",
            "Epoch: [148][170/268]\tTime  2.339 ( 0.911)\tData  1.987 ( 0.514)\tLoss 2.5979e+00 (2.1626e+00)\tAcc@1  37.11 ( 59.32)\tAcc@5  80.47 ( 91.57)\n",
            "Epoch: [148][180/268]\tTime  0.431 ( 0.884)\tData  0.007 ( 0.487)\tLoss 1.9508e+00 (2.1560e+00)\tAcc@1  66.80 ( 59.66)\tAcc@5  96.48 ( 91.70)\n",
            "Epoch: [148][190/268]\tTime  0.440 ( 0.870)\tData  0.000 ( 0.473)\tLoss 2.5317e+00 (2.1554e+00)\tAcc@1  35.16 ( 59.70)\tAcc@5  82.03 ( 91.69)\n",
            "Epoch: [148][200/268]\tTime  0.423 ( 0.857)\tData  0.000 ( 0.460)\tLoss 2.1587e+00 (2.1595e+00)\tAcc@1  53.91 ( 59.33)\tAcc@5  93.36 ( 91.67)\n",
            "Epoch: [148][210/268]\tTime  0.409 ( 0.845)\tData  0.000 ( 0.447)\tLoss 1.7447e+00 (2.1566e+00)\tAcc@1  78.52 ( 59.39)\tAcc@5  98.44 ( 91.74)\n",
            "Epoch: [148][220/268]\tTime  0.407 ( 0.834)\tData  0.000 ( 0.437)\tLoss 1.8845e+00 (2.1547e+00)\tAcc@1  75.78 ( 59.36)\tAcc@5  98.05 ( 91.81)\n",
            "Epoch: [148][230/268]\tTime  2.160 ( 0.824)\tData  1.821 ( 0.426)\tLoss 2.0193e+00 (2.1543e+00)\tAcc@1  60.55 ( 59.28)\tAcc@5  95.70 ( 91.84)\n",
            "Epoch: [148][240/268]\tTime  0.438 ( 0.808)\tData  0.000 ( 0.409)\tLoss 2.1649e+00 (2.1494e+00)\tAcc@1  59.77 ( 59.77)\tAcc@5  92.97 ( 91.95)\n",
            "Epoch: [148][250/268]\tTime  0.416 ( 0.800)\tData  0.000 ( 0.401)\tLoss 2.2734e+00 (2.1556e+00)\tAcc@1  73.05 ( 59.55)\tAcc@5  91.41 ( 91.85)\n",
            "Epoch: [148][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.390)\tLoss 2.0941e+00 (2.1550e+00)\tAcc@1  63.67 ( 59.63)\tAcc@5  94.14 ( 91.86)\n",
            "epoch: 148\n",
            "2023-03-25 03:59:12.433969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:12.434116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:12.434166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:16.335288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:16.335382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:16.335403: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:20.228340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:20.228439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:20.228458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:24.211978: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:24.212076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:24.212095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:28.116353: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:28.116453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:28.116472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:32.007893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:32.007991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:32.008011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:35.986193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:35.986284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:35.986300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:39.862504: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:39.862601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:39.862619: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:43.733635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:43.733746: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:43.733764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:47.665561: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:47.665674: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:47.665692: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:51.572411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:51.572518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:51.572536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 03:59:55.459691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:55.459797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 03:59:55.459815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [149][  0/268]\tTime 54.492 (54.492)\tData 54.155 (54.155)\tLoss 1.6166e+00 (1.6166e+00)\tAcc@1  92.19 ( 92.19)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [149][ 10/268]\tTime  0.412 ( 5.440)\tData  0.000 ( 5.039)\tLoss 2.4676e+00 (2.2067e+00)\tAcc@1  40.62 ( 54.40)\tAcc@5  82.81 ( 90.48)\n",
            "Epoch: [149][ 20/268]\tTime  0.424 ( 3.141)\tData  0.000 ( 2.742)\tLoss 2.2479e+00 (2.1065e+00)\tAcc@1  50.00 ( 61.25)\tAcc@5  94.14 ( 92.43)\n",
            "Epoch: [149][ 30/268]\tTime  0.416 ( 2.319)\tData  0.000 ( 1.924)\tLoss 2.1271e+00 (2.1593e+00)\tAcc@1  54.69 ( 57.60)\tAcc@5  94.92 ( 91.42)\n",
            "Epoch: [149][ 40/268]\tTime  0.424 ( 1.890)\tData  0.000 ( 1.497)\tLoss 2.0345e+00 (2.1687e+00)\tAcc@1  62.89 ( 57.68)\tAcc@5  98.44 ( 91.44)\n",
            "Epoch: [149][ 50/268]\tTime  0.417 ( 1.649)\tData  0.000 ( 1.256)\tLoss 1.9322e+00 (2.2014e+00)\tAcc@1  71.48 ( 55.50)\tAcc@5  94.92 ( 90.70)\n",
            "Epoch: [149][ 60/268]\tTime  1.677 ( 1.468)\tData  1.338 ( 1.074)\tLoss 2.0585e+00 (2.1711e+00)\tAcc@1  57.42 ( 56.64)\tAcc@5  94.53 ( 91.26)\n",
            "Epoch: [149][ 70/268]\tTime  0.413 ( 1.326)\tData  0.000 ( 0.931)\tLoss 1.7514e+00 (2.1766e+00)\tAcc@1  75.39 ( 56.76)\tAcc@5  97.66 ( 90.99)\n",
            "Epoch: [149][ 80/268]\tTime  0.419 ( 1.238)\tData  0.000 ( 0.841)\tLoss 2.0044e+00 (2.1938e+00)\tAcc@1  64.84 ( 55.73)\tAcc@5  96.88 ( 90.58)\n",
            "Epoch: [149][ 90/268]\tTime  0.416 ( 1.170)\tData  0.000 ( 0.773)\tLoss 2.2409e+00 (2.1915e+00)\tAcc@1  47.66 ( 55.85)\tAcc@5  93.75 ( 90.59)\n",
            "Epoch: [149][100/268]\tTime  0.427 ( 1.116)\tData  0.000 ( 0.719)\tLoss 2.1946e+00 (2.1924e+00)\tAcc@1  72.27 ( 56.19)\tAcc@5  91.41 ( 90.35)\n",
            "Epoch: [149][110/268]\tTime  0.424 ( 1.070)\tData  0.000 ( 0.674)\tLoss 2.2676e+00 (2.1840e+00)\tAcc@1  50.78 ( 56.71)\tAcc@5  93.36 ( 90.64)\n",
            "Epoch: [149][120/268]\tTime  2.346 ( 1.033)\tData  2.007 ( 0.636)\tLoss 1.9223e+00 (2.1842e+00)\tAcc@1  87.11 ( 56.81)\tAcc@5  96.48 ( 90.78)\n",
            "Epoch: [149][130/268]\tTime  0.421 ( 0.990)\tData  0.000 ( 0.593)\tLoss 2.0030e+00 (2.1967e+00)\tAcc@1  61.33 ( 56.11)\tAcc@5  96.09 ( 90.55)\n",
            "Epoch: [149][140/268]\tTime  0.423 ( 0.963)\tData  0.000 ( 0.567)\tLoss 2.0593e+00 (2.2039e+00)\tAcc@1  60.55 ( 55.98)\tAcc@5  94.53 ( 90.38)\n",
            "Epoch: [149][150/268]\tTime  0.445 ( 0.938)\tData  0.000 ( 0.543)\tLoss 2.5420e+00 (2.2080e+00)\tAcc@1  33.20 ( 55.64)\tAcc@5  83.20 ( 90.26)\n",
            "Epoch: [149][160/268]\tTime  0.837 ( 0.921)\tData  0.504 ( 0.526)\tLoss 2.1043e+00 (2.2030e+00)\tAcc@1  57.42 ( 55.78)\tAcc@5  92.58 ( 90.28)\n",
            "Epoch: [149][170/268]\tTime  0.432 ( 0.902)\tData  0.000 ( 0.507)\tLoss 1.9138e+00 (2.1913e+00)\tAcc@1  79.30 ( 56.57)\tAcc@5  95.70 ( 90.46)\n",
            "Epoch: [149][180/268]\tTime  2.027 ( 0.884)\tData  1.698 ( 0.489)\tLoss 2.1873e+00 (2.1910e+00)\tAcc@1  56.25 ( 56.46)\tAcc@5  90.62 ( 90.47)\n",
            "Epoch: [149][190/268]\tTime  0.416 ( 0.865)\tData  0.021 ( 0.470)\tLoss 2.2823e+00 (2.1886e+00)\tAcc@1  76.17 ( 56.88)\tAcc@5  92.97 ( 90.58)\n",
            "Epoch: [149][200/268]\tTime  0.417 ( 0.850)\tData  0.000 ( 0.455)\tLoss 1.6155e+00 (2.1756e+00)\tAcc@1  77.73 ( 57.36)\tAcc@5  98.44 ( 90.80)\n",
            "Epoch: [149][210/268]\tTime  0.427 ( 0.839)\tData  0.000 ( 0.444)\tLoss 2.1481e+00 (2.1681e+00)\tAcc@1  53.52 ( 57.71)\tAcc@5  92.97 ( 90.98)\n",
            "Epoch: [149][220/268]\tTime  0.426 ( 0.828)\tData  0.000 ( 0.434)\tLoss 2.2712e+00 (2.1666e+00)\tAcc@1  70.70 ( 57.91)\tAcc@5  91.02 ( 91.04)\n",
            "Epoch: [149][230/268]\tTime  0.409 ( 0.818)\tData  0.000 ( 0.424)\tLoss 2.1426e+00 (2.1603e+00)\tAcc@1  53.12 ( 58.24)\tAcc@5  95.31 ( 91.15)\n",
            "Epoch: [149][240/268]\tTime  1.936 ( 0.808)\tData  1.592 ( 0.414)\tLoss 2.4707e+00 (2.1602e+00)\tAcc@1  35.55 ( 58.30)\tAcc@5  86.72 ( 91.22)\n",
            "Epoch: [149][250/268]\tTime  0.418 ( 0.794)\tData  0.000 ( 0.399)\tLoss 1.9893e+00 (2.1650e+00)\tAcc@1  66.41 ( 58.09)\tAcc@5  96.09 ( 91.15)\n",
            "Epoch: [149][260/268]\tTime  0.415 ( 0.786)\tData  0.000 ( 0.391)\tLoss 3.5182e+00 (2.1624e+00)\tAcc@1   5.86 ( 58.44)\tAcc@5  65.62 ( 91.19)\n",
            "epoch: 149\n",
            "2023-03-25 04:02:42.088964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:42.089062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:42.089081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:02:46.006951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:46.007051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:46.007072: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:02:49.952742: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:49.952842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:49.952862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:02:53.824650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:53.824764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:53.824782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:02:57.706727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:57.706827: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:02:57.706845: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:01.660227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:01.660326: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:01.660347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:05.545774: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:05.545868: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:05.545886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:09.417763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:09.417865: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:09.417883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:13.372349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:13.372452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:13.372473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:17.337837: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:17.337928: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:17.337946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:21.219136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:21.219233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:21.219252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:03:25.141996: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:25.142093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:03:25.142111: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [150][  0/268]\tTime 55.358 (55.358)\tData 55.016 (55.016)\tLoss 4.2800e+00 (4.2800e+00)\tAcc@1   0.00 (  0.00)\tAcc@5  19.53 ( 19.53)\n",
            "Epoch: [150][ 10/268]\tTime  0.421 ( 5.415)\tData  0.000 ( 5.013)\tLoss 2.2066e+00 (2.3198e+00)\tAcc@1  73.44 ( 54.87)\tAcc@5  91.80 ( 85.40)\n",
            "Epoch: [150][ 20/268]\tTime  0.422 ( 3.079)\tData  0.000 ( 2.678)\tLoss 1.7011e+00 (2.2248e+00)\tAcc@1  78.52 ( 56.77)\tAcc@5  98.44 ( 88.73)\n",
            "Epoch: [150][ 30/268]\tTime  0.417 ( 2.289)\tData  0.001 ( 1.891)\tLoss 2.2062e+00 (2.1977e+00)\tAcc@1  44.92 ( 56.67)\tAcc@5  94.14 ( 90.10)\n",
            "Epoch: [150][ 40/268]\tTime  0.437 ( 1.884)\tData  0.000 ( 1.488)\tLoss 2.6182e+00 (2.2371e+00)\tAcc@1  20.70 ( 53.63)\tAcc@5  80.86 ( 89.65)\n",
            "Epoch: [150][ 50/268]\tTime  0.591 ( 1.626)\tData  0.273 ( 1.231)\tLoss 2.2103e+00 (2.2106e+00)\tAcc@1  58.98 ( 55.53)\tAcc@5  92.97 ( 90.20)\n",
            "Epoch: [150][ 60/268]\tTime  1.817 ( 1.462)\tData  1.499 ( 1.066)\tLoss 2.2407e+00 (2.2104e+00)\tAcc@1  51.17 ( 54.82)\tAcc@5  92.58 ( 90.61)\n",
            "Epoch: [150][ 70/268]\tTime  0.411 ( 1.320)\tData  0.000 ( 0.926)\tLoss 2.1417e+00 (2.2100e+00)\tAcc@1  55.86 ( 54.89)\tAcc@5  94.14 ( 90.77)\n",
            "Epoch: [150][ 80/268]\tTime  0.410 ( 1.236)\tData  0.000 ( 0.842)\tLoss 2.0021e+00 (2.2225e+00)\tAcc@1  66.80 ( 54.64)\tAcc@5  96.88 ( 90.42)\n",
            "Epoch: [150][ 90/268]\tTime  0.409 ( 1.166)\tData  0.000 ( 0.771)\tLoss 2.0891e+00 (2.2309e+00)\tAcc@1  56.25 ( 54.27)\tAcc@5  96.09 ( 90.26)\n",
            "Epoch: [150][100/268]\tTime  0.416 ( 1.111)\tData  0.001 ( 0.715)\tLoss 2.2839e+00 (2.2306e+00)\tAcc@1  46.09 ( 54.23)\tAcc@5  89.84 ( 90.18)\n",
            "Epoch: [150][110/268]\tTime  0.417 ( 1.072)\tData  0.000 ( 0.676)\tLoss 2.4898e+00 (2.2413e+00)\tAcc@1  35.16 ( 53.94)\tAcc@5  84.38 ( 90.04)\n",
            "Epoch: [150][120/268]\tTime  1.774 ( 1.030)\tData  1.456 ( 0.633)\tLoss 1.8983e+00 (2.2200e+00)\tAcc@1  76.17 ( 55.11)\tAcc@5  94.14 ( 90.37)\n",
            "Epoch: [150][130/268]\tTime  0.414 ( 0.986)\tData  0.000 ( 0.590)\tLoss 2.5248e+00 (2.2187e+00)\tAcc@1  35.94 ( 54.88)\tAcc@5  84.38 ( 90.46)\n",
            "Epoch: [150][140/268]\tTime  0.410 ( 0.958)\tData  0.000 ( 0.564)\tLoss 1.9570e+00 (2.1995e+00)\tAcc@1  72.27 ( 56.06)\tAcc@5  96.88 ( 90.81)\n",
            "Epoch: [150][150/268]\tTime  0.416 ( 0.937)\tData  0.000 ( 0.543)\tLoss 1.6747e+00 (2.1911e+00)\tAcc@1  83.20 ( 56.64)\tAcc@5  97.66 ( 90.95)\n",
            "Epoch: [150][160/268]\tTime  0.415 ( 0.916)\tData  0.070 ( 0.523)\tLoss 2.1702e+00 (2.1832e+00)\tAcc@1  55.47 ( 57.10)\tAcc@5  94.92 ( 91.19)\n",
            "Epoch: [150][170/268]\tTime  0.431 ( 0.899)\tData  0.009 ( 0.505)\tLoss 2.3026e+00 (2.1872e+00)\tAcc@1  35.16 ( 56.92)\tAcc@5  89.45 ( 91.07)\n",
            "Epoch: [150][180/268]\tTime  1.647 ( 0.883)\tData  1.320 ( 0.490)\tLoss 2.2824e+00 (2.1777e+00)\tAcc@1  50.00 ( 57.46)\tAcc@5  91.80 ( 91.21)\n",
            "Epoch: [150][190/268]\tTime  0.417 ( 0.864)\tData  0.004 ( 0.470)\tLoss 1.7354e+00 (2.1697e+00)\tAcc@1  87.89 ( 58.08)\tAcc@5  97.27 ( 91.38)\n",
            "Epoch: [150][200/268]\tTime  0.421 ( 0.854)\tData  0.000 ( 0.462)\tLoss 1.6224e+00 (2.1632e+00)\tAcc@1  88.28 ( 58.53)\tAcc@5  99.22 ( 91.53)\n",
            "Epoch: [150][210/268]\tTime  0.417 ( 0.842)\tData  0.000 ( 0.451)\tLoss 2.3192e+00 (2.1620e+00)\tAcc@1  52.34 ( 58.40)\tAcc@5  92.97 ( 91.57)\n",
            "Epoch: [150][220/268]\tTime  0.949 ( 0.828)\tData  0.603 ( 0.437)\tLoss 1.8632e+00 (2.1650e+00)\tAcc@1  71.88 ( 58.09)\tAcc@5  97.66 ( 91.51)\n",
            "Epoch: [150][230/268]\tTime  0.416 ( 0.816)\tData  0.015 ( 0.425)\tLoss 2.5247e+00 (2.1670e+00)\tAcc@1  36.72 ( 57.95)\tAcc@5  83.20 ( 91.52)\n",
            "Epoch: [150][240/268]\tTime  0.428 ( 0.806)\tData  0.056 ( 0.415)\tLoss 1.7293e+00 (2.1582e+00)\tAcc@1  87.11 ( 58.36)\tAcc@5  96.88 ( 91.63)\n",
            "Epoch: [150][250/268]\tTime  0.417 ( 0.799)\tData  0.000 ( 0.409)\tLoss 2.2816e+00 (2.1567e+00)\tAcc@1  46.48 ( 58.34)\tAcc@5  91.02 ( 91.68)\n",
            "Epoch: [150][260/268]\tTime  0.416 ( 0.787)\tData  0.000 ( 0.397)\tLoss 1.8069e+00 (2.1548e+00)\tAcc@1  87.50 ( 58.44)\tAcc@5  97.66 ( 91.74)\n",
            "epoch: 150\n",
            "2023-03-25 04:06:12.263033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:12.263141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:12.263161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:16.215175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:16.215280: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:16.215299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:20.194153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:20.194255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:20.194275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:24.168100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:24.168200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:24.168220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:28.066506: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:28.066609: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:28.066628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:31.962017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:31.962117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:31.962137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:35.870778: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:35.870882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:35.870901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:39.822177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:39.822271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:39.822289: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:43.834006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:43.834104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:43.834125: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:47.783148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:47.783245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:47.783264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:51.729565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:51.729684: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:51.729705: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:06:55.651455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:55.651564: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:06:55.651583: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [151][  0/268]\tTime 55.601 (55.601)\tData 55.253 (55.253)\tLoss 2.1069e+00 (2.1069e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  94.92 ( 94.92)\n",
            "Epoch: [151][ 10/268]\tTime  0.413 ( 5.436)\tData  0.000 ( 5.033)\tLoss 1.8207e+00 (2.1078e+00)\tAcc@1  88.28 ( 61.51)\tAcc@5  97.27 ( 93.08)\n",
            "Epoch: [151][ 20/268]\tTime  0.453 ( 3.172)\tData  0.013 ( 2.769)\tLoss 1.9096e+00 (2.1805e+00)\tAcc@1  75.39 ( 55.54)\tAcc@5  98.44 ( 91.70)\n",
            "Epoch: [151][ 30/268]\tTime  0.436 ( 2.328)\tData  0.000 ( 1.929)\tLoss 2.5618e+00 (2.2170e+00)\tAcc@1  30.47 ( 53.79)\tAcc@5  83.20 ( 90.78)\n",
            "Epoch: [151][ 40/268]\tTime  0.411 ( 1.899)\tData  0.000 ( 1.500)\tLoss 2.5308e+00 (2.2272e+00)\tAcc@1  32.81 ( 52.96)\tAcc@5  82.81 ( 90.47)\n",
            "Epoch: [151][ 50/268]\tTime  0.422 ( 1.661)\tData  0.001 ( 1.261)\tLoss 2.2917e+00 (2.1903e+00)\tAcc@1  50.00 ( 56.05)\tAcc@5  91.41 ( 91.07)\n",
            "Epoch: [151][ 60/268]\tTime  1.624 ( 1.477)\tData  1.293 ( 1.077)\tLoss 2.3159e+00 (2.1862e+00)\tAcc@1  70.70 ( 56.41)\tAcc@5  89.06 ( 91.02)\n",
            "Epoch: [151][ 70/268]\tTime  0.415 ( 1.337)\tData  0.000 ( 0.937)\tLoss 1.6317e+00 (2.1567e+00)\tAcc@1  81.64 ( 58.14)\tAcc@5  98.83 ( 91.49)\n",
            "Epoch: [151][ 80/268]\tTime  0.417 ( 1.249)\tData  0.000 ( 0.850)\tLoss 2.0363e+00 (2.1487e+00)\tAcc@1  60.16 ( 58.75)\tAcc@5  94.14 ( 91.56)\n",
            "Epoch: [151][ 90/268]\tTime  0.431 ( 1.183)\tData  0.000 ( 0.784)\tLoss 1.7299e+00 (2.1509e+00)\tAcc@1  87.11 ( 58.82)\tAcc@5  98.83 ( 91.64)\n",
            "Epoch: [151][100/268]\tTime  0.417 ( 1.129)\tData  0.002 ( 0.730)\tLoss 2.0808e+00 (2.1331e+00)\tAcc@1  76.17 ( 60.28)\tAcc@5  92.19 ( 91.99)\n",
            "Epoch: [151][110/268]\tTime  0.765 ( 1.083)\tData  0.443 ( 0.686)\tLoss 2.0228e+00 (2.1341e+00)\tAcc@1  62.50 ( 60.12)\tAcc@5  96.09 ( 92.10)\n",
            "Epoch: [151][120/268]\tTime  2.086 ( 1.042)\tData  1.767 ( 0.645)\tLoss 2.3446e+00 (2.1355e+00)\tAcc@1  39.06 ( 60.04)\tAcc@5  88.28 ( 92.06)\n",
            "Epoch: [151][130/268]\tTime  0.416 ( 0.997)\tData  0.000 ( 0.599)\tLoss 2.2735e+00 (2.1355e+00)\tAcc@1  67.58 ( 59.87)\tAcc@5  91.41 ( 92.12)\n",
            "Epoch: [151][140/268]\tTime  0.418 ( 0.972)\tData  0.000 ( 0.575)\tLoss 2.2285e+00 (2.1395e+00)\tAcc@1  43.75 ( 59.39)\tAcc@5  93.75 ( 92.04)\n",
            "Epoch: [151][150/268]\tTime  0.432 ( 0.950)\tData  0.000 ( 0.554)\tLoss 2.0718e+00 (2.1288e+00)\tAcc@1  66.80 ( 60.04)\tAcc@5  96.09 ( 92.24)\n",
            "Epoch: [151][160/268]\tTime  0.416 ( 0.931)\tData  0.000 ( 0.535)\tLoss 2.4127e+00 (2.1286e+00)\tAcc@1  37.11 ( 59.84)\tAcc@5  83.98 ( 92.27)\n",
            "Epoch: [151][170/268]\tTime  1.775 ( 0.912)\tData  1.457 ( 0.516)\tLoss 2.0327e+00 (2.1222e+00)\tAcc@1  58.20 ( 60.26)\tAcc@5  96.48 ( 92.42)\n",
            "Epoch: [151][180/268]\tTime  0.926 ( 0.887)\tData  0.584 ( 0.491)\tLoss 2.4835e+00 (2.1274e+00)\tAcc@1  36.72 ( 60.00)\tAcc@5  83.20 ( 92.33)\n",
            "Epoch: [151][190/268]\tTime  0.410 ( 0.868)\tData  0.000 ( 0.472)\tLoss 1.8548e+00 (2.1298e+00)\tAcc@1  83.98 ( 59.86)\tAcc@5  96.48 ( 92.22)\n",
            "Epoch: [151][200/268]\tTime  0.431 ( 0.854)\tData  0.000 ( 0.458)\tLoss 2.5130e+00 (2.1290e+00)\tAcc@1  32.42 ( 59.90)\tAcc@5  80.08 ( 92.19)\n",
            "Epoch: [151][210/268]\tTime  0.423 ( 0.845)\tData  0.000 ( 0.450)\tLoss 2.5401e+00 (2.1374e+00)\tAcc@1  35.55 ( 59.61)\tAcc@5  84.77 ( 91.98)\n",
            "Epoch: [151][220/268]\tTime  0.511 ( 0.832)\tData  0.193 ( 0.437)\tLoss 2.1431e+00 (2.1336e+00)\tAcc@1  58.20 ( 59.86)\tAcc@5  94.53 ( 92.10)\n",
            "Epoch: [151][230/268]\tTime  0.454 ( 0.821)\tData  0.114 ( 0.427)\tLoss 2.0383e+00 (2.1387e+00)\tAcc@1  65.23 ( 59.45)\tAcc@5  96.09 ( 91.97)\n",
            "Epoch: [151][240/268]\tTime  1.200 ( 0.812)\tData  0.864 ( 0.417)\tLoss 2.0231e+00 (2.1404e+00)\tAcc@1  55.47 ( 59.22)\tAcc@5  95.70 ( 91.93)\n",
            "Epoch: [151][250/268]\tTime  0.416 ( 0.800)\tData  0.000 ( 0.406)\tLoss 1.9282e+00 (2.1336e+00)\tAcc@1  70.70 ( 59.64)\tAcc@5  97.66 ( 92.07)\n",
            "Epoch: [151][260/268]\tTime  0.415 ( 0.790)\tData  0.000 ( 0.397)\tLoss 2.0154e+00 (2.1338e+00)\tAcc@1  79.69 ( 59.58)\tAcc@5  94.53 ( 92.10)\n",
            "epoch: 151\n",
            "2023-03-25 04:09:43.120860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:43.120984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:43.121002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:09:47.089964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:47.090059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:47.090080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:09:51.005526: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:51.005623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:51.005643: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:09:54.890447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:54.890557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:54.890576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:09:58.803167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:58.803261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:09:58.803280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:02.723501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:02.723599: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:02.723617: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:06.618859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:06.618963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:06.618982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:10.529654: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:10.529767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:10.529787: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:14.469397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:14.469507: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:14.469528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:18.363828: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:18.363929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:18.363947: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:22.257213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:22.257315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:22.257332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:10:26.171435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:26.171533: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:10:26.171551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [152][  0/268]\tTime 56.269 (56.269)\tData 55.921 (55.921)\tLoss 2.5565e+00 (2.5565e+00)\tAcc@1  35.55 ( 35.55)\tAcc@5  79.30 ( 79.30)\n",
            "Epoch: [152][ 10/268]\tTime  0.440 ( 5.502)\tData  0.012 ( 5.094)\tLoss 2.0272e+00 (2.1187e+00)\tAcc@1  60.55 ( 58.27)\tAcc@5  94.92 ( 93.54)\n",
            "Epoch: [152][ 20/268]\tTime  0.421 ( 3.141)\tData  0.001 ( 2.738)\tLoss 2.1483e+00 (2.2210e+00)\tAcc@1  60.94 ( 54.20)\tAcc@5  94.53 ( 91.33)\n",
            "Epoch: [152][ 30/268]\tTime  0.416 ( 2.305)\tData  0.000 ( 1.906)\tLoss 1.6685e+00 (2.1869e+00)\tAcc@1  83.59 ( 56.26)\tAcc@5  98.83 ( 91.62)\n",
            "Epoch: [152][ 40/268]\tTime  0.419 ( 1.896)\tData  0.000 ( 1.499)\tLoss 2.4414e+00 (2.1700e+00)\tAcc@1  58.20 ( 57.42)\tAcc@5  90.23 ( 91.92)\n",
            "Epoch: [152][ 50/268]\tTime  0.425 ( 1.643)\tData  0.000 ( 1.248)\tLoss 2.3714e+00 (2.1769e+00)\tAcc@1  39.06 ( 57.12)\tAcc@5  87.50 ( 92.10)\n",
            "Epoch: [152][ 60/268]\tTime  1.253 ( 1.457)\tData  0.927 ( 1.061)\tLoss 2.4786e+00 (2.1778e+00)\tAcc@1  38.28 ( 57.49)\tAcc@5  86.72 ( 92.05)\n",
            "Epoch: [152][ 70/268]\tTime  0.407 ( 1.336)\tData  0.000 ( 0.938)\tLoss 2.5060e+00 (2.1739e+00)\tAcc@1  35.55 ( 57.70)\tAcc@5  84.77 ( 92.10)\n",
            "Epoch: [152][ 80/268]\tTime  0.417 ( 1.247)\tData  0.009 ( 0.849)\tLoss 1.8254e+00 (2.1665e+00)\tAcc@1  82.81 ( 57.79)\tAcc@5  95.70 ( 92.00)\n",
            "Epoch: [152][ 90/268]\tTime  0.435 ( 1.176)\tData  0.000 ( 0.778)\tLoss 1.5629e+00 (2.1545e+00)\tAcc@1  92.19 ( 58.59)\tAcc@5  97.27 ( 92.15)\n",
            "Epoch: [152][100/268]\tTime  0.416 ( 1.119)\tData  0.001 ( 0.721)\tLoss 2.5538e+00 (2.1644e+00)\tAcc@1  32.81 ( 58.03)\tAcc@5  83.20 ( 92.06)\n",
            "Epoch: [152][110/268]\tTime  0.423 ( 1.076)\tData  0.001 ( 0.678)\tLoss 1.9321e+00 (2.1722e+00)\tAcc@1  73.05 ( 57.64)\tAcc@5  96.48 ( 92.04)\n",
            "Epoch: [152][120/268]\tTime  0.405 ( 1.022)\tData  0.000 ( 0.623)\tLoss 1.7441e+00 (2.1844e+00)\tAcc@1  81.25 ( 57.02)\tAcc@5  96.88 ( 91.68)\n",
            "Epoch: [152][130/268]\tTime  0.410 ( 0.993)\tData  0.000 ( 0.593)\tLoss 1.5234e+00 (2.1710e+00)\tAcc@1  94.53 ( 57.85)\tAcc@5  99.61 ( 91.86)\n",
            "Epoch: [152][140/268]\tTime  0.416 ( 0.966)\tData  0.000 ( 0.566)\tLoss 2.6141e+00 (2.1706e+00)\tAcc@1  37.50 ( 57.88)\tAcc@5  80.86 ( 91.81)\n",
            "Epoch: [152][150/268]\tTime  0.409 ( 0.946)\tData  0.000 ( 0.546)\tLoss 1.8921e+00 (2.1554e+00)\tAcc@1  69.92 ( 58.56)\tAcc@5  98.44 ( 92.07)\n",
            "Epoch: [152][160/268]\tTime  0.420 ( 0.925)\tData  0.001 ( 0.525)\tLoss 2.4620e+00 (2.1599e+00)\tAcc@1  40.23 ( 58.36)\tAcc@5  83.98 ( 91.87)\n",
            "Epoch: [152][170/268]\tTime  0.414 ( 0.914)\tData  0.000 ( 0.513)\tLoss 2.0806e+00 (2.1566e+00)\tAcc@1  59.38 ( 58.57)\tAcc@5  94.92 ( 92.00)\n",
            "Epoch: [152][180/268]\tTime  0.420 ( 0.886)\tData  0.000 ( 0.486)\tLoss 2.5322e+00 (2.1575e+00)\tAcc@1  35.94 ( 58.53)\tAcc@5  83.20 ( 91.96)\n",
            "Epoch: [152][190/268]\tTime  0.434 ( 0.871)\tData  0.011 ( 0.470)\tLoss 2.4317e+00 (2.1591e+00)\tAcc@1  41.80 ( 58.39)\tAcc@5  84.77 ( 91.89)\n",
            "Epoch: [152][200/268]\tTime  0.415 ( 0.861)\tData  0.000 ( 0.460)\tLoss 2.1974e+00 (2.1503e+00)\tAcc@1  63.28 ( 58.84)\tAcc@5  93.36 ( 92.08)\n",
            "Epoch: [152][210/268]\tTime  0.426 ( 0.849)\tData  0.000 ( 0.448)\tLoss 2.4359e+00 (2.1438e+00)\tAcc@1  35.16 ( 58.98)\tAcc@5  84.77 ( 92.16)\n",
            "Epoch: [152][220/268]\tTime  0.416 ( 0.840)\tData  0.001 ( 0.439)\tLoss 2.4370e+00 (2.1395e+00)\tAcc@1  37.50 ( 59.18)\tAcc@5  86.33 ( 92.23)\n",
            "Epoch: [152][230/268]\tTime  0.424 ( 0.830)\tData  0.000 ( 0.429)\tLoss 1.9892e+00 (2.1370e+00)\tAcc@1  62.11 ( 59.26)\tAcc@5  96.09 ( 92.25)\n",
            "Epoch: [152][240/268]\tTime  0.421 ( 0.813)\tData  0.013 ( 0.412)\tLoss 2.2534e+00 (2.1383e+00)\tAcc@1  64.45 ( 59.29)\tAcc@5  91.41 ( 92.20)\n",
            "Epoch: [152][250/268]\tTime  0.415 ( 0.808)\tData  0.000 ( 0.406)\tLoss 2.4236e+00 (2.1322e+00)\tAcc@1  60.94 ( 59.74)\tAcc@5  90.62 ( 92.29)\n",
            "Epoch: [152][260/268]\tTime  0.416 ( 0.796)\tData  0.000 ( 0.394)\tLoss 2.0974e+00 (2.1338e+00)\tAcc@1  62.11 ( 59.70)\tAcc@5  93.75 ( 92.23)\n",
            "epoch: 152\n",
            "2023-03-25 04:13:15.644927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:15.645017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:15.645033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:19.564074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:19.564172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:19.564192: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:23.462750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:23.462841: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:23.462863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:27.375555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:27.375654: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:27.375683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:31.291237: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:31.291348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:31.291367: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:35.211451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:35.211560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:35.211580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:39.156693: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:39.156789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:39.156809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:43.110210: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:43.110306: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:43.110325: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:47.016194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:47.016298: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:47.016317: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:50.911102: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:50.911207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:50.911226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:54.805347: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:54.805447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:54.805465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:13:58.712559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:58.712665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:13:58.712683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [153][  0/268]\tTime 55.460 (55.460)\tData 55.128 (55.128)\tLoss 1.8699e+00 (1.8699e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [153][ 10/268]\tTime  0.416 ( 5.420)\tData  0.000 ( 5.021)\tLoss 2.5465e+00 (2.2274e+00)\tAcc@1  37.11 ( 54.72)\tAcc@5  83.20 ( 90.23)\n",
            "Epoch: [153][ 20/268]\tTime  0.416 ( 3.127)\tData  0.000 ( 2.726)\tLoss 2.1002e+00 (2.1966e+00)\tAcc@1  54.69 ( 57.51)\tAcc@5  92.97 ( 89.16)\n",
            "Epoch: [153][ 30/268]\tTime  0.410 ( 2.325)\tData  0.000 ( 1.926)\tLoss 2.1158e+00 (2.2044e+00)\tAcc@1  57.81 ( 55.81)\tAcc@5  94.53 ( 89.78)\n",
            "Epoch: [153][ 40/268]\tTime  0.427 ( 1.897)\tData  0.001 ( 1.498)\tLoss 2.5956e+00 (2.1741e+00)\tAcc@1  34.38 ( 57.86)\tAcc@5  79.69 ( 90.38)\n",
            "Epoch: [153][ 50/268]\tTime  0.418 ( 1.657)\tData  0.013 ( 1.258)\tLoss 1.9640e+00 (2.1825e+00)\tAcc@1  61.33 ( 56.86)\tAcc@5  97.66 ( 90.07)\n",
            "Epoch: [153][ 60/268]\tTime  2.130 ( 1.483)\tData  1.803 ( 1.083)\tLoss 2.0457e+00 (2.2065e+00)\tAcc@1  60.55 ( 55.92)\tAcc@5  96.09 ( 90.02)\n",
            "Epoch: [153][ 70/268]\tTime  0.415 ( 1.333)\tData  0.000 ( 0.932)\tLoss 2.6358e+00 (2.2053e+00)\tAcc@1  13.28 ( 55.71)\tAcc@5  74.22 ( 90.01)\n",
            "Epoch: [153][ 80/268]\tTime  0.415 ( 1.251)\tData  0.000 ( 0.849)\tLoss 1.6407e+00 (2.2136e+00)\tAcc@1  89.84 ( 55.61)\tAcc@5  97.66 ( 89.84)\n",
            "Epoch: [153][ 90/268]\tTime  0.415 ( 1.183)\tData  0.000 ( 0.782)\tLoss 2.0628e+00 (2.1981e+00)\tAcc@1  69.53 ( 56.74)\tAcc@5  96.09 ( 90.22)\n",
            "Epoch: [153][100/268]\tTime  0.420 ( 1.132)\tData  0.000 ( 0.731)\tLoss 1.9970e+00 (2.1927e+00)\tAcc@1  55.08 ( 56.87)\tAcc@5  96.09 ( 90.32)\n",
            "Epoch: [153][110/268]\tTime  0.417 ( 1.082)\tData  0.000 ( 0.681)\tLoss 1.5895e+00 (2.1859e+00)\tAcc@1  83.98 ( 57.26)\tAcc@5  98.83 ( 90.44)\n",
            "Epoch: [153][120/268]\tTime  3.368 ( 1.052)\tData  3.000 ( 0.651)\tLoss 1.7391e+00 (2.1788e+00)\tAcc@1  77.34 ( 57.62)\tAcc@5  97.66 ( 90.70)\n",
            "Epoch: [153][130/268]\tTime  0.422 ( 1.003)\tData  0.000 ( 0.602)\tLoss 2.0571e+00 (2.1661e+00)\tAcc@1  59.77 ( 58.63)\tAcc@5  96.88 ( 90.99)\n",
            "Epoch: [153][140/268]\tTime  0.419 ( 0.974)\tData  0.000 ( 0.573)\tLoss 2.5659e+00 (2.1652e+00)\tAcc@1  29.69 ( 58.72)\tAcc@5  79.69 ( 90.95)\n",
            "Epoch: [153][150/268]\tTime  0.435 ( 0.952)\tData  0.013 ( 0.551)\tLoss 2.0841e+00 (2.1715e+00)\tAcc@1  51.56 ( 58.32)\tAcc@5  96.09 ( 90.78)\n",
            "Epoch: [153][160/268]\tTime  0.431 ( 0.933)\tData  0.000 ( 0.532)\tLoss 2.5078e+00 (2.1674e+00)\tAcc@1  33.59 ( 58.78)\tAcc@5  84.38 ( 90.92)\n",
            "Epoch: [153][170/268]\tTime  0.412 ( 0.915)\tData  0.013 ( 0.514)\tLoss 2.5147e+00 (2.1620e+00)\tAcc@1  33.98 ( 58.94)\tAcc@5  82.42 ( 91.00)\n",
            "Epoch: [153][180/268]\tTime  2.419 ( 0.899)\tData  2.088 ( 0.498)\tLoss 1.7978e+00 (2.1546e+00)\tAcc@1  74.22 ( 59.33)\tAcc@5  98.83 ( 91.15)\n",
            "Epoch: [153][190/268]\tTime  0.422 ( 0.874)\tData  0.000 ( 0.472)\tLoss 2.5338e+00 (2.1624e+00)\tAcc@1  55.47 ( 58.92)\tAcc@5  83.20 ( 90.96)\n",
            "Epoch: [153][200/268]\tTime  0.422 ( 0.860)\tData  0.000 ( 0.459)\tLoss 2.0166e+00 (2.1559e+00)\tAcc@1  59.38 ( 59.26)\tAcc@5  94.92 ( 91.08)\n",
            "Epoch: [153][210/268]\tTime  0.413 ( 0.848)\tData  0.000 ( 0.447)\tLoss 1.7169e+00 (2.1486e+00)\tAcc@1  77.73 ( 59.71)\tAcc@5  96.88 ( 91.18)\n",
            "Epoch: [153][220/268]\tTime  0.420 ( 0.836)\tData  0.012 ( 0.435)\tLoss 1.7241e+00 (2.1434e+00)\tAcc@1  87.11 ( 59.99)\tAcc@5  97.66 ( 91.32)\n",
            "Epoch: [153][230/268]\tTime  0.428 ( 0.827)\tData  0.000 ( 0.426)\tLoss 2.5911e+00 (2.1418e+00)\tAcc@1  28.91 ( 59.86)\tAcc@5  80.86 ( 91.33)\n",
            "Epoch: [153][240/268]\tTime  2.096 ( 0.817)\tData  1.767 ( 0.416)\tLoss 1.7854e+00 (2.1392e+00)\tAcc@1  79.69 ( 59.90)\tAcc@5  97.27 ( 91.39)\n",
            "Epoch: [153][250/268]\tTime  0.417 ( 0.801)\tData  0.000 ( 0.400)\tLoss 2.1878e+00 (2.1365e+00)\tAcc@1  51.56 ( 60.14)\tAcc@5  93.36 ( 91.48)\n",
            "Epoch: [153][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.391)\tLoss 1.8456e+00 (2.1420e+00)\tAcc@1  82.42 ( 59.83)\tAcc@5  97.66 ( 91.40)\n",
            "epoch: 153\n",
            "2023-03-25 04:16:47.037423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:47.037537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:47.037557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:16:50.984095: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:50.984194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:50.984211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:16:54.884922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:54.885027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:54.885045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:16:58.803788: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:58.803884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:16:58.803904: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:02.731977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:02.732075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:02.732093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:06.631340: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:06.631438: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:06.631457: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:10.557283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:10.557393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:10.557412: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:14.469822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:14.469918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:14.469937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:18.357077: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:18.357176: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:18.357197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:22.283606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:22.283716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:22.283735: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:26.192313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:26.192411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:26.192429: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:17:30.078387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:30.078498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:17:30.078519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [154][  0/268]\tTime 55.676 (55.676)\tData 55.350 (55.350)\tLoss 2.6055e+00 (2.6055e+00)\tAcc@1  32.42 ( 32.42)\tAcc@5  77.34 ( 77.34)\n",
            "Epoch: [154][ 10/268]\tTime  0.416 ( 5.441)\tData  0.001 ( 5.042)\tLoss 1.5343e+00 (2.1381e+00)\tAcc@1  89.06 ( 57.35)\tAcc@5  98.83 ( 91.02)\n",
            "Epoch: [154][ 20/268]\tTime  0.417 ( 3.173)\tData  0.011 ( 2.774)\tLoss 2.4900e+00 (2.1343e+00)\tAcc@1  39.84 ( 59.39)\tAcc@5  85.16 ( 91.29)\n",
            "Epoch: [154][ 30/268]\tTime  0.410 ( 2.334)\tData  0.000 ( 1.936)\tLoss 2.1660e+00 (2.1119e+00)\tAcc@1  53.12 ( 60.01)\tAcc@5  93.36 ( 91.92)\n",
            "Epoch: [154][ 40/268]\tTime  0.417 ( 1.932)\tData  0.000 ( 1.533)\tLoss 2.4632e+00 (2.0916e+00)\tAcc@1  32.42 ( 61.02)\tAcc@5  84.38 ( 92.48)\n",
            "Epoch: [154][ 50/268]\tTime  0.416 ( 1.662)\tData  0.001 ( 1.262)\tLoss 1.7291e+00 (2.0914e+00)\tAcc@1  78.52 ( 61.11)\tAcc@5  97.66 ( 92.26)\n",
            "Epoch: [154][ 60/268]\tTime  2.901 ( 1.499)\tData  2.571 ( 1.099)\tLoss 2.3269e+00 (2.1177e+00)\tAcc@1  68.36 ( 59.64)\tAcc@5  89.45 ( 92.04)\n",
            "Epoch: [154][ 70/268]\tTime  0.429 ( 1.348)\tData  0.013 ( 0.946)\tLoss 1.6085e+00 (2.0934e+00)\tAcc@1  84.77 ( 61.54)\tAcc@5  97.27 ( 92.60)\n",
            "Epoch: [154][ 80/268]\tTime  0.423 ( 1.253)\tData  0.000 ( 0.852)\tLoss 2.4702e+00 (2.0915e+00)\tAcc@1  37.11 ( 61.45)\tAcc@5  83.20 ( 92.48)\n",
            "Epoch: [154][ 90/268]\tTime  0.416 ( 1.185)\tData  0.013 ( 0.783)\tLoss 1.7832e+00 (2.0854e+00)\tAcc@1  83.20 ( 61.93)\tAcc@5  97.27 ( 92.55)\n",
            "Epoch: [154][100/268]\tTime  0.414 ( 1.128)\tData  0.000 ( 0.727)\tLoss 1.9327e+00 (2.1032e+00)\tAcc@1  66.80 ( 60.73)\tAcc@5  96.09 ( 92.12)\n",
            "Epoch: [154][110/268]\tTime  0.417 ( 1.084)\tData  0.000 ( 0.683)\tLoss 2.1733e+00 (2.1056e+00)\tAcc@1  74.22 ( 60.96)\tAcc@5  92.97 ( 92.18)\n",
            "Epoch: [154][120/268]\tTime  2.494 ( 1.046)\tData  2.154 ( 0.646)\tLoss 1.5208e+00 (2.1245e+00)\tAcc@1  89.84 ( 60.58)\tAcc@5  98.83 ( 91.31)\n",
            "Epoch: [154][130/268]\tTime  0.418 ( 0.998)\tData  0.001 ( 0.597)\tLoss 2.4941e+00 (2.1251e+00)\tAcc@1  35.55 ( 60.53)\tAcc@5  82.03 ( 91.28)\n",
            "Epoch: [154][140/268]\tTime  0.417 ( 0.976)\tData  0.000 ( 0.575)\tLoss 1.7704e+00 (2.1186e+00)\tAcc@1  86.72 ( 60.69)\tAcc@5  98.05 ( 91.41)\n",
            "Epoch: [154][150/268]\tTime  0.417 ( 0.952)\tData  0.000 ( 0.551)\tLoss 2.1831e+00 (2.1183e+00)\tAcc@1  51.56 ( 60.60)\tAcc@5  92.58 ( 91.43)\n",
            "Epoch: [154][160/268]\tTime  0.416 ( 0.930)\tData  0.001 ( 0.529)\tLoss 2.1578e+00 (2.1128e+00)\tAcc@1  57.81 ( 60.79)\tAcc@5  92.97 ( 91.53)\n",
            "Epoch: [154][170/268]\tTime  0.416 ( 0.911)\tData  0.000 ( 0.510)\tLoss 1.6213e+00 (2.1057e+00)\tAcc@1  92.19 ( 61.05)\tAcc@5  97.66 ( 91.68)\n",
            "Epoch: [154][180/268]\tTime  2.410 ( 0.894)\tData  2.066 ( 0.494)\tLoss 2.4535e+00 (2.1084e+00)\tAcc@1  33.98 ( 60.93)\tAcc@5  86.72 ( 91.73)\n",
            "Epoch: [154][190/268]\tTime  0.435 ( 0.870)\tData  0.001 ( 0.469)\tLoss 2.0608e+00 (2.1068e+00)\tAcc@1  55.08 ( 61.24)\tAcc@5  94.92 ( 91.85)\n",
            "Epoch: [154][200/268]\tTime  0.416 ( 0.856)\tData  0.000 ( 0.455)\tLoss 2.0257e+00 (2.1144e+00)\tAcc@1  75.00 ( 60.95)\tAcc@5  92.58 ( 91.72)\n",
            "Epoch: [154][210/268]\tTime  0.419 ( 0.846)\tData  0.000 ( 0.445)\tLoss 2.0095e+00 (2.1091e+00)\tAcc@1  74.61 ( 61.44)\tAcc@5  94.53 ( 91.85)\n",
            "Epoch: [154][220/268]\tTime  0.417 ( 0.836)\tData  0.000 ( 0.435)\tLoss 2.3548e+00 (2.1061e+00)\tAcc@1  66.02 ( 61.73)\tAcc@5  91.80 ( 91.96)\n",
            "Epoch: [154][230/268]\tTime  0.424 ( 0.826)\tData  0.000 ( 0.426)\tLoss 2.0131e+00 (2.1056e+00)\tAcc@1  60.55 ( 61.72)\tAcc@5  95.31 ( 91.98)\n",
            "Epoch: [154][240/268]\tTime  2.097 ( 0.817)\tData  1.776 ( 0.416)\tLoss 2.1700e+00 (2.1027e+00)\tAcc@1  54.69 ( 61.92)\tAcc@5  93.75 ( 92.09)\n",
            "Epoch: [154][250/268]\tTime  0.414 ( 0.801)\tData  0.000 ( 0.400)\tLoss 2.2473e+00 (2.1023e+00)\tAcc@1  71.88 ( 61.98)\tAcc@5  92.19 ( 92.13)\n",
            "Epoch: [154][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.391)\tLoss 2.4898e+00 (2.1015e+00)\tAcc@1  33.20 ( 62.02)\tAcc@5  83.59 ( 92.14)\n",
            "epoch: 154\n",
            "2023-03-25 04:20:18.440276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:18.440373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:18.440391: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:22.445149: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:22.445257: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:22.445277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:26.367712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:26.367815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:26.367833: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:30.323993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:30.324095: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:30.324114: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:34.330473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:34.330584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:34.330604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:38.261377: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:38.261479: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:38.261498: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:42.166302: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:42.166406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:42.166426: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:46.084738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:46.084834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:46.084853: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:50.031523: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:50.031621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:50.031640: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:53.946059: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:53.946154: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:53.946173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:20:57.833956: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:57.834056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:20:57.834075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:21:01.732354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:21:01.732451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:21:01.732470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [155][  0/268]\tTime 55.663 (55.663)\tData 55.324 (55.324)\tLoss 1.9404e+00 (1.9404e+00)\tAcc@1  66.80 ( 66.80)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [155][ 10/268]\tTime  0.434 ( 5.450)\tData  0.000 ( 5.048)\tLoss 1.9579e+00 (2.1308e+00)\tAcc@1  69.92 ( 60.26)\tAcc@5  95.31 ( 93.15)\n",
            "Epoch: [155][ 20/268]\tTime  0.418 ( 3.128)\tData  0.000 ( 2.733)\tLoss 1.7541e+00 (2.0753e+00)\tAcc@1  73.83 ( 60.94)\tAcc@5  98.05 ( 93.47)\n",
            "Epoch: [155][ 30/268]\tTime  0.417 ( 2.316)\tData  0.000 ( 1.923)\tLoss 2.1950e+00 (2.1002e+00)\tAcc@1  85.16 ( 61.71)\tAcc@5  91.41 ( 93.13)\n",
            "Epoch: [155][ 40/268]\tTime  0.421 ( 1.900)\tData  0.000 ( 1.508)\tLoss 2.2175e+00 (2.0896e+00)\tAcc@1  48.05 ( 62.39)\tAcc@5  92.19 ( 93.41)\n",
            "Epoch: [155][ 50/268]\tTime  0.436 ( 1.660)\tData  0.000 ( 1.268)\tLoss 1.9932e+00 (2.1064e+00)\tAcc@1  75.78 ( 61.08)\tAcc@5  95.70 ( 93.17)\n",
            "Epoch: [155][ 60/268]\tTime  0.416 ( 1.456)\tData  0.000 ( 1.062)\tLoss 2.3332e+00 (2.1144e+00)\tAcc@1  52.34 ( 60.85)\tAcc@5  86.72 ( 92.78)\n",
            "Epoch: [155][ 70/268]\tTime  0.429 ( 1.333)\tData  0.001 ( 0.937)\tLoss 1.6753e+00 (2.0967e+00)\tAcc@1  90.62 ( 61.97)\tAcc@5  98.05 ( 93.01)\n",
            "Epoch: [155][ 80/268]\tTime  0.431 ( 1.246)\tData  0.000 ( 0.850)\tLoss 1.9654e+00 (2.0810e+00)\tAcc@1  75.00 ( 62.73)\tAcc@5  96.09 ( 93.15)\n",
            "Epoch: [155][ 90/268]\tTime  0.417 ( 1.182)\tData  0.000 ( 0.786)\tLoss 2.1186e+00 (2.0638e+00)\tAcc@1  66.80 ( 64.07)\tAcc@5  92.58 ( 93.40)\n",
            "Epoch: [155][100/268]\tTime  0.429 ( 1.127)\tData  0.000 ( 0.732)\tLoss 2.3760e+00 (2.0611e+00)\tAcc@1  44.92 ( 64.20)\tAcc@5  87.11 ( 93.42)\n",
            "Epoch: [155][110/268]\tTime  0.417 ( 1.078)\tData  0.001 ( 0.683)\tLoss 1.9144e+00 (2.0494e+00)\tAcc@1  72.27 ( 64.62)\tAcc@5  95.70 ( 93.56)\n",
            "Epoch: [155][120/268]\tTime  0.420 ( 1.024)\tData  0.080 ( 0.628)\tLoss 2.3144e+00 (2.0517e+00)\tAcc@1  43.36 ( 64.73)\tAcc@5  86.72 ( 93.61)\n",
            "Epoch: [155][130/268]\tTime  0.416 ( 0.999)\tData  0.000 ( 0.602)\tLoss 2.0694e+00 (2.0556e+00)\tAcc@1  57.42 ( 64.58)\tAcc@5  96.88 ( 93.65)\n",
            "Epoch: [155][140/268]\tTime  0.426 ( 0.971)\tData  0.000 ( 0.573)\tLoss 2.0292e+00 (2.0616e+00)\tAcc@1  73.05 ( 64.35)\tAcc@5  96.88 ( 93.58)\n",
            "Epoch: [155][150/268]\tTime  0.417 ( 0.954)\tData  0.000 ( 0.556)\tLoss 2.2333e+00 (2.0619e+00)\tAcc@1  64.06 ( 64.09)\tAcc@5  94.53 ( 93.55)\n",
            "Epoch: [155][160/268]\tTime  0.416 ( 0.932)\tData  0.000 ( 0.534)\tLoss 1.9761e+00 (2.0571e+00)\tAcc@1  73.05 ( 64.49)\tAcc@5  96.88 ( 93.59)\n",
            "Epoch: [155][170/268]\tTime  0.430 ( 0.917)\tData  0.000 ( 0.520)\tLoss 2.3781e+00 (2.0612e+00)\tAcc@1  33.59 ( 63.86)\tAcc@5  90.62 ( 93.53)\n",
            "Epoch: [155][180/268]\tTime  0.410 ( 0.890)\tData  0.000 ( 0.492)\tLoss 1.7106e+00 (2.0643e+00)\tAcc@1  76.56 ( 63.61)\tAcc@5  98.83 ( 93.43)\n",
            "Epoch: [155][190/268]\tTime  0.429 ( 0.876)\tData  0.009 ( 0.477)\tLoss 2.7055e+00 (2.0686e+00)\tAcc@1  26.56 ( 63.33)\tAcc@5  83.59 ( 93.30)\n",
            "Epoch: [155][200/268]\tTime  0.410 ( 0.864)\tData  0.000 ( 0.465)\tLoss 1.7813e+00 (2.0643e+00)\tAcc@1  71.48 ( 63.55)\tAcc@5  97.66 ( 93.36)\n",
            "Epoch: [155][210/268]\tTime  0.416 ( 0.854)\tData  0.013 ( 0.455)\tLoss 2.1543e+00 (2.0609e+00)\tAcc@1  69.14 ( 63.63)\tAcc@5  93.75 ( 93.42)\n",
            "Epoch: [155][220/268]\tTime  0.417 ( 0.845)\tData  0.000 ( 0.446)\tLoss 2.2765e+00 (2.0670e+00)\tAcc@1  42.58 ( 63.37)\tAcc@5  91.41 ( 93.29)\n",
            "Epoch: [155][230/268]\tTime  0.420 ( 0.839)\tData  0.000 ( 0.439)\tLoss 1.8304e+00 (2.0635e+00)\tAcc@1  84.77 ( 63.65)\tAcc@5  96.48 ( 93.39)\n",
            "Epoch: [155][240/268]\tTime  0.417 ( 0.821)\tData  0.001 ( 0.422)\tLoss 1.9338e+00 (2.0716e+00)\tAcc@1  82.03 ( 63.22)\tAcc@5  95.31 ( 93.29)\n",
            "Epoch: [155][250/268]\tTime  0.416 ( 0.812)\tData  0.000 ( 0.412)\tLoss 2.3896e+00 (2.0744e+00)\tAcc@1  43.75 ( 62.96)\tAcc@5  85.55 ( 93.24)\n",
            "Epoch: [155][260/268]\tTime  0.415 ( 0.799)\tData  0.000 ( 0.399)\tLoss 1.9952e+00 (2.0761e+00)\tAcc@1  62.89 ( 62.82)\tAcc@5  95.70 ( 93.18)\n",
            "epoch: 155\n",
            "2023-03-25 04:23:51.691405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:51.691508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:51.691528: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:23:55.610004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:55.610104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:55.610124: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:23:59.561918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:59.562030: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:23:59.562051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:03.506631: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:03.506744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:03.506763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:07.423979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:07.424088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:07.424107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:11.370440: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:11.370547: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:11.370565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:15.319094: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:15.319196: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:15.319214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:19.216391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:19.216491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:19.216510: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:23.122233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:23.122325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:23.122342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:27.028901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:27.029000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:27.029019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:30.964848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:30.964946: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:30.964965: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:24:34.885651: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:34.885767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:24:34.885785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [156][  0/268]\tTime 55.908 (55.908)\tData 55.560 (55.560)\tLoss 2.0513e+00 (2.0513e+00)\tAcc@1  78.12 ( 78.12)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [156][ 10/268]\tTime  0.418 ( 5.465)\tData  0.000 ( 5.062)\tLoss 2.0752e+00 (2.2298e+00)\tAcc@1  55.86 ( 54.87)\tAcc@5  95.31 ( 90.34)\n",
            "Epoch: [156][ 20/268]\tTime  0.424 ( 3.159)\tData  0.000 ( 2.760)\tLoss 1.7048e+00 (2.1287e+00)\tAcc@1  84.38 ( 59.43)\tAcc@5  99.61 ( 92.22)\n",
            "Epoch: [156][ 30/268]\tTime  0.417 ( 2.325)\tData  0.000 ( 1.926)\tLoss 2.1062e+00 (2.1207e+00)\tAcc@1  50.00 ( 59.44)\tAcc@5  95.70 ( 92.36)\n",
            "Epoch: [156][ 40/268]\tTime  0.414 ( 1.904)\tData  0.000 ( 1.507)\tLoss 2.1154e+00 (2.1121e+00)\tAcc@1  58.98 ( 60.40)\tAcc@5  93.75 ( 92.50)\n",
            "Epoch: [156][ 50/268]\tTime  0.422 ( 1.660)\tData  0.000 ( 1.264)\tLoss 2.0224e+00 (2.0927e+00)\tAcc@1  57.81 ( 61.56)\tAcc@5  94.14 ( 92.85)\n",
            "Epoch: [156][ 60/268]\tTime  1.308 ( 1.471)\tData  0.975 ( 1.074)\tLoss 2.4695e+00 (2.1013e+00)\tAcc@1  43.75 ( 60.92)\tAcc@5  85.16 ( 92.79)\n",
            "Epoch: [156][ 70/268]\tTime  0.414 ( 1.324)\tData  0.000 ( 0.926)\tLoss 1.8845e+00 (2.0980e+00)\tAcc@1  70.31 ( 61.06)\tAcc@5  98.05 ( 92.83)\n",
            "Epoch: [156][ 80/268]\tTime  0.413 ( 1.242)\tData  0.000 ( 0.844)\tLoss 2.1161e+00 (2.0895e+00)\tAcc@1  67.19 ( 61.48)\tAcc@5  94.92 ( 92.92)\n",
            "Epoch: [156][ 90/268]\tTime  0.421 ( 1.176)\tData  0.000 ( 0.780)\tLoss 2.4208e+00 (2.0837e+00)\tAcc@1  51.17 ( 62.17)\tAcc@5  94.92 ( 93.06)\n",
            "Epoch: [156][100/268]\tTime  0.431 ( 1.126)\tData  0.012 ( 0.731)\tLoss 2.1842e+00 (2.0729e+00)\tAcc@1  62.89 ( 62.42)\tAcc@5  91.41 ( 93.15)\n",
            "Epoch: [156][110/268]\tTime  0.417 ( 1.081)\tData  0.000 ( 0.686)\tLoss 1.5492e+00 (2.0891e+00)\tAcc@1  91.80 ( 61.44)\tAcc@5  98.44 ( 92.86)\n",
            "Epoch: [156][120/268]\tTime  1.937 ( 1.039)\tData  1.597 ( 0.644)\tLoss 1.5939e+00 (2.0858e+00)\tAcc@1  85.16 ( 61.96)\tAcc@5  97.27 ( 92.85)\n",
            "Epoch: [156][130/268]\tTime  0.417 ( 0.993)\tData  0.000 ( 0.596)\tLoss 2.0838e+00 (2.0795e+00)\tAcc@1  57.42 ( 62.12)\tAcc@5  94.14 ( 92.95)\n",
            "Epoch: [156][140/268]\tTime  0.441 ( 0.970)\tData  0.000 ( 0.573)\tLoss 1.9988e+00 (2.0716e+00)\tAcc@1  80.86 ( 62.89)\tAcc@5  96.09 ( 93.11)\n",
            "Epoch: [156][150/268]\tTime  0.429 ( 0.947)\tData  0.013 ( 0.550)\tLoss 2.3404e+00 (2.0815e+00)\tAcc@1  64.06 ( 62.57)\tAcc@5  92.97 ( 92.82)\n",
            "Epoch: [156][160/268]\tTime  0.416 ( 0.931)\tData  0.001 ( 0.534)\tLoss 2.4995e+00 (2.0795e+00)\tAcc@1  34.77 ( 62.53)\tAcc@5  82.81 ( 92.85)\n",
            "Epoch: [156][170/268]\tTime  0.427 ( 0.910)\tData  0.000 ( 0.513)\tLoss 2.0307e+00 (2.0865e+00)\tAcc@1  57.42 ( 61.97)\tAcc@5  95.70 ( 92.69)\n",
            "Epoch: [156][180/268]\tTime  2.588 ( 0.895)\tData  2.244 ( 0.498)\tLoss 2.0498e+00 (2.0872e+00)\tAcc@1  58.98 ( 61.91)\tAcc@5  96.48 ( 92.69)\n",
            "Epoch: [156][190/268]\tTime  0.417 ( 0.871)\tData  0.000 ( 0.474)\tLoss 2.5170e+00 (2.0837e+00)\tAcc@1  34.77 ( 62.06)\tAcc@5  83.98 ( 92.73)\n",
            "Epoch: [156][200/268]\tTime  0.417 ( 0.859)\tData  0.014 ( 0.462)\tLoss 1.9630e+00 (2.0817e+00)\tAcc@1  87.50 ( 62.30)\tAcc@5  95.70 ( 92.78)\n",
            "Epoch: [156][210/268]\tTime  0.410 ( 0.847)\tData  0.000 ( 0.450)\tLoss 1.5929e+00 (2.0788e+00)\tAcc@1  89.45 ( 62.32)\tAcc@5  99.22 ( 92.77)\n",
            "Epoch: [156][220/268]\tTime  0.415 ( 0.837)\tData  0.000 ( 0.440)\tLoss 2.4789e+00 (2.0850e+00)\tAcc@1  46.88 ( 61.98)\tAcc@5  85.16 ( 92.66)\n",
            "Epoch: [156][230/268]\tTime  0.410 ( 0.827)\tData  0.000 ( 0.431)\tLoss 1.9035e+00 (2.0861e+00)\tAcc@1  76.17 ( 61.83)\tAcc@5  95.70 ( 92.64)\n",
            "Epoch: [156][240/268]\tTime  2.576 ( 0.819)\tData  2.246 ( 0.423)\tLoss 1.8451e+00 (2.0844e+00)\tAcc@1  74.61 ( 61.91)\tAcc@5  96.48 ( 92.68)\n",
            "Epoch: [156][250/268]\tTime  0.416 ( 0.803)\tData  0.000 ( 0.406)\tLoss 2.4020e+00 (2.0905e+00)\tAcc@1  40.23 ( 61.53)\tAcc@5  87.50 ( 92.63)\n",
            "Epoch: [156][260/268]\tTime  0.415 ( 0.793)\tData  0.000 ( 0.396)\tLoss 1.9198e+00 (2.0855e+00)\tAcc@1  83.59 ( 61.93)\tAcc@5  98.44 ( 92.76)\n",
            "epoch: 156\n",
            "2023-03-25 04:27:23.348673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:23.348773: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:23.348793: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:27.288569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:27.288679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:27.288699: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:31.207300: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:31.207404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:31.207423: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:35.100035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:35.100131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:35.100149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:39.061286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:39.061391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:39.061411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:42.988334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:42.988431: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:42.988450: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:46.920477: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:46.920589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:46.920608: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:50.856994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:50.857091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:50.857110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:54.817540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:54.817646: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:54.817676: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:27:58.742473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:58.742576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:27:58.742596: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:28:02.665758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:28:02.665858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:28:02.665877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:28:06.622152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:28:06.622247: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:28:06.622266: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [157][  0/268]\tTime 54.972 (54.972)\tData 54.634 (54.634)\tLoss 2.4499e+00 (2.4499e+00)\tAcc@1  31.25 ( 31.25)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [157][ 10/268]\tTime  0.430 ( 5.401)\tData  0.000 ( 5.005)\tLoss 2.4640e+00 (2.0578e+00)\tAcc@1  36.72 ( 60.83)\tAcc@5  86.33 ( 93.43)\n",
            "Epoch: [157][ 20/268]\tTime  0.416 ( 3.121)\tData  0.000 ( 2.724)\tLoss 2.0256e+00 (1.9621e+00)\tAcc@1  68.36 ( 68.06)\tAcc@5  96.09 ( 94.94)\n",
            "Epoch: [157][ 30/268]\tTime  0.417 ( 2.317)\tData  0.012 ( 1.919)\tLoss 1.7925e+00 (1.9494e+00)\tAcc@1  87.11 ( 70.01)\tAcc@5  96.48 ( 95.16)\n",
            "Epoch: [157][ 40/268]\tTime  0.416 ( 1.889)\tData  0.013 ( 1.491)\tLoss 1.9193e+00 (1.9828e+00)\tAcc@1  80.86 ( 68.39)\tAcc@5  96.09 ( 94.78)\n",
            "Epoch: [157][ 50/268]\tTime  0.419 ( 1.641)\tData  0.030 ( 1.244)\tLoss 1.7122e+00 (1.9852e+00)\tAcc@1  80.08 ( 68.57)\tAcc@5  97.66 ( 94.48)\n",
            "Epoch: [157][ 60/268]\tTime  2.287 ( 1.471)\tData  1.932 ( 1.073)\tLoss 2.1398e+00 (1.9832e+00)\tAcc@1  66.80 ( 68.65)\tAcc@5  95.31 ( 94.65)\n",
            "Epoch: [157][ 70/268]\tTime  0.422 ( 1.325)\tData  0.001 ( 0.927)\tLoss 1.9170e+00 (1.9910e+00)\tAcc@1  75.39 ( 68.31)\tAcc@5  98.44 ( 94.60)\n",
            "Epoch: [157][ 80/268]\tTime  0.416 ( 1.240)\tData  0.000 ( 0.843)\tLoss 2.3144e+00 (1.9817e+00)\tAcc@1  42.58 ( 69.39)\tAcc@5  88.67 ( 94.76)\n",
            "Epoch: [157][ 90/268]\tTime  0.423 ( 1.174)\tData  0.000 ( 0.781)\tLoss 2.4084e+00 (2.0037e+00)\tAcc@1  33.20 ( 67.67)\tAcc@5  89.84 ( 94.37)\n",
            "Epoch: [157][100/268]\tTime  0.409 ( 1.119)\tData  0.000 ( 0.727)\tLoss 2.3628e+00 (2.0121e+00)\tAcc@1  39.45 ( 66.81)\tAcc@5  88.28 ( 94.18)\n",
            "Epoch: [157][110/268]\tTime  0.417 ( 1.078)\tData  0.000 ( 0.687)\tLoss 3.1153e+00 (2.0107e+00)\tAcc@1   9.77 ( 66.98)\tAcc@5  65.23 ( 94.12)\n",
            "Epoch: [157][120/268]\tTime  1.034 ( 1.029)\tData  0.716 ( 0.637)\tLoss 2.3218e+00 (2.0140e+00)\tAcc@1  37.89 ( 66.71)\tAcc@5  87.11 ( 94.16)\n",
            "Epoch: [157][130/268]\tTime  0.416 ( 0.995)\tData  0.000 ( 0.602)\tLoss 2.3847e+00 (2.0223e+00)\tAcc@1  38.67 ( 66.06)\tAcc@5  86.72 ( 94.00)\n",
            "Epoch: [157][140/268]\tTime  0.419 ( 0.967)\tData  0.000 ( 0.575)\tLoss 1.6675e+00 (2.0226e+00)\tAcc@1  87.89 ( 65.94)\tAcc@5  98.05 ( 94.00)\n",
            "Epoch: [157][150/268]\tTime  0.419 ( 0.944)\tData  0.000 ( 0.553)\tLoss 1.8274e+00 (2.0270e+00)\tAcc@1  82.03 ( 65.67)\tAcc@5  95.70 ( 93.98)\n",
            "Epoch: [157][160/268]\tTime  0.459 ( 0.922)\tData  0.000 ( 0.532)\tLoss 1.9760e+00 (2.0279e+00)\tAcc@1  82.03 ( 65.62)\tAcc@5  96.09 ( 93.99)\n",
            "Epoch: [157][170/268]\tTime  0.424 ( 0.907)\tData  0.000 ( 0.517)\tLoss 2.3773e+00 (2.0335e+00)\tAcc@1  35.16 ( 65.10)\tAcc@5  86.33 ( 93.91)\n",
            "Epoch: [157][180/268]\tTime  0.752 ( 0.882)\tData  0.424 ( 0.491)\tLoss 3.3638e+00 (2.0413e+00)\tAcc@1   4.69 ( 64.91)\tAcc@5  35.16 ( 93.59)\n",
            "Epoch: [157][190/268]\tTime  0.424 ( 0.867)\tData  0.000 ( 0.475)\tLoss 2.4131e+00 (2.0472e+00)\tAcc@1  39.45 ( 64.42)\tAcc@5  82.81 ( 93.40)\n",
            "Epoch: [157][200/268]\tTime  0.429 ( 0.855)\tData  0.013 ( 0.463)\tLoss 1.8761e+00 (2.0508e+00)\tAcc@1  81.64 ( 64.24)\tAcc@5  97.27 ( 93.32)\n",
            "Epoch: [157][210/268]\tTime  0.419 ( 0.843)\tData  0.000 ( 0.451)\tLoss 2.0071e+00 (2.0539e+00)\tAcc@1  75.78 ( 64.18)\tAcc@5  95.70 ( 93.34)\n",
            "Epoch: [157][220/268]\tTime  0.415 ( 0.833)\tData  0.000 ( 0.440)\tLoss 2.3869e+00 (2.0516e+00)\tAcc@1  36.72 ( 64.39)\tAcc@5  86.33 ( 93.36)\n",
            "Epoch: [157][230/268]\tTime  0.417 ( 0.823)\tData  0.000 ( 0.430)\tLoss 1.8250e+00 (2.0480e+00)\tAcc@1  77.34 ( 64.54)\tAcc@5  97.66 ( 93.40)\n",
            "Epoch: [157][240/268]\tTime  0.656 ( 0.807)\tData  0.308 ( 0.414)\tLoss 2.3280e+00 (2.0450e+00)\tAcc@1  61.72 ( 64.79)\tAcc@5  91.02 ( 93.44)\n",
            "Epoch: [157][250/268]\tTime  0.417 ( 0.799)\tData  0.000 ( 0.406)\tLoss 1.9571e+00 (2.0428e+00)\tAcc@1  68.36 ( 64.96)\tAcc@5  97.27 ( 93.46)\n",
            "Epoch: [157][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.398)\tLoss 1.7975e+00 (2.0417e+00)\tAcc@1  80.08 ( 64.81)\tAcc@5  97.27 ( 93.48)\n",
            "epoch: 157\n",
            "2023-03-25 04:30:54.422859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:30:54.422963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:30:54.422982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:30:58.347356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:30:58.347453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:30:58.347473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:02.274449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:02.274557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:02.274576: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:06.209354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:06.209447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:06.209468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:10.103425: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:10.103535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:10.103554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:14.009893: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:14.009994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:14.010012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:17.962051: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:17.962147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:17.962166: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:21.922614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:21.922724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:21.922743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:25.861153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:25.861261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:25.861280: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:29.780957: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:29.781061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:29.781080: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:33.686780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:33.686878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:33.686896: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:31:37.576348: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:37.576452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:31:37.576472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [158][  0/268]\tTime 55.738 (55.738)\tData 55.400 (55.400)\tLoss 2.1372e+00 (2.1372e+00)\tAcc@1  54.30 ( 54.30)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [158][ 10/268]\tTime  0.423 ( 5.448)\tData  0.000 ( 5.047)\tLoss 1.7453e+00 (2.0923e+00)\tAcc@1  88.67 ( 61.90)\tAcc@5  98.05 ( 92.76)\n",
            "Epoch: [158][ 20/268]\tTime  0.433 ( 3.111)\tData  0.000 ( 2.716)\tLoss 2.0046e+00 (2.0789e+00)\tAcc@1  63.28 ( 62.26)\tAcc@5  95.31 ( 92.65)\n",
            "Epoch: [158][ 30/268]\tTime  0.417 ( 2.311)\tData  0.000 ( 1.920)\tLoss 1.7158e+00 (1.9896e+00)\tAcc@1  89.06 ( 67.75)\tAcc@5  96.88 ( 94.08)\n",
            "Epoch: [158][ 40/268]\tTime  0.417 ( 1.909)\tData  0.000 ( 1.523)\tLoss 2.2918e+00 (1.9896e+00)\tAcc@1  46.09 ( 67.91)\tAcc@5  89.45 ( 94.30)\n",
            "Epoch: [158][ 50/268]\tTime  0.428 ( 1.636)\tData  0.000 ( 1.249)\tLoss 1.6498e+00 (1.9877e+00)\tAcc@1  85.94 ( 69.19)\tAcc@5  98.05 ( 94.54)\n",
            "Epoch: [158][ 60/268]\tTime  0.432 ( 1.464)\tData  0.013 ( 1.074)\tLoss 2.1453e+00 (2.0072e+00)\tAcc@1  55.47 ( 68.04)\tAcc@5  91.80 ( 93.99)\n",
            "Epoch: [158][ 70/268]\tTime  0.416 ( 1.340)\tData  0.013 ( 0.950)\tLoss 1.7262e+00 (1.9916e+00)\tAcc@1  88.28 ( 68.77)\tAcc@5  96.88 ( 94.26)\n",
            "Epoch: [158][ 80/268]\tTime  0.416 ( 1.248)\tData  0.000 ( 0.860)\tLoss 2.0836e+00 (2.0046e+00)\tAcc@1  72.27 ( 68.52)\tAcc@5  95.70 ( 94.24)\n",
            "Epoch: [158][ 90/268]\tTime  0.416 ( 1.178)\tData  0.000 ( 0.791)\tLoss 2.0336e+00 (2.0097e+00)\tAcc@1  58.20 ( 67.81)\tAcc@5  94.53 ( 94.19)\n",
            "Epoch: [158][100/268]\tTime  0.418 ( 1.128)\tData  0.000 ( 0.738)\tLoss 1.9873e+00 (2.0189e+00)\tAcc@1  59.77 ( 66.84)\tAcc@5  96.48 ( 94.02)\n",
            "Epoch: [158][110/268]\tTime  0.436 ( 1.083)\tData  0.000 ( 0.693)\tLoss 1.5679e+00 (2.0090e+00)\tAcc@1  89.45 ( 67.57)\tAcc@5  99.22 ( 94.20)\n",
            "Epoch: [158][120/268]\tTime  0.428 ( 1.029)\tData  0.000 ( 0.636)\tLoss 1.9051e+00 (2.0137e+00)\tAcc@1  73.83 ( 66.94)\tAcc@5  96.88 ( 94.15)\n",
            "Epoch: [158][130/268]\tTime  0.417 ( 0.997)\tData  0.000 ( 0.603)\tLoss 2.3378e+00 (2.0150e+00)\tAcc@1  59.38 ( 66.76)\tAcc@5  94.53 ( 94.17)\n",
            "Epoch: [158][140/268]\tTime  0.418 ( 0.969)\tData  0.000 ( 0.576)\tLoss 2.3393e+00 (2.0300e+00)\tAcc@1  41.80 ( 65.38)\tAcc@5  87.89 ( 93.93)\n",
            "Epoch: [158][150/268]\tTime  0.412 ( 0.949)\tData  0.000 ( 0.555)\tLoss 1.8682e+00 (2.0255e+00)\tAcc@1  74.61 ( 65.51)\tAcc@5  96.48 ( 94.02)\n",
            "Epoch: [158][160/268]\tTime  0.416 ( 0.934)\tData  0.000 ( 0.539)\tLoss 2.0131e+00 (2.0289e+00)\tAcc@1  61.72 ( 65.37)\tAcc@5  96.88 ( 93.96)\n",
            "Epoch: [158][170/268]\tTime  0.418 ( 0.916)\tData  0.000 ( 0.521)\tLoss 2.0053e+00 (2.0338e+00)\tAcc@1  64.45 ( 65.08)\tAcc@5  96.09 ( 93.86)\n",
            "Epoch: [158][180/268]\tTime  0.469 ( 0.889)\tData  0.000 ( 0.493)\tLoss 2.6823e+00 (2.0389e+00)\tAcc@1  33.20 ( 64.63)\tAcc@5  85.55 ( 93.78)\n",
            "Epoch: [158][190/268]\tTime  0.417 ( 0.875)\tData  0.000 ( 0.479)\tLoss 2.0764e+00 (2.0373e+00)\tAcc@1  75.00 ( 64.79)\tAcc@5  93.36 ( 93.85)\n",
            "Epoch: [158][200/268]\tTime  0.422 ( 0.863)\tData  0.000 ( 0.466)\tLoss 2.2882e+00 (2.0414e+00)\tAcc@1  40.62 ( 64.48)\tAcc@5  89.06 ( 93.82)\n",
            "Epoch: [158][210/268]\tTime  0.412 ( 0.854)\tData  0.000 ( 0.457)\tLoss 2.1735e+00 (2.0393e+00)\tAcc@1  50.78 ( 64.40)\tAcc@5  92.19 ( 93.84)\n",
            "Epoch: [158][220/268]\tTime  0.419 ( 0.841)\tData  0.000 ( 0.444)\tLoss 2.3717e+00 (2.0431e+00)\tAcc@1  39.06 ( 64.28)\tAcc@5  88.67 ( 93.82)\n",
            "Epoch: [158][230/268]\tTime  0.420 ( 0.833)\tData  0.000 ( 0.435)\tLoss 1.9934e+00 (2.0434e+00)\tAcc@1  51.56 ( 64.21)\tAcc@5  96.48 ( 93.84)\n",
            "Epoch: [158][240/268]\tTime  0.436 ( 0.816)\tData  0.000 ( 0.418)\tLoss 2.0541e+00 (2.0381e+00)\tAcc@1  56.64 ( 64.47)\tAcc@5  96.48 ( 93.95)\n",
            "Epoch: [158][250/268]\tTime  0.417 ( 0.806)\tData  0.000 ( 0.408)\tLoss 2.0128e+00 (2.0361e+00)\tAcc@1  69.53 ( 64.54)\tAcc@5  95.70 ( 93.99)\n",
            "Epoch: [158][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.396)\tLoss 2.4165e+00 (2.0353e+00)\tAcc@1  42.19 ( 64.67)\tAcc@5  83.20 ( 93.97)\n",
            "epoch: 158\n",
            "2023-03-25 04:34:26.366545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:26.366645: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:26.366673: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:30.387567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:30.387681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:30.387701: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:34.329505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:34.329610: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:34.329630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:38.220349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:38.220450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:38.220469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:42.175462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:42.175570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:42.175589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:46.107095: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:46.107195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:46.107214: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:49.980755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:49.980856: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:49.980874: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:53.885026: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:53.885121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:53.885139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:34:57.777344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:57.777452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:34:57.777473: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:35:01.686914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:01.687015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:01.687033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:35:05.622403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:05.622508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:05.622529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:35:09.539108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:09.539204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:35:09.539223: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [159][  0/268]\tTime 54.458 (54.458)\tData 54.126 (54.126)\tLoss 2.0918e+00 (2.0918e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [159][ 10/268]\tTime  0.429 ( 5.387)\tData  0.000 ( 4.994)\tLoss 2.1284e+00 (2.0613e+00)\tAcc@1  52.34 ( 63.32)\tAcc@5  92.19 ( 94.53)\n",
            "Epoch: [159][ 20/268]\tTime  0.417 ( 3.123)\tData  0.000 ( 2.736)\tLoss 1.5056e+00 (2.0578e+00)\tAcc@1  91.02 ( 61.31)\tAcc@5  98.44 ( 94.12)\n",
            "Epoch: [159][ 30/268]\tTime  0.431 ( 2.298)\tData  0.000 ( 1.913)\tLoss 1.5553e+00 (2.0722e+00)\tAcc@1  85.55 ( 59.72)\tAcc@5  98.44 ( 93.32)\n",
            "Epoch: [159][ 40/268]\tTime  0.427 ( 1.894)\tData  0.000 ( 1.507)\tLoss 1.9972e+00 (2.0559e+00)\tAcc@1  65.62 ( 60.57)\tAcc@5  97.27 ( 93.77)\n",
            "Epoch: [159][ 50/268]\tTime  1.279 ( 1.636)\tData  0.960 ( 1.251)\tLoss 1.8604e+00 (2.0470e+00)\tAcc@1  81.25 ( 61.93)\tAcc@5  96.48 ( 93.94)\n",
            "Epoch: [159][ 60/268]\tTime  1.489 ( 1.455)\tData  1.171 ( 1.067)\tLoss 2.0255e+00 (2.0917e+00)\tAcc@1  69.14 ( 59.86)\tAcc@5  95.70 ( 92.52)\n",
            "Epoch: [159][ 70/268]\tTime  0.426 ( 1.325)\tData  0.000 ( 0.935)\tLoss 1.6947e+00 (2.0947e+00)\tAcc@1  86.33 ( 59.66)\tAcc@5  96.09 ( 92.35)\n",
            "Epoch: [159][ 80/268]\tTime  0.424 ( 1.235)\tData  0.000 ( 0.845)\tLoss 1.7915e+00 (2.0685e+00)\tAcc@1  83.98 ( 61.28)\tAcc@5  98.44 ( 92.66)\n",
            "Epoch: [159][ 90/268]\tTime  0.412 ( 1.166)\tData  0.000 ( 0.776)\tLoss 2.4624e+00 (2.0681e+00)\tAcc@1  33.98 ( 61.42)\tAcc@5  85.55 ( 92.67)\n",
            "Epoch: [159][100/268]\tTime  0.416 ( 1.110)\tData  0.000 ( 0.720)\tLoss 2.0364e+00 (2.0671e+00)\tAcc@1  62.11 ( 61.48)\tAcc@5  94.92 ( 92.68)\n",
            "Epoch: [159][110/268]\tTime  1.074 ( 1.065)\tData  0.745 ( 0.676)\tLoss 1.7192e+00 (2.0772e+00)\tAcc@1  85.94 ( 61.06)\tAcc@5  96.88 ( 92.40)\n",
            "Epoch: [159][120/268]\tTime  1.664 ( 1.022)\tData  1.345 ( 0.633)\tLoss 1.4194e+00 (2.0819e+00)\tAcc@1  91.80 ( 60.96)\tAcc@5  98.05 ( 92.28)\n",
            "Epoch: [159][130/268]\tTime  0.426 ( 0.984)\tData  0.001 ( 0.594)\tLoss 1.9770e+00 (2.0690e+00)\tAcc@1  69.53 ( 61.76)\tAcc@5  94.53 ( 92.55)\n",
            "Epoch: [159][140/268]\tTime  0.423 ( 0.958)\tData  0.013 ( 0.568)\tLoss 2.0112e+00 (2.0578e+00)\tAcc@1  54.69 ( 62.43)\tAcc@5  94.92 ( 92.72)\n",
            "Epoch: [159][150/268]\tTime  0.416 ( 0.935)\tData  0.000 ( 0.546)\tLoss 2.0335e+00 (2.0583e+00)\tAcc@1  56.64 ( 62.32)\tAcc@5  96.88 ( 92.73)\n",
            "Epoch: [159][160/268]\tTime  0.422 ( 0.920)\tData  0.000 ( 0.531)\tLoss 1.9091e+00 (2.0579e+00)\tAcc@1  75.00 ( 62.65)\tAcc@5  94.53 ( 92.76)\n",
            "Epoch: [159][170/268]\tTime  2.561 ( 0.908)\tData  2.210 ( 0.518)\tLoss 2.3909e+00 (2.0642e+00)\tAcc@1  38.67 ( 62.21)\tAcc@5  88.28 ( 92.66)\n",
            "Epoch: [159][180/268]\tTime  0.410 ( 0.881)\tData  0.001 ( 0.490)\tLoss 2.4540e+00 (2.0677e+00)\tAcc@1  36.33 ( 61.93)\tAcc@5  87.11 ( 92.58)\n",
            "Epoch: [159][190/268]\tTime  0.416 ( 0.865)\tData  0.001 ( 0.474)\tLoss 2.3867e+00 (2.0695e+00)\tAcc@1  34.38 ( 61.77)\tAcc@5  85.16 ( 92.62)\n",
            "Epoch: [159][200/268]\tTime  0.423 ( 0.854)\tData  0.000 ( 0.462)\tLoss 2.4249e+00 (2.0663e+00)\tAcc@1  38.28 ( 62.01)\tAcc@5  86.72 ( 92.74)\n",
            "Epoch: [159][210/268]\tTime  0.416 ( 0.841)\tData  0.003 ( 0.450)\tLoss 2.4678e+00 (2.0716e+00)\tAcc@1  40.23 ( 61.70)\tAcc@5  83.98 ( 92.66)\n",
            "Epoch: [159][220/268]\tTime  0.416 ( 0.837)\tData  0.000 ( 0.445)\tLoss 1.7308e+00 (2.0760e+00)\tAcc@1  82.81 ( 61.39)\tAcc@5  96.48 ( 92.59)\n",
            "Epoch: [159][230/268]\tTime  1.801 ( 0.825)\tData  1.476 ( 0.432)\tLoss 1.6787e+00 (2.0661e+00)\tAcc@1  86.33 ( 61.91)\tAcc@5  98.44 ( 92.72)\n",
            "Epoch: [159][240/268]\tTime  0.410 ( 0.808)\tData  0.000 ( 0.415)\tLoss 2.5383e+00 (2.0642e+00)\tAcc@1  30.08 ( 61.95)\tAcc@5  83.59 ( 92.79)\n",
            "Epoch: [159][250/268]\tTime  0.416 ( 0.803)\tData  0.000 ( 0.409)\tLoss 2.4429e+00 (2.0639e+00)\tAcc@1  37.89 ( 62.03)\tAcc@5  86.33 ( 92.85)\n",
            "Epoch: [159][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.397)\tLoss 1.8443e+00 (2.0600e+00)\tAcc@1  73.83 ( 62.35)\tAcc@5  96.88 ( 92.94)\n",
            "epoch: 159\n",
            "2023-03-25 04:37:57.465919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:37:57.466015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:37:57.466034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:01.399692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:01.399819: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:01.399842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:05.364115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:05.364208: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:05.364225: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:09.317793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:09.317881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:09.317900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:13.257279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:13.257384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:13.257404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:17.200384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:17.200481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:17.200507: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:21.132704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:21.132805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:21.132823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:25.056006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:25.056109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:25.056127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:28.955215: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:28.955310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:28.955328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:32.845188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:32.845283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:32.845303: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:36.721328: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:36.721429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:36.721448: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:38:40.622576: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:40.622685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:38:40.622706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [160][  0/268]\tTime 54.285 (54.285)\tData 53.939 (53.939)\tLoss 2.0214e+00 (2.0214e+00)\tAcc@1  55.08 ( 55.08)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [160][ 10/268]\tTime  0.417 ( 5.368)\tData  0.008 ( 4.976)\tLoss 2.0077e+00 (1.9853e+00)\tAcc@1  61.33 ( 67.76)\tAcc@5  95.70 ( 94.50)\n",
            "Epoch: [160][ 20/268]\tTime  0.421 ( 3.087)\tData  0.000 ( 2.700)\tLoss 2.4188e+00 (2.0191e+00)\tAcc@1  33.20 ( 65.57)\tAcc@5  88.28 ( 94.07)\n",
            "Epoch: [160][ 30/268]\tTime  0.417 ( 2.299)\tData  0.012 ( 1.913)\tLoss 2.1694e+00 (1.9987e+00)\tAcc@1  56.25 ( 66.29)\tAcc@5  94.14 ( 94.43)\n",
            "Epoch: [160][ 40/268]\tTime  0.410 ( 1.883)\tData  0.000 ( 1.496)\tLoss 2.3036e+00 (1.9918e+00)\tAcc@1  39.84 ( 67.38)\tAcc@5  91.41 ( 94.70)\n",
            "Epoch: [160][ 50/268]\tTime  1.002 ( 1.637)\tData  0.677 ( 1.251)\tLoss 1.7399e+00 (1.9945e+00)\tAcc@1  75.39 ( 66.64)\tAcc@5  98.44 ( 94.58)\n",
            "Epoch: [160][ 60/268]\tTime  0.925 ( 1.445)\tData  0.591 ( 1.057)\tLoss 1.9493e+00 (2.0049e+00)\tAcc@1  69.14 ( 66.04)\tAcc@5  97.66 ( 94.51)\n",
            "Epoch: [160][ 70/268]\tTime  0.412 ( 1.319)\tData  0.000 ( 0.929)\tLoss 1.9983e+00 (2.0113e+00)\tAcc@1  60.55 ( 65.09)\tAcc@5  95.70 ( 94.36)\n",
            "Epoch: [160][ 80/268]\tTime  0.416 ( 1.240)\tData  0.000 ( 0.851)\tLoss 1.5053e+00 (2.0059e+00)\tAcc@1  85.55 ( 66.00)\tAcc@5  98.05 ( 94.45)\n",
            "Epoch: [160][ 90/268]\tTime  0.413 ( 1.168)\tData  0.000 ( 0.780)\tLoss 2.2674e+00 (2.0132e+00)\tAcc@1  56.64 ( 65.33)\tAcc@5  95.31 ( 94.27)\n",
            "Epoch: [160][100/268]\tTime  0.565 ( 1.115)\tData  0.241 ( 0.727)\tLoss 1.5507e+00 (2.0068e+00)\tAcc@1  88.67 ( 65.69)\tAcc@5 100.00 ( 94.35)\n",
            "Epoch: [160][110/268]\tTime  0.425 ( 1.070)\tData  0.009 ( 0.682)\tLoss 1.8684e+00 (1.9986e+00)\tAcc@1  84.77 ( 66.34)\tAcc@5  95.70 ( 94.43)\n",
            "Epoch: [160][120/268]\tTime  1.214 ( 1.024)\tData  0.877 ( 0.635)\tLoss 2.3140e+00 (2.0015e+00)\tAcc@1  50.78 ( 66.06)\tAcc@5  90.23 ( 94.31)\n",
            "Epoch: [160][130/268]\tTime  0.416 ( 0.983)\tData  0.000 ( 0.594)\tLoss 2.1312e+00 (1.9990e+00)\tAcc@1  56.64 ( 66.44)\tAcc@5  91.41 ( 94.45)\n",
            "Epoch: [160][140/268]\tTime  0.435 ( 0.959)\tData  0.000 ( 0.571)\tLoss 1.4576e+00 (1.9861e+00)\tAcc@1  92.58 ( 67.25)\tAcc@5  98.44 ( 94.58)\n",
            "Epoch: [160][150/268]\tTime  0.431 ( 0.939)\tData  0.000 ( 0.552)\tLoss 1.6480e+00 (1.9912e+00)\tAcc@1  83.20 ( 67.10)\tAcc@5 100.00 ( 94.32)\n",
            "Epoch: [160][160/268]\tTime  0.640 ( 0.917)\tData  0.322 ( 0.531)\tLoss 2.2994e+00 (1.9947e+00)\tAcc@1  44.14 ( 66.74)\tAcc@5  87.89 ( 94.25)\n",
            "Epoch: [160][170/268]\tTime  0.644 ( 0.897)\tData  0.316 ( 0.511)\tLoss 2.1572e+00 (2.0018e+00)\tAcc@1  53.52 ( 66.39)\tAcc@5  91.41 ( 94.16)\n",
            "Epoch: [160][180/268]\tTime  1.344 ( 0.881)\tData  1.026 ( 0.494)\tLoss 2.4104e+00 (2.0029e+00)\tAcc@1  49.22 ( 66.50)\tAcc@5  88.28 ( 94.12)\n",
            "Epoch: [160][190/268]\tTime  0.423 ( 0.863)\tData  0.000 ( 0.476)\tLoss 2.0703e+00 (2.0042e+00)\tAcc@1  64.06 ( 66.31)\tAcc@5  95.31 ( 94.07)\n",
            "Epoch: [160][200/268]\tTime  0.418 ( 0.850)\tData  0.000 ( 0.464)\tLoss 1.7788e+00 (2.0018e+00)\tAcc@1  73.05 ( 66.32)\tAcc@5  98.83 ( 94.11)\n",
            "Epoch: [160][210/268]\tTime  0.414 ( 0.842)\tData  0.000 ( 0.456)\tLoss 1.5016e+00 (2.0014e+00)\tAcc@1  89.84 ( 66.38)\tAcc@5  98.44 ( 94.15)\n",
            "Epoch: [160][220/268]\tTime  1.416 ( 0.831)\tData  1.098 ( 0.446)\tLoss 1.9162e+00 (2.0027e+00)\tAcc@1  66.80 ( 66.21)\tAcc@5  97.27 ( 94.17)\n",
            "Epoch: [160][230/268]\tTime  0.450 ( 0.820)\tData  0.113 ( 0.435)\tLoss 1.5250e+00 (2.0016e+00)\tAcc@1  86.33 ( 66.18)\tAcc@5  98.83 ( 94.15)\n",
            "Epoch: [160][240/268]\tTime  2.569 ( 0.813)\tData  2.220 ( 0.427)\tLoss 2.1298e+00 (2.0016e+00)\tAcc@1  50.00 ( 66.24)\tAcc@5  93.75 ( 94.19)\n",
            "Epoch: [160][250/268]\tTime  0.417 ( 0.797)\tData  0.000 ( 0.410)\tLoss 1.8025e+00 (2.0003e+00)\tAcc@1  81.25 ( 66.35)\tAcc@5  97.27 ( 94.22)\n",
            "Epoch: [160][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.404)\tLoss 1.6477e+00 (1.9966e+00)\tAcc@1  89.45 ( 66.66)\tAcc@5  98.05 ( 94.32)\n",
            "epoch: 160\n",
            "2023-03-25 04:41:28.445120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:28.445215: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:28.445235: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:32.431801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:32.431894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:32.431914: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:36.377290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:36.377386: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:36.377407: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:40.306211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:40.306305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:40.306323: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:44.251109: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:44.251212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:44.251232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:48.159899: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:48.159988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:48.160004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:52.090317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:52.090413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:52.090432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:56.068970: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:56.069068: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:56.069087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:41:59.968233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:59.968337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:41:59.968355: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:42:03.921192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:03.921290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:03.921309: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:42:07.880933: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:07.881029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:07.881048: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:42:11.775411: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:11.775521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:42:11.775541: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [161][  0/268]\tTime 55.082 (55.082)\tData 54.736 (54.736)\tLoss 2.2995e+00 (2.2995e+00)\tAcc@1  41.80 ( 41.80)\tAcc@5  90.23 ( 90.23)\n",
            "Epoch: [161][ 10/268]\tTime  0.424 ( 5.388)\tData  0.000 ( 4.987)\tLoss 1.9847e+00 (1.8734e+00)\tAcc@1  69.53 ( 74.04)\tAcc@5  97.27 ( 96.77)\n",
            "Epoch: [161][ 20/268]\tTime  0.417 ( 3.158)\tData  0.000 ( 2.757)\tLoss 1.9639e+00 (1.9123e+00)\tAcc@1  73.05 ( 71.26)\tAcc@5  98.05 ( 95.81)\n",
            "Epoch: [161][ 30/268]\tTime  0.430 ( 2.335)\tData  0.009 ( 1.933)\tLoss 2.4042e+00 (1.9936e+00)\tAcc@1  37.50 ( 65.94)\tAcc@5  86.33 ( 94.57)\n",
            "Epoch: [161][ 40/268]\tTime  0.417 ( 1.919)\tData  0.000 ( 1.518)\tLoss 1.8652e+00 (1.9892e+00)\tAcc@1  75.78 ( 67.00)\tAcc@5  96.88 ( 94.71)\n",
            "Epoch: [161][ 50/268]\tTime  0.417 ( 1.663)\tData  0.000 ( 1.262)\tLoss 1.7572e+00 (1.9870e+00)\tAcc@1  87.11 ( 67.26)\tAcc@5  98.44 ( 95.00)\n",
            "Epoch: [161][ 60/268]\tTime  2.570 ( 1.495)\tData  2.239 ( 1.094)\tLoss 1.8175e+00 (1.9768e+00)\tAcc@1  82.42 ( 67.93)\tAcc@5  97.27 ( 94.97)\n",
            "Epoch: [161][ 70/268]\tTime  0.416 ( 1.343)\tData  0.000 ( 0.941)\tLoss 2.0135e+00 (1.9672e+00)\tAcc@1  73.83 ( 69.00)\tAcc@5  96.48 ( 95.20)\n",
            "Epoch: [161][ 80/268]\tTime  0.417 ( 1.251)\tData  0.000 ( 0.849)\tLoss 1.9139e+00 (1.9663e+00)\tAcc@1  70.31 ( 68.96)\tAcc@5  96.88 ( 95.26)\n",
            "Epoch: [161][ 90/268]\tTime  0.417 ( 1.189)\tData  0.000 ( 0.787)\tLoss 1.8525e+00 (1.9770e+00)\tAcc@1  77.34 ( 68.38)\tAcc@5  98.44 ( 95.10)\n",
            "Epoch: [161][100/268]\tTime  0.427 ( 1.130)\tData  0.001 ( 0.729)\tLoss 2.2347e+00 (1.9704e+00)\tAcc@1  51.56 ( 68.42)\tAcc@5  91.80 ( 95.10)\n",
            "Epoch: [161][110/268]\tTime  0.416 ( 1.091)\tData  0.001 ( 0.689)\tLoss 2.2558e+00 (1.9784e+00)\tAcc@1  42.58 ( 67.74)\tAcc@5  89.84 ( 94.94)\n",
            "Epoch: [161][120/268]\tTime  1.956 ( 1.048)\tData  1.627 ( 0.647)\tLoss 1.6032e+00 (1.9870e+00)\tAcc@1  88.67 ( 67.17)\tAcc@5  98.83 ( 94.88)\n",
            "Epoch: [161][130/268]\tTime  0.416 ( 1.000)\tData  0.001 ( 0.598)\tLoss 2.1656e+00 (1.9932e+00)\tAcc@1  44.53 ( 66.65)\tAcc@5  93.36 ( 94.86)\n",
            "Epoch: [161][140/268]\tTime  0.411 ( 0.976)\tData  0.000 ( 0.574)\tLoss 1.6514e+00 (1.9901e+00)\tAcc@1  87.89 ( 66.72)\tAcc@5  98.44 ( 94.81)\n",
            "Epoch: [161][150/268]\tTime  0.420 ( 0.952)\tData  0.000 ( 0.551)\tLoss 1.9769e+00 (1.9848e+00)\tAcc@1  53.52 ( 67.01)\tAcc@5  96.09 ( 94.84)\n",
            "Epoch: [161][160/268]\tTime  0.422 ( 0.930)\tData  0.000 ( 0.529)\tLoss 1.7178e+00 (1.9718e+00)\tAcc@1  85.55 ( 67.63)\tAcc@5  97.66 ( 94.97)\n",
            "Epoch: [161][170/268]\tTime  0.418 ( 0.912)\tData  0.000 ( 0.511)\tLoss 2.2198e+00 (1.9664e+00)\tAcc@1  46.88 ( 67.99)\tAcc@5  91.02 ( 95.02)\n",
            "Epoch: [161][180/268]\tTime  2.729 ( 0.898)\tData  2.404 ( 0.497)\tLoss 1.9744e+00 (1.9705e+00)\tAcc@1  64.45 ( 67.65)\tAcc@5  97.27 ( 94.92)\n",
            "Epoch: [161][190/268]\tTime  0.420 ( 0.873)\tData  0.001 ( 0.471)\tLoss 1.7083e+00 (1.9701e+00)\tAcc@1  75.39 ( 67.58)\tAcc@5  96.88 ( 94.91)\n",
            "Epoch: [161][200/268]\tTime  0.410 ( 0.861)\tData  0.000 ( 0.460)\tLoss 2.0397e+00 (1.9745e+00)\tAcc@1  56.64 ( 67.43)\tAcc@5  94.92 ( 94.94)\n",
            "Epoch: [161][210/268]\tTime  0.440 ( 0.851)\tData  0.001 ( 0.450)\tLoss 1.8692e+00 (1.9745e+00)\tAcc@1  69.92 ( 67.41)\tAcc@5  96.48 ( 94.96)\n",
            "Epoch: [161][220/268]\tTime  0.417 ( 0.842)\tData  0.000 ( 0.441)\tLoss 2.3234e+00 (1.9785e+00)\tAcc@1  42.97 ( 67.18)\tAcc@5  89.84 ( 94.92)\n",
            "Epoch: [161][230/268]\tTime  0.417 ( 0.832)\tData  0.000 ( 0.431)\tLoss 1.7363e+00 (1.9735e+00)\tAcc@1  80.47 ( 67.39)\tAcc@5  97.27 ( 95.00)\n",
            "Epoch: [161][240/268]\tTime  2.207 ( 0.822)\tData  1.870 ( 0.421)\tLoss 2.0830e+00 (1.9792e+00)\tAcc@1  56.25 ( 67.02)\tAcc@5  95.70 ( 94.94)\n",
            "Epoch: [161][250/268]\tTime  0.417 ( 0.807)\tData  0.000 ( 0.405)\tLoss 1.7057e+00 (1.9761e+00)\tAcc@1  83.98 ( 67.21)\tAcc@5  98.44 ( 95.01)\n",
            "Epoch: [161][260/268]\tTime  0.415 ( 0.796)\tData  0.000 ( 0.394)\tLoss 2.3046e+00 (1.9754e+00)\tAcc@1  41.80 ( 67.19)\tAcc@5  89.45 ( 95.00)\n",
            "epoch: 161\n",
            "2023-03-25 04:45:00.698704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:00.698806: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:00.698825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:04.631179: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:04.631276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:04.631295: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:08.543555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:08.543669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:08.543690: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:12.444868: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:12.444963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:12.444982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:16.373699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:16.373807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:16.373825: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:20.345245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:20.345343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:20.345362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:24.203991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:24.204088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:24.204105: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:28.123687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:28.123789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:28.123809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:32.084738: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:32.084858: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:32.084880: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:35.981122: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:35.981247: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:35.981270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:39.876277: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:39.876395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:39.876418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:45:43.815615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:43.815750: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:45:43.815772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [162][  0/268]\tTime 54.647 (54.647)\tData 54.313 (54.313)\tLoss 2.2748e+00 (2.2748e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  88.67 ( 88.67)\n",
            "Epoch: [162][ 10/268]\tTime  0.497 ( 5.360)\tData  0.000 ( 4.947)\tLoss 1.6616e+00 (1.8846e+00)\tAcc@1  90.62 ( 73.86)\tAcc@5  98.83 ( 95.70)\n",
            "Epoch: [162][ 20/268]\tTime  0.417 ( 3.120)\tData  0.000 ( 2.712)\tLoss 2.3575e+00 (1.9803e+00)\tAcc@1  66.02 ( 69.98)\tAcc@5  89.45 ( 94.75)\n",
            "Epoch: [162][ 30/268]\tTime  0.425 ( 2.334)\tData  0.000 ( 1.929)\tLoss 2.3338e+00 (2.0370e+00)\tAcc@1  39.45 ( 65.36)\tAcc@5  87.11 ( 93.95)\n",
            "Epoch: [162][ 40/268]\tTime  0.423 ( 1.913)\tData  0.000 ( 1.509)\tLoss 1.8971e+00 (2.0363e+00)\tAcc@1  76.95 ( 64.86)\tAcc@5  95.31 ( 93.92)\n",
            "Epoch: [162][ 50/268]\tTime  0.417 ( 1.655)\tData  0.000 ( 1.251)\tLoss 1.8484e+00 (2.0159e+00)\tAcc@1  71.48 ( 66.24)\tAcc@5  97.66 ( 94.29)\n",
            "Epoch: [162][ 60/268]\tTime  2.719 ( 1.490)\tData  2.378 ( 1.087)\tLoss 1.9260e+00 (2.0298e+00)\tAcc@1  64.45 ( 65.75)\tAcc@5  96.48 ( 94.04)\n",
            "Epoch: [162][ 70/268]\tTime  0.423 ( 1.339)\tData  0.000 ( 0.935)\tLoss 2.1532e+00 (2.0298e+00)\tAcc@1  55.86 ( 65.89)\tAcc@5  93.36 ( 94.05)\n",
            "Epoch: [162][ 80/268]\tTime  0.420 ( 1.245)\tData  0.000 ( 0.843)\tLoss 1.7554e+00 (2.0165e+00)\tAcc@1  82.03 ( 66.58)\tAcc@5  95.70 ( 94.30)\n",
            "Epoch: [162][ 90/268]\tTime  0.416 ( 1.181)\tData  0.013 ( 0.778)\tLoss 2.2336e+00 (2.0100e+00)\tAcc@1  48.44 ( 66.58)\tAcc@5  93.75 ( 94.48)\n",
            "Epoch: [162][100/268]\tTime  0.417 ( 1.125)\tData  0.000 ( 0.723)\tLoss 1.9809e+00 (2.0056e+00)\tAcc@1  69.53 ( 66.47)\tAcc@5  95.70 ( 94.54)\n",
            "Epoch: [162][110/268]\tTime  0.427 ( 1.077)\tData  0.001 ( 0.675)\tLoss 1.9988e+00 (2.0186e+00)\tAcc@1  76.17 ( 66.45)\tAcc@5  94.53 ( 94.06)\n",
            "Epoch: [162][120/268]\tTime  2.291 ( 1.038)\tData  1.948 ( 0.636)\tLoss 2.2003e+00 (2.0143e+00)\tAcc@1  57.42 ( 66.51)\tAcc@5  94.92 ( 94.17)\n",
            "Epoch: [162][130/268]\tTime  0.417 ( 0.991)\tData  0.000 ( 0.589)\tLoss 2.0455e+00 (2.0088e+00)\tAcc@1  60.16 ( 66.90)\tAcc@5  94.14 ( 94.30)\n",
            "Epoch: [162][140/268]\tTime  0.433 ( 0.968)\tData  0.000 ( 0.566)\tLoss 1.9758e+00 (2.0171e+00)\tAcc@1  63.67 ( 66.35)\tAcc@5  96.48 ( 94.13)\n",
            "Epoch: [162][150/268]\tTime  0.421 ( 0.944)\tData  0.000 ( 0.543)\tLoss 1.8689e+00 (2.0143e+00)\tAcc@1  80.47 ( 66.37)\tAcc@5  96.88 ( 94.13)\n",
            "Epoch: [162][160/268]\tTime  0.416 ( 0.923)\tData  0.000 ( 0.523)\tLoss 1.6812e+00 (2.0078e+00)\tAcc@1  80.08 ( 66.81)\tAcc@5  98.83 ( 94.22)\n",
            "Epoch: [162][170/268]\tTime  0.443 ( 0.908)\tData  0.000 ( 0.507)\tLoss 1.7618e+00 (2.0042e+00)\tAcc@1  86.72 ( 66.84)\tAcc@5  96.09 ( 94.27)\n",
            "Epoch: [162][180/268]\tTime  2.498 ( 0.892)\tData  2.154 ( 0.492)\tLoss 1.7621e+00 (1.9992e+00)\tAcc@1  78.91 ( 67.03)\tAcc@5  97.27 ( 94.31)\n",
            "Epoch: [162][190/268]\tTime  0.442 ( 0.868)\tData  0.000 ( 0.466)\tLoss 1.5980e+00 (1.9996e+00)\tAcc@1  83.98 ( 66.91)\tAcc@5  98.44 ( 94.30)\n",
            "Epoch: [162][200/268]\tTime  0.417 ( 0.857)\tData  0.000 ( 0.456)\tLoss 1.8798e+00 (2.0035e+00)\tAcc@1  70.31 ( 66.69)\tAcc@5  95.70 ( 94.27)\n",
            "Epoch: [162][210/268]\tTime  0.417 ( 0.844)\tData  0.004 ( 0.443)\tLoss 1.8984e+00 (2.0046e+00)\tAcc@1  79.69 ( 66.59)\tAcc@5  96.88 ( 94.26)\n",
            "Epoch: [162][220/268]\tTime  0.411 ( 0.834)\tData  0.000 ( 0.433)\tLoss 1.8793e+00 (2.0069e+00)\tAcc@1  78.12 ( 66.45)\tAcc@5  95.31 ( 94.17)\n",
            "Epoch: [162][230/268]\tTime  0.415 ( 0.824)\tData  0.006 ( 0.423)\tLoss 1.5263e+00 (2.0047e+00)\tAcc@1  93.75 ( 66.48)\tAcc@5  98.05 ( 94.21)\n",
            "Epoch: [162][240/268]\tTime  2.983 ( 0.818)\tData  2.646 ( 0.417)\tLoss 2.0559e+00 (2.0073e+00)\tAcc@1  79.30 ( 66.32)\tAcc@5  94.92 ( 94.18)\n",
            "Epoch: [162][250/268]\tTime  0.417 ( 0.802)\tData  0.000 ( 0.401)\tLoss 1.8352e+00 (2.0031e+00)\tAcc@1  76.17 ( 66.53)\tAcc@5  96.88 ( 94.24)\n",
            "Epoch: [162][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.391)\tLoss 2.1988e+00 (2.0041e+00)\tAcc@1  48.05 ( 66.46)\tAcc@5  92.58 ( 94.26)\n",
            "epoch: 162\n",
            "2023-03-25 04:48:32.122148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:32.122248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:32.122267: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:36.055194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:36.055295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:36.055318: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:39.989765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:39.989867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:39.989886: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:43.962168: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:43.962270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:43.962291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:47.875669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:47.875768: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:47.875786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:51.765815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:51.765916: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:51.765935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:55.762148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:55.762248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:55.762268: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:48:59.669356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:59.669456: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:48:59.669474: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:49:03.543040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:03.543141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:03.543159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:49:07.475477: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:07.475584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:07.475604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:49:11.408027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:11.408125: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:11.408144: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:49:15.298427: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:15.298545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:49:15.298565: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [163][  0/268]\tTime 55.316 (55.316)\tData 54.951 (54.951)\tLoss 1.7498e+00 (1.7498e+00)\tAcc@1  77.34 ( 77.34)\tAcc@5  97.27 ( 97.27)\n",
            "Epoch: [163][ 10/268]\tTime  0.413 ( 5.414)\tData  0.000 ( 5.005)\tLoss 2.1270e+00 (2.1046e+00)\tAcc@1  53.52 ( 59.02)\tAcc@5  93.75 ( 93.22)\n",
            "Epoch: [163][ 20/268]\tTime  0.410 ( 3.122)\tData  0.000 ( 2.718)\tLoss 1.6733e+00 (1.9786e+00)\tAcc@1  89.45 ( 66.44)\tAcc@5  98.05 ( 94.55)\n",
            "Epoch: [163][ 30/268]\tTime  0.421 ( 2.308)\tData  0.000 ( 1.908)\tLoss 1.5965e+00 (2.0161e+00)\tAcc@1  88.67 ( 63.38)\tAcc@5  98.83 ( 93.99)\n",
            "Epoch: [163][ 40/268]\tTime  0.410 ( 1.894)\tData  0.000 ( 1.497)\tLoss 1.4658e+00 (1.9846e+00)\tAcc@1  94.92 ( 65.36)\tAcc@5  99.61 ( 94.46)\n",
            "Epoch: [163][ 50/268]\tTime  0.594 ( 1.637)\tData  0.255 ( 1.243)\tLoss 1.9962e+00 (1.9980e+00)\tAcc@1  75.78 ( 64.69)\tAcc@5  95.70 ( 94.16)\n",
            "Epoch: [163][ 60/268]\tTime  1.853 ( 1.461)\tData  1.523 ( 1.066)\tLoss 1.6932e+00 (1.9972e+00)\tAcc@1  79.69 ( 64.36)\tAcc@5  98.44 ( 94.12)\n",
            "Epoch: [163][ 70/268]\tTime  0.434 ( 1.344)\tData  0.001 ( 0.947)\tLoss 2.0256e+00 (2.0017e+00)\tAcc@1  62.11 ( 64.13)\tAcc@5  94.92 ( 94.15)\n",
            "Epoch: [163][ 80/268]\tTime  0.417 ( 1.255)\tData  0.000 ( 0.858)\tLoss 2.4064e+00 (2.0329e+00)\tAcc@1  40.62 ( 62.75)\tAcc@5  87.50 ( 93.75)\n",
            "Epoch: [163][ 90/268]\tTime  0.427 ( 1.187)\tData  0.000 ( 0.789)\tLoss 2.0628e+00 (2.0282e+00)\tAcc@1  77.34 ( 63.36)\tAcc@5  92.19 ( 93.84)\n",
            "Epoch: [163][100/268]\tTime  0.417 ( 1.136)\tData  0.000 ( 0.737)\tLoss 2.3539e+00 (2.0334e+00)\tAcc@1  43.36 ( 63.34)\tAcc@5  87.50 ( 93.80)\n",
            "Epoch: [163][110/268]\tTime  0.423 ( 1.089)\tData  0.000 ( 0.690)\tLoss 1.9424e+00 (2.0281e+00)\tAcc@1  76.17 ( 63.76)\tAcc@5  96.48 ( 93.77)\n",
            "Epoch: [163][120/268]\tTime  0.417 ( 1.034)\tData  0.000 ( 0.634)\tLoss 1.5413e+00 (2.0153e+00)\tAcc@1  83.20 ( 64.73)\tAcc@5  98.05 ( 93.98)\n",
            "Epoch: [163][130/268]\tTime  0.441 ( 1.002)\tData  0.000 ( 0.601)\tLoss 1.6310e+00 (2.0061e+00)\tAcc@1  83.98 ( 65.18)\tAcc@5  98.83 ( 94.05)\n",
            "Epoch: [163][140/268]\tTime  0.423 ( 0.976)\tData  0.009 ( 0.575)\tLoss 2.0781e+00 (2.0155e+00)\tAcc@1  53.12 ( 64.35)\tAcc@5  93.75 ( 93.93)\n",
            "Epoch: [163][150/268]\tTime  0.400 ( 0.950)\tData  0.000 ( 0.549)\tLoss 2.1967e+00 (2.0230e+00)\tAcc@1  48.83 ( 63.66)\tAcc@5  94.14 ( 93.76)\n",
            "Epoch: [163][160/268]\tTime  0.415 ( 0.932)\tData  0.000 ( 0.532)\tLoss 2.7813e+00 (2.0381e+00)\tAcc@1  46.09 ( 62.70)\tAcc@5  88.67 ( 93.51)\n",
            "Epoch: [163][170/268]\tTime  0.420 ( 0.911)\tData  0.006 ( 0.512)\tLoss 1.6324e+00 (2.0305e+00)\tAcc@1  87.50 ( 63.29)\tAcc@5  97.27 ( 93.62)\n",
            "Epoch: [163][180/268]\tTime  1.006 ( 0.888)\tData  0.680 ( 0.488)\tLoss 1.8517e+00 (2.0320e+00)\tAcc@1  85.94 ( 63.30)\tAcc@5  96.88 ( 93.60)\n",
            "Epoch: [163][190/268]\tTime  0.417 ( 0.871)\tData  0.000 ( 0.471)\tLoss 1.6456e+00 (2.0269e+00)\tAcc@1  78.52 ( 63.60)\tAcc@5  97.27 ( 93.65)\n",
            "Epoch: [163][200/268]\tTime  0.417 ( 0.858)\tData  0.000 ( 0.458)\tLoss 1.7792e+00 (2.0282e+00)\tAcc@1  83.98 ( 63.55)\tAcc@5  97.66 ( 93.62)\n",
            "Epoch: [163][210/268]\tTime  0.416 ( 0.849)\tData  0.000 ( 0.449)\tLoss 1.8559e+00 (2.0274e+00)\tAcc@1  71.48 ( 63.47)\tAcc@5  97.66 ( 93.62)\n",
            "Epoch: [163][220/268]\tTime  0.421 ( 0.836)\tData  0.001 ( 0.437)\tLoss 1.8989e+00 (2.0246e+00)\tAcc@1  67.58 ( 63.65)\tAcc@5  96.48 ( 93.64)\n",
            "Epoch: [163][230/268]\tTime  0.417 ( 0.826)\tData  0.000 ( 0.427)\tLoss 2.4152e+00 (2.0230e+00)\tAcc@1  37.11 ( 63.89)\tAcc@5  87.89 ( 93.66)\n",
            "Epoch: [163][240/268]\tTime  0.852 ( 0.811)\tData  0.520 ( 0.412)\tLoss 2.5115e+00 (2.0331e+00)\tAcc@1  35.16 ( 63.26)\tAcc@5  83.98 ( 93.56)\n",
            "Epoch: [163][250/268]\tTime  0.416 ( 0.800)\tData  0.000 ( 0.400)\tLoss 2.3917e+00 (2.0296e+00)\tAcc@1  36.33 ( 63.40)\tAcc@5  85.55 ( 93.58)\n",
            "Epoch: [163][260/268]\tTime  0.416 ( 0.791)\tData  0.000 ( 0.392)\tLoss 1.7736e+00 (2.0239e+00)\tAcc@1  82.81 ( 63.74)\tAcc@5  96.48 ( 93.62)\n",
            "epoch: 163\n",
            "2023-03-25 04:52:03.114170: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:03.114264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:03.114282: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:07.081811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:07.081913: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:07.081933: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:10.963063: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:10.963164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:10.963182: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:14.846670: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:14.846779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:14.846796: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:18.771364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:18.771464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:18.771482: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:22.684799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:22.684892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:22.684910: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:26.553776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:26.553874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:26.553891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:30.480242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:30.480344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:30.480363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:34.414002: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:34.414101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:34.414119: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:38.320950: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:38.321049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:38.321068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:42.243383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:42.243481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:42.243500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:52:46.263491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:46.263622: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:52:46.263642: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [164][  0/268]\tTime 54.647 (54.647)\tData 54.307 (54.307)\tLoss 2.0451e+00 (2.0451e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [164][ 10/268]\tTime  0.417 ( 5.445)\tData  0.009 ( 5.046)\tLoss 1.7364e+00 (1.9475e+00)\tAcc@1  79.30 ( 68.11)\tAcc@5  98.05 ( 94.60)\n",
            "Epoch: [164][ 20/268]\tTime  0.418 ( 3.139)\tData  0.000 ( 2.744)\tLoss 2.4256e+00 (1.9780e+00)\tAcc@1  34.77 ( 66.46)\tAcc@5  84.38 ( 94.27)\n",
            "Epoch: [164][ 30/268]\tTime  0.419 ( 2.320)\tData  0.012 ( 1.928)\tLoss 1.8422e+00 (1.9583e+00)\tAcc@1  88.28 ( 68.98)\tAcc@5  94.14 ( 94.52)\n",
            "Epoch: [164][ 40/268]\tTime  0.417 ( 1.908)\tData  0.000 ( 1.517)\tLoss 2.1847e+00 (1.9844e+00)\tAcc@1  68.75 ( 67.50)\tAcc@5  92.97 ( 94.01)\n",
            "Epoch: [164][ 50/268]\tTime  0.413 ( 1.656)\tData  0.000 ( 1.265)\tLoss 2.1478e+00 (2.0146e+00)\tAcc@1  47.27 ( 65.12)\tAcc@5  95.31 ( 93.67)\n",
            "Epoch: [164][ 60/268]\tTime  1.194 ( 1.467)\tData  0.874 ( 1.074)\tLoss 1.7300e+00 (2.0757e+00)\tAcc@1  83.59 ( 63.44)\tAcc@5  98.44 ( 92.07)\n",
            "Epoch: [164][ 70/268]\tTime  0.423 ( 1.333)\tData  0.000 ( 0.938)\tLoss 2.4303e+00 (2.0771e+00)\tAcc@1  40.23 ( 62.93)\tAcc@5  87.50 ( 92.21)\n",
            "Epoch: [164][ 80/268]\tTime  0.417 ( 1.246)\tData  0.000 ( 0.851)\tLoss 1.5130e+00 (2.0993e+00)\tAcc@1  89.06 ( 62.70)\tAcc@5  98.83 ( 91.42)\n",
            "Epoch: [164][ 90/268]\tTime  0.416 ( 1.179)\tData  0.000 ( 0.786)\tLoss 1.6422e+00 (2.0831e+00)\tAcc@1  87.89 ( 63.69)\tAcc@5  95.70 ( 91.61)\n",
            "Epoch: [164][100/268]\tTime  0.421 ( 1.127)\tData  0.000 ( 0.733)\tLoss 1.7838e+00 (2.0834e+00)\tAcc@1  85.94 ( 63.31)\tAcc@5  98.83 ( 91.64)\n",
            "Epoch: [164][110/268]\tTime  0.418 ( 1.081)\tData  0.000 ( 0.688)\tLoss 1.9178e+00 (2.0825e+00)\tAcc@1  79.30 ( 63.15)\tAcc@5  95.31 ( 91.77)\n",
            "Epoch: [164][120/268]\tTime  1.343 ( 1.034)\tData  1.015 ( 0.640)\tLoss 1.5497e+00 (2.0758e+00)\tAcc@1  85.55 ( 63.63)\tAcc@5  98.44 ( 91.92)\n",
            "Epoch: [164][130/268]\tTime  0.417 ( 0.993)\tData  0.000 ( 0.598)\tLoss 1.7633e+00 (2.0634e+00)\tAcc@1  87.11 ( 64.36)\tAcc@5  97.66 ( 92.23)\n",
            "Epoch: [164][140/268]\tTime  0.416 ( 0.967)\tData  0.011 ( 0.573)\tLoss 1.6490e+00 (2.0567e+00)\tAcc@1  83.59 ( 64.67)\tAcc@5  98.05 ( 92.40)\n",
            "Epoch: [164][150/268]\tTime  0.423 ( 0.945)\tData  0.000 ( 0.551)\tLoss 1.9328e+00 (2.0584e+00)\tAcc@1  69.92 ( 64.55)\tAcc@5  94.92 ( 92.32)\n",
            "Epoch: [164][160/268]\tTime  0.418 ( 0.925)\tData  0.000 ( 0.531)\tLoss 2.5182e+00 (2.0463e+00)\tAcc@1  42.97 ( 65.06)\tAcc@5  93.75 ( 92.54)\n",
            "Epoch: [164][170/268]\tTime  0.415 ( 0.905)\tData  0.000 ( 0.512)\tLoss 1.5651e+00 (2.0331e+00)\tAcc@1  84.77 ( 65.80)\tAcc@5  97.27 ( 92.78)\n",
            "Epoch: [164][180/268]\tTime  1.900 ( 0.887)\tData  1.582 ( 0.493)\tLoss 1.5744e+00 (2.0365e+00)\tAcc@1  91.02 ( 65.31)\tAcc@5  98.44 ( 92.77)\n",
            "Epoch: [164][190/268]\tTime  0.451 ( 0.865)\tData  0.000 ( 0.471)\tLoss 2.4560e+00 (2.0318e+00)\tAcc@1  37.11 ( 65.56)\tAcc@5  85.16 ( 92.89)\n",
            "Epoch: [164][200/268]\tTime  0.416 ( 0.854)\tData  0.000 ( 0.460)\tLoss 2.0027e+00 (2.0275e+00)\tAcc@1  75.00 ( 65.75)\tAcc@5  95.31 ( 93.01)\n",
            "Epoch: [164][210/268]\tTime  0.420 ( 0.843)\tData  0.000 ( 0.449)\tLoss 2.2079e+00 (2.0297e+00)\tAcc@1  75.00 ( 65.60)\tAcc@5  93.36 ( 92.99)\n",
            "Epoch: [164][220/268]\tTime  0.417 ( 0.833)\tData  0.000 ( 0.439)\tLoss 1.7080e+00 (2.0305e+00)\tAcc@1  83.20 ( 65.54)\tAcc@5  98.44 ( 92.99)\n",
            "Epoch: [164][230/268]\tTime  0.418 ( 0.824)\tData  0.000 ( 0.430)\tLoss 1.8403e+00 (2.0279e+00)\tAcc@1  81.25 ( 65.78)\tAcc@5  98.05 ( 93.05)\n",
            "Epoch: [164][240/268]\tTime  1.567 ( 0.812)\tData  1.240 ( 0.418)\tLoss 1.8213e+00 (2.0268e+00)\tAcc@1  76.95 ( 65.79)\tAcc@5  96.48 ( 93.09)\n",
            "Epoch: [164][250/268]\tTime  0.417 ( 0.800)\tData  0.000 ( 0.406)\tLoss 1.7148e+00 (2.0208e+00)\tAcc@1  79.69 ( 66.13)\tAcc@5  97.66 ( 93.21)\n",
            "Epoch: [164][260/268]\tTime  0.415 ( 0.789)\tData  0.000 ( 0.395)\tLoss 2.1428e+00 (2.0218e+00)\tAcc@1  53.52 ( 65.92)\tAcc@5  94.14 ( 93.20)\n",
            "epoch: 164\n",
            "2023-03-25 04:55:33.882975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:33.883079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:33.883099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:37.876390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:37.876492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:37.876517: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:41.842189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:41.842282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:41.842301: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:45.840840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:45.840934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:45.840953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:49.749222: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:49.749316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:49.749335: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:53.631331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:53.631430: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:53.631451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:55:57.552704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:57.552803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:55:57.552821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:56:01.481335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:01.481439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:01.481458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:56:05.387590: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:05.387700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:05.387721: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:56:09.349299: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:09.349400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:09.349418: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:56:13.241716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:13.241809: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:13.241827: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:56:17.168824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:17.168922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:56:17.168940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [165][  0/268]\tTime 54.908 (54.908)\tData 54.556 (54.556)\tLoss 1.5720e+00 (1.5720e+00)\tAcc@1  91.02 ( 91.02)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [165][ 10/268]\tTime  0.418 ( 5.375)\tData  0.000 ( 4.971)\tLoss 2.4431e+00 (1.8206e+00)\tAcc@1  37.50 ( 76.70)\tAcc@5  85.55 ( 96.52)\n",
            "Epoch: [165][ 20/268]\tTime  0.416 ( 3.110)\tData  0.001 ( 2.714)\tLoss 2.4131e+00 (1.8654e+00)\tAcc@1  39.45 ( 75.13)\tAcc@5  87.50 ( 95.63)\n",
            "Epoch: [165][ 30/268]\tTime  0.417 ( 2.302)\tData  0.001 ( 1.907)\tLoss 1.6787e+00 (1.9620e+00)\tAcc@1  86.33 ( 70.33)\tAcc@5  98.05 ( 93.37)\n",
            "Epoch: [165][ 40/268]\tTime  0.412 ( 1.891)\tData  0.000 ( 1.498)\tLoss 2.0605e+00 (1.9513e+00)\tAcc@1  57.81 ( 70.23)\tAcc@5  95.31 ( 93.87)\n",
            "Epoch: [165][ 50/268]\tTime  0.438 ( 1.622)\tData  0.000 ( 1.227)\tLoss 2.5414e+00 (2.0162e+00)\tAcc@1  21.88 ( 66.07)\tAcc@5  80.47 ( 92.93)\n",
            "Epoch: [165][ 60/268]\tTime  1.149 ( 1.454)\tData  0.824 ( 1.059)\tLoss 2.4285e+00 (2.0444e+00)\tAcc@1  36.72 ( 63.74)\tAcc@5  83.98 ( 92.58)\n",
            "Epoch: [165][ 70/268]\tTime  0.430 ( 1.325)\tData  0.013 ( 0.930)\tLoss 2.0266e+00 (2.0337e+00)\tAcc@1  67.58 ( 64.39)\tAcc@5  95.70 ( 92.95)\n",
            "Epoch: [165][ 80/268]\tTime  0.416 ( 1.239)\tData  0.000 ( 0.846)\tLoss 2.0720e+00 (2.0384e+00)\tAcc@1  68.75 ( 64.27)\tAcc@5  96.48 ( 93.07)\n",
            "Epoch: [165][ 90/268]\tTime  0.423 ( 1.166)\tData  0.000 ( 0.775)\tLoss 2.4558e+00 (2.0480e+00)\tAcc@1  35.55 ( 63.31)\tAcc@5  85.55 ( 92.98)\n",
            "Epoch: [165][100/268]\tTime  0.428 ( 1.111)\tData  0.000 ( 0.720)\tLoss 2.0156e+00 (2.0554e+00)\tAcc@1  56.25 ( 62.71)\tAcc@5  94.92 ( 92.93)\n",
            "Epoch: [165][110/268]\tTime  0.429 ( 1.075)\tData  0.000 ( 0.682)\tLoss 1.7120e+00 (2.0446e+00)\tAcc@1  80.47 ( 63.15)\tAcc@5  98.05 ( 93.13)\n",
            "Epoch: [165][120/268]\tTime  2.103 ( 1.035)\tData  1.785 ( 0.641)\tLoss 2.3690e+00 (2.0378e+00)\tAcc@1  39.06 ( 63.42)\tAcc@5  88.67 ( 93.23)\n",
            "Epoch: [165][130/268]\tTime  0.429 ( 0.988)\tData  0.000 ( 0.593)\tLoss 2.0363e+00 (2.0334e+00)\tAcc@1  76.56 ( 63.79)\tAcc@5  94.92 ( 93.31)\n",
            "Epoch: [165][140/268]\tTime  0.415 ( 0.964)\tData  0.000 ( 0.569)\tLoss 2.0251e+00 (2.0195e+00)\tAcc@1  71.09 ( 64.79)\tAcc@5  94.53 ( 93.51)\n",
            "Epoch: [165][150/268]\tTime  0.432 ( 0.942)\tData  0.000 ( 0.547)\tLoss 2.3144e+00 (2.0252e+00)\tAcc@1  42.58 ( 64.42)\tAcc@5  89.06 ( 93.46)\n",
            "Epoch: [165][160/268]\tTime  0.432 ( 0.926)\tData  0.000 ( 0.531)\tLoss 2.3625e+00 (2.0263e+00)\tAcc@1  55.47 ( 64.36)\tAcc@5  91.41 ( 93.47)\n",
            "Epoch: [165][170/268]\tTime  0.415 ( 0.904)\tData  0.013 ( 0.509)\tLoss 1.5692e+00 (2.0256e+00)\tAcc@1  90.23 ( 64.36)\tAcc@5  98.83 ( 93.43)\n",
            "Epoch: [165][180/268]\tTime  1.659 ( 0.888)\tData  1.341 ( 0.492)\tLoss 1.7326e+00 (2.0212e+00)\tAcc@1  81.64 ( 64.59)\tAcc@5  98.05 ( 93.55)\n",
            "Epoch: [165][190/268]\tTime  0.417 ( 0.867)\tData  0.009 ( 0.471)\tLoss 1.6558e+00 (2.0125e+00)\tAcc@1  84.77 ( 65.30)\tAcc@5  96.48 ( 93.69)\n",
            "Epoch: [165][200/268]\tTime  0.417 ( 0.853)\tData  0.000 ( 0.458)\tLoss 1.9497e+00 (2.0046e+00)\tAcc@1  59.77 ( 65.76)\tAcc@5  95.70 ( 93.83)\n",
            "Epoch: [165][210/268]\tTime  0.416 ( 0.843)\tData  0.013 ( 0.448)\tLoss 1.5703e+00 (2.0017e+00)\tAcc@1  85.16 ( 65.95)\tAcc@5  98.05 ( 93.91)\n",
            "Epoch: [165][220/268]\tTime  0.417 ( 0.834)\tData  0.013 ( 0.439)\tLoss 2.3882e+00 (2.0013e+00)\tAcc@1  51.95 ( 65.79)\tAcc@5  84.38 ( 93.89)\n",
            "Epoch: [165][230/268]\tTime  0.417 ( 0.822)\tData  0.000 ( 0.427)\tLoss 2.3330e+00 (1.9953e+00)\tAcc@1  41.80 ( 66.23)\tAcc@5  85.55 ( 94.01)\n",
            "Epoch: [165][240/268]\tTime  2.336 ( 0.815)\tData  2.011 ( 0.420)\tLoss 1.6206e+00 (1.9985e+00)\tAcc@1  87.50 ( 65.96)\tAcc@5  98.05 ( 93.88)\n",
            "Epoch: [165][250/268]\tTime  0.417 ( 0.801)\tData  0.000 ( 0.406)\tLoss 1.5075e+00 (1.9962e+00)\tAcc@1  91.80 ( 65.94)\tAcc@5  98.44 ( 93.91)\n",
            "Epoch: [165][260/268]\tTime  0.416 ( 0.790)\tData  0.000 ( 0.395)\tLoss 2.0942e+00 (1.9947e+00)\tAcc@1  66.41 ( 66.06)\tAcc@5  94.53 ( 93.99)\n",
            "epoch: 165\n",
            "2023-03-25 04:59:04.741266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:04.741369: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:04.741387: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:08.734157: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:08.734259: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:08.734279: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:12.654677: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:12.654770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:12.654790: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:16.600426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:16.600532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:16.600551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:20.527439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:20.527587: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:20.527616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:24.436540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:24.436641: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:24.436669: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:28.356781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:28.356882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:28.356900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:32.261980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:32.262081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:32.262099: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:36.163000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:36.163098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:36.163116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:40.069090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:40.069190: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:40.069211: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:43.972329: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:43.972433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:43.972452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 04:59:47.932835: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:47.932929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 04:59:47.932948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [166][  0/268]\tTime 54.186 (54.186)\tData 53.843 (53.843)\tLoss 1.6727e+00 (1.6727e+00)\tAcc@1  83.98 ( 83.98)\tAcc@5  98.83 ( 98.83)\n",
            "Epoch: [166][ 10/268]\tTime  0.417 ( 5.414)\tData  0.000 ( 5.010)\tLoss 2.0891e+00 (1.9240e+00)\tAcc@1  43.36 ( 68.29)\tAcc@5  94.92 ( 94.89)\n",
            "Epoch: [166][ 20/268]\tTime  0.425 ( 3.142)\tData  0.000 ( 2.738)\tLoss 1.6029e+00 (1.9517e+00)\tAcc@1  92.58 ( 67.41)\tAcc@5  98.83 ( 94.72)\n",
            "Epoch: [166][ 30/268]\tTime  0.416 ( 2.339)\tData  0.000 ( 1.936)\tLoss 1.7163e+00 (1.9103e+00)\tAcc@1  81.64 ( 71.17)\tAcc@5  96.88 ( 95.33)\n",
            "Epoch: [166][ 40/268]\tTime  0.423 ( 1.897)\tData  0.000 ( 1.494)\tLoss 2.0735e+00 (1.9685e+00)\tAcc@1  68.75 ( 66.58)\tAcc@5  93.75 ( 94.64)\n",
            "Epoch: [166][ 50/268]\tTime  0.443 ( 1.643)\tData  0.104 ( 1.242)\tLoss 1.8722e+00 (1.9736e+00)\tAcc@1  78.12 ( 66.70)\tAcc@5  96.09 ( 94.78)\n",
            "Epoch: [166][ 60/268]\tTime  2.588 ( 1.478)\tData  2.237 ( 1.077)\tLoss 1.9894e+00 (1.9805e+00)\tAcc@1  63.28 ( 66.53)\tAcc@5  97.66 ( 94.68)\n",
            "Epoch: [166][ 70/268]\tTime  0.422 ( 1.336)\tData  0.001 ( 0.936)\tLoss 2.0355e+00 (1.9817e+00)\tAcc@1  71.48 ( 66.61)\tAcc@5  94.14 ( 94.57)\n",
            "Epoch: [166][ 80/268]\tTime  0.424 ( 1.245)\tData  0.000 ( 0.846)\tLoss 1.9570e+00 (1.9868e+00)\tAcc@1  61.72 ( 66.52)\tAcc@5  95.31 ( 94.57)\n",
            "Epoch: [166][ 90/268]\tTime  0.422 ( 1.177)\tData  0.000 ( 0.778)\tLoss 1.9826e+00 (1.9902e+00)\tAcc@1  73.44 ( 66.41)\tAcc@5  96.09 ( 94.52)\n",
            "Epoch: [166][100/268]\tTime  0.423 ( 1.113)\tData  0.000 ( 0.714)\tLoss 2.3591e+00 (1.9858e+00)\tAcc@1  38.67 ( 66.90)\tAcc@5  85.16 ( 94.57)\n",
            "Epoch: [166][110/268]\tTime  1.175 ( 1.073)\tData  0.857 ( 0.674)\tLoss 1.9601e+00 (1.9843e+00)\tAcc@1  71.48 ( 66.66)\tAcc@5  96.88 ( 94.58)\n",
            "Epoch: [166][120/268]\tTime  1.946 ( 1.031)\tData  1.624 ( 0.633)\tLoss 2.2332e+00 (1.9826e+00)\tAcc@1  51.95 ( 67.01)\tAcc@5  89.84 ( 94.65)\n",
            "Epoch: [166][130/268]\tTime  0.417 ( 0.989)\tData  0.000 ( 0.590)\tLoss 1.6123e+00 (1.9996e+00)\tAcc@1  91.80 ( 65.72)\tAcc@5  97.27 ( 94.40)\n",
            "Epoch: [166][140/268]\tTime  0.418 ( 0.963)\tData  0.001 ( 0.565)\tLoss 2.3610e+00 (2.0082e+00)\tAcc@1  40.62 ( 65.25)\tAcc@5  87.50 ( 94.24)\n",
            "Epoch: [166][150/268]\tTime  0.417 ( 0.943)\tData  0.000 ( 0.546)\tLoss 2.3386e+00 (2.0081e+00)\tAcc@1  60.55 ( 65.31)\tAcc@5  89.84 ( 94.26)\n",
            "Epoch: [166][160/268]\tTime  0.420 ( 0.921)\tData  0.000 ( 0.524)\tLoss 2.3173e+00 (2.0023e+00)\tAcc@1  42.19 ( 65.57)\tAcc@5  89.45 ( 94.34)\n",
            "Epoch: [166][170/268]\tTime  1.244 ( 0.910)\tData  0.921 ( 0.513)\tLoss 2.3873e+00 (2.0098e+00)\tAcc@1  35.55 ( 65.03)\tAcc@5  87.50 ( 94.19)\n",
            "Epoch: [166][180/268]\tTime  1.760 ( 0.890)\tData  1.429 ( 0.493)\tLoss 2.0831e+00 (2.0091e+00)\tAcc@1  64.45 ( 65.15)\tAcc@5  93.75 ( 94.19)\n",
            "Epoch: [166][190/268]\tTime  0.432 ( 0.867)\tData  0.000 ( 0.470)\tLoss 1.9411e+00 (2.0065e+00)\tAcc@1  78.52 ( 65.27)\tAcc@5  96.48 ( 94.24)\n",
            "Epoch: [166][200/268]\tTime  0.417 ( 0.855)\tData  0.013 ( 0.458)\tLoss 1.6082e+00 (2.0061e+00)\tAcc@1  86.33 ( 65.35)\tAcc@5  98.44 ( 94.24)\n",
            "Epoch: [166][210/268]\tTime  0.416 ( 0.846)\tData  0.001 ( 0.449)\tLoss 1.9830e+00 (2.0029e+00)\tAcc@1  71.48 ( 65.56)\tAcc@5  96.48 ( 94.25)\n",
            "Epoch: [166][220/268]\tTime  0.417 ( 0.836)\tData  0.000 ( 0.439)\tLoss 2.2379e+00 (1.9953e+00)\tAcc@1  48.83 ( 66.07)\tAcc@5  93.75 ( 94.39)\n",
            "Epoch: [166][230/268]\tTime  0.430 ( 0.827)\tData  0.000 ( 0.429)\tLoss 1.8940e+00 (1.9885e+00)\tAcc@1  77.34 ( 66.45)\tAcc@5  96.09 ( 94.46)\n",
            "Epoch: [166][240/268]\tTime  2.971 ( 0.820)\tData  2.639 ( 0.423)\tLoss 2.4190e+00 (1.9934e+00)\tAcc@1  37.50 ( 66.19)\tAcc@5  87.89 ( 94.40)\n",
            "Epoch: [166][250/268]\tTime  0.416 ( 0.804)\tData  0.000 ( 0.407)\tLoss 1.8396e+00 (1.9948e+00)\tAcc@1  74.22 ( 66.06)\tAcc@5  96.09 ( 94.36)\n",
            "Epoch: [166][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.397)\tLoss 1.8297e+00 (1.9946e+00)\tAcc@1  75.78 ( 65.91)\tAcc@5  98.05 ( 94.35)\n",
            "epoch: 166\n",
            "2023-03-25 05:02:36.831099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:36.831197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:36.831218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:02:40.743143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:40.743249: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:40.743269: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:02:44.665023: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:44.665129: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:44.665147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:02:48.608263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:48.608358: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:48.608376: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:02:52.506468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:52.506583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:52.506603: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:02:56.395015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:56.395120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:02:56.395140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:00.314264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:00.314359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:00.314378: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:04.225844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:04.225938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:04.225958: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:08.167006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:08.167120: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:08.167139: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:12.080531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:12.080632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:12.080653: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:15.984882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:15.984980: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:15.984998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:03:19.895605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:19.895721: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:03:19.895741: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [167][  0/268]\tTime 55.576 (55.576)\tData 55.231 (55.231)\tLoss 1.7480e+00 (1.7480e+00)\tAcc@1  80.08 ( 80.08)\tAcc@5  98.05 ( 98.05)\n",
            "Epoch: [167][ 10/268]\tTime  0.416 ( 5.431)\tData  0.000 ( 5.032)\tLoss 1.9153e+00 (1.8809e+00)\tAcc@1  75.00 ( 75.78)\tAcc@5  96.09 ( 96.34)\n",
            "Epoch: [167][ 20/268]\tTime  0.439 ( 3.109)\tData  0.000 ( 2.714)\tLoss 2.4237e+00 (2.0011e+00)\tAcc@1  38.28 ( 67.62)\tAcc@5  87.11 ( 93.92)\n",
            "Epoch: [167][ 30/268]\tTime  0.416 ( 2.313)\tData  0.012 ( 1.916)\tLoss 1.9765e+00 (1.9944e+00)\tAcc@1  67.58 ( 67.26)\tAcc@5  95.70 ( 94.00)\n",
            "Epoch: [167][ 40/268]\tTime  0.422 ( 1.905)\tData  0.001 ( 1.508)\tLoss 1.6144e+00 (2.0094e+00)\tAcc@1  89.84 ( 65.49)\tAcc@5  98.44 ( 93.62)\n",
            "Epoch: [167][ 50/268]\tTime  0.410 ( 1.654)\tData  0.000 ( 1.256)\tLoss 1.5916e+00 (1.9801e+00)\tAcc@1  93.36 ( 67.26)\tAcc@5  97.27 ( 93.99)\n",
            "Epoch: [167][ 60/268]\tTime  1.401 ( 1.467)\tData  1.081 ( 1.070)\tLoss 1.7597e+00 (1.9655e+00)\tAcc@1  86.33 ( 68.20)\tAcc@5  97.66 ( 94.38)\n",
            "Epoch: [167][ 70/268]\tTime  0.426 ( 1.330)\tData  0.000 ( 0.931)\tLoss 1.6393e+00 (1.9692e+00)\tAcc@1  89.45 ( 67.71)\tAcc@5  99.22 ( 94.31)\n",
            "Epoch: [167][ 80/268]\tTime  0.417 ( 1.249)\tData  0.000 ( 0.850)\tLoss 1.8805e+00 (1.9703e+00)\tAcc@1  73.05 ( 67.40)\tAcc@5  95.31 ( 94.28)\n",
            "Epoch: [167][ 90/268]\tTime  0.415 ( 1.179)\tData  0.000 ( 0.781)\tLoss 2.2829e+00 (1.9661e+00)\tAcc@1  42.58 ( 67.41)\tAcc@5  88.28 ( 94.42)\n",
            "Epoch: [167][100/268]\tTime  0.416 ( 1.125)\tData  0.000 ( 0.726)\tLoss 2.5588e+00 (1.9880e+00)\tAcc@1  28.12 ( 66.17)\tAcc@5  81.64 ( 94.01)\n",
            "Epoch: [167][110/268]\tTime  0.417 ( 1.079)\tData  0.000 ( 0.681)\tLoss 1.8060e+00 (1.9713e+00)\tAcc@1  73.05 ( 67.13)\tAcc@5  98.44 ( 94.28)\n",
            "Epoch: [167][120/268]\tTime  1.198 ( 1.031)\tData  0.873 ( 0.633)\tLoss 1.9381e+00 (1.9650e+00)\tAcc@1  61.72 ( 67.42)\tAcc@5  96.09 ( 94.35)\n",
            "Epoch: [167][130/268]\tTime  0.418 ( 0.990)\tData  0.000 ( 0.591)\tLoss 2.3097e+00 (1.9732e+00)\tAcc@1  45.31 ( 66.95)\tAcc@5  89.84 ( 94.30)\n",
            "Epoch: [167][140/268]\tTime  0.413 ( 0.968)\tData  0.000 ( 0.569)\tLoss 2.3485e+00 (1.9770e+00)\tAcc@1  51.95 ( 66.60)\tAcc@5  91.02 ( 94.29)\n",
            "Epoch: [167][150/268]\tTime  0.424 ( 0.941)\tData  0.000 ( 0.542)\tLoss 1.6436e+00 (1.9744e+00)\tAcc@1  87.11 ( 66.60)\tAcc@5  98.83 ( 94.36)\n",
            "Epoch: [167][160/268]\tTime  0.423 ( 0.919)\tData  0.000 ( 0.521)\tLoss 2.0338e+00 (1.9735e+00)\tAcc@1  55.86 ( 66.66)\tAcc@5  93.36 ( 94.37)\n",
            "Epoch: [167][170/268]\tTime  0.418 ( 0.904)\tData  0.000 ( 0.507)\tLoss 2.0641e+00 (1.9692e+00)\tAcc@1  49.61 ( 66.89)\tAcc@5  95.31 ( 94.46)\n",
            "Epoch: [167][180/268]\tTime  1.033 ( 0.881)\tData  0.715 ( 0.483)\tLoss 1.7215e+00 (1.9741e+00)\tAcc@1  86.72 ( 66.70)\tAcc@5  95.70 ( 94.36)\n",
            "Epoch: [167][190/268]\tTime  0.427 ( 0.868)\tData  0.000 ( 0.470)\tLoss 1.5886e+00 (1.9697e+00)\tAcc@1  87.11 ( 66.81)\tAcc@5  98.83 ( 94.45)\n",
            "Epoch: [167][200/268]\tTime  0.422 ( 0.854)\tData  0.000 ( 0.456)\tLoss 1.7619e+00 (1.9700e+00)\tAcc@1  78.52 ( 66.76)\tAcc@5  97.66 ( 94.42)\n",
            "Epoch: [167][210/268]\tTime  0.417 ( 0.845)\tData  0.000 ( 0.446)\tLoss 1.6134e+00 (1.9764e+00)\tAcc@1  88.67 ( 66.23)\tAcc@5  97.27 ( 94.26)\n",
            "Epoch: [167][220/268]\tTime  0.416 ( 0.834)\tData  0.000 ( 0.436)\tLoss 1.8698e+00 (1.9778e+00)\tAcc@1  80.86 ( 66.21)\tAcc@5  96.88 ( 94.28)\n",
            "Epoch: [167][230/268]\tTime  0.417 ( 0.826)\tData  0.000 ( 0.427)\tLoss 1.6097e+00 (1.9796e+00)\tAcc@1  89.84 ( 66.09)\tAcc@5  99.22 ( 94.26)\n",
            "Epoch: [167][240/268]\tTime  0.417 ( 0.809)\tData  0.000 ( 0.410)\tLoss 2.3407e+00 (1.9838e+00)\tAcc@1  39.06 ( 65.95)\tAcc@5  90.23 ( 94.23)\n",
            "Epoch: [167][250/268]\tTime  0.416 ( 0.801)\tData  0.000 ( 0.402)\tLoss 1.6063e+00 (1.9801e+00)\tAcc@1  82.03 ( 66.20)\tAcc@5  96.88 ( 94.29)\n",
            "Epoch: [167][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.392)\tLoss 1.6821e+00 (1.9835e+00)\tAcc@1  92.19 ( 66.07)\tAcc@5  98.05 ( 94.20)\n",
            "epoch: 167\n",
            "2023-03-25 05:06:08.022301: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:08.022404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:08.022422: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:11.960521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:11.960628: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:11.960648: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:15.890289: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:15.890382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:15.890398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:19.782198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:19.782297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:19.782315: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:23.700126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:23.700224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:23.700241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:27.605406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:27.605512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:27.605530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:31.532407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:31.532508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:31.532526: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:35.466060: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:35.466159: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:35.466178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:39.412505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:39.412605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:39.412624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:43.310197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:43.310293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:43.310311: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:47.240807: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:47.240899: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:47.240918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:06:51.173866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:51.173995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:06:51.174014: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [168][  0/268]\tTime 54.228 (54.228)\tData 53.877 (53.877)\tLoss 2.0770e+00 (2.0770e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  93.36 ( 93.36)\n",
            "Epoch: [168][ 10/268]\tTime  0.416 ( 5.485)\tData  0.000 ( 5.081)\tLoss 1.5736e+00 (2.0684e+00)\tAcc@1  91.02 ( 65.66)\tAcc@5  98.05 ( 93.75)\n",
            "Epoch: [168][ 20/268]\tTime  0.416 ( 3.157)\tData  0.000 ( 2.762)\tLoss 1.8960e+00 (1.9954e+00)\tAcc@1  85.94 ( 68.19)\tAcc@5  97.27 ( 94.42)\n",
            "Epoch: [168][ 30/268]\tTime  0.412 ( 2.325)\tData  0.000 ( 1.930)\tLoss 1.7936e+00 (1.9371e+00)\tAcc@1  80.86 ( 70.79)\tAcc@5  97.27 ( 95.05)\n",
            "Epoch: [168][ 40/268]\tTime  0.416 ( 1.912)\tData  0.000 ( 1.519)\tLoss 1.7156e+00 (1.9136e+00)\tAcc@1  86.33 ( 71.93)\tAcc@5  98.44 ( 95.64)\n",
            "Epoch: [168][ 50/268]\tTime  0.424 ( 1.660)\tData  0.000 ( 1.266)\tLoss 2.2060e+00 (1.9141e+00)\tAcc@1  48.44 ( 71.92)\tAcc@5  92.97 ( 95.50)\n",
            "Epoch: [168][ 60/268]\tTime  2.331 ( 1.488)\tData  1.989 ( 1.094)\tLoss 1.7397e+00 (1.8889e+00)\tAcc@1  84.38 ( 73.89)\tAcc@5  96.48 ( 95.83)\n",
            "Epoch: [168][ 70/268]\tTime  0.416 ( 1.341)\tData  0.002 ( 0.945)\tLoss 1.8952e+00 (1.8943e+00)\tAcc@1  89.45 ( 74.12)\tAcc@5  93.75 ( 95.87)\n",
            "Epoch: [168][ 80/268]\tTime  0.444 ( 1.246)\tData  0.000 ( 0.849)\tLoss 1.6758e+00 (1.9155e+00)\tAcc@1  86.33 ( 72.29)\tAcc@5  99.61 ( 95.66)\n",
            "Epoch: [168][ 90/268]\tTime  0.416 ( 1.185)\tData  0.000 ( 0.787)\tLoss 1.9068e+00 (1.9036e+00)\tAcc@1  81.64 ( 72.65)\tAcc@5  95.70 ( 95.85)\n",
            "Epoch: [168][100/268]\tTime  0.421 ( 1.129)\tData  0.000 ( 0.731)\tLoss 1.9886e+00 (1.8956e+00)\tAcc@1  57.03 ( 72.63)\tAcc@5  96.09 ( 95.91)\n",
            "Epoch: [168][110/268]\tTime  0.420 ( 1.084)\tData  0.000 ( 0.685)\tLoss 1.8488e+00 (1.9006e+00)\tAcc@1  75.78 ( 72.30)\tAcc@5  96.88 ( 95.79)\n",
            "Epoch: [168][120/268]\tTime  2.239 ( 1.044)\tData  1.921 ( 0.645)\tLoss 2.2170e+00 (1.9280e+00)\tAcc@1  62.11 ( 71.26)\tAcc@5  91.80 ( 95.00)\n",
            "Epoch: [168][130/268]\tTime  0.411 ( 0.996)\tData  0.000 ( 0.597)\tLoss 2.0463e+00 (1.9298e+00)\tAcc@1  55.08 ( 70.95)\tAcc@5  95.70 ( 95.01)\n",
            "Epoch: [168][140/268]\tTime  0.408 ( 0.969)\tData  0.009 ( 0.570)\tLoss 2.6217e+00 (1.9429e+00)\tAcc@1  32.81 ( 70.06)\tAcc@5  91.02 ( 94.87)\n",
            "Epoch: [168][150/268]\tTime  0.416 ( 0.945)\tData  0.010 ( 0.546)\tLoss 2.4006e+00 (1.9488e+00)\tAcc@1  42.19 ( 69.47)\tAcc@5  83.20 ( 94.72)\n",
            "Epoch: [168][160/268]\tTime  0.416 ( 0.922)\tData  0.000 ( 0.523)\tLoss 2.4639e+00 (1.9439e+00)\tAcc@1  41.41 ( 69.64)\tAcc@5  85.94 ( 94.78)\n",
            "Epoch: [168][170/268]\tTime  0.551 ( 0.907)\tData  0.233 ( 0.509)\tLoss 2.3658e+00 (1.9497e+00)\tAcc@1  42.97 ( 69.29)\tAcc@5  87.11 ( 94.75)\n",
            "Epoch: [168][180/268]\tTime  1.786 ( 0.888)\tData  1.468 ( 0.490)\tLoss 1.9497e+00 (1.9581e+00)\tAcc@1  66.41 ( 68.92)\tAcc@5  95.70 ( 94.62)\n",
            "Epoch: [168][190/268]\tTime  0.416 ( 0.866)\tData  0.000 ( 0.468)\tLoss 1.9783e+00 (1.9512e+00)\tAcc@1  71.09 ( 69.47)\tAcc@5  93.36 ( 94.72)\n",
            "Epoch: [168][200/268]\tTime  0.416 ( 0.855)\tData  0.000 ( 0.457)\tLoss 2.0710e+00 (1.9547e+00)\tAcc@1  81.64 ( 69.35)\tAcc@5  95.31 ( 94.70)\n",
            "Epoch: [168][210/268]\tTime  0.414 ( 0.842)\tData  0.000 ( 0.445)\tLoss 1.9357e+00 (1.9573e+00)\tAcc@1  80.86 ( 69.09)\tAcc@5  94.14 ( 94.67)\n",
            "Epoch: [168][220/268]\tTime  0.416 ( 0.836)\tData  0.000 ( 0.439)\tLoss 1.9283e+00 (1.9533e+00)\tAcc@1  58.59 ( 69.28)\tAcc@5  97.66 ( 94.75)\n",
            "Epoch: [168][230/268]\tTime  0.433 ( 0.826)\tData  0.000 ( 0.428)\tLoss 4.2921e+00 (1.9598e+00)\tAcc@1   0.39 ( 69.16)\tAcc@5  25.00 ( 94.52)\n",
            "Epoch: [168][240/268]\tTime  2.424 ( 0.817)\tData  2.087 ( 0.419)\tLoss 1.9539e+00 (1.9562e+00)\tAcc@1  60.55 ( 69.25)\tAcc@5  96.09 ( 94.58)\n",
            "Epoch: [168][250/268]\tTime  0.417 ( 0.801)\tData  0.000 ( 0.403)\tLoss 2.2469e+00 (1.9590e+00)\tAcc@1  43.75 ( 68.94)\tAcc@5  88.67 ( 94.57)\n",
            "Epoch: [168][260/268]\tTime  0.416 ( 0.791)\tData  0.000 ( 0.393)\tLoss 1.9651e+00 (1.9624e+00)\tAcc@1  55.86 ( 68.59)\tAcc@5  96.88 ( 94.55)\n",
            "epoch: 168\n",
            "2023-03-25 05:09:39.254014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:39.254114: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:39.254133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:09:43.203539: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:43.203637: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:43.203667: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:09:47.178017: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:47.178116: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:47.178135: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:09:51.149295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:51.149394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:51.149414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:09:55.142520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:55.142619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:55.142637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:09:59.102428: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:59.102529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:09:59.102547: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:03.019448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:03.019558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:03.019579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:06.928073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:06.928178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:06.928199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:10.858983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:10.859082: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:10.859101: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:14.777031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:14.777130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:14.777149: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:18.667776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:18.667872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:18.667890: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:10:22.576910: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:22.577016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:10:22.577036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [169][  0/268]\tTime 54.667 (54.667)\tData 54.307 (54.307)\tLoss 2.1183e+00 (2.1183e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  94.14 ( 94.14)\n",
            "Epoch: [169][ 10/268]\tTime  0.424 ( 5.450)\tData  0.000 ( 5.046)\tLoss 2.2445e+00 (2.0318e+00)\tAcc@1  51.17 ( 64.28)\tAcc@5  92.19 ( 94.35)\n",
            "Epoch: [169][ 20/268]\tTime  0.417 ( 3.125)\tData  0.000 ( 2.727)\tLoss 1.5939e+00 (1.9735e+00)\tAcc@1  91.80 ( 67.89)\tAcc@5  98.05 ( 94.77)\n",
            "Epoch: [169][ 30/268]\tTime  0.420 ( 2.297)\tData  0.000 ( 1.901)\tLoss 2.2936e+00 (1.9955e+00)\tAcc@1  42.97 ( 66.31)\tAcc@5  88.67 ( 94.48)\n",
            "Epoch: [169][ 40/268]\tTime  0.410 ( 1.903)\tData  0.000 ( 1.508)\tLoss 2.1673e+00 (2.0660e+00)\tAcc@1  56.64 ( 61.67)\tAcc@5  90.23 ( 92.94)\n",
            "Epoch: [169][ 50/268]\tTime  0.422 ( 1.648)\tData  0.000 ( 1.254)\tLoss 2.0532e+00 (2.0474e+00)\tAcc@1  62.11 ( 63.17)\tAcc@5  96.88 ( 93.21)\n",
            "Epoch: [169][ 60/268]\tTime  2.143 ( 1.475)\tData  1.824 ( 1.080)\tLoss 2.2550e+00 (2.0442e+00)\tAcc@1  51.56 ( 63.22)\tAcc@5  94.92 ( 93.33)\n",
            "Epoch: [169][ 70/268]\tTime  0.424 ( 1.334)\tData  0.000 ( 0.938)\tLoss 2.2968e+00 (2.0379e+00)\tAcc@1  40.62 ( 63.66)\tAcc@5  88.67 ( 93.50)\n",
            "Epoch: [169][ 80/268]\tTime  0.416 ( 1.249)\tData  0.000 ( 0.854)\tLoss 2.5748e+00 (2.0591e+00)\tAcc@1  44.14 ( 62.56)\tAcc@5  92.97 ( 93.46)\n",
            "Epoch: [169][ 90/268]\tTime  0.411 ( 1.181)\tData  0.000 ( 0.786)\tLoss 1.7916e+00 (2.0531e+00)\tAcc@1  85.16 ( 62.92)\tAcc@5  96.88 ( 93.38)\n",
            "Epoch: [169][100/268]\tTime  0.416 ( 1.125)\tData  0.000 ( 0.730)\tLoss 1.7573e+00 (2.0296e+00)\tAcc@1  81.25 ( 64.27)\tAcc@5  97.66 ( 93.60)\n",
            "Epoch: [169][110/268]\tTime  0.418 ( 1.075)\tData  0.013 ( 0.681)\tLoss 1.9901e+00 (2.0361e+00)\tAcc@1  76.56 ( 63.88)\tAcc@5  96.48 ( 93.63)\n",
            "Epoch: [169][120/268]\tTime  1.807 ( 1.032)\tData  1.485 ( 0.638)\tLoss 1.7655e+00 (2.0171e+00)\tAcc@1  80.47 ( 65.06)\tAcc@5  95.31 ( 93.88)\n",
            "Epoch: [169][130/268]\tTime  0.412 ( 0.994)\tData  0.000 ( 0.598)\tLoss 1.9440e+00 (2.0093e+00)\tAcc@1  71.09 ( 65.45)\tAcc@5  94.14 ( 93.98)\n",
            "Epoch: [169][140/268]\tTime  0.422 ( 0.965)\tData  0.000 ( 0.570)\tLoss 1.4015e+00 (2.0048e+00)\tAcc@1  92.58 ( 65.52)\tAcc@5  98.44 ( 94.01)\n",
            "Epoch: [169][150/268]\tTime  0.417 ( 0.942)\tData  0.000 ( 0.547)\tLoss 2.0695e+00 (2.0099e+00)\tAcc@1  65.62 ( 65.30)\tAcc@5  94.14 ( 93.88)\n",
            "Epoch: [169][160/268]\tTime  0.416 ( 0.923)\tData  0.000 ( 0.528)\tLoss 1.9132e+00 (2.0064e+00)\tAcc@1  78.12 ( 65.53)\tAcc@5  96.09 ( 93.93)\n",
            "Epoch: [169][170/268]\tTime  0.417 ( 0.904)\tData  0.000 ( 0.509)\tLoss 2.0358e+00 (2.0079e+00)\tAcc@1  70.31 ( 65.56)\tAcc@5  96.09 ( 93.90)\n",
            "Epoch: [169][180/268]\tTime  0.623 ( 0.882)\tData  0.301 ( 0.488)\tLoss 2.2956e+00 (2.0045e+00)\tAcc@1  42.58 ( 65.60)\tAcc@5  89.06 ( 93.98)\n",
            "Epoch: [169][190/268]\tTime  0.416 ( 0.868)\tData  0.000 ( 0.473)\tLoss 2.0487e+00 (1.9987e+00)\tAcc@1  60.16 ( 65.93)\tAcc@5  94.14 ( 94.07)\n",
            "Epoch: [169][200/268]\tTime  0.418 ( 0.856)\tData  0.000 ( 0.462)\tLoss 1.7008e+00 (1.9946e+00)\tAcc@1  78.52 ( 66.23)\tAcc@5  97.27 ( 94.15)\n",
            "Epoch: [169][210/268]\tTime  0.417 ( 0.846)\tData  0.000 ( 0.453)\tLoss 1.9098e+00 (1.9963e+00)\tAcc@1  76.17 ( 66.13)\tAcc@5  97.66 ( 94.04)\n",
            "Epoch: [169][220/268]\tTime  1.430 ( 0.836)\tData  1.108 ( 0.443)\tLoss 2.3151e+00 (1.9932e+00)\tAcc@1  42.19 ( 66.17)\tAcc@5  89.84 ( 94.06)\n",
            "Epoch: [169][230/268]\tTime  0.417 ( 0.824)\tData  0.000 ( 0.432)\tLoss 1.6675e+00 (1.9803e+00)\tAcc@1  88.28 ( 66.94)\tAcc@5  97.66 ( 94.23)\n",
            "Epoch: [169][240/268]\tTime  0.960 ( 0.813)\tData  0.629 ( 0.421)\tLoss 1.7144e+00 (1.9799e+00)\tAcc@1  77.34 ( 66.90)\tAcc@5  98.05 ( 94.27)\n",
            "Epoch: [169][250/268]\tTime  0.435 ( 0.804)\tData  0.000 ( 0.411)\tLoss 1.7659e+00 (1.9809e+00)\tAcc@1  80.86 ( 66.67)\tAcc@5  97.27 ( 94.29)\n",
            "Epoch: [169][260/268]\tTime  0.415 ( 0.792)\tData  0.000 ( 0.400)\tLoss 1.8792e+00 (1.9811e+00)\tAcc@1  78.12 ( 66.59)\tAcc@5  96.09 ( 94.30)\n",
            "epoch: 169\n",
            "2023-03-25 05:13:10.648598: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:10.648712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:10.648730: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:14.620787: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:14.620884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:14.620903: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:18.606349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:18.606444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:18.606461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:22.569039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:22.569135: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:22.569153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:26.529816: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:26.529944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:26.529962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:30.453530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:30.453632: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:30.453652: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:34.393130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:34.393232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:34.393250: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:38.344585: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:38.344697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:38.344717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:42.250724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:42.250820: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:42.250839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:46.158927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:46.159044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:46.159067: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:50.132748: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:50.132844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:50.132862: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:13:54.065873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:54.065968: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:13:54.065985: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [170][  0/268]\tTime 55.684 (55.684)\tData 55.324 (55.324)\tLoss 1.7291e+00 (1.7291e+00)\tAcc@1  89.06 ( 89.06)\tAcc@5  96.48 ( 96.48)\n",
            "Epoch: [170][ 10/268]\tTime  0.416 ( 5.496)\tData  0.000 ( 5.094)\tLoss 1.8178e+00 (2.1273e+00)\tAcc@1  72.27 ( 63.03)\tAcc@5  97.66 ( 92.44)\n",
            "Epoch: [170][ 20/268]\tTime  0.457 ( 3.181)\tData  0.000 ( 2.777)\tLoss 1.6942e+00 (2.0883e+00)\tAcc@1  87.11 ( 62.59)\tAcc@5  97.66 ( 92.52)\n",
            "Epoch: [170][ 30/268]\tTime  0.417 ( 2.361)\tData  0.000 ( 1.959)\tLoss 2.0891e+00 (2.0694e+00)\tAcc@1  74.61 ( 63.72)\tAcc@5  94.92 ( 92.87)\n",
            "Epoch: [170][ 40/268]\tTime  0.423 ( 1.923)\tData  0.000 ( 1.522)\tLoss 2.2707e+00 (2.0186e+00)\tAcc@1  38.67 ( 65.88)\tAcc@5  89.45 ( 93.70)\n",
            "Epoch: [170][ 50/268]\tTime  0.416 ( 1.663)\tData  0.000 ( 1.263)\tLoss 2.3418e+00 (2.0029e+00)\tAcc@1  46.09 ( 66.81)\tAcc@5  86.72 ( 93.87)\n",
            "Epoch: [170][ 60/268]\tTime  2.458 ( 1.493)\tData  2.114 ( 1.093)\tLoss 2.3184e+00 (1.9991e+00)\tAcc@1  39.45 ( 66.71)\tAcc@5  86.33 ( 93.93)\n",
            "Epoch: [170][ 70/268]\tTime  0.424 ( 1.341)\tData  0.000 ( 0.940)\tLoss 2.1471e+00 (2.0069e+00)\tAcc@1  52.34 ( 66.57)\tAcc@5  93.36 ( 93.77)\n",
            "Epoch: [170][ 80/268]\tTime  0.429 ( 1.262)\tData  0.000 ( 0.861)\tLoss 2.0819e+00 (1.9930e+00)\tAcc@1  55.86 ( 67.11)\tAcc@5  94.14 ( 94.08)\n",
            "Epoch: [170][ 90/268]\tTime  0.410 ( 1.196)\tData  0.001 ( 0.795)\tLoss 1.8742e+00 (2.0030e+00)\tAcc@1  77.34 ( 66.46)\tAcc@5  98.05 ( 94.00)\n",
            "Epoch: [170][100/268]\tTime  0.429 ( 1.141)\tData  0.000 ( 0.740)\tLoss 1.5930e+00 (2.0086e+00)\tAcc@1  92.58 ( 65.86)\tAcc@5  97.27 ( 93.80)\n",
            "Epoch: [170][110/268]\tTime  0.442 ( 1.094)\tData  0.000 ( 0.693)\tLoss 2.7027e+00 (2.0050e+00)\tAcc@1  13.67 ( 65.88)\tAcc@5  76.17 ( 93.78)\n",
            "Epoch: [170][120/268]\tTime  2.362 ( 1.054)\tData  2.020 ( 0.653)\tLoss 2.0589e+00 (2.0213e+00)\tAcc@1  64.45 ( 65.01)\tAcc@5  94.14 ( 93.61)\n",
            "Epoch: [170][130/268]\tTime  0.420 ( 1.006)\tData  0.010 ( 0.604)\tLoss 1.8299e+00 (2.0053e+00)\tAcc@1  78.52 ( 65.83)\tAcc@5  96.48 ( 93.82)\n",
            "Epoch: [170][140/268]\tTime  0.417 ( 0.980)\tData  0.000 ( 0.578)\tLoss 1.6073e+00 (2.0135e+00)\tAcc@1  90.23 ( 65.18)\tAcc@5  97.27 ( 93.55)\n",
            "Epoch: [170][150/268]\tTime  0.418 ( 0.956)\tData  0.000 ( 0.554)\tLoss 1.6485e+00 (2.0046e+00)\tAcc@1  83.98 ( 65.57)\tAcc@5  99.22 ( 93.77)\n",
            "Epoch: [170][160/268]\tTime  0.408 ( 0.943)\tData  0.000 ( 0.542)\tLoss 2.1014e+00 (1.9984e+00)\tAcc@1  76.95 ( 65.91)\tAcc@5  95.70 ( 93.93)\n",
            "Epoch: [170][170/268]\tTime  0.417 ( 0.924)\tData  0.013 ( 0.522)\tLoss 1.8172e+00 (1.9911e+00)\tAcc@1  76.56 ( 66.51)\tAcc@5  97.66 ( 94.09)\n",
            "Epoch: [170][180/268]\tTime  2.422 ( 0.907)\tData  2.091 ( 0.506)\tLoss 1.9082e+00 (1.9818e+00)\tAcc@1  64.45 ( 66.97)\tAcc@5  98.05 ( 94.24)\n",
            "Epoch: [170][190/268]\tTime  0.418 ( 0.882)\tData  0.000 ( 0.480)\tLoss 1.6095e+00 (1.9797e+00)\tAcc@1  83.20 ( 67.10)\tAcc@5  98.44 ( 94.27)\n",
            "Epoch: [170][200/268]\tTime  0.426 ( 0.867)\tData  0.000 ( 0.465)\tLoss 1.7627e+00 (1.9772e+00)\tAcc@1  83.98 ( 67.35)\tAcc@5  97.66 ( 94.29)\n",
            "Epoch: [170][210/268]\tTime  0.402 ( 0.855)\tData  0.001 ( 0.453)\tLoss 2.2086e+00 (1.9770e+00)\tAcc@1  48.05 ( 67.25)\tAcc@5  91.41 ( 94.31)\n",
            "Epoch: [170][220/268]\tTime  0.418 ( 0.844)\tData  0.000 ( 0.442)\tLoss 1.6480e+00 (1.9800e+00)\tAcc@1  88.28 ( 67.04)\tAcc@5  97.66 ( 94.18)\n",
            "Epoch: [170][230/268]\tTime  0.416 ( 0.835)\tData  0.000 ( 0.433)\tLoss 1.5657e+00 (1.9861e+00)\tAcc@1  90.23 ( 66.57)\tAcc@5  99.61 ( 94.11)\n",
            "Epoch: [170][240/268]\tTime  2.323 ( 0.826)\tData  1.972 ( 0.424)\tLoss 2.1904e+00 (1.9826e+00)\tAcc@1  58.98 ( 66.70)\tAcc@5  94.14 ( 94.13)\n",
            "Epoch: [170][250/268]\tTime  0.417 ( 0.809)\tData  0.000 ( 0.407)\tLoss 1.9055e+00 (1.9795e+00)\tAcc@1  68.36 ( 66.94)\tAcc@5  97.66 ( 94.18)\n",
            "Epoch: [170][260/268]\tTime  0.415 ( 0.798)\tData  0.000 ( 0.396)\tLoss 2.3242e+00 (1.9741e+00)\tAcc@1  55.86 ( 67.22)\tAcc@5  91.41 ( 94.25)\n",
            "epoch: 170\n",
            "2023-03-25 05:16:43.517606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:43.517714: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:43.517734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:16:47.479455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:47.479550: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:47.479569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:16:51.413694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:51.413803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:51.413821: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:16:55.390177: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:55.390267: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:55.390284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:16:59.334169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:59.334270: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:16:59.334291: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:03.264986: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:03.265088: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:03.265107: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:07.186704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:07.186796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:07.186815: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:11.116022: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:11.116117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:11.116134: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:15.070811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:15.070907: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:15.070928: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:19.006884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:19.007007: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:19.007026: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:22.927724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:22.927830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:22.927851: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:17:26.873501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:26.873601: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:17:26.873627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [171][  0/268]\tTime 55.770 (55.770)\tData 55.426 (55.426)\tLoss 2.3802e+00 (2.3802e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [171][ 10/268]\tTime  0.417 ( 5.453)\tData  0.000 ( 5.049)\tLoss 1.9096e+00 (2.0241e+00)\tAcc@1  62.50 ( 61.75)\tAcc@5  98.44 ( 94.64)\n",
            "Epoch: [171][ 20/268]\tTime  0.432 ( 3.121)\tData  0.000 ( 2.722)\tLoss 1.5748e+00 (2.0314e+00)\tAcc@1  86.33 ( 62.35)\tAcc@5  99.22 ( 94.29)\n",
            "Epoch: [171][ 30/268]\tTime  0.417 ( 2.306)\tData  0.000 ( 1.907)\tLoss 2.3339e+00 (2.0337e+00)\tAcc@1  42.19 ( 63.63)\tAcc@5  86.72 ( 94.00)\n",
            "Epoch: [171][ 40/268]\tTime  0.416 ( 1.904)\tData  0.000 ( 1.506)\tLoss 2.4809e+00 (2.0305e+00)\tAcc@1  43.75 ( 64.08)\tAcc@5  84.77 ( 93.61)\n",
            "Epoch: [171][ 50/268]\tTime  0.411 ( 1.639)\tData  0.000 ( 1.242)\tLoss 1.5848e+00 (2.0126e+00)\tAcc@1  94.53 ( 65.47)\tAcc@5  96.88 ( 93.77)\n",
            "Epoch: [171][ 60/268]\tTime  2.168 ( 1.468)\tData  1.825 ( 1.070)\tLoss 2.4384e+00 (2.0382e+00)\tAcc@1  40.62 ( 64.47)\tAcc@5  85.55 ( 93.44)\n",
            "Epoch: [171][ 70/268]\tTime  0.416 ( 1.336)\tData  0.000 ( 0.937)\tLoss 2.4440e+00 (2.0408e+00)\tAcc@1  36.72 ( 64.26)\tAcc@5  87.50 ( 93.38)\n",
            "Epoch: [171][ 80/268]\tTime  0.416 ( 1.240)\tData  0.000 ( 0.842)\tLoss 1.4924e+00 (2.0213e+00)\tAcc@1  94.14 ( 65.23)\tAcc@5  99.22 ( 93.62)\n",
            "Epoch: [171][ 90/268]\tTime  0.416 ( 1.172)\tData  0.000 ( 0.776)\tLoss 2.4908e+00 (2.0313e+00)\tAcc@1  39.06 ( 64.26)\tAcc@5  91.41 ( 93.56)\n",
            "Epoch: [171][100/268]\tTime  0.416 ( 1.121)\tData  0.000 ( 0.725)\tLoss 1.7365e+00 (2.0160e+00)\tAcc@1  81.64 ( 65.30)\tAcc@5  98.05 ( 93.73)\n",
            "Epoch: [171][110/268]\tTime  0.641 ( 1.077)\tData  0.307 ( 0.682)\tLoss 2.2960e+00 (2.0185e+00)\tAcc@1  44.53 ( 64.97)\tAcc@5  91.02 ( 93.71)\n",
            "Epoch: [171][120/268]\tTime  1.916 ( 1.035)\tData  1.582 ( 0.640)\tLoss 1.7114e+00 (2.0054e+00)\tAcc@1  91.02 ( 66.11)\tAcc@5  96.48 ( 93.91)\n",
            "Epoch: [171][130/268]\tTime  0.418 ( 0.994)\tData  0.012 ( 0.599)\tLoss 1.7793e+00 (2.0046e+00)\tAcc@1  77.73 ( 66.12)\tAcc@5  98.44 ( 93.91)\n",
            "Epoch: [171][140/268]\tTime  0.416 ( 0.968)\tData  0.000 ( 0.573)\tLoss 2.3008e+00 (2.0062e+00)\tAcc@1  42.97 ( 65.80)\tAcc@5  89.45 ( 93.92)\n",
            "Epoch: [171][150/268]\tTime  0.417 ( 0.945)\tData  0.000 ( 0.551)\tLoss 2.3590e+00 (2.0001e+00)\tAcc@1  39.45 ( 66.20)\tAcc@5  87.89 ( 93.99)\n",
            "Epoch: [171][160/268]\tTime  0.417 ( 0.923)\tData  0.000 ( 0.529)\tLoss 1.7338e+00 (1.9927e+00)\tAcc@1  83.20 ( 66.60)\tAcc@5  98.05 ( 94.05)\n",
            "Epoch: [171][170/268]\tTime  1.265 ( 0.906)\tData  0.928 ( 0.511)\tLoss 1.9545e+00 (1.9984e+00)\tAcc@1  71.88 ( 66.16)\tAcc@5  95.70 ( 93.98)\n",
            "Epoch: [171][180/268]\tTime  1.904 ( 0.887)\tData  1.574 ( 0.492)\tLoss 2.3059e+00 (1.9892e+00)\tAcc@1  69.92 ( 67.00)\tAcc@5  91.80 ( 94.08)\n",
            "Epoch: [171][190/268]\tTime  0.416 ( 0.864)\tData  0.013 ( 0.469)\tLoss 1.6365e+00 (1.9881e+00)\tAcc@1  92.19 ( 67.19)\tAcc@5  96.48 ( 94.05)\n",
            "Epoch: [171][200/268]\tTime  0.408 ( 0.856)\tData  0.000 ( 0.461)\tLoss 1.6313e+00 (1.9879e+00)\tAcc@1  89.06 ( 67.05)\tAcc@5  96.09 ( 93.98)\n",
            "Epoch: [171][210/268]\tTime  0.410 ( 0.846)\tData  0.001 ( 0.451)\tLoss 1.8588e+00 (1.9824e+00)\tAcc@1  80.08 ( 67.28)\tAcc@5  96.88 ( 94.07)\n",
            "Epoch: [171][220/268]\tTime  0.422 ( 0.837)\tData  0.000 ( 0.443)\tLoss 1.8735e+00 (1.9743e+00)\tAcc@1  69.53 ( 67.80)\tAcc@5  96.48 ( 94.19)\n",
            "Epoch: [171][230/268]\tTime  1.583 ( 0.827)\tData  1.261 ( 0.433)\tLoss 1.7981e+00 (1.9732e+00)\tAcc@1  76.56 ( 68.00)\tAcc@5  96.88 ( 94.23)\n",
            "Epoch: [171][240/268]\tTime  1.667 ( 0.815)\tData  1.336 ( 0.421)\tLoss 2.4371e+00 (1.9748e+00)\tAcc@1  35.16 ( 67.84)\tAcc@5  87.50 ( 94.18)\n",
            "Epoch: [171][250/268]\tTime  0.418 ( 0.803)\tData  0.000 ( 0.408)\tLoss 1.6480e+00 (1.9658e+00)\tAcc@1  89.84 ( 68.29)\tAcc@5  97.66 ( 94.32)\n",
            "Epoch: [171][260/268]\tTime  0.416 ( 0.792)\tData  0.000 ( 0.398)\tLoss 2.3205e+00 (1.9661e+00)\tAcc@1  39.06 ( 68.30)\tAcc@5  87.50 ( 94.30)\n",
            "epoch: 171\n",
            "2023-03-25 05:20:15.009511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:15.009615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:15.009633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:18.949864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:18.949964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:18.949982: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:22.895717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:22.895825: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:22.895842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:26.837150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:26.837247: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:26.837265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:30.765979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:30.766079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:30.766098: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:34.698767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:34.698864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:34.698883: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:38.609566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:38.609676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:38.609697: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:42.524436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:42.524546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:42.524564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:46.505944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:46.506039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:46.506056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:50.402278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:50.402384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:50.402404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:54.309751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:54.309851: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:54.309870: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:20:58.251435: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:58.251546: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:20:58.251567: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [172][  0/268]\tTime 55.158 (55.158)\tData 54.810 (54.810)\tLoss 1.8540e+00 (1.8540e+00)\tAcc@1  69.14 ( 69.14)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [172][ 10/268]\tTime  0.429 ( 5.415)\tData  0.000 ( 5.012)\tLoss 2.4217e+00 (1.9381e+00)\tAcc@1  30.08 ( 69.25)\tAcc@5  83.59 ( 94.03)\n",
            "Epoch: [172][ 20/268]\tTime  0.428 ( 3.129)\tData  0.000 ( 2.733)\tLoss 1.9574e+00 (1.9722e+00)\tAcc@1  62.89 ( 66.16)\tAcc@5  96.48 ( 94.03)\n",
            "Epoch: [172][ 30/268]\tTime  0.421 ( 2.320)\tData  0.000 ( 1.925)\tLoss 1.4806e+00 (1.9543e+00)\tAcc@1  95.70 ( 66.89)\tAcc@5  98.83 ( 94.37)\n",
            "Epoch: [172][ 40/268]\tTime  0.421 ( 1.915)\tData  0.000 ( 1.521)\tLoss 2.1235e+00 (1.9914e+00)\tAcc@1  55.08 ( 65.69)\tAcc@5  93.36 ( 93.98)\n",
            "Epoch: [172][ 50/268]\tTime  0.417 ( 1.660)\tData  0.000 ( 1.267)\tLoss 1.9773e+00 (1.9975e+00)\tAcc@1  61.33 ( 66.17)\tAcc@5  96.88 ( 93.36)\n",
            "Epoch: [172][ 60/268]\tTime  1.430 ( 1.473)\tData  1.083 ( 1.079)\tLoss 1.7868e+00 (2.0108e+00)\tAcc@1  84.77 ( 65.91)\tAcc@5  97.66 ( 92.76)\n",
            "Epoch: [172][ 70/268]\tTime  0.417 ( 1.341)\tData  0.013 ( 0.946)\tLoss 1.7961e+00 (2.0007e+00)\tAcc@1  79.69 ( 66.58)\tAcc@5  97.66 ( 92.98)\n",
            "Epoch: [172][ 80/268]\tTime  0.417 ( 1.256)\tData  0.001 ( 0.861)\tLoss 1.8849e+00 (2.0086e+00)\tAcc@1  77.34 ( 65.90)\tAcc@5  97.66 ( 92.93)\n",
            "Epoch: [172][ 90/268]\tTime  0.436 ( 1.185)\tData  0.000 ( 0.790)\tLoss 2.3030e+00 (2.0177e+00)\tAcc@1  44.92 ( 65.09)\tAcc@5  87.89 ( 92.84)\n",
            "Epoch: [172][100/268]\tTime  0.410 ( 1.132)\tData  0.000 ( 0.738)\tLoss 2.1207e+00 (2.0106e+00)\tAcc@1  52.73 ( 65.32)\tAcc@5  92.97 ( 93.03)\n",
            "Epoch: [172][110/268]\tTime  0.415 ( 1.084)\tData  0.000 ( 0.690)\tLoss 1.7084e+00 (2.0000e+00)\tAcc@1  87.89 ( 65.91)\tAcc@5  97.27 ( 93.26)\n",
            "Epoch: [172][120/268]\tTime  1.616 ( 1.039)\tData  1.288 ( 0.645)\tLoss 1.4758e+00 (1.9924e+00)\tAcc@1  96.09 ( 66.71)\tAcc@5  99.22 ( 93.37)\n",
            "Epoch: [172][130/268]\tTime  0.420 ( 0.997)\tData  0.000 ( 0.602)\tLoss 2.3504e+00 (1.9950e+00)\tAcc@1  37.11 ( 66.47)\tAcc@5  88.67 ( 93.42)\n",
            "Epoch: [172][140/268]\tTime  0.431 ( 0.968)\tData  0.000 ( 0.573)\tLoss 2.0913e+00 (1.9937e+00)\tAcc@1  57.42 ( 66.34)\tAcc@5  92.97 ( 93.41)\n",
            "Epoch: [172][150/268]\tTime  0.414 ( 0.949)\tData  0.001 ( 0.553)\tLoss 1.9593e+00 (1.9986e+00)\tAcc@1  65.62 ( 65.97)\tAcc@5  96.09 ( 93.31)\n",
            "Epoch: [172][160/268]\tTime  0.428 ( 0.927)\tData  0.012 ( 0.533)\tLoss 1.6327e+00 (1.9950e+00)\tAcc@1  83.59 ( 66.04)\tAcc@5  99.22 ( 93.38)\n",
            "Epoch: [172][170/268]\tTime  0.573 ( 0.911)\tData  0.255 ( 0.517)\tLoss 1.6631e+00 (1.9954e+00)\tAcc@1  84.77 ( 66.21)\tAcc@5  97.66 ( 93.51)\n",
            "Epoch: [172][180/268]\tTime  2.126 ( 0.893)\tData  1.798 ( 0.499)\tLoss 2.0192e+00 (1.9953e+00)\tAcc@1  52.73 ( 66.27)\tAcc@5  96.09 ( 93.53)\n",
            "Epoch: [172][190/268]\tTime  0.418 ( 0.869)\tData  0.000 ( 0.475)\tLoss 1.7851e+00 (1.9903e+00)\tAcc@1  82.81 ( 66.60)\tAcc@5  96.48 ( 93.62)\n",
            "Epoch: [172][200/268]\tTime  0.420 ( 0.859)\tData  0.003 ( 0.465)\tLoss 1.7000e+00 (1.9885e+00)\tAcc@1  88.28 ( 66.62)\tAcc@5  96.09 ( 93.66)\n",
            "Epoch: [172][210/268]\tTime  0.416 ( 0.846)\tData  0.000 ( 0.453)\tLoss 2.3520e+00 (1.9888e+00)\tAcc@1  42.97 ( 66.61)\tAcc@5  87.50 ( 93.72)\n",
            "Epoch: [172][220/268]\tTime  0.417 ( 0.838)\tData  0.000 ( 0.445)\tLoss 1.7512e+00 (1.9902e+00)\tAcc@1  77.34 ( 66.53)\tAcc@5  98.83 ( 93.71)\n",
            "Epoch: [172][230/268]\tTime  0.503 ( 0.827)\tData  0.173 ( 0.435)\tLoss 2.1507e+00 (1.9914e+00)\tAcc@1  68.75 ( 66.58)\tAcc@5  92.58 ( 93.72)\n",
            "Epoch: [172][240/268]\tTime  2.024 ( 0.817)\tData  1.692 ( 0.424)\tLoss 1.6918e+00 (1.9872e+00)\tAcc@1  83.98 ( 66.63)\tAcc@5  97.66 ( 93.77)\n",
            "Epoch: [172][250/268]\tTime  0.409 ( 0.801)\tData  0.000 ( 0.408)\tLoss 1.6865e+00 (1.9865e+00)\tAcc@1  83.98 ( 66.60)\tAcc@5  98.05 ( 93.77)\n",
            "Epoch: [172][260/268]\tTime  0.415 ( 0.793)\tData  0.000 ( 0.400)\tLoss 1.9059e+00 (1.9837e+00)\tAcc@1  64.84 ( 66.74)\tAcc@5  98.05 ( 93.84)\n",
            "epoch: 172\n",
            "2023-03-25 05:23:46.808008: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:46.808112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:46.808131: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:23:50.747446: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:50.747560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:50.747580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:23:54.694615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:54.694728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:54.694749: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:23:58.716035: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:58.716136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:23:58.716156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:02.620224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:02.620327: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:02.620345: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:06.553016: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:06.553110: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:06.553128: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:10.483164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:10.483266: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:10.483285: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:14.387635: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:14.387749: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:14.387768: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:18.343194: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:18.343288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:18.343307: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:22.285687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:22.285783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:22.285801: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:26.226653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:26.226769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:26.226788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:24:30.133294: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:30.133388: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:24:30.133406: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [173][  0/268]\tTime 56.455 (56.455)\tData 56.123 (56.123)\tLoss 1.6992e+00 (1.6992e+00)\tAcc@1  83.59 ( 83.59)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [173][ 10/268]\tTime  0.417 ( 5.512)\tData  0.001 ( 5.113)\tLoss 1.7189e+00 (1.8851e+00)\tAcc@1  84.77 ( 72.34)\tAcc@5  98.44 ( 95.28)\n",
            "Epoch: [173][ 20/268]\tTime  0.417 ( 3.148)\tData  0.000 ( 2.753)\tLoss 1.8126e+00 (1.8688e+00)\tAcc@1  79.69 ( 74.76)\tAcc@5  97.66 ( 95.59)\n",
            "Epoch: [173][ 30/268]\tTime  0.418 ( 2.355)\tData  0.000 ( 1.958)\tLoss 1.6960e+00 (1.8479e+00)\tAcc@1  73.83 ( 75.67)\tAcc@5  98.44 ( 96.09)\n",
            "Epoch: [173][ 40/268]\tTime  0.416 ( 1.921)\tData  0.000 ( 1.523)\tLoss 1.6025e+00 (1.8440e+00)\tAcc@1  90.23 ( 75.13)\tAcc@5  98.05 ( 96.33)\n",
            "Epoch: [173][ 50/268]\tTime  0.413 ( 1.676)\tData  0.001 ( 1.278)\tLoss 1.9692e+00 (1.8946e+00)\tAcc@1  69.53 ( 72.54)\tAcc@5  96.09 ( 95.71)\n",
            "Epoch: [173][ 60/268]\tTime  2.149 ( 1.499)\tData  1.813 ( 1.100)\tLoss 1.7139e+00 (1.9180e+00)\tAcc@1  77.34 ( 70.45)\tAcc@5  98.83 ( 95.40)\n",
            "Epoch: [173][ 70/268]\tTime  0.417 ( 1.347)\tData  0.001 ( 0.946)\tLoss 1.8010e+00 (1.9100e+00)\tAcc@1  77.73 ( 71.26)\tAcc@5  97.66 ( 95.35)\n",
            "Epoch: [173][ 80/268]\tTime  0.411 ( 1.246)\tData  0.000 ( 0.847)\tLoss 2.3703e+00 (1.9274e+00)\tAcc@1  41.41 ( 69.78)\tAcc@5  85.94 ( 95.05)\n",
            "Epoch: [173][ 90/268]\tTime  0.416 ( 1.186)\tData  0.000 ( 0.787)\tLoss 2.3700e+00 (1.9418e+00)\tAcc@1  52.73 ( 68.69)\tAcc@5  93.75 ( 94.93)\n",
            "Epoch: [173][100/268]\tTime  0.427 ( 1.124)\tData  0.001 ( 0.726)\tLoss 1.9620e+00 (1.9440e+00)\tAcc@1  61.72 ( 68.49)\tAcc@5  94.14 ( 94.95)\n",
            "Epoch: [173][110/268]\tTime  0.427 ( 1.081)\tData  0.000 ( 0.683)\tLoss 1.8641e+00 (1.9384e+00)\tAcc@1  85.94 ( 68.95)\tAcc@5  95.70 ( 94.95)\n",
            "Epoch: [173][120/268]\tTime  2.101 ( 1.040)\tData  1.775 ( 0.642)\tLoss 2.3754e+00 (1.9513e+00)\tAcc@1  28.91 ( 67.77)\tAcc@5  83.98 ( 94.78)\n",
            "Epoch: [173][130/268]\tTime  0.424 ( 0.995)\tData  0.000 ( 0.596)\tLoss 1.8247e+00 (1.9611e+00)\tAcc@1  76.95 ( 67.24)\tAcc@5  97.27 ( 94.63)\n",
            "Epoch: [173][140/268]\tTime  0.417 ( 0.965)\tData  0.000 ( 0.566)\tLoss 1.9716e+00 (1.9660e+00)\tAcc@1  61.72 ( 67.00)\tAcc@5  96.09 ( 94.59)\n",
            "Epoch: [173][150/268]\tTime  0.435 ( 0.943)\tData  0.000 ( 0.545)\tLoss 1.8152e+00 (1.9777e+00)\tAcc@1  75.00 ( 66.41)\tAcc@5  96.09 ( 94.41)\n",
            "Epoch: [173][160/268]\tTime  0.417 ( 0.925)\tData  0.000 ( 0.527)\tLoss 1.8388e+00 (1.9719e+00)\tAcc@1  82.42 ( 66.83)\tAcc@5  96.09 ( 94.48)\n",
            "Epoch: [173][170/268]\tTime  0.412 ( 0.905)\tData  0.000 ( 0.508)\tLoss 1.8055e+00 (1.9658e+00)\tAcc@1  73.44 ( 67.23)\tAcc@5  97.27 ( 94.56)\n",
            "Epoch: [173][180/268]\tTime  2.440 ( 0.889)\tData  2.102 ( 0.492)\tLoss 2.1671e+00 (1.9642e+00)\tAcc@1  53.91 ( 67.18)\tAcc@5  92.19 ( 94.56)\n",
            "Epoch: [173][190/268]\tTime  0.428 ( 0.868)\tData  0.000 ( 0.470)\tLoss 1.6346e+00 (1.9545e+00)\tAcc@1  81.64 ( 67.71)\tAcc@5  96.48 ( 94.68)\n",
            "Epoch: [173][200/268]\tTime  0.416 ( 0.855)\tData  0.000 ( 0.458)\tLoss 2.1857e+00 (1.9453e+00)\tAcc@1  44.53 ( 68.22)\tAcc@5  89.45 ( 94.79)\n",
            "Epoch: [173][210/268]\tTime  0.419 ( 0.843)\tData  0.000 ( 0.446)\tLoss 2.0140e+00 (1.9393e+00)\tAcc@1  53.12 ( 68.55)\tAcc@5  92.58 ( 94.89)\n",
            "Epoch: [173][220/268]\tTime  0.429 ( 0.833)\tData  0.000 ( 0.436)\tLoss 1.7474e+00 (1.9349e+00)\tAcc@1  83.98 ( 68.87)\tAcc@5  97.66 ( 94.91)\n",
            "Epoch: [173][230/268]\tTime  0.423 ( 0.826)\tData  0.000 ( 0.429)\tLoss 1.6627e+00 (1.9314e+00)\tAcc@1  85.94 ( 69.01)\tAcc@5  98.44 ( 94.98)\n",
            "Epoch: [173][240/268]\tTime  2.467 ( 0.818)\tData  2.131 ( 0.421)\tLoss 1.7024e+00 (1.9354e+00)\tAcc@1  89.45 ( 68.83)\tAcc@5  96.48 ( 94.94)\n",
            "Epoch: [173][250/268]\tTime  0.413 ( 0.802)\tData  0.000 ( 0.404)\tLoss 2.0049e+00 (1.9368e+00)\tAcc@1  59.77 ( 68.81)\tAcc@5  94.92 ( 94.96)\n",
            "Epoch: [173][260/268]\tTime  0.416 ( 0.792)\tData  0.000 ( 0.395)\tLoss 2.2745e+00 (1.9416e+00)\tAcc@1  49.61 ( 68.48)\tAcc@5  90.23 ( 94.92)\n",
            "epoch: 173\n",
            "2023-03-25 05:27:18.305081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:18.305178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:18.305197: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:22.333288: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:22.333394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:22.333414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:26.278256: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:26.278377: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:26.278400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:30.229818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:30.229917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:30.229936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:34.196095: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:34.196209: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:34.196226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:38.121449: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:38.121559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:38.121579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:42.045963: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:42.046092: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:42.046116: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:45.996290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:45.996412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:45.996435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:49.952633: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:49.952763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:49.952785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:53.859257: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:53.859378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:53.859402: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:27:57.784393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:57.784503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:27:57.784521: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:28:01.733832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:28:01.733929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:28:01.733948: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [174][  0/268]\tTime 54.901 (54.901)\tData 54.563 (54.563)\tLoss 1.9547e+00 (1.9547e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  95.70 ( 95.70)\n",
            "Epoch: [174][ 10/268]\tTime  0.417 ( 5.439)\tData  0.001 ( 5.033)\tLoss 2.0036e+00 (1.9634e+00)\tAcc@1  66.41 ( 67.12)\tAcc@5  96.09 ( 94.78)\n",
            "Epoch: [174][ 20/268]\tTime  0.414 ( 3.159)\tData  0.000 ( 2.761)\tLoss 1.6317e+00 (1.9523e+00)\tAcc@1  92.19 ( 66.83)\tAcc@5  97.27 ( 94.77)\n",
            "Epoch: [174][ 30/268]\tTime  0.422 ( 2.335)\tData  0.000 ( 1.940)\tLoss 1.5987e+00 (1.9227e+00)\tAcc@1  88.28 ( 69.15)\tAcc@5  99.22 ( 94.96)\n",
            "Epoch: [174][ 40/268]\tTime  0.413 ( 1.916)\tData  0.000 ( 1.522)\tLoss 2.1211e+00 (1.9427e+00)\tAcc@1  53.52 ( 67.46)\tAcc@5  95.31 ( 94.78)\n",
            "Epoch: [174][ 50/268]\tTime  0.417 ( 1.658)\tData  0.000 ( 1.264)\tLoss 1.8432e+00 (1.9403e+00)\tAcc@1  79.69 ( 67.93)\tAcc@5  97.66 ( 94.94)\n",
            "Epoch: [174][ 60/268]\tTime  1.147 ( 1.467)\tData  0.819 ( 1.072)\tLoss 2.2308e+00 (1.9888e+00)\tAcc@1  64.84 ( 65.32)\tAcc@5  92.19 ( 94.29)\n",
            "Epoch: [174][ 70/268]\tTime  0.422 ( 1.339)\tData  0.000 ( 0.942)\tLoss 1.6995e+00 (1.9857e+00)\tAcc@1  89.84 ( 65.64)\tAcc@5  94.14 ( 94.27)\n",
            "Epoch: [174][ 80/268]\tTime  0.421 ( 1.249)\tData  0.000 ( 0.854)\tLoss 2.0829e+00 (2.0003e+00)\tAcc@1  64.45 ( 64.70)\tAcc@5  94.14 ( 94.05)\n",
            "Epoch: [174][ 90/268]\tTime  0.417 ( 1.187)\tData  0.000 ( 0.792)\tLoss 2.0486e+00 (1.9915e+00)\tAcc@1  61.72 ( 64.94)\tAcc@5  94.53 ( 94.21)\n",
            "Epoch: [174][100/268]\tTime  0.416 ( 1.132)\tData  0.000 ( 0.737)\tLoss 2.0129e+00 (1.9852e+00)\tAcc@1  63.67 ( 65.58)\tAcc@5  95.31 ( 94.35)\n",
            "Epoch: [174][110/268]\tTime  0.412 ( 1.089)\tData  0.000 ( 0.695)\tLoss 2.0910e+00 (1.9867e+00)\tAcc@1  57.42 ( 65.46)\tAcc@5  94.14 ( 94.33)\n",
            "Epoch: [174][120/268]\tTime  0.553 ( 1.035)\tData  0.233 ( 0.640)\tLoss 1.8718e+00 (1.9847e+00)\tAcc@1  66.41 ( 65.84)\tAcc@5  96.48 ( 94.42)\n",
            "Epoch: [174][130/268]\tTime  0.412 ( 1.003)\tData  0.001 ( 0.607)\tLoss 1.6092e+00 (1.9894e+00)\tAcc@1  91.80 ( 65.48)\tAcc@5  96.88 ( 94.44)\n",
            "Epoch: [174][140/268]\tTime  0.417 ( 0.977)\tData  0.000 ( 0.581)\tLoss 2.2002e+00 (1.9862e+00)\tAcc@1  49.22 ( 65.74)\tAcc@5  90.62 ( 94.50)\n",
            "Epoch: [174][150/268]\tTime  0.413 ( 0.956)\tData  0.000 ( 0.560)\tLoss 2.3653e+00 (1.9857e+00)\tAcc@1  41.80 ( 66.15)\tAcc@5  85.94 ( 94.55)\n",
            "Epoch: [174][160/268]\tTime  0.420 ( 0.937)\tData  0.000 ( 0.541)\tLoss 1.6632e+00 (1.9838e+00)\tAcc@1  85.94 ( 66.26)\tAcc@5  97.66 ( 94.58)\n",
            "Epoch: [174][170/268]\tTime  0.422 ( 0.920)\tData  0.000 ( 0.524)\tLoss 1.7717e+00 (1.9769e+00)\tAcc@1  81.64 ( 66.60)\tAcc@5  97.27 ( 94.68)\n",
            "Epoch: [174][180/268]\tTime  0.416 ( 0.892)\tData  0.001 ( 0.496)\tLoss 1.6898e+00 (1.9774e+00)\tAcc@1  77.34 ( 66.59)\tAcc@5  99.22 ( 94.69)\n",
            "Epoch: [174][190/268]\tTime  0.428 ( 0.878)\tData  0.000 ( 0.481)\tLoss 2.1985e+00 (1.9762e+00)\tAcc@1  49.61 ( 66.68)\tAcc@5  91.80 ( 94.65)\n",
            "Epoch: [174][200/268]\tTime  0.415 ( 0.866)\tData  0.000 ( 0.469)\tLoss 1.8120e+00 (1.9788e+00)\tAcc@1  87.11 ( 66.66)\tAcc@5  98.44 ( 94.64)\n",
            "Epoch: [174][210/268]\tTime  0.428 ( 0.852)\tData  0.000 ( 0.455)\tLoss 1.6199e+00 (1.9782e+00)\tAcc@1  86.33 ( 66.69)\tAcc@5  98.44 ( 94.62)\n",
            "Epoch: [174][220/268]\tTime  0.420 ( 0.842)\tData  0.000 ( 0.445)\tLoss 2.2789e+00 (1.9747e+00)\tAcc@1  41.02 ( 66.94)\tAcc@5  92.58 ( 94.61)\n",
            "Epoch: [174][230/268]\tTime  0.417 ( 0.831)\tData  0.000 ( 0.434)\tLoss 2.2897e+00 (1.9767e+00)\tAcc@1  42.58 ( 66.86)\tAcc@5  88.28 ( 94.59)\n",
            "Epoch: [174][240/268]\tTime  1.627 ( 0.819)\tData  1.308 ( 0.422)\tLoss 3.6587e+00 (1.9878e+00)\tAcc@1   1.17 ( 66.52)\tAcc@5  25.78 ( 94.20)\n",
            "Epoch: [174][250/268]\tTime  0.417 ( 0.808)\tData  0.000 ( 0.411)\tLoss 2.1880e+00 (1.9889e+00)\tAcc@1  64.06 ( 66.49)\tAcc@5  94.92 ( 94.23)\n",
            "Epoch: [174][260/268]\tTime  0.415 ( 0.795)\tData  0.000 ( 0.398)\tLoss 1.6330e+00 (1.9787e+00)\tAcc@1  84.38 ( 67.09)\tAcc@5  98.05 ( 94.34)\n",
            "epoch: 174\n",
            "2023-03-25 05:30:50.434623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:50.434734: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:50.434755: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:30:54.392324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:54.392426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:54.392444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:30:58.374627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:58.374735: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:30:58.374754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:02.274436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:02.274557: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:02.274577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:06.211964: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:06.212058: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:06.212077: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:10.164233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:10.164334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:10.164353: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:14.133178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:14.133279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:14.133297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:18.097853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:18.097952: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:18.097972: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:22.050708: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:22.050810: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:22.050829: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:26.023311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:26.023408: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:26.023427: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:29.961014: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:29.961147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:29.961167: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:31:33.881426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:33.881531: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:31:33.881551: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [175][  0/268]\tTime 55.010 (55.010)\tData 54.669 (54.669)\tLoss 1.6009e+00 (1.6009e+00)\tAcc@1  84.38 ( 84.38)\tAcc@5  98.83 ( 98.83)\n",
            "Epoch: [175][ 10/268]\tTime  0.423 ( 5.380)\tData  0.000 ( 4.979)\tLoss 1.7480e+00 (1.9311e+00)\tAcc@1  81.64 ( 69.42)\tAcc@5  98.05 ( 95.81)\n",
            "Epoch: [175][ 20/268]\tTime  0.417 ( 3.142)\tData  0.000 ( 2.746)\tLoss 1.6417e+00 (1.9078e+00)\tAcc@1  89.06 ( 71.93)\tAcc@5  98.44 ( 95.94)\n",
            "Epoch: [175][ 30/268]\tTime  0.417 ( 2.335)\tData  0.001 ( 1.941)\tLoss 2.1144e+00 (1.9022e+00)\tAcc@1  54.69 ( 72.01)\tAcc@5  94.14 ( 95.94)\n",
            "Epoch: [175][ 40/268]\tTime  0.436 ( 1.912)\tData  0.000 ( 1.519)\tLoss 1.5361e+00 (1.9128e+00)\tAcc@1  92.58 ( 71.83)\tAcc@5  98.44 ( 95.62)\n",
            "Epoch: [175][ 50/268]\tTime  0.410 ( 1.659)\tData  0.000 ( 1.267)\tLoss 2.0729e+00 (1.9172e+00)\tAcc@1  59.77 ( 71.21)\tAcc@5  94.53 ( 95.54)\n",
            "Epoch: [175][ 60/268]\tTime  0.783 ( 1.462)\tData  0.457 ( 1.068)\tLoss 1.5906e+00 (1.9208e+00)\tAcc@1  88.67 ( 70.98)\tAcc@5  98.83 ( 95.53)\n",
            "Epoch: [175][ 70/268]\tTime  0.427 ( 1.339)\tData  0.008 ( 0.943)\tLoss 1.8467e+00 (1.9106e+00)\tAcc@1  74.61 ( 71.67)\tAcc@5  97.66 ( 95.63)\n",
            "Epoch: [175][ 80/268]\tTime  0.412 ( 1.252)\tData  0.000 ( 0.857)\tLoss 1.6892e+00 (1.9226e+00)\tAcc@1  86.72 ( 70.70)\tAcc@5  96.48 ( 95.50)\n",
            "Epoch: [175][ 90/268]\tTime  0.429 ( 1.182)\tData  0.012 ( 0.786)\tLoss 1.9765e+00 (1.9137e+00)\tAcc@1  68.36 ( 71.23)\tAcc@5  95.70 ( 95.66)\n",
            "Epoch: [175][100/268]\tTime  0.414 ( 1.131)\tData  0.000 ( 0.736)\tLoss 1.8144e+00 (1.9178e+00)\tAcc@1  82.81 ( 70.59)\tAcc@5  97.66 ( 95.57)\n",
            "Epoch: [175][110/268]\tTime  0.424 ( 1.083)\tData  0.000 ( 0.687)\tLoss 2.2392e+00 (1.9251e+00)\tAcc@1  41.02 ( 70.23)\tAcc@5  88.28 ( 95.44)\n",
            "Epoch: [175][120/268]\tTime  0.434 ( 1.028)\tData  0.001 ( 0.632)\tLoss 1.7316e+00 (1.9236e+00)\tAcc@1  89.84 ( 70.48)\tAcc@5  96.09 ( 95.50)\n",
            "Epoch: [175][130/268]\tTime  0.417 ( 0.999)\tData  0.000 ( 0.601)\tLoss 1.7630e+00 (1.9244e+00)\tAcc@1  85.55 ( 70.35)\tAcc@5  97.27 ( 95.47)\n",
            "Epoch: [175][140/268]\tTime  0.435 ( 0.969)\tData  0.000 ( 0.571)\tLoss 2.1798e+00 (1.9295e+00)\tAcc@1  52.73 ( 69.87)\tAcc@5  91.80 ( 95.43)\n",
            "Epoch: [175][150/268]\tTime  0.419 ( 0.951)\tData  0.000 ( 0.553)\tLoss 2.2102e+00 (1.9264e+00)\tAcc@1  46.88 ( 70.06)\tAcc@5  90.23 ( 95.49)\n",
            "Epoch: [175][160/268]\tTime  0.416 ( 0.929)\tData  0.000 ( 0.531)\tLoss 1.5942e+00 (1.9254e+00)\tAcc@1  90.23 ( 69.92)\tAcc@5  98.44 ( 95.46)\n",
            "Epoch: [175][170/268]\tTime  0.414 ( 0.914)\tData  0.000 ( 0.516)\tLoss 1.9584e+00 (1.9189e+00)\tAcc@1  55.86 ( 70.34)\tAcc@5  97.27 ( 95.56)\n",
            "Epoch: [175][180/268]\tTime  0.415 ( 0.887)\tData  0.012 ( 0.489)\tLoss 1.9433e+00 (1.9146e+00)\tAcc@1  62.11 ( 70.51)\tAcc@5  94.92 ( 95.60)\n",
            "Epoch: [175][190/268]\tTime  0.416 ( 0.873)\tData  0.000 ( 0.474)\tLoss 1.8259e+00 (1.9134e+00)\tAcc@1  80.86 ( 70.82)\tAcc@5  96.88 ( 95.60)\n",
            "Epoch: [175][200/268]\tTime  0.442 ( 0.862)\tData  0.000 ( 0.463)\tLoss 2.1157e+00 (1.9183e+00)\tAcc@1  45.70 ( 70.30)\tAcc@5  92.58 ( 95.53)\n",
            "Epoch: [175][210/268]\tTime  0.422 ( 0.852)\tData  0.013 ( 0.453)\tLoss 2.1185e+00 (1.9265e+00)\tAcc@1  53.12 ( 69.82)\tAcc@5  90.23 ( 95.43)\n",
            "Epoch: [175][220/268]\tTime  0.422 ( 0.842)\tData  0.000 ( 0.443)\tLoss 1.7733e+00 (1.9295e+00)\tAcc@1  73.44 ( 69.49)\tAcc@5  98.05 ( 95.37)\n",
            "Epoch: [175][230/268]\tTime  0.423 ( 0.832)\tData  0.000 ( 0.433)\tLoss 1.5176e+00 (1.9357e+00)\tAcc@1  88.67 ( 69.08)\tAcc@5  99.61 ( 95.30)\n",
            "Epoch: [175][240/268]\tTime  0.416 ( 0.815)\tData  0.000 ( 0.416)\tLoss 2.2374e+00 (1.9359e+00)\tAcc@1  44.14 ( 69.26)\tAcc@5  88.67 ( 95.28)\n",
            "Epoch: [175][250/268]\tTime  0.424 ( 0.807)\tData  0.000 ( 0.408)\tLoss 1.8973e+00 (1.9337e+00)\tAcc@1  82.42 ( 69.59)\tAcc@5  98.44 ( 95.34)\n",
            "Epoch: [175][260/268]\tTime  0.415 ( 0.798)\tData  0.000 ( 0.399)\tLoss 2.0368e+00 (1.9340e+00)\tAcc@1  57.03 ( 69.41)\tAcc@5  94.14 ( 95.34)\n",
            "epoch: 175\n",
            "2023-03-25 05:34:23.508830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:23.508927: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:23.508945: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:27.439723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:27.439818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:27.439837: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:31.350426: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:31.350536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:31.350555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:35.285189: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:35.285290: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:35.285308: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:39.218951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:39.219046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:39.219064: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:43.125300: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:43.125397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:43.125414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:47.071936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:47.072031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:47.072051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:51.012696: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:51.012801: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:51.012820: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:54.976042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:54.976140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:54.976159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:34:58.882520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:58.882618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:34:58.882638: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:35:02.800115: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:35:02.800216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:35:02.800236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:35:06.692940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:35:06.693034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:35:06.693053: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [176][  0/268]\tTime 55.612 (55.612)\tData 55.281 (55.281)\tLoss 1.8619e+00 (1.8619e+00)\tAcc@1  84.77 ( 84.77)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [176][ 10/268]\tTime  0.422 ( 5.436)\tData  0.000 ( 5.035)\tLoss 2.3050e+00 (1.9974e+00)\tAcc@1  44.53 ( 69.32)\tAcc@5  87.50 ( 93.86)\n",
            "Epoch: [176][ 20/268]\tTime  0.430 ( 3.138)\tData  0.000 ( 2.738)\tLoss 2.2831e+00 (2.0454e+00)\tAcc@1  46.09 ( 65.03)\tAcc@5  87.89 ( 93.02)\n",
            "Epoch: [176][ 30/268]\tTime  0.407 ( 2.302)\tData  0.000 ( 1.906)\tLoss 1.7154e+00 (1.9864e+00)\tAcc@1  80.86 ( 68.56)\tAcc@5  98.05 ( 93.85)\n",
            "Epoch: [176][ 40/268]\tTime  0.420 ( 1.901)\tData  0.000 ( 1.506)\tLoss 2.3209e+00 (2.0241e+00)\tAcc@1  53.52 ( 66.12)\tAcc@5  88.28 ( 93.42)\n",
            "Epoch: [176][ 50/268]\tTime  0.427 ( 1.644)\tData  0.000 ( 1.249)\tLoss 1.7399e+00 (1.9769e+00)\tAcc@1  83.59 ( 68.56)\tAcc@5  97.27 ( 94.25)\n",
            "Epoch: [176][ 60/268]\tTime  2.065 ( 1.470)\tData  1.734 ( 1.074)\tLoss 2.2563e+00 (1.9797e+00)\tAcc@1  44.53 ( 68.03)\tAcc@5  88.28 ( 94.33)\n",
            "Epoch: [176][ 70/268]\tTime  0.423 ( 1.330)\tData  0.000 ( 0.933)\tLoss 2.4288e+00 (1.9797e+00)\tAcc@1  39.45 ( 67.90)\tAcc@5  85.94 ( 94.34)\n",
            "Epoch: [176][ 80/268]\tTime  0.412 ( 1.244)\tData  0.000 ( 0.849)\tLoss 1.7587e+00 (1.9588e+00)\tAcc@1  80.08 ( 68.87)\tAcc@5  98.44 ( 94.70)\n",
            "Epoch: [176][ 90/268]\tTime  0.416 ( 1.186)\tData  0.000 ( 0.792)\tLoss 2.1099e+00 (1.9681e+00)\tAcc@1  60.16 ( 68.87)\tAcc@5  96.88 ( 94.77)\n",
            "Epoch: [176][100/268]\tTime  0.426 ( 1.132)\tData  0.000 ( 0.737)\tLoss 2.3473e+00 (1.9677e+00)\tAcc@1  46.48 ( 68.77)\tAcc@5  89.45 ( 94.82)\n",
            "Epoch: [176][110/268]\tTime  0.417 ( 1.085)\tData  0.000 ( 0.691)\tLoss 2.2097e+00 (1.9632e+00)\tAcc@1  43.75 ( 68.92)\tAcc@5  90.62 ( 94.93)\n",
            "Epoch: [176][120/268]\tTime  0.715 ( 1.032)\tData  0.392 ( 0.638)\tLoss 1.9543e+00 (1.9572e+00)\tAcc@1  77.73 ( 69.39)\tAcc@5  97.27 ( 95.05)\n",
            "Epoch: [176][130/268]\tTime  0.417 ( 0.996)\tData  0.000 ( 0.601)\tLoss 1.7814e+00 (1.9619e+00)\tAcc@1  90.62 ( 68.89)\tAcc@5  97.27 ( 94.92)\n",
            "Epoch: [176][140/268]\tTime  0.426 ( 0.971)\tData  0.000 ( 0.576)\tLoss 2.8093e+00 (1.9564e+00)\tAcc@1  15.23 ( 69.06)\tAcc@5  72.66 ( 94.88)\n",
            "Epoch: [176][150/268]\tTime  0.434 ( 0.946)\tData  0.000 ( 0.550)\tLoss 2.2729e+00 (1.9482e+00)\tAcc@1  45.31 ( 69.29)\tAcc@5  89.45 ( 95.01)\n",
            "Epoch: [176][160/268]\tTime  0.417 ( 0.930)\tData  0.000 ( 0.534)\tLoss 2.7906e+00 (1.9593e+00)\tAcc@1  24.22 ( 68.55)\tAcc@5  89.84 ( 94.91)\n",
            "Epoch: [176][170/268]\tTime  0.414 ( 0.910)\tData  0.000 ( 0.514)\tLoss 1.9654e+00 (1.9589e+00)\tAcc@1  69.14 ( 68.47)\tAcc@5  98.44 ( 94.84)\n",
            "Epoch: [176][180/268]\tTime  0.430 ( 0.883)\tData  0.102 ( 0.487)\tLoss 2.8782e+00 (1.9810e+00)\tAcc@1  11.72 ( 67.52)\tAcc@5  78.91 ( 94.05)\n",
            "Epoch: [176][190/268]\tTime  0.422 ( 0.873)\tData  0.000 ( 0.476)\tLoss 1.9499e+00 (1.9728e+00)\tAcc@1  69.53 ( 67.86)\tAcc@5  95.70 ( 94.17)\n",
            "Epoch: [176][200/268]\tTime  0.417 ( 0.861)\tData  0.000 ( 0.464)\tLoss 1.7713e+00 (1.9673e+00)\tAcc@1  91.80 ( 68.28)\tAcc@5  96.09 ( 94.25)\n",
            "Epoch: [176][210/268]\tTime  0.420 ( 0.852)\tData  0.000 ( 0.454)\tLoss 2.1445e+00 (1.9650e+00)\tAcc@1  47.66 ( 68.50)\tAcc@5  93.36 ( 94.31)\n",
            "Epoch: [176][220/268]\tTime  0.424 ( 0.840)\tData  0.000 ( 0.443)\tLoss 1.7421e+00 (1.9599e+00)\tAcc@1  77.73 ( 68.68)\tAcc@5  97.66 ( 94.40)\n",
            "Epoch: [176][230/268]\tTime  0.418 ( 0.830)\tData  0.000 ( 0.433)\tLoss 1.9414e+00 (1.9565e+00)\tAcc@1  69.53 ( 68.85)\tAcc@5  98.05 ( 94.51)\n",
            "Epoch: [176][240/268]\tTime  0.416 ( 0.813)\tData  0.001 ( 0.415)\tLoss 1.6488e+00 (1.9528e+00)\tAcc@1  79.30 ( 68.93)\tAcc@5  97.66 ( 94.58)\n",
            "Epoch: [176][250/268]\tTime  0.416 ( 0.807)\tData  0.000 ( 0.408)\tLoss 1.8544e+00 (1.9492e+00)\tAcc@1  71.88 ( 68.95)\tAcc@5  97.27 ( 94.65)\n",
            "Epoch: [176][260/268]\tTime  0.416 ( 0.795)\tData  0.000 ( 0.397)\tLoss 2.3048e+00 (1.9467e+00)\tAcc@1  62.89 ( 69.12)\tAcc@5  89.84 ( 94.70)\n",
            "epoch: 176\n",
            "2023-03-25 05:37:55.729718: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:37:55.729934: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:37:55.729967: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:37:59.701510: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:37:59.701605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:37:59.701624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:03.684672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:03.684770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:03.684789: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:07.598942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:07.599045: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:07.599062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:11.519956: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:11.520057: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:11.520078: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:15.465398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:15.465498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:15.465518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:19.405258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:19.405352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:19.405371: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:23.333357: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:23.333459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:23.333477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:27.261252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:27.261349: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:27.261366: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:31.160938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:31.161040: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:31.161058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:35.085387: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:35.085491: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:35.085514: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:38:39.005724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:39.005823: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:38:39.005843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [177][  0/268]\tTime 55.832 (55.832)\tData 55.494 (55.494)\tLoss 2.2641e+00 (2.2641e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [177][ 10/268]\tTime  0.412 ( 5.455)\tData  0.000 ( 5.056)\tLoss 1.6761e+00 (1.9360e+00)\tAcc@1  87.11 ( 69.82)\tAcc@5  98.05 ( 95.92)\n",
            "Epoch: [177][ 20/268]\tTime  0.427 ( 3.145)\tData  0.013 ( 2.751)\tLoss 2.2406e+00 (1.9547e+00)\tAcc@1  47.27 ( 69.03)\tAcc@5  91.80 ( 95.33)\n",
            "Epoch: [177][ 30/268]\tTime  0.459 ( 2.325)\tData  0.000 ( 1.931)\tLoss 2.2255e+00 (1.9486e+00)\tAcc@1  46.09 ( 69.43)\tAcc@5  89.06 ( 95.46)\n",
            "Epoch: [177][ 40/268]\tTime  0.411 ( 1.928)\tData  0.000 ( 1.532)\tLoss 1.6956e+00 (1.9797e+00)\tAcc@1  83.59 ( 66.61)\tAcc@5  99.61 ( 95.00)\n",
            "Epoch: [177][ 50/268]\tTime  0.417 ( 1.664)\tData  0.000 ( 1.269)\tLoss 1.7622e+00 (1.9551e+00)\tAcc@1  75.00 ( 68.58)\tAcc@5  97.66 ( 95.36)\n",
            "Epoch: [177][ 60/268]\tTime  2.448 ( 1.493)\tData  2.109 ( 1.098)\tLoss 1.6538e+00 (1.9574e+00)\tAcc@1  92.19 ( 68.59)\tAcc@5  98.44 ( 95.20)\n",
            "Epoch: [177][ 70/268]\tTime  0.417 ( 1.342)\tData  0.000 ( 0.945)\tLoss 2.1065e+00 (1.9613e+00)\tAcc@1  55.08 ( 68.03)\tAcc@5  93.75 ( 95.16)\n",
            "Epoch: [177][ 80/268]\tTime  0.416 ( 1.248)\tData  0.000 ( 0.853)\tLoss 2.1573e+00 (1.9680e+00)\tAcc@1  49.61 ( 67.54)\tAcc@5  92.58 ( 95.03)\n",
            "Epoch: [177][ 90/268]\tTime  0.410 ( 1.182)\tData  0.000 ( 0.787)\tLoss 1.5706e+00 (1.9556e+00)\tAcc@1  93.36 ( 68.10)\tAcc@5  98.44 ( 95.18)\n",
            "Epoch: [177][100/268]\tTime  0.429 ( 1.127)\tData  0.000 ( 0.731)\tLoss 1.7065e+00 (1.9694e+00)\tAcc@1  87.50 ( 67.33)\tAcc@5  97.66 ( 95.03)\n",
            "Epoch: [177][110/268]\tTime  0.424 ( 1.084)\tData  0.000 ( 0.688)\tLoss 2.0872e+00 (1.9656e+00)\tAcc@1  78.52 ( 67.81)\tAcc@5  92.97 ( 95.06)\n",
            "Epoch: [177][120/268]\tTime  2.050 ( 1.043)\tData  1.719 ( 0.646)\tLoss 2.0610e+00 (1.9589e+00)\tAcc@1  59.38 ( 68.04)\tAcc@5  93.75 ( 95.09)\n",
            "Epoch: [177][130/268]\tTime  0.428 ( 0.995)\tData  0.001 ( 0.598)\tLoss 2.2645e+00 (1.9592e+00)\tAcc@1  45.31 ( 67.88)\tAcc@5  89.84 ( 95.06)\n",
            "Epoch: [177][140/268]\tTime  0.411 ( 0.966)\tData  0.000 ( 0.568)\tLoss 2.5489e+00 (1.9559e+00)\tAcc@1  52.34 ( 68.37)\tAcc@5  88.67 ( 95.12)\n",
            "Epoch: [177][150/268]\tTime  0.430 ( 0.949)\tData  0.000 ( 0.551)\tLoss 1.5859e+00 (1.9482e+00)\tAcc@1  87.11 ( 68.99)\tAcc@5  98.83 ( 95.21)\n",
            "Epoch: [177][160/268]\tTime  0.426 ( 0.930)\tData  0.001 ( 0.533)\tLoss 2.2403e+00 (1.9484e+00)\tAcc@1  47.27 ( 68.95)\tAcc@5  89.45 ( 95.15)\n",
            "Epoch: [177][170/268]\tTime  0.417 ( 0.912)\tData  0.000 ( 0.514)\tLoss 2.0176e+00 (1.9514e+00)\tAcc@1  76.17 ( 68.93)\tAcc@5  96.48 ( 95.13)\n",
            "Epoch: [177][180/268]\tTime  2.628 ( 0.897)\tData  2.294 ( 0.499)\tLoss 1.8854e+00 (1.9501e+00)\tAcc@1  71.09 ( 69.04)\tAcc@5  96.48 ( 95.12)\n",
            "Epoch: [177][190/268]\tTime  0.432 ( 0.872)\tData  0.000 ( 0.473)\tLoss 2.2981e+00 (1.9420e+00)\tAcc@1  55.47 ( 69.43)\tAcc@5  89.06 ( 95.17)\n",
            "Epoch: [177][200/268]\tTime  0.424 ( 0.861)\tData  0.000 ( 0.463)\tLoss 1.7572e+00 (1.9396e+00)\tAcc@1  70.31 ( 69.45)\tAcc@5  96.48 ( 95.16)\n",
            "Epoch: [177][210/268]\tTime  0.424 ( 0.849)\tData  0.000 ( 0.450)\tLoss 2.1271e+00 (1.9406e+00)\tAcc@1  57.81 ( 69.45)\tAcc@5  94.92 ( 95.17)\n",
            "Epoch: [177][220/268]\tTime  0.417 ( 0.842)\tData  0.000 ( 0.443)\tLoss 1.8926e+00 (1.9327e+00)\tAcc@1  76.95 ( 69.92)\tAcc@5  96.09 ( 95.27)\n",
            "Epoch: [177][230/268]\tTime  0.416 ( 0.833)\tData  0.000 ( 0.434)\tLoss 1.7283e+00 (1.9265e+00)\tAcc@1  73.83 ( 70.23)\tAcc@5  97.66 ( 95.34)\n",
            "Epoch: [177][240/268]\tTime  2.468 ( 0.824)\tData  2.131 ( 0.425)\tLoss 1.9522e+00 (1.9322e+00)\tAcc@1  75.00 ( 69.91)\tAcc@5  95.70 ( 95.28)\n",
            "Epoch: [177][250/268]\tTime  0.416 ( 0.808)\tData  0.000 ( 0.408)\tLoss 1.8865e+00 (1.9298e+00)\tAcc@1  73.83 ( 70.15)\tAcc@5  96.48 ( 95.30)\n",
            "Epoch: [177][260/268]\tTime  0.416 ( 0.796)\tData  0.000 ( 0.396)\tLoss 1.5948e+00 (1.9271e+00)\tAcc@1  87.89 ( 70.24)\tAcc@5  97.27 ( 95.31)\n",
            "epoch: 177\n",
            "2023-03-25 05:41:28.123498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:28.123608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:28.123628: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:32.050201: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:32.050297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:32.050316: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:35.944525: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:35.944634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:35.944664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:39.866401: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:39.866493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:39.866519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:43.799882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:43.799985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:43.800003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:47.704570: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:47.704687: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:47.704707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:51.723457: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:51.723569: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:51.723589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:55.665815: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:55.665914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:55.665952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:41:59.613634: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:59.613739: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:41:59.613759: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:42:03.564724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:03.564822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:03.564842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:42:07.476581: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:07.476697: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:07.476718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:42:11.386501: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:11.386606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:42:11.386623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [178][  0/268]\tTime 55.974 (55.974)\tData 55.644 (55.644)\tLoss 2.3300e+00 (2.3300e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [178][ 10/268]\tTime  0.429 ( 5.470)\tData  0.009 ( 5.069)\tLoss 1.9518e+00 (1.9692e+00)\tAcc@1  61.33 ( 67.86)\tAcc@5  96.09 ( 94.78)\n",
            "Epoch: [178][ 20/268]\tTime  0.416 ( 3.139)\tData  0.000 ( 2.744)\tLoss 2.0964e+00 (1.9578e+00)\tAcc@1  75.78 ( 70.18)\tAcc@5  92.58 ( 94.64)\n",
            "Epoch: [178][ 30/268]\tTime  0.424 ( 2.322)\tData  0.000 ( 1.929)\tLoss 1.9871e+00 (1.9586e+00)\tAcc@1  80.08 ( 69.82)\tAcc@5  96.09 ( 94.93)\n",
            "Epoch: [178][ 40/268]\tTime  0.422 ( 1.901)\tData  0.000 ( 1.510)\tLoss 2.0361e+00 (1.9686e+00)\tAcc@1  81.25 ( 69.57)\tAcc@5  95.31 ( 94.80)\n",
            "Epoch: [178][ 50/268]\tTime  0.411 ( 1.649)\tData  0.000 ( 1.258)\tLoss 1.9521e+00 (1.9824e+00)\tAcc@1  70.70 ( 68.46)\tAcc@5  97.66 ( 94.58)\n",
            "Epoch: [178][ 60/268]\tTime  2.138 ( 1.476)\tData  1.807 ( 1.083)\tLoss 2.2734e+00 (1.9928e+00)\tAcc@1  43.75 ( 67.30)\tAcc@5  89.06 ( 94.34)\n",
            "Epoch: [178][ 70/268]\tTime  0.424 ( 1.327)\tData  0.000 ( 0.932)\tLoss 1.7089e+00 (1.9980e+00)\tAcc@1  83.98 ( 67.02)\tAcc@5  97.27 ( 94.22)\n",
            "Epoch: [178][ 80/268]\tTime  0.417 ( 1.246)\tData  0.000 ( 0.850)\tLoss 2.3232e+00 (2.0039e+00)\tAcc@1  38.67 ( 66.03)\tAcc@5  85.16 ( 94.10)\n",
            "Epoch: [178][ 90/268]\tTime  0.417 ( 1.178)\tData  0.000 ( 0.783)\tLoss 1.8421e+00 (1.9892e+00)\tAcc@1  66.02 ( 66.79)\tAcc@5  96.09 ( 94.39)\n",
            "Epoch: [178][100/268]\tTime  0.417 ( 1.124)\tData  0.000 ( 0.729)\tLoss 1.7441e+00 (1.9801e+00)\tAcc@1  81.25 ( 67.23)\tAcc@5  99.22 ( 94.46)\n",
            "Epoch: [178][110/268]\tTime  0.422 ( 1.078)\tData  0.000 ( 0.683)\tLoss 2.3187e+00 (1.9688e+00)\tAcc@1  46.88 ( 67.92)\tAcc@5  87.89 ( 94.56)\n",
            "Epoch: [178][120/268]\tTime  2.680 ( 1.043)\tData  2.349 ( 0.647)\tLoss 1.9851e+00 (1.9696e+00)\tAcc@1  72.66 ( 67.72)\tAcc@5  96.88 ( 94.56)\n",
            "Epoch: [178][130/268]\tTime  0.417 ( 0.995)\tData  0.000 ( 0.598)\tLoss 1.8580e+00 (1.9694e+00)\tAcc@1  78.91 ( 67.38)\tAcc@5  97.66 ( 94.60)\n",
            "Epoch: [178][140/268]\tTime  0.417 ( 0.969)\tData  0.009 ( 0.571)\tLoss 2.9856e+00 (1.9721e+00)\tAcc@1   4.69 ( 67.20)\tAcc@5  53.91 ( 94.32)\n",
            "Epoch: [178][150/268]\tTime  0.424 ( 0.941)\tData  0.001 ( 0.544)\tLoss 1.8015e+00 (1.9709e+00)\tAcc@1  77.34 ( 67.27)\tAcc@5  98.05 ( 94.33)\n",
            "Epoch: [178][160/268]\tTime  0.417 ( 0.921)\tData  0.000 ( 0.524)\tLoss 1.6157e+00 (1.9677e+00)\tAcc@1  92.58 ( 67.61)\tAcc@5  98.05 ( 94.42)\n",
            "Epoch: [178][170/268]\tTime  0.416 ( 0.908)\tData  0.000 ( 0.511)\tLoss 1.7398e+00 (1.9648e+00)\tAcc@1  85.55 ( 67.60)\tAcc@5  97.27 ( 94.47)\n",
            "Epoch: [178][180/268]\tTime  2.420 ( 0.892)\tData  2.083 ( 0.495)\tLoss 2.1952e+00 (1.9580e+00)\tAcc@1  48.44 ( 67.95)\tAcc@5  88.67 ( 94.55)\n",
            "Epoch: [178][190/268]\tTime  0.416 ( 0.868)\tData  0.000 ( 0.470)\tLoss 1.9816e+00 (1.9524e+00)\tAcc@1  72.66 ( 68.51)\tAcc@5  94.14 ( 94.67)\n",
            "Epoch: [178][200/268]\tTime  0.415 ( 0.856)\tData  0.000 ( 0.457)\tLoss 2.2264e+00 (1.9535e+00)\tAcc@1  46.09 ( 68.51)\tAcc@5  91.02 ( 94.65)\n",
            "Epoch: [178][210/268]\tTime  0.413 ( 0.845)\tData  0.000 ( 0.446)\tLoss 2.2740e+00 (1.9497e+00)\tAcc@1  38.28 ( 68.67)\tAcc@5  88.28 ( 94.66)\n",
            "Epoch: [178][220/268]\tTime  0.409 ( 0.834)\tData  0.000 ( 0.435)\tLoss 2.3220e+00 (1.9466e+00)\tAcc@1  48.44 ( 68.95)\tAcc@5  89.45 ( 94.68)\n",
            "Epoch: [178][230/268]\tTime  0.411 ( 0.824)\tData  0.001 ( 0.425)\tLoss 1.7495e+00 (1.9457e+00)\tAcc@1  85.94 ( 68.89)\tAcc@5  98.83 ( 94.69)\n",
            "Epoch: [178][240/268]\tTime  2.226 ( 0.814)\tData  1.880 ( 0.416)\tLoss 1.8537e+00 (1.9561e+00)\tAcc@1  79.69 ( 68.29)\tAcc@5  95.70 ( 94.52)\n",
            "Epoch: [178][250/268]\tTime  0.423 ( 0.799)\tData  0.000 ( 0.400)\tLoss 1.4550e+00 (1.9632e+00)\tAcc@1  91.41 ( 67.73)\tAcc@5  97.66 ( 94.38)\n",
            "Epoch: [178][260/268]\tTime  0.416 ( 0.791)\tData  0.000 ( 0.392)\tLoss 1.7188e+00 (1.9616e+00)\tAcc@1  87.89 ( 67.77)\tAcc@5  97.27 ( 94.39)\n",
            "epoch: 178\n",
            "2023-03-25 05:44:59.186794: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:44:59.186894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:44:59.186913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:03.160973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:03.161073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:03.161093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:07.084204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:07.084305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:07.084324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:11.010384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:11.010478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:11.010497: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:14.936894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:14.936994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:14.937012: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:18.822606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:18.822716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:18.822737: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:22.768041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:22.768140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:22.768160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:26.740376: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:26.740472: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:26.740499: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:30.655824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:30.655920: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:30.655938: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:34.613364: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:34.613468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:34.613496: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:38.566602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:38.566717: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:38.566736: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:45:42.464338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:42.464441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:45:42.464460: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [179][  0/268]\tTime 54.955 (54.955)\tData 54.621 (54.621)\tLoss 2.3679e+00 (2.3679e+00)\tAcc@1  37.11 ( 37.11)\tAcc@5  89.45 ( 89.45)\n",
            "Epoch: [179][ 10/268]\tTime  0.417 ( 5.409)\tData  0.000 ( 5.017)\tLoss 1.9555e+00 (1.9231e+00)\tAcc@1  68.75 ( 69.74)\tAcc@5  94.14 ( 93.79)\n",
            "Epoch: [179][ 20/268]\tTime  0.410 ( 3.133)\tData  0.000 ( 2.743)\tLoss 1.6438e+00 (1.9061e+00)\tAcc@1  87.89 ( 71.74)\tAcc@5  98.05 ( 94.57)\n",
            "Epoch: [179][ 30/268]\tTime  0.417 ( 2.335)\tData  0.000 ( 1.940)\tLoss 1.6391e+00 (1.9060e+00)\tAcc@1  86.72 ( 70.93)\tAcc@5  99.22 ( 94.68)\n",
            "Epoch: [179][ 40/268]\tTime  0.417 ( 1.927)\tData  0.000 ( 1.530)\tLoss 1.8809e+00 (1.8996e+00)\tAcc@1  78.52 ( 71.17)\tAcc@5  96.88 ( 94.82)\n",
            "Epoch: [179][ 50/268]\tTime  0.441 ( 1.663)\tData  0.000 ( 1.266)\tLoss 1.6592e+00 (1.9024e+00)\tAcc@1  81.25 ( 70.55)\tAcc@5  98.05 ( 94.65)\n",
            "Epoch: [179][ 60/268]\tTime  2.631 ( 1.496)\tData  2.286 ( 1.098)\tLoss 2.3526e+00 (1.9362e+00)\tAcc@1  42.19 ( 68.78)\tAcc@5  87.50 ( 93.99)\n",
            "Epoch: [179][ 70/268]\tTime  0.429 ( 1.344)\tData  0.000 ( 0.945)\tLoss 2.3468e+00 (1.9499e+00)\tAcc@1  38.67 ( 67.97)\tAcc@5  90.23 ( 94.06)\n",
            "Epoch: [179][ 80/268]\tTime  0.416 ( 1.252)\tData  0.000 ( 0.853)\tLoss 2.4086e+00 (1.9614e+00)\tAcc@1  38.67 ( 67.39)\tAcc@5  84.77 ( 93.89)\n",
            "Epoch: [179][ 90/268]\tTime  0.410 ( 1.189)\tData  0.000 ( 0.789)\tLoss 1.7437e+00 (1.9830e+00)\tAcc@1  84.38 ( 66.24)\tAcc@5  99.22 ( 93.45)\n",
            "Epoch: [179][100/268]\tTime  0.416 ( 1.133)\tData  0.000 ( 0.734)\tLoss 2.0077e+00 (1.9818e+00)\tAcc@1  65.62 ( 66.21)\tAcc@5  96.09 ( 93.31)\n",
            "Epoch: [179][110/268]\tTime  0.412 ( 1.084)\tData  0.000 ( 0.685)\tLoss 1.8120e+00 (1.9782e+00)\tAcc@1  79.69 ( 66.55)\tAcc@5  97.66 ( 93.42)\n",
            "Epoch: [179][120/268]\tTime  1.790 ( 1.041)\tData  1.467 ( 0.641)\tLoss 1.8826e+00 (1.9763e+00)\tAcc@1  80.08 ( 66.82)\tAcc@5  95.31 ( 93.49)\n",
            "Epoch: [179][130/268]\tTime  0.433 ( 0.993)\tData  0.001 ( 0.593)\tLoss 2.4179e+00 (1.9675e+00)\tAcc@1  43.36 ( 67.27)\tAcc@5  84.77 ( 93.58)\n",
            "Epoch: [179][140/268]\tTime  0.416 ( 0.971)\tData  0.000 ( 0.571)\tLoss 1.6957e+00 (1.9539e+00)\tAcc@1  85.16 ( 68.18)\tAcc@5  97.27 ( 93.84)\n",
            "Epoch: [179][150/268]\tTime  0.417 ( 0.950)\tData  0.000 ( 0.550)\tLoss 1.6856e+00 (1.9469e+00)\tAcc@1  87.89 ( 68.40)\tAcc@5  98.44 ( 94.01)\n",
            "Epoch: [179][160/268]\tTime  0.413 ( 0.930)\tData  0.000 ( 0.530)\tLoss 1.7836e+00 (1.9372e+00)\tAcc@1  81.25 ( 68.84)\tAcc@5  97.66 ( 94.17)\n",
            "Epoch: [179][170/268]\tTime  0.417 ( 0.913)\tData  0.000 ( 0.513)\tLoss 1.7338e+00 (1.9336e+00)\tAcc@1  80.08 ( 69.00)\tAcc@5  98.05 ( 94.18)\n",
            "Epoch: [179][180/268]\tTime  2.432 ( 0.897)\tData  2.102 ( 0.497)\tLoss 2.3805e+00 (1.9396e+00)\tAcc@1  40.23 ( 68.65)\tAcc@5  89.45 ( 94.15)\n",
            "Epoch: [179][190/268]\tTime  0.424 ( 0.872)\tData  0.000 ( 0.471)\tLoss 1.8739e+00 (1.9398e+00)\tAcc@1  61.72 ( 68.62)\tAcc@5  97.27 ( 94.19)\n",
            "Epoch: [179][200/268]\tTime  0.417 ( 0.858)\tData  0.000 ( 0.458)\tLoss 1.7494e+00 (1.9366e+00)\tAcc@1  83.20 ( 68.95)\tAcc@5  98.05 ( 94.24)\n",
            "Epoch: [179][210/268]\tTime  0.407 ( 0.847)\tData  0.000 ( 0.447)\tLoss 1.8730e+00 (1.9320e+00)\tAcc@1  71.09 ( 69.21)\tAcc@5  96.88 ( 94.36)\n",
            "Epoch: [179][220/268]\tTime  0.426 ( 0.838)\tData  0.013 ( 0.438)\tLoss 1.9738e+00 (1.9347e+00)\tAcc@1  58.20 ( 69.00)\tAcc@5  96.48 ( 94.39)\n",
            "Epoch: [179][230/268]\tTime  0.417 ( 0.828)\tData  0.000 ( 0.428)\tLoss 2.3011e+00 (1.9374e+00)\tAcc@1  60.55 ( 68.83)\tAcc@5  86.72 ( 94.38)\n",
            "Epoch: [179][240/268]\tTime  3.139 ( 0.823)\tData  2.798 ( 0.422)\tLoss 2.1454e+00 (1.9346e+00)\tAcc@1  50.78 ( 68.94)\tAcc@5  91.02 ( 94.44)\n",
            "Epoch: [179][250/268]\tTime  0.416 ( 0.806)\tData  0.000 ( 0.406)\tLoss 2.2076e+00 (1.9338e+00)\tAcc@1  58.20 ( 69.08)\tAcc@5  89.84 ( 94.48)\n",
            "Epoch: [179][260/268]\tTime  0.415 ( 0.796)\tData  0.000 ( 0.395)\tLoss 2.2918e+00 (1.9337e+00)\tAcc@1  44.14 ( 69.15)\tAcc@5  89.45 ( 94.50)\n",
            "epoch: 179\n",
            "2023-03-25 05:48:31.492242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:31.492344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:31.492362: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:35.452487: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:35.452597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:35.452618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:39.417840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:39.417938: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:39.417956: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:43.358425: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:43.358521: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:43.358540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:47.331936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:47.332031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:47.332051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:51.289482: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:51.289591: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:51.289611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:55.217220: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:55.217325: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:55.217343: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:48:59.157106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:59.157200: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:48:59.157218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:49:03.136653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:03.136764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:03.136783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:49:07.079518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:07.079617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:07.079635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:49:10.975772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:10.975872: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:10.975889: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:49:14.916122: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:14.916224: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:49:14.916243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [180][  0/268]\tTime 55.605 (55.605)\tData 55.254 (55.254)\tLoss 1.9426e+00 (1.9426e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [180][ 10/268]\tTime  0.444 ( 5.439)\tData  0.013 ( 5.036)\tLoss 2.2743e+00 (1.8746e+00)\tAcc@1  41.80 ( 74.18)\tAcc@5  91.80 ( 96.41)\n",
            "Epoch: [180][ 20/268]\tTime  0.417 ( 3.129)\tData  0.000 ( 2.729)\tLoss 1.8616e+00 (1.8598e+00)\tAcc@1  78.52 ( 75.07)\tAcc@5  96.88 ( 96.22)\n",
            "Epoch: [180][ 30/268]\tTime  0.428 ( 2.350)\tData  0.000 ( 1.951)\tLoss 1.5384e+00 (1.8415e+00)\tAcc@1  90.62 ( 75.98)\tAcc@5  99.22 ( 96.22)\n",
            "Epoch: [180][ 40/268]\tTime  0.417 ( 1.921)\tData  0.000 ( 1.522)\tLoss 2.0527e+00 (1.8440e+00)\tAcc@1  73.05 ( 76.08)\tAcc@5  96.88 ( 96.50)\n",
            "Epoch: [180][ 50/268]\tTime  0.422 ( 1.662)\tData  0.000 ( 1.262)\tLoss 1.9652e+00 (1.8622e+00)\tAcc@1  58.59 ( 74.54)\tAcc@5  94.53 ( 96.31)\n",
            "Epoch: [180][ 60/268]\tTime  2.674 ( 1.496)\tData  2.323 ( 1.095)\tLoss 1.6820e+00 (1.8705e+00)\tAcc@1  82.03 ( 74.00)\tAcc@5  96.88 ( 96.18)\n",
            "Epoch: [180][ 70/268]\tTime  0.435 ( 1.344)\tData  0.000 ( 0.943)\tLoss 2.0234e+00 (1.8882e+00)\tAcc@1  51.95 ( 72.39)\tAcc@5  96.09 ( 95.83)\n",
            "Epoch: [180][ 80/268]\tTime  0.410 ( 1.247)\tData  0.000 ( 0.845)\tLoss 1.8073e+00 (1.8876e+00)\tAcc@1  79.30 ( 72.75)\tAcc@5  98.05 ( 95.86)\n",
            "Epoch: [180][ 90/268]\tTime  0.430 ( 1.175)\tData  0.000 ( 0.775)\tLoss 2.1804e+00 (1.8849e+00)\tAcc@1  44.92 ( 72.69)\tAcc@5  92.58 ( 95.92)\n",
            "Epoch: [180][100/268]\tTime  0.420 ( 1.127)\tData  0.000 ( 0.727)\tLoss 2.1867e+00 (1.8947e+00)\tAcc@1  45.70 ( 71.74)\tAcc@5  92.58 ( 95.83)\n",
            "Epoch: [180][110/268]\tTime  0.428 ( 1.083)\tData  0.000 ( 0.682)\tLoss 2.0505e+00 (1.8851e+00)\tAcc@1  56.64 ( 72.26)\tAcc@5  94.14 ( 95.89)\n",
            "Epoch: [180][120/268]\tTime  2.647 ( 1.047)\tData  2.317 ( 0.646)\tLoss 2.0032e+00 (1.8957e+00)\tAcc@1  67.97 ( 71.63)\tAcc@5  97.27 ( 95.78)\n",
            "Epoch: [180][130/268]\tTime  0.414 ( 0.999)\tData  0.006 ( 0.598)\tLoss 1.8432e+00 (1.8988e+00)\tAcc@1  84.77 ( 71.34)\tAcc@5  97.27 ( 95.69)\n",
            "Epoch: [180][140/268]\tTime  0.420 ( 0.969)\tData  0.000 ( 0.567)\tLoss 1.6874e+00 (1.9044e+00)\tAcc@1  83.59 ( 71.11)\tAcc@5  97.66 ( 95.63)\n",
            "Epoch: [180][150/268]\tTime  0.417 ( 0.947)\tData  0.001 ( 0.545)\tLoss 1.6661e+00 (1.9075e+00)\tAcc@1  82.03 ( 71.05)\tAcc@5  97.66 ( 95.55)\n",
            "Epoch: [180][160/268]\tTime  0.432 ( 0.926)\tData  0.000 ( 0.524)\tLoss 1.9016e+00 (1.9130e+00)\tAcc@1  76.17 ( 70.78)\tAcc@5  96.09 ( 95.52)\n",
            "Epoch: [180][170/268]\tTime  0.423 ( 0.912)\tData  0.000 ( 0.511)\tLoss 2.1391e+00 (1.9140e+00)\tAcc@1  50.78 ( 70.69)\tAcc@5  92.97 ( 95.52)\n",
            "Epoch: [180][180/268]\tTime  2.255 ( 0.895)\tData  1.918 ( 0.494)\tLoss 1.8643e+00 (1.9144e+00)\tAcc@1  73.44 ( 70.58)\tAcc@5  96.88 ( 95.53)\n",
            "Epoch: [180][190/268]\tTime  0.417 ( 0.870)\tData  0.000 ( 0.468)\tLoss 2.0173e+00 (1.9169e+00)\tAcc@1  71.09 ( 70.37)\tAcc@5  96.88 ( 95.48)\n",
            "Epoch: [180][200/268]\tTime  0.417 ( 0.860)\tData  0.000 ( 0.458)\tLoss 2.2960e+00 (1.9196e+00)\tAcc@1  58.20 ( 70.21)\tAcc@5  93.36 ( 95.45)\n",
            "Epoch: [180][210/268]\tTime  0.431 ( 0.848)\tData  0.013 ( 0.447)\tLoss 1.8652e+00 (1.9180e+00)\tAcc@1  81.64 ( 70.18)\tAcc@5  97.27 ( 95.42)\n",
            "Epoch: [180][220/268]\tTime  0.417 ( 0.835)\tData  0.000 ( 0.433)\tLoss 1.6238e+00 (1.9185e+00)\tAcc@1  91.41 ( 69.96)\tAcc@5  99.22 ( 95.40)\n",
            "Epoch: [180][230/268]\tTime  0.416 ( 0.826)\tData  0.000 ( 0.424)\tLoss 1.2836e+00 (1.9133e+00)\tAcc@1  95.70 ( 70.16)\tAcc@5  98.83 ( 95.43)\n",
            "Epoch: [180][240/268]\tTime  3.219 ( 0.820)\tData  2.877 ( 0.419)\tLoss 1.8154e+00 (1.9115e+00)\tAcc@1  81.25 ( 70.30)\tAcc@5  97.66 ( 95.43)\n",
            "Epoch: [180][250/268]\tTime  0.417 ( 0.805)\tData  0.000 ( 0.402)\tLoss 2.0306e+00 (1.9129e+00)\tAcc@1  57.42 ( 70.12)\tAcc@5  94.92 ( 95.41)\n",
            "Epoch: [180][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.392)\tLoss 2.0937e+00 (1.9101e+00)\tAcc@1  54.30 ( 70.38)\tAcc@5  94.92 ( 95.47)\n",
            "epoch: 180\n",
            "2023-03-25 05:52:03.518988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:03.519090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:03.519110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:07.433133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:07.433232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:07.433251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:11.362163: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:11.362258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:11.362277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:15.344295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:15.344422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:15.344442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:19.268767: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:19.268863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:19.268882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:23.169558: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:23.169672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:23.169693: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:27.143351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:27.143447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:27.143465: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:31.080709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:31.080808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:31.080828: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:34.999579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:34.999688: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:34.999707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:38.970833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:38.970924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:38.970943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:42.875233: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:42.875331: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:42.875349: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:52:46.800354: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:46.800462: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:52:46.800488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [181][  0/268]\tTime 55.418 (55.418)\tData 55.083 (55.083)\tLoss 2.0817e+00 (2.0817e+00)\tAcc@1  75.78 ( 75.78)\tAcc@5  94.14 ( 94.14)\n",
            "Epoch: [181][ 10/268]\tTime  0.417 ( 5.425)\tData  0.013 ( 5.026)\tLoss 2.1696e+00 (2.1366e+00)\tAcc@1  59.38 ( 55.86)\tAcc@5  94.53 ( 93.29)\n",
            "Epoch: [181][ 20/268]\tTime  0.417 ( 3.150)\tData  0.000 ( 2.750)\tLoss 1.9027e+00 (2.0455e+00)\tAcc@1  79.30 ( 63.73)\tAcc@5  96.88 ( 94.40)\n",
            "Epoch: [181][ 30/268]\tTime  0.423 ( 2.342)\tData  0.005 ( 1.943)\tLoss 2.3748e+00 (2.0436e+00)\tAcc@1  40.23 ( 63.24)\tAcc@5  89.84 ( 93.91)\n",
            "Epoch: [181][ 40/268]\tTime  0.408 ( 1.904)\tData  0.000 ( 1.505)\tLoss 1.5093e+00 (2.0509e+00)\tAcc@1  91.80 ( 63.12)\tAcc@5  98.83 ( 93.62)\n",
            "Epoch: [181][ 50/268]\tTime  0.485 ( 1.643)\tData  0.167 ( 1.246)\tLoss 2.0578e+00 (2.0208e+00)\tAcc@1  83.98 ( 65.19)\tAcc@5  94.92 ( 94.01)\n",
            "Epoch: [181][ 60/268]\tTime  2.007 ( 1.469)\tData  1.682 ( 1.071)\tLoss 1.7520e+00 (2.0438e+00)\tAcc@1  73.05 ( 63.31)\tAcc@5  98.83 ( 93.69)\n",
            "Epoch: [181][ 70/268]\tTime  0.420 ( 1.321)\tData  0.000 ( 0.922)\tLoss 2.1867e+00 (2.0498e+00)\tAcc@1  52.73 ( 62.70)\tAcc@5  92.97 ( 93.32)\n",
            "Epoch: [181][ 80/268]\tTime  0.408 ( 1.236)\tData  0.000 ( 0.837)\tLoss 2.1942e+00 (2.0566e+00)\tAcc@1  52.34 ( 63.04)\tAcc@5  93.75 ( 93.35)\n",
            "Epoch: [181][ 90/268]\tTime  0.411 ( 1.167)\tData  0.000 ( 0.768)\tLoss 1.6727e+00 (2.0374e+00)\tAcc@1  78.12 ( 63.83)\tAcc@5  98.83 ( 93.52)\n",
            "Epoch: [181][100/268]\tTime  0.450 ( 1.115)\tData  0.000 ( 0.716)\tLoss 1.6302e+00 (2.0356e+00)\tAcc@1  80.08 ( 63.71)\tAcc@5  97.27 ( 93.41)\n",
            "Epoch: [181][110/268]\tTime  0.409 ( 1.085)\tData  0.001 ( 0.685)\tLoss 2.4614e+00 (2.0238e+00)\tAcc@1  58.20 ( 64.34)\tAcc@5  88.67 ( 93.51)\n",
            "Epoch: [181][120/268]\tTime  2.701 ( 1.048)\tData  2.374 ( 0.649)\tLoss 1.8262e+00 (2.0039e+00)\tAcc@1  88.67 ( 65.32)\tAcc@5  96.48 ( 93.70)\n",
            "Epoch: [181][130/268]\tTime  0.435 ( 1.001)\tData  0.000 ( 0.600)\tLoss 1.4375e+00 (2.0040e+00)\tAcc@1  94.14 ( 65.34)\tAcc@5  98.83 ( 93.72)\n",
            "Epoch: [181][140/268]\tTime  0.422 ( 0.973)\tData  0.000 ( 0.573)\tLoss 1.5850e+00 (1.9999e+00)\tAcc@1  89.06 ( 65.70)\tAcc@5  98.83 ( 93.80)\n",
            "Epoch: [181][150/268]\tTime  0.425 ( 0.943)\tData  0.000 ( 0.543)\tLoss 1.5888e+00 (1.9993e+00)\tAcc@1  84.77 ( 65.64)\tAcc@5  99.22 ( 93.83)\n",
            "Epoch: [181][160/268]\tTime  0.421 ( 0.926)\tData  0.000 ( 0.527)\tLoss 2.4249e+00 (1.9987e+00)\tAcc@1  37.50 ( 65.75)\tAcc@5  84.38 ( 93.77)\n",
            "Epoch: [181][170/268]\tTime  0.418 ( 0.905)\tData  0.080 ( 0.506)\tLoss 2.4246e+00 (1.9893e+00)\tAcc@1  23.05 ( 66.19)\tAcc@5  87.11 ( 93.91)\n",
            "Epoch: [181][180/268]\tTime  2.527 ( 0.889)\tData  2.190 ( 0.490)\tLoss 1.7629e+00 (1.9836e+00)\tAcc@1  85.94 ( 66.43)\tAcc@5  98.83 ( 93.90)\n",
            "Epoch: [181][190/268]\tTime  0.426 ( 0.868)\tData  0.001 ( 0.469)\tLoss 1.7347e+00 (1.9859e+00)\tAcc@1  82.03 ( 66.33)\tAcc@5  98.05 ( 93.89)\n",
            "Epoch: [181][200/268]\tTime  0.417 ( 0.855)\tData  0.000 ( 0.456)\tLoss 2.3591e+00 (1.9851e+00)\tAcc@1  37.89 ( 66.40)\tAcc@5  87.50 ( 93.91)\n",
            "Epoch: [181][210/268]\tTime  0.417 ( 0.843)\tData  0.000 ( 0.445)\tLoss 1.6357e+00 (1.9848e+00)\tAcc@1  87.50 ( 66.48)\tAcc@5  97.66 ( 93.88)\n",
            "Epoch: [181][220/268]\tTime  0.423 ( 0.833)\tData  0.000 ( 0.436)\tLoss 1.7758e+00 (1.9869e+00)\tAcc@1  80.08 ( 66.62)\tAcc@5  98.44 ( 93.86)\n",
            "Epoch: [181][230/268]\tTime  1.323 ( 0.826)\tData  1.005 ( 0.428)\tLoss 1.7126e+00 (1.9805e+00)\tAcc@1  85.55 ( 66.85)\tAcc@5  98.83 ( 93.94)\n",
            "Epoch: [181][240/268]\tTime  1.254 ( 0.812)\tData  0.934 ( 0.415)\tLoss 1.5750e+00 (1.9781e+00)\tAcc@1  91.02 ( 67.07)\tAcc@5  99.22 ( 93.97)\n",
            "Epoch: [181][250/268]\tTime  0.417 ( 0.801)\tData  0.000 ( 0.404)\tLoss 1.6814e+00 (1.9695e+00)\tAcc@1  85.94 ( 67.51)\tAcc@5  97.27 ( 94.07)\n",
            "Epoch: [181][260/268]\tTime  0.416 ( 0.793)\tData  0.000 ( 0.396)\tLoss 1.7790e+00 (1.9610e+00)\tAcc@1  80.86 ( 67.97)\tAcc@5  97.66 ( 94.21)\n",
            "epoch: 181\n",
            "2023-03-25 05:55:35.152278: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:35.152378: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:35.152397: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:39.099800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:39.099898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:39.099917: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:42.993258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:42.993355: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:42.993375: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:46.888723: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:46.888818: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:46.888834: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:50.823429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:50.823528: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:50.823546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:54.717966: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:54.718065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:54.718084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:55:58.597518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:58.597617: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:55:58.597635: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:56:02.533383: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:02.533481: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:02.533500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:56:06.517034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:06.517145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:06.517165: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:56:10.431914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:10.432037: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:10.432056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:56:14.346459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:14.346592: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:14.346616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:56:18.270969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:18.271086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:56:18.271109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [182][  0/268]\tTime 54.635 (54.635)\tData 54.299 (54.299)\tLoss 2.3321e+00 (2.3321e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [182][ 10/268]\tTime  0.425 ( 5.347)\tData  0.000 ( 4.947)\tLoss 2.2623e+00 (1.9951e+00)\tAcc@1  42.97 ( 63.07)\tAcc@5  88.67 ( 94.50)\n",
            "Epoch: [182][ 20/268]\tTime  0.417 ( 3.123)\tData  0.000 ( 2.723)\tLoss 1.6522e+00 (1.9703e+00)\tAcc@1  83.20 ( 65.87)\tAcc@5  98.44 ( 95.09)\n",
            "Epoch: [182][ 30/268]\tTime  0.417 ( 2.306)\tData  0.000 ( 1.909)\tLoss 2.2814e+00 (1.9618e+00)\tAcc@1  58.20 ( 67.01)\tAcc@5  89.45 ( 95.17)\n",
            "Epoch: [182][ 40/268]\tTime  0.446 ( 1.898)\tData  0.001 ( 1.503)\tLoss 1.8861e+00 (1.9575e+00)\tAcc@1  71.09 ( 67.33)\tAcc@5  98.44 ( 95.23)\n",
            "Epoch: [182][ 50/268]\tTime  0.416 ( 1.669)\tData  0.001 ( 1.272)\tLoss 2.2493e+00 (1.9798e+00)\tAcc@1  39.84 ( 65.81)\tAcc@5  89.06 ( 94.89)\n",
            "Epoch: [182][ 60/268]\tTime  2.339 ( 1.496)\tData  2.001 ( 1.099)\tLoss 2.3418e+00 (1.9885e+00)\tAcc@1  42.19 ( 65.96)\tAcc@5  90.23 ( 94.79)\n",
            "Epoch: [182][ 70/268]\tTime  0.417 ( 1.345)\tData  0.000 ( 0.945)\tLoss 2.2882e+00 (1.9813e+00)\tAcc@1  48.83 ( 66.85)\tAcc@5  89.45 ( 94.89)\n",
            "Epoch: [182][ 80/268]\tTime  0.424 ( 1.253)\tData  0.000 ( 0.854)\tLoss 2.0028e+00 (1.9754e+00)\tAcc@1  75.00 ( 67.37)\tAcc@5  94.92 ( 94.87)\n",
            "Epoch: [182][ 90/268]\tTime  0.424 ( 1.188)\tData  0.000 ( 0.788)\tLoss 1.8134e+00 (1.9572e+00)\tAcc@1  87.50 ( 68.35)\tAcc@5  96.48 ( 95.08)\n",
            "Epoch: [182][100/268]\tTime  0.416 ( 1.131)\tData  0.000 ( 0.731)\tLoss 1.6437e+00 (1.9516e+00)\tAcc@1  89.45 ( 68.86)\tAcc@5  97.66 ( 95.16)\n",
            "Epoch: [182][110/268]\tTime  0.409 ( 1.086)\tData  0.000 ( 0.686)\tLoss 1.6322e+00 (1.9438e+00)\tAcc@1  89.45 ( 69.53)\tAcc@5  96.88 ( 95.18)\n",
            "Epoch: [182][120/268]\tTime  2.651 ( 1.050)\tData  2.316 ( 0.650)\tLoss 1.8450e+00 (1.9418e+00)\tAcc@1  71.09 ( 69.55)\tAcc@5  96.88 ( 95.29)\n",
            "Epoch: [182][130/268]\tTime  0.423 ( 1.002)\tData  0.000 ( 0.601)\tLoss 2.1938e+00 (1.9336e+00)\tAcc@1  44.92 ( 69.68)\tAcc@5  90.62 ( 95.33)\n",
            "Epoch: [182][140/268]\tTime  0.420 ( 0.975)\tData  0.000 ( 0.575)\tLoss 1.9558e+00 (1.9462e+00)\tAcc@1  56.64 ( 68.86)\tAcc@5  96.09 ( 95.25)\n",
            "Epoch: [182][150/268]\tTime  0.417 ( 0.954)\tData  0.000 ( 0.553)\tLoss 2.1514e+00 (1.9538e+00)\tAcc@1  53.91 ( 68.60)\tAcc@5  92.19 ( 95.08)\n",
            "Epoch: [182][160/268]\tTime  0.421 ( 0.932)\tData  0.000 ( 0.531)\tLoss 1.7350e+00 (1.9495e+00)\tAcc@1  91.80 ( 69.01)\tAcc@5  99.22 ( 95.13)\n",
            "Epoch: [182][170/268]\tTime  0.417 ( 0.915)\tData  0.000 ( 0.514)\tLoss 2.2125e+00 (1.9491e+00)\tAcc@1  41.41 ( 68.91)\tAcc@5  93.75 ( 95.15)\n",
            "Epoch: [182][180/268]\tTime  1.742 ( 0.895)\tData  1.408 ( 0.494)\tLoss 1.9068e+00 (1.9437e+00)\tAcc@1  80.08 ( 69.22)\tAcc@5  96.48 ( 95.22)\n",
            "Epoch: [182][190/268]\tTime  0.417 ( 0.870)\tData  0.000 ( 0.469)\tLoss 1.9441e+00 (1.9385e+00)\tAcc@1  59.38 ( 69.48)\tAcc@5  94.53 ( 95.27)\n",
            "Epoch: [182][200/268]\tTime  0.423 ( 0.860)\tData  0.000 ( 0.459)\tLoss 1.9788e+00 (1.9361e+00)\tAcc@1  60.16 ( 69.54)\tAcc@5  95.31 ( 95.33)\n",
            "Epoch: [182][210/268]\tTime  0.420 ( 0.849)\tData  0.000 ( 0.447)\tLoss 2.1581e+00 (1.9413e+00)\tAcc@1  46.48 ( 69.09)\tAcc@5  93.36 ( 95.30)\n",
            "Epoch: [182][220/268]\tTime  0.416 ( 0.839)\tData  0.000 ( 0.438)\tLoss 1.9711e+00 (1.9427e+00)\tAcc@1  69.92 ( 69.03)\tAcc@5  96.48 ( 95.29)\n",
            "Epoch: [182][230/268]\tTime  0.413 ( 0.829)\tData  0.000 ( 0.428)\tLoss 1.6459e+00 (1.9386e+00)\tAcc@1  85.16 ( 69.18)\tAcc@5  98.83 ( 95.35)\n",
            "Epoch: [182][240/268]\tTime  2.238 ( 0.820)\tData  1.911 ( 0.419)\tLoss 1.8839e+00 (1.9390e+00)\tAcc@1  79.30 ( 69.10)\tAcc@5  98.44 ( 95.38)\n",
            "Epoch: [182][250/268]\tTime  0.417 ( 0.804)\tData  0.000 ( 0.403)\tLoss 2.2745e+00 (1.9410e+00)\tAcc@1  43.75 ( 68.99)\tAcc@5  87.50 ( 95.34)\n",
            "Epoch: [182][260/268]\tTime  0.416 ( 0.794)\tData  0.000 ( 0.393)\tLoss 2.1846e+00 (1.9437e+00)\tAcc@1  46.09 ( 68.65)\tAcc@5  90.23 ( 95.31)\n",
            "epoch: 182\n",
            "2023-03-25 05:59:07.027891: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:07.027984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:07.028004: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:10.989627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:10.989743: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:10.989763: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:14.980981: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:14.981669: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:14.981694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:18.909475: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:18.909583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:18.909602: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:22.807443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:22.807568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:22.807587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:26.766725: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:26.766824: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:26.766842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:30.639672: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:30.639779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:30.639798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:34.547537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:34.547642: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:34.547672: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:38.471296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:38.471393: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:38.471413: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:42.394859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:42.394977: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:42.395000: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:46.324341: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:46.324437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:46.324456: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 05:59:50.289402: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:50.289499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 05:59:50.289519: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [183][  0/268]\tTime 55.143 (55.143)\tData 54.803 (54.803)\tLoss 1.7426e+00 (1.7426e+00)\tAcc@1  89.84 ( 89.84)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [183][ 10/268]\tTime  0.437 ( 5.434)\tData  0.000 ( 5.030)\tLoss 1.8787e+00 (1.9357e+00)\tAcc@1  68.75 ( 67.58)\tAcc@5  97.66 ( 95.42)\n",
            "Epoch: [183][ 20/268]\tTime  0.430 ( 3.131)\tData  0.002 ( 2.733)\tLoss 1.5876e+00 (1.9119e+00)\tAcc@1  87.89 ( 67.41)\tAcc@5  98.05 ( 95.22)\n",
            "Epoch: [183][ 30/268]\tTime  0.417 ( 2.317)\tData  0.000 ( 1.922)\tLoss 1.9535e+00 (1.9381e+00)\tAcc@1  75.78 ( 68.11)\tAcc@5  97.27 ( 95.50)\n",
            "Epoch: [183][ 40/268]\tTime  0.417 ( 1.899)\tData  0.001 ( 1.505)\tLoss 2.1725e+00 (1.9793e+00)\tAcc@1  44.92 ( 64.78)\tAcc@5  91.02 ( 94.97)\n",
            "Epoch: [183][ 50/268]\tTime  0.417 ( 1.645)\tData  0.000 ( 1.252)\tLoss 1.6558e+00 (1.9751e+00)\tAcc@1  85.16 ( 65.84)\tAcc@5  97.27 ( 94.92)\n",
            "Epoch: [183][ 60/268]\tTime  1.403 ( 1.460)\tData  1.076 ( 1.066)\tLoss 2.2522e+00 (1.9846e+00)\tAcc@1  47.66 ( 64.89)\tAcc@5  87.89 ( 94.66)\n",
            "Epoch: [183][ 70/268]\tTime  0.417 ( 1.331)\tData  0.000 ( 0.935)\tLoss 1.7822e+00 (1.9694e+00)\tAcc@1  89.84 ( 66.07)\tAcc@5  97.27 ( 94.86)\n",
            "Epoch: [183][ 80/268]\tTime  0.416 ( 1.244)\tData  0.000 ( 0.848)\tLoss 1.4592e+00 (1.9706e+00)\tAcc@1  85.94 ( 66.14)\tAcc@5  99.22 ( 94.74)\n",
            "Epoch: [183][ 90/268]\tTime  0.421 ( 1.180)\tData  0.000 ( 0.784)\tLoss 2.0955e+00 (1.9646e+00)\tAcc@1  73.83 ( 66.73)\tAcc@5  95.70 ( 94.89)\n",
            "Epoch: [183][100/268]\tTime  0.427 ( 1.118)\tData  0.000 ( 0.723)\tLoss 1.6675e+00 (1.9637e+00)\tAcc@1  84.38 ( 66.67)\tAcc@5  97.27 ( 94.66)\n",
            "Epoch: [183][110/268]\tTime  0.442 ( 1.072)\tData  0.000 ( 0.677)\tLoss 1.5461e+00 (1.9665e+00)\tAcc@1  92.58 ( 66.69)\tAcc@5  98.44 ( 94.64)\n",
            "Epoch: [183][120/268]\tTime  1.724 ( 1.029)\tData  1.396 ( 0.633)\tLoss 2.1171e+00 (1.9582e+00)\tAcc@1  76.95 ( 67.33)\tAcc@5  92.97 ( 94.73)\n",
            "Epoch: [183][130/268]\tTime  0.431 ( 0.990)\tData  0.000 ( 0.593)\tLoss 1.6358e+00 (1.9440e+00)\tAcc@1  85.94 ( 68.41)\tAcc@5  99.61 ( 94.93)\n",
            "Epoch: [183][140/268]\tTime  0.412 ( 0.960)\tData  0.000 ( 0.563)\tLoss 1.5927e+00 (1.9476e+00)\tAcc@1  89.45 ( 68.42)\tAcc@5 100.00 ( 94.58)\n",
            "Epoch: [183][150/268]\tTime  0.423 ( 0.940)\tData  0.000 ( 0.544)\tLoss 2.5585e+00 (1.9590e+00)\tAcc@1  49.61 ( 67.97)\tAcc@5  92.97 ( 94.51)\n",
            "Epoch: [183][160/268]\tTime  0.510 ( 0.920)\tData  0.192 ( 0.525)\tLoss 1.9217e+00 (1.9599e+00)\tAcc@1  66.80 ( 67.71)\tAcc@5  96.88 ( 94.54)\n",
            "Epoch: [183][170/268]\tTime  0.418 ( 0.904)\tData  0.001 ( 0.508)\tLoss 2.0028e+00 (1.9493e+00)\tAcc@1  70.31 ( 68.35)\tAcc@5  95.31 ( 94.65)\n",
            "Epoch: [183][180/268]\tTime  2.142 ( 0.886)\tData  1.822 ( 0.491)\tLoss 2.2409e+00 (1.9509e+00)\tAcc@1  42.97 ( 68.21)\tAcc@5  90.62 ( 94.62)\n",
            "Epoch: [183][190/268]\tTime  0.426 ( 0.863)\tData  0.000 ( 0.466)\tLoss 2.1079e+00 (1.9410e+00)\tAcc@1  55.47 ( 68.96)\tAcc@5  93.75 ( 94.74)\n",
            "Epoch: [183][200/268]\tTime  0.422 ( 0.852)\tData  0.000 ( 0.455)\tLoss 1.6179e+00 (1.9322e+00)\tAcc@1  85.94 ( 69.53)\tAcc@5  97.27 ( 94.83)\n",
            "Epoch: [183][210/268]\tTime  0.425 ( 0.843)\tData  0.000 ( 0.446)\tLoss 2.0555e+00 (1.9306e+00)\tAcc@1  56.25 ( 69.46)\tAcc@5  95.31 ( 94.86)\n",
            "Epoch: [183][220/268]\tTime  0.411 ( 0.835)\tData  0.000 ( 0.438)\tLoss 2.0804e+00 (1.9325e+00)\tAcc@1  50.00 ( 69.11)\tAcc@5  94.92 ( 94.82)\n",
            "Epoch: [183][230/268]\tTime  0.422 ( 0.824)\tData  0.000 ( 0.427)\tLoss 2.3598e+00 (1.9306e+00)\tAcc@1  37.50 ( 69.26)\tAcc@5  86.33 ( 94.82)\n",
            "Epoch: [183][240/268]\tTime  2.514 ( 0.815)\tData  2.170 ( 0.418)\tLoss 1.6427e+00 (1.9337e+00)\tAcc@1  86.72 ( 69.12)\tAcc@5  98.83 ( 94.80)\n",
            "Epoch: [183][250/268]\tTime  0.423 ( 0.800)\tData  0.000 ( 0.402)\tLoss 1.8705e+00 (1.9326e+00)\tAcc@1  86.72 ( 69.16)\tAcc@5  96.09 ( 94.83)\n",
            "Epoch: [183][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.394)\tLoss 1.7697e+00 (1.9314e+00)\tAcc@1  73.05 ( 69.05)\tAcc@5  96.88 ( 94.85)\n",
            "epoch: 183\n",
            "2023-03-25 06:02:38.319675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:38.319804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:38.319824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:02:42.273783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:42.273882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:42.273900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:02:46.256113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:46.256212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:46.256230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:02:50.284817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:50.284909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:50.284926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:02:54.248897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:54.248993: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:54.249011: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:02:58.189620: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:58.189733: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:02:58.189752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:02.130676: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:02.130764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:02.130786: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:06.066886: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:06.066985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:06.067003: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:09.998488: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:09.998586: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:09.998604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:13.940573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:13.940686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:13.940706: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:17.881574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:17.881686: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:17.881707: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:03:21.814699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:21.814791: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:03:21.814811: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [184][  0/268]\tTime 54.861 (54.861)\tData 54.517 (54.517)\tLoss 2.2538e+00 (2.2538e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [184][ 10/268]\tTime  0.418 ( 5.507)\tData  0.000 ( 5.106)\tLoss 1.5728e+00 (1.9094e+00)\tAcc@1  89.84 ( 70.81)\tAcc@5  96.88 ( 95.92)\n",
            "Epoch: [184][ 20/268]\tTime  0.420 ( 3.151)\tData  0.013 ( 2.756)\tLoss 2.2105e+00 (1.9862e+00)\tAcc@1  45.70 ( 66.28)\tAcc@5  90.23 ( 94.35)\n",
            "Epoch: [184][ 30/268]\tTime  0.421 ( 2.350)\tData  0.001 ( 1.953)\tLoss 2.2176e+00 (1.9270e+00)\tAcc@1  46.09 ( 69.46)\tAcc@5  89.06 ( 95.04)\n",
            "Epoch: [184][ 40/268]\tTime  0.417 ( 1.925)\tData  0.000 ( 1.527)\tLoss 1.9157e+00 (1.9487e+00)\tAcc@1  65.23 ( 67.77)\tAcc@5  97.27 ( 94.98)\n",
            "Epoch: [184][ 50/268]\tTime  0.417 ( 1.667)\tData  0.000 ( 1.269)\tLoss 1.9305e+00 (1.9265e+00)\tAcc@1  78.52 ( 69.60)\tAcc@5  96.88 ( 95.20)\n",
            "Epoch: [184][ 60/268]\tTime  2.820 ( 1.502)\tData  2.478 ( 1.103)\tLoss 1.8963e+00 (1.9167e+00)\tAcc@1  76.56 ( 70.52)\tAcc@5  97.27 ( 95.52)\n",
            "Epoch: [184][ 70/268]\tTime  0.423 ( 1.350)\tData  0.000 ( 0.950)\tLoss 2.1996e+00 (1.9172e+00)\tAcc@1  54.69 ( 70.58)\tAcc@5  89.84 ( 95.54)\n",
            "Epoch: [184][ 80/268]\tTime  0.443 ( 1.263)\tData  0.000 ( 0.862)\tLoss 1.9623e+00 (1.9110e+00)\tAcc@1  69.53 ( 70.72)\tAcc@5  98.05 ( 95.66)\n",
            "Epoch: [184][ 90/268]\tTime  0.422 ( 1.192)\tData  0.000 ( 0.791)\tLoss 2.0434e+00 (1.9108e+00)\tAcc@1  76.17 ( 70.84)\tAcc@5  92.97 ( 95.62)\n",
            "Epoch: [184][100/268]\tTime  0.414 ( 1.132)\tData  0.004 ( 0.731)\tLoss 1.6799e+00 (1.9156e+00)\tAcc@1  88.28 ( 70.47)\tAcc@5  98.83 ( 95.58)\n",
            "Epoch: [184][110/268]\tTime  0.416 ( 1.087)\tData  0.000 ( 0.686)\tLoss 1.9375e+00 (1.9147e+00)\tAcc@1  69.14 ( 70.82)\tAcc@5  95.70 ( 95.66)\n",
            "Epoch: [184][120/268]\tTime  2.282 ( 1.047)\tData  1.942 ( 0.646)\tLoss 2.1643e+00 (1.9190e+00)\tAcc@1  46.48 ( 70.57)\tAcc@5  93.36 ( 95.54)\n",
            "Epoch: [184][130/268]\tTime  0.417 ( 0.999)\tData  0.000 ( 0.598)\tLoss 1.8591e+00 (1.9135e+00)\tAcc@1  73.44 ( 70.89)\tAcc@5  97.27 ( 95.59)\n",
            "Epoch: [184][140/268]\tTime  0.417 ( 0.974)\tData  0.000 ( 0.573)\tLoss 2.0150e+00 (1.9147e+00)\tAcc@1  75.78 ( 70.82)\tAcc@5  96.88 ( 95.58)\n",
            "Epoch: [184][150/268]\tTime  0.436 ( 0.948)\tData  0.001 ( 0.547)\tLoss 2.2981e+00 (1.9314e+00)\tAcc@1  42.58 ( 69.88)\tAcc@5  88.28 ( 95.03)\n",
            "Epoch: [184][160/268]\tTime  0.412 ( 0.929)\tData  0.000 ( 0.528)\tLoss 1.8845e+00 (1.9291e+00)\tAcc@1  71.88 ( 70.15)\tAcc@5  97.66 ( 95.03)\n",
            "Epoch: [184][170/268]\tTime  0.421 ( 0.911)\tData  0.000 ( 0.510)\tLoss 1.7747e+00 (1.9244e+00)\tAcc@1  79.30 ( 70.21)\tAcc@5  97.66 ( 95.07)\n",
            "Epoch: [184][180/268]\tTime  2.612 ( 0.897)\tData  2.280 ( 0.496)\tLoss 1.9879e+00 (1.9174e+00)\tAcc@1  58.20 ( 70.66)\tAcc@5  95.70 ( 95.19)\n",
            "Epoch: [184][190/268]\tTime  0.430 ( 0.872)\tData  0.013 ( 0.470)\tLoss 1.8355e+00 (1.9137e+00)\tAcc@1  80.08 ( 70.72)\tAcc@5  97.27 ( 95.21)\n",
            "Epoch: [184][200/268]\tTime  0.417 ( 0.859)\tData  0.001 ( 0.458)\tLoss 1.8386e+00 (1.9134e+00)\tAcc@1  75.39 ( 70.66)\tAcc@5  96.48 ( 95.24)\n",
            "Epoch: [184][210/268]\tTime  0.417 ( 0.848)\tData  0.001 ( 0.447)\tLoss 2.3559e+00 (1.9127e+00)\tAcc@1  36.33 ( 70.72)\tAcc@5  87.11 ( 95.23)\n",
            "Epoch: [184][220/268]\tTime  0.417 ( 0.838)\tData  0.000 ( 0.437)\tLoss 1.9028e+00 (1.9153e+00)\tAcc@1  76.56 ( 70.60)\tAcc@5  97.27 ( 95.21)\n",
            "Epoch: [184][230/268]\tTime  0.424 ( 0.827)\tData  0.000 ( 0.426)\tLoss 2.2435e+00 (1.9129e+00)\tAcc@1  47.66 ( 70.73)\tAcc@5  88.28 ( 95.26)\n",
            "Epoch: [184][240/268]\tTime  1.414 ( 0.818)\tData  1.095 ( 0.417)\tLoss 1.8465e+00 (1.9127e+00)\tAcc@1  73.83 ( 70.89)\tAcc@5  97.66 ( 95.28)\n",
            "Epoch: [184][250/268]\tTime  0.415 ( 0.810)\tData  0.000 ( 0.409)\tLoss 1.8872e+00 (1.9115e+00)\tAcc@1  64.84 ( 70.89)\tAcc@5  96.09 ( 95.31)\n",
            "Epoch: [184][260/268]\tTime  0.416 ( 0.795)\tData  0.000 ( 0.394)\tLoss 2.4584e+00 (1.9142e+00)\tAcc@1  43.75 ( 70.87)\tAcc@5  92.19 ( 95.31)\n",
            "epoch: 184\n",
            "2023-03-25 06:06:10.482351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:10.482450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:10.482470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:14.428496: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:14.428607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:14.428626: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:18.380232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:18.380338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:18.380359: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:22.310511: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:22.310605: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:22.310623: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:26.289265: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:26.289366: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:26.289385: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:30.195894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:30.195991: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:30.196009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:34.120629: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:34.120770: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:34.120788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:38.099399: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:38.099509: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:38.099530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:42.074155: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:42.074255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:42.074275: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:46.012455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:46.012560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:46.012581: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:49.994568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:49.994691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:49.994719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:06:53.953859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:53.953961: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:06:53.953978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [185][  0/268]\tTime 55.157 (55.157)\tData 54.819 (54.819)\tLoss 1.6935e+00 (1.6935e+00)\tAcc@1  84.77 ( 84.77)\tAcc@5  98.05 ( 98.05)\n",
            "Epoch: [185][ 10/268]\tTime  0.416 ( 5.396)\tData  0.000 ( 4.992)\tLoss 1.9996e+00 (1.8901e+00)\tAcc@1  63.28 ( 68.39)\tAcc@5  97.27 ( 96.88)\n",
            "Epoch: [185][ 20/268]\tTime  0.417 ( 3.142)\tData  0.000 ( 2.740)\tLoss 1.5803e+00 (1.9170e+00)\tAcc@1  87.50 ( 67.15)\tAcc@5  96.48 ( 95.81)\n",
            "Epoch: [185][ 30/268]\tTime  0.427 ( 2.325)\tData  0.000 ( 1.923)\tLoss 1.7339e+00 (1.9232e+00)\tAcc@1  86.33 ( 67.89)\tAcc@5  97.27 ( 95.82)\n",
            "Epoch: [185][ 40/268]\tTime  0.423 ( 1.909)\tData  0.000 ( 1.509)\tLoss 2.1709e+00 (1.9352e+00)\tAcc@1  45.70 ( 67.64)\tAcc@5  91.02 ( 95.62)\n",
            "Epoch: [185][ 50/268]\tTime  0.421 ( 1.643)\tData  0.000 ( 1.243)\tLoss 2.1782e+00 (1.9576e+00)\tAcc@1  47.66 ( 65.83)\tAcc@5  90.23 ( 94.98)\n",
            "Epoch: [185][ 60/268]\tTime  3.071 ( 1.486)\tData  2.732 ( 1.087)\tLoss 2.3320e+00 (1.9511e+00)\tAcc@1  39.45 ( 66.76)\tAcc@5  85.94 ( 95.01)\n",
            "Epoch: [185][ 70/268]\tTime  0.417 ( 1.336)\tData  0.000 ( 0.935)\tLoss 2.0498e+00 (1.9594e+00)\tAcc@1  77.73 ( 66.66)\tAcc@5  95.70 ( 94.88)\n",
            "Epoch: [185][ 80/268]\tTime  0.423 ( 1.251)\tData  0.000 ( 0.852)\tLoss 2.0736e+00 (1.9475e+00)\tAcc@1  53.52 ( 67.04)\tAcc@5  95.70 ( 94.93)\n",
            "Epoch: [185][ 90/268]\tTime  0.415 ( 1.179)\tData  0.001 ( 0.781)\tLoss 2.2544e+00 (1.9486e+00)\tAcc@1  49.61 ( 67.33)\tAcc@5  90.62 ( 94.92)\n",
            "Epoch: [185][100/268]\tTime  0.417 ( 1.122)\tData  0.013 ( 0.725)\tLoss 1.6692e+00 (1.9422e+00)\tAcc@1  81.64 ( 67.73)\tAcc@5  98.44 ( 94.96)\n",
            "Epoch: [185][110/268]\tTime  0.409 ( 1.076)\tData  0.000 ( 0.678)\tLoss 1.9129e+00 (1.9272e+00)\tAcc@1  72.27 ( 69.09)\tAcc@5  96.48 ( 95.14)\n",
            "Epoch: [185][120/268]\tTime  1.897 ( 1.035)\tData  1.562 ( 0.638)\tLoss 1.7863e+00 (1.9122e+00)\tAcc@1  73.83 ( 69.78)\tAcc@5  97.27 ( 95.34)\n",
            "Epoch: [185][130/268]\tTime  0.407 ( 0.990)\tData  0.001 ( 0.592)\tLoss 2.1432e+00 (1.9088e+00)\tAcc@1  49.22 ( 69.84)\tAcc@5  89.45 ( 95.34)\n",
            "Epoch: [185][140/268]\tTime  0.422 ( 0.967)\tData  0.000 ( 0.571)\tLoss 2.2936e+00 (1.9163e+00)\tAcc@1  41.41 ( 69.11)\tAcc@5  89.45 ( 95.22)\n",
            "Epoch: [185][150/268]\tTime  0.416 ( 0.944)\tData  0.000 ( 0.548)\tLoss 2.2910e+00 (1.9114e+00)\tAcc@1  40.23 ( 69.44)\tAcc@5  89.45 ( 95.26)\n",
            "Epoch: [185][160/268]\tTime  0.417 ( 0.923)\tData  0.000 ( 0.527)\tLoss 1.3946e+00 (1.9056e+00)\tAcc@1  93.36 ( 69.83)\tAcc@5  99.22 ( 95.36)\n",
            "Epoch: [185][170/268]\tTime  0.416 ( 0.909)\tData  0.000 ( 0.513)\tLoss 1.5410e+00 (1.9081e+00)\tAcc@1  85.16 ( 69.85)\tAcc@5  98.83 ( 95.30)\n",
            "Epoch: [185][180/268]\tTime  2.164 ( 0.892)\tData  1.823 ( 0.495)\tLoss 2.1923e+00 (1.9082e+00)\tAcc@1  51.56 ( 69.74)\tAcc@5  91.80 ( 95.30)\n",
            "Epoch: [185][190/268]\tTime  0.421 ( 0.867)\tData  0.000 ( 0.470)\tLoss 1.7077e+00 (1.9076e+00)\tAcc@1  82.03 ( 69.76)\tAcc@5  98.05 ( 95.27)\n",
            "Epoch: [185][200/268]\tTime  0.423 ( 0.857)\tData  0.000 ( 0.460)\tLoss 1.7370e+00 (1.9086e+00)\tAcc@1  85.16 ( 69.98)\tAcc@5  98.05 ( 95.26)\n",
            "Epoch: [185][210/268]\tTime  0.416 ( 0.845)\tData  0.000 ( 0.449)\tLoss 1.7657e+00 (1.9069e+00)\tAcc@1  82.81 ( 70.08)\tAcc@5  97.66 ( 95.27)\n",
            "Epoch: [185][220/268]\tTime  0.430 ( 0.837)\tData  0.001 ( 0.441)\tLoss 1.6801e+00 (1.9057e+00)\tAcc@1  88.28 ( 70.16)\tAcc@5  97.27 ( 95.29)\n",
            "Epoch: [185][230/268]\tTime  0.792 ( 0.828)\tData  0.474 ( 0.433)\tLoss 2.1821e+00 (1.9031e+00)\tAcc@1  43.36 ( 70.26)\tAcc@5  91.02 ( 95.35)\n",
            "Epoch: [185][240/268]\tTime  1.168 ( 0.814)\tData  0.819 ( 0.419)\tLoss 1.7211e+00 (1.9040e+00)\tAcc@1  75.39 ( 70.28)\tAcc@5  96.88 ( 95.35)\n",
            "Epoch: [185][250/268]\tTime  0.417 ( 0.805)\tData  0.000 ( 0.410)\tLoss 1.7428e+00 (1.9023e+00)\tAcc@1  79.30 ( 70.31)\tAcc@5  97.66 ( 95.39)\n",
            "Epoch: [185][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.399)\tLoss 1.5406e+00 (1.9022e+00)\tAcc@1  92.58 ( 70.23)\tAcc@5  96.48 ( 95.39)\n",
            "epoch: 185\n",
            "2023-03-25 06:09:42.369434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:42.369544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:42.369564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:09:46.303242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:46.303344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:46.303363: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:09:50.247039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:50.247136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:50.247155: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:09:54.215683: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:54.215782: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:54.215799: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:09:58.155625: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:58.155753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:09:58.155772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:02.062694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:02.062787: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:02.062806: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:05.967583: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:05.967692: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:05.967710: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:09.893974: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:09.894074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:09.894094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:13.815239: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:13.815338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:13.815357: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:17.751448: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:17.751556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:17.751577: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:21.657975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:21.658078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:21.658096: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:10:25.595903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:25.596032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:10:25.596051: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [186][  0/268]\tTime 54.273 (54.273)\tData 53.930 (53.930)\tLoss 1.7872e+00 (1.7872e+00)\tAcc@1  83.20 ( 83.20)\tAcc@5  98.05 ( 98.05)\n",
            "Epoch: [186][ 10/268]\tTime  0.414 ( 5.376)\tData  0.000 ( 4.971)\tLoss 1.5576e+00 (1.9136e+00)\tAcc@1  90.62 ( 68.50)\tAcc@5  98.05 ( 95.63)\n",
            "Epoch: [186][ 20/268]\tTime  0.423 ( 3.122)\tData  0.000 ( 2.718)\tLoss 1.6342e+00 (1.9407e+00)\tAcc@1  80.08 ( 66.33)\tAcc@5  98.83 ( 95.07)\n",
            "Epoch: [186][ 30/268]\tTime  0.414 ( 2.297)\tData  0.000 ( 1.899)\tLoss 3.5730e+00 (1.9684e+00)\tAcc@1   3.52 ( 66.08)\tAcc@5  57.81 ( 94.25)\n",
            "Epoch: [186][ 40/268]\tTime  0.431 ( 1.882)\tData  0.000 ( 1.483)\tLoss 2.1682e+00 (1.9643e+00)\tAcc@1  48.83 ( 65.59)\tAcc@5  94.14 ( 94.58)\n",
            "Epoch: [186][ 50/268]\tTime  1.067 ( 1.644)\tData  0.729 ( 1.248)\tLoss 1.8351e+00 (1.9319e+00)\tAcc@1  81.25 ( 68.11)\tAcc@5  98.83 ( 95.17)\n",
            "Epoch: [186][ 60/268]\tTime  1.204 ( 1.456)\tData  0.882 ( 1.060)\tLoss 2.0029e+00 (1.9287e+00)\tAcc@1  53.91 ( 68.90)\tAcc@5  94.92 ( 95.29)\n",
            "Epoch: [186][ 70/268]\tTime  0.426 ( 1.328)\tData  0.000 ( 0.932)\tLoss 1.8343e+00 (1.9356e+00)\tAcc@1  80.47 ( 68.32)\tAcc@5  96.48 ( 95.16)\n",
            "Epoch: [186][ 80/268]\tTime  0.425 ( 1.245)\tData  0.000 ( 0.849)\tLoss 1.5905e+00 (1.9303e+00)\tAcc@1  94.92 ( 68.65)\tAcc@5 100.00 ( 95.16)\n",
            "Epoch: [186][ 90/268]\tTime  0.416 ( 1.173)\tData  0.000 ( 0.780)\tLoss 2.2280e+00 (1.9212e+00)\tAcc@1  37.50 ( 68.85)\tAcc@5  88.67 ( 95.25)\n",
            "Epoch: [186][100/268]\tTime  0.417 ( 1.121)\tData  0.001 ( 0.729)\tLoss 2.1786e+00 (1.9272e+00)\tAcc@1  53.91 ( 68.56)\tAcc@5  91.41 ( 95.18)\n",
            "Epoch: [186][110/268]\tTime  0.931 ( 1.074)\tData  0.613 ( 0.683)\tLoss 1.6651e+00 (1.9310e+00)\tAcc@1  84.77 ( 68.37)\tAcc@5  98.44 ( 95.12)\n",
            "Epoch: [186][120/268]\tTime  1.332 ( 1.028)\tData  0.999 ( 0.635)\tLoss 1.6820e+00 (1.9339e+00)\tAcc@1  91.41 ( 68.52)\tAcc@5  98.05 ( 95.12)\n",
            "Epoch: [186][130/268]\tTime  0.423 ( 0.995)\tData  0.000 ( 0.602)\tLoss 1.9451e+00 (1.9358e+00)\tAcc@1  72.27 ( 68.54)\tAcc@5  95.70 ( 95.09)\n",
            "Epoch: [186][140/268]\tTime  0.438 ( 0.969)\tData  0.000 ( 0.577)\tLoss 1.9426e+00 (1.9362e+00)\tAcc@1  74.61 ( 68.44)\tAcc@5  95.31 ( 95.06)\n",
            "Epoch: [186][150/268]\tTime  0.418 ( 0.950)\tData  0.001 ( 0.557)\tLoss 2.2166e+00 (1.9437e+00)\tAcc@1  42.58 ( 67.84)\tAcc@5  90.62 ( 94.91)\n",
            "Epoch: [186][160/268]\tTime  0.428 ( 0.931)\tData  0.000 ( 0.538)\tLoss 1.9830e+00 (1.9409e+00)\tAcc@1  80.86 ( 68.23)\tAcc@5  96.48 ( 94.95)\n",
            "Epoch: [186][170/268]\tTime  1.974 ( 0.910)\tData  1.656 ( 0.517)\tLoss 1.6820e+00 (1.9300e+00)\tAcc@1  86.33 ( 68.92)\tAcc@5  96.09 ( 95.04)\n",
            "Epoch: [186][180/268]\tTime  0.456 ( 0.883)\tData  0.118 ( 0.489)\tLoss 1.3802e+00 (1.9289e+00)\tAcc@1  92.19 ( 68.86)\tAcc@5  98.44 ( 95.00)\n",
            "Epoch: [186][190/268]\tTime  0.425 ( 0.870)\tData  0.001 ( 0.475)\tLoss 1.6915e+00 (1.9263e+00)\tAcc@1  86.72 ( 69.14)\tAcc@5  96.48 ( 95.02)\n",
            "Epoch: [186][200/268]\tTime  0.417 ( 0.856)\tData  0.000 ( 0.462)\tLoss 1.7281e+00 (1.9158e+00)\tAcc@1  80.47 ( 69.75)\tAcc@5  98.05 ( 95.13)\n",
            "Epoch: [186][210/268]\tTime  0.426 ( 0.844)\tData  0.000 ( 0.450)\tLoss 1.8731e+00 (1.9192e+00)\tAcc@1  74.61 ( 69.59)\tAcc@5  96.09 ( 95.09)\n",
            "Epoch: [186][220/268]\tTime  0.424 ( 0.833)\tData  0.000 ( 0.439)\tLoss 1.5679e+00 (1.9208e+00)\tAcc@1  88.67 ( 69.44)\tAcc@5  98.44 ( 95.09)\n",
            "Epoch: [186][230/268]\tTime  1.865 ( 0.828)\tData  1.539 ( 0.433)\tLoss 1.5834e+00 (1.9183e+00)\tAcc@1  90.62 ( 69.51)\tAcc@5  98.44 ( 95.09)\n",
            "Epoch: [186][240/268]\tTime  0.410 ( 0.811)\tData  0.000 ( 0.416)\tLoss 2.3347e+00 (1.9267e+00)\tAcc@1  33.20 ( 68.95)\tAcc@5  85.94 ( 94.95)\n",
            "Epoch: [186][250/268]\tTime  0.417 ( 0.804)\tData  0.000 ( 0.409)\tLoss 2.1751e+00 (1.9253e+00)\tAcc@1  50.78 ( 69.11)\tAcc@5  92.19 ( 94.96)\n",
            "Epoch: [186][260/268]\tTime  0.415 ( 0.795)\tData  0.000 ( 0.400)\tLoss 2.0329e+00 (1.9245e+00)\tAcc@1  77.73 ( 69.46)\tAcc@5  95.31 ( 95.03)\n",
            "epoch: 186\n",
            "2023-03-25 06:13:14.594100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:14.594197: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:14.594216: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:18.536494: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:18.536608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:18.536627: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:22.484087: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:22.484188: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:22.484207: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:26.415951: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:26.416049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:26.416069: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:30.370983: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:30.371076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:30.371095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:34.267454: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:34.267584: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:34.267604: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:38.185296: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:38.185397: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:38.185417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:42.111914: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:42.112012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:42.112033: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:46.027839: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:46.027930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:46.027949: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:49.951183: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:49.951286: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:49.951310: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:53.883409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:53.883513: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:53.883532: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:13:57.792624: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:57.792733: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:13:57.792751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [187][  0/268]\tTime 55.381 (55.381)\tData 55.040 (55.040)\tLoss 2.1633e+00 (2.1633e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [187][ 10/268]\tTime  0.417 ( 5.415)\tData  0.000 ( 5.015)\tLoss 1.7447e+00 (1.9863e+00)\tAcc@1  79.69 ( 66.02)\tAcc@5  97.66 ( 94.00)\n",
            "Epoch: [187][ 20/268]\tTime  0.416 ( 3.135)\tData  0.009 ( 2.737)\tLoss 1.7437e+00 (1.9600e+00)\tAcc@1  87.50 ( 68.66)\tAcc@5  96.48 ( 94.36)\n",
            "Epoch: [187][ 30/268]\tTime  0.422 ( 2.312)\tData  0.000 ( 1.919)\tLoss 2.0719e+00 (1.9423e+00)\tAcc@1  55.08 ( 68.57)\tAcc@5  94.53 ( 94.62)\n",
            "Epoch: [187][ 40/268]\tTime  0.420 ( 1.889)\tData  0.000 ( 1.500)\tLoss 1.6285e+00 (1.9509e+00)\tAcc@1  83.98 ( 67.60)\tAcc@5  98.83 ( 94.68)\n",
            "Epoch: [187][ 50/268]\tTime  0.653 ( 1.645)\tData  0.333 ( 1.256)\tLoss 2.2895e+00 (1.9672e+00)\tAcc@1  50.78 ( 67.06)\tAcc@5  88.67 ( 94.31)\n",
            "Epoch: [187][ 60/268]\tTime  2.434 ( 1.477)\tData  2.097 ( 1.087)\tLoss 1.7272e+00 (1.9546e+00)\tAcc@1  80.08 ( 67.92)\tAcc@5  97.66 ( 94.60)\n",
            "Epoch: [187][ 70/268]\tTime  0.434 ( 1.332)\tData  0.001 ( 0.940)\tLoss 1.8378e+00 (1.9425e+00)\tAcc@1  74.61 ( 68.74)\tAcc@5  97.27 ( 94.74)\n",
            "Epoch: [187][ 80/268]\tTime  0.410 ( 1.245)\tData  0.000 ( 0.853)\tLoss 1.8540e+00 (1.9375e+00)\tAcc@1  71.48 ( 69.16)\tAcc@5  97.66 ( 94.82)\n",
            "Epoch: [187][ 90/268]\tTime  0.423 ( 1.177)\tData  0.000 ( 0.785)\tLoss 1.8361e+00 (1.9218e+00)\tAcc@1  83.20 ( 70.27)\tAcc@5  96.48 ( 95.02)\n",
            "Epoch: [187][100/268]\tTime  0.423 ( 1.123)\tData  0.013 ( 0.732)\tLoss 1.6001e+00 (1.9219e+00)\tAcc@1  89.84 ( 70.53)\tAcc@5  98.83 ( 95.01)\n",
            "Epoch: [187][110/268]\tTime  0.927 ( 1.078)\tData  0.601 ( 0.687)\tLoss 2.1253e+00 (1.9353e+00)\tAcc@1  73.83 ( 70.32)\tAcc@5  94.92 ( 94.91)\n",
            "Epoch: [187][120/268]\tTime  1.809 ( 1.035)\tData  1.477 ( 0.644)\tLoss 1.7123e+00 (1.9318e+00)\tAcc@1  77.34 ( 70.45)\tAcc@5  96.88 ( 94.98)\n",
            "Epoch: [187][130/268]\tTime  0.420 ( 0.991)\tData  0.003 ( 0.598)\tLoss 1.9048e+00 (1.9258e+00)\tAcc@1  64.06 ( 70.63)\tAcc@5  97.66 ( 95.10)\n",
            "Epoch: [187][140/268]\tTime  0.416 ( 0.968)\tData  0.000 ( 0.575)\tLoss 1.5775e+00 (1.9159e+00)\tAcc@1  91.02 ( 71.23)\tAcc@5  99.22 ( 95.21)\n",
            "Epoch: [187][150/268]\tTime  0.417 ( 0.946)\tData  0.001 ( 0.552)\tLoss 1.6451e+00 (1.9077e+00)\tAcc@1  89.06 ( 71.77)\tAcc@5  97.66 ( 95.33)\n",
            "Epoch: [187][160/268]\tTime  0.414 ( 0.924)\tData  0.009 ( 0.530)\tLoss 1.8495e+00 (1.9079e+00)\tAcc@1  86.72 ( 71.76)\tAcc@5  96.09 ( 95.26)\n",
            "Epoch: [187][170/268]\tTime  0.416 ( 0.913)\tData  0.000 ( 0.518)\tLoss 2.2085e+00 (1.9062e+00)\tAcc@1  46.88 ( 71.79)\tAcc@5  90.62 ( 95.31)\n",
            "Epoch: [187][180/268]\tTime  1.951 ( 0.894)\tData  1.624 ( 0.499)\tLoss 1.9323e+00 (1.9084e+00)\tAcc@1  59.38 ( 71.67)\tAcc@5  96.48 ( 95.32)\n",
            "Epoch: [187][190/268]\tTime  0.409 ( 0.869)\tData  0.000 ( 0.474)\tLoss 1.9417e+00 (1.9110e+00)\tAcc@1  58.20 ( 71.58)\tAcc@5  96.09 ( 95.36)\n",
            "Epoch: [187][200/268]\tTime  0.417 ( 0.855)\tData  0.000 ( 0.460)\tLoss 2.2017e+00 (1.9199e+00)\tAcc@1  64.84 ( 71.13)\tAcc@5  93.36 ( 95.11)\n",
            "Epoch: [187][210/268]\tTime  0.430 ( 0.841)\tData  0.000 ( 0.446)\tLoss 1.9297e+00 (1.9144e+00)\tAcc@1  74.61 ( 71.58)\tAcc@5  95.70 ( 95.20)\n",
            "Epoch: [187][220/268]\tTime  0.426 ( 0.833)\tData  0.000 ( 0.438)\tLoss 2.3115e+00 (1.9184e+00)\tAcc@1  42.58 ( 71.21)\tAcc@5  89.06 ( 95.16)\n",
            "Epoch: [187][230/268]\tTime  0.416 ( 0.825)\tData  0.001 ( 0.429)\tLoss 1.7875e+00 (1.9196e+00)\tAcc@1  82.81 ( 71.12)\tAcc@5  98.05 ( 95.12)\n",
            "Epoch: [187][240/268]\tTime  2.527 ( 0.817)\tData  2.196 ( 0.421)\tLoss 1.7562e+00 (1.9169e+00)\tAcc@1  80.86 ( 71.18)\tAcc@5  96.88 ( 95.16)\n",
            "Epoch: [187][250/268]\tTime  0.417 ( 0.801)\tData  0.000 ( 0.405)\tLoss 1.7267e+00 (1.9082e+00)\tAcc@1  84.77 ( 71.72)\tAcc@5  98.83 ( 95.26)\n",
            "Epoch: [187][260/268]\tTime  0.415 ( 0.791)\tData  0.000 ( 0.396)\tLoss 1.8239e+00 (1.9190e+00)\tAcc@1  82.81 ( 71.16)\tAcc@5  96.09 ( 95.02)\n",
            "epoch: 187\n",
            "2023-03-25 06:16:45.756140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:45.756240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:45.756259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:16:49.732834: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:49.732929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:49.732946: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:16:53.702679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:53.702804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:53.702823: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:16:57.603391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:57.603498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:16:57.603518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:01.540869: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:01.540969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:01.540988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:05.504124: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:05.504226: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:05.504244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:09.399293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:09.399385: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:09.399404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:13.334419: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:13.334524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:13.334543: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:17.294573: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:17.294706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:17.294729: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:21.190644: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:21.190758: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:21.190779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:25.094559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:25.094653: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:25.094681: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:17:29.053424: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:29.053529: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:17:29.053546: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [188][  0/268]\tTime 55.204 (55.204)\tData 54.877 (54.877)\tLoss 1.8294e+00 (1.8294e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [188][ 10/268]\tTime  0.423 ( 5.428)\tData  0.000 ( 5.027)\tLoss 1.7701e+00 (1.8352e+00)\tAcc@1  85.16 ( 75.75)\tAcc@5  97.66 ( 97.05)\n",
            "Epoch: [188][ 20/268]\tTime  0.417 ( 3.171)\tData  0.000 ( 2.771)\tLoss 1.8297e+00 (1.8614e+00)\tAcc@1  82.42 ( 73.77)\tAcc@5  97.27 ( 96.65)\n",
            "Epoch: [188][ 30/268]\tTime  0.417 ( 2.344)\tData  0.000 ( 1.943)\tLoss 1.7951e+00 (1.8486e+00)\tAcc@1  89.45 ( 75.64)\tAcc@5  98.44 ( 96.59)\n",
            "Epoch: [188][ 40/268]\tTime  0.416 ( 1.909)\tData  0.001 ( 1.506)\tLoss 2.4293e+00 (1.8766e+00)\tAcc@1  36.72 ( 73.69)\tAcc@5  87.50 ( 96.21)\n",
            "Epoch: [188][ 50/268]\tTime  0.415 ( 1.668)\tData  0.000 ( 1.266)\tLoss 1.6847e+00 (1.8661e+00)\tAcc@1  86.72 ( 74.33)\tAcc@5  97.66 ( 96.25)\n",
            "Epoch: [188][ 60/268]\tTime  2.503 ( 1.498)\tData  2.165 ( 1.096)\tLoss 1.9885e+00 (1.8697e+00)\tAcc@1  52.73 ( 73.98)\tAcc@5  95.31 ( 96.11)\n",
            "Epoch: [188][ 70/268]\tTime  0.424 ( 1.346)\tData  0.000 ( 0.943)\tLoss 2.1621e+00 (1.9105e+00)\tAcc@1  48.05 ( 71.13)\tAcc@5  91.80 ( 95.41)\n",
            "Epoch: [188][ 80/268]\tTime  0.415 ( 1.256)\tData  0.001 ( 0.854)\tLoss 2.2764e+00 (1.9272e+00)\tAcc@1  43.36 ( 69.68)\tAcc@5  89.84 ( 95.16)\n",
            "Epoch: [188][ 90/268]\tTime  0.417 ( 1.190)\tData  0.000 ( 0.788)\tLoss 1.8096e+00 (1.9282e+00)\tAcc@1  77.34 ( 69.42)\tAcc@5  96.88 ( 95.12)\n",
            "Epoch: [188][100/268]\tTime  0.443 ( 1.137)\tData  0.013 ( 0.735)\tLoss 2.2176e+00 (1.9202e+00)\tAcc@1  47.66 ( 70.24)\tAcc@5  90.23 ( 95.25)\n",
            "Epoch: [188][110/268]\tTime  0.430 ( 1.092)\tData  0.000 ( 0.690)\tLoss 1.5844e+00 (1.9244e+00)\tAcc@1  87.50 ( 69.74)\tAcc@5  98.44 ( 95.15)\n",
            "Epoch: [188][120/268]\tTime  2.012 ( 1.050)\tData  1.694 ( 0.648)\tLoss 1.7621e+00 (1.9272e+00)\tAcc@1  75.39 ( 69.85)\tAcc@5  98.83 ( 95.15)\n",
            "Epoch: [188][130/268]\tTime  0.416 ( 1.001)\tData  0.000 ( 0.599)\tLoss 1.6478e+00 (1.9244e+00)\tAcc@1  91.41 ( 70.09)\tAcc@5  98.05 ( 95.15)\n",
            "Epoch: [188][140/268]\tTime  0.416 ( 0.974)\tData  0.000 ( 0.572)\tLoss 1.8069e+00 (1.9315e+00)\tAcc@1  77.73 ( 69.64)\tAcc@5  96.88 ( 95.02)\n",
            "Epoch: [188][150/268]\tTime  0.418 ( 0.952)\tData  0.013 ( 0.550)\tLoss 1.6516e+00 (1.9213e+00)\tAcc@1  89.45 ( 70.39)\tAcc@5  98.44 ( 95.17)\n",
            "Epoch: [188][160/268]\tTime  0.417 ( 0.928)\tData  0.000 ( 0.527)\tLoss 2.4117e+00 (1.9286e+00)\tAcc@1  37.11 ( 69.88)\tAcc@5  87.89 ( 95.05)\n",
            "Epoch: [188][170/268]\tTime  0.416 ( 0.910)\tData  0.000 ( 0.509)\tLoss 2.3212e+00 (1.9260e+00)\tAcc@1  41.80 ( 70.02)\tAcc@5  84.77 ( 95.05)\n",
            "Epoch: [188][180/268]\tTime  2.388 ( 0.894)\tData  2.057 ( 0.493)\tLoss 1.6346e+00 (1.9185e+00)\tAcc@1  84.77 ( 70.33)\tAcc@5  98.05 ( 95.07)\n",
            "Epoch: [188][190/268]\tTime  0.435 ( 0.870)\tData  0.000 ( 0.469)\tLoss 2.1922e+00 (1.9259e+00)\tAcc@1  63.67 ( 70.00)\tAcc@5  92.19 ( 94.93)\n",
            "Epoch: [188][200/268]\tTime  0.424 ( 0.858)\tData  0.000 ( 0.457)\tLoss 1.8608e+00 (1.9220e+00)\tAcc@1  79.69 ( 70.41)\tAcc@5  94.14 ( 94.98)\n",
            "Epoch: [188][210/268]\tTime  0.410 ( 0.847)\tData  0.000 ( 0.446)\tLoss 2.2800e+00 (1.9186e+00)\tAcc@1  37.11 ( 70.62)\tAcc@5  87.89 ( 95.02)\n",
            "Epoch: [188][220/268]\tTime  0.417 ( 0.836)\tData  0.000 ( 0.435)\tLoss 2.2058e+00 (1.9207e+00)\tAcc@1  46.48 ( 70.38)\tAcc@5  91.02 ( 95.00)\n",
            "Epoch: [188][230/268]\tTime  0.417 ( 0.824)\tData  0.000 ( 0.423)\tLoss 1.7158e+00 (1.9173e+00)\tAcc@1  85.16 ( 70.72)\tAcc@5  98.44 ( 95.08)\n",
            "Epoch: [188][240/268]\tTime  1.734 ( 0.815)\tData  1.414 ( 0.415)\tLoss 1.8315e+00 (1.9164e+00)\tAcc@1  73.44 ( 70.74)\tAcc@5  97.66 ( 95.09)\n",
            "Epoch: [188][250/268]\tTime  0.417 ( 0.805)\tData  0.000 ( 0.405)\tLoss 2.2914e+00 (1.9186e+00)\tAcc@1  42.97 ( 70.59)\tAcc@5  89.06 ( 95.06)\n",
            "Epoch: [188][260/268]\tTime  0.416 ( 0.792)\tData  0.000 ( 0.393)\tLoss 2.2650e+00 (1.9168e+00)\tAcc@1  63.67 ( 70.69)\tAcc@5  94.14 ( 95.09)\n",
            "epoch: 188\n",
            "2023-03-25 06:20:17.350310: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:17.350410: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:17.350428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:21.351351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:21.351450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:21.351469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:25.272297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:25.272395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:25.272414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:29.218443: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:29.218544: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:29.218564: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:33.120336: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:33.120434: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:33.120452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:37.054312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:37.054412: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:37.054432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:41.055130: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:41.055231: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:41.055252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:44.957469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:44.957579: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:44.957599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:48.852936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:48.853064: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:48.853082: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:52.760043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:52.760136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:52.760153: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:20:56.672356: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:56.672459: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:20:56.672480: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:21:00.545919: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:21:00.546025: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:21:00.546045: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [189][  0/268]\tTime 55.842 (55.842)\tData 55.500 (55.500)\tLoss 1.7588e+00 (1.7588e+00)\tAcc@1  82.42 ( 82.42)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [189][ 10/268]\tTime  0.431 ( 5.459)\tData  0.000 ( 5.056)\tLoss 1.8535e+00 (2.1256e+00)\tAcc@1  69.53 ( 59.66)\tAcc@5  96.88 ( 92.65)\n",
            "Epoch: [189][ 20/268]\tTime  0.417 ( 3.166)\tData  0.000 ( 2.766)\tLoss 1.8383e+00 (1.9794e+00)\tAcc@1  81.64 ( 66.78)\tAcc@5  98.44 ( 94.46)\n",
            "Epoch: [189][ 30/268]\tTime  0.421 ( 2.357)\tData  0.012 ( 1.957)\tLoss 2.3385e+00 (1.9400e+00)\tAcc@1  43.36 ( 69.04)\tAcc@5  88.28 ( 94.54)\n",
            "Epoch: [189][ 40/268]\tTime  0.416 ( 1.921)\tData  0.000 ( 1.521)\tLoss 1.6345e+00 (1.9533e+00)\tAcc@1  86.33 ( 68.23)\tAcc@5  98.83 ( 94.22)\n",
            "Epoch: [189][ 50/268]\tTime  0.416 ( 1.672)\tData  0.013 ( 1.272)\tLoss 1.6297e+00 (1.9464e+00)\tAcc@1  91.41 ( 68.88)\tAcc@5  98.83 ( 94.29)\n",
            "Epoch: [189][ 60/268]\tTime  2.302 ( 1.497)\tData  1.966 ( 1.098)\tLoss 2.3142e+00 (1.9636e+00)\tAcc@1  45.70 ( 67.98)\tAcc@5  89.06 ( 94.08)\n",
            "Epoch: [189][ 70/268]\tTime  0.436 ( 1.345)\tData  0.000 ( 0.945)\tLoss 2.3622e+00 (1.9375e+00)\tAcc@1  43.36 ( 69.34)\tAcc@5  87.50 ( 94.45)\n",
            "Epoch: [189][ 80/268]\tTime  0.417 ( 1.257)\tData  0.000 ( 0.857)\tLoss 1.8669e+00 (1.9348e+00)\tAcc@1  79.69 ( 69.78)\tAcc@5  96.88 ( 94.54)\n",
            "Epoch: [189][ 90/268]\tTime  0.413 ( 1.181)\tData  0.000 ( 0.780)\tLoss 1.5842e+00 (1.9269e+00)\tAcc@1  93.75 ( 70.38)\tAcc@5  99.22 ( 94.63)\n",
            "Epoch: [189][100/268]\tTime  0.408 ( 1.127)\tData  0.000 ( 0.727)\tLoss 1.9061e+00 (1.9262e+00)\tAcc@1  81.64 ( 70.65)\tAcc@5  95.31 ( 94.74)\n",
            "Epoch: [189][110/268]\tTime  0.411 ( 1.082)\tData  0.000 ( 0.683)\tLoss 1.4372e+00 (1.9129e+00)\tAcc@1  91.41 ( 71.13)\tAcc@5  99.61 ( 94.90)\n",
            "Epoch: [189][120/268]\tTime  1.598 ( 1.039)\tData  1.261 ( 0.641)\tLoss 1.8325e+00 (1.9263e+00)\tAcc@1  79.30 ( 70.72)\tAcc@5  98.44 ( 94.83)\n",
            "Epoch: [189][130/268]\tTime  0.420 ( 0.998)\tData  0.000 ( 0.599)\tLoss 1.8809e+00 (1.9321e+00)\tAcc@1  81.64 ( 70.37)\tAcc@5  95.31 ( 94.72)\n",
            "Epoch: [189][140/268]\tTime  0.416 ( 0.971)\tData  0.000 ( 0.575)\tLoss 2.3517e+00 (1.9355e+00)\tAcc@1  43.75 ( 69.90)\tAcc@5  84.38 ( 94.67)\n",
            "Epoch: [189][150/268]\tTime  0.961 ( 0.950)\tData  0.640 ( 0.555)\tLoss 2.2292e+00 (1.9349e+00)\tAcc@1  45.31 ( 69.77)\tAcc@5  90.62 ( 94.63)\n",
            "Epoch: [189][160/268]\tTime  0.417 ( 0.926)\tData  0.000 ( 0.530)\tLoss 1.6763e+00 (1.9304e+00)\tAcc@1  88.28 ( 69.83)\tAcc@5  98.44 ( 94.67)\n",
            "Epoch: [189][170/268]\tTime  0.416 ( 0.910)\tData  0.000 ( 0.515)\tLoss 1.7511e+00 (1.9202e+00)\tAcc@1  84.38 ( 70.43)\tAcc@5  97.66 ( 94.82)\n",
            "Epoch: [189][180/268]\tTime  0.861 ( 0.890)\tData  0.543 ( 0.495)\tLoss 1.6385e+00 (1.9242e+00)\tAcc@1  94.53 ( 70.43)\tAcc@5  98.83 ( 94.86)\n",
            "Epoch: [189][190/268]\tTime  0.418 ( 0.875)\tData  0.000 ( 0.480)\tLoss 1.9054e+00 (1.9210e+00)\tAcc@1  74.22 ( 70.79)\tAcc@5  97.27 ( 94.94)\n",
            "Epoch: [189][200/268]\tTime  0.416 ( 0.862)\tData  0.000 ( 0.468)\tLoss 2.3057e+00 (1.9263e+00)\tAcc@1  41.80 ( 70.48)\tAcc@5  89.45 ( 94.86)\n",
            "Epoch: [189][210/268]\tTime  1.731 ( 0.850)\tData  1.404 ( 0.457)\tLoss 2.1671e+00 (1.9254e+00)\tAcc@1  69.14 ( 70.65)\tAcc@5  92.58 ( 94.91)\n",
            "Epoch: [189][220/268]\tTime  0.417 ( 0.832)\tData  0.001 ( 0.438)\tLoss 1.9556e+00 (1.9303e+00)\tAcc@1  81.25 ( 70.38)\tAcc@5  96.09 ( 94.83)\n",
            "Epoch: [189][230/268]\tTime  0.433 ( 0.823)\tData  0.000 ( 0.429)\tLoss 1.6450e+00 (1.9252e+00)\tAcc@1  91.02 ( 70.75)\tAcc@5  95.70 ( 94.85)\n",
            "Epoch: [189][240/268]\tTime  0.660 ( 0.815)\tData  0.328 ( 0.421)\tLoss 1.8261e+00 (1.9186e+00)\tAcc@1  67.19 ( 71.14)\tAcc@5  97.27 ( 94.94)\n",
            "Epoch: [189][250/268]\tTime  0.418 ( 0.805)\tData  0.000 ( 0.412)\tLoss 2.2070e+00 (1.9178e+00)\tAcc@1  43.36 ( 71.22)\tAcc@5  90.23 ( 94.95)\n",
            "Epoch: [189][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.400)\tLoss 1.5483e+00 (1.9158e+00)\tAcc@1  92.58 ( 71.25)\tAcc@5  97.66 ( 94.96)\n",
            "epoch: 189\n",
            "2023-03-25 06:23:49.160850: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:49.160953: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:49.160974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:23:53.143050: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:53.143150: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:53.143168: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:23:57.057461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:57.057562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:23:57.057579: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:00.958582: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:00.958699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:00.958719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:04.923351: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:04.923451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:04.923471: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:08.822295: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:08.822394: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:08.822414: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:12.793152: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:12.793250: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:12.793270: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:16.710343: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:16.710444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:16.710463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:20.599789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:20.599881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:20.599900: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:24.491335: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:24.491436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:24.491455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:28.440067: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:28.440161: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:28.440179: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:24:32.336214: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:32.336311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:24:32.336328: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [190][  0/268]\tTime 54.097 (54.097)\tData 53.766 (53.766)\tLoss 1.7080e+00 (1.7080e+00)\tAcc@1  88.28 ( 88.28)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [190][ 10/268]\tTime  0.416 ( 5.343)\tData  0.000 ( 4.949)\tLoss 1.5927e+00 (1.9837e+00)\tAcc@1  90.23 ( 69.07)\tAcc@5  98.83 ( 94.82)\n",
            "Epoch: [190][ 20/268]\tTime  0.414 ( 3.119)\tData  0.000 ( 2.726)\tLoss 1.6773e+00 (1.9454e+00)\tAcc@1  79.69 ( 68.06)\tAcc@5  97.27 ( 94.92)\n",
            "Epoch: [190][ 30/268]\tTime  0.417 ( 2.300)\tData  0.000 ( 1.905)\tLoss 1.7125e+00 (1.8897e+00)\tAcc@1  84.38 ( 71.09)\tAcc@5  98.05 ( 95.30)\n",
            "Epoch: [190][ 40/268]\tTime  0.417 ( 1.915)\tData  0.013 ( 1.519)\tLoss 1.5803e+00 (1.8517e+00)\tAcc@1  85.55 ( 73.39)\tAcc@5  97.66 ( 95.78)\n",
            "Epoch: [190][ 50/268]\tTime  0.422 ( 1.648)\tData  0.000 ( 1.252)\tLoss 2.1862e+00 (1.8567e+00)\tAcc@1  44.92 ( 72.83)\tAcc@5  92.19 ( 95.83)\n",
            "Epoch: [190][ 60/268]\tTime  2.673 ( 1.484)\tData  2.339 ( 1.087)\tLoss 1.7458e+00 (1.8479e+00)\tAcc@1  80.47 ( 73.37)\tAcc@5  98.83 ( 95.96)\n",
            "Epoch: [190][ 70/268]\tTime  0.417 ( 1.333)\tData  0.000 ( 0.935)\tLoss 1.6860e+00 (1.8492e+00)\tAcc@1  90.62 ( 73.27)\tAcc@5  98.05 ( 95.92)\n",
            "Epoch: [190][ 80/268]\tTime  0.417 ( 1.242)\tData  0.000 ( 0.843)\tLoss 1.9719e+00 (1.8576e+00)\tAcc@1  69.14 ( 73.18)\tAcc@5  96.48 ( 95.90)\n",
            "Epoch: [190][ 90/268]\tTime  0.417 ( 1.177)\tData  0.000 ( 0.778)\tLoss 1.9180e+00 (1.8608e+00)\tAcc@1  74.22 ( 72.89)\tAcc@5  96.48 ( 95.97)\n",
            "Epoch: [190][100/268]\tTime  0.427 ( 1.124)\tData  0.000 ( 0.727)\tLoss 2.2389e+00 (1.8674e+00)\tAcc@1  40.23 ( 72.29)\tAcc@5  91.41 ( 95.89)\n",
            "Epoch: [190][110/268]\tTime  0.416 ( 1.078)\tData  0.000 ( 0.680)\tLoss 1.7119e+00 (1.8621e+00)\tAcc@1  86.72 ( 72.87)\tAcc@5  98.05 ( 95.96)\n",
            "Epoch: [190][120/268]\tTime  1.570 ( 1.033)\tData  1.243 ( 0.635)\tLoss 2.1395e+00 (1.8694e+00)\tAcc@1  65.23 ( 72.66)\tAcc@5  91.41 ( 95.84)\n",
            "Epoch: [190][130/268]\tTime  0.417 ( 0.991)\tData  0.000 ( 0.592)\tLoss 2.2539e+00 (1.8779e+00)\tAcc@1  43.36 ( 71.93)\tAcc@5  92.58 ( 95.67)\n",
            "Epoch: [190][140/268]\tTime  0.414 ( 0.966)\tData  0.000 ( 0.568)\tLoss 1.7654e+00 (1.8717e+00)\tAcc@1  82.42 ( 72.50)\tAcc@5  98.44 ( 95.76)\n",
            "Epoch: [190][150/268]\tTime  0.416 ( 0.942)\tData  0.000 ( 0.544)\tLoss 1.7134e+00 (1.8822e+00)\tAcc@1  85.55 ( 72.28)\tAcc@5  97.27 ( 95.49)\n",
            "Epoch: [190][160/268]\tTime  0.424 ( 0.924)\tData  0.000 ( 0.527)\tLoss 2.2182e+00 (1.8832e+00)\tAcc@1  50.39 ( 72.14)\tAcc@5  90.23 ( 95.48)\n",
            "Epoch: [190][170/268]\tTime  0.424 ( 0.906)\tData  0.000 ( 0.508)\tLoss 1.7700e+00 (1.8774e+00)\tAcc@1  80.08 ( 72.55)\tAcc@5  96.88 ( 95.55)\n",
            "Epoch: [190][180/268]\tTime  1.685 ( 0.887)\tData  1.354 ( 0.489)\tLoss 1.7159e+00 (1.8815e+00)\tAcc@1  92.58 ( 72.31)\tAcc@5  97.27 ( 95.46)\n",
            "Epoch: [190][190/268]\tTime  0.411 ( 0.865)\tData  0.001 ( 0.468)\tLoss 2.1145e+00 (1.8829e+00)\tAcc@1  47.27 ( 72.30)\tAcc@5  91.80 ( 95.44)\n",
            "Epoch: [190][200/268]\tTime  0.424 ( 0.857)\tData  0.000 ( 0.459)\tLoss 1.7628e+00 (1.8814e+00)\tAcc@1  83.98 ( 72.22)\tAcc@5  96.09 ( 95.48)\n",
            "Epoch: [190][210/268]\tTime  0.424 ( 0.845)\tData  0.003 ( 0.447)\tLoss 1.5279e+00 (1.8782e+00)\tAcc@1  92.58 ( 72.44)\tAcc@5  97.66 ( 95.51)\n",
            "Epoch: [190][220/268]\tTime  0.423 ( 0.834)\tData  0.000 ( 0.437)\tLoss 2.1835e+00 (1.8809e+00)\tAcc@1  51.95 ( 72.28)\tAcc@5  90.23 ( 95.49)\n",
            "Epoch: [190][230/268]\tTime  0.409 ( 0.822)\tData  0.000 ( 0.425)\tLoss 1.9082e+00 (1.8793e+00)\tAcc@1  69.53 ( 72.42)\tAcc@5  96.09 ( 95.52)\n",
            "Epoch: [190][240/268]\tTime  1.296 ( 0.813)\tData  0.979 ( 0.415)\tLoss 2.1458e+00 (1.8822e+00)\tAcc@1  52.34 ( 72.25)\tAcc@5  92.58 ( 95.51)\n",
            "Epoch: [190][250/268]\tTime  0.416 ( 0.800)\tData  0.000 ( 0.403)\tLoss 2.0107e+00 (1.8834e+00)\tAcc@1  63.28 ( 72.05)\tAcc@5  95.31 ( 95.51)\n",
            "Epoch: [190][260/268]\tTime  0.416 ( 0.787)\tData  0.000 ( 0.390)\tLoss 1.9375e+00 (1.8826e+00)\tAcc@1  67.19 ( 72.06)\tAcc@5  95.70 ( 95.55)\n",
            "epoch: 190\n",
            "2023-03-25 06:27:19.357766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:19.357860: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:19.357879: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:23.289580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:23.289701: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:23.289724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:27.210144: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:27.210244: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:27.210264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:31.166766: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:31.166859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:31.166877: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:35.065690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:35.065785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:35.065804: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:38.952517: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:38.952606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:38.952624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:42.854508: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:42.854611: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:42.854632: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:46.756061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:46.756160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:46.756178: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:50.630293: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:50.630390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:50.630408: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:54.528283: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:54.528380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:54.528400: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:27:58.421423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:58.421535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:27:58.421555: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:28:02.317020: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:28:02.317118: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:28:02.317137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [191][  0/268]\tTime 55.312 (55.312)\tData 54.974 (54.974)\tLoss 2.2510e+00 (2.2510e+00)\tAcc@1  51.17 ( 51.17)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [191][ 10/268]\tTime  0.423 ( 5.443)\tData  0.000 ( 5.039)\tLoss 2.2639e+00 (2.0601e+00)\tAcc@1  47.66 ( 58.81)\tAcc@5  90.62 ( 94.92)\n",
            "Epoch: [191][ 20/268]\tTime  0.417 ( 3.103)\tData  0.000 ( 2.711)\tLoss 2.2453e+00 (1.9910e+00)\tAcc@1  46.88 ( 64.86)\tAcc@5  89.06 ( 95.13)\n",
            "Epoch: [191][ 30/268]\tTime  0.422 ( 2.307)\tData  0.000 ( 1.918)\tLoss 2.2564e+00 (2.0270e+00)\tAcc@1  41.41 ( 63.00)\tAcc@5  91.41 ( 94.57)\n",
            "Epoch: [191][ 40/268]\tTime  0.428 ( 1.889)\tData  0.001 ( 1.498)\tLoss 2.2183e+00 (2.0266e+00)\tAcc@1  54.69 ( 63.56)\tAcc@5  91.80 ( 94.36)\n",
            "Epoch: [191][ 50/268]\tTime  0.433 ( 1.648)\tData  0.000 ( 1.255)\tLoss 1.6161e+00 (1.9708e+00)\tAcc@1  89.84 ( 67.29)\tAcc@5  96.48 ( 94.90)\n",
            "Epoch: [191][ 60/268]\tTime  2.248 ( 1.477)\tData  1.911 ( 1.083)\tLoss 2.0415e+00 (1.9582e+00)\tAcc@1  67.58 ( 68.37)\tAcc@5  96.48 ( 94.99)\n",
            "Epoch: [191][ 70/268]\tTime  0.450 ( 1.328)\tData  0.000 ( 0.932)\tLoss 2.2047e+00 (1.9319e+00)\tAcc@1  48.05 ( 69.83)\tAcc@5  93.36 ( 95.33)\n",
            "Epoch: [191][ 80/268]\tTime  0.421 ( 1.241)\tData  0.000 ( 0.844)\tLoss 2.1395e+00 (1.9369e+00)\tAcc@1  78.52 ( 69.42)\tAcc@5  93.75 ( 95.22)\n",
            "Epoch: [191][ 90/268]\tTime  0.415 ( 1.173)\tData  0.013 ( 0.776)\tLoss 1.9909e+00 (1.9391e+00)\tAcc@1  82.42 ( 69.52)\tAcc@5  96.88 ( 95.27)\n",
            "Epoch: [191][100/268]\tTime  0.416 ( 1.122)\tData  0.000 ( 0.726)\tLoss 1.6146e+00 (1.9353e+00)\tAcc@1  91.02 ( 70.17)\tAcc@5  96.48 ( 95.33)\n",
            "Epoch: [191][110/268]\tTime  0.417 ( 1.074)\tData  0.000 ( 0.677)\tLoss 2.4511e+00 (1.9305e+00)\tAcc@1  23.05 ( 70.17)\tAcc@5  83.59 ( 95.27)\n",
            "Epoch: [191][120/268]\tTime  1.530 ( 1.031)\tData  1.188 ( 0.633)\tLoss 2.3100e+00 (1.9174e+00)\tAcc@1  40.23 ( 70.62)\tAcc@5  87.50 ( 95.37)\n",
            "Epoch: [191][130/268]\tTime  0.417 ( 0.991)\tData  0.000 ( 0.594)\tLoss 1.5596e+00 (1.9132e+00)\tAcc@1  84.77 ( 70.75)\tAcc@5  98.44 ( 95.41)\n",
            "Epoch: [191][140/268]\tTime  0.423 ( 0.963)\tData  0.001 ( 0.566)\tLoss 2.8471e+00 (1.9074e+00)\tAcc@1  32.81 ( 71.27)\tAcc@5  89.06 ( 95.50)\n",
            "Epoch: [191][150/268]\tTime  0.426 ( 0.940)\tData  0.013 ( 0.544)\tLoss 2.2443e+00 (1.9113e+00)\tAcc@1  46.48 ( 71.28)\tAcc@5  91.41 ( 95.44)\n",
            "Epoch: [191][160/268]\tTime  0.416 ( 0.923)\tData  0.000 ( 0.527)\tLoss 2.0662e+00 (1.9054e+00)\tAcc@1  63.28 ( 71.38)\tAcc@5  94.92 ( 95.44)\n",
            "Epoch: [191][170/268]\tTime  0.424 ( 0.899)\tData  0.000 ( 0.503)\tLoss 1.5980e+00 (1.9009e+00)\tAcc@1  86.72 ( 71.86)\tAcc@5  98.83 ( 95.52)\n",
            "Epoch: [191][180/268]\tTime  0.712 ( 0.881)\tData  0.393 ( 0.484)\tLoss 1.7496e+00 (1.8966e+00)\tAcc@1  81.25 ( 72.13)\tAcc@5  98.05 ( 95.62)\n",
            "Epoch: [191][190/268]\tTime  0.416 ( 0.865)\tData  0.000 ( 0.468)\tLoss 1.9991e+00 (1.9030e+00)\tAcc@1  63.28 ( 71.67)\tAcc@5  95.31 ( 95.50)\n",
            "Epoch: [191][200/268]\tTime  0.423 ( 0.851)\tData  0.000 ( 0.455)\tLoss 2.1590e+00 (1.8974e+00)\tAcc@1  50.00 ( 72.07)\tAcc@5  89.84 ( 95.58)\n",
            "Epoch: [191][210/268]\tTime  0.409 ( 0.840)\tData  0.000 ( 0.445)\tLoss 2.2759e+00 (1.8986e+00)\tAcc@1  49.61 ( 72.01)\tAcc@5  87.89 ( 95.59)\n",
            "Epoch: [191][220/268]\tTime  0.416 ( 0.830)\tData  0.000 ( 0.435)\tLoss 1.7709e+00 (1.8962e+00)\tAcc@1  79.30 ( 72.04)\tAcc@5  98.05 ( 95.60)\n",
            "Epoch: [191][230/268]\tTime  0.429 ( 0.817)\tData  0.000 ( 0.422)\tLoss 1.6137e+00 (1.8931e+00)\tAcc@1  88.67 ( 72.27)\tAcc@5  96.88 ( 95.64)\n",
            "Epoch: [191][240/268]\tTime  1.206 ( 0.810)\tData  0.886 ( 0.415)\tLoss 1.9251e+00 (1.8919e+00)\tAcc@1  69.92 ( 72.25)\tAcc@5  96.88 ( 95.65)\n",
            "Epoch: [191][250/268]\tTime  0.416 ( 0.798)\tData  0.000 ( 0.402)\tLoss 1.6357e+00 (1.8923e+00)\tAcc@1  85.94 ( 72.15)\tAcc@5  98.44 ( 95.64)\n",
            "Epoch: [191][260/268]\tTime  0.415 ( 0.788)\tData  0.000 ( 0.392)\tLoss 1.6927e+00 (1.8930e+00)\tAcc@1  83.20 ( 72.08)\tAcc@5  96.88 ( 95.64)\n",
            "epoch: 191\n",
            "2023-03-25 06:30:49.641292: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:49.641419: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:49.641442: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:30:53.549369: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:53.549466: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:53.549485: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:30:57.455319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:57.455415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:30:57.455434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:01.383682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:01.383783: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:01.383802: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:05.305772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:05.305905: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:05.305924: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:09.216429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:09.216538: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:09.216556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:13.122740: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:13.122842: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:13.122860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:17.023803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:17.023901: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:17.023920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:20.972406: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:20.972515: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:20.972536: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:24.878804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:24.878900: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:24.878926: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:28.759359: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:28.759460: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:28.759479: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:31:32.669680: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:32.669776: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:31:32.669794: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [192][  0/268]\tTime 56.181 (56.181)\tData 55.837 (55.837)\tLoss 2.0836e+00 (2.0836e+00)\tAcc@1  69.92 ( 69.92)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [192][ 10/268]\tTime  0.417 ( 5.488)\tData  0.001 ( 5.086)\tLoss 1.6219e+00 (1.9112e+00)\tAcc@1  88.28 ( 74.68)\tAcc@5  97.66 ( 95.38)\n",
            "Epoch: [192][ 20/268]\tTime  0.418 ( 3.125)\tData  0.000 ( 2.723)\tLoss 1.5920e+00 (1.8678e+00)\tAcc@1  92.58 ( 75.45)\tAcc@5  99.22 ( 95.54)\n",
            "Epoch: [192][ 30/268]\tTime  0.418 ( 2.316)\tData  0.006 ( 1.914)\tLoss 1.5746e+00 (1.8896e+00)\tAcc@1  92.58 ( 72.49)\tAcc@5  98.05 ( 95.36)\n",
            "Epoch: [192][ 40/268]\tTime  0.416 ( 1.890)\tData  0.015 ( 1.491)\tLoss 1.7379e+00 (1.8832e+00)\tAcc@1  83.59 ( 72.74)\tAcc@5  98.83 ( 95.38)\n",
            "Epoch: [192][ 50/268]\tTime  0.952 ( 1.642)\tData  0.629 ( 1.246)\tLoss 1.8363e+00 (1.8950e+00)\tAcc@1  87.11 ( 71.65)\tAcc@5  96.88 ( 95.24)\n",
            "Epoch: [192][ 60/268]\tTime  2.369 ( 1.474)\tData  2.012 ( 1.077)\tLoss 2.0053e+00 (1.9147e+00)\tAcc@1  58.20 ( 70.37)\tAcc@5  96.09 ( 95.19)\n",
            "Epoch: [192][ 70/268]\tTime  0.424 ( 1.325)\tData  0.000 ( 0.928)\tLoss 1.8602e+00 (1.9206e+00)\tAcc@1  75.39 ( 70.35)\tAcc@5  98.83 ( 95.15)\n",
            "Epoch: [192][ 80/268]\tTime  0.424 ( 1.238)\tData  0.000 ( 0.840)\tLoss 1.7246e+00 (1.9265e+00)\tAcc@1  77.34 ( 69.51)\tAcc@5  97.27 ( 94.98)\n",
            "Epoch: [192][ 90/268]\tTime  0.417 ( 1.169)\tData  0.000 ( 0.772)\tLoss 1.7994e+00 (1.9132e+00)\tAcc@1  80.47 ( 70.25)\tAcc@5  96.88 ( 95.13)\n",
            "Epoch: [192][100/268]\tTime  0.425 ( 1.118)\tData  0.000 ( 0.721)\tLoss 1.9874e+00 (1.9205e+00)\tAcc@1  74.22 ( 70.04)\tAcc@5  93.75 ( 95.02)\n",
            "Epoch: [192][110/268]\tTime  0.420 ( 1.067)\tData  0.001 ( 0.671)\tLoss 1.4250e+00 (1.9178e+00)\tAcc@1  95.31 ( 70.30)\tAcc@5  98.05 ( 95.06)\n",
            "Epoch: [192][120/268]\tTime  2.496 ( 1.031)\tData  2.165 ( 0.634)\tLoss 1.5452e+00 (1.9145e+00)\tAcc@1  90.62 ( 70.34)\tAcc@5  99.22 ( 95.20)\n",
            "Epoch: [192][130/268]\tTime  0.424 ( 0.984)\tData  0.000 ( 0.587)\tLoss 2.2625e+00 (1.9130e+00)\tAcc@1  42.19 ( 70.34)\tAcc@5  92.58 ( 95.26)\n",
            "Epoch: [192][140/268]\tTime  0.423 ( 0.958)\tData  0.003 ( 0.561)\tLoss 1.7694e+00 (1.9150e+00)\tAcc@1  80.08 ( 70.27)\tAcc@5  97.66 ( 95.21)\n",
            "Epoch: [192][150/268]\tTime  0.417 ( 0.937)\tData  0.000 ( 0.539)\tLoss 1.7457e+00 (1.9110e+00)\tAcc@1  84.77 ( 70.57)\tAcc@5  97.66 ( 95.30)\n",
            "Epoch: [192][160/268]\tTime  0.417 ( 0.914)\tData  0.000 ( 0.516)\tLoss 2.2432e+00 (1.9007e+00)\tAcc@1  47.66 ( 71.16)\tAcc@5  91.02 ( 95.42)\n",
            "Epoch: [192][170/268]\tTime  0.493 ( 0.897)\tData  0.158 ( 0.500)\tLoss 1.6523e+00 (1.8984e+00)\tAcc@1  88.67 ( 71.26)\tAcc@5  97.27 ( 95.47)\n",
            "Epoch: [192][180/268]\tTime  2.641 ( 0.883)\tData  2.299 ( 0.486)\tLoss 3.1293e+00 (1.9025e+00)\tAcc@1   2.34 ( 71.06)\tAcc@5  50.78 ( 95.30)\n",
            "Epoch: [192][190/268]\tTime  0.417 ( 0.859)\tData  0.000 ( 0.461)\tLoss 2.1930e+00 (1.9047e+00)\tAcc@1  48.44 ( 70.94)\tAcc@5  91.80 ( 95.27)\n",
            "Epoch: [192][200/268]\tTime  0.416 ( 0.848)\tData  0.000 ( 0.450)\tLoss 1.8787e+00 (1.9007e+00)\tAcc@1  80.47 ( 71.31)\tAcc@5  94.92 ( 95.32)\n",
            "Epoch: [192][210/268]\tTime  0.424 ( 0.836)\tData  0.000 ( 0.438)\tLoss 1.9994e+00 (1.9013e+00)\tAcc@1  71.88 ( 71.42)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [192][220/268]\tTime  0.420 ( 0.829)\tData  0.000 ( 0.432)\tLoss 1.5312e+00 (1.9031e+00)\tAcc@1  94.14 ( 71.18)\tAcc@5  97.27 ( 95.26)\n",
            "Epoch: [192][230/268]\tTime  1.167 ( 0.818)\tData  0.849 ( 0.421)\tLoss 2.2502e+00 (1.8978e+00)\tAcc@1  40.62 ( 71.55)\tAcc@5  88.67 ( 95.33)\n",
            "Epoch: [192][240/268]\tTime  1.689 ( 0.806)\tData  1.357 ( 0.409)\tLoss 1.9350e+00 (1.9000e+00)\tAcc@1  74.22 ( 71.39)\tAcc@5  96.48 ( 95.31)\n",
            "Epoch: [192][250/268]\tTime  0.416 ( 0.793)\tData  0.000 ( 0.395)\tLoss 2.2331e+00 (1.9003e+00)\tAcc@1  44.92 ( 71.33)\tAcc@5  91.80 ( 95.32)\n",
            "Epoch: [192][260/268]\tTime  0.416 ( 0.785)\tData  0.000 ( 0.389)\tLoss 1.8832e+00 (1.9046e+00)\tAcc@1  78.91 ( 70.92)\tAcc@5  97.27 ( 95.28)\n",
            "epoch: 192\n",
            "2023-03-25 06:34:19.278447: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:19.278562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:19.278580: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:23.194218: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:23.194315: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:23.194334: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:27.132979: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:27.133076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:27.133095: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:31.032747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:31.032844: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:31.032863: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:34.914519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:34.914616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:34.914634: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:38.826171: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:38.826276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:38.826298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:42.745691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:42.745789: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:42.745809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:46.644148: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:46.644246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:46.644265: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:50.550480: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:50.550595: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:50.550613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:54.486682: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:54.486786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:54.486805: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:34:58.420455: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:58.420580: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:34:58.420599: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:35:02.309074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:35:02.309175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:35:02.309194: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [193][  0/268]\tTime 55.388 (55.388)\tData 55.057 (55.057)\tLoss 1.6570e+00 (1.6570e+00)\tAcc@1  87.11 ( 87.11)\tAcc@5  98.05 ( 98.05)\n",
            "Epoch: [193][ 10/268]\tTime  0.409 ( 5.415)\tData  0.000 ( 5.016)\tLoss 2.1950e+00 (1.8474e+00)\tAcc@1  56.25 ( 74.57)\tAcc@5  96.48 ( 96.31)\n",
            "Epoch: [193][ 20/268]\tTime  0.417 ( 3.149)\tData  0.000 ( 2.748)\tLoss 1.7511e+00 (1.8906e+00)\tAcc@1  84.77 ( 71.43)\tAcc@5  98.44 ( 95.26)\n",
            "Epoch: [193][ 30/268]\tTime  0.417 ( 2.316)\tData  0.000 ( 1.916)\tLoss 1.6769e+00 (1.9102e+00)\tAcc@1  82.81 ( 71.56)\tAcc@5  97.66 ( 94.93)\n",
            "Epoch: [193][ 40/268]\tTime  0.418 ( 1.912)\tData  0.000 ( 1.513)\tLoss 1.6962e+00 (1.9055e+00)\tAcc@1  78.12 ( 71.41)\tAcc@5  96.88 ( 94.94)\n",
            "Epoch: [193][ 50/268]\tTime  0.418 ( 1.662)\tData  0.000 ( 1.262)\tLoss 1.8317e+00 (1.9162e+00)\tAcc@1  70.31 ( 71.12)\tAcc@5  96.48 ( 94.81)\n",
            "Epoch: [193][ 60/268]\tTime  2.351 ( 1.490)\tData  1.987 ( 1.090)\tLoss 1.7933e+00 (1.9354e+00)\tAcc@1  80.86 ( 70.06)\tAcc@5  95.70 ( 94.56)\n",
            "Epoch: [193][ 70/268]\tTime  0.410 ( 1.339)\tData  0.000 ( 0.938)\tLoss 1.5779e+00 (1.9157e+00)\tAcc@1  86.72 ( 70.98)\tAcc@5  98.83 ( 94.89)\n",
            "Epoch: [193][ 80/268]\tTime  0.417 ( 1.235)\tData  0.000 ( 0.834)\tLoss 1.6249e+00 (1.9155e+00)\tAcc@1  83.98 ( 70.69)\tAcc@5  98.44 ( 94.71)\n",
            "Epoch: [193][ 90/268]\tTime  0.421 ( 1.180)\tData  0.000 ( 0.779)\tLoss 2.0066e+00 (1.9113e+00)\tAcc@1  57.42 ( 70.55)\tAcc@5  94.14 ( 94.88)\n",
            "Epoch: [193][100/268]\tTime  0.431 ( 1.119)\tData  0.000 ( 0.718)\tLoss 2.3242e+00 (1.9121e+00)\tAcc@1  46.88 ( 70.63)\tAcc@5  87.11 ( 94.85)\n",
            "Epoch: [193][110/268]\tTime  0.413 ( 1.077)\tData  0.000 ( 0.676)\tLoss 1.6692e+00 (1.9173e+00)\tAcc@1  83.98 ( 70.40)\tAcc@5  98.44 ( 94.88)\n",
            "Epoch: [193][120/268]\tTime  2.113 ( 1.037)\tData  1.773 ( 0.636)\tLoss 2.5736e+00 (1.9215e+00)\tAcc@1  45.31 ( 70.35)\tAcc@5  92.19 ( 94.91)\n",
            "Epoch: [193][130/268]\tTime  0.416 ( 0.989)\tData  0.000 ( 0.588)\tLoss 1.8578e+00 (1.9218e+00)\tAcc@1  78.12 ( 70.64)\tAcc@5  96.88 ( 94.97)\n",
            "Epoch: [193][140/268]\tTime  0.416 ( 0.967)\tData  0.000 ( 0.565)\tLoss 1.5984e+00 (1.9145e+00)\tAcc@1  93.36 ( 71.15)\tAcc@5  97.66 ( 95.12)\n",
            "Epoch: [193][150/268]\tTime  0.416 ( 0.946)\tData  0.000 ( 0.544)\tLoss 2.1519e+00 (1.9127e+00)\tAcc@1  48.05 ( 71.26)\tAcc@5  96.48 ( 95.23)\n",
            "Epoch: [193][160/268]\tTime  0.416 ( 0.925)\tData  0.000 ( 0.524)\tLoss 1.3870e+00 (1.9072e+00)\tAcc@1  91.80 ( 71.60)\tAcc@5  98.83 ( 95.29)\n",
            "Epoch: [193][170/268]\tTime  0.409 ( 0.909)\tData  0.000 ( 0.508)\tLoss 2.2366e+00 (1.9068e+00)\tAcc@1  39.45 ( 71.67)\tAcc@5  89.45 ( 95.31)\n",
            "Epoch: [193][180/268]\tTime  2.842 ( 0.896)\tData  2.499 ( 0.494)\tLoss 2.2785e+00 (1.9081e+00)\tAcc@1  41.41 ( 71.61)\tAcc@5  90.62 ( 95.32)\n",
            "Epoch: [193][190/268]\tTime  0.410 ( 0.871)\tData  0.000 ( 0.469)\tLoss 2.2519e+00 (1.9181e+00)\tAcc@1  50.00 ( 70.93)\tAcc@5  91.02 ( 95.15)\n",
            "Epoch: [193][200/268]\tTime  0.422 ( 0.859)\tData  0.001 ( 0.457)\tLoss 2.3226e+00 (1.9223e+00)\tAcc@1  39.45 ( 70.37)\tAcc@5  91.02 ( 95.12)\n",
            "Epoch: [193][210/268]\tTime  0.417 ( 0.849)\tData  0.000 ( 0.447)\tLoss 2.3951e+00 (1.9205e+00)\tAcc@1  30.47 ( 70.47)\tAcc@5  90.23 ( 95.13)\n",
            "Epoch: [193][220/268]\tTime  0.432 ( 0.836)\tData  0.000 ( 0.434)\tLoss 2.1494e+00 (1.9207e+00)\tAcc@1  64.45 ( 70.40)\tAcc@5  92.97 ( 95.17)\n",
            "Epoch: [193][230/268]\tTime  0.418 ( 0.828)\tData  0.001 ( 0.426)\tLoss 2.2906e+00 (1.9268e+00)\tAcc@1  51.17 ( 70.17)\tAcc@5  90.23 ( 95.15)\n",
            "Epoch: [193][240/268]\tTime  2.544 ( 0.819)\tData  2.210 ( 0.418)\tLoss 1.3953e+00 (1.9265e+00)\tAcc@1  91.80 ( 69.99)\tAcc@5  98.83 ( 95.17)\n",
            "Epoch: [193][250/268]\tTime  0.418 ( 0.803)\tData  0.000 ( 0.402)\tLoss 1.4981e+00 (1.9248e+00)\tAcc@1  92.97 ( 70.05)\tAcc@5  98.05 ( 95.18)\n",
            "Epoch: [193][260/268]\tTime  0.415 ( 0.794)\tData  0.000 ( 0.392)\tLoss 2.2501e+00 (1.9239e+00)\tAcc@1  44.14 ( 70.04)\tAcc@5  90.62 ( 95.18)\n",
            "epoch: 193\n",
            "2023-03-25 06:37:51.019499: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:51.019606: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:51.019624: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:37:54.920203: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:54.920303: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:54.920322: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:37:58.849648: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:58.849757: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:37:58.849778: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:02.764043: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:02.764143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:02.764161: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:06.686520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:06.686618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:06.686636: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:10.603282: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:10.603379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:10.603398: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:14.499731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:14.499832: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:14.499850: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:18.401623: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:18.401732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:18.401752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:22.319969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:22.320070: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:22.320090: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:26.197618: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:26.197732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:26.197752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:30.115380: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:30.115480: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:30.115500: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:38:34.029056: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:34.029153: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:38:34.029171: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [194][  0/268]\tTime 54.752 (54.752)\tData 54.393 (54.393)\tLoss 2.1842e+00 (2.1842e+00)\tAcc@1  69.14 ( 69.14)\tAcc@5  93.36 ( 93.36)\n",
            "Epoch: [194][ 10/268]\tTime  0.416 ( 5.374)\tData  0.001 ( 4.978)\tLoss 1.9058e+00 (1.9752e+00)\tAcc@1  68.75 ( 67.90)\tAcc@5  97.27 ( 94.39)\n",
            "Epoch: [194][ 20/268]\tTime  0.417 ( 3.110)\tData  0.000 ( 2.712)\tLoss 1.5904e+00 (1.8911e+00)\tAcc@1  89.84 ( 71.63)\tAcc@5  97.27 ( 95.00)\n",
            "Epoch: [194][ 30/268]\tTime  0.416 ( 2.285)\tData  0.000 ( 1.886)\tLoss 1.5379e+00 (1.8737e+00)\tAcc@1  87.50 ( 72.29)\tAcc@5  99.61 ( 95.35)\n",
            "Epoch: [194][ 40/268]\tTime  0.423 ( 1.888)\tData  0.000 ( 1.489)\tLoss 1.7590e+00 (1.8745e+00)\tAcc@1  78.12 ( 72.35)\tAcc@5  98.83 ( 95.53)\n",
            "Epoch: [194][ 50/268]\tTime  0.421 ( 1.636)\tData  0.000 ( 1.237)\tLoss 1.9267e+00 (1.8767e+00)\tAcc@1  68.75 ( 72.17)\tAcc@5  95.70 ( 95.59)\n",
            "Epoch: [194][ 60/268]\tTime  2.679 ( 1.474)\tData  2.333 ( 1.074)\tLoss 1.9888e+00 (1.8732e+00)\tAcc@1  59.38 ( 72.00)\tAcc@5  97.66 ( 95.73)\n",
            "Epoch: [194][ 70/268]\tTime  0.420 ( 1.325)\tData  0.000 ( 0.924)\tLoss 1.5916e+00 (1.8738e+00)\tAcc@1  88.28 ( 72.15)\tAcc@5  97.27 ( 95.77)\n",
            "Epoch: [194][ 80/268]\tTime  0.417 ( 1.237)\tData  0.000 ( 0.836)\tLoss 1.8936e+00 (1.8690e+00)\tAcc@1  60.55 ( 72.71)\tAcc@5  96.88 ( 95.90)\n",
            "Epoch: [194][ 90/268]\tTime  0.416 ( 1.171)\tData  0.000 ( 0.771)\tLoss 1.9371e+00 (1.8916e+00)\tAcc@1  75.39 ( 71.58)\tAcc@5  95.31 ( 95.55)\n",
            "Epoch: [194][100/268]\tTime  0.423 ( 1.122)\tData  0.000 ( 0.723)\tLoss 1.6845e+00 (1.8818e+00)\tAcc@1  88.67 ( 71.71)\tAcc@5  98.44 ( 95.63)\n",
            "Epoch: [194][110/268]\tTime  1.121 ( 1.076)\tData  0.787 ( 0.678)\tLoss 1.7564e+00 (1.8855e+00)\tAcc@1  87.50 ( 71.50)\tAcc@5  95.70 ( 95.51)\n",
            "Epoch: [194][120/268]\tTime  1.622 ( 1.032)\tData  1.295 ( 0.634)\tLoss 2.2273e+00 (1.8906e+00)\tAcc@1  38.67 ( 71.12)\tAcc@5  91.02 ( 95.47)\n",
            "Epoch: [194][130/268]\tTime  0.416 ( 0.992)\tData  0.000 ( 0.594)\tLoss 2.2898e+00 (1.9045e+00)\tAcc@1  41.41 ( 70.60)\tAcc@5  90.23 ( 95.31)\n",
            "Epoch: [194][140/268]\tTime  0.427 ( 0.968)\tData  0.000 ( 0.570)\tLoss 1.7615e+00 (1.9047e+00)\tAcc@1  79.69 ( 70.74)\tAcc@5  97.27 ( 95.25)\n",
            "Epoch: [194][150/268]\tTime  0.432 ( 0.944)\tData  0.000 ( 0.546)\tLoss 1.7665e+00 (1.9059e+00)\tAcc@1  81.64 ( 70.65)\tAcc@5  99.22 ( 95.17)\n",
            "Epoch: [194][160/268]\tTime  0.424 ( 0.926)\tData  0.000 ( 0.530)\tLoss 1.7247e+00 (1.8966e+00)\tAcc@1  78.12 ( 71.10)\tAcc@5  97.66 ( 95.28)\n",
            "Epoch: [194][170/268]\tTime  0.609 ( 0.905)\tData  0.280 ( 0.510)\tLoss 1.8228e+00 (1.8898e+00)\tAcc@1  77.73 ( 71.37)\tAcc@5  98.05 ( 95.36)\n",
            "Epoch: [194][180/268]\tTime  1.529 ( 0.884)\tData  1.209 ( 0.489)\tLoss 1.8025e+00 (1.8898e+00)\tAcc@1  80.86 ( 71.55)\tAcc@5  96.88 ( 95.36)\n",
            "Epoch: [194][190/268]\tTime  0.445 ( 0.864)\tData  0.000 ( 0.468)\tLoss 2.2750e+00 (1.8917e+00)\tAcc@1  45.31 ( 71.23)\tAcc@5  92.58 ( 95.34)\n",
            "Epoch: [194][200/268]\tTime  0.417 ( 0.852)\tData  0.000 ( 0.456)\tLoss 1.9169e+00 (1.8942e+00)\tAcc@1  67.97 ( 71.05)\tAcc@5  96.09 ( 95.33)\n",
            "Epoch: [194][210/268]\tTime  0.417 ( 0.841)\tData  0.001 ( 0.445)\tLoss 1.6196e+00 (1.8897e+00)\tAcc@1  95.70 ( 71.45)\tAcc@5  99.22 ( 95.38)\n",
            "Epoch: [194][220/268]\tTime  0.417 ( 0.831)\tData  0.000 ( 0.436)\tLoss 1.7355e+00 (1.8857e+00)\tAcc@1  80.47 ( 71.73)\tAcc@5  96.88 ( 95.43)\n",
            "Epoch: [194][230/268]\tTime  0.434 ( 0.821)\tData  0.000 ( 0.426)\tLoss 1.6776e+00 (1.8864e+00)\tAcc@1  89.84 ( 71.66)\tAcc@5  98.44 ( 95.44)\n",
            "Epoch: [194][240/268]\tTime  2.285 ( 0.813)\tData  1.943 ( 0.416)\tLoss 1.7746e+00 (1.8911e+00)\tAcc@1  75.78 ( 71.33)\tAcc@5  98.05 ( 95.41)\n",
            "Epoch: [194][250/268]\tTime  0.417 ( 0.798)\tData  0.000 ( 0.401)\tLoss 1.7133e+00 (1.8887e+00)\tAcc@1  83.98 ( 71.42)\tAcc@5  97.66 ( 95.48)\n",
            "Epoch: [194][260/268]\tTime  0.416 ( 0.788)\tData  0.000 ( 0.392)\tLoss 1.7007e+00 (1.8856e+00)\tAcc@1  87.11 ( 71.70)\tAcc@5  96.88 ( 95.54)\n",
            "epoch: 194\n",
            "2023-03-25 06:41:21.531942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:21.532042: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:21.532062: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:25.518276: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:25.518373: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:25.518393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:29.549005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:29.549140: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:29.549159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:33.577142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:33.577240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:33.577259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:37.514679: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:37.514780: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:37.514798: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:41.476492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:41.476602: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:41.476621: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:45.438694: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:45.438786: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:45.438803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:49.391113: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:49.391221: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:49.391239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:53.347712: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:53.347813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:53.347832: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:41:57.345545: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:57.345647: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:41:57.345678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:42:01.389429: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:42:01.389537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:42:01.389556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:42:05.357213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:42:05.357316: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:42:05.357333: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [195][  0/268]\tTime 56.333 (56.333)\tData 56.001 (56.001)\tLoss 1.8082e+00 (1.8082e+00)\tAcc@1  87.11 ( 87.11)\tAcc@5  95.70 ( 95.70)\n",
            "Epoch: [195][ 10/268]\tTime  0.422 ( 5.524)\tData  0.000 ( 5.123)\tLoss 1.6961e+00 (1.9017e+00)\tAcc@1  80.86 ( 70.67)\tAcc@5  99.61 ( 95.21)\n",
            "Epoch: [195][ 20/268]\tTime  0.419 ( 3.184)\tData  0.000 ( 2.785)\tLoss 1.8557e+00 (1.8858e+00)\tAcc@1  85.94 ( 73.57)\tAcc@5  96.88 ( 95.87)\n",
            "Epoch: [195][ 30/268]\tTime  0.416 ( 2.367)\tData  0.000 ( 1.969)\tLoss 1.8055e+00 (1.9258e+00)\tAcc@1  87.11 ( 71.96)\tAcc@5  96.48 ( 95.15)\n",
            "Epoch: [195][ 40/268]\tTime  0.441 ( 1.938)\tData  0.000 ( 1.541)\tLoss 2.1674e+00 (1.9310e+00)\tAcc@1  55.08 ( 71.63)\tAcc@5  96.88 ( 95.26)\n",
            "Epoch: [195][ 50/268]\tTime  0.422 ( 1.686)\tData  0.000 ( 1.290)\tLoss 1.4411e+00 (1.9542e+00)\tAcc@1  92.58 ( 69.40)\tAcc@5  98.83 ( 94.68)\n",
            "Epoch: [195][ 60/268]\tTime  2.196 ( 1.508)\tData  1.877 ( 1.111)\tLoss 1.7897e+00 (1.9332e+00)\tAcc@1  76.95 ( 70.22)\tAcc@5  96.48 ( 94.92)\n",
            "Epoch: [195][ 70/268]\tTime  0.416 ( 1.359)\tData  0.000 ( 0.960)\tLoss 1.8133e+00 (1.9121e+00)\tAcc@1  75.39 ( 70.75)\tAcc@5  95.70 ( 95.19)\n",
            "Epoch: [195][ 80/268]\tTime  0.413 ( 1.268)\tData  0.000 ( 0.871)\tLoss 1.7662e+00 (1.9051e+00)\tAcc@1  72.66 ( 71.33)\tAcc@5  96.48 ( 95.30)\n",
            "Epoch: [195][ 90/268]\tTime  0.410 ( 1.196)\tData  0.000 ( 0.800)\tLoss 1.9843e+00 (1.9000e+00)\tAcc@1  64.45 ( 71.99)\tAcc@5  92.97 ( 95.30)\n",
            "Epoch: [195][100/268]\tTime  0.416 ( 1.136)\tData  0.001 ( 0.740)\tLoss 2.0148e+00 (1.8924e+00)\tAcc@1  61.33 ( 72.19)\tAcc@5  93.36 ( 95.39)\n",
            "Epoch: [195][110/268]\tTime  0.417 ( 1.093)\tData  0.008 ( 0.697)\tLoss 2.1077e+00 (1.8949e+00)\tAcc@1  54.30 ( 71.73)\tAcc@5  95.31 ( 95.39)\n",
            "Epoch: [195][120/268]\tTime  1.838 ( 1.049)\tData  1.504 ( 0.653)\tLoss 1.6394e+00 (1.8949e+00)\tAcc@1  89.45 ( 71.67)\tAcc@5  96.48 ( 95.37)\n",
            "Epoch: [195][130/268]\tTime  0.409 ( 1.005)\tData  0.001 ( 0.609)\tLoss 1.7237e+00 (1.9047e+00)\tAcc@1  81.25 ( 70.84)\tAcc@5  98.05 ( 95.26)\n",
            "Epoch: [195][140/268]\tTime  0.413 ( 0.977)\tData  0.000 ( 0.580)\tLoss 2.2641e+00 (1.9114e+00)\tAcc@1  47.27 ( 70.61)\tAcc@5  87.89 ( 95.15)\n",
            "Epoch: [195][150/268]\tTime  0.411 ( 0.953)\tData  0.000 ( 0.557)\tLoss 2.3030e+00 (1.9229e+00)\tAcc@1  41.02 ( 70.32)\tAcc@5  86.72 ( 94.90)\n",
            "Epoch: [195][160/268]\tTime  0.417 ( 0.937)\tData  0.000 ( 0.541)\tLoss 1.6651e+00 (1.9111e+00)\tAcc@1  89.45 ( 71.10)\tAcc@5  97.66 ( 95.06)\n",
            "Epoch: [195][170/268]\tTime  0.409 ( 0.920)\tData  0.000 ( 0.525)\tLoss 2.3191e+00 (1.9079e+00)\tAcc@1  45.31 ( 71.21)\tAcc@5  87.89 ( 95.09)\n",
            "Epoch: [195][180/268]\tTime  1.562 ( 0.899)\tData  1.224 ( 0.503)\tLoss 2.0915e+00 (1.9055e+00)\tAcc@1  57.03 ( 71.34)\tAcc@5  94.53 ( 95.13)\n",
            "Epoch: [195][190/268]\tTime  0.416 ( 0.881)\tData  0.000 ( 0.484)\tLoss 2.2655e+00 (1.9001e+00)\tAcc@1  47.27 ( 71.67)\tAcc@5  89.45 ( 95.15)\n",
            "Epoch: [195][200/268]\tTime  0.426 ( 0.866)\tData  0.004 ( 0.470)\tLoss 1.7209e+00 (1.8940e+00)\tAcc@1  83.98 ( 72.07)\tAcc@5  96.88 ( 95.25)\n",
            "Epoch: [195][210/268]\tTime  0.417 ( 0.855)\tData  0.000 ( 0.458)\tLoss 1.8050e+00 (1.8887e+00)\tAcc@1  82.03 ( 72.55)\tAcc@5  96.88 ( 95.35)\n",
            "Epoch: [195][220/268]\tTime  0.417 ( 0.841)\tData  0.000 ( 0.445)\tLoss 2.1913e+00 (1.8907e+00)\tAcc@1  50.00 ( 72.42)\tAcc@5  90.62 ( 95.36)\n",
            "Epoch: [195][230/268]\tTime  0.417 ( 0.833)\tData  0.000 ( 0.437)\tLoss 1.7279e+00 (1.8940e+00)\tAcc@1  85.55 ( 72.36)\tAcc@5  98.44 ( 95.21)\n",
            "Epoch: [195][240/268]\tTime  1.589 ( 0.821)\tData  1.254 ( 0.425)\tLoss 1.8345e+00 (1.9003e+00)\tAcc@1  82.03 ( 72.17)\tAcc@5  94.92 ( 95.14)\n",
            "Epoch: [195][250/268]\tTime  0.417 ( 0.808)\tData  0.000 ( 0.412)\tLoss 1.8574e+00 (1.8991e+00)\tAcc@1  82.03 ( 72.21)\tAcc@5  96.09 ( 95.18)\n",
            "Epoch: [195][260/268]\tTime  0.418 ( 0.798)\tData  0.000 ( 0.402)\tLoss 1.8170e+00 (1.8973e+00)\tAcc@1  79.30 ( 72.32)\tAcc@5  97.66 ( 95.23)\n",
            "epoch: 195\n",
            "2023-03-25 06:44:54.441405: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:44:54.441519: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:44:54.441537: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:44:58.439126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:44:58.439223: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:44:58.439242: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:02.422667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:02.422769: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:02.422788: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:06.412621: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:06.412727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:06.412745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:10.387075: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:10.387172: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:10.387191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:14.359232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:14.359338: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:14.359358: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:18.305992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:18.306090: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:18.306109: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:22.287597: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:22.287744: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:22.287765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:26.269822: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:26.269917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:26.269935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:30.241324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:30.241423: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:30.241441: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:34.209763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:34.209864: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:34.209884: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:45:38.157560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:38.157665: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:45:38.157685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [196][  0/268]\tTime 56.709 (56.709)\tData 56.360 (56.360)\tLoss 1.5599e+00 (1.5599e+00)\tAcc@1  88.67 ( 88.67)\tAcc@5  98.83 ( 98.83)\n",
            "Epoch: [196][ 10/268]\tTime  0.417 ( 5.536)\tData  0.013 ( 5.136)\tLoss 1.8617e+00 (1.8518e+00)\tAcc@1  74.22 ( 74.11)\tAcc@5  96.48 ( 97.09)\n",
            "Epoch: [196][ 20/268]\tTime  0.417 ( 3.211)\tData  0.000 ( 2.810)\tLoss 1.6226e+00 (1.8520e+00)\tAcc@1  88.67 ( 73.64)\tAcc@5  99.22 ( 96.06)\n",
            "Epoch: [196][ 30/268]\tTime  0.436 ( 2.364)\tData  0.000 ( 1.964)\tLoss 1.7025e+00 (1.8652e+00)\tAcc@1  82.03 ( 72.19)\tAcc@5  98.05 ( 96.11)\n",
            "Epoch: [196][ 40/268]\tTime  0.415 ( 1.948)\tData  0.013 ( 1.548)\tLoss 2.1706e+00 (1.8648e+00)\tAcc@1  48.44 ( 71.98)\tAcc@5  92.58 ( 96.01)\n",
            "Epoch: [196][ 50/268]\tTime  0.408 ( 1.678)\tData  0.013 ( 1.278)\tLoss 2.2077e+00 (1.8883e+00)\tAcc@1  43.75 ( 70.25)\tAcc@5  91.41 ( 95.53)\n",
            "Epoch: [196][ 60/268]\tTime  3.139 ( 1.516)\tData  2.791 ( 1.116)\tLoss 1.6706e+00 (1.8932e+00)\tAcc@1  91.02 ( 70.52)\tAcc@5  98.05 ( 95.48)\n",
            "Epoch: [196][ 70/268]\tTime  0.419 ( 1.361)\tData  0.000 ( 0.961)\tLoss 1.9634e+00 (1.8837e+00)\tAcc@1  73.44 ( 71.13)\tAcc@5  95.70 ( 95.62)\n",
            "Epoch: [196][ 80/268]\tTime  0.439 ( 1.269)\tData  0.000 ( 0.868)\tLoss 1.4368e+00 (1.8710e+00)\tAcc@1  92.97 ( 72.00)\tAcc@5  98.83 ( 95.76)\n",
            "Epoch: [196][ 90/268]\tTime  0.436 ( 1.203)\tData  0.000 ( 0.802)\tLoss 1.7565e+00 (1.8719e+00)\tAcc@1  78.52 ( 71.68)\tAcc@5  97.66 ( 95.64)\n",
            "Epoch: [196][100/268]\tTime  0.425 ( 1.143)\tData  0.000 ( 0.741)\tLoss 1.6362e+00 (1.8797e+00)\tAcc@1  87.11 ( 71.26)\tAcc@5  99.22 ( 95.54)\n",
            "Epoch: [196][110/268]\tTime  0.416 ( 1.095)\tData  0.013 ( 0.693)\tLoss 2.2869e+00 (1.8904e+00)\tAcc@1  59.77 ( 70.84)\tAcc@5  90.23 ( 95.46)\n",
            "Epoch: [196][120/268]\tTime  2.256 ( 1.054)\tData  1.915 ( 0.653)\tLoss 1.9626e+00 (1.8931e+00)\tAcc@1  70.31 ( 70.83)\tAcc@5  97.27 ( 95.55)\n",
            "Epoch: [196][130/268]\tTime  0.416 ( 1.006)\tData  0.000 ( 0.604)\tLoss 1.5909e+00 (1.8884e+00)\tAcc@1  91.80 ( 71.22)\tAcc@5  98.44 ( 95.67)\n",
            "Epoch: [196][140/268]\tTime  0.417 ( 0.980)\tData  0.000 ( 0.579)\tLoss 1.7830e+00 (1.8830e+00)\tAcc@1  80.08 ( 71.48)\tAcc@5  97.66 ( 95.68)\n",
            "Epoch: [196][150/268]\tTime  0.412 ( 0.957)\tData  0.000 ( 0.555)\tLoss 1.9464e+00 (1.8841e+00)\tAcc@1  80.86 ( 71.51)\tAcc@5  94.92 ( 95.71)\n",
            "Epoch: [196][160/268]\tTime  0.421 ( 0.935)\tData  0.013 ( 0.534)\tLoss 2.2116e+00 (1.8871e+00)\tAcc@1  40.62 ( 71.54)\tAcc@5  91.41 ( 95.67)\n",
            "Epoch: [196][170/268]\tTime  0.412 ( 0.917)\tData  0.000 ( 0.516)\tLoss 2.2518e+00 (1.9008e+00)\tAcc@1  41.80 ( 70.31)\tAcc@5  90.23 ( 95.44)\n",
            "Epoch: [196][180/268]\tTime  2.367 ( 0.900)\tData  2.018 ( 0.499)\tLoss 1.8334e+00 (1.9001e+00)\tAcc@1  78.52 ( 70.39)\tAcc@5  96.48 ( 95.48)\n",
            "Epoch: [196][190/268]\tTime  0.416 ( 0.875)\tData  0.000 ( 0.474)\tLoss 1.9929e+00 (1.8995e+00)\tAcc@1  58.59 ( 70.44)\tAcc@5  94.53 ( 95.48)\n",
            "Epoch: [196][200/268]\tTime  0.417 ( 0.862)\tData  0.000 ( 0.460)\tLoss 1.7938e+00 (1.8994e+00)\tAcc@1  75.39 ( 70.51)\tAcc@5  98.05 ( 95.48)\n",
            "Epoch: [196][210/268]\tTime  0.412 ( 0.850)\tData  0.001 ( 0.449)\tLoss 1.6279e+00 (1.8910e+00)\tAcc@1  91.02 ( 71.06)\tAcc@5  99.22 ( 95.54)\n",
            "Epoch: [196][220/268]\tTime  0.422 ( 0.840)\tData  0.000 ( 0.439)\tLoss 2.2909e+00 (1.8918e+00)\tAcc@1  39.45 ( 70.93)\tAcc@5  87.89 ( 95.48)\n",
            "Epoch: [196][230/268]\tTime  0.426 ( 0.830)\tData  0.013 ( 0.429)\tLoss 1.8821e+00 (1.8904e+00)\tAcc@1  74.22 ( 71.07)\tAcc@5  95.31 ( 95.49)\n",
            "Epoch: [196][240/268]\tTime  2.831 ( 0.824)\tData  2.477 ( 0.422)\tLoss 2.2801e+00 (1.8923e+00)\tAcc@1  46.88 ( 71.05)\tAcc@5  88.67 ( 95.47)\n",
            "Epoch: [196][250/268]\tTime  0.421 ( 0.807)\tData  0.000 ( 0.405)\tLoss 1.6931e+00 (1.8892e+00)\tAcc@1  85.94 ( 71.21)\tAcc@5  98.05 ( 95.50)\n",
            "Epoch: [196][260/268]\tTime  0.416 ( 0.797)\tData  0.000 ( 0.395)\tLoss 1.6974e+00 (1.8907e+00)\tAcc@1  86.72 ( 71.07)\tAcc@5  97.66 ( 95.48)\n",
            "epoch: 196\n",
            "2023-03-25 06:48:27.185031: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:27.185132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:27.185151: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:31.212884: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:31.212990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:31.213009: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:35.237616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:35.237730: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:35.237752: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:39.198878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:39.198976: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:39.198994: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:43.172098: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:43.172195: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:43.172226: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:47.232805: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:47.232898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:47.232916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:51.232639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:51.232755: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:51.232774: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:55.199212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:55.199312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:55.199329: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:48:59.206937: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:59.207034: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:48:59.207052: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:49:03.176593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:03.176706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:03.176726: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:49:07.110532: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:07.110640: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:07.110668: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:49:11.102594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:11.102722: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:49:11.102743: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [197][  0/268]\tTime 56.883 (56.883)\tData 56.538 (56.538)\tLoss 1.5324e+00 (1.5324e+00)\tAcc@1  84.38 ( 84.38)\tAcc@5  99.61 ( 99.61)\n",
            "Epoch: [197][ 10/268]\tTime  0.416 ( 5.553)\tData  0.001 ( 5.150)\tLoss 2.3014e+00 (2.0066e+00)\tAcc@1  44.14 ( 66.65)\tAcc@5  87.50 ( 92.79)\n",
            "Epoch: [197][ 20/268]\tTime  0.435 ( 3.142)\tData  0.000 ( 2.739)\tLoss 1.7170e+00 (1.9342e+00)\tAcc@1  85.55 ( 70.48)\tAcc@5  97.27 ( 94.74)\n",
            "Epoch: [197][ 30/268]\tTime  0.402 ( 2.351)\tData  0.000 ( 1.951)\tLoss 1.7010e+00 (1.9555e+00)\tAcc@1  84.38 ( 68.50)\tAcc@5  97.66 ( 94.42)\n",
            "Epoch: [197][ 40/268]\tTime  0.421 ( 1.944)\tData  0.000 ( 1.547)\tLoss 2.7347e+00 (1.9437e+00)\tAcc@1  23.44 ( 69.07)\tAcc@5  80.08 ( 94.48)\n",
            "Epoch: [197][ 50/268]\tTime  0.416 ( 1.677)\tData  0.000 ( 1.282)\tLoss 1.5533e+00 (1.9423e+00)\tAcc@1  87.50 ( 69.09)\tAcc@5  97.27 ( 94.33)\n",
            "Epoch: [197][ 60/268]\tTime  1.006 ( 1.481)\tData  0.686 ( 1.086)\tLoss 2.3823e+00 (1.9377e+00)\tAcc@1  46.88 ( 69.26)\tAcc@5  85.16 ( 94.54)\n",
            "Epoch: [197][ 70/268]\tTime  0.428 ( 1.361)\tData  0.000 ( 0.964)\tLoss 2.2613e+00 (1.9392e+00)\tAcc@1  58.98 ( 68.84)\tAcc@5  88.67 ( 94.57)\n",
            "Epoch: [197][ 80/268]\tTime  0.417 ( 1.267)\tData  0.000 ( 0.871)\tLoss 1.6972e+00 (1.9368e+00)\tAcc@1  81.25 ( 68.97)\tAcc@5  98.83 ( 94.52)\n",
            "Epoch: [197][ 90/268]\tTime  0.425 ( 1.201)\tData  0.000 ( 0.805)\tLoss 2.3661e+00 (1.9486e+00)\tAcc@1  39.84 ( 68.17)\tAcc@5  88.67 ( 94.40)\n",
            "Epoch: [197][100/268]\tTime  0.415 ( 1.142)\tData  0.000 ( 0.747)\tLoss 1.7526e+00 (1.9512e+00)\tAcc@1  89.84 ( 68.06)\tAcc@5  98.83 ( 94.35)\n",
            "Epoch: [197][110/268]\tTime  0.418 ( 1.094)\tData  0.001 ( 0.700)\tLoss 2.1224e+00 (1.9378e+00)\tAcc@1  78.52 ( 68.95)\tAcc@5  92.97 ( 94.49)\n",
            "Epoch: [197][120/268]\tTime  0.428 ( 1.039)\tData  0.001 ( 0.643)\tLoss 1.5193e+00 (1.9320e+00)\tAcc@1  90.23 ( 69.20)\tAcc@5  98.05 ( 94.50)\n",
            "Epoch: [197][130/268]\tTime  0.417 ( 1.008)\tData  0.000 ( 0.611)\tLoss 1.8185e+00 (1.9249e+00)\tAcc@1  73.83 ( 69.35)\tAcc@5  96.48 ( 94.62)\n",
            "Epoch: [197][140/268]\tTime  0.436 ( 0.979)\tData  0.000 ( 0.582)\tLoss 2.3026e+00 (1.9389e+00)\tAcc@1  56.25 ( 68.85)\tAcc@5  91.02 ( 94.27)\n",
            "Epoch: [197][150/268]\tTime  0.422 ( 0.957)\tData  0.000 ( 0.559)\tLoss 1.6307e+00 (1.9252e+00)\tAcc@1  88.67 ( 69.60)\tAcc@5  98.83 ( 94.49)\n",
            "Epoch: [197][160/268]\tTime  0.422 ( 0.935)\tData  0.000 ( 0.538)\tLoss 1.6578e+00 (1.9257e+00)\tAcc@1  90.23 ( 69.40)\tAcc@5  96.48 ( 94.48)\n",
            "Epoch: [197][170/268]\tTime  0.424 ( 0.917)\tData  0.000 ( 0.520)\tLoss 1.6774e+00 (1.9253e+00)\tAcc@1  76.95 ( 69.41)\tAcc@5  98.05 ( 94.56)\n",
            "Epoch: [197][180/268]\tTime  0.417 ( 0.890)\tData  0.000 ( 0.492)\tLoss 1.5348e+00 (1.9280e+00)\tAcc@1  93.36 ( 69.21)\tAcc@5  98.44 ( 94.53)\n",
            "Epoch: [197][190/268]\tTime  0.430 ( 0.874)\tData  0.003 ( 0.476)\tLoss 2.2624e+00 (1.9197e+00)\tAcc@1  42.58 ( 69.61)\tAcc@5  89.06 ( 94.59)\n",
            "Epoch: [197][200/268]\tTime  0.416 ( 0.861)\tData  0.000 ( 0.463)\tLoss 1.9098e+00 (1.9201e+00)\tAcc@1  71.88 ( 69.63)\tAcc@5  94.53 ( 94.59)\n",
            "Epoch: [197][210/268]\tTime  0.417 ( 0.852)\tData  0.000 ( 0.454)\tLoss 1.8989e+00 (1.9173e+00)\tAcc@1  76.17 ( 69.75)\tAcc@5  97.27 ( 94.64)\n",
            "Epoch: [197][220/268]\tTime  0.415 ( 0.843)\tData  0.000 ( 0.444)\tLoss 1.5936e+00 (1.9140e+00)\tAcc@1  88.28 ( 70.00)\tAcc@5  98.44 ( 94.66)\n",
            "Epoch: [197][230/268]\tTime  0.417 ( 0.833)\tData  0.000 ( 0.434)\tLoss 2.1763e+00 (1.9141e+00)\tAcc@1  55.47 ( 70.03)\tAcc@5  91.80 ( 94.69)\n",
            "Epoch: [197][240/268]\tTime  0.427 ( 0.816)\tData  0.001 ( 0.417)\tLoss 1.7540e+00 (1.9101e+00)\tAcc@1  81.64 ( 70.30)\tAcc@5  97.66 ( 94.79)\n",
            "Epoch: [197][250/268]\tTime  0.417 ( 0.810)\tData  0.000 ( 0.411)\tLoss 1.4962e+00 (1.9096e+00)\tAcc@1  91.41 ( 70.31)\tAcc@5  98.83 ( 94.77)\n",
            "Epoch: [197][260/268]\tTime  0.415 ( 0.799)\tData  0.000 ( 0.400)\tLoss 1.6893e+00 (1.9049e+00)\tAcc@1  81.64 ( 70.67)\tAcc@5  98.05 ( 94.85)\n",
            "epoch: 197\n",
            "2023-03-25 06:52:00.560439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:00.560549: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:00.560569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:04.580627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:04.580739: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:04.580758: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:08.559352: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:08.559453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:08.559469: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:12.527554: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:12.527666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:12.527691: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:16.498100: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:16.498202: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:16.498221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:20.452480: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:20.452589: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:20.452609: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:24.449133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:24.449232: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:24.449251: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:28.403808: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:28.403906: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:28.403925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:32.380594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:32.380702: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:32.380719: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:36.388690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:36.388796: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:36.388814: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:40.316574: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:40.316690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:40.316709: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:52:44.247216: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:44.247319: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:52:44.247337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [198][  0/268]\tTime 56.461 (56.461)\tData 56.113 (56.113)\tLoss 2.2990e+00 (2.2990e+00)\tAcc@1  39.45 ( 39.45)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [198][ 10/268]\tTime  0.408 ( 5.516)\tData  0.000 ( 5.114)\tLoss 1.8774e+00 (2.0311e+00)\tAcc@1  75.00 ( 63.00)\tAcc@5  96.88 ( 93.86)\n",
            "Epoch: [198][ 20/268]\tTime  0.417 ( 3.192)\tData  0.001 ( 2.790)\tLoss 1.6500e+00 (1.9977e+00)\tAcc@1  84.77 ( 63.88)\tAcc@5  98.05 ( 94.36)\n",
            "Epoch: [198][ 30/268]\tTime  0.417 ( 2.369)\tData  0.000 ( 1.968)\tLoss 1.7899e+00 (1.9707e+00)\tAcc@1  82.03 ( 65.42)\tAcc@5  98.05 ( 94.68)\n",
            "Epoch: [198][ 40/268]\tTime  0.416 ( 1.932)\tData  0.000 ( 1.533)\tLoss 2.2390e+00 (1.9500e+00)\tAcc@1  45.70 ( 67.95)\tAcc@5  91.02 ( 94.90)\n",
            "Epoch: [198][ 50/268]\tTime  0.427 ( 1.673)\tData  0.000 ( 1.273)\tLoss 2.0205e+00 (1.9251e+00)\tAcc@1  64.45 ( 69.74)\tAcc@5  96.48 ( 95.26)\n",
            "Epoch: [198][ 60/268]\tTime  1.964 ( 1.493)\tData  1.646 ( 1.093)\tLoss 1.8347e+00 (1.9594e+00)\tAcc@1  80.08 ( 67.98)\tAcc@5  97.66 ( 94.58)\n",
            "Epoch: [198][ 70/268]\tTime  0.421 ( 1.342)\tData  0.000 ( 0.941)\tLoss 1.6330e+00 (1.9576e+00)\tAcc@1  81.25 ( 68.28)\tAcc@5  98.44 ( 94.63)\n",
            "Epoch: [198][ 80/268]\tTime  0.414 ( 1.255)\tData  0.000 ( 0.855)\tLoss 1.7077e+00 (1.9398e+00)\tAcc@1  85.94 ( 69.57)\tAcc@5  98.44 ( 94.97)\n",
            "Epoch: [198][ 90/268]\tTime  0.418 ( 1.187)\tData  0.000 ( 0.789)\tLoss 2.0238e+00 (1.9328e+00)\tAcc@1  60.55 ( 69.96)\tAcc@5  93.75 ( 95.11)\n",
            "Epoch: [198][100/268]\tTime  0.416 ( 1.131)\tData  0.000 ( 0.734)\tLoss 1.7003e+00 (1.9232e+00)\tAcc@1  78.12 ( 70.26)\tAcc@5  98.05 ( 95.23)\n",
            "Epoch: [198][110/268]\tTime  0.418 ( 1.086)\tData  0.000 ( 0.689)\tLoss 2.1394e+00 (1.9144e+00)\tAcc@1  47.27 ( 70.44)\tAcc@5  92.58 ( 95.34)\n",
            "Epoch: [198][120/268]\tTime  2.197 ( 1.045)\tData  1.854 ( 0.648)\tLoss 1.8188e+00 (1.9066e+00)\tAcc@1  68.75 ( 70.66)\tAcc@5  96.88 ( 95.50)\n",
            "Epoch: [198][130/268]\tTime  0.425 ( 0.999)\tData  0.000 ( 0.602)\tLoss 1.6457e+00 (1.8984e+00)\tAcc@1  86.72 ( 71.17)\tAcc@5  99.22 ( 95.65)\n",
            "Epoch: [198][140/268]\tTime  0.426 ( 0.974)\tData  0.000 ( 0.576)\tLoss 1.5524e+00 (1.8987e+00)\tAcc@1  94.14 ( 71.47)\tAcc@5  98.83 ( 95.64)\n",
            "Epoch: [198][150/268]\tTime  0.412 ( 0.949)\tData  0.000 ( 0.552)\tLoss 1.6549e+00 (1.8940e+00)\tAcc@1  86.33 ( 71.89)\tAcc@5  98.44 ( 95.74)\n",
            "Epoch: [198][160/268]\tTime  0.422 ( 0.931)\tData  0.000 ( 0.535)\tLoss 1.6230e+00 (1.8945e+00)\tAcc@1  87.50 ( 71.70)\tAcc@5  96.48 ( 95.76)\n",
            "Epoch: [198][170/268]\tTime  1.063 ( 0.916)\tData  0.740 ( 0.521)\tLoss 1.9638e+00 (1.8957e+00)\tAcc@1  58.59 ( 71.37)\tAcc@5  95.31 ( 95.78)\n",
            "Epoch: [198][180/268]\tTime  1.732 ( 0.896)\tData  1.371 ( 0.500)\tLoss 1.6533e+00 (1.8982e+00)\tAcc@1  85.55 ( 70.95)\tAcc@5  98.83 ( 95.75)\n",
            "Epoch: [198][190/268]\tTime  0.425 ( 0.875)\tData  0.000 ( 0.478)\tLoss 2.0860e+00 (1.8985e+00)\tAcc@1  60.55 ( 70.92)\tAcc@5  95.31 ( 95.77)\n",
            "Epoch: [198][200/268]\tTime  0.420 ( 0.861)\tData  0.000 ( 0.465)\tLoss 1.7170e+00 (1.8984e+00)\tAcc@1  81.64 ( 70.85)\tAcc@5  96.88 ( 95.78)\n",
            "Epoch: [198][210/268]\tTime  0.407 ( 0.850)\tData  0.000 ( 0.454)\tLoss 1.5207e+00 (1.8916e+00)\tAcc@1  90.62 ( 71.27)\tAcc@5  99.61 ( 95.85)\n",
            "Epoch: [198][220/268]\tTime  0.421 ( 0.838)\tData  0.000 ( 0.443)\tLoss 2.0724e+00 (1.8960e+00)\tAcc@1  49.61 ( 70.83)\tAcc@5  94.53 ( 95.78)\n",
            "Epoch: [198][230/268]\tTime  0.533 ( 0.830)\tData  0.201 ( 0.436)\tLoss 1.7380e+00 (1.8910e+00)\tAcc@1  80.86 ( 71.12)\tAcc@5  98.05 ( 95.82)\n",
            "Epoch: [198][240/268]\tTime  2.198 ( 0.821)\tData  1.872 ( 0.426)\tLoss 1.8890e+00 (1.8871e+00)\tAcc@1  72.66 ( 71.41)\tAcc@5  94.92 ( 95.82)\n",
            "Epoch: [198][250/268]\tTime  0.413 ( 0.806)\tData  0.000 ( 0.412)\tLoss 1.9724e+00 (1.8886e+00)\tAcc@1  77.34 ( 71.19)\tAcc@5  94.92 ( 95.79)\n",
            "Epoch: [198][260/268]\tTime  0.415 ( 0.797)\tData  0.000 ( 0.403)\tLoss 2.2267e+00 (1.8879e+00)\tAcc@1  46.88 ( 71.36)\tAcc@5  91.02 ( 95.80)\n",
            "epoch: 198\n",
            "2023-03-25 06:55:33.336975: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:33.337074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:33.337092: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:37.355422: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:37.355522: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:37.355540: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:41.352166: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:41.352264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:41.352284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:45.301588: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:45.301704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:45.301725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:49.312896: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:49.312995: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:49.313015: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:53.298119: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:53.298227: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:53.298245: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:55:57.286305: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:57.286436: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:55:57.286452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:56:01.265041: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:01.265138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:01.265156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:56:05.227287: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:05.227382: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:05.227401: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:56:09.202390: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:09.202498: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:09.202518: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:56:13.233803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:13.233897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:13.233916: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-25 06:56:17.170695: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:17.170799: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-25 06:56:17.170817: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [199][  0/268]\tTime 56.176 (56.176)\tData 55.838 (55.838)\tLoss 1.5340e+00 (1.5340e+00)\tAcc@1  90.23 ( 90.23)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [199][ 10/268]\tTime  0.414 ( 5.488)\tData  0.000 ( 5.085)\tLoss 2.1129e+00 (1.8940e+00)\tAcc@1  53.91 ( 71.41)\tAcc@5  94.92 ( 95.99)\n",
            "Epoch: [199][ 20/268]\tTime  0.417 ( 3.199)\tData  0.000 ( 2.799)\tLoss 1.7963e+00 (1.9058e+00)\tAcc@1  77.73 ( 70.31)\tAcc@5  98.05 ( 95.78)\n",
            "Epoch: [199][ 30/268]\tTime  0.417 ( 2.353)\tData  0.000 ( 1.952)\tLoss 1.9379e+00 (1.9123e+00)\tAcc@1  71.09 ( 71.47)\tAcc@5  96.48 ( 95.90)\n",
            "Epoch: [199][ 40/268]\tTime  0.418 ( 1.939)\tData  0.011 ( 1.538)\tLoss 2.1444e+00 (1.8997e+00)\tAcc@1  49.61 ( 72.44)\tAcc@5  96.48 ( 96.05)\n",
            "Epoch: [199][ 50/268]\tTime  0.416 ( 1.684)\tData  0.000 ( 1.283)\tLoss 1.6786e+00 (1.8858e+00)\tAcc@1  73.83 ( 71.95)\tAcc@5  98.83 ( 96.01)\n",
            "Epoch: [199][ 60/268]\tTime  2.702 ( 1.514)\tData  2.369 ( 1.113)\tLoss 2.1315e+00 (1.9187e+00)\tAcc@1  61.72 ( 69.97)\tAcc@5  94.14 ( 95.61)\n",
            "Epoch: [199][ 70/268]\tTime  0.417 ( 1.359)\tData  0.000 ( 0.958)\tLoss 1.5590e+00 (1.9441e+00)\tAcc@1  89.84 ( 69.49)\tAcc@5  98.05 ( 94.66)\n",
            "Epoch: [199][ 80/268]\tTime  0.436 ( 1.262)\tData  0.000 ( 0.861)\tLoss 1.8674e+00 (1.9299e+00)\tAcc@1  68.36 ( 70.01)\tAcc@5  97.66 ( 94.94)\n",
            "Epoch: [199][ 90/268]\tTime  0.424 ( 1.188)\tData  0.000 ( 0.787)\tLoss 1.4417e+00 (1.9378e+00)\tAcc@1  91.80 ( 69.91)\tAcc@5  98.83 ( 94.89)\n",
            "Epoch: [199][100/268]\tTime  0.429 ( 1.132)\tData  0.000 ( 0.730)\tLoss 1.3273e+00 (1.9142e+00)\tAcc@1  93.75 ( 71.00)\tAcc@5  99.22 ( 95.18)\n",
            "Epoch: [199][110/268]\tTime  0.410 ( 1.091)\tData  0.000 ( 0.690)\tLoss 2.2410e+00 (1.9111e+00)\tAcc@1  51.17 ( 71.61)\tAcc@5  90.23 ( 95.28)\n",
            "Epoch: [199][120/268]\tTime  1.823 ( 1.047)\tData  1.490 ( 0.646)\tLoss 1.4896e+00 (1.9112e+00)\tAcc@1  92.97 ( 71.35)\tAcc@5  97.27 ( 95.26)\n",
            "Epoch: [199][130/268]\tTime  0.413 ( 0.999)\tData  0.000 ( 0.598)\tLoss 1.5324e+00 (1.9082e+00)\tAcc@1  92.58 ( 71.31)\tAcc@5  98.83 ( 95.30)\n",
            "Epoch: [199][140/268]\tTime  0.408 ( 0.975)\tData  0.000 ( 0.574)\tLoss 1.5346e+00 (1.9134e+00)\tAcc@1  93.75 ( 70.96)\tAcc@5  98.05 ( 95.17)\n",
            "Epoch: [199][150/268]\tTime  0.777 ( 0.950)\tData  0.441 ( 0.550)\tLoss 1.9113e+00 (1.9027e+00)\tAcc@1  78.52 ( 71.72)\tAcc@5  94.53 ( 95.31)\n",
            "Epoch: [199][160/268]\tTime  0.429 ( 0.932)\tData  0.001 ( 0.532)\tLoss 1.7754e+00 (1.9088e+00)\tAcc@1  85.55 ( 71.44)\tAcc@5  96.09 ( 95.25)\n",
            "Epoch: [199][170/268]\tTime  0.433 ( 0.914)\tData  0.000 ( 0.514)\tLoss 1.7344e+00 (1.9075e+00)\tAcc@1  78.52 ( 71.46)\tAcc@5  98.83 ( 95.29)\n",
            "Epoch: [199][180/268]\tTime  2.719 ( 0.900)\tData  2.386 ( 0.500)\tLoss 1.5368e+00 (1.9086e+00)\tAcc@1  92.97 ( 71.62)\tAcc@5  98.44 ( 95.30)\n",
            "Epoch: [199][190/268]\tTime  0.422 ( 0.876)\tData  0.000 ( 0.475)\tLoss 1.6474e+00 (1.9016e+00)\tAcc@1  71.88 ( 71.90)\tAcc@5  98.44 ( 95.41)\n",
            "Epoch: [199][200/268]\tTime  0.418 ( 0.864)\tData  0.000 ( 0.465)\tLoss 1.7938e+00 (1.8965e+00)\tAcc@1  66.41 ( 72.09)\tAcc@5  97.27 ( 95.50)\n",
            "Epoch: [199][210/268]\tTime  1.426 ( 0.855)\tData  1.108 ( 0.456)\tLoss 1.7811e+00 (1.9073e+00)\tAcc@1  80.08 ( 71.55)\tAcc@5  98.05 ( 95.22)\n",
            "Epoch: [199][220/268]\tTime  0.416 ( 0.840)\tData  0.000 ( 0.440)\tLoss 2.1952e+00 (1.9037e+00)\tAcc@1  47.27 ( 71.66)\tAcc@5  89.06 ( 95.25)\n",
            "Epoch: [199][230/268]\tTime  0.418 ( 0.829)\tData  0.001 ( 0.430)\tLoss 1.9922e+00 (1.9045e+00)\tAcc@1  68.36 ( 71.60)\tAcc@5  94.14 ( 95.26)\n",
            "Epoch: [199][240/268]\tTime  1.494 ( 0.822)\tData  1.155 ( 0.423)\tLoss 2.1193e+00 (1.9020e+00)\tAcc@1  46.48 ( 71.72)\tAcc@5  94.92 ( 95.30)\n",
            "Epoch: [199][250/268]\tTime  0.415 ( 0.810)\tData  0.000 ( 0.411)\tLoss 1.8503e+00 (1.9008e+00)\tAcc@1  75.78 ( 71.73)\tAcc@5  98.83 ( 95.37)\n",
            "Epoch: [199][260/268]\tTime  0.416 ( 0.797)\tData  0.000 ( 0.399)\tLoss 2.1858e+00 (1.9038e+00)\tAcc@1  51.95 ( 71.59)\tAcc@5  91.41 ( 95.35)\n",
            "epoch: 199\n",
            "Traceback (most recent call last):\n",
            "  File \"h5py/_objects.pyx\", line 201, in h5py._objects.ObjectID.__dealloc__\n",
            "RuntimeError: Can't decrement id ref count (unable to close file, errno = 107, error message = 'Transport endpoint is not connected')\n",
            "Exception ignored in: 'h5py._objects.ObjectID.__dealloc__'\n",
            "Traceback (most recent call last):\n",
            "  File \"h5py/_objects.pyx\", line 201, in h5py._objects.ObjectID.__dealloc__\n",
            "RuntimeError: Can't decrement id ref count (unable to close file, errno = 107, error message = 'Transport endpoint is not connected')\n",
            "double free or corruption (fasttop)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 449, in <module>\n",
            "    main()\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 147, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/multiprocessing/spawn.py\", line 140, in join\n",
            "    raise ProcessExitedException(\n",
            "torch.multiprocessing.spawn.ProcessExitedException: process 0 terminated with signal SIGABRT\n"
          ]
        }
      ],
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  --lr 0.03 \\\n",
        "  --batch-size 256 \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  --lr 0.03 \\\n",
        "  --batch-size 256 \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFbxPkSzu6KL",
        "outputId": "73cb435e-dd96-4106-9b2d-9c8e2ec9c6ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-27 20:11:21.641595: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-27 20:11:21.799859: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-27 20:11:22.710797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:11:22.710898: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:11:22.710918: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:11:26.576866: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:11:26.576990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:11:26.577013: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet50'\n",
            "MoCo(\n",
            "  (encoder_q): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  )\n",
            "  (encoder_k): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=2048, out_features=128, bias=True)\n",
            "  )\n",
            ")\n",
            "2023-03-27 20:19:18.023578: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:18.023675: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:18.023694: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:21.956062: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:21.956158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:21.956176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:25.896044: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:25.896132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:25.896152: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:29.779536: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:29.779639: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:29.779660: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:33.653960: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:33.654052: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:33.654070: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:37.585284: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:37.585398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:37.585416: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:41.507437: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:41.507530: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:41.507548: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:45.354608: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:45.354707: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:45.354725: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:49.278565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:49.278661: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:49.278678: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:53.194464: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:53.194560: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:53.194578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:19:57.060973: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:57.061074: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:19:57.061094: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-27 20:20:00.943470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:20:00.943566: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-27 20:20:00.943584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][  0/268]\tTime 72.518 (72.518)\tData 56.722 (56.722)\tLoss 3.9363e-01 (3.9363e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 10/268]\tTime  0.417 ( 6.965)\tData  0.000 ( 5.157)\tLoss 7.7854e+00 (6.4598e+00)\tAcc@1   0.00 (  9.23)\tAcc@5   0.00 (  9.94)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 20/268]\tTime  0.432 ( 3.850)\tData  0.002 ( 2.706)\tLoss 8.1086e+00 (7.1962e+00)\tAcc@1   0.39 (  4.93)\tAcc@5   2.34 (  5.73)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 30/268]\tTime  0.417 ( 2.744)\tData  0.000 ( 1.837)\tLoss 8.0636e+00 (7.4874e+00)\tAcc@1   0.78 (  3.60)\tAcc@5   1.95 (  4.52)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 40/268]\tTime  0.430 ( 2.177)\tData  0.000 ( 1.392)\tLoss 7.9407e+00 (7.6102e+00)\tAcc@1   1.17 (  2.90)\tAcc@5   3.52 (  4.30)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 50/268]\tTime  0.422 ( 1.833)\tData  0.064 ( 1.122)\tLoss 7.8992e+00 (7.6688e+00)\tAcc@1   2.73 (  2.61)\tAcc@5   5.47 (  4.30)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 60/268]\tTime  0.708 ( 1.633)\tData  0.387 ( 0.977)\tLoss 7.8795e+00 (7.7041e+00)\tAcc@1   0.39 (  2.35)\tAcc@5   3.12 (  4.30)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 70/268]\tTime  0.418 ( 1.488)\tData  0.000 ( 0.872)\tLoss 7.8902e+00 (7.7270e+00)\tAcc@1   0.39 (  2.16)\tAcc@5   3.91 (  4.24)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 80/268]\tTime  0.412 ( 1.370)\tData  0.000 ( 0.783)\tLoss 7.9138e+00 (7.7448e+00)\tAcc@1   0.78 (  2.02)\tAcc@5   3.12 (  4.16)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][ 90/268]\tTime  0.793 ( 1.288)\tData  0.462 ( 0.725)\tLoss 7.8616e+00 (7.7602e+00)\tAcc@1   1.95 (  1.91)\tAcc@5   5.08 (  4.23)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][100/268]\tTime  0.433 ( 1.214)\tData  0.038 ( 0.668)\tLoss 7.8835e+00 (7.7729e+00)\tAcc@1   0.78 (  1.83)\tAcc@5   3.52 (  4.30)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][110/268]\tTime  0.420 ( 1.159)\tData  0.048 ( 0.627)\tLoss 7.9211e+00 (7.7856e+00)\tAcc@1   3.91 (  1.84)\tAcc@5   7.03 (  4.42)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][120/268]\tTime  0.421 ( 1.116)\tData  0.011 ( 0.597)\tLoss 7.9101e+00 (7.7972e+00)\tAcc@1   1.95 (  1.82)\tAcc@5   8.20 (  4.56)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][130/268]\tTime  0.432 ( 1.081)\tData  0.000 ( 0.571)\tLoss 7.9699e+00 (7.8081e+00)\tAcc@1   0.39 (  1.81)\tAcc@5   3.91 (  4.58)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][140/268]\tTime  0.455 ( 1.037)\tData  0.136 ( 0.536)\tLoss 7.9496e+00 (7.8189e+00)\tAcc@1   0.39 (  1.80)\tAcc@5   5.86 (  4.73)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "Epoch: [0][150/268]\tTime  0.417 ( 1.007)\tData  0.000 ( 0.513)\tLoss 7.9876e+00 (7.8283e+00)\tAcc@1   2.34 (  1.80)\tAcc@5   5.86 (  4.83)\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n",
            "tensor(0, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdN-L14q0r6B",
        "outputId": "219454c9-45cf-47c0-ef5c-162ad23b5d53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 31, in <module>\n",
            "    from models.SmaAt_UNet import SmaAt_UNet\n",
            "ModuleNotFoundError: No module named 'models'\n"
          ]
        }
      ],
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  -a resnet50 \\\n",
        "  --lr 0.10 \\\n",
        "  --batch-size 128 \\\n",
        "  --mlp --moco-t 0.2 --aug-plus --cos \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2zR7dEjZnlu",
        "outputId": "fa8a3fd0-b30c-4b04-92e6-b5e0ee2dc14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-04-19 14:17:00.351238: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-19 14:17:01.266562: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "=> loading checkpoint '/content/checkpoint_0008.pth.tar'\n",
            "module.queue\n",
            "module.queue_ptr\n",
            "module.encoder_q.inc.double_conv.0.depthwise.weight\n",
            "module.encoder_q.inc.double_conv.0.depthwise.bias\n",
            "module.encoder_q.inc.double_conv.0.pointwise.weight\n",
            "module.encoder_q.inc.double_conv.0.pointwise.bias\n",
            "module.encoder_q.inc.double_conv.1.weight\n",
            "module.encoder_q.inc.double_conv.1.bias\n",
            "module.encoder_q.inc.double_conv.1.running_mean\n",
            "module.encoder_q.inc.double_conv.1.running_var\n",
            "module.encoder_q.inc.double_conv.1.num_batches_tracked\n",
            "module.encoder_q.inc.double_conv.3.depthwise.weight\n",
            "module.encoder_q.inc.double_conv.3.depthwise.bias\n",
            "module.encoder_q.inc.double_conv.3.pointwise.weight\n",
            "module.encoder_q.inc.double_conv.3.pointwise.bias\n",
            "module.encoder_q.inc.double_conv.4.weight\n",
            "module.encoder_q.inc.double_conv.4.bias\n",
            "module.encoder_q.inc.double_conv.4.running_mean\n",
            "module.encoder_q.inc.double_conv.4.running_var\n",
            "module.encoder_q.inc.double_conv.4.num_batches_tracked\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_q.down1.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_q.down2.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_q.down3.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_q.down4.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_q.cbam5.channel_att.MLP.1.weight\n",
            "module.encoder_q.cbam5.channel_att.MLP.1.bias\n",
            "module.encoder_q.cbam5.channel_att.MLP.3.weight\n",
            "module.encoder_q.cbam5.channel_att.MLP.3.bias\n",
            "module.encoder_q.cbam5.spatial_att.conv.weight\n",
            "module.encoder_q.cbam5.spatial_att.bn.weight\n",
            "module.encoder_q.cbam5.spatial_att.bn.bias\n",
            "module.encoder_q.cbam5.spatial_att.bn.running_mean\n",
            "module.encoder_q.cbam5.spatial_att.bn.running_var\n",
            "module.encoder_q.cbam5.spatial_att.bn.num_batches_tracked\n",
            "module.encoder_q.fc.weight\n",
            "module.encoder_q.fc.bias\n",
            "module.encoder_k.inc.double_conv.0.depthwise.weight\n",
            "module.encoder_k.inc.double_conv.0.depthwise.bias\n",
            "module.encoder_k.inc.double_conv.0.pointwise.weight\n",
            "module.encoder_k.inc.double_conv.0.pointwise.bias\n",
            "module.encoder_k.inc.double_conv.1.weight\n",
            "module.encoder_k.inc.double_conv.1.bias\n",
            "module.encoder_k.inc.double_conv.1.running_mean\n",
            "module.encoder_k.inc.double_conv.1.running_var\n",
            "module.encoder_k.inc.double_conv.1.num_batches_tracked\n",
            "module.encoder_k.inc.double_conv.3.depthwise.weight\n",
            "module.encoder_k.inc.double_conv.3.depthwise.bias\n",
            "module.encoder_k.inc.double_conv.3.pointwise.weight\n",
            "module.encoder_k.inc.double_conv.3.pointwise.bias\n",
            "module.encoder_k.inc.double_conv.4.weight\n",
            "module.encoder_k.inc.double_conv.4.bias\n",
            "module.encoder_k.inc.double_conv.4.running_mean\n",
            "module.encoder_k.inc.double_conv.4.running_var\n",
            "module.encoder_k.inc.double_conv.4.num_batches_tracked\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_k.down1.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_k.down2.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_k.down3.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.0.depthwise.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.0.depthwise.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.0.pointwise.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.0.pointwise.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.1.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.1.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.1.running_mean\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.1.running_var\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.1.num_batches_tracked\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.3.depthwise.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.3.depthwise.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.3.pointwise.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.3.pointwise.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.4.weight\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.4.bias\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.4.running_mean\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.4.running_var\n",
            "module.encoder_k.down4.maxpool_conv.1.double_conv.4.num_batches_tracked\n",
            "module.encoder_k.cbam5.channel_att.MLP.1.weight\n",
            "module.encoder_k.cbam5.channel_att.MLP.1.bias\n",
            "module.encoder_k.cbam5.channel_att.MLP.3.weight\n",
            "module.encoder_k.cbam5.channel_att.MLP.3.bias\n",
            "module.encoder_k.cbam5.spatial_att.conv.weight\n",
            "module.encoder_k.cbam5.spatial_att.bn.weight\n",
            "module.encoder_k.cbam5.spatial_att.bn.bias\n",
            "module.encoder_k.cbam5.spatial_att.bn.running_mean\n",
            "module.encoder_k.cbam5.spatial_att.bn.running_var\n",
            "module.encoder_k.cbam5.spatial_att.bn.num_batches_tracked\n",
            "module.encoder_k.fc.weight\n",
            "module.encoder_k.fc.bias\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/downstream_task.py\", line 175, in <module>\n",
            "    model.load_state_dict(state_dict_smaat_unet)\n",
            "  File \"/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\", line 2041, in load_state_dict\n",
            "    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n",
            "RuntimeError: Error(s) in loading state_dict for SmaAt_UNet:\n",
            "\tsize mismatch for inc.double_conv.0.pointwise.weight: copying a param with shape torch.Size([6, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 6, 1, 1]).\n",
            "\tsize mismatch for inc.double_conv.0.pointwise.bias: copying a param with shape torch.Size([6]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for inc.double_conv.1.weight: copying a param with shape torch.Size([64, 6, 1, 1]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for inc.double_conv.3.depthwise.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128, 1, 3, 3]).\n",
            "\tsize mismatch for inc.double_conv.3.depthwise.bias: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for inc.double_conv.3.pointwise.weight: copying a param with shape torch.Size([128, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 128, 1, 1]).\n",
            "\tsize mismatch for inc.double_conv.3.pointwise.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for inc.double_conv.4.weight: copying a param with shape torch.Size([64, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for cbam1.channel_att.MLP.1.weight: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([4, 64]).\n",
            "\tsize mismatch for cbam1.channel_att.MLP.1.bias: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([4]).\n",
            "\tsize mismatch for cbam1.channel_att.MLP.3.weight: copying a param with shape torch.Size([128, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([64, 4]).\n",
            "\tsize mismatch for cbam1.channel_att.MLP.3.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n",
            "\tsize mismatch for cbam1.spatial_att.conv.weight: copying a param with shape torch.Size([128, 128, 1, 1]) from checkpoint, the shape in current model is torch.Size([1, 2, 7, 7]).\n",
            "\tsize mismatch for cbam1.spatial_att.bn.weight: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam1.spatial_att.bn.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam1.spatial_att.bn.running_mean: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam1.spatial_att.bn.running_var: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.0.depthwise.weight: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([128, 1, 3, 3]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.0.depthwise.bias: copying a param with shape torch.Size([256, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.0.pointwise.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128, 128, 1, 1]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.0.pointwise.bias: copying a param with shape torch.Size([128, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.3.depthwise.weight: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.3.depthwise.bias: copying a param with shape torch.Size([256, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.3.pointwise.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128, 256, 1, 1]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.3.pointwise.bias: copying a param with shape torch.Size([256, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.4.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.4.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.4.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for down1.maxpool_conv.1.double_conv.4.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cbam2.channel_att.MLP.1.weight: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([8, 128]).\n",
            "\tsize mismatch for cbam2.channel_att.MLP.1.bias: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([8]).\n",
            "\tsize mismatch for cbam2.channel_att.MLP.3.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([128, 8]).\n",
            "\tsize mismatch for cbam2.channel_att.MLP.3.bias: copying a param with shape torch.Size([256, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([128]).\n",
            "\tsize mismatch for cbam2.spatial_att.conv.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1, 2, 7, 7]).\n",
            "\tsize mismatch for cbam2.spatial_att.bn.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam2.spatial_att.bn.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam2.spatial_att.bn.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam2.spatial_att.bn.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.0.depthwise.weight: copying a param with shape torch.Size([512, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([256, 1, 3, 3]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.0.depthwise.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.0.pointwise.weight: copying a param with shape torch.Size([512, 512, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 256, 1, 1]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.0.pointwise.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.1.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.1.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.1.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.1.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.3.depthwise.weight: copying a param with shape torch.Size([1024, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([512, 1, 3, 3]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.3.depthwise.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.3.pointwise.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 512, 1, 1]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.3.pointwise.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.4.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.4.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.4.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for down2.maxpool_conv.1.double_conv.4.running_var: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cbam3.channel_att.MLP.1.weight: copying a param with shape torch.Size([1024, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([16, 256]).\n",
            "\tsize mismatch for cbam3.channel_att.MLP.1.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([16]).\n",
            "\tsize mismatch for cbam3.channel_att.MLP.3.weight: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 16]).\n",
            "\tsize mismatch for cbam3.channel_att.MLP.3.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([256]).\n",
            "\tsize mismatch for cbam3.spatial_att.conv.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1, 2, 7, 7]).\n",
            "\tsize mismatch for cbam3.spatial_att.bn.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam3.spatial_att.bn.bias: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam3.spatial_att.bn.running_mean: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam3.spatial_att.bn.running_var: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([1]).\n",
            "\tsize mismatch for cbam3.spatial_att.bn.num_batches_tracked: copying a param with shape torch.Size([1024, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.0.depthwise.weight: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512, 1, 3, 3]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.0.depthwise.bias: copying a param with shape torch.Size([512, 1024, 1, 1]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.0.pointwise.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([512, 512, 1, 1]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.1.running_var: copying a param with shape torch.Size([]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.1.num_batches_tracked: copying a param with shape torch.Size([32, 512]) from checkpoint, the shape in current model is torch.Size([]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.3.depthwise.weight: copying a param with shape torch.Size([32]) from checkpoint, the shape in current model is torch.Size([1024, 1, 3, 3]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.3.depthwise.bias: copying a param with shape torch.Size([512, 32]) from checkpoint, the shape in current model is torch.Size([1024]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.3.pointwise.weight: copying a param with shape torch.Size([512]) from checkpoint, the shape in current model is torch.Size([512, 1024, 1, 1]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.3.pointwise.bias: copying a param with shape torch.Size([1, 2, 7, 7]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.4.weight: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.4.bias: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.4.running_mean: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512]).\n",
            "\tsize mismatch for down3.maxpool_conv.1.double_conv.4.running_var: copying a param with shape torch.Size([1]) from checkpoint, the shape in current model is torch.Size([512]).\n"
          ]
        }
      ],
      "source": [
        "!python /content/Master_Thesis/downstream_task.py \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu2JYzjWm-5A",
        "outputId": "ebe00283-914f-4117-c8f3-7f91beed4443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: torchvision 0.14.1+cu116\n",
            "Uninstalling torchvision-0.14.1+cu116:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision-0.14.1+cu116.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libcudart.a44f4c9b.so.11.0\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libnvjpeg.5afee195.so.11\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchvision-0.14.1+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-0.14.2+cu117.html\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (57.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.14.1\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall torchvision\n",
        "!pip install --upgrade -U torchvision -f https://data.pyg.org/whl/torch-0.14.2+cu117.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "cv34I957tbJw",
        "outputId": "834a24e8-6180-4904-abd7-500be44fa7a0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-3882461a2f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9yRYFma1cJ8q"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583
        },
        "id": "BNKWPapwnmnY",
        "outputId": "efa6fccf-1505-40bc-b4b1-6a466bdf6480"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5734, 18, 288, 288)\n",
            "[[0.00020907 0.00020907 0.00020907 ... 0.         0.         0.        ]\n",
            " [0.00020907 0.00020907 0.00020907 ... 0.         0.         0.        ]\n",
            " [0.00020907 0.00020907 0.00020907 ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.00020907 0.00020907 0.00020907]\n",
            " [0.         0.         0.         ... 0.00020907 0.00020907 0.00020907]\n",
            " [0.         0.         0.         ... 0.00020907 0.00020907 0.00020907]]\n",
            "[[5.1 5.1 5.1 ... 0.  0.  0. ]\n",
            " [5.1 5.1 5.1 ... 0.  0.  0. ]\n",
            " [5.1 5.1 5.1 ... 0.  0.  0. ]\n",
            " ...\n",
            " [0.  0.  0.  ... 5.1 5.1 5.1]\n",
            " [0.  0.  0.  ... 5.1 5.1 5.1]\n",
            " [0.  0.  0.  ... 5.1 5.1 5.1]]\n",
            "<PIL.Image.Image image mode=L size=288x288 at 0x7F9AD86A8D60>\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9ad8401310>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pylab as plt\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image\n",
        "\n",
        "f = h5py.File('/content/drive/MyDrive/train_test_2016-2019_input-length_12_img-ahead_6_rain-threshhold_50.h5', \"r\")\n",
        "traindir = f['/train/images']\n",
        "print(traindir.shape)\n",
        "test = np.reshape(traindir[4][17:], (288,288))\n",
        "print(test)\n",
        "# Assuming the tensor values are in the range [min_val, max_val]\n",
        "min_val = np.min(test)\n",
        "max_val = np.max(test)\n",
        "test = (test - min_val) / (max_val - min_val) * 255.0\n",
        "print(test)\n",
        "# test = test*10000\n",
        "\n",
        "image = Image.fromarray(np.uint8(test))\n",
        "print(image)\n",
        "image.save(\"test.jpeg\")\n",
        "# image.open(\"test.jpeg\")\n",
        "plt.imshow(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86UtcR9SxL7G",
        "outputId": "4a009a2d-b88b-4421-e18c-e719b9529313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!git push https://github.com/tamarasessink/Master_Thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "X5fjm0-OnNiF",
        "outputId": "f5c99b3f-b051-4c97-bedd-0058952dd845"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6c97127850>"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# after agmentation\n",
        "image = Image.fromarray(np.uint8(test))\n",
        "\n",
        "transform = transforms.RandomHorizontalFlip(p=0.8)\n",
        "img = transform(image)\n",
        "plt.imshow(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "P1FzRzFAtAIt",
        "outputId": "c1c86a2f-6f66-4747-a80d-510e2f5f916d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean and std before normalize:\n",
            "Mean of the image: tensor([0.0619])\n",
            "Std of the image: tensor([0.0852])\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f9a25ab4700>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "# we only have 1 not 3 dimensions per image thus only 1 mean and std\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "# get tensor image\n",
        "img_tr = transform(image)\n",
        "# calculate mean and std\n",
        "mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
        "# print mean and std\n",
        "print(\"mean and std before normalize:\")\n",
        "print(\"Mean of the image:\", mean)\n",
        "print(\"Std of the image:\", std)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.0188],\n",
        "                                     std=[0.0278])\n",
        "augmentation = [transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(), normalize]\n",
        "aug = transforms.Compose(augmentation)\n",
        "img = aug(image)\n",
        "test2 =  torch.squeeze(img,0)\n",
        "plt.imshow(test2)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1x2GvwuM2rSEdAOuinhciWSAigYkLWGSI",
      "authorship_tag": "ABX9TyMG3IlkTBs9P/mTYo2/0R/2",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}