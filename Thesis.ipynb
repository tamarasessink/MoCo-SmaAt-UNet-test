{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1x2GvwuM2rSEdAOuinhciWSAigYkLWGSI",
      "authorship_tag": "ABX9TyMt2gxN9h46Y4tllsyrRBQe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tamarasessink/Master_Thesis/blob/master/Thesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWlSGYfHk5iS",
        "outputId": "25266988-57da-4a6a-e705-9824d53efb6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Master_Thesis'...\n",
            "remote: Enumerating objects: 162, done.\u001b[K\n",
            "remote: Counting objects: 100% (162/162), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 162 (delta 87), reused 93 (delta 37), pack-reused 0\n",
            "Receiving objects: 100% (162/162), 511.14 KiB | 3.65 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/tamarasessink/Master_Thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch.multiprocessing as mp\n",
        "print(\"Number of cpu : \", mp.cpu_count())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiJBBfpOn2tY",
        "outputId": "502471ad-b1a1-4578-e378-6d607f68d0eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cpu :  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.9.2\n",
        "!pip install fastapi==0.90.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1m9wiU-iWDc",
        "outputId": "39b9e122-423b-4728-f892-cba205b9382e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.9.2\n",
            "  Downloading tensorflow-2.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.4.0)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 KB\u001b[0m \u001b[31m39.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.22.4)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (57.4.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.19.6)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (15.0.6.1)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (4.5.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (0.31.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (2.2.0)\n",
            "Collecting tensorboard<2.10,>=2.9\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m97.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.9.2) (1.51.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.2) (0.38.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.25.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (6.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (1.26.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.2) (3.2.2)\n",
            "Installing collected packages: keras, flatbuffers, tensorflow-estimator, keras-preprocessing, tensorboard, tensorflow\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.11.0\n",
            "    Uninstalling keras-2.11.0:\n",
            "      Successfully uninstalled keras-2.11.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.1.21\n",
            "    Uninstalling flatbuffers-23.1.21:\n",
            "      Successfully uninstalled flatbuffers-23.1.21\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.11.0\n",
            "    Uninstalling tensorflow-estimator-2.11.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.11.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.11.0\n",
            "    Uninstalling tensorflow-2.11.0:\n",
            "      Successfully uninstalled tensorflow-2.11.0\n",
            "Successfully installed flatbuffers-1.12 keras-2.9.0 keras-preprocessing-1.1.2 tensorboard-2.9.1 tensorflow-2.9.2 tensorflow-estimator-2.9.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastapi==0.90.0\n",
            "  Downloading fastapi-0.90.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.0/56.0 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from fastapi==0.90.0) (1.10.5)\n",
            "Collecting starlette<=0.23.0,>=0.22.0\n",
            "  Downloading starlette-0.23.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.90.0) (4.5.0)\n",
            "Collecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<=0.23.0,>=0.22.0->fastapi==0.90.0) (2.10)\n",
            "Installing collected packages: sniffio, anyio, starlette, fastapi\n",
            "Successfully installed anyio-3.6.2 fastapi-0.90.0 sniffio-1.3.0 starlette-0.23.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi==0.90.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSi-gza7i5vH",
        "outputId": "08af6fb5-e07e-4a27-a462-c07002886416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: fastapi==0.90.0 in /usr/local/lib/python3.8/dist-packages (0.90.0)\n",
            "Requirement already satisfied: pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2 in /usr/local/lib/python3.8/dist-packages (from fastapi==0.90.0) (1.10.5)\n",
            "Requirement already satisfied: starlette<=0.23.0,>=0.22.0 in /usr/local/lib/python3.8/dist-packages (from fastapi==0.90.0) (0.23.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.8/dist-packages (from pydantic!=1.7,!=1.7.1,!=1.7.2,!=1.7.3,!=1.8,!=1.8.1,<2.0.0,>=1.6.2->fastapi==0.90.0) (4.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.8/dist-packages (from starlette<=0.23.0,>=0.22.0->fastapi==0.90.0) (3.6.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<=0.23.0,>=0.22.0->fastapi==0.90.0) (2.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.8/dist-packages (from anyio<5,>=3.4.0->starlette<=0.23.0,>=0.22.0->fastapi==0.90.0) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tensorflow==2.11.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhBt1XKKV34l",
        "outputId": "9081cd86-b0af-418a-d7d8-c984c5137254"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (15.0.6.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (2.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.6.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (4.5.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.19.6)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (57.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (23.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.31.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.1.0)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.3.3-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.22.4)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.51.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0) (1.15.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.16.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.2.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.25.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (6.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (1.26.14)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (4.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.8/dist-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.3.3 keras-2.11.0 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "model = torch.load('/content/drive/MyDrive/checkpoint_0199.pth.tar', map_location='cpu')\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGbg0wTIPEXy",
        "outputId": "1479a43d-a5b0-4681-b41c-40328b6730ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'epoch': 200, 'arch': 'resnet50', 'state_dict': OrderedDict([('module.queue', tensor([[ 0.1754,  0.0120,  0.2373,  ..., -0.0143, -0.0732,  0.0803],\n",
            "        [-0.0169, -0.1075, -0.0609,  ...,  0.0293,  0.0364,  0.0060],\n",
            "        [ 0.0045,  0.1483, -0.0422,  ...,  0.0360,  0.0889,  0.1925],\n",
            "        ...,\n",
            "        [-0.0383, -0.1552,  0.0384,  ...,  0.0388,  0.0537,  0.1211],\n",
            "        [-0.1201, -0.1051, -0.0991,  ...,  0.1683, -0.0665,  0.0569],\n",
            "        [ 0.1065, -0.0230,  0.1664,  ...,  0.2027, -0.1606,  0.0505]])), ('module.queue_ptr', tensor([0])), ('module.encoder_q.conv1.weight', tensor([[[[ 7.0230e-02, -4.1660e-02,  4.2025e-02,  ...,  7.0984e-03,\n",
            "            1.7880e-02,  6.1800e-03],\n",
            "          [-3.7125e-02,  2.1589e-02, -6.1565e-02,  ...,  2.3484e-02,\n",
            "           -1.0346e-02,  9.8234e-03],\n",
            "          [-6.0116e-03, -3.5639e-02,  6.6227e-02,  ...,  2.8408e-03,\n",
            "           -1.8451e-02,  1.1533e-02],\n",
            "          ...,\n",
            "          [ 2.8007e-02, -2.9953e-02, -1.4943e-04,  ...,  7.7149e-03,\n",
            "            1.0768e-02, -3.9815e-03],\n",
            "          [ 3.5528e-02,  1.2809e-02,  1.1890e-02,  ..., -1.5099e-02,\n",
            "           -3.3117e-02,  2.6577e-03],\n",
            "          [ 1.0346e-02,  2.0440e-02,  1.7211e-02,  ..., -1.4749e-02,\n",
            "           -3.1250e-02,  1.9889e-02]],\n",
            "\n",
            "         [[ 1.6978e-02, -2.0200e-02, -1.5252e-02,  ..., -9.0668e-03,\n",
            "            2.0540e-02,  5.4303e-02],\n",
            "          [ 5.8020e-03,  4.0708e-03, -4.3752e-02,  ..., -3.2700e-02,\n",
            "            1.2490e-02,  3.5838e-02],\n",
            "          [-4.4854e-03,  5.2392e-02,  6.5438e-02,  ..., -2.9543e-02,\n",
            "           -2.2481e-03,  2.8845e-02],\n",
            "          ...,\n",
            "          [-6.2591e-02,  1.4685e-02,  2.0848e-04,  ..., -1.1576e-02,\n",
            "           -2.1890e-02, -3.1101e-03],\n",
            "          [ 3.5477e-02,  6.7638e-03,  3.6611e-03,  ...,  2.1740e-02,\n",
            "           -2.5287e-02, -1.5249e-02],\n",
            "          [-9.2705e-03,  2.7793e-02,  4.0567e-03,  ...,  5.7866e-03,\n",
            "           -2.4483e-02,  5.1187e-02]],\n",
            "\n",
            "         [[-2.7297e-02,  3.8953e-02, -1.3653e-02,  ...,  1.3295e-03,\n",
            "            2.4538e-02,  2.1381e-02],\n",
            "          [ 7.1911e-03, -2.2159e-03, -2.1939e-04,  ...,  7.2159e-03,\n",
            "           -4.1779e-02,  3.4479e-02],\n",
            "          [-6.8842e-03,  4.6468e-03,  4.4188e-03,  ..., -3.7277e-04,\n",
            "           -2.0970e-02,  1.0558e-02],\n",
            "          ...,\n",
            "          [ 4.2007e-02,  3.8454e-02,  1.8357e-03,  ...,  2.9692e-02,\n",
            "           -1.7751e-03, -4.3309e-02],\n",
            "          [-6.9537e-03,  3.9794e-02, -4.0673e-02,  ...,  2.8152e-02,\n",
            "            8.8234e-03, -4.8268e-03],\n",
            "          [-3.5405e-03, -1.0165e-03,  1.2776e-02,  ...,  9.8090e-03,\n",
            "           -9.8217e-03, -5.3463e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4752e-02, -8.4444e-03, -2.9275e-02,  ..., -7.1644e-02,\n",
            "            3.8834e-02,  1.1322e-03],\n",
            "          [ 2.2865e-03,  2.8854e-03, -2.2197e-02,  ..., -4.7384e-02,\n",
            "           -1.6463e-02,  1.3788e-02],\n",
            "          [-2.9182e-02, -5.0805e-02,  1.3142e-02,  ...,  1.7480e-02,\n",
            "           -2.7692e-02,  2.5823e-02],\n",
            "          ...,\n",
            "          [ 3.3552e-02,  3.1358e-02,  2.7909e-02,  ..., -4.8022e-02,\n",
            "            3.4819e-02, -4.6961e-02],\n",
            "          [-1.5143e-02,  4.9633e-03, -2.4345e-03,  ..., -9.2266e-03,\n",
            "           -1.1866e-02,  4.0504e-02],\n",
            "          [-7.0114e-04, -1.0913e-02,  5.0891e-03,  ..., -3.0052e-02,\n",
            "           -8.0363e-03, -2.8494e-02]],\n",
            "\n",
            "         [[ 3.6098e-02, -3.8480e-03, -2.0068e-02,  ...,  1.9626e-02,\n",
            "            3.3643e-04,  2.2916e-02],\n",
            "          [ 3.1339e-02, -1.6150e-02, -1.1722e-02,  ...,  1.8728e-02,\n",
            "           -2.0508e-02,  4.5048e-02],\n",
            "          [-2.8513e-02, -1.1217e-02,  4.4236e-02,  ...,  4.2896e-02,\n",
            "            5.4312e-03,  5.4972e-02],\n",
            "          ...,\n",
            "          [ 7.5011e-03,  2.9551e-02,  5.5053e-02,  ...,  2.0889e-02,\n",
            "            1.6487e-02,  4.0055e-02],\n",
            "          [ 1.7780e-02,  2.6815e-03,  5.7258e-03,  ..., -3.5343e-02,\n",
            "            2.4972e-02,  5.0713e-04],\n",
            "          [ 7.8590e-03,  6.4522e-03, -1.0198e-02,  ...,  8.6444e-03,\n",
            "            1.8308e-02,  2.9113e-03]],\n",
            "\n",
            "         [[-4.5121e-02,  6.9182e-03, -5.1733e-03,  ..., -3.8342e-02,\n",
            "           -2.5513e-02, -2.0584e-02],\n",
            "          [-3.2628e-03, -1.7867e-02, -1.6492e-02,  ..., -6.9671e-04,\n",
            "            3.4794e-02, -1.8322e-02],\n",
            "          [ 2.7563e-02, -7.7159e-05,  2.1879e-02,  ...,  4.0160e-02,\n",
            "           -1.1417e-02,  1.9615e-02],\n",
            "          ...,\n",
            "          [ 1.0656e-02,  1.6287e-02, -1.4590e-02,  ...,  1.4935e-02,\n",
            "            1.3162e-02, -8.6805e-03],\n",
            "          [ 1.6429e-02,  1.6164e-02,  2.2839e-02,  ...,  9.4537e-03,\n",
            "            3.4451e-02, -8.0257e-03],\n",
            "          [-3.1262e-02,  4.3514e-02, -3.8360e-02,  ...,  5.0107e-03,\n",
            "           -8.1864e-03,  2.0612e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9908e-02,  8.1612e-03, -1.1382e-03,  ..., -6.3385e-02,\n",
            "           -1.1457e-02,  1.9245e-02],\n",
            "          [-2.6531e-02, -7.4353e-04,  1.3543e-02,  ...,  2.9808e-02,\n",
            "           -1.5420e-02, -1.1478e-03],\n",
            "          [ 8.9283e-03, -2.0357e-02, -8.1833e-03,  ..., -1.5308e-02,\n",
            "            1.9048e-02, -2.5538e-02],\n",
            "          ...,\n",
            "          [ 8.5311e-03,  1.6157e-02,  3.9713e-02,  ..., -3.0088e-02,\n",
            "            2.5326e-02, -2.4186e-02],\n",
            "          [-2.0506e-02,  2.2312e-02, -5.8071e-03,  ...,  8.7675e-05,\n",
            "           -8.1253e-03, -1.9233e-02],\n",
            "          [ 1.9164e-02, -3.8491e-02, -2.1227e-02,  ...,  2.8487e-02,\n",
            "           -2.4936e-02,  2.8053e-02]],\n",
            "\n",
            "         [[-3.1551e-02,  3.0845e-02, -4.6333e-02,  ..., -2.0439e-02,\n",
            "           -1.3002e-04,  2.3501e-03],\n",
            "          [-5.4811e-02,  2.4578e-02,  3.4488e-02,  ..., -1.0159e-02,\n",
            "            8.3985e-03, -1.3669e-02],\n",
            "          [ 2.6749e-02,  3.3788e-02, -7.4282e-02,  ..., -2.8719e-02,\n",
            "            1.0436e-02, -3.4942e-02],\n",
            "          ...,\n",
            "          [-3.9291e-02,  8.9732e-03,  1.1399e-02,  ...,  3.3853e-02,\n",
            "           -3.7613e-03,  1.7712e-02],\n",
            "          [ 2.6835e-02,  3.6792e-02,  2.8290e-02,  ..., -3.8296e-03,\n",
            "            1.5680e-02, -2.1990e-02],\n",
            "          [ 1.5139e-02,  1.3929e-03, -1.9972e-02,  ..., -3.4302e-02,\n",
            "           -1.8412e-03, -5.6194e-02]],\n",
            "\n",
            "         [[-3.4498e-02, -1.9150e-02, -1.7266e-03,  ..., -2.6108e-02,\n",
            "            4.9628e-02, -3.5181e-02],\n",
            "          [-2.5755e-02,  9.3788e-03, -2.6652e-02,  ..., -4.2523e-02,\n",
            "           -2.0693e-02, -1.1058e-02],\n",
            "          [-9.0799e-03,  3.2399e-03,  8.1756e-03,  ..., -1.7115e-03,\n",
            "            1.7861e-02, -4.4432e-03],\n",
            "          ...,\n",
            "          [ 2.0659e-02,  5.6964e-02,  1.0905e-02,  ...,  1.1691e-02,\n",
            "           -5.7176e-02,  1.1352e-02],\n",
            "          [-2.3308e-02,  3.2889e-02,  4.9990e-03,  ...,  3.7745e-02,\n",
            "            4.1016e-02,  3.4258e-02],\n",
            "          [-2.5163e-03, -1.5997e-02, -8.1919e-03,  ...,  7.8564e-03,\n",
            "           -1.2524e-02,  1.1577e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-6.1407e-02,  1.3469e-02,  4.2060e-03,  ...,  5.6182e-03,\n",
            "           -2.2445e-02, -1.5390e-02],\n",
            "          [ 3.3404e-03, -4.0883e-02, -7.7294e-03,  ..., -1.2372e-02,\n",
            "           -2.1456e-02,  1.1274e-03],\n",
            "          [-6.6711e-04,  1.7167e-03,  5.2219e-03,  ...,  2.5639e-02,\n",
            "            2.6200e-02, -2.6497e-02],\n",
            "          ...,\n",
            "          [ 1.6529e-02,  2.6490e-02, -1.7791e-02,  ...,  3.3424e-03,\n",
            "            1.1694e-02, -1.6976e-03],\n",
            "          [-1.6655e-02, -6.1082e-03, -2.2970e-02,  ..., -3.9323e-02,\n",
            "            6.1883e-04, -2.3682e-03],\n",
            "          [ 4.4987e-02, -8.7138e-03, -7.6173e-03,  ...,  3.3059e-02,\n",
            "           -1.3781e-02, -3.5161e-02]],\n",
            "\n",
            "         [[ 1.9720e-03,  4.7350e-03,  5.8949e-03,  ..., -4.0766e-02,\n",
            "           -2.0361e-02,  1.3355e-02],\n",
            "          [ 3.6404e-02, -8.5382e-03,  2.0897e-02,  ...,  1.7898e-02,\n",
            "           -6.1549e-03, -2.1664e-02],\n",
            "          [ 9.8432e-03, -1.3589e-02, -1.3936e-02,  ...,  1.3763e-02,\n",
            "           -2.6872e-02,  3.3035e-02],\n",
            "          ...,\n",
            "          [-3.6468e-03, -3.1737e-02, -1.7515e-02,  ...,  4.0983e-02,\n",
            "           -6.5273e-03, -3.9143e-02],\n",
            "          [ 8.3578e-03,  3.1648e-04, -2.8919e-02,  ..., -2.7139e-03,\n",
            "            1.4206e-02, -1.4428e-02],\n",
            "          [ 1.8483e-02,  3.5556e-02, -7.5411e-02,  ..., -1.8482e-02,\n",
            "            4.6642e-02, -1.1625e-02]],\n",
            "\n",
            "         [[ 5.4270e-02,  4.2750e-02,  9.4106e-03,  ...,  6.2735e-04,\n",
            "            1.4387e-02,  5.2428e-02],\n",
            "          [ 1.1644e-03, -1.2585e-02,  3.3322e-03,  ..., -2.3003e-02,\n",
            "            1.5390e-02,  8.0922e-03],\n",
            "          [ 5.3882e-03, -1.7276e-02,  1.7107e-02,  ...,  4.4807e-03,\n",
            "            6.5512e-03, -1.6624e-02],\n",
            "          ...,\n",
            "          [-2.5646e-02,  5.3798e-03, -1.7412e-03,  ...,  1.3048e-02,\n",
            "           -2.4354e-03, -8.9014e-04],\n",
            "          [-1.0876e-02,  3.7389e-02, -2.5460e-02,  ..., -3.4094e-02,\n",
            "            9.7123e-03, -2.9183e-02],\n",
            "          [-2.4222e-02, -2.3116e-02, -5.5438e-02,  ..., -2.6687e-04,\n",
            "            2.3819e-02, -1.8324e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0084e-02,  2.8457e-02, -5.8527e-03,  ..., -9.9049e-03,\n",
            "           -8.7022e-04,  4.8238e-02],\n",
            "          [-5.0136e-02, -4.4192e-02,  3.7280e-03,  ..., -3.7206e-03,\n",
            "            2.9080e-02, -5.5944e-02],\n",
            "          [-2.7226e-02,  3.7091e-02, -3.7416e-03,  ..., -7.4820e-03,\n",
            "            2.8279e-02, -3.3986e-02],\n",
            "          ...,\n",
            "          [-4.1813e-03,  4.1199e-02, -1.0520e-02,  ...,  5.5861e-02,\n",
            "            1.9605e-02,  1.8645e-02],\n",
            "          [-1.6161e-02, -1.2307e-02, -1.2783e-02,  ..., -6.7683e-02,\n",
            "           -1.0589e-02, -1.0007e-02],\n",
            "          [ 1.9776e-02,  2.1824e-02,  7.5859e-03,  ..., -1.1652e-02,\n",
            "           -3.6287e-02, -2.7321e-02]],\n",
            "\n",
            "         [[ 2.3408e-02,  1.0959e-02, -2.1279e-02,  ..., -1.2795e-02,\n",
            "            7.1886e-03,  3.9015e-02],\n",
            "          [-7.0718e-04, -1.1121e-02, -4.0811e-02,  ..., -2.3752e-03,\n",
            "           -1.4919e-02, -1.1367e-02],\n",
            "          [ 1.6177e-02,  2.0736e-02,  1.1559e-02,  ..., -2.1132e-02,\n",
            "           -2.4160e-02, -1.8381e-02],\n",
            "          ...,\n",
            "          [-1.9383e-02, -3.1119e-02, -1.4758e-02,  ...,  9.5608e-03,\n",
            "            8.8614e-03, -1.3779e-02],\n",
            "          [ 5.4465e-03, -1.9311e-02,  3.4193e-02,  ..., -2.4402e-02,\n",
            "           -4.3357e-03,  2.7986e-02],\n",
            "          [ 4.5155e-02,  8.9034e-03, -5.0754e-03,  ..., -4.0866e-02,\n",
            "            3.1324e-02, -2.1887e-02]],\n",
            "\n",
            "         [[ 1.8403e-02, -3.3352e-02, -1.5684e-02,  ..., -2.6239e-02,\n",
            "            2.4014e-02,  3.5036e-02],\n",
            "          [-5.6479e-03, -4.5572e-02,  1.0105e-02,  ...,  1.7639e-02,\n",
            "            1.2393e-02, -3.8210e-03],\n",
            "          [-4.5983e-03, -4.6958e-02,  1.4627e-02,  ...,  2.6429e-02,\n",
            "           -1.1667e-02,  7.4409e-03],\n",
            "          ...,\n",
            "          [ 2.6675e-02, -5.2743e-02,  4.2398e-03,  ..., -2.5748e-02,\n",
            "            2.7027e-02, -1.8848e-02],\n",
            "          [ 8.2440e-03,  1.1575e-02, -2.3767e-02,  ...,  9.9610e-03,\n",
            "            5.6627e-03,  2.1254e-02],\n",
            "          [ 4.3452e-03,  4.3235e-02, -2.5197e-02,  ...,  8.4720e-03,\n",
            "           -3.5400e-03,  1.5177e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4204e-02,  5.1498e-03,  6.4632e-04,  ..., -4.1986e-02,\n",
            "           -1.0445e-02, -3.4503e-02],\n",
            "          [ 3.8031e-03,  5.5788e-02, -2.3032e-03,  ..., -6.8555e-04,\n",
            "           -2.2692e-02,  5.6992e-03],\n",
            "          [-5.7408e-03, -1.6614e-02, -2.6557e-02,  ...,  7.0247e-02,\n",
            "            6.0583e-03,  3.5718e-02],\n",
            "          ...,\n",
            "          [ 4.4964e-03,  2.5738e-03,  1.5803e-02,  ...,  1.3609e-02,\n",
            "            1.2865e-02, -7.7757e-03],\n",
            "          [ 5.0254e-03, -5.7688e-02,  1.7978e-02,  ..., -2.8550e-02,\n",
            "            1.3342e-02,  4.7349e-02],\n",
            "          [ 8.0002e-03, -7.3216e-03, -2.1323e-02,  ..., -3.7589e-02,\n",
            "           -4.0416e-02,  2.6647e-02]],\n",
            "\n",
            "         [[ 1.0272e-02,  3.4455e-02, -7.7892e-04,  ..., -1.7804e-02,\n",
            "            1.7395e-02,  4.1567e-03],\n",
            "          [-1.1379e-02,  2.8746e-02,  1.2102e-02,  ..., -3.7311e-02,\n",
            "           -3.6472e-03,  1.7210e-02],\n",
            "          [-2.8158e-03,  2.6575e-02,  1.0746e-02,  ..., -4.6048e-03,\n",
            "           -7.5171e-03,  1.8699e-02],\n",
            "          ...,\n",
            "          [-1.4394e-02, -1.0298e-02,  1.0477e-02,  ...,  2.8987e-02,\n",
            "            3.3398e-03,  3.4187e-02],\n",
            "          [-2.1582e-02,  2.8460e-02,  2.2240e-02,  ..., -3.6928e-02,\n",
            "           -4.4400e-02, -3.8616e-02],\n",
            "          [ 1.5327e-03,  2.0117e-03, -3.6534e-02,  ..., -3.3467e-03,\n",
            "            1.5529e-02,  1.4318e-02]],\n",
            "\n",
            "         [[ 1.7505e-02, -3.9768e-02, -2.1495e-02,  ...,  4.4170e-02,\n",
            "            1.4225e-02, -1.0634e-02],\n",
            "          [ 4.0998e-02,  1.9948e-02, -3.0305e-02,  ...,  1.4370e-02,\n",
            "            3.2112e-03, -3.5947e-04],\n",
            "          [ 1.8017e-02, -4.4208e-02,  3.3003e-02,  ...,  4.0463e-02,\n",
            "           -4.3131e-02, -7.4157e-02],\n",
            "          ...,\n",
            "          [ 2.9672e-02,  1.3462e-02,  2.6593e-02,  ..., -1.0309e-03,\n",
            "            3.1557e-02, -1.7248e-02],\n",
            "          [-2.6385e-02,  1.0508e-02,  6.3523e-03,  ...,  1.5473e-02,\n",
            "           -2.7822e-02,  1.1228e-03],\n",
            "          [ 1.6536e-03,  5.4364e-02,  1.5907e-02,  ...,  1.4138e-02,\n",
            "           -4.5217e-02, -2.6619e-02]]]])), ('module.encoder_q.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.0.conv1.weight', tensor([[[[ 0.0953]],\n",
            "\n",
            "         [[ 0.1736]],\n",
            "\n",
            "         [[-0.1402]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1086]],\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         [[-0.1563]]],\n",
            "\n",
            "\n",
            "        [[[-0.1641]],\n",
            "\n",
            "         [[-0.0071]],\n",
            "\n",
            "         [[ 0.2727]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0580]],\n",
            "\n",
            "         [[ 0.2194]],\n",
            "\n",
            "         [[-0.1120]]],\n",
            "\n",
            "\n",
            "        [[[-0.0537]],\n",
            "\n",
            "         [[-0.0324]],\n",
            "\n",
            "         [[ 0.2052]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1070]],\n",
            "\n",
            "         [[-0.0249]],\n",
            "\n",
            "         [[ 0.0808]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0952]],\n",
            "\n",
            "         [[-0.2897]],\n",
            "\n",
            "         [[-0.0294]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0598]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         [[-0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.1860]],\n",
            "\n",
            "         [[-0.0718]],\n",
            "\n",
            "         [[ 0.2525]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0538]],\n",
            "\n",
            "         [[ 0.2263]],\n",
            "\n",
            "         [[ 0.1914]]],\n",
            "\n",
            "\n",
            "        [[[-0.4515]],\n",
            "\n",
            "         [[ 0.2588]],\n",
            "\n",
            "         [[ 0.0228]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0364]],\n",
            "\n",
            "         [[ 0.0959]],\n",
            "\n",
            "         [[-0.0864]]]])), ('module.encoder_q.layer1.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.0.conv2.weight', tensor([[[[-0.0503,  0.0082,  0.0151],\n",
            "          [-0.0864,  0.0201, -0.0398],\n",
            "          [-0.0194,  0.0198,  0.0288]],\n",
            "\n",
            "         [[ 0.0515,  0.0416, -0.0776],\n",
            "          [ 0.0598, -0.0157,  0.0211],\n",
            "          [-0.0337, -0.0146, -0.0351]],\n",
            "\n",
            "         [[-0.0137, -0.0381,  0.0651],\n",
            "          [ 0.0350, -0.0639,  0.0508],\n",
            "          [-0.0206,  0.0213, -0.0806]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0087,  0.0487, -0.0541],\n",
            "          [ 0.0186,  0.0020, -0.0955],\n",
            "          [-0.0774,  0.0930, -0.0208]],\n",
            "\n",
            "         [[-0.0222, -0.0623,  0.0315],\n",
            "          [ 0.0644, -0.0668, -0.0968],\n",
            "          [-0.0893, -0.0195, -0.0200]],\n",
            "\n",
            "         [[-0.0394, -0.0638,  0.0178],\n",
            "          [-0.0823, -0.0321,  0.0420],\n",
            "          [-0.0490,  0.0152,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[-0.0579,  0.0290,  0.0165],\n",
            "          [ 0.0490,  0.0363,  0.1265],\n",
            "          [ 0.0931,  0.0347,  0.0121]],\n",
            "\n",
            "         [[ 0.0273,  0.0466, -0.0225],\n",
            "          [-0.0083, -0.0497,  0.0003],\n",
            "          [-0.1060,  0.0444, -0.0250]],\n",
            "\n",
            "         [[ 0.0043, -0.0553,  0.0670],\n",
            "          [ 0.0851,  0.0343, -0.0508],\n",
            "          [-0.0814, -0.0263, -0.1125]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0116, -0.0296, -0.0278],\n",
            "          [ 0.0895, -0.0178,  0.0262],\n",
            "          [-0.0558, -0.0599,  0.0509]],\n",
            "\n",
            "         [[-0.0023, -0.0432, -0.0626],\n",
            "          [-0.0371,  0.0572,  0.0531],\n",
            "          [-0.0518, -0.0283, -0.0850]],\n",
            "\n",
            "         [[ 0.0099,  0.0266,  0.0954],\n",
            "          [ 0.0287,  0.0324, -0.0365],\n",
            "          [ 0.0725,  0.0800, -0.0616]]],\n",
            "\n",
            "\n",
            "        [[[-0.1050,  0.0031,  0.0057],\n",
            "          [ 0.0368,  0.0322, -0.0948],\n",
            "          [-0.0974, -0.0177,  0.0062]],\n",
            "\n",
            "         [[ 0.0012,  0.0179,  0.0028],\n",
            "          [-0.0045,  0.0955,  0.0806],\n",
            "          [-0.0363,  0.0656,  0.1129]],\n",
            "\n",
            "         [[ 0.0220,  0.0024, -0.1031],\n",
            "          [-0.0946,  0.0183,  0.0122],\n",
            "          [ 0.0750, -0.0300,  0.0271]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0645, -0.1163,  0.0157],\n",
            "          [ 0.1172,  0.0285, -0.0353],\n",
            "          [ 0.0278, -0.0606,  0.0098]],\n",
            "\n",
            "         [[-0.0210,  0.0239, -0.0548],\n",
            "          [-0.0453,  0.0913, -0.0608],\n",
            "          [-0.0110,  0.1067,  0.0035]],\n",
            "\n",
            "         [[-0.0636,  0.0035, -0.0306],\n",
            "          [ 0.0949,  0.0762,  0.0221],\n",
            "          [ 0.0006, -0.0208, -0.0439]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1025, -0.1338, -0.0422],\n",
            "          [-0.0293, -0.0308, -0.0128],\n",
            "          [-0.0152,  0.0761,  0.0145]],\n",
            "\n",
            "         [[ 0.0104, -0.0274,  0.0339],\n",
            "          [-0.1868, -0.0419, -0.0578],\n",
            "          [ 0.1339,  0.0050,  0.0860]],\n",
            "\n",
            "         [[ 0.0179,  0.0811, -0.1119],\n",
            "          [ 0.0541,  0.1185, -0.0222],\n",
            "          [-0.0892,  0.0222,  0.0395]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1419,  0.0914,  0.0201],\n",
            "          [-0.0113, -0.0709,  0.0150],\n",
            "          [-0.0608, -0.0171, -0.0725]],\n",
            "\n",
            "         [[-0.0247, -0.0260,  0.0348],\n",
            "          [ 0.0721, -0.0374, -0.0026],\n",
            "          [ 0.0679,  0.0066,  0.0163]],\n",
            "\n",
            "         [[ 0.0056, -0.0475, -0.0386],\n",
            "          [-0.0294, -0.0072,  0.0433],\n",
            "          [ 0.1199, -0.0136,  0.0428]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0608, -0.0322, -0.0085],\n",
            "          [-0.0598, -0.0667, -0.0329],\n",
            "          [ 0.0607, -0.0763, -0.0750]],\n",
            "\n",
            "         [[-0.0419, -0.1956,  0.0004],\n",
            "          [-0.0137,  0.1166,  0.0582],\n",
            "          [-0.0116,  0.0063, -0.0289]],\n",
            "\n",
            "         [[-0.0224,  0.0332, -0.1120],\n",
            "          [-0.1162, -0.0252,  0.0242],\n",
            "          [ 0.1963, -0.0145,  0.0184]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0264,  0.0890,  0.0523],\n",
            "          [ 0.0194, -0.0512, -0.0061],\n",
            "          [-0.0152,  0.0824, -0.0444]],\n",
            "\n",
            "         [[ 0.0468, -0.0456,  0.0277],\n",
            "          [-0.0202, -0.0626,  0.0102],\n",
            "          [-0.0094,  0.0107,  0.0494]],\n",
            "\n",
            "         [[-0.0484, -0.0689, -0.0976],\n",
            "          [ 0.0118, -0.0284,  0.0255],\n",
            "          [-0.1383, -0.0997, -0.0219]]],\n",
            "\n",
            "\n",
            "        [[[-0.0527,  0.1238,  0.0615],\n",
            "          [ 0.0659, -0.0324,  0.0751],\n",
            "          [ 0.0907, -0.1133,  0.0249]],\n",
            "\n",
            "         [[-0.0110, -0.0023, -0.0174],\n",
            "          [ 0.0196,  0.0117, -0.0020],\n",
            "          [-0.0474, -0.0106, -0.0483]],\n",
            "\n",
            "         [[ 0.0768,  0.0051,  0.0955],\n",
            "          [-0.0243,  0.0323, -0.0065],\n",
            "          [-0.0158, -0.0086, -0.0324]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0818, -0.1410, -0.0508],\n",
            "          [ 0.0659, -0.0870, -0.0003],\n",
            "          [-0.0525,  0.0063, -0.0181]],\n",
            "\n",
            "         [[-0.0286, -0.0691,  0.0024],\n",
            "          [-0.0282,  0.0489, -0.0776],\n",
            "          [ 0.0347,  0.0379, -0.0288]],\n",
            "\n",
            "         [[-0.1418, -0.0059,  0.0695],\n",
            "          [-0.0191,  0.0104, -0.1015],\n",
            "          [-0.0149, -0.0225, -0.0067]]]])), ('module.encoder_q.layer1.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.0.conv3.weight', tensor([[[[ 0.0086]],\n",
            "\n",
            "         [[ 0.1217]],\n",
            "\n",
            "         [[-0.0309]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0394]],\n",
            "\n",
            "         [[-0.0780]],\n",
            "\n",
            "         [[ 0.1036]]],\n",
            "\n",
            "\n",
            "        [[[-0.0775]],\n",
            "\n",
            "         [[-0.0274]],\n",
            "\n",
            "         [[-0.0844]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1288]],\n",
            "\n",
            "         [[-0.0166]],\n",
            "\n",
            "         [[-0.0381]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0108]],\n",
            "\n",
            "         [[-0.0093]],\n",
            "\n",
            "         [[-0.1621]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0759]],\n",
            "\n",
            "         [[ 0.0121]],\n",
            "\n",
            "         [[ 0.0193]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0542]],\n",
            "\n",
            "         [[-0.1269]],\n",
            "\n",
            "         [[ 0.0742]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         [[ 0.0302]],\n",
            "\n",
            "         [[-0.0487]]],\n",
            "\n",
            "\n",
            "        [[[-0.0417]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         [[ 0.0897]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1649]],\n",
            "\n",
            "         [[-0.1305]],\n",
            "\n",
            "         [[ 0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0028]],\n",
            "\n",
            "         [[-0.0789]],\n",
            "\n",
            "         [[ 0.0831]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0823]],\n",
            "\n",
            "         [[-0.0459]],\n",
            "\n",
            "         [[ 0.0028]]]])), ('module.encoder_q.layer1.0.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.0.downsample.0.weight', tensor([[[[ 0.0380]],\n",
            "\n",
            "         [[ 0.0571]],\n",
            "\n",
            "         [[ 0.0408]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0871]],\n",
            "\n",
            "         [[ 0.0048]],\n",
            "\n",
            "         [[ 0.1026]]],\n",
            "\n",
            "\n",
            "        [[[-0.0139]],\n",
            "\n",
            "         [[ 0.0301]],\n",
            "\n",
            "         [[ 0.0937]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0712]],\n",
            "\n",
            "         [[-0.0161]],\n",
            "\n",
            "         [[-0.0416]]],\n",
            "\n",
            "\n",
            "        [[[-0.2329]],\n",
            "\n",
            "         [[-0.1154]],\n",
            "\n",
            "         [[ 0.2080]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0241]],\n",
            "\n",
            "         [[-0.1014]],\n",
            "\n",
            "         [[-0.2189]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0531]],\n",
            "\n",
            "         [[ 0.0785]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0398]],\n",
            "\n",
            "         [[ 0.0452]],\n",
            "\n",
            "         [[ 0.0389]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1086]],\n",
            "\n",
            "         [[-0.0810]],\n",
            "\n",
            "         [[ 0.1441]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0723]],\n",
            "\n",
            "         [[ 0.0156]],\n",
            "\n",
            "         [[ 0.1300]]],\n",
            "\n",
            "\n",
            "        [[[-0.0777]],\n",
            "\n",
            "         [[-0.0059]],\n",
            "\n",
            "         [[-0.0633]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1431]],\n",
            "\n",
            "         [[ 0.1648]],\n",
            "\n",
            "         [[ 0.0437]]]])), ('module.encoder_q.layer1.0.downsample.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.0.downsample.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.downsample.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.0.downsample.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.1.conv1.weight', tensor([[[[-0.2225]],\n",
            "\n",
            "         [[-0.2296]],\n",
            "\n",
            "         [[-0.1735]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2486]],\n",
            "\n",
            "         [[-0.0756]],\n",
            "\n",
            "         [[-0.0332]]],\n",
            "\n",
            "\n",
            "        [[[-0.1860]],\n",
            "\n",
            "         [[ 0.0561]],\n",
            "\n",
            "         [[-0.0155]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         [[-0.3197]],\n",
            "\n",
            "         [[ 0.2779]]],\n",
            "\n",
            "\n",
            "        [[[-0.0550]],\n",
            "\n",
            "         [[-0.0024]],\n",
            "\n",
            "         [[ 0.2024]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[ 0.0226]],\n",
            "\n",
            "         [[ 0.1982]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0716]],\n",
            "\n",
            "         [[-0.2513]],\n",
            "\n",
            "         [[-0.1058]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.4073]],\n",
            "\n",
            "         [[-0.2568]],\n",
            "\n",
            "         [[-0.1591]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2728]],\n",
            "\n",
            "         [[ 0.1823]],\n",
            "\n",
            "         [[-0.1355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2628]],\n",
            "\n",
            "         [[ 0.1837]],\n",
            "\n",
            "         [[ 0.1337]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1592]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[ 0.0342]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2679]],\n",
            "\n",
            "         [[-0.0896]],\n",
            "\n",
            "         [[ 0.1781]]]])), ('module.encoder_q.layer1.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.1.conv2.weight', tensor([[[[-6.5673e-02,  6.5597e-02,  5.1537e-03],\n",
            "          [-6.0078e-03,  8.3128e-02, -4.9375e-02],\n",
            "          [ 9.3630e-02,  4.0858e-02, -6.1507e-02]],\n",
            "\n",
            "         [[-8.2784e-02,  4.0099e-02, -9.3083e-02],\n",
            "          [ 7.1944e-02, -3.3836e-02,  6.5259e-03],\n",
            "          [ 2.4779e-02, -5.3078e-02, -5.4378e-02]],\n",
            "\n",
            "         [[-8.3928e-03,  1.0463e-01, -8.7174e-02],\n",
            "          [ 8.0704e-02, -2.4267e-02, -6.5795e-02],\n",
            "          [ 2.9890e-02,  9.1220e-04,  1.4737e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.9785e-03, -9.4143e-02,  1.8813e-02],\n",
            "          [-2.9107e-02,  5.7558e-02, -4.6638e-02],\n",
            "          [ 3.5302e-03,  6.7818e-02, -3.9947e-02]],\n",
            "\n",
            "         [[ 5.5756e-02,  2.5369e-02,  2.5120e-02],\n",
            "          [ 2.0748e-02, -4.2986e-02, -4.8831e-02],\n",
            "          [ 3.0477e-03, -1.0818e-01, -6.0839e-02]],\n",
            "\n",
            "         [[-4.5327e-02, -2.1476e-02,  4.9856e-02],\n",
            "          [ 8.0569e-03, -4.7794e-02, -2.0113e-03],\n",
            "          [-1.7258e-01, -6.5406e-02,  7.6279e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.6070e-03, -6.2043e-02,  4.3469e-02],\n",
            "          [ 1.4060e-02,  2.3879e-02, -8.9212e-02],\n",
            "          [ 1.0773e-02,  2.0363e-02,  1.3298e-02]],\n",
            "\n",
            "         [[ 5.5590e-02, -6.2404e-02,  3.1229e-02],\n",
            "          [ 1.3064e-01,  7.4132e-02,  2.8472e-02],\n",
            "          [-9.7442e-02,  6.6070e-02,  1.2241e-02]],\n",
            "\n",
            "         [[ 2.3923e-02, -1.2311e-01, -6.8299e-02],\n",
            "          [ 6.6578e-02, -6.9903e-02, -5.5504e-02],\n",
            "          [-3.4481e-04, -1.4249e-01,  1.1030e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7050e-02, -2.7398e-03, -2.0177e-03],\n",
            "          [-4.9660e-03,  1.0688e-02,  8.2533e-02],\n",
            "          [ 1.7431e-02, -3.9503e-02,  5.7283e-02]],\n",
            "\n",
            "         [[-2.3632e-02, -1.8841e-02,  3.4771e-02],\n",
            "          [ 1.3370e-01,  3.9075e-02,  1.1259e-01],\n",
            "          [ 8.2257e-02, -5.4913e-02,  4.2678e-02]],\n",
            "\n",
            "         [[-2.8088e-02,  7.3369e-02,  3.4175e-02],\n",
            "          [ 5.2580e-02, -3.2959e-02, -7.2868e-02],\n",
            "          [ 6.9150e-02,  4.1473e-02,  2.6726e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4513e-02,  5.8604e-02, -3.7320e-02],\n",
            "          [ 6.4221e-02, -3.0385e-03, -1.7816e-01],\n",
            "          [-5.5555e-02, -3.2168e-02, -1.3486e-01]],\n",
            "\n",
            "         [[-5.4363e-02, -5.9631e-02,  6.7412e-02],\n",
            "          [-8.2694e-02,  1.1926e-01,  1.6039e-02],\n",
            "          [ 3.7751e-02, -2.3702e-02,  2.9976e-02]],\n",
            "\n",
            "         [[-5.0905e-02,  3.0562e-02,  7.1059e-02],\n",
            "          [ 6.7741e-03,  5.7531e-02, -4.1475e-02],\n",
            "          [-7.5536e-02,  2.0857e-02,  1.0407e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0639e-02, -2.6243e-02, -1.4337e-02],\n",
            "          [-5.3915e-03,  1.7152e-02,  7.5500e-02],\n",
            "          [ 3.3060e-02,  3.7353e-02,  2.1464e-02]],\n",
            "\n",
            "         [[-4.3894e-02,  8.8875e-02,  3.8173e-02],\n",
            "          [-7.3647e-02, -4.3829e-03,  1.0784e-02],\n",
            "          [-6.9969e-02, -2.2678e-03,  7.8271e-02]],\n",
            "\n",
            "         [[ 3.5074e-02, -3.1899e-02, -7.5564e-02],\n",
            "          [ 7.1015e-02, -1.1879e-01,  7.6878e-02],\n",
            "          [ 6.5666e-02, -9.8525e-03, -6.4458e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5469e-02,  5.5147e-02,  3.1574e-03],\n",
            "          [ 2.6864e-02,  4.9064e-02,  4.5578e-02],\n",
            "          [ 5.8666e-02,  4.7466e-02,  1.2792e-01]],\n",
            "\n",
            "         [[-6.9840e-03, -1.1045e-01,  7.2633e-02],\n",
            "          [-1.1106e-02,  5.8288e-02,  1.0451e-01],\n",
            "          [-6.7101e-02, -3.8129e-02,  4.4633e-02]],\n",
            "\n",
            "         [[-2.9951e-03, -3.4150e-02, -2.1943e-02],\n",
            "          [-5.4951e-02, -2.6643e-02,  4.2370e-02],\n",
            "          [-2.2774e-02,  2.4258e-02,  1.1675e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1285e-02,  1.5558e-02,  7.6102e-02],\n",
            "          [-2.6794e-02,  8.6562e-02, -1.9055e-03],\n",
            "          [-9.7718e-02,  8.7692e-02, -4.8950e-02]],\n",
            "\n",
            "         [[-8.7578e-02,  2.4455e-02,  7.8888e-02],\n",
            "          [ 2.9745e-02, -2.2924e-02, -3.9564e-03],\n",
            "          [ 5.0226e-02, -7.6325e-02, -7.0053e-02]],\n",
            "\n",
            "         [[ 4.7228e-03, -7.1214e-02, -4.4870e-02],\n",
            "          [-2.0086e-01, -8.6639e-02,  8.7553e-03],\n",
            "          [-2.8885e-02, -3.5340e-02,  2.9298e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6981e-02,  8.8044e-02, -2.7243e-02],\n",
            "          [ 3.8394e-02,  1.9731e-04, -1.7240e-02],\n",
            "          [-6.5699e-02,  4.7398e-02, -1.0411e-01]],\n",
            "\n",
            "         [[-3.0350e-02, -6.3512e-02,  2.0827e-02],\n",
            "          [-5.2706e-02,  4.0507e-04, -4.7975e-02],\n",
            "          [ 1.4005e-02, -1.8404e-02, -1.4714e-02]],\n",
            "\n",
            "         [[ 3.4095e-02, -9.7688e-03,  8.5852e-02],\n",
            "          [-1.0031e-01, -1.4331e-01, -9.0626e-03],\n",
            "          [ 1.2238e-01,  2.3100e-02, -6.8060e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.3225e-03,  1.3182e-02, -3.2347e-02],\n",
            "          [ 8.9527e-02,  3.2962e-02,  1.8867e-02],\n",
            "          [ 7.2466e-02, -7.3928e-02, -2.7953e-02]],\n",
            "\n",
            "         [[ 6.3800e-02,  1.4418e-01,  3.4040e-02],\n",
            "          [ 7.4271e-02,  8.5860e-03, -2.5841e-02],\n",
            "          [-2.3854e-02, -1.1485e-01,  2.6870e-02]],\n",
            "\n",
            "         [[ 5.9830e-02, -3.6188e-02, -3.8140e-02],\n",
            "          [ 2.8009e-02,  3.1075e-02, -3.7484e-02],\n",
            "          [ 8.4571e-03, -1.7862e-02,  3.9864e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.9828e-02, -5.4043e-02, -2.9599e-02],\n",
            "          [ 1.6376e-02,  2.0085e-03,  3.5066e-02],\n",
            "          [ 2.3815e-02, -1.0063e-01, -5.8876e-02]],\n",
            "\n",
            "         [[-6.4904e-02,  5.8849e-02,  5.6255e-02],\n",
            "          [-5.0280e-03,  6.4268e-03,  2.3374e-02],\n",
            "          [-6.1599e-02,  1.1111e-01, -1.0597e-01]],\n",
            "\n",
            "         [[-4.8450e-02, -5.7946e-02,  7.5990e-02],\n",
            "          [-1.0928e-01, -5.8135e-02,  2.8330e-02],\n",
            "          [-5.9680e-03, -8.4228e-02,  4.4362e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2177e-02,  1.1847e-03, -3.8432e-02],\n",
            "          [-2.2157e-02, -6.9662e-03, -1.6152e-01],\n",
            "          [ 1.2358e-02,  1.0428e-02,  1.6503e-02]],\n",
            "\n",
            "         [[-6.8377e-02, -1.0550e-01, -4.7228e-02],\n",
            "          [ 2.9491e-02, -2.9811e-02,  1.3245e-02],\n",
            "          [ 9.6639e-02,  3.0286e-02,  8.3568e-02]],\n",
            "\n",
            "         [[-1.8480e-01, -2.0892e-02,  1.9227e-02],\n",
            "          [ 3.7227e-02,  4.6209e-02, -1.2227e-01],\n",
            "          [-1.2171e-01, -7.8799e-02,  5.2849e-02]]]])), ('module.encoder_q.layer1.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.1.conv3.weight', tensor([[[[ 0.0277]],\n",
            "\n",
            "         [[ 0.0183]],\n",
            "\n",
            "         [[-0.0957]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1118]],\n",
            "\n",
            "         [[ 0.0809]],\n",
            "\n",
            "         [[-0.0681]]],\n",
            "\n",
            "\n",
            "        [[[-0.1046]],\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[-0.0474]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0763]],\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[ 0.0323]]],\n",
            "\n",
            "\n",
            "        [[[-0.0742]],\n",
            "\n",
            "         [[ 0.0631]],\n",
            "\n",
            "         [[-0.0554]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0305]],\n",
            "\n",
            "         [[-0.0777]],\n",
            "\n",
            "         [[-0.0941]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0636]],\n",
            "\n",
            "         [[-0.0241]],\n",
            "\n",
            "         [[-0.2409]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0855]],\n",
            "\n",
            "         [[ 0.0521]],\n",
            "\n",
            "         [[ 0.0948]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1568]],\n",
            "\n",
            "         [[ 0.0065]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1434]],\n",
            "\n",
            "         [[-0.0642]],\n",
            "\n",
            "         [[ 0.0926]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0520]],\n",
            "\n",
            "         [[-0.1135]],\n",
            "\n",
            "         [[-0.0087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0121]],\n",
            "\n",
            "         [[-0.0872]],\n",
            "\n",
            "         [[ 0.0980]]]])), ('module.encoder_q.layer1.1.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.1.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.2.conv1.weight', tensor([[[[-0.1526]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         [[ 0.1592]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0120]],\n",
            "\n",
            "         [[ 0.3159]],\n",
            "\n",
            "         [[-0.0656]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1162]],\n",
            "\n",
            "         [[-0.1572]],\n",
            "\n",
            "         [[-0.1217]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2382]],\n",
            "\n",
            "         [[ 0.1467]],\n",
            "\n",
            "         [[-0.1869]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0670]],\n",
            "\n",
            "         [[ 0.2555]],\n",
            "\n",
            "         [[ 0.1076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0891]],\n",
            "\n",
            "         [[-0.0641]],\n",
            "\n",
            "         [[-0.0242]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0284]],\n",
            "\n",
            "         [[ 0.0487]],\n",
            "\n",
            "         [[-0.3654]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1371]],\n",
            "\n",
            "         [[ 0.2403]],\n",
            "\n",
            "         [[-0.0616]]],\n",
            "\n",
            "\n",
            "        [[[-0.0829]],\n",
            "\n",
            "         [[ 0.1793]],\n",
            "\n",
            "         [[-0.0796]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0634]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[-0.1871]]],\n",
            "\n",
            "\n",
            "        [[[-0.3399]],\n",
            "\n",
            "         [[-0.0732]],\n",
            "\n",
            "         [[ 0.1289]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2831]],\n",
            "\n",
            "         [[ 0.1750]],\n",
            "\n",
            "         [[ 0.0203]]]])), ('module.encoder_q.layer1.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.2.conv2.weight', tensor([[[[-6.0778e-03,  2.1031e-02,  2.5290e-02],\n",
            "          [-5.1883e-02,  9.1967e-03,  2.5988e-02],\n",
            "          [ 3.9177e-03,  3.2230e-02,  7.0825e-02]],\n",
            "\n",
            "         [[ 3.9418e-02,  6.9763e-02,  1.1778e-01],\n",
            "          [ 1.4276e-02,  7.8560e-02,  2.9490e-02],\n",
            "          [-6.5573e-02,  9.8496e-03, -2.1543e-02]],\n",
            "\n",
            "         [[-2.8932e-02, -9.0720e-02,  2.9278e-02],\n",
            "          [ 2.3240e-02, -1.1038e-02, -1.0610e-02],\n",
            "          [-3.4702e-02,  6.9394e-02,  9.1250e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.0101e-02, -4.4052e-03,  1.9697e-02],\n",
            "          [-1.5685e-02, -4.5189e-02,  3.0481e-02],\n",
            "          [ 3.6819e-03, -6.3322e-02,  3.5783e-05]],\n",
            "\n",
            "         [[-1.6072e-02,  9.6707e-02, -3.9388e-02],\n",
            "          [-7.8277e-02,  3.8245e-02, -4.2239e-02],\n",
            "          [-2.4985e-02,  1.0249e-01, -5.5338e-02]],\n",
            "\n",
            "         [[-1.9227e-02, -5.4404e-02, -8.4714e-02],\n",
            "          [-5.9622e-02,  4.2524e-02,  1.0980e-01],\n",
            "          [ 3.3176e-02,  1.4340e-02,  7.2818e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4554e-02,  1.9929e-02, -7.8697e-02],\n",
            "          [ 9.6134e-03, -8.3944e-02,  7.2779e-02],\n",
            "          [ 5.7358e-02, -9.0376e-02, -5.0937e-03]],\n",
            "\n",
            "         [[-1.2439e-02, -8.4718e-02, -6.4281e-05],\n",
            "          [-1.1148e-01, -5.6460e-02, -2.6405e-02],\n",
            "          [-1.5739e-02, -2.4567e-04, -8.8720e-02]],\n",
            "\n",
            "         [[-1.7407e-02, -1.1308e-02,  4.6703e-02],\n",
            "          [-7.2237e-02, -5.2607e-02,  6.3663e-02],\n",
            "          [ 6.4852e-02, -7.3712e-02,  5.3530e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.1049e-02,  7.3583e-03, -8.8328e-02],\n",
            "          [-5.1333e-02, -4.4481e-02,  4.9971e-02],\n",
            "          [-1.7573e-02, -2.5875e-02,  1.6520e-02]],\n",
            "\n",
            "         [[-6.9118e-02, -2.9721e-02, -3.7937e-02],\n",
            "          [-6.0912e-02, -2.5121e-02,  2.4538e-02],\n",
            "          [-5.7496e-02,  7.1583e-02, -3.6002e-02]],\n",
            "\n",
            "         [[-3.5448e-03,  8.4357e-02,  1.7223e-02],\n",
            "          [-8.0595e-02, -8.6246e-03,  3.2503e-02],\n",
            "          [-8.5198e-02,  4.1421e-02, -5.5877e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6130e-02,  2.0584e-02, -3.2139e-02],\n",
            "          [-1.0153e-01,  2.5168e-02,  4.0848e-02],\n",
            "          [-1.0837e-01,  1.0187e-01,  9.4544e-03]],\n",
            "\n",
            "         [[-2.2456e-02,  5.9296e-02,  1.8459e-02],\n",
            "          [ 1.0181e-02, -8.8629e-02,  6.7996e-02],\n",
            "          [ 1.0445e-01,  5.9389e-02,  7.8330e-04]],\n",
            "\n",
            "         [[-5.3213e-02, -9.7417e-02,  1.8210e-02],\n",
            "          [ 1.0116e-01,  6.0832e-02,  8.5433e-02],\n",
            "          [ 4.8347e-02, -6.5057e-03,  6.1583e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7600e-02,  4.8636e-02,  1.3369e-02],\n",
            "          [-5.2037e-03, -6.1425e-03, -1.7332e-01],\n",
            "          [ 4.6918e-02,  7.0206e-02,  6.1246e-02]],\n",
            "\n",
            "         [[-4.7921e-02,  2.8547e-02, -2.2433e-02],\n",
            "          [ 1.1644e-01, -1.1179e-01,  4.2170e-02],\n",
            "          [ 4.6279e-02, -5.5693e-03,  4.0620e-02]],\n",
            "\n",
            "         [[-4.3897e-03, -1.9469e-03, -2.9500e-03],\n",
            "          [-3.9732e-02,  6.5351e-02,  2.3392e-02],\n",
            "          [-6.3447e-02, -9.5497e-03,  9.9367e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.3290e-02,  4.3588e-02, -6.4836e-02],\n",
            "          [ 2.7611e-02,  1.4736e-02, -4.6644e-02],\n",
            "          [ 1.2004e-03,  7.7106e-02, -6.9098e-03]],\n",
            "\n",
            "         [[-4.6347e-02, -3.4102e-02, -5.4033e-02],\n",
            "          [-1.8556e-02,  1.9300e-01, -1.0496e-01],\n",
            "          [-3.4021e-02, -2.7948e-02,  2.0478e-02]],\n",
            "\n",
            "         [[ 7.8592e-02,  3.8000e-03, -5.4964e-02],\n",
            "          [-7.5379e-02, -7.1115e-03, -8.3431e-02],\n",
            "          [-8.7539e-03,  7.9315e-02, -1.0940e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.7544e-02, -6.7479e-02, -2.9374e-02],\n",
            "          [-3.9698e-02, -1.2420e-02, -1.6550e-01],\n",
            "          [ 3.3778e-03, -5.8733e-02, -7.9985e-02]],\n",
            "\n",
            "         [[-2.9937e-02, -2.4995e-02,  2.9781e-02],\n",
            "          [ 2.1947e-02,  6.3806e-02, -5.7573e-02],\n",
            "          [-5.3851e-02,  5.7907e-02, -6.4272e-02]],\n",
            "\n",
            "         [[ 8.5677e-02,  5.1765e-02, -8.0795e-02],\n",
            "          [-1.6212e-02,  4.7519e-02,  4.3720e-02],\n",
            "          [ 2.7326e-03, -1.3319e-02,  4.2344e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.9530e-02,  3.7925e-02, -9.9350e-03],\n",
            "          [ 6.4543e-02,  4.9591e-02,  6.1224e-02],\n",
            "          [ 4.4094e-02, -6.5532e-03, -7.1924e-02]],\n",
            "\n",
            "         [[ 5.3679e-02, -5.8549e-02, -4.0666e-02],\n",
            "          [-7.7944e-02,  2.2262e-02,  1.1973e-02],\n",
            "          [ 1.0957e-02,  3.6152e-02,  2.0136e-02]],\n",
            "\n",
            "         [[ 7.0934e-02,  8.0707e-02, -1.0715e-01],\n",
            "          [ 1.2147e-01, -3.7879e-02,  7.5630e-03],\n",
            "          [ 7.4727e-02, -1.1200e-01,  4.2435e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2437e-02,  4.4417e-02, -1.8937e-01],\n",
            "          [ 2.1761e-02,  8.8527e-03,  5.9626e-03],\n",
            "          [ 4.8839e-02, -2.0821e-02, -6.5295e-02]],\n",
            "\n",
            "         [[ 1.0098e-01,  2.3350e-02,  3.1670e-02],\n",
            "          [ 1.1844e-01, -5.7054e-02,  4.0257e-02],\n",
            "          [ 7.8167e-03,  9.1751e-02,  3.0461e-02]],\n",
            "\n",
            "         [[ 2.7224e-02,  6.5090e-02, -3.0683e-02],\n",
            "          [-6.4743e-02,  1.8940e-02,  4.5373e-02],\n",
            "          [-8.8446e-03, -1.8280e-02,  9.8689e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4499e-02,  6.3660e-02,  2.3537e-02],\n",
            "          [ 4.3741e-03, -6.5495e-02, -2.3966e-02],\n",
            "          [-1.2779e-02,  2.9163e-02, -6.8777e-02]],\n",
            "\n",
            "         [[-2.7703e-02,  8.8968e-02, -9.8178e-02],\n",
            "          [-6.2503e-03,  4.5962e-02, -5.9999e-02],\n",
            "          [ 3.1836e-02,  7.9025e-02,  5.9087e-03]],\n",
            "\n",
            "         [[ 3.0821e-03,  4.4218e-02, -1.7628e-02],\n",
            "          [-3.0777e-03, -5.7251e-02, -1.1024e-02],\n",
            "          [-9.4324e-03, -1.5370e-03,  1.9066e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.8486e-02, -4.7505e-02, -1.2007e-01],\n",
            "          [ 2.8841e-02, -2.6374e-02,  5.5415e-02],\n",
            "          [-6.8415e-02, -8.7069e-02,  2.9346e-03]],\n",
            "\n",
            "         [[ 7.2117e-04,  4.3525e-02,  1.8491e-02],\n",
            "          [ 1.0621e-01,  1.4593e-02,  1.4970e-02],\n",
            "          [ 8.6689e-03, -1.0337e-01,  5.6997e-02]],\n",
            "\n",
            "         [[-5.6581e-02, -2.2049e-02, -7.6268e-02],\n",
            "          [ 5.3347e-03,  2.3434e-02,  3.2561e-03],\n",
            "          [ 1.7297e-02,  4.4042e-02, -3.6694e-02]]]])), ('module.encoder_q.layer1.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer1.2.conv3.weight', tensor([[[[-0.0433]],\n",
            "\n",
            "         [[ 0.0604]],\n",
            "\n",
            "         [[ 0.0423]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         [[ 0.1426]],\n",
            "\n",
            "         [[ 0.1472]]],\n",
            "\n",
            "\n",
            "        [[[-0.0353]],\n",
            "\n",
            "         [[ 0.0615]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0833]],\n",
            "\n",
            "         [[ 0.0340]],\n",
            "\n",
            "         [[-0.0431]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315]],\n",
            "\n",
            "         [[-0.1730]],\n",
            "\n",
            "         [[ 0.0494]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1409]],\n",
            "\n",
            "         [[ 0.0236]],\n",
            "\n",
            "         [[-0.1658]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0690]],\n",
            "\n",
            "         [[-0.0737]],\n",
            "\n",
            "         [[-0.0288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0120]],\n",
            "\n",
            "         [[ 0.0804]],\n",
            "\n",
            "         [[ 0.0157]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0792]],\n",
            "\n",
            "         [[-0.1062]],\n",
            "\n",
            "         [[-0.1223]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0941]],\n",
            "\n",
            "         [[-0.0180]],\n",
            "\n",
            "         [[ 0.0022]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0565]],\n",
            "\n",
            "         [[ 0.1556]],\n",
            "\n",
            "         [[ 0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0662]],\n",
            "\n",
            "         [[-0.0322]],\n",
            "\n",
            "         [[-0.0803]]]])), ('module.encoder_q.layer1.2.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer1.2.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer1.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.0.conv1.weight', tensor([[[[ 0.0335]],\n",
            "\n",
            "         [[ 0.0788]],\n",
            "\n",
            "         [[ 0.0653]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1057]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[-0.0691]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2211]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         [[ 0.1696]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0826]],\n",
            "\n",
            "         [[ 0.0656]],\n",
            "\n",
            "         [[-0.1677]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2016]],\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.1313]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0590]],\n",
            "\n",
            "         [[ 0.2383]],\n",
            "\n",
            "         [[-0.1460]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0083]],\n",
            "\n",
            "         [[-0.0768]],\n",
            "\n",
            "         [[-0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0340]],\n",
            "\n",
            "         [[-0.0193]],\n",
            "\n",
            "         [[ 0.0039]]],\n",
            "\n",
            "\n",
            "        [[[-0.0493]],\n",
            "\n",
            "         [[ 0.0630]],\n",
            "\n",
            "         [[ 0.1726]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0117]],\n",
            "\n",
            "         [[-0.2906]],\n",
            "\n",
            "         [[ 0.0218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2447]],\n",
            "\n",
            "         [[ 0.1345]],\n",
            "\n",
            "         [[ 0.3536]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1933]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         [[-0.1509]]]])), ('module.encoder_q.layer2.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.0.conv2.weight', tensor([[[[ 9.5564e-02,  7.4802e-03,  6.7313e-02],\n",
            "          [-3.0044e-02, -1.5301e-02,  1.1513e-02],\n",
            "          [-1.0669e-02,  7.7900e-03, -1.1240e-02]],\n",
            "\n",
            "         [[ 3.5639e-02,  2.9068e-02,  2.7528e-02],\n",
            "          [ 5.7293e-02, -9.8795e-03,  2.0632e-02],\n",
            "          [-1.6313e-02, -8.3863e-02, -4.4737e-02]],\n",
            "\n",
            "         [[ 4.4271e-02,  1.8065e-02,  2.0374e-02],\n",
            "          [ 1.5781e-02,  4.0068e-03,  5.6635e-03],\n",
            "          [-1.8553e-02, -1.7232e-03, -2.7541e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1890e-02, -1.3627e-02, -5.1101e-02],\n",
            "          [ 2.0286e-03,  2.2264e-02,  1.8767e-05],\n",
            "          [ 8.1193e-03,  2.7130e-02, -4.5714e-02]],\n",
            "\n",
            "         [[ 3.7817e-02,  2.7810e-02, -4.9336e-02],\n",
            "          [-7.6076e-03,  6.6028e-03, -1.4366e-02],\n",
            "          [ 7.7824e-03, -4.4112e-02,  5.2326e-02]],\n",
            "\n",
            "         [[ 4.4187e-02, -9.5055e-03, -5.1266e-03],\n",
            "          [-9.1394e-03, -7.4296e-02, -7.4889e-02],\n",
            "          [ 1.6104e-02,  2.1934e-02, -6.0913e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2608e-02,  4.1064e-02, -3.2276e-02],\n",
            "          [ 4.2542e-02,  1.2734e-02,  5.3378e-02],\n",
            "          [ 7.7442e-03, -4.9562e-02,  3.4951e-02]],\n",
            "\n",
            "         [[-1.7049e-04, -9.5120e-04,  3.8512e-02],\n",
            "          [-1.2933e-02, -2.6473e-02,  5.1219e-02],\n",
            "          [-2.3943e-02,  1.0201e-01, -1.5647e-03]],\n",
            "\n",
            "         [[-1.0711e-01, -1.0715e-02, -2.5244e-02],\n",
            "          [ 1.2424e-02, -7.6289e-02,  6.4690e-03],\n",
            "          [-5.2877e-02,  5.6392e-03,  4.1979e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2500e-02,  1.2385e-02, -2.8566e-02],\n",
            "          [ 5.1617e-04,  3.4973e-02,  2.9874e-02],\n",
            "          [ 5.0883e-03, -2.7488e-02, -1.8361e-02]],\n",
            "\n",
            "         [[ 1.0285e-02,  1.9435e-02,  2.6590e-02],\n",
            "          [-3.2130e-02, -7.1974e-03, -9.5913e-03],\n",
            "          [ 3.7731e-03,  1.4688e-03,  3.9087e-04]],\n",
            "\n",
            "         [[ 3.4970e-02,  1.7187e-02,  5.6129e-02],\n",
            "          [ 1.5058e-02, -2.8139e-03,  2.1764e-02],\n",
            "          [ 1.5986e-02,  2.7617e-02, -6.4071e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2208e-03, -1.1835e-02, -9.4561e-02],\n",
            "          [-7.2751e-03,  7.4011e-02,  6.3089e-02],\n",
            "          [ 1.7558e-02,  8.8767e-02, -3.3039e-02]],\n",
            "\n",
            "         [[-1.0553e-02, -3.5139e-03,  4.1840e-03],\n",
            "          [ 6.4999e-02,  9.1774e-02,  1.5115e-02],\n",
            "          [-2.3631e-02, -3.5679e-02,  2.5063e-02]],\n",
            "\n",
            "         [[ 3.8487e-02,  4.2044e-02,  2.5408e-02],\n",
            "          [ 9.7594e-03,  4.6497e-02, -3.3497e-02],\n",
            "          [-5.2825e-02,  1.7522e-02, -1.8611e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.6521e-02, -3.4359e-02, -1.3447e-02],\n",
            "          [ 1.0213e-01, -1.6399e-03,  1.6602e-02],\n",
            "          [ 2.6341e-02, -1.1826e-02, -6.2982e-04]],\n",
            "\n",
            "         [[-6.4889e-03, -5.0561e-02, -1.0876e-01],\n",
            "          [ 7.4923e-02, -2.6142e-02,  1.0679e-01],\n",
            "          [ 3.4326e-02,  8.0179e-02,  4.8701e-02]],\n",
            "\n",
            "         [[ 3.2389e-02,  3.1953e-02, -5.8567e-02],\n",
            "          [ 5.5803e-02,  8.4076e-03,  1.8383e-02],\n",
            "          [ 3.3115e-02,  2.6133e-03, -1.4742e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.9049e-02, -1.9286e-04,  7.1004e-03],\n",
            "          [ 4.3563e-02, -5.9369e-02, -2.6085e-02],\n",
            "          [ 4.7260e-02, -2.8975e-02, -6.3615e-02]],\n",
            "\n",
            "         [[ 8.8889e-03,  1.2512e-03,  2.1641e-02],\n",
            "          [ 1.9218e-02,  4.8266e-02,  3.0982e-02],\n",
            "          [ 2.3080e-02,  8.0840e-03, -3.3561e-02]],\n",
            "\n",
            "         [[-5.8409e-02, -3.1792e-03,  2.0712e-02],\n",
            "          [-1.2524e-02, -1.5699e-02, -6.1308e-03],\n",
            "          [ 6.1127e-02,  2.8549e-02,  9.1019e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7961e-03,  2.0993e-02,  8.4987e-02],\n",
            "          [-2.7398e-02, -8.0587e-02, -1.8647e-02],\n",
            "          [ 5.0908e-02,  1.6297e-02, -4.1915e-03]],\n",
            "\n",
            "         [[-1.7441e-02,  5.2442e-02, -4.4641e-02],\n",
            "          [-2.3515e-02,  2.8372e-02, -7.5687e-02],\n",
            "          [ 4.0277e-02,  5.4168e-02, -3.7372e-02]],\n",
            "\n",
            "         [[ 1.9991e-02,  6.0403e-03,  2.6457e-02],\n",
            "          [ 2.8366e-02,  7.2770e-02,  7.4291e-02],\n",
            "          [-6.9783e-02,  3.4633e-02, -4.6988e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9415e-02, -6.0324e-03, -6.8092e-02],\n",
            "          [-1.3770e-02,  7.1382e-02,  2.4164e-02],\n",
            "          [ 1.4306e-02,  3.7954e-03, -2.7367e-02]],\n",
            "\n",
            "         [[-4.1882e-02,  6.7325e-02,  7.6916e-02],\n",
            "          [ 1.1186e-01,  4.1740e-02, -2.7499e-02],\n",
            "          [-4.8076e-02, -1.9526e-02, -1.8575e-02]],\n",
            "\n",
            "         [[-1.1417e-02, -1.6355e-02,  3.0151e-02],\n",
            "          [ 6.0729e-02,  2.0041e-02, -1.2763e-02],\n",
            "          [ 2.1167e-02, -1.7334e-02,  1.9317e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.0206e-02, -1.0961e-01, -5.2340e-02],\n",
            "          [-1.8403e-02,  8.3577e-02,  2.0537e-02],\n",
            "          [ 9.0196e-02,  1.1627e-02,  1.4996e-02]],\n",
            "\n",
            "         [[ 3.4345e-02, -7.8837e-02,  1.7752e-02],\n",
            "          [-4.4236e-02,  3.0105e-02,  6.1128e-02],\n",
            "          [ 9.6327e-02,  5.0425e-02,  4.9496e-03]],\n",
            "\n",
            "         [[ 3.4890e-02,  4.9269e-02,  1.3378e-02],\n",
            "          [-5.0193e-02,  1.7138e-03,  1.8194e-02],\n",
            "          [ 2.0615e-03,  5.7121e-02, -4.5547e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.0124e-01,  3.5744e-02,  3.5384e-02],\n",
            "          [-1.7518e-02, -2.2879e-02,  7.3905e-02],\n",
            "          [-5.2962e-02, -1.2880e-02, -3.7926e-02]],\n",
            "\n",
            "         [[ 3.8139e-02,  1.6738e-02,  3.1361e-02],\n",
            "          [-5.8242e-03, -3.7098e-02, -6.8245e-03],\n",
            "          [ 3.0275e-02, -5.3301e-02, -5.8391e-03]],\n",
            "\n",
            "         [[ 4.0760e-02, -3.9798e-02,  6.0473e-02],\n",
            "          [ 6.9290e-02, -5.0383e-02,  2.5765e-02],\n",
            "          [ 3.5284e-02, -1.3286e-02,  3.2636e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3105e-03, -2.3914e-02,  6.7505e-02],\n",
            "          [ 1.2013e-02, -2.1723e-02,  3.6502e-02],\n",
            "          [-1.2688e-02,  7.5403e-03, -6.0569e-02]],\n",
            "\n",
            "         [[-1.9598e-04,  1.5440e-02, -5.5732e-02],\n",
            "          [-1.9595e-02, -2.8402e-02,  3.6859e-02],\n",
            "          [ 2.7925e-02, -3.8986e-02, -6.6399e-02]],\n",
            "\n",
            "         [[ 4.7966e-02, -5.1521e-05,  3.1309e-02],\n",
            "          [ 4.6506e-02, -3.3850e-02,  4.2715e-02],\n",
            "          [ 6.1498e-02,  5.5042e-02, -5.9903e-02]]]])), ('module.encoder_q.layer2.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.0.conv3.weight', tensor([[[[ 0.0392]],\n",
            "\n",
            "         [[ 0.0557]],\n",
            "\n",
            "         [[ 0.0739]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2723]],\n",
            "\n",
            "         [[-0.0327]],\n",
            "\n",
            "         [[-0.0063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0261]],\n",
            "\n",
            "         [[-0.0548]],\n",
            "\n",
            "         [[-0.0799]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0633]],\n",
            "\n",
            "         [[-0.0845]],\n",
            "\n",
            "         [[-0.0055]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0203]],\n",
            "\n",
            "         [[ 0.0198]],\n",
            "\n",
            "         [[-0.0436]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1107]],\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.1057]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0040]],\n",
            "\n",
            "         [[ 0.0428]],\n",
            "\n",
            "         [[-0.0767]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0691]],\n",
            "\n",
            "         [[-0.0083]],\n",
            "\n",
            "         [[-0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0685]],\n",
            "\n",
            "         [[-0.1017]],\n",
            "\n",
            "         [[ 0.0291]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0607]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         [[ 0.0878]]],\n",
            "\n",
            "\n",
            "        [[[-0.0722]],\n",
            "\n",
            "         [[ 0.0875]],\n",
            "\n",
            "         [[ 0.0860]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0552]],\n",
            "\n",
            "         [[ 0.0235]],\n",
            "\n",
            "         [[-0.0231]]]])), ('module.encoder_q.layer2.0.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.0.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.0.downsample.0.weight', tensor([[[[-0.0634]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         [[ 0.1495]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0341]],\n",
            "\n",
            "         [[ 0.0252]],\n",
            "\n",
            "         [[-0.0214]]],\n",
            "\n",
            "\n",
            "        [[[-0.0924]],\n",
            "\n",
            "         [[ 0.0035]],\n",
            "\n",
            "         [[-0.0706]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0218]],\n",
            "\n",
            "         [[ 0.0111]],\n",
            "\n",
            "         [[-0.0233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0484]],\n",
            "\n",
            "         [[ 0.0520]],\n",
            "\n",
            "         [[ 0.0971]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0257]],\n",
            "\n",
            "         [[ 0.0249]],\n",
            "\n",
            "         [[-0.1163]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0049]],\n",
            "\n",
            "         [[ 0.0545]],\n",
            "\n",
            "         [[-0.0500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0796]],\n",
            "\n",
            "         [[ 0.0463]],\n",
            "\n",
            "         [[-0.0497]]],\n",
            "\n",
            "\n",
            "        [[[-0.0442]],\n",
            "\n",
            "         [[ 0.0846]],\n",
            "\n",
            "         [[ 0.1007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[-0.0272]],\n",
            "\n",
            "         [[ 0.0153]]],\n",
            "\n",
            "\n",
            "        [[[-0.1229]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0772]],\n",
            "\n",
            "         [[-0.1290]],\n",
            "\n",
            "         [[ 0.0257]]]])), ('module.encoder_q.layer2.0.downsample.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.0.downsample.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.downsample.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.0.downsample.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.1.conv1.weight', tensor([[[[ 0.0926]],\n",
            "\n",
            "         [[-0.0228]],\n",
            "\n",
            "         [[-0.2365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1820]],\n",
            "\n",
            "         [[ 0.1204]],\n",
            "\n",
            "         [[-0.0330]]],\n",
            "\n",
            "\n",
            "        [[[-0.0729]],\n",
            "\n",
            "         [[ 0.1143]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0717]],\n",
            "\n",
            "         [[ 0.1223]],\n",
            "\n",
            "         [[ 0.0861]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0740]],\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0721]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0764]],\n",
            "\n",
            "         [[-0.0872]],\n",
            "\n",
            "         [[-0.0515]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0044]],\n",
            "\n",
            "         [[-0.1122]],\n",
            "\n",
            "         [[ 0.1625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[-0.0420]],\n",
            "\n",
            "         [[-0.1038]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[-0.0912]],\n",
            "\n",
            "         [[ 0.1461]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         [[-0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0135]],\n",
            "\n",
            "         [[ 0.0570]],\n",
            "\n",
            "         [[ 0.0341]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0164]],\n",
            "\n",
            "         [[ 0.0017]],\n",
            "\n",
            "         [[ 0.0894]]]])), ('module.encoder_q.layer2.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.1.conv2.weight', tensor([[[[ 0.0605, -0.0221,  0.0493],\n",
            "          [ 0.0430,  0.0210, -0.0888],\n",
            "          [ 0.0691,  0.1352, -0.0750]],\n",
            "\n",
            "         [[-0.0194,  0.0388,  0.0074],\n",
            "          [ 0.0081, -0.0321,  0.0505],\n",
            "          [ 0.0345, -0.0367,  0.0024]],\n",
            "\n",
            "         [[-0.0347,  0.0069,  0.0237],\n",
            "          [ 0.0146, -0.0034,  0.0035],\n",
            "          [ 0.0026,  0.0506, -0.0235]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0208,  0.0627,  0.0128],\n",
            "          [-0.0596, -0.0180,  0.0352],\n",
            "          [ 0.0771,  0.0187,  0.0314]],\n",
            "\n",
            "         [[-0.0243,  0.0847, -0.0102],\n",
            "          [ 0.0136,  0.0416,  0.0080],\n",
            "          [-0.0395,  0.0238,  0.0154]],\n",
            "\n",
            "         [[ 0.0877,  0.0118,  0.0320],\n",
            "          [ 0.0359, -0.0305,  0.0360],\n",
            "          [-0.0262,  0.0336,  0.0391]]],\n",
            "\n",
            "\n",
            "        [[[-0.0273,  0.0717, -0.0551],\n",
            "          [-0.0415, -0.0250, -0.0744],\n",
            "          [-0.0089, -0.0122, -0.0054]],\n",
            "\n",
            "         [[-0.0137, -0.0302,  0.0637],\n",
            "          [ 0.0687,  0.0456, -0.0472],\n",
            "          [-0.0964, -0.0372,  0.0214]],\n",
            "\n",
            "         [[ 0.0042,  0.0280, -0.0206],\n",
            "          [ 0.0138,  0.0227, -0.0590],\n",
            "          [ 0.0506, -0.0112, -0.0128]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0236,  0.0151, -0.0401],\n",
            "          [-0.0677, -0.0117, -0.0193],\n",
            "          [ 0.0034, -0.0228, -0.0306]],\n",
            "\n",
            "         [[-0.0173,  0.0231,  0.0418],\n",
            "          [ 0.0226, -0.0199, -0.0228],\n",
            "          [ 0.0773, -0.1227, -0.0147]],\n",
            "\n",
            "         [[-0.0737, -0.0305, -0.0120],\n",
            "          [ 0.0064, -0.0600, -0.0155],\n",
            "          [-0.0060,  0.0035,  0.0031]]],\n",
            "\n",
            "\n",
            "        [[[-0.0206, -0.0342, -0.0228],\n",
            "          [-0.0318, -0.0736,  0.0076],\n",
            "          [-0.0182, -0.0178,  0.0931]],\n",
            "\n",
            "         [[-0.0305, -0.0263,  0.0389],\n",
            "          [ 0.0376, -0.0330, -0.0054],\n",
            "          [ 0.0701, -0.0252, -0.0254]],\n",
            "\n",
            "         [[ 0.0363, -0.0257,  0.0052],\n",
            "          [-0.0229,  0.0177, -0.0502],\n",
            "          [-0.0205, -0.0332,  0.0573]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168, -0.0095,  0.0150],\n",
            "          [-0.0227,  0.0057,  0.0603],\n",
            "          [-0.0458,  0.0450, -0.0382]],\n",
            "\n",
            "         [[-0.0137,  0.0209, -0.0698],\n",
            "          [ 0.0308,  0.0515, -0.0535],\n",
            "          [-0.0064,  0.0711,  0.0512]],\n",
            "\n",
            "         [[-0.0007,  0.0081, -0.0236],\n",
            "          [ 0.0362, -0.0455, -0.0123],\n",
            "          [ 0.1983, -0.0110,  0.0077]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0373,  0.0840,  0.0479],\n",
            "          [ 0.0394,  0.0844, -0.0636],\n",
            "          [-0.0830,  0.0423,  0.0227]],\n",
            "\n",
            "         [[-0.0226, -0.0209, -0.0335],\n",
            "          [-0.0501, -0.0605, -0.0595],\n",
            "          [ 0.0196,  0.0336, -0.0248]],\n",
            "\n",
            "         [[ 0.0394, -0.0675, -0.0319],\n",
            "          [-0.0551, -0.0101,  0.0052],\n",
            "          [-0.0075, -0.0035, -0.0240]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0017, -0.0399, -0.0223],\n",
            "          [-0.0839,  0.0908,  0.0245],\n",
            "          [ 0.0590, -0.0581,  0.0532]],\n",
            "\n",
            "         [[ 0.0266, -0.0241, -0.0070],\n",
            "          [-0.0298,  0.0043, -0.0791],\n",
            "          [-0.0161, -0.0036,  0.0418]],\n",
            "\n",
            "         [[-0.0231,  0.0510,  0.0889],\n",
            "          [-0.0795, -0.0165, -0.0217],\n",
            "          [ 0.0311,  0.0143, -0.0167]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0523,  0.0327, -0.0152],\n",
            "          [ 0.0339,  0.0518,  0.0175],\n",
            "          [-0.0447,  0.0073, -0.0508]],\n",
            "\n",
            "         [[-0.0112, -0.0210,  0.0064],\n",
            "          [-0.0236,  0.0236,  0.0024],\n",
            "          [-0.0025, -0.0117,  0.0310]],\n",
            "\n",
            "         [[ 0.0025, -0.0809, -0.0177],\n",
            "          [-0.0382,  0.0278, -0.0614],\n",
            "          [ 0.0110,  0.0540, -0.0103]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0041, -0.0212, -0.0609],\n",
            "          [-0.0502,  0.0309, -0.0925],\n",
            "          [ 0.0149, -0.1268,  0.0253]],\n",
            "\n",
            "         [[ 0.0020, -0.0173,  0.0035],\n",
            "          [-0.0459, -0.0693, -0.0476],\n",
            "          [-0.0444,  0.0187,  0.0373]],\n",
            "\n",
            "         [[-0.0434, -0.0307,  0.0406],\n",
            "          [-0.0169, -0.0245,  0.0410],\n",
            "          [-0.0281,  0.0011, -0.0632]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0013, -0.0097,  0.0696],\n",
            "          [ 0.0381, -0.0180,  0.0155],\n",
            "          [ 0.0637, -0.0496,  0.0377]],\n",
            "\n",
            "         [[ 0.0663, -0.0438,  0.0324],\n",
            "          [ 0.0165, -0.0185, -0.0194],\n",
            "          [-0.0364,  0.0202,  0.0805]],\n",
            "\n",
            "         [[ 0.0216,  0.0192, -0.0202],\n",
            "          [ 0.1161,  0.0192, -0.0294],\n",
            "          [ 0.0287, -0.0170, -0.0026]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0194, -0.0406,  0.0145],\n",
            "          [ 0.0105, -0.0202, -0.0229],\n",
            "          [ 0.0237, -0.0048, -0.0188]],\n",
            "\n",
            "         [[-0.0350,  0.0564,  0.0321],\n",
            "          [ 0.0348, -0.0583,  0.0178],\n",
            "          [-0.0045,  0.0256, -0.0667]],\n",
            "\n",
            "         [[ 0.0178,  0.0496, -0.0991],\n",
            "          [-0.0374,  0.0535,  0.1022],\n",
            "          [-0.0446, -0.0028,  0.0672]]]])), ('module.encoder_q.layer2.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.1.conv3.weight', tensor([[[[-0.0307]],\n",
            "\n",
            "         [[ 0.0356]],\n",
            "\n",
            "         [[ 0.0464]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0450]],\n",
            "\n",
            "         [[-0.0658]],\n",
            "\n",
            "         [[ 0.1105]]],\n",
            "\n",
            "\n",
            "        [[[-0.0297]],\n",
            "\n",
            "         [[ 0.0140]],\n",
            "\n",
            "         [[-0.0420]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0199]],\n",
            "\n",
            "         [[ 0.1145]],\n",
            "\n",
            "         [[ 0.0236]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0164]],\n",
            "\n",
            "         [[-0.0030]],\n",
            "\n",
            "         [[ 0.0698]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1073]],\n",
            "\n",
            "         [[-0.0822]],\n",
            "\n",
            "         [[-0.0799]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1021]],\n",
            "\n",
            "         [[ 0.0298]],\n",
            "\n",
            "         [[ 0.0249]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.0085]],\n",
            "\n",
            "         [[-0.0738]]],\n",
            "\n",
            "\n",
            "        [[[-0.0259]],\n",
            "\n",
            "         [[-0.1195]],\n",
            "\n",
            "         [[-0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0510]],\n",
            "\n",
            "         [[ 0.0883]],\n",
            "\n",
            "         [[-0.0678]]],\n",
            "\n",
            "\n",
            "        [[[-0.0384]],\n",
            "\n",
            "         [[-0.1033]],\n",
            "\n",
            "         [[ 0.0134]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0214]],\n",
            "\n",
            "         [[ 0.0112]],\n",
            "\n",
            "         [[-0.0111]]]])), ('module.encoder_q.layer2.1.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.1.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.1.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.2.conv1.weight', tensor([[[[-0.0462]],\n",
            "\n",
            "         [[-0.0860]],\n",
            "\n",
            "         [[ 0.2435]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3129]],\n",
            "\n",
            "         [[ 0.0518]],\n",
            "\n",
            "         [[ 0.0729]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0233]],\n",
            "\n",
            "         [[-0.1573]],\n",
            "\n",
            "         [[ 0.0401]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1704]],\n",
            "\n",
            "         [[ 0.1288]],\n",
            "\n",
            "         [[-0.0288]]],\n",
            "\n",
            "\n",
            "        [[[-0.0690]],\n",
            "\n",
            "         [[-0.0855]],\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1292]],\n",
            "\n",
            "         [[-0.0148]],\n",
            "\n",
            "         [[-0.0995]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0591]],\n",
            "\n",
            "         [[ 0.2056]],\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1038]],\n",
            "\n",
            "         [[ 0.2020]],\n",
            "\n",
            "         [[-0.2573]]],\n",
            "\n",
            "\n",
            "        [[[-0.2237]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[ 0.2163]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0736]],\n",
            "\n",
            "         [[-0.0507]],\n",
            "\n",
            "         [[ 0.3319]]],\n",
            "\n",
            "\n",
            "        [[[-0.1276]],\n",
            "\n",
            "         [[-0.0740]],\n",
            "\n",
            "         [[-0.2575]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2182]],\n",
            "\n",
            "         [[ 0.0925]],\n",
            "\n",
            "         [[ 0.1306]]]])), ('module.encoder_q.layer2.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.2.conv2.weight', tensor([[[[ 0.0156, -0.0523, -0.0431],\n",
            "          [ 0.0094, -0.0275,  0.0040],\n",
            "          [-0.0086,  0.0213, -0.0466]],\n",
            "\n",
            "         [[-0.0323,  0.0137, -0.0159],\n",
            "          [-0.0079,  0.0211, -0.0577],\n",
            "          [ 0.0061, -0.0110,  0.0037]],\n",
            "\n",
            "         [[-0.0221,  0.0452, -0.0110],\n",
            "          [-0.0069, -0.0090,  0.0394],\n",
            "          [-0.0128,  0.0437,  0.0475]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0002, -0.0187, -0.0038],\n",
            "          [-0.0023,  0.0272,  0.0494],\n",
            "          [ 0.0324, -0.0002,  0.0056]],\n",
            "\n",
            "         [[-0.0024, -0.0769, -0.0661],\n",
            "          [ 0.0170,  0.0370, -0.0587],\n",
            "          [ 0.0465, -0.0149,  0.0545]],\n",
            "\n",
            "         [[ 0.0080,  0.0128, -0.0002],\n",
            "          [ 0.0168, -0.0569,  0.0042],\n",
            "          [ 0.0293,  0.0134, -0.0533]]],\n",
            "\n",
            "\n",
            "        [[[-0.0319,  0.0042, -0.0065],\n",
            "          [-0.0259, -0.0445,  0.0489],\n",
            "          [-0.0051,  0.0231,  0.0149]],\n",
            "\n",
            "         [[ 0.0405,  0.0749,  0.0042],\n",
            "          [-0.0036, -0.0351,  0.0708],\n",
            "          [-0.0349,  0.0490,  0.0033]],\n",
            "\n",
            "         [[ 0.0372,  0.0191,  0.0284],\n",
            "          [ 0.0045,  0.0048,  0.0284],\n",
            "          [-0.0244, -0.0733, -0.0292]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0019,  0.0564,  0.0096],\n",
            "          [-0.0330,  0.0924, -0.0306],\n",
            "          [-0.1008,  0.0624, -0.0037]],\n",
            "\n",
            "         [[-0.0325, -0.0426,  0.0185],\n",
            "          [-0.0231, -0.0849, -0.0240],\n",
            "          [-0.0200, -0.0055,  0.0203]],\n",
            "\n",
            "         [[ 0.0360,  0.0226, -0.0500],\n",
            "          [ 0.0521, -0.0231,  0.0311],\n",
            "          [ 0.0043,  0.0227,  0.0063]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0134,  0.0300,  0.0283],\n",
            "          [ 0.0089,  0.0305,  0.0248],\n",
            "          [ 0.0380, -0.0514,  0.0168]],\n",
            "\n",
            "         [[ 0.0572, -0.0589,  0.0530],\n",
            "          [ 0.0251,  0.0233, -0.0319],\n",
            "          [ 0.0101,  0.0021, -0.0621]],\n",
            "\n",
            "         [[-0.0523,  0.0199, -0.1482],\n",
            "          [ 0.0550,  0.0036, -0.0362],\n",
            "          [ 0.0010,  0.0554,  0.0521]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0133, -0.0239,  0.0029],\n",
            "          [ 0.0212,  0.0130, -0.0425],\n",
            "          [ 0.0104, -0.0491, -0.0216]],\n",
            "\n",
            "         [[-0.0175, -0.0524,  0.0127],\n",
            "          [-0.0010,  0.0363,  0.0634],\n",
            "          [-0.0104,  0.0031, -0.0983]],\n",
            "\n",
            "         [[ 0.0006, -0.0316,  0.0387],\n",
            "          [ 0.0465, -0.0353,  0.0334],\n",
            "          [ 0.0518, -0.0092, -0.0312]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0012,  0.0051, -0.0505],\n",
            "          [ 0.0195, -0.0126,  0.0038],\n",
            "          [-0.0099, -0.0123, -0.0881]],\n",
            "\n",
            "         [[-0.0666, -0.0317, -0.0035],\n",
            "          [-0.0081, -0.0313,  0.0622],\n",
            "          [-0.0186, -0.0818, -0.0326]],\n",
            "\n",
            "         [[-0.0119,  0.0031, -0.0378],\n",
            "          [ 0.0335,  0.0566,  0.0344],\n",
            "          [ 0.0376, -0.0257, -0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0035,  0.0588, -0.0296],\n",
            "          [ 0.0371,  0.0096, -0.0034],\n",
            "          [-0.0469, -0.0070, -0.0211]],\n",
            "\n",
            "         [[ 0.0301,  0.0367,  0.0473],\n",
            "          [-0.0174,  0.0542, -0.0306],\n",
            "          [-0.0458,  0.0167, -0.0362]],\n",
            "\n",
            "         [[-0.0148, -0.0122,  0.0332],\n",
            "          [-0.0126, -0.0476,  0.0123],\n",
            "          [-0.0582,  0.0326,  0.0765]]],\n",
            "\n",
            "\n",
            "        [[[-0.0315, -0.0141, -0.0791],\n",
            "          [ 0.0666,  0.1131, -0.0225],\n",
            "          [ 0.0528,  0.0480, -0.0180]],\n",
            "\n",
            "         [[ 0.0527,  0.0678,  0.0131],\n",
            "          [-0.0050, -0.0128,  0.0170],\n",
            "          [-0.1508,  0.0283, -0.0398]],\n",
            "\n",
            "         [[ 0.0272, -0.0006, -0.0738],\n",
            "          [-0.0428,  0.0259,  0.0080],\n",
            "          [-0.0037,  0.0254, -0.0113]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0430, -0.0658, -0.0068],\n",
            "          [ 0.0223, -0.0101, -0.0929],\n",
            "          [-0.0381,  0.0391,  0.0074]],\n",
            "\n",
            "         [[-0.0194, -0.1032, -0.0640],\n",
            "          [ 0.0284, -0.0526, -0.0340],\n",
            "          [ 0.0734, -0.0605,  0.0427]],\n",
            "\n",
            "         [[ 0.0558,  0.0489, -0.0586],\n",
            "          [ 0.0505,  0.0066,  0.0449],\n",
            "          [-0.0349, -0.0071,  0.0624]]],\n",
            "\n",
            "\n",
            "        [[[-0.0207,  0.0273,  0.0014],\n",
            "          [-0.1042, -0.0158,  0.0229],\n",
            "          [ 0.0422, -0.0650,  0.0165]],\n",
            "\n",
            "         [[ 0.0073,  0.0427, -0.0058],\n",
            "          [-0.0366, -0.0107, -0.0447],\n",
            "          [ 0.0086, -0.0177, -0.0010]],\n",
            "\n",
            "         [[ 0.0402,  0.0321,  0.0216],\n",
            "          [-0.0080, -0.0428,  0.0240],\n",
            "          [ 0.0438,  0.0190,  0.0041]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0186, -0.0121, -0.0897],\n",
            "          [-0.0147,  0.0569, -0.0360],\n",
            "          [ 0.0399, -0.0361,  0.0084]],\n",
            "\n",
            "         [[ 0.0687, -0.0346, -0.0108],\n",
            "          [-0.0281, -0.0493,  0.0418],\n",
            "          [ 0.0051, -0.0045,  0.0392]],\n",
            "\n",
            "         [[-0.0019,  0.0615, -0.0528],\n",
            "          [-0.0098, -0.0565, -0.0086],\n",
            "          [ 0.0702, -0.0490,  0.0441]]]])), ('module.encoder_q.layer2.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.2.conv3.weight', tensor([[[[ 0.0162]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         [[-0.0581]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0006]],\n",
            "\n",
            "         [[-0.0278]],\n",
            "\n",
            "         [[-0.0658]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0367]],\n",
            "\n",
            "         [[-0.0580]],\n",
            "\n",
            "         [[-0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0252]],\n",
            "\n",
            "         [[ 0.0281]],\n",
            "\n",
            "         [[-0.1131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0028]],\n",
            "\n",
            "         [[ 0.0339]],\n",
            "\n",
            "         [[ 0.0179]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1477]],\n",
            "\n",
            "         [[-0.0822]],\n",
            "\n",
            "         [[-0.0192]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0572]],\n",
            "\n",
            "         [[-0.0946]],\n",
            "\n",
            "         [[-0.0280]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0124]],\n",
            "\n",
            "         [[ 0.1155]],\n",
            "\n",
            "         [[-0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0326]],\n",
            "\n",
            "         [[-0.0597]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0582]],\n",
            "\n",
            "         [[-0.1249]],\n",
            "\n",
            "         [[-0.0081]]],\n",
            "\n",
            "\n",
            "        [[[-0.0914]],\n",
            "\n",
            "         [[-0.0796]],\n",
            "\n",
            "         [[-0.0320]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0934]],\n",
            "\n",
            "         [[-0.0957]],\n",
            "\n",
            "         [[-0.0545]]]])), ('module.encoder_q.layer2.2.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.2.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.2.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.3.conv1.weight', tensor([[[[ 0.1634]],\n",
            "\n",
            "         [[ 0.1546]],\n",
            "\n",
            "         [[-0.1973]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0063]],\n",
            "\n",
            "         [[-0.0004]],\n",
            "\n",
            "         [[-0.2340]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1462]],\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[-0.0380]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1263]],\n",
            "\n",
            "         [[-0.1100]],\n",
            "\n",
            "         [[ 0.1089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204]],\n",
            "\n",
            "         [[ 0.1834]],\n",
            "\n",
            "         [[-0.0685]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0970]],\n",
            "\n",
            "         [[ 0.0020]],\n",
            "\n",
            "         [[-0.1100]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0636]],\n",
            "\n",
            "         [[-0.0080]],\n",
            "\n",
            "         [[ 0.0098]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1787]],\n",
            "\n",
            "         [[-0.0566]],\n",
            "\n",
            "         [[ 0.1044]]],\n",
            "\n",
            "\n",
            "        [[[-0.1067]],\n",
            "\n",
            "         [[ 0.1645]],\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0935]],\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         [[ 0.2193]]],\n",
            "\n",
            "\n",
            "        [[[-0.0080]],\n",
            "\n",
            "         [[ 0.2346]],\n",
            "\n",
            "         [[ 0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         [[ 0.0264]],\n",
            "\n",
            "         [[-0.0833]]]])), ('module.encoder_q.layer2.3.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.3.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.3.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.3.conv2.weight', tensor([[[[ 7.3497e-02,  2.1962e-02, -4.2201e-03],\n",
            "          [ 9.5974e-03, -8.6623e-04, -1.3851e-02],\n",
            "          [-4.1984e-03, -6.3631e-02, -3.2177e-02]],\n",
            "\n",
            "         [[ 3.8268e-02,  4.4671e-03,  6.2141e-03],\n",
            "          [-1.7520e-02,  4.2654e-02,  5.0988e-02],\n",
            "          [-9.7652e-03,  1.3578e-01, -4.3674e-02]],\n",
            "\n",
            "         [[ 1.7944e-02,  3.4590e-02,  1.4852e-02],\n",
            "          [-5.2700e-02, -3.3267e-02, -2.7509e-02],\n",
            "          [ 1.3541e-03,  8.5641e-03,  2.8167e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.7612e-02, -2.9776e-02,  5.7160e-03],\n",
            "          [-1.1761e-02, -4.3762e-03,  5.4077e-02],\n",
            "          [ 6.0091e-02,  2.1712e-02,  7.7632e-02]],\n",
            "\n",
            "         [[-1.9806e-02,  2.7688e-02,  7.4892e-02],\n",
            "          [-1.4858e-02, -2.8394e-02, -1.9524e-02],\n",
            "          [-7.8309e-02, -2.6777e-02,  1.0059e-01]],\n",
            "\n",
            "         [[ 5.7815e-02, -1.4227e-02, -7.2202e-02],\n",
            "          [ 6.8782e-02,  1.6994e-02,  2.5283e-03],\n",
            "          [-3.2463e-02,  2.5852e-02, -3.2543e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6790e-02,  9.2434e-03, -5.7604e-02],\n",
            "          [ 5.6901e-02, -6.6339e-03,  6.2517e-02],\n",
            "          [ 6.0121e-02,  1.1022e-02,  5.8181e-02]],\n",
            "\n",
            "         [[-3.6046e-03, -1.7133e-02,  2.5426e-02],\n",
            "          [ 4.6385e-02,  2.8519e-02, -5.0508e-02],\n",
            "          [ 1.1826e-02, -1.3038e-01, -1.1524e-02]],\n",
            "\n",
            "         [[-8.1995e-02,  5.7327e-02,  4.5260e-02],\n",
            "          [ 8.9381e-02,  1.1208e-01,  1.4266e-03],\n",
            "          [-4.4925e-02, -7.4783e-02, -1.1810e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4496e-03, -2.6290e-02, -3.5686e-02],\n",
            "          [-8.6725e-02, -6.6405e-02, -2.5709e-02],\n",
            "          [ 2.3962e-02,  2.9266e-02, -1.3232e-02]],\n",
            "\n",
            "         [[ 4.7316e-03, -3.2027e-03, -6.1636e-02],\n",
            "          [ 2.9870e-02, -5.1156e-02, -1.9421e-02],\n",
            "          [ 2.5220e-02, -7.3778e-04,  4.0020e-02]],\n",
            "\n",
            "         [[ 5.4043e-02, -9.1860e-03,  7.7965e-02],\n",
            "          [ 4.5336e-02, -1.9628e-02,  7.1211e-02],\n",
            "          [ 2.3061e-02, -4.5180e-02, -2.3573e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.0291e-01, -7.8657e-02, -1.9550e-02],\n",
            "          [-1.0191e-02,  4.3485e-03, -5.6207e-02],\n",
            "          [ 6.6759e-03, -4.6502e-02,  3.6970e-02]],\n",
            "\n",
            "         [[ 3.8708e-02,  2.9876e-02,  3.3753e-02],\n",
            "          [ 8.7522e-02, -4.2145e-02, -7.5818e-02],\n",
            "          [-3.1546e-02,  3.6052e-02,  1.4430e-02]],\n",
            "\n",
            "         [[ 4.5737e-02, -9.3283e-02, -6.2237e-02],\n",
            "          [-2.4330e-04,  1.9173e-02,  9.2847e-03],\n",
            "          [ 1.0665e-03,  3.0539e-02, -2.9983e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.8350e-02, -2.0814e-02, -2.2883e-02],\n",
            "          [-3.6517e-02, -2.6142e-02, -2.8073e-02],\n",
            "          [-2.9324e-02,  1.1660e-02, -2.8289e-03]],\n",
            "\n",
            "         [[-8.4914e-02, -5.4831e-03, -4.1188e-02],\n",
            "          [-1.5806e-02, -3.9671e-02,  3.7419e-02],\n",
            "          [-4.9370e-02, -2.4254e-02,  6.7274e-02]],\n",
            "\n",
            "         [[-8.8635e-02,  4.3669e-02,  5.9139e-02],\n",
            "          [-6.3563e-03,  9.1158e-03,  6.5693e-02],\n",
            "          [ 2.6917e-02, -3.1036e-02, -2.2993e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8321e-04,  1.2337e-02,  6.0565e-02],\n",
            "          [-2.1838e-02,  1.4173e-02, -2.1628e-02],\n",
            "          [-5.2156e-02, -3.1882e-02, -3.1025e-02]],\n",
            "\n",
            "         [[-7.5517e-03, -7.9413e-02,  4.0100e-02],\n",
            "          [ 1.9147e-02, -3.7430e-02, -8.7601e-02],\n",
            "          [-1.2509e-02, -1.0716e-02,  2.8296e-02]],\n",
            "\n",
            "         [[-2.3965e-02, -3.0195e-02, -3.8776e-02],\n",
            "          [ 3.2006e-02,  7.6516e-03, -2.1318e-02],\n",
            "          [ 8.9448e-03, -6.7615e-02,  2.9057e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2462e-04,  6.6771e-02, -5.1844e-03],\n",
            "          [ 2.5719e-02, -5.1697e-02,  3.3111e-02],\n",
            "          [ 2.5794e-02, -1.5443e-02,  5.4360e-02]],\n",
            "\n",
            "         [[-9.5505e-02,  4.6302e-02,  1.1384e-02],\n",
            "          [-1.0154e-02,  2.9378e-02,  5.1836e-02],\n",
            "          [ 8.7175e-03, -3.3500e-02,  2.5306e-02]],\n",
            "\n",
            "         [[ 1.4768e-02,  3.7158e-02, -2.0268e-02],\n",
            "          [-2.2832e-02,  4.7761e-03, -2.6948e-03],\n",
            "          [ 5.8582e-04,  1.1468e-02,  3.6419e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.1331e-03, -5.8595e-03,  3.6922e-02],\n",
            "          [ 1.7414e-02,  1.1410e-01, -4.0412e-04],\n",
            "          [-1.1058e-02, -1.6056e-02, -6.6449e-02]],\n",
            "\n",
            "         [[ 3.0792e-02, -2.9954e-02, -3.5840e-02],\n",
            "          [-4.8895e-02, -1.2940e-02, -2.4149e-02],\n",
            "          [ 1.2103e-01, -5.6121e-03,  5.1470e-03]],\n",
            "\n",
            "         [[-1.1212e-02,  5.5661e-02, -2.0974e-02],\n",
            "          [-1.3182e-02,  6.5907e-02,  5.7097e-02],\n",
            "          [ 4.7265e-02,  9.5786e-02, -1.7952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0440e-02, -3.0773e-02,  1.7443e-02],\n",
            "          [ 1.0650e-02, -7.2580e-02, -7.6375e-02],\n",
            "          [ 4.6634e-02,  4.6443e-02,  1.5834e-02]],\n",
            "\n",
            "         [[ 6.1971e-04,  2.0822e-02,  2.6039e-02],\n",
            "          [ 5.9719e-02, -2.4735e-02, -3.5424e-02],\n",
            "          [-4.4247e-02,  2.7197e-04,  1.9516e-02]],\n",
            "\n",
            "         [[ 5.2017e-03, -6.0717e-02,  3.9297e-02],\n",
            "          [-1.3585e-02, -4.4474e-02,  3.6900e-02],\n",
            "          [-1.0438e-02, -2.1893e-02,  4.5572e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.0926e-02,  2.5006e-02,  1.9450e-02],\n",
            "          [ 4.2647e-02,  1.3402e-02, -6.2047e-03],\n",
            "          [ 6.8751e-03, -1.7562e-02, -3.6012e-02]],\n",
            "\n",
            "         [[-6.4880e-03, -2.9046e-04,  3.6202e-02],\n",
            "          [-2.4446e-02,  3.0826e-02,  9.7593e-02],\n",
            "          [-1.7705e-02, -1.1504e-02,  1.0390e-01]],\n",
            "\n",
            "         [[ 1.5943e-02,  1.0239e-02, -6.3483e-02],\n",
            "          [-9.6723e-02,  1.0609e-02,  5.3427e-02],\n",
            "          [ 6.3694e-03,  5.1223e-02, -9.3401e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.4862e-03, -1.1650e-02, -1.7556e-02],\n",
            "          [ 3.3485e-02, -1.6501e-02,  2.8443e-03],\n",
            "          [ 3.3304e-02,  8.6860e-02,  3.3843e-02]],\n",
            "\n",
            "         [[-3.6320e-02, -1.8913e-02, -1.1707e-02],\n",
            "          [ 8.2705e-03, -5.0673e-02, -6.2071e-02],\n",
            "          [-2.4736e-02,  6.1819e-02,  2.7819e-02]],\n",
            "\n",
            "         [[-3.9525e-02, -3.9709e-02, -2.6275e-02],\n",
            "          [ 4.6188e-02,  4.7785e-02, -3.5540e-02],\n",
            "          [-6.5820e-02,  9.9100e-03, -3.9453e-02]]]])), ('module.encoder_q.layer2.3.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.3.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_q.layer2.3.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer2.3.conv3.weight', tensor([[[[-0.0496]],\n",
            "\n",
            "         [[ 0.0308]],\n",
            "\n",
            "         [[-0.0671]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0225]],\n",
            "\n",
            "         [[-0.0443]],\n",
            "\n",
            "         [[-0.0912]]],\n",
            "\n",
            "\n",
            "        [[[-0.0430]],\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[ 0.1286]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0950]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         [[-0.0738]]],\n",
            "\n",
            "\n",
            "        [[[-0.0059]],\n",
            "\n",
            "         [[ 0.0812]],\n",
            "\n",
            "         [[-0.0936]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1761]],\n",
            "\n",
            "         [[ 0.0358]],\n",
            "\n",
            "         [[ 0.0380]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0665]],\n",
            "\n",
            "         [[ 0.0652]],\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0563]],\n",
            "\n",
            "         [[-0.0551]],\n",
            "\n",
            "         [[-0.0765]]],\n",
            "\n",
            "\n",
            "        [[[-0.0174]],\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         [[ 0.0449]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0276]],\n",
            "\n",
            "         [[-0.1217]],\n",
            "\n",
            "         [[ 0.0428]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0202]],\n",
            "\n",
            "         [[-0.1253]],\n",
            "\n",
            "         [[-0.0650]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0617]],\n",
            "\n",
            "         [[-0.0924]],\n",
            "\n",
            "         [[-0.0165]]]])), ('module.encoder_q.layer2.3.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.3.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer2.3.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer2.3.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.0.conv1.weight', tensor([[[[-0.0199]],\n",
            "\n",
            "         [[-0.0956]],\n",
            "\n",
            "         [[ 0.0166]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0142]],\n",
            "\n",
            "         [[ 0.0951]],\n",
            "\n",
            "         [[-0.0889]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0015]],\n",
            "\n",
            "         [[-0.1013]],\n",
            "\n",
            "         [[-0.1308]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0605]],\n",
            "\n",
            "         [[-0.1027]],\n",
            "\n",
            "         [[ 0.0254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0518]],\n",
            "\n",
            "         [[ 0.1133]],\n",
            "\n",
            "         [[ 0.0779]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1883]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[-0.0929]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0577]],\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[ 0.0622]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0487]],\n",
            "\n",
            "         [[ 0.1069]],\n",
            "\n",
            "         [[-0.0538]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0331]],\n",
            "\n",
            "         [[ 0.0904]],\n",
            "\n",
            "         [[-0.1863]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0472]],\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         [[-0.0246]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0551]],\n",
            "\n",
            "         [[-0.2448]],\n",
            "\n",
            "         [[-0.0770]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0390]],\n",
            "\n",
            "         [[-0.0319]],\n",
            "\n",
            "         [[ 0.0552]]]])), ('module.encoder_q.layer3.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.0.conv2.weight', tensor([[[[-4.9663e-02,  2.3397e-02,  2.8464e-03],\n",
            "          [ 2.2094e-03, -2.4448e-02, -2.2365e-02],\n",
            "          [ 3.7250e-03, -2.2872e-02, -7.1784e-03]],\n",
            "\n",
            "         [[-5.3836e-03,  5.0482e-02, -4.6048e-02],\n",
            "          [-2.2515e-02,  1.5977e-02, -1.6546e-02],\n",
            "          [ 3.6730e-03,  2.8759e-03,  1.3568e-02]],\n",
            "\n",
            "         [[-3.9657e-02,  1.3886e-03, -1.4713e-02],\n",
            "          [-7.8913e-02,  2.3137e-02, -3.6984e-03],\n",
            "          [ 4.4267e-02,  3.6957e-02, -1.4662e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.6209e-03,  2.7667e-02, -9.4998e-03],\n",
            "          [ 1.9873e-02, -4.2416e-02,  3.9956e-03],\n",
            "          [ 8.1255e-03, -2.8597e-02,  5.3577e-03]],\n",
            "\n",
            "         [[-1.0911e-02, -9.2327e-03,  5.4599e-02],\n",
            "          [-2.9180e-02,  1.6269e-02,  5.1846e-03],\n",
            "          [-1.3205e-02,  8.4887e-03,  4.6257e-02]],\n",
            "\n",
            "         [[ 1.1215e-02, -3.5248e-02, -4.9783e-02],\n",
            "          [-5.0163e-03, -1.1215e-03,  2.2925e-02],\n",
            "          [ 3.6902e-02, -1.4246e-02,  4.8238e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.3506e-03, -3.2564e-02, -2.5500e-02],\n",
            "          [-2.0019e-03, -4.2125e-04,  2.5693e-03],\n",
            "          [-5.2061e-02,  2.6567e-02, -3.3902e-02]],\n",
            "\n",
            "         [[-3.3594e-02, -2.3197e-02,  1.1350e-02],\n",
            "          [-4.6662e-02, -4.1333e-02,  5.3211e-02],\n",
            "          [ 1.4485e-02, -1.1782e-02, -1.5482e-02]],\n",
            "\n",
            "         [[ 4.1609e-02, -2.8274e-03, -3.6219e-02],\n",
            "          [ 3.0869e-02, -2.0871e-02, -2.5953e-02],\n",
            "          [ 1.2111e-03,  3.8068e-03, -1.3093e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6906e-02,  4.1184e-02, -6.7997e-03],\n",
            "          [ 4.6377e-02,  3.4289e-02, -2.0415e-02],\n",
            "          [ 4.4391e-05, -2.9314e-02,  1.6006e-02]],\n",
            "\n",
            "         [[ 1.6508e-02,  4.4465e-02, -4.7056e-03],\n",
            "          [-3.2881e-02,  6.7810e-03, -1.1304e-02],\n",
            "          [ 9.3818e-03,  6.8706e-03, -2.6984e-02]],\n",
            "\n",
            "         [[-4.8381e-02,  1.0455e-02, -6.8211e-03],\n",
            "          [ 2.8087e-02,  3.0887e-02,  3.3556e-03],\n",
            "          [-3.1545e-03,  4.8943e-02, -7.6599e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2367e-02, -3.1496e-02,  6.0545e-03],\n",
            "          [ 4.3655e-02,  2.5236e-03, -2.4202e-02],\n",
            "          [-1.3633e-03, -7.6109e-03,  4.8260e-02]],\n",
            "\n",
            "         [[ 2.6626e-02,  4.0929e-02,  9.6613e-03],\n",
            "          [-2.7113e-02,  3.9245e-02,  2.4958e-03],\n",
            "          [-8.7761e-03,  2.9972e-02, -8.8409e-03]],\n",
            "\n",
            "         [[-1.6143e-02,  3.1484e-02, -5.0397e-03],\n",
            "          [-9.5713e-03, -3.8084e-02, -2.8171e-02],\n",
            "          [-1.9697e-02, -4.7335e-03, -2.3531e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.8628e-02, -4.3312e-02,  1.9249e-02],\n",
            "          [ 4.5846e-03, -1.8125e-02, -3.0215e-03],\n",
            "          [-2.6459e-02,  2.9310e-02, -1.7524e-03]],\n",
            "\n",
            "         [[ 3.4652e-02,  1.3164e-02, -2.7427e-03],\n",
            "          [-9.8975e-02,  4.9779e-03, -1.7790e-02],\n",
            "          [ 3.3417e-02, -3.0878e-02,  3.3808e-02]],\n",
            "\n",
            "         [[-3.9711e-02,  7.3333e-02, -3.0276e-02],\n",
            "          [-2.8341e-02, -1.5603e-03,  7.1847e-04],\n",
            "          [ 2.4754e-03,  4.1580e-02, -2.1754e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.1305e-02, -3.0037e-02, -3.0353e-02],\n",
            "          [ 6.7595e-03,  1.3360e-02,  1.0195e-02],\n",
            "          [-3.0045e-02, -1.6443e-02,  1.6502e-02]],\n",
            "\n",
            "         [[ 1.3505e-02, -1.1012e-02,  1.7798e-02],\n",
            "          [ 3.4832e-02, -4.8080e-02, -2.5357e-02],\n",
            "          [ 2.9775e-03,  3.1159e-03, -6.5683e-02]],\n",
            "\n",
            "         [[-2.6140e-02, -3.5974e-03, -5.7961e-02],\n",
            "          [ 3.7935e-02,  1.7469e-02, -3.7175e-02],\n",
            "          [-1.9885e-02, -1.0218e-02,  7.3468e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3351e-02,  2.0622e-03, -3.2270e-02],\n",
            "          [-1.8721e-02,  5.7329e-03,  6.9424e-03],\n",
            "          [-3.0536e-02,  2.5859e-02,  1.7404e-02]],\n",
            "\n",
            "         [[-2.4225e-02,  3.1108e-02, -3.4956e-02],\n",
            "          [ 1.2613e-02, -1.6718e-02, -5.7247e-02],\n",
            "          [ 3.3959e-02, -3.9786e-02,  2.5693e-02]],\n",
            "\n",
            "         [[-2.2300e-02,  1.8675e-02, -1.8242e-02],\n",
            "          [ 1.9164e-02, -2.0378e-02, -3.4195e-02],\n",
            "          [ 1.1678e-02,  4.6326e-02, -5.3498e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6348e-02, -2.9376e-03,  3.0171e-02],\n",
            "          [ 3.0700e-02, -8.8262e-03, -2.7142e-02],\n",
            "          [-5.1273e-02,  4.5427e-02, -1.2912e-02]],\n",
            "\n",
            "         [[-2.8729e-02, -1.1387e-02,  5.3612e-03],\n",
            "          [-2.4562e-02,  1.8516e-02, -5.5989e-02],\n",
            "          [ 3.2987e-02,  1.5897e-02, -3.7957e-02]],\n",
            "\n",
            "         [[-5.0488e-02, -7.0461e-02,  1.9902e-02],\n",
            "          [ 1.6605e-02,  7.2966e-03, -3.2870e-02],\n",
            "          [-4.7814e-03,  1.5486e-02, -2.4417e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9508e-02, -3.5648e-02, -2.5301e-02],\n",
            "          [-4.6586e-03, -1.7064e-02,  2.5175e-02],\n",
            "          [ 5.2074e-02, -3.9429e-02, -7.1824e-02]],\n",
            "\n",
            "         [[-8.0111e-03, -1.8161e-02,  1.7190e-02],\n",
            "          [ 1.8336e-02,  1.0150e-02,  1.3615e-02],\n",
            "          [-2.3567e-02, -5.4529e-02, -2.7474e-02]],\n",
            "\n",
            "         [[ 4.9409e-02,  9.0935e-03,  3.9998e-02],\n",
            "          [ 3.7406e-03, -6.4088e-02,  3.3114e-02],\n",
            "          [-1.7218e-02,  2.1583e-02, -1.5669e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2692e-02, -1.9992e-02,  6.2626e-02],\n",
            "          [-5.2451e-02, -2.2966e-02, -2.9006e-02],\n",
            "          [-1.2961e-02,  1.7061e-02, -1.2150e-02]],\n",
            "\n",
            "         [[-4.3864e-02,  2.8314e-03, -6.4951e-03],\n",
            "          [-9.5238e-03,  1.7325e-02, -1.4232e-02],\n",
            "          [-2.3668e-02, -6.7524e-02, -4.6335e-02]],\n",
            "\n",
            "         [[-1.9403e-02, -2.3183e-02, -1.2787e-02],\n",
            "          [-4.4870e-03, -1.2735e-02,  3.5427e-02],\n",
            "          [ 4.7133e-04, -7.3741e-02, -2.7211e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7108e-02,  1.8472e-02, -2.4584e-03],\n",
            "          [-1.9707e-02,  1.0193e-02,  5.6982e-02],\n",
            "          [ 2.0483e-02,  4.0088e-02,  9.4193e-03]],\n",
            "\n",
            "         [[-1.6692e-02,  6.4275e-02, -2.5562e-02],\n",
            "          [-9.6341e-03,  1.1054e-02, -4.5480e-03],\n",
            "          [ 2.0154e-03, -5.0286e-02,  6.6681e-02]],\n",
            "\n",
            "         [[ 1.0447e-03,  1.3399e-02, -2.0519e-03],\n",
            "          [ 1.4928e-02, -6.2575e-03,  3.9796e-02],\n",
            "          [ 1.3097e-02,  1.3690e-02,  4.8567e-02]]]])), ('module.encoder_q.layer3.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.0.conv3.weight', tensor([[[[ 0.0193]],\n",
            "\n",
            "         [[-0.0338]],\n",
            "\n",
            "         [[ 0.0822]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0016]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         [[ 0.0770]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0033]],\n",
            "\n",
            "         [[ 0.0469]],\n",
            "\n",
            "         [[ 0.0356]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0240]],\n",
            "\n",
            "         [[-0.0358]],\n",
            "\n",
            "         [[ 0.0104]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0578]],\n",
            "\n",
            "         [[ 0.0277]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0446]],\n",
            "\n",
            "         [[-0.0372]],\n",
            "\n",
            "         [[ 0.0213]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0054]],\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         [[-0.0508]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         [[-0.0679]],\n",
            "\n",
            "         [[ 0.0852]]],\n",
            "\n",
            "\n",
            "        [[[-0.0079]],\n",
            "\n",
            "         [[ 0.0787]],\n",
            "\n",
            "         [[-0.0173]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[ 0.0218]],\n",
            "\n",
            "         [[ 0.0574]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0525]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         [[-0.0303]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0213]],\n",
            "\n",
            "         [[-0.0300]],\n",
            "\n",
            "         [[ 0.0243]]]])), ('module.encoder_q.layer3.0.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.0.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.0.downsample.0.weight', tensor([[[[ 0.0392]],\n",
            "\n",
            "         [[ 0.0246]],\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0758]],\n",
            "\n",
            "         [[-0.0460]],\n",
            "\n",
            "         [[-0.0219]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0417]],\n",
            "\n",
            "         [[-0.0274]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0185]],\n",
            "\n",
            "         [[ 0.1011]],\n",
            "\n",
            "         [[-0.0318]]],\n",
            "\n",
            "\n",
            "        [[[-0.0215]],\n",
            "\n",
            "         [[ 0.0232]],\n",
            "\n",
            "         [[ 0.0761]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         [[-0.0149]],\n",
            "\n",
            "         [[-0.0079]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1125]],\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.0519]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0230]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0618]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]],\n",
            "\n",
            "         [[-0.0252]],\n",
            "\n",
            "         [[-0.0375]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0022]],\n",
            "\n",
            "         [[ 0.0551]],\n",
            "\n",
            "         [[ 0.0322]]],\n",
            "\n",
            "\n",
            "        [[[-0.0244]],\n",
            "\n",
            "         [[-0.0082]],\n",
            "\n",
            "         [[ 0.0995]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0575]],\n",
            "\n",
            "         [[-0.0205]],\n",
            "\n",
            "         [[ 0.0132]]]])), ('module.encoder_q.layer3.0.downsample.1.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.0.downsample.1.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.0.downsample.1.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.0.downsample.1.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.1.conv1.weight', tensor([[[[ 0.0807]],\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0097]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         [[ 0.0112]]],\n",
            "\n",
            "\n",
            "        [[[-0.0172]],\n",
            "\n",
            "         [[-0.0354]],\n",
            "\n",
            "         [[ 0.0108]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1473]],\n",
            "\n",
            "         [[-0.0188]],\n",
            "\n",
            "         [[ 0.1102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1178]],\n",
            "\n",
            "         [[ 0.0543]],\n",
            "\n",
            "         [[ 0.0593]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1215]],\n",
            "\n",
            "         [[ 0.0952]],\n",
            "\n",
            "         [[-0.0217]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0756]],\n",
            "\n",
            "         [[-0.0607]],\n",
            "\n",
            "         [[ 0.0654]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         [[-0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0455]],\n",
            "\n",
            "         [[-0.0460]],\n",
            "\n",
            "         [[-0.1572]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[-0.0425]],\n",
            "\n",
            "         [[-0.0976]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1218]],\n",
            "\n",
            "         [[ 0.0242]],\n",
            "\n",
            "         [[-0.1139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0453]],\n",
            "\n",
            "         [[-0.0877]],\n",
            "\n",
            "         [[ 0.0651]]]])), ('module.encoder_q.layer3.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.1.conv2.weight', tensor([[[[ 0.0032, -0.0051,  0.0349],\n",
            "          [ 0.0125, -0.0590,  0.0119],\n",
            "          [ 0.0204, -0.0140, -0.0222]],\n",
            "\n",
            "         [[ 0.0156,  0.0457, -0.0649],\n",
            "          [-0.0375,  0.0392, -0.0283],\n",
            "          [ 0.0025, -0.0237, -0.0171]],\n",
            "\n",
            "         [[-0.0547, -0.0167,  0.0195],\n",
            "          [-0.0066,  0.0331,  0.0187],\n",
            "          [ 0.0283, -0.0397,  0.0076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0435,  0.0277,  0.0117],\n",
            "          [-0.0409,  0.0077,  0.0216],\n",
            "          [-0.0702,  0.0298, -0.0381]],\n",
            "\n",
            "         [[-0.0260, -0.0069, -0.0239],\n",
            "          [ 0.0437, -0.0274,  0.0626],\n",
            "          [ 0.0156,  0.0352,  0.0203]],\n",
            "\n",
            "         [[ 0.0471,  0.0069, -0.0261],\n",
            "          [ 0.0295,  0.0107,  0.0434],\n",
            "          [-0.0010, -0.0103, -0.0194]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0051, -0.0396, -0.0489],\n",
            "          [-0.0104,  0.0123, -0.0211],\n",
            "          [-0.0206, -0.0182, -0.0463]],\n",
            "\n",
            "         [[ 0.0713, -0.0569, -0.0073],\n",
            "          [-0.0098,  0.0084, -0.0003],\n",
            "          [-0.0051,  0.0743,  0.0210]],\n",
            "\n",
            "         [[ 0.0140, -0.0011, -0.0072],\n",
            "          [-0.0444,  0.0273, -0.0052],\n",
            "          [-0.0724, -0.0344,  0.0515]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0294, -0.0039, -0.0071],\n",
            "          [ 0.0933, -0.0392,  0.0472],\n",
            "          [ 0.0230, -0.0042,  0.0516]],\n",
            "\n",
            "         [[ 0.0017,  0.0021, -0.0161],\n",
            "          [ 0.0210,  0.0025,  0.0162],\n",
            "          [ 0.0208,  0.0050,  0.0532]],\n",
            "\n",
            "         [[ 0.0240, -0.0368,  0.0369],\n",
            "          [-0.0222,  0.0151, -0.0234],\n",
            "          [ 0.0392,  0.0008, -0.0069]]],\n",
            "\n",
            "\n",
            "        [[[-0.0287, -0.0374,  0.0039],\n",
            "          [ 0.0444, -0.0070,  0.0044],\n",
            "          [ 0.0025, -0.0442,  0.0050]],\n",
            "\n",
            "         [[ 0.0071,  0.0097, -0.0076],\n",
            "          [ 0.0093,  0.0133, -0.0313],\n",
            "          [-0.0097,  0.0343, -0.0166]],\n",
            "\n",
            "         [[-0.0079,  0.0239, -0.0434],\n",
            "          [-0.0326,  0.0129, -0.0250],\n",
            "          [-0.0011, -0.0389, -0.0252]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0232,  0.0356,  0.0025],\n",
            "          [ 0.0119, -0.0193, -0.0030],\n",
            "          [-0.0019,  0.0208, -0.0085]],\n",
            "\n",
            "         [[ 0.0052, -0.0287,  0.0148],\n",
            "          [ 0.0010,  0.0112, -0.0117],\n",
            "          [ 0.0253,  0.0097,  0.0309]],\n",
            "\n",
            "         [[ 0.0142,  0.0101,  0.0317],\n",
            "          [-0.0081,  0.0380, -0.0338],\n",
            "          [ 0.0202, -0.0305,  0.0354]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0224, -0.0193,  0.0210],\n",
            "          [-0.0169, -0.0204, -0.0081],\n",
            "          [-0.0280,  0.0347,  0.0095]],\n",
            "\n",
            "         [[-0.0111, -0.0086,  0.0285],\n",
            "          [-0.0436,  0.0025, -0.0190],\n",
            "          [-0.0227,  0.0127,  0.0139]],\n",
            "\n",
            "         [[ 0.0398, -0.0096, -0.0086],\n",
            "          [-0.0162, -0.0160, -0.0023],\n",
            "          [ 0.0154, -0.0226,  0.0320]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0841,  0.0549,  0.0102],\n",
            "          [ 0.0017, -0.0586,  0.0183],\n",
            "          [ 0.0321, -0.0490,  0.0501]],\n",
            "\n",
            "         [[ 0.0502, -0.0068, -0.0228],\n",
            "          [-0.0474,  0.0025,  0.0394],\n",
            "          [ 0.0092, -0.0043, -0.0518]],\n",
            "\n",
            "         [[ 0.0134,  0.0361,  0.0151],\n",
            "          [ 0.0316, -0.0263,  0.0125],\n",
            "          [ 0.0194,  0.0359, -0.0384]]],\n",
            "\n",
            "\n",
            "        [[[-0.0415,  0.0374, -0.0066],\n",
            "          [ 0.0118,  0.0407,  0.0016],\n",
            "          [-0.0187, -0.0168,  0.0363]],\n",
            "\n",
            "         [[ 0.0699, -0.0003, -0.0231],\n",
            "          [-0.0317,  0.0075, -0.0151],\n",
            "          [-0.0105,  0.0221, -0.0091]],\n",
            "\n",
            "         [[-0.0168, -0.0044, -0.0073],\n",
            "          [ 0.0234,  0.0258, -0.0571],\n",
            "          [ 0.0324,  0.0292, -0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0440, -0.0024,  0.0367],\n",
            "          [ 0.0137,  0.0202, -0.0371],\n",
            "          [-0.0304,  0.0308, -0.0212]],\n",
            "\n",
            "         [[-0.0270, -0.0288, -0.0269],\n",
            "          [ 0.0740,  0.0410,  0.0238],\n",
            "          [ 0.0031,  0.0354,  0.0316]],\n",
            "\n",
            "         [[ 0.0287, -0.0049, -0.0097],\n",
            "          [-0.0260,  0.0295, -0.0172],\n",
            "          [ 0.0288,  0.0437, -0.0021]]],\n",
            "\n",
            "\n",
            "        [[[-0.0572,  0.0229, -0.0047],\n",
            "          [ 0.0278,  0.0123,  0.0061],\n",
            "          [ 0.0248,  0.0215, -0.0076]],\n",
            "\n",
            "         [[-0.0206,  0.0160,  0.0061],\n",
            "          [-0.0286, -0.0193,  0.0251],\n",
            "          [-0.0140,  0.0350,  0.0214]],\n",
            "\n",
            "         [[ 0.0138, -0.0378,  0.0720],\n",
            "          [ 0.0035, -0.0041,  0.0079],\n",
            "          [ 0.0269, -0.0355,  0.0153]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0055, -0.0400, -0.0421],\n",
            "          [-0.0009, -0.0363, -0.0327],\n",
            "          [ 0.0452, -0.0046,  0.0044]],\n",
            "\n",
            "         [[ 0.0357, -0.0156,  0.0356],\n",
            "          [ 0.0051,  0.0086, -0.0025],\n",
            "          [-0.0248,  0.0487,  0.0141]],\n",
            "\n",
            "         [[ 0.0330,  0.0084,  0.0097],\n",
            "          [-0.0096, -0.0114, -0.0373],\n",
            "          [-0.0487, -0.0550,  0.0282]]]])), ('module.encoder_q.layer3.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.1.conv3.weight', tensor([[[[-0.0442]],\n",
            "\n",
            "         [[-0.0007]],\n",
            "\n",
            "         [[ 0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1020]],\n",
            "\n",
            "         [[-0.0623]],\n",
            "\n",
            "         [[ 0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0431]],\n",
            "\n",
            "         [[ 0.0072]],\n",
            "\n",
            "         [[-0.0353]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[-0.0932]],\n",
            "\n",
            "         [[-0.0387]]],\n",
            "\n",
            "\n",
            "        [[[-0.0175]],\n",
            "\n",
            "         [[-0.0396]],\n",
            "\n",
            "         [[-0.0007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0453]],\n",
            "\n",
            "         [[ 0.1117]],\n",
            "\n",
            "         [[ 0.0139]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0107]],\n",
            "\n",
            "         [[ 0.0327]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0875]],\n",
            "\n",
            "         [[ 0.0180]],\n",
            "\n",
            "         [[ 0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0091]],\n",
            "\n",
            "         [[-0.0017]],\n",
            "\n",
            "         [[ 0.0335]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0858]],\n",
            "\n",
            "         [[ 0.0190]],\n",
            "\n",
            "         [[-0.0294]]],\n",
            "\n",
            "\n",
            "        [[[-0.0109]],\n",
            "\n",
            "         [[ 0.0166]],\n",
            "\n",
            "         [[ 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0086]],\n",
            "\n",
            "         [[ 0.0105]],\n",
            "\n",
            "         [[ 0.0325]]]])), ('module.encoder_q.layer3.1.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.1.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.2.conv1.weight', tensor([[[[-0.0274]],\n",
            "\n",
            "         [[-0.0174]],\n",
            "\n",
            "         [[ 0.0243]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0985]],\n",
            "\n",
            "         [[ 0.0036]],\n",
            "\n",
            "         [[-0.0047]]],\n",
            "\n",
            "\n",
            "        [[[-0.0339]],\n",
            "\n",
            "         [[-0.0891]],\n",
            "\n",
            "         [[-0.0051]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0517]],\n",
            "\n",
            "         [[-0.1746]],\n",
            "\n",
            "         [[-0.1943]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0243]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0423]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0425]],\n",
            "\n",
            "         [[-0.0675]],\n",
            "\n",
            "         [[-0.0299]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0167]],\n",
            "\n",
            "         [[-0.0739]],\n",
            "\n",
            "         [[-0.0005]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0609]],\n",
            "\n",
            "         [[-0.0851]],\n",
            "\n",
            "         [[ 0.0511]]],\n",
            "\n",
            "\n",
            "        [[[-0.2224]],\n",
            "\n",
            "         [[ 0.0176]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[ 0.0170]],\n",
            "\n",
            "         [[-0.0864]]],\n",
            "\n",
            "\n",
            "        [[[-0.0312]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         [[ 0.0597]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0719]],\n",
            "\n",
            "         [[ 0.0622]],\n",
            "\n",
            "         [[ 0.0539]]]])), ('module.encoder_q.layer3.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.2.conv2.weight', tensor([[[[-0.0643,  0.0223,  0.0073],\n",
            "          [ 0.0162, -0.0381,  0.0261],\n",
            "          [-0.0165,  0.0149,  0.0564]],\n",
            "\n",
            "         [[-0.0097,  0.0235, -0.0080],\n",
            "          [-0.0150, -0.0014, -0.0292],\n",
            "          [ 0.0432, -0.0088,  0.0094]],\n",
            "\n",
            "         [[-0.0078, -0.0232,  0.0319],\n",
            "          [ 0.0023,  0.0009,  0.0180],\n",
            "          [ 0.0438,  0.0202, -0.0544]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0281,  0.0036, -0.0266],\n",
            "          [ 0.0365,  0.0640, -0.0349],\n",
            "          [-0.0848, -0.0114, -0.0288]],\n",
            "\n",
            "         [[ 0.0426, -0.0100,  0.0073],\n",
            "          [-0.0480, -0.0071, -0.0553],\n",
            "          [-0.0200,  0.0513,  0.0159]],\n",
            "\n",
            "         [[ 0.0402, -0.0476,  0.0255],\n",
            "          [-0.0136,  0.0160, -0.0121],\n",
            "          [ 0.0555,  0.0129,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[-0.0239,  0.0209,  0.0062],\n",
            "          [-0.0331,  0.0579, -0.0338],\n",
            "          [-0.0065,  0.0223,  0.0047]],\n",
            "\n",
            "         [[ 0.0165, -0.0215,  0.0520],\n",
            "          [-0.0438, -0.0154, -0.0185],\n",
            "          [-0.0012,  0.0539, -0.0542]],\n",
            "\n",
            "         [[ 0.0294,  0.0187, -0.0234],\n",
            "          [ 0.0244,  0.0481,  0.0672],\n",
            "          [-0.0100, -0.0477,  0.0354]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0134, -0.0125, -0.0260],\n",
            "          [-0.0299,  0.0121,  0.0122],\n",
            "          [-0.0525, -0.0131, -0.0469]],\n",
            "\n",
            "         [[ 0.0039,  0.0256, -0.0228],\n",
            "          [ 0.0170, -0.0026, -0.0413],\n",
            "          [ 0.0329,  0.0189, -0.0141]],\n",
            "\n",
            "         [[-0.0151, -0.0145, -0.0449],\n",
            "          [ 0.0039,  0.0094, -0.0355],\n",
            "          [ 0.0268,  0.0145, -0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0052,  0.0215,  0.0100],\n",
            "          [-0.0039,  0.0448,  0.0085],\n",
            "          [ 0.0734,  0.0120,  0.0126]],\n",
            "\n",
            "         [[ 0.0521, -0.0005,  0.0276],\n",
            "          [-0.0158,  0.0335,  0.0498],\n",
            "          [-0.0126,  0.0727, -0.0156]],\n",
            "\n",
            "         [[-0.0998, -0.0048,  0.0272],\n",
            "          [-0.0034,  0.0141,  0.0077],\n",
            "          [ 0.0203, -0.0094,  0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0272,  0.0455, -0.0812],\n",
            "          [ 0.0325,  0.0141,  0.0399],\n",
            "          [ 0.0117,  0.0029,  0.0020]],\n",
            "\n",
            "         [[-0.0203, -0.0459,  0.0109],\n",
            "          [ 0.0452, -0.0026,  0.0010],\n",
            "          [ 0.0003, -0.0345, -0.0043]],\n",
            "\n",
            "         [[-0.0413, -0.0033, -0.0667],\n",
            "          [-0.0121, -0.0124, -0.0042],\n",
            "          [-0.0197, -0.0158,  0.0031]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0072,  0.0461,  0.0095],\n",
            "          [-0.0013,  0.0059, -0.0221],\n",
            "          [-0.0396,  0.0050, -0.0216]],\n",
            "\n",
            "         [[ 0.0043, -0.0269, -0.0075],\n",
            "          [ 0.0044, -0.0500, -0.0524],\n",
            "          [-0.0131,  0.0083,  0.0448]],\n",
            "\n",
            "         [[ 0.0147, -0.0036,  0.0378],\n",
            "          [-0.0350, -0.0124, -0.0100],\n",
            "          [-0.0219, -0.0230, -0.0448]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0114, -0.0230,  0.0363],\n",
            "          [ 0.0042, -0.0237,  0.0023],\n",
            "          [-0.0379,  0.0189,  0.0090]],\n",
            "\n",
            "         [[ 0.0151,  0.0036, -0.0057],\n",
            "          [-0.0053,  0.0030,  0.0486],\n",
            "          [ 0.0136,  0.0249,  0.0402]],\n",
            "\n",
            "         [[ 0.0108, -0.0105,  0.0003],\n",
            "          [-0.0175,  0.0449, -0.0467],\n",
            "          [ 0.0103,  0.0106,  0.0008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0437, -0.0165, -0.0123],\n",
            "          [ 0.0187, -0.0420, -0.0154],\n",
            "          [ 0.0508, -0.0394, -0.0162]],\n",
            "\n",
            "         [[ 0.0202, -0.0033,  0.0333],\n",
            "          [-0.0191, -0.0061,  0.0133],\n",
            "          [-0.0239, -0.0229,  0.0214]],\n",
            "\n",
            "         [[ 0.0463,  0.0008,  0.0137],\n",
            "          [-0.0088,  0.0123, -0.0059],\n",
            "          [-0.0055, -0.0631, -0.0345]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0030, -0.0097,  0.0106],\n",
            "          [ 0.0060, -0.0005, -0.0054],\n",
            "          [-0.0397,  0.0170,  0.0177]],\n",
            "\n",
            "         [[-0.0287, -0.0639, -0.0053],\n",
            "          [ 0.0037, -0.0585, -0.0272],\n",
            "          [ 0.0076, -0.0113,  0.0544]],\n",
            "\n",
            "         [[-0.0519,  0.0067,  0.0457],\n",
            "          [ 0.0775, -0.0114,  0.0120],\n",
            "          [-0.0241, -0.0231,  0.0114]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0041, -0.0243,  0.0234],\n",
            "          [ 0.0091,  0.0364, -0.0146],\n",
            "          [-0.0123, -0.0127,  0.0271]],\n",
            "\n",
            "         [[-0.0203, -0.0301,  0.0107],\n",
            "          [-0.0191,  0.0026,  0.0096],\n",
            "          [-0.0156, -0.0539,  0.0371]],\n",
            "\n",
            "         [[ 0.0344,  0.0038, -0.0109],\n",
            "          [-0.0147,  0.0592, -0.0123],\n",
            "          [-0.0229, -0.0084, -0.0109]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0335,  0.0209,  0.0526],\n",
            "          [-0.0490, -0.0254,  0.0236],\n",
            "          [ 0.0111, -0.0114,  0.0162]],\n",
            "\n",
            "         [[-0.0454,  0.0177, -0.0170],\n",
            "          [ 0.0010, -0.0315, -0.0019],\n",
            "          [-0.0272, -0.0231,  0.0362]],\n",
            "\n",
            "         [[ 0.0032, -0.0265, -0.0161],\n",
            "          [-0.0130, -0.0284,  0.0087],\n",
            "          [ 0.0304, -0.0663, -0.0237]]]])), ('module.encoder_q.layer3.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.2.conv3.weight', tensor([[[[ 8.7330e-02]],\n",
            "\n",
            "         [[ 1.8150e-02]],\n",
            "\n",
            "         [[-3.7326e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.9561e-02]],\n",
            "\n",
            "         [[-3.0356e-02]],\n",
            "\n",
            "         [[-1.5931e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2362e-02]],\n",
            "\n",
            "         [[-4.6797e-02]],\n",
            "\n",
            "         [[ 4.0196e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.9174e-02]],\n",
            "\n",
            "         [[-3.8268e-02]],\n",
            "\n",
            "         [[-1.2184e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.0946e-02]],\n",
            "\n",
            "         [[ 3.2996e-02]],\n",
            "\n",
            "         [[ 4.6675e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8309e-02]],\n",
            "\n",
            "         [[ 1.0863e-02]],\n",
            "\n",
            "         [[-9.7164e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.7940e-02]],\n",
            "\n",
            "         [[-5.3418e-02]],\n",
            "\n",
            "         [[ 4.0627e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8222e-02]],\n",
            "\n",
            "         [[-6.7527e-02]],\n",
            "\n",
            "         [[-3.9943e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5668e-03]],\n",
            "\n",
            "         [[ 3.1713e-03]],\n",
            "\n",
            "         [[-1.7004e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2723e-03]],\n",
            "\n",
            "         [[ 9.0465e-02]],\n",
            "\n",
            "         [[ 2.6719e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9085e-02]],\n",
            "\n",
            "         [[-4.1878e-05]],\n",
            "\n",
            "         [[ 1.9438e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1368e-02]],\n",
            "\n",
            "         [[ 6.1185e-02]],\n",
            "\n",
            "         [[-4.8456e-02]]]])), ('module.encoder_q.layer3.2.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.2.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.3.conv1.weight', tensor([[[[ 0.0106]],\n",
            "\n",
            "         [[-0.0747]],\n",
            "\n",
            "         [[ 0.1107]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0489]],\n",
            "\n",
            "         [[ 0.0715]],\n",
            "\n",
            "         [[-0.0667]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0502]],\n",
            "\n",
            "         [[ 0.0354]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1239]],\n",
            "\n",
            "         [[ 0.1164]],\n",
            "\n",
            "         [[-0.0048]]],\n",
            "\n",
            "\n",
            "        [[[-0.0058]],\n",
            "\n",
            "         [[ 0.0650]],\n",
            "\n",
            "         [[-0.1496]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1950]],\n",
            "\n",
            "         [[ 0.0182]],\n",
            "\n",
            "         [[-0.0900]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1352]],\n",
            "\n",
            "         [[-0.2122]],\n",
            "\n",
            "         [[-0.0060]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1065]],\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         [[-0.0944]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0566]],\n",
            "\n",
            "         [[ 0.0987]],\n",
            "\n",
            "         [[ 0.1623]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0158]],\n",
            "\n",
            "         [[-0.1581]],\n",
            "\n",
            "         [[-0.0340]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0085]],\n",
            "\n",
            "         [[-0.0855]],\n",
            "\n",
            "         [[-0.0304]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0025]],\n",
            "\n",
            "         [[ 0.0801]],\n",
            "\n",
            "         [[-0.0548]]]])), ('module.encoder_q.layer3.3.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.3.conv2.weight', tensor([[[[ 2.3732e-02, -1.5593e-02,  1.1678e-02],\n",
            "          [-5.4454e-03, -7.3257e-02,  4.1764e-02],\n",
            "          [-4.7421e-02,  5.0688e-02,  2.8520e-04]],\n",
            "\n",
            "         [[-3.2251e-02,  1.4166e-02,  1.9641e-02],\n",
            "          [-3.1768e-03,  2.6278e-02,  3.7000e-02],\n",
            "          [-6.4823e-02,  4.0941e-02,  1.6621e-02]],\n",
            "\n",
            "         [[ 5.8608e-02, -5.1863e-03, -4.0947e-03],\n",
            "          [-1.4858e-02, -3.2162e-02,  3.3937e-02],\n",
            "          [-5.2022e-03,  2.4755e-02,  2.1484e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7701e-02, -7.8604e-03, -3.1996e-02],\n",
            "          [-4.6200e-02, -3.9020e-02,  8.4957e-05],\n",
            "          [-1.1204e-02, -1.2654e-02, -5.2672e-03]],\n",
            "\n",
            "         [[-3.5223e-02, -5.3915e-02,  2.3004e-02],\n",
            "          [-1.0993e-02,  2.0502e-02, -8.6021e-03],\n",
            "          [ 7.0887e-03,  2.8324e-03, -6.1497e-02]],\n",
            "\n",
            "         [[-5.4516e-03, -1.0753e-02,  1.9851e-02],\n",
            "          [ 3.3721e-03,  2.9858e-02, -1.7922e-03],\n",
            "          [-1.2642e-02, -3.6905e-04,  6.3297e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9347e-02,  1.9499e-02,  2.1435e-02],\n",
            "          [ 1.5802e-02,  9.2978e-04, -1.9972e-02],\n",
            "          [-6.1844e-02, -1.5045e-02,  6.0212e-02]],\n",
            "\n",
            "         [[ 6.2442e-03,  7.2824e-02, -8.0176e-03],\n",
            "          [ 1.8436e-02,  2.5399e-02, -1.4074e-02],\n",
            "          [-2.0551e-02, -2.8144e-02, -8.5662e-03]],\n",
            "\n",
            "         [[-7.5520e-03,  1.3732e-02,  2.5948e-02],\n",
            "          [-5.3264e-03, -2.5864e-02, -1.2898e-02],\n",
            "          [-7.7851e-03,  5.7545e-03,  1.1646e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9417e-02, -7.6236e-03,  9.8140e-03],\n",
            "          [-2.7307e-02,  8.3805e-03, -2.4744e-02],\n",
            "          [-2.2565e-03, -2.4605e-02, -9.5554e-03]],\n",
            "\n",
            "         [[-1.4980e-02,  2.3043e-02, -1.0219e-02],\n",
            "          [ 5.2415e-02,  1.8503e-02, -1.7898e-02],\n",
            "          [-4.1631e-02,  8.4491e-03,  6.4376e-04]],\n",
            "\n",
            "         [[-3.7732e-03, -1.8132e-02, -3.2454e-02],\n",
            "          [-3.3283e-02,  5.9590e-03, -1.0538e-02],\n",
            "          [-1.0680e-02, -3.2789e-02,  1.7172e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7386e-02,  1.2469e-02, -6.8572e-04],\n",
            "          [ 3.2313e-02,  8.9345e-03,  6.6208e-02],\n",
            "          [-2.8205e-02,  1.6004e-02, -2.2782e-02]],\n",
            "\n",
            "         [[-3.5977e-02, -5.5905e-02,  2.1250e-02],\n",
            "          [-3.7974e-02, -5.5258e-02, -1.9676e-02],\n",
            "          [ 1.3267e-02, -4.1506e-02, -6.7810e-02]],\n",
            "\n",
            "         [[ 1.1042e-03,  2.6430e-02,  6.8759e-02],\n",
            "          [ 3.2589e-03, -1.5611e-02,  6.7705e-02],\n",
            "          [ 3.4563e-02, -8.5563e-03,  3.4557e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2739e-02, -2.3634e-02, -5.2943e-02],\n",
            "          [ 2.3409e-02, -5.7300e-02,  4.8073e-02],\n",
            "          [-9.7026e-03,  2.4309e-03,  4.3754e-03]],\n",
            "\n",
            "         [[ 3.4525e-02, -7.9031e-03,  3.2685e-03],\n",
            "          [-3.0254e-02, -4.2163e-02,  3.3051e-02],\n",
            "          [ 5.2238e-03, -5.5978e-03,  3.1332e-02]],\n",
            "\n",
            "         [[-1.8831e-02, -3.1148e-03, -1.7265e-02],\n",
            "          [ 3.1696e-02,  2.7305e-02, -2.8414e-02],\n",
            "          [-3.3642e-02, -2.8114e-03, -7.8746e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.7127e-02, -1.3488e-02, -4.0076e-02],\n",
            "          [ 2.9296e-02, -5.2778e-02, -7.7201e-03],\n",
            "          [ 4.3360e-02, -1.5603e-02, -2.5685e-02]],\n",
            "\n",
            "         [[ 5.2682e-02,  2.9663e-02, -1.5212e-02],\n",
            "          [ 2.3712e-02,  9.6656e-03, -2.3161e-02],\n",
            "          [ 3.2293e-02, -4.1549e-02,  5.6114e-02]],\n",
            "\n",
            "         [[ 3.9051e-02, -4.3433e-02,  1.3252e-02],\n",
            "          [ 3.5322e-02,  2.5708e-02,  1.8754e-02],\n",
            "          [-1.0086e-02,  2.3038e-02, -3.9194e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.9949e-02, -2.0227e-02, -1.7385e-03],\n",
            "          [ 5.3137e-03, -9.6847e-02, -6.8197e-02],\n",
            "          [ 6.7398e-03,  1.3202e-02,  4.9642e-02]],\n",
            "\n",
            "         [[ 1.7395e-03,  4.3736e-03, -4.8616e-02],\n",
            "          [ 3.2420e-02,  6.2609e-02,  7.4321e-02],\n",
            "          [-1.2509e-02,  1.2482e-02,  4.2508e-02]],\n",
            "\n",
            "         [[-2.2197e-02, -3.9564e-02,  5.0979e-03],\n",
            "          [ 2.1141e-02,  3.1019e-02,  4.0500e-05],\n",
            "          [ 1.1919e-02,  1.9278e-02,  3.7940e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.5047e-02,  7.2339e-04, -1.4314e-02],\n",
            "          [ 3.1569e-02,  1.8815e-02, -1.3703e-02],\n",
            "          [ 1.8622e-02, -6.1251e-02,  3.2271e-03]],\n",
            "\n",
            "         [[-4.3960e-02,  1.1834e-02, -7.2148e-03],\n",
            "          [-2.8679e-02, -7.3731e-03, -9.6342e-03],\n",
            "          [ 4.7729e-02, -3.2625e-02, -9.0215e-03]],\n",
            "\n",
            "         [[-5.0980e-02,  6.6582e-03,  1.0131e-02],\n",
            "          [ 1.3340e-02,  1.7635e-02,  1.0425e-03],\n",
            "          [-6.0471e-02,  1.6080e-02, -4.1475e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7050e-03,  4.7610e-02,  3.4454e-02],\n",
            "          [-1.9878e-02,  6.3343e-02, -4.0136e-02],\n",
            "          [-2.0662e-03,  6.2416e-05, -2.7687e-02]],\n",
            "\n",
            "         [[ 9.0488e-03,  1.2649e-02, -8.6824e-03],\n",
            "          [-9.5001e-03, -2.0791e-02,  3.5548e-02],\n",
            "          [ 3.1303e-02, -2.0169e-03, -2.5569e-02]],\n",
            "\n",
            "         [[-2.7612e-03,  7.8085e-03,  1.4336e-02],\n",
            "          [-3.8492e-03,  4.5317e-03, -1.1357e-02],\n",
            "          [ 3.9413e-03,  3.0328e-02, -3.1430e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2665e-02,  2.2151e-02, -3.8377e-02],\n",
            "          [-5.1898e-02,  2.1006e-02, -4.3976e-02],\n",
            "          [ 1.6070e-02, -1.7512e-02,  8.7686e-03]],\n",
            "\n",
            "         [[ 1.2831e-02, -2.3482e-02, -7.7172e-02],\n",
            "          [ 5.6686e-02, -1.3040e-02,  1.1819e-02],\n",
            "          [-2.9326e-02,  3.2904e-02,  3.0136e-02]],\n",
            "\n",
            "         [[ 8.9100e-03,  2.7034e-02,  3.1578e-02],\n",
            "          [-1.5928e-02, -1.8973e-02, -3.4173e-03],\n",
            "          [ 1.9817e-02,  6.5007e-02,  5.0847e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8451e-02, -8.4973e-04, -2.4299e-02],\n",
            "          [-1.5435e-02,  2.4706e-02, -2.8424e-02],\n",
            "          [-2.8462e-02, -2.1828e-02,  4.1044e-02]],\n",
            "\n",
            "         [[-9.3262e-03, -1.2199e-02, -2.8219e-02],\n",
            "          [-9.3040e-03,  1.5445e-02,  8.1939e-03],\n",
            "          [ 2.0456e-02,  1.8526e-02,  6.8105e-03]],\n",
            "\n",
            "         [[-3.2708e-02,  3.1330e-02,  1.4906e-02],\n",
            "          [ 2.7782e-03, -6.4040e-02,  1.6050e-02],\n",
            "          [-6.7987e-02,  7.6307e-03,  2.2476e-02]]]])), ('module.encoder_q.layer3.3.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.3.conv3.weight', tensor([[[[ 0.0196]],\n",
            "\n",
            "         [[-0.0302]],\n",
            "\n",
            "         [[-0.0862]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         [[-0.0122]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0399]],\n",
            "\n",
            "         [[-0.0524]],\n",
            "\n",
            "         [[-0.0882]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0732]],\n",
            "\n",
            "         [[-0.0345]],\n",
            "\n",
            "         [[-0.0184]]],\n",
            "\n",
            "\n",
            "        [[[-0.1086]],\n",
            "\n",
            "         [[-0.0271]],\n",
            "\n",
            "         [[-0.0176]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0346]],\n",
            "\n",
            "         [[ 0.0667]],\n",
            "\n",
            "         [[ 0.0071]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0578]],\n",
            "\n",
            "         [[ 0.0352]],\n",
            "\n",
            "         [[-0.0026]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0163]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[-0.0598]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0192]],\n",
            "\n",
            "         [[-0.0185]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0390]],\n",
            "\n",
            "         [[ 0.0543]],\n",
            "\n",
            "         [[-0.0640]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0416]],\n",
            "\n",
            "         [[-0.0424]],\n",
            "\n",
            "         [[-0.0597]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         [[ 0.0494]],\n",
            "\n",
            "         [[ 0.0014]]]])), ('module.encoder_q.layer3.3.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.3.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.3.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.4.conv1.weight', tensor([[[[ 0.0799]],\n",
            "\n",
            "         [[-0.0296]],\n",
            "\n",
            "         [[-0.0306]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1074]],\n",
            "\n",
            "         [[-0.0672]],\n",
            "\n",
            "         [[ 0.1173]]],\n",
            "\n",
            "\n",
            "        [[[-0.0271]],\n",
            "\n",
            "         [[-0.0502]],\n",
            "\n",
            "         [[ 0.0263]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         [[-0.1001]],\n",
            "\n",
            "         [[-0.0853]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1534]],\n",
            "\n",
            "         [[ 0.1222]],\n",
            "\n",
            "         [[ 0.2072]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0918]],\n",
            "\n",
            "         [[ 0.0631]],\n",
            "\n",
            "         [[-0.0900]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0545]],\n",
            "\n",
            "         [[ 0.0312]],\n",
            "\n",
            "         [[ 0.1165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3064]],\n",
            "\n",
            "         [[-0.0094]],\n",
            "\n",
            "         [[-0.1112]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1367]],\n",
            "\n",
            "         [[ 0.1480]],\n",
            "\n",
            "         [[ 0.1162]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0068]],\n",
            "\n",
            "         [[-0.0569]],\n",
            "\n",
            "         [[ 0.0480]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[ 0.0227]],\n",
            "\n",
            "         [[ 0.0858]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[ 0.0481]],\n",
            "\n",
            "         [[-0.0725]]]])), ('module.encoder_q.layer3.4.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.4.conv2.weight', tensor([[[[ 7.3338e-03,  1.9373e-02,  1.9707e-02],\n",
            "          [-2.1532e-02,  3.3052e-02,  3.8693e-03],\n",
            "          [ 4.9842e-02,  1.1481e-02, -1.8720e-02]],\n",
            "\n",
            "         [[-4.4669e-03, -1.9365e-02,  2.7681e-02],\n",
            "          [-3.4476e-02,  3.0804e-02,  2.4409e-02],\n",
            "          [ 6.7232e-02,  4.8196e-02, -2.9887e-02]],\n",
            "\n",
            "         [[-2.9078e-02,  2.1809e-03, -3.0370e-02],\n",
            "          [ 1.8337e-02,  6.7131e-02, -2.2435e-02],\n",
            "          [ 6.6499e-03, -2.2528e-02,  1.3491e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5089e-02, -2.4167e-02, -2.0454e-03],\n",
            "          [-1.8794e-02, -5.5745e-03,  2.6232e-02],\n",
            "          [-4.9493e-02, -5.8282e-03, -2.5210e-02]],\n",
            "\n",
            "         [[ 2.2521e-02,  9.8507e-03, -2.4652e-02],\n",
            "          [-2.0316e-02,  3.1309e-02,  4.9494e-02],\n",
            "          [ 1.4034e-02, -3.7115e-02,  2.3547e-02]],\n",
            "\n",
            "         [[-1.1358e-03,  3.5542e-04, -1.2628e-03],\n",
            "          [-1.6295e-02, -1.1953e-02, -1.4556e-02],\n",
            "          [ 1.0524e-02, -5.7744e-02, -4.0654e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2436e-02,  3.2009e-02,  6.1339e-02],\n",
            "          [ 8.0088e-03,  5.2708e-02,  2.2592e-02],\n",
            "          [ 2.7179e-02,  5.4765e-02, -1.7246e-02]],\n",
            "\n",
            "         [[-5.5990e-03,  4.9686e-03,  2.7578e-02],\n",
            "          [ 4.8319e-03, -1.5796e-03, -2.1701e-02],\n",
            "          [-1.9010e-04, -1.3032e-02, -1.1791e-02]],\n",
            "\n",
            "         [[ 2.0560e-02, -3.8087e-03,  7.5032e-03],\n",
            "          [-2.0210e-02,  2.4846e-02, -2.5836e-02],\n",
            "          [ 3.7694e-02, -4.5862e-02, -6.7203e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2206e-02, -3.1616e-02,  1.6677e-02],\n",
            "          [ 7.6647e-03, -5.9905e-03,  1.3925e-02],\n",
            "          [ 1.1554e-02,  1.2417e-02, -5.2968e-02]],\n",
            "\n",
            "         [[ 1.6572e-02, -2.4887e-03,  3.1444e-02],\n",
            "          [-4.7708e-03,  1.3446e-02,  7.4763e-02],\n",
            "          [ 5.2145e-02, -2.1992e-02,  2.6994e-02]],\n",
            "\n",
            "         [[-1.3365e-02, -4.1066e-02,  3.8403e-03],\n",
            "          [ 3.1768e-02,  2.6510e-02,  4.0382e-03],\n",
            "          [-4.7060e-03, -4.0799e-02,  6.2538e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1928e-02,  4.6622e-03,  1.2519e-02],\n",
            "          [ 9.7049e-03,  2.6652e-02, -1.2445e-02],\n",
            "          [ 2.8512e-02,  7.0706e-03,  8.5247e-03]],\n",
            "\n",
            "         [[ 5.4512e-03,  2.0676e-02,  2.9383e-02],\n",
            "          [-2.1671e-02,  1.8166e-03,  3.6396e-02],\n",
            "          [ 2.3776e-03,  3.2034e-02, -3.0996e-02]],\n",
            "\n",
            "         [[ 1.6800e-02, -1.1749e-02, -1.1074e-02],\n",
            "          [-4.0777e-02,  3.5455e-02,  1.4780e-02],\n",
            "          [ 2.1859e-02, -3.9251e-03,  3.2919e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7828e-02,  1.0827e-05,  1.9743e-06],\n",
            "          [-1.9438e-02,  3.9270e-02,  9.7671e-03],\n",
            "          [ 3.0816e-02, -7.8504e-03,  3.0842e-03]],\n",
            "\n",
            "         [[-2.8241e-02, -4.5488e-02,  5.5693e-02],\n",
            "          [ 1.2261e-02, -2.2980e-02,  2.0408e-02],\n",
            "          [ 2.0188e-02,  7.4564e-02,  3.4933e-02]],\n",
            "\n",
            "         [[-2.7857e-02,  5.7332e-02, -7.4515e-03],\n",
            "          [-3.1164e-02, -5.1421e-02,  2.6589e-02],\n",
            "          [ 4.6449e-03, -3.9002e-02, -1.3897e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.5883e-02, -2.0598e-02, -1.4898e-02],\n",
            "          [-2.8440e-02,  4.8448e-03, -5.1242e-02],\n",
            "          [-5.1865e-02,  3.6375e-02, -1.8724e-02]],\n",
            "\n",
            "         [[-5.4636e-03,  5.8682e-02, -3.4376e-03],\n",
            "          [-1.2862e-02,  5.4607e-02, -1.1043e-02],\n",
            "          [ 3.0432e-03, -1.9293e-02, -5.6977e-04]],\n",
            "\n",
            "         [[-3.0361e-02, -5.6498e-02, -3.7615e-02],\n",
            "          [-2.0395e-02,  5.2192e-03, -4.0035e-03],\n",
            "          [-4.6382e-02, -2.7645e-02, -3.2080e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6264e-02,  4.3974e-03,  5.9875e-02],\n",
            "          [-1.9964e-02,  2.3373e-02,  1.3863e-02],\n",
            "          [ 5.4157e-02, -6.6494e-04,  3.0034e-02]],\n",
            "\n",
            "         [[ 1.9180e-02,  2.3389e-02, -3.8610e-03],\n",
            "          [-8.3238e-02,  4.8742e-02,  5.2547e-02],\n",
            "          [-1.2360e-02,  1.8731e-02,  3.9457e-02]],\n",
            "\n",
            "         [[ 4.5196e-02,  2.6556e-02, -1.0691e-02],\n",
            "          [-4.0563e-02, -1.7030e-02,  4.0822e-03],\n",
            "          [ 3.1594e-02, -2.4108e-02,  5.5873e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4277e-02, -3.7920e-03, -4.5502e-02],\n",
            "          [ 2.4866e-02,  4.6103e-02, -1.8280e-02],\n",
            "          [-2.1839e-02, -1.2583e-02,  3.2019e-03]],\n",
            "\n",
            "         [[-1.9080e-02, -1.4795e-03, -6.8670e-02],\n",
            "          [ 2.6803e-02,  3.2726e-02, -2.3882e-02],\n",
            "          [-8.9142e-03,  1.1211e-02, -2.6944e-02]],\n",
            "\n",
            "         [[-2.7137e-02, -8.7176e-04,  6.0583e-02],\n",
            "          [-1.8364e-02, -3.9713e-02,  3.0423e-02],\n",
            "          [ 1.0112e-02,  1.7569e-02, -3.2467e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7712e-02,  3.1637e-02, -4.1139e-02],\n",
            "          [ 2.4305e-02, -3.3765e-02, -4.2754e-02],\n",
            "          [-3.1040e-02, -2.4065e-02, -2.4195e-02]],\n",
            "\n",
            "         [[-1.1691e-02, -1.6935e-02, -3.4363e-02],\n",
            "          [-7.1964e-02,  1.9702e-02,  5.0091e-02],\n",
            "          [-4.8034e-02,  1.9559e-02,  1.8886e-02]],\n",
            "\n",
            "         [[-3.0133e-02, -4.1614e-02,  2.3148e-02],\n",
            "          [-1.0256e-03,  2.5346e-02,  2.7380e-02],\n",
            "          [-2.7163e-02, -5.9948e-02,  3.5772e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2613e-02, -8.2736e-03, -1.3233e-02],\n",
            "          [ 1.3102e-02,  9.8061e-03, -1.5685e-02],\n",
            "          [-1.8228e-02, -3.6573e-03, -3.1424e-02]],\n",
            "\n",
            "         [[-1.9826e-02,  1.5436e-02,  2.0194e-02],\n",
            "          [ 3.3407e-02, -2.4175e-02,  3.7801e-02],\n",
            "          [-1.5570e-02, -1.7875e-02, -3.9777e-02]],\n",
            "\n",
            "         [[-2.8840e-03, -8.4796e-03, -4.2131e-02],\n",
            "          [-4.1780e-02,  1.7280e-02,  2.9073e-02],\n",
            "          [-1.2562e-02,  1.5958e-02, -6.5201e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5029e-03, -2.3417e-02, -8.4006e-03],\n",
            "          [-5.1869e-02, -1.0626e-02, -6.8510e-03],\n",
            "          [ 1.2352e-02, -3.8892e-02,  1.0894e-02]],\n",
            "\n",
            "         [[ 2.6845e-03,  2.3776e-02,  2.6875e-02],\n",
            "          [ 3.8813e-03,  2.6486e-03,  2.1920e-02],\n",
            "          [ 2.8081e-02, -6.7758e-02,  2.8913e-02]],\n",
            "\n",
            "         [[-1.5596e-02, -1.3100e-02, -6.2818e-03],\n",
            "          [-8.4096e-03, -2.2520e-02,  1.0863e-02],\n",
            "          [ 1.2086e-02,  1.9446e-02, -1.4481e-02]]]])), ('module.encoder_q.layer3.4.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.4.conv3.weight', tensor([[[[ 0.0591]],\n",
            "\n",
            "         [[-0.0245]],\n",
            "\n",
            "         [[ 0.0028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         [[ 0.0369]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0241]],\n",
            "\n",
            "         [[ 0.0255]],\n",
            "\n",
            "         [[-0.0615]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0379]],\n",
            "\n",
            "         [[ 0.0380]],\n",
            "\n",
            "         [[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0351]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         [[ 0.0018]],\n",
            "\n",
            "         [[-0.0682]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0098]],\n",
            "\n",
            "         [[-0.0784]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0286]],\n",
            "\n",
            "         [[-0.0435]],\n",
            "\n",
            "         [[-0.0261]]],\n",
            "\n",
            "\n",
            "        [[[-0.0007]],\n",
            "\n",
            "         [[-0.0155]],\n",
            "\n",
            "         [[-0.0395]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0143]],\n",
            "\n",
            "         [[-0.0031]],\n",
            "\n",
            "         [[-0.0070]]],\n",
            "\n",
            "\n",
            "        [[[-0.0179]],\n",
            "\n",
            "         [[-0.0476]],\n",
            "\n",
            "         [[ 0.0652]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0597]],\n",
            "\n",
            "         [[-0.0157]]]])), ('module.encoder_q.layer3.4.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.4.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.4.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.5.conv1.weight', tensor([[[[ 0.0311]],\n",
            "\n",
            "         [[-0.1026]],\n",
            "\n",
            "         [[-0.0805]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0174]],\n",
            "\n",
            "         [[ 0.0507]],\n",
            "\n",
            "         [[ 0.0129]]],\n",
            "\n",
            "\n",
            "        [[[-0.0657]],\n",
            "\n",
            "         [[ 0.1879]],\n",
            "\n",
            "         [[ 0.0184]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0172]],\n",
            "\n",
            "         [[-0.1596]],\n",
            "\n",
            "         [[ 0.0704]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0384]],\n",
            "\n",
            "         [[-0.1039]],\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0151]],\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         [[ 0.0039]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0008]],\n",
            "\n",
            "         [[-0.1391]],\n",
            "\n",
            "         [[ 0.0889]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0930]],\n",
            "\n",
            "         [[ 0.1101]],\n",
            "\n",
            "         [[-0.1277]]],\n",
            "\n",
            "\n",
            "        [[[-0.0543]],\n",
            "\n",
            "         [[-0.0452]],\n",
            "\n",
            "         [[-0.1099]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2051]],\n",
            "\n",
            "         [[ 0.1050]],\n",
            "\n",
            "         [[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[-0.0711]],\n",
            "\n",
            "         [[-0.1662]],\n",
            "\n",
            "         [[-0.0603]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1026]],\n",
            "\n",
            "         [[-0.0911]],\n",
            "\n",
            "         [[-0.0779]]]])), ('module.encoder_q.layer3.5.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.5.conv2.weight', tensor([[[[ 9.0440e-02,  2.0534e-02, -7.7406e-03],\n",
            "          [ 2.8284e-03,  4.9834e-02, -2.4910e-02],\n",
            "          [ 4.5202e-02, -6.1041e-03, -1.2747e-02]],\n",
            "\n",
            "         [[-2.1289e-02, -2.5111e-02, -1.7840e-02],\n",
            "          [-6.7436e-02,  3.6001e-02,  3.3544e-02],\n",
            "          [ 1.0144e-03, -2.8867e-02,  9.5248e-02]],\n",
            "\n",
            "         [[-2.1593e-02, -2.9160e-02, -7.8151e-03],\n",
            "          [-4.5436e-03,  1.7428e-02, -1.1323e-02],\n",
            "          [-2.9771e-02,  2.1989e-02,  2.3313e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8566e-03, -4.8792e-03, -1.4691e-03],\n",
            "          [ 5.8666e-03, -1.8188e-02,  9.4425e-03],\n",
            "          [-3.2236e-04,  3.7093e-02, -5.2100e-03]],\n",
            "\n",
            "         [[ 5.4807e-03,  3.6524e-02, -2.6637e-02],\n",
            "          [-9.7260e-03, -2.5284e-03,  2.2978e-02],\n",
            "          [-1.2457e-02,  2.0358e-02,  9.4651e-03]],\n",
            "\n",
            "         [[-1.3539e-02,  2.7713e-02, -2.6751e-02],\n",
            "          [ 7.9041e-02, -6.8605e-04,  8.7066e-03],\n",
            "          [ 3.2171e-02,  1.1949e-02, -2.6947e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7576e-02,  6.2860e-03, -1.6077e-02],\n",
            "          [-2.1336e-03, -3.3161e-02, -2.5050e-02],\n",
            "          [ 2.9323e-03,  2.7131e-02, -4.6799e-02]],\n",
            "\n",
            "         [[ 2.5350e-02, -6.8396e-02,  4.2902e-02],\n",
            "          [ 2.6301e-02,  1.4769e-02,  1.3784e-02],\n",
            "          [ 1.4025e-02,  3.7343e-02, -1.1796e-02]],\n",
            "\n",
            "         [[-4.9172e-02,  2.6133e-03, -3.6964e-02],\n",
            "          [ 3.0517e-02,  3.0161e-02,  5.6012e-03],\n",
            "          [ 4.1809e-03,  2.2845e-02, -9.0767e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9861e-02,  3.4645e-03, -2.5882e-05],\n",
            "          [ 3.2645e-02, -1.5918e-02,  4.2310e-03],\n",
            "          [ 7.5870e-03,  5.6676e-02, -1.2210e-02]],\n",
            "\n",
            "         [[ 3.5530e-03,  2.3748e-02,  3.7409e-02],\n",
            "          [ 3.2672e-03,  2.1271e-02, -1.0553e-02],\n",
            "          [ 1.3351e-02,  4.8374e-02,  6.1318e-02]],\n",
            "\n",
            "         [[-1.3426e-02, -2.4830e-02,  3.1365e-02],\n",
            "          [-1.3926e-02, -5.5849e-03,  1.7786e-02],\n",
            "          [-3.2056e-03,  6.4852e-02, -5.9317e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1134e-03,  8.0173e-03,  4.2754e-04],\n",
            "          [ 6.9294e-03,  3.0562e-02, -2.0753e-02],\n",
            "          [-2.2630e-02,  3.1358e-02, -1.6587e-02]],\n",
            "\n",
            "         [[-1.0962e-02, -1.6781e-02, -7.3434e-05],\n",
            "          [-8.0097e-04,  4.2661e-03,  2.4255e-02],\n",
            "          [-1.0004e-02,  4.0777e-03,  1.5919e-02]],\n",
            "\n",
            "         [[-1.2314e-02,  5.5724e-02, -6.2577e-03],\n",
            "          [-1.5044e-02,  2.6860e-02, -1.1038e-02],\n",
            "          [ 3.3670e-02, -1.1752e-02, -1.9094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1297e-02,  1.3522e-02, -3.2208e-02],\n",
            "          [-8.9566e-03, -1.9581e-02, -1.9526e-02],\n",
            "          [ 4.5077e-02,  1.1327e-02, -2.8326e-02]],\n",
            "\n",
            "         [[-1.1127e-02, -1.4566e-02, -2.0468e-02],\n",
            "          [ 1.6162e-02, -1.4077e-02, -1.3731e-02],\n",
            "          [-5.8856e-03,  6.9850e-02, -2.3763e-02]],\n",
            "\n",
            "         [[ 6.3726e-03,  3.0382e-03,  1.8988e-02],\n",
            "          [-3.2335e-03, -4.2224e-02, -2.7614e-02],\n",
            "          [-2.1357e-02,  8.9532e-03,  1.1307e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.9779e-02,  4.7866e-02, -1.4124e-03],\n",
            "          [ 1.9138e-02,  2.0259e-03, -2.4408e-04],\n",
            "          [-3.4522e-02,  5.6187e-03,  1.4601e-03]],\n",
            "\n",
            "         [[-4.5323e-03, -3.1312e-02, -1.5576e-02],\n",
            "          [-5.0370e-03, -2.0592e-02, -4.8158e-02],\n",
            "          [-3.3287e-02,  6.8144e-04,  1.8129e-02]],\n",
            "\n",
            "         [[ 2.8428e-02, -6.4925e-02,  2.6934e-02],\n",
            "          [ 4.8027e-02,  3.3632e-02,  4.3520e-02],\n",
            "          [-3.5167e-02, -6.8467e-02,  4.9150e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8043e-03, -7.1903e-02, -2.2077e-02],\n",
            "          [-2.9521e-02, -9.1072e-03,  2.9936e-02],\n",
            "          [-3.7952e-02, -1.4079e-02, -6.6847e-02]],\n",
            "\n",
            "         [[-1.0489e-02,  3.8752e-03, -8.1818e-02],\n",
            "          [ 1.0940e-02, -4.9740e-03, -6.2629e-03],\n",
            "          [ 2.2878e-02,  2.9969e-03, -5.6671e-03]],\n",
            "\n",
            "         [[-2.2620e-02, -2.6445e-02,  1.9574e-02],\n",
            "          [-2.8337e-04,  9.4012e-03, -1.1164e-02],\n",
            "          [-2.7370e-02,  4.5752e-04,  1.6665e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7664e-02, -2.3467e-02,  1.6995e-02],\n",
            "          [ 2.4366e-02, -4.9385e-03,  2.4229e-02],\n",
            "          [-1.8158e-02, -8.3595e-03, -6.2210e-02]],\n",
            "\n",
            "         [[-6.5096e-03, -2.6362e-02, -1.4052e-02],\n",
            "          [ 6.0626e-02, -1.0534e-02, -2.6178e-02],\n",
            "          [-1.1044e-03, -1.1587e-02, -5.7076e-04]],\n",
            "\n",
            "         [[ 2.7055e-02,  2.6492e-02,  6.9794e-02],\n",
            "          [-2.1124e-02,  1.6630e-03, -2.0191e-02],\n",
            "          [ 3.0975e-02, -2.7955e-02,  1.5355e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7466e-02,  5.0268e-02,  2.4323e-02],\n",
            "          [ 4.4811e-02,  3.7672e-03,  5.0753e-02],\n",
            "          [ 3.0597e-02, -2.6485e-02,  1.3060e-04]],\n",
            "\n",
            "         [[ 9.0979e-03, -3.6375e-02,  4.8779e-02],\n",
            "          [ 3.6125e-03,  5.0255e-03, -1.2534e-02],\n",
            "          [-3.3372e-02, -2.4967e-02,  2.5237e-03]],\n",
            "\n",
            "         [[ 2.9611e-02,  2.5255e-02,  2.0107e-02],\n",
            "          [ 2.9365e-03,  2.6167e-02, -2.4041e-02],\n",
            "          [ 2.0335e-02, -3.6483e-02,  7.8198e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3002e-02, -1.7374e-02,  9.7171e-03],\n",
            "          [-2.9202e-02, -1.3995e-03, -1.9644e-02],\n",
            "          [ 3.4119e-02,  1.2469e-02,  1.5316e-02]],\n",
            "\n",
            "         [[-1.3471e-02, -4.1007e-02, -9.1064e-03],\n",
            "          [-3.7565e-02,  1.9079e-02, -4.2723e-02],\n",
            "          [-4.0482e-02, -1.6124e-02,  2.3614e-02]],\n",
            "\n",
            "         [[-1.4701e-02, -1.8024e-02,  6.4676e-02],\n",
            "          [-4.4285e-02, -5.6837e-02, -2.2810e-02],\n",
            "          [-1.6795e-02, -1.4620e-03, -3.0532e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3792e-02,  1.3065e-02,  3.5286e-02],\n",
            "          [-4.8995e-02, -7.7605e-03, -1.6198e-02],\n",
            "          [-4.0200e-02, -2.0337e-03,  5.1502e-04]],\n",
            "\n",
            "         [[ 2.7279e-03,  4.0213e-02, -2.7145e-02],\n",
            "          [-1.7334e-02,  3.6952e-04,  7.1956e-03],\n",
            "          [-2.6340e-02,  1.3979e-02,  3.9511e-02]],\n",
            "\n",
            "         [[ 1.0842e-02, -1.5908e-02, -4.6484e-02],\n",
            "          [ 4.5240e-04,  3.8241e-04, -3.6206e-02],\n",
            "          [-3.5801e-02,  1.5203e-02, -1.7612e-02]]]])), ('module.encoder_q.layer3.5.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer3.5.conv3.weight', tensor([[[[-0.0345]],\n",
            "\n",
            "         [[ 0.0133]],\n",
            "\n",
            "         [[-0.0003]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0130]],\n",
            "\n",
            "         [[-0.0922]],\n",
            "\n",
            "         [[-0.0202]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0217]],\n",
            "\n",
            "         [[ 0.0492]],\n",
            "\n",
            "         [[ 0.0692]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0034]],\n",
            "\n",
            "         [[-0.0288]],\n",
            "\n",
            "         [[-0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0283]],\n",
            "\n",
            "         [[-0.0106]],\n",
            "\n",
            "         [[-0.0659]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0403]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.0135]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0396]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         [[ 0.0505]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[ 0.0138]],\n",
            "\n",
            "         [[-0.0799]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458]],\n",
            "\n",
            "         [[-0.0399]],\n",
            "\n",
            "         [[ 0.0443]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0192]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0061]]],\n",
            "\n",
            "\n",
            "        [[[-0.0401]],\n",
            "\n",
            "         [[ 0.0034]],\n",
            "\n",
            "         [[ 0.0205]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0270]],\n",
            "\n",
            "         [[ 0.0619]],\n",
            "\n",
            "         [[ 0.0519]]]])), ('module.encoder_q.layer3.5.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer3.5.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer3.5.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.0.conv1.weight', tensor([[[[ 0.0840]],\n",
            "\n",
            "         [[-0.0026]],\n",
            "\n",
            "         [[ 0.0714]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1042]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         [[ 0.0499]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1154]],\n",
            "\n",
            "         [[ 0.0465]],\n",
            "\n",
            "         [[-0.0511]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         [[ 0.0704]],\n",
            "\n",
            "         [[-0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1430]],\n",
            "\n",
            "         [[-0.0147]],\n",
            "\n",
            "         [[ 0.0401]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0937]],\n",
            "\n",
            "         [[-0.0057]],\n",
            "\n",
            "         [[ 0.0867]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0336]],\n",
            "\n",
            "         [[ 0.1140]],\n",
            "\n",
            "         [[-0.0714]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0301]],\n",
            "\n",
            "         [[ 0.1395]],\n",
            "\n",
            "         [[ 0.0135]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0646]],\n",
            "\n",
            "         [[-0.1104]],\n",
            "\n",
            "         [[ 0.0441]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1529]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         [[-0.0339]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0903]],\n",
            "\n",
            "         [[-0.0557]],\n",
            "\n",
            "         [[-0.0779]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0726]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[ 0.0010]]]])), ('module.encoder_q.layer4.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.0.conv2.weight', tensor([[[[ 6.5585e-03, -3.2748e-02,  1.4668e-02],\n",
            "          [ 2.2598e-02, -9.6221e-03, -1.6693e-02],\n",
            "          [ 3.8255e-02, -1.7218e-02,  4.2272e-03]],\n",
            "\n",
            "         [[ 1.4050e-02, -2.0900e-03, -2.1188e-03],\n",
            "          [ 6.9391e-03, -1.4407e-02, -6.0526e-03],\n",
            "          [-2.6982e-02,  8.1345e-03, -3.1335e-02]],\n",
            "\n",
            "         [[-8.4789e-03,  9.3633e-03, -3.0524e-02],\n",
            "          [ 8.5017e-03, -3.8445e-02,  5.5057e-03],\n",
            "          [ 2.6320e-02, -5.3213e-02, -1.8361e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.2976e-04,  1.1157e-03, -1.9025e-02],\n",
            "          [ 3.6225e-03,  1.9838e-02,  1.0335e-04],\n",
            "          [-1.9048e-02, -3.8563e-02,  1.9773e-02]],\n",
            "\n",
            "         [[ 9.7245e-03,  8.0973e-03,  2.8868e-02],\n",
            "          [ 8.7752e-04, -3.4818e-02, -1.2328e-02],\n",
            "          [ 1.3617e-02,  1.6038e-02, -3.6396e-02]],\n",
            "\n",
            "         [[-9.6424e-03, -1.6470e-03,  3.7932e-03],\n",
            "          [-9.1329e-04,  3.1398e-02, -2.9201e-02],\n",
            "          [ 2.1374e-02, -2.9768e-02, -9.4264e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2604e-02, -2.9150e-02,  4.5612e-02],\n",
            "          [ 5.2425e-03, -2.1961e-02, -2.1806e-03],\n",
            "          [ 2.8476e-02, -2.0675e-02,  1.5138e-02]],\n",
            "\n",
            "         [[ 1.5065e-02, -2.2665e-03,  2.0867e-02],\n",
            "          [ 4.6234e-03,  2.4643e-03, -8.6775e-04],\n",
            "          [-1.1015e-02, -2.7199e-02,  1.9833e-02]],\n",
            "\n",
            "         [[ 1.6576e-02, -8.4360e-03,  2.3408e-02],\n",
            "          [ 3.6334e-03, -2.4203e-02, -1.6086e-02],\n",
            "          [ 1.2978e-02,  6.4331e-03, -1.8426e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4435e-02, -3.3955e-02,  5.9870e-03],\n",
            "          [-3.2614e-02,  4.3992e-03, -1.5491e-02],\n",
            "          [ 9.7659e-03, -3.1873e-03, -4.1006e-02]],\n",
            "\n",
            "         [[-5.1243e-03,  1.1752e-02,  1.5294e-02],\n",
            "          [-1.2933e-02, -2.0291e-02,  4.8796e-03],\n",
            "          [-2.8228e-02,  3.1144e-03,  4.8573e-02]],\n",
            "\n",
            "         [[-3.9237e-02, -1.8004e-02,  1.8811e-02],\n",
            "          [-1.2395e-02,  5.9403e-03, -3.6181e-03],\n",
            "          [ 3.6783e-02,  1.7589e-03, -3.2825e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8778e-03, -7.3901e-03,  6.1089e-03],\n",
            "          [ 3.7169e-02,  6.9986e-03,  2.0635e-02],\n",
            "          [-2.6032e-02, -7.9848e-03, -3.8109e-02]],\n",
            "\n",
            "         [[ 2.1097e-02, -2.7189e-02, -1.8741e-03],\n",
            "          [ 1.9571e-02,  1.9764e-02,  2.7685e-03],\n",
            "          [-2.3287e-02, -1.5894e-02,  4.9156e-03]],\n",
            "\n",
            "         [[ 1.0963e-03,  2.8113e-02,  7.4703e-03],\n",
            "          [-1.4931e-02, -1.3069e-02,  3.8060e-02],\n",
            "          [-4.5288e-02,  2.6818e-03,  1.1763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2792e-03,  6.4174e-03, -2.1990e-02],\n",
            "          [-6.9425e-03, -1.6088e-02,  8.9639e-03],\n",
            "          [-5.3009e-03, -5.2146e-03,  1.8017e-02]],\n",
            "\n",
            "         [[-3.7953e-02,  2.2104e-03,  9.5364e-03],\n",
            "          [ 8.5368e-04, -1.2426e-03, -8.1243e-03],\n",
            "          [ 4.1929e-02,  4.7146e-03,  2.0462e-02]],\n",
            "\n",
            "         [[ 2.0886e-02, -8.3334e-03, -8.3462e-03],\n",
            "          [-1.1562e-02, -8.2201e-03,  4.7284e-03],\n",
            "          [ 4.9911e-03,  5.5469e-03,  7.3941e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3924e-02, -1.3986e-02, -1.1217e-02],\n",
            "          [ 3.1803e-02,  4.5202e-02,  2.6818e-02],\n",
            "          [-4.4075e-02,  2.4556e-02,  1.3719e-02]],\n",
            "\n",
            "         [[-6.9594e-03, -1.0092e-03, -5.3897e-02],\n",
            "          [ 8.2898e-03, -3.5543e-02,  4.9238e-03],\n",
            "          [ 1.3407e-03, -3.7284e-03, -6.5214e-03]],\n",
            "\n",
            "         [[-1.3087e-02,  1.2744e-03,  7.0806e-03],\n",
            "          [ 7.1695e-03,  1.7984e-02,  5.7473e-06],\n",
            "          [-9.0714e-03, -2.1370e-03, -1.3192e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8769e-02, -1.3857e-02,  3.1347e-03],\n",
            "          [ 2.5172e-03, -5.9059e-05,  1.7332e-02],\n",
            "          [ 2.4516e-02,  1.2461e-02,  1.0119e-02]],\n",
            "\n",
            "         [[-1.7007e-02, -7.7989e-04,  3.1556e-02],\n",
            "          [-7.7296e-03,  2.2028e-02, -2.9343e-02],\n",
            "          [-6.1727e-04, -2.2441e-02,  1.9114e-02]],\n",
            "\n",
            "         [[-2.0412e-04, -3.8693e-02, -5.2298e-03],\n",
            "          [-1.0716e-02,  1.3632e-02,  2.1280e-02],\n",
            "          [-2.5349e-03, -3.3848e-03,  1.6969e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.6080e-02,  1.8601e-02, -4.5164e-02],\n",
            "          [-1.3685e-02, -5.2854e-04, -1.3513e-02],\n",
            "          [ 1.2640e-02,  1.5251e-02, -2.5658e-02]],\n",
            "\n",
            "         [[-9.8698e-03,  2.8484e-02,  7.6270e-03],\n",
            "          [ 6.5307e-03,  1.8197e-02, -1.1473e-02],\n",
            "          [ 2.1544e-02, -1.0207e-02,  1.6369e-02]],\n",
            "\n",
            "         [[-2.0815e-02, -2.9778e-02,  5.2350e-03],\n",
            "          [-1.4085e-02,  2.0180e-02, -2.0708e-02],\n",
            "          [-7.8979e-03,  5.5252e-03, -2.2205e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2889e-02, -5.2528e-03, -1.1750e-02],\n",
            "          [-1.3108e-03,  8.1215e-03, -1.9652e-02],\n",
            "          [-7.2737e-03,  1.7644e-02, -1.7358e-02]],\n",
            "\n",
            "         [[-3.1226e-02, -2.3212e-04,  1.6040e-02],\n",
            "          [-4.0378e-02,  4.3791e-03, -9.0051e-03],\n",
            "          [-9.3602e-03, -3.6968e-02, -1.3541e-02]],\n",
            "\n",
            "         [[-1.5561e-02, -2.0917e-02,  8.8536e-03],\n",
            "          [-3.3578e-02,  1.1117e-02, -1.0509e-02],\n",
            "          [-5.2379e-03, -6.5119e-03, -1.2110e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2155e-02, -1.4971e-02,  8.9321e-03],\n",
            "          [-4.2680e-02,  5.3592e-03,  7.9697e-03],\n",
            "          [-1.0014e-02, -1.8525e-02,  8.7852e-04]],\n",
            "\n",
            "         [[ 4.1528e-02, -6.1444e-04,  4.6572e-02],\n",
            "          [-1.8386e-02, -2.4102e-02, -6.7021e-03],\n",
            "          [ 1.2595e-02, -1.9719e-02, -2.6093e-02]],\n",
            "\n",
            "         [[ 1.2358e-02, -7.2542e-02, -4.5360e-03],\n",
            "          [ 2.1530e-02,  1.7947e-02, -2.6980e-02],\n",
            "          [-7.2753e-05,  2.8378e-03, -1.0552e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7559e-03,  1.4703e-02,  2.1935e-02],\n",
            "          [-1.1185e-02, -3.1418e-02, -2.4522e-03],\n",
            "          [ 1.8595e-02,  2.2634e-03, -6.7254e-03]],\n",
            "\n",
            "         [[-3.7949e-02,  3.5406e-02,  4.2613e-03],\n",
            "          [ 3.7572e-03, -2.4697e-03,  1.1840e-03],\n",
            "          [-2.8383e-02, -8.3262e-03, -4.7166e-03]],\n",
            "\n",
            "         [[ 3.1577e-03,  4.5717e-02,  2.8721e-02],\n",
            "          [ 3.8448e-04,  3.3520e-02,  2.2737e-02],\n",
            "          [-1.3515e-02, -3.2723e-02,  1.1897e-02]]]])), ('module.encoder_q.layer4.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.0.conv3.weight', tensor([[[[ 0.0418]],\n",
            "\n",
            "         [[-0.0500]],\n",
            "\n",
            "         [[ 0.0070]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[-0.0376]]],\n",
            "\n",
            "\n",
            "        [[[-0.0601]],\n",
            "\n",
            "         [[-0.0061]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0101]],\n",
            "\n",
            "         [[-0.0408]],\n",
            "\n",
            "         [[-0.0297]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0108]],\n",
            "\n",
            "         [[-0.0137]],\n",
            "\n",
            "         [[-0.0062]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299]],\n",
            "\n",
            "         [[ 0.0403]],\n",
            "\n",
            "         [[ 0.0407]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0107]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0032]],\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         [[ 0.0116]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0093]],\n",
            "\n",
            "         [[ 0.0097]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0715]],\n",
            "\n",
            "         [[-0.0019]],\n",
            "\n",
            "         [[ 0.0420]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295]],\n",
            "\n",
            "         [[-0.0347]],\n",
            "\n",
            "         [[ 0.0564]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0428]],\n",
            "\n",
            "         [[-0.0206]],\n",
            "\n",
            "         [[-0.0400]]]])), ('module.encoder_q.layer4.0.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.0.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.0.downsample.0.weight', tensor([[[[ 0.0240]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[-0.0311]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[-0.0349]],\n",
            "\n",
            "         [[ 0.0338]]],\n",
            "\n",
            "\n",
            "        [[[-0.0387]],\n",
            "\n",
            "         [[ 0.0074]],\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0191]],\n",
            "\n",
            "         [[-0.0171]],\n",
            "\n",
            "         [[ 0.0069]]],\n",
            "\n",
            "\n",
            "        [[[-0.0112]],\n",
            "\n",
            "         [[-0.0184]],\n",
            "\n",
            "         [[-0.0273]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0364]],\n",
            "\n",
            "         [[-0.0100]],\n",
            "\n",
            "         [[ 0.0402]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0193]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         [[-0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0366]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[-0.0057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[ 0.0476]],\n",
            "\n",
            "         [[-0.0223]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0083]],\n",
            "\n",
            "         [[-0.0258]],\n",
            "\n",
            "         [[ 0.0263]]],\n",
            "\n",
            "\n",
            "        [[[-0.0365]],\n",
            "\n",
            "         [[-0.0131]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0026]],\n",
            "\n",
            "         [[-0.0248]],\n",
            "\n",
            "         [[ 0.0026]]]])), ('module.encoder_q.layer4.0.downsample.1.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.0.downsample.1.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.0.downsample.1.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.0.downsample.1.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.1.conv1.weight', tensor([[[[ 0.0951]],\n",
            "\n",
            "         [[ 0.1021]],\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0090]],\n",
            "\n",
            "         [[-0.0827]],\n",
            "\n",
            "         [[-0.1062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0229]],\n",
            "\n",
            "         [[-0.0817]],\n",
            "\n",
            "         [[-0.0741]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0466]],\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[-0.0212]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0578]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[-0.0219]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0129]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[ 0.0391]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0363]],\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[-0.0484]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0240]],\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         [[-0.0232]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         [[-0.0655]]],\n",
            "\n",
            "\n",
            "        [[[-0.0347]],\n",
            "\n",
            "         [[ 0.0098]],\n",
            "\n",
            "         [[ 0.0200]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         [[ 0.0411]],\n",
            "\n",
            "         [[-0.0480]]]])), ('module.encoder_q.layer4.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.1.conv2.weight', tensor([[[[-7.3814e-03, -1.6185e-03,  4.1269e-02],\n",
            "          [-3.4813e-04, -6.5095e-03, -8.9302e-03],\n",
            "          [-2.0391e-02,  6.4274e-03, -4.2294e-03]],\n",
            "\n",
            "         [[-1.7317e-02, -2.8197e-02, -3.4322e-02],\n",
            "          [-2.8817e-02, -3.6634e-03,  1.6631e-02],\n",
            "          [-6.0894e-02,  2.3477e-02,  9.4727e-03]],\n",
            "\n",
            "         [[ 1.5811e-02, -5.5481e-03,  8.6242e-03],\n",
            "          [-2.8544e-03,  1.7761e-02, -1.2966e-02],\n",
            "          [-1.5290e-02, -1.6547e-02, -1.0916e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4917e-02, -3.5584e-02,  7.1230e-03],\n",
            "          [ 1.4633e-02,  1.2499e-03,  9.4763e-03],\n",
            "          [-1.5858e-02, -1.4865e-02, -5.3695e-03]],\n",
            "\n",
            "         [[-2.1831e-02,  2.2923e-02,  2.3531e-02],\n",
            "          [-2.7302e-03,  1.0418e-02, -1.3314e-02],\n",
            "          [ 2.9128e-03, -1.1342e-02, -4.1396e-03]],\n",
            "\n",
            "         [[-1.9575e-02, -1.3802e-02, -3.6632e-02],\n",
            "          [-1.5000e-02, -1.3952e-02,  3.3575e-02],\n",
            "          [ 3.6460e-02, -3.3979e-02,  1.3541e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1492e-02, -3.7352e-04,  3.1189e-02],\n",
            "          [-3.9138e-02, -1.3486e-02,  2.5266e-02],\n",
            "          [-2.4664e-02,  2.6599e-02, -1.6492e-02]],\n",
            "\n",
            "         [[ 2.7748e-02,  1.4629e-02,  1.2743e-02],\n",
            "          [ 9.3989e-03, -5.6655e-03, -6.9773e-03],\n",
            "          [-4.7968e-03, -1.7719e-02, -2.5712e-02]],\n",
            "\n",
            "         [[ 3.0530e-02, -7.2237e-03,  2.6349e-02],\n",
            "          [ 1.2789e-02,  1.2519e-02,  3.7331e-02],\n",
            "          [ 3.5956e-02, -2.0166e-03,  4.1376e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.1789e-02,  1.4381e-02, -1.8169e-02],\n",
            "          [-1.8865e-02,  8.9827e-03,  8.8650e-03],\n",
            "          [ 1.5344e-02, -4.2490e-02, -2.6014e-03]],\n",
            "\n",
            "         [[-1.5715e-02,  7.7178e-03, -2.4319e-02],\n",
            "          [-1.0312e-02,  1.1892e-03,  6.0195e-03],\n",
            "          [ 6.2908e-03,  1.7201e-02,  9.1106e-03]],\n",
            "\n",
            "         [[-1.6010e-03,  3.1782e-02, -2.2814e-02],\n",
            "          [-1.2059e-02,  8.3228e-04, -1.9418e-02],\n",
            "          [-4.0015e-02,  1.9597e-02, -2.1821e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7584e-02,  2.6464e-02, -2.3271e-03],\n",
            "          [-3.9331e-03,  2.9278e-02,  1.4493e-02],\n",
            "          [ 1.8865e-02,  3.2255e-02,  1.8295e-02]],\n",
            "\n",
            "         [[ 8.7632e-04,  2.9559e-02, -1.0432e-02],\n",
            "          [-1.9121e-02,  2.7266e-02, -3.4690e-02],\n",
            "          [-4.1126e-02, -1.2117e-02,  3.9537e-02]],\n",
            "\n",
            "         [[-1.8303e-02,  3.3266e-03,  2.6360e-03],\n",
            "          [-7.3329e-03,  1.2197e-02,  1.9004e-02],\n",
            "          [-5.2972e-03,  3.2684e-02, -1.8616e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1077e-03,  3.3310e-03, -4.1052e-02],\n",
            "          [-2.6801e-02, -5.9275e-03,  2.6260e-02],\n",
            "          [-3.3463e-02, -2.8397e-02,  1.0909e-02]],\n",
            "\n",
            "         [[ 4.9467e-02,  9.3187e-03, -1.3890e-02],\n",
            "          [ 1.2055e-02, -2.3214e-02,  5.7277e-03],\n",
            "          [ 3.1605e-02, -5.0976e-05, -3.9619e-02]],\n",
            "\n",
            "         [[ 3.2946e-02,  2.1702e-02,  2.4688e-03],\n",
            "          [ 2.9190e-03, -3.6701e-04,  2.5533e-04],\n",
            "          [ 2.3168e-02,  1.4762e-02, -6.1189e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.8243e-02, -8.6041e-03, -2.8301e-02],\n",
            "          [ 5.3847e-04,  3.2997e-02, -1.9101e-03],\n",
            "          [-4.0163e-02,  3.0870e-02, -6.9938e-03]],\n",
            "\n",
            "         [[-5.6154e-03, -1.8680e-02,  2.4065e-02],\n",
            "          [ 2.2318e-02, -1.4281e-03,  4.5899e-02],\n",
            "          [-2.5011e-03, -6.5530e-03,  2.3204e-02]],\n",
            "\n",
            "         [[-1.5518e-02,  1.7247e-03,  2.7762e-02],\n",
            "          [-1.4071e-02, -3.1900e-02,  2.0102e-03],\n",
            "          [ 6.6558e-03,  1.2910e-02,  1.1491e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0742e-02,  1.0239e-02,  1.6182e-03],\n",
            "          [ 5.8820e-03,  1.4353e-02, -5.8836e-03],\n",
            "          [ 1.3609e-02,  2.0870e-02, -5.4176e-03]],\n",
            "\n",
            "         [[ 1.8857e-03, -3.8026e-03,  1.0044e-02],\n",
            "          [ 1.7379e-03,  3.5733e-03, -1.9635e-02],\n",
            "          [ 3.9499e-03, -1.2560e-02,  7.0899e-03]],\n",
            "\n",
            "         [[ 1.4400e-02, -1.6410e-02,  1.1526e-03],\n",
            "          [ 3.7114e-03, -2.4402e-02, -2.0224e-02],\n",
            "          [ 1.0286e-02,  1.3683e-02, -3.6651e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9415e-03,  9.3087e-03,  1.2978e-02],\n",
            "          [ 1.1848e-02, -1.6089e-03,  9.8278e-03],\n",
            "          [ 1.0717e-02, -2.1980e-02,  3.2408e-02]],\n",
            "\n",
            "         [[ 2.4709e-02, -7.7980e-03,  3.6737e-02],\n",
            "          [-1.2486e-03,  1.3969e-02, -1.2195e-02],\n",
            "          [ 8.6391e-03,  2.7633e-02,  1.1783e-02]],\n",
            "\n",
            "         [[ 9.3668e-03, -1.5184e-02, -1.3857e-02],\n",
            "          [ 1.5560e-02,  3.9109e-02, -1.0901e-02],\n",
            "          [-4.3304e-04,  2.0903e-02, -1.3750e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9821e-02, -9.4683e-03, -5.5842e-03],\n",
            "          [ 1.2902e-02, -1.8058e-02,  1.0444e-02],\n",
            "          [ 6.8827e-03, -2.0821e-02, -1.1689e-02]],\n",
            "\n",
            "         [[ 9.3320e-03, -1.5785e-02, -3.4661e-02],\n",
            "          [-5.5720e-02, -1.5326e-02, -2.7506e-02],\n",
            "          [ 6.0891e-03, -3.2175e-02,  2.8354e-02]],\n",
            "\n",
            "         [[ 3.4392e-03, -1.2277e-02, -3.2340e-02],\n",
            "          [-6.5083e-04,  4.0298e-02,  6.7452e-03],\n",
            "          [ 1.0148e-02,  1.0345e-02, -6.6034e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0150e-02,  2.2810e-02, -2.0671e-03],\n",
            "          [-3.9005e-02,  1.3107e-02,  3.3569e-03],\n",
            "          [ 1.6399e-02, -7.4265e-03, -6.2866e-03]],\n",
            "\n",
            "         [[ 1.4259e-02,  4.2510e-02,  6.4062e-03],\n",
            "          [-1.6002e-02, -2.5729e-02, -4.1847e-02],\n",
            "          [-1.5609e-03,  6.8361e-03, -2.9198e-02]],\n",
            "\n",
            "         [[ 2.5413e-02, -2.7298e-02,  1.9589e-02],\n",
            "          [-8.4087e-03, -8.7112e-03, -9.8301e-03],\n",
            "          [-2.5651e-02,  2.4844e-03, -8.6954e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8682e-02,  1.9608e-02, -2.1790e-02],\n",
            "          [-4.5122e-02, -3.1113e-02, -4.1028e-02],\n",
            "          [ 6.6815e-03, -1.4416e-02, -5.6779e-02]],\n",
            "\n",
            "         [[ 1.3445e-02,  1.5687e-02,  3.0581e-03],\n",
            "          [-7.7190e-03, -3.9109e-02,  4.0275e-02],\n",
            "          [-3.0644e-03, -3.8116e-02,  1.3374e-02]],\n",
            "\n",
            "         [[-3.9553e-02, -6.8817e-03,  4.8256e-02],\n",
            "          [-2.0112e-02, -1.3887e-02, -2.6608e-02],\n",
            "          [ 2.8581e-02,  1.5040e-02,  1.3006e-02]]]])), ('module.encoder_q.layer4.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.1.conv3.weight', tensor([[[[-0.0004]],\n",
            "\n",
            "         [[-0.0085]],\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152]],\n",
            "\n",
            "         [[-0.0393]],\n",
            "\n",
            "         [[ 0.0093]]],\n",
            "\n",
            "\n",
            "        [[[-0.0329]],\n",
            "\n",
            "         [[ 0.0480]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0094]],\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[-0.0413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[-0.0070]],\n",
            "\n",
            "         [[ 0.0283]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0239]],\n",
            "\n",
            "         [[ 0.0085]],\n",
            "\n",
            "         [[ 0.0109]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0085]],\n",
            "\n",
            "         [[ 0.0196]],\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0417]],\n",
            "\n",
            "         [[-0.0248]],\n",
            "\n",
            "         [[-0.0273]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067]],\n",
            "\n",
            "         [[ 0.0250]],\n",
            "\n",
            "         [[ 0.0365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221]],\n",
            "\n",
            "         [[ 0.0444]],\n",
            "\n",
            "         [[ 0.0047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0098]],\n",
            "\n",
            "         [[-0.0702]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0256]],\n",
            "\n",
            "         [[-0.0266]],\n",
            "\n",
            "         [[-0.0424]]]])), ('module.encoder_q.layer4.1.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.1.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.2.conv1.weight', tensor([[[[ 0.1153]],\n",
            "\n",
            "         [[ 0.0825]],\n",
            "\n",
            "         [[-0.0131]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0117]],\n",
            "\n",
            "         [[-0.0547]],\n",
            "\n",
            "         [[ 0.0557]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0194]],\n",
            "\n",
            "         [[ 0.0795]],\n",
            "\n",
            "         [[-0.0266]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0044]],\n",
            "\n",
            "         [[ 0.0511]],\n",
            "\n",
            "         [[-0.0564]]],\n",
            "\n",
            "\n",
            "        [[[-0.0736]],\n",
            "\n",
            "         [[-0.0221]],\n",
            "\n",
            "         [[ 0.0939]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[ 0.0300]],\n",
            "\n",
            "         [[-0.1061]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0377]],\n",
            "\n",
            "         [[ 0.0640]],\n",
            "\n",
            "         [[-0.0344]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0970]],\n",
            "\n",
            "         [[ 0.0518]],\n",
            "\n",
            "         [[ 0.0572]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0218]],\n",
            "\n",
            "         [[ 0.0071]],\n",
            "\n",
            "         [[-0.0213]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0385]],\n",
            "\n",
            "         [[ 0.0416]],\n",
            "\n",
            "         [[ 0.0302]]],\n",
            "\n",
            "\n",
            "        [[[-0.0708]],\n",
            "\n",
            "         [[ 0.0136]],\n",
            "\n",
            "         [[-0.0095]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0462]],\n",
            "\n",
            "         [[ 0.0313]],\n",
            "\n",
            "         [[-0.0069]]]])), ('module.encoder_q.layer4.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.2.conv2.weight', tensor([[[[ 0.0198, -0.0144, -0.0280],\n",
            "          [-0.0083,  0.0060,  0.0126],\n",
            "          [ 0.0387,  0.0154,  0.0037]],\n",
            "\n",
            "         [[-0.0123, -0.0223, -0.0089],\n",
            "          [-0.0496, -0.0540, -0.0110],\n",
            "          [-0.0109,  0.0283, -0.0093]],\n",
            "\n",
            "         [[ 0.0273, -0.0269,  0.0045],\n",
            "          [-0.0064, -0.0310,  0.0015],\n",
            "          [ 0.0408, -0.0158, -0.0171]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0319, -0.0090,  0.0173],\n",
            "          [ 0.0236, -0.0102, -0.0111],\n",
            "          [ 0.0154,  0.0089, -0.0134]],\n",
            "\n",
            "         [[ 0.0055,  0.0201, -0.0339],\n",
            "          [ 0.0214,  0.0113, -0.0058],\n",
            "          [-0.0055,  0.0187,  0.0171]],\n",
            "\n",
            "         [[-0.0101, -0.0113,  0.0033],\n",
            "          [ 0.0262,  0.0064,  0.0201],\n",
            "          [ 0.0099, -0.0223,  0.0605]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0221, -0.0226],\n",
            "          [ 0.0304, -0.0093, -0.0220],\n",
            "          [-0.0012, -0.0492,  0.0036]],\n",
            "\n",
            "         [[-0.0018, -0.0071, -0.0181],\n",
            "          [ 0.0116, -0.0282, -0.0052],\n",
            "          [-0.0198, -0.0203, -0.0014]],\n",
            "\n",
            "         [[-0.0066, -0.0061,  0.0030],\n",
            "          [-0.0434, -0.0013, -0.0249],\n",
            "          [ 0.0138, -0.0082, -0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0004,  0.0087,  0.0178],\n",
            "          [ 0.0046, -0.0325,  0.0149],\n",
            "          [ 0.0308, -0.0171,  0.0033]],\n",
            "\n",
            "         [[-0.0233, -0.0115, -0.0232],\n",
            "          [-0.0117, -0.0149, -0.0089],\n",
            "          [ 0.0117,  0.0358, -0.0034]],\n",
            "\n",
            "         [[-0.0501, -0.0036, -0.0037],\n",
            "          [ 0.0398,  0.0110,  0.0049],\n",
            "          [ 0.0089,  0.0308, -0.0197]]],\n",
            "\n",
            "\n",
            "        [[[-0.0228,  0.0103, -0.0156],\n",
            "          [ 0.0145,  0.0077, -0.0412],\n",
            "          [-0.0144,  0.0323,  0.0099]],\n",
            "\n",
            "         [[-0.0014, -0.0085, -0.0130],\n",
            "          [-0.0094,  0.0098, -0.0002],\n",
            "          [ 0.0255, -0.0489, -0.0073]],\n",
            "\n",
            "         [[ 0.0168,  0.0053,  0.0306],\n",
            "          [ 0.0147, -0.0221, -0.0315],\n",
            "          [-0.0107, -0.0093,  0.0215]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0024, -0.0573, -0.0021],\n",
            "          [ 0.0184,  0.0126,  0.0228],\n",
            "          [-0.0049,  0.0235, -0.0148]],\n",
            "\n",
            "         [[-0.0297, -0.0136, -0.0271],\n",
            "          [-0.0154,  0.0025,  0.0271],\n",
            "          [-0.0014,  0.0277, -0.0272]],\n",
            "\n",
            "         [[ 0.0256, -0.0128,  0.0199],\n",
            "          [-0.0202,  0.0083,  0.0363],\n",
            "          [-0.0100, -0.0069, -0.0107]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0027, -0.0139,  0.0074],\n",
            "          [-0.0159, -0.0197, -0.0303],\n",
            "          [ 0.0058,  0.0348,  0.0143]],\n",
            "\n",
            "         [[-0.0127, -0.0087,  0.0287],\n",
            "          [-0.0010, -0.0099,  0.0137],\n",
            "          [ 0.0016,  0.0311, -0.0080]],\n",
            "\n",
            "         [[-0.0220,  0.0131, -0.0088],\n",
            "          [-0.0260,  0.0568,  0.0581],\n",
            "          [-0.0286, -0.0034,  0.0127]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0213, -0.0386,  0.0412],\n",
            "          [ 0.0181,  0.0101, -0.0074],\n",
            "          [-0.0118, -0.0215,  0.0303]],\n",
            "\n",
            "         [[-0.0170, -0.0038,  0.0018],\n",
            "          [ 0.0003, -0.0133,  0.0429],\n",
            "          [ 0.0085,  0.0146, -0.0261]],\n",
            "\n",
            "         [[ 0.0006, -0.0192, -0.0245],\n",
            "          [ 0.0234,  0.0092,  0.0546],\n",
            "          [-0.0278,  0.0069,  0.0308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0231, -0.0050,  0.0123],\n",
            "          [-0.0045, -0.0221,  0.0097],\n",
            "          [-0.0267, -0.0306,  0.0314]],\n",
            "\n",
            "         [[-0.0439, -0.0237,  0.0148],\n",
            "          [-0.0164, -0.0367, -0.0075],\n",
            "          [ 0.0219,  0.0066,  0.0170]],\n",
            "\n",
            "         [[-0.0211,  0.0015,  0.0091],\n",
            "          [-0.0029,  0.0032, -0.0607],\n",
            "          [-0.0018, -0.0084,  0.0017]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0112, -0.0396, -0.0138],\n",
            "          [-0.0106,  0.0051,  0.0133],\n",
            "          [-0.0034, -0.0034,  0.0126]],\n",
            "\n",
            "         [[-0.0026,  0.0196,  0.0100],\n",
            "          [ 0.0327, -0.0248, -0.0230],\n",
            "          [-0.0145, -0.0203,  0.0136]],\n",
            "\n",
            "         [[ 0.0225, -0.0001, -0.0105],\n",
            "          [ 0.0244,  0.0028,  0.0009],\n",
            "          [ 0.0104,  0.0341, -0.0064]]],\n",
            "\n",
            "\n",
            "        [[[-0.0085,  0.0118,  0.0018],\n",
            "          [-0.0175, -0.0206,  0.0113],\n",
            "          [ 0.0007,  0.0072,  0.0180]],\n",
            "\n",
            "         [[-0.0081, -0.0136, -0.0261],\n",
            "          [-0.0063, -0.0119, -0.0099],\n",
            "          [ 0.0010,  0.0366, -0.0021]],\n",
            "\n",
            "         [[ 0.0268,  0.0007,  0.0016],\n",
            "          [ 0.0138, -0.0101, -0.0098],\n",
            "          [ 0.0419, -0.0491,  0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0308,  0.0002,  0.0265],\n",
            "          [-0.0022,  0.0268,  0.0387],\n",
            "          [ 0.0033,  0.0021,  0.0031]],\n",
            "\n",
            "         [[-0.0165, -0.0078, -0.0187],\n",
            "          [ 0.0084, -0.0122,  0.0170],\n",
            "          [ 0.0002,  0.0452, -0.0151]],\n",
            "\n",
            "         [[ 0.0156,  0.0026,  0.0126],\n",
            "          [ 0.0165, -0.0126, -0.0112],\n",
            "          [ 0.0076,  0.0259,  0.0252]]]])), ('module.encoder_q.layer4.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_q.layer4.2.conv3.weight', tensor([[[[ 0.0252]],\n",
            "\n",
            "         [[-0.0268]],\n",
            "\n",
            "         [[-0.0158]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0273]],\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         [[ 0.0271]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243]],\n",
            "\n",
            "         [[ 0.0089]],\n",
            "\n",
            "         [[-0.0130]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0416]],\n",
            "\n",
            "         [[-0.0473]],\n",
            "\n",
            "         [[ 0.0464]]],\n",
            "\n",
            "\n",
            "        [[[-0.0072]],\n",
            "\n",
            "         [[ 0.0607]],\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         [[-0.0096]],\n",
            "\n",
            "         [[ 0.0302]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0282]],\n",
            "\n",
            "         [[ 0.0019]],\n",
            "\n",
            "         [[ 0.0621]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0351]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.0142]]],\n",
            "\n",
            "\n",
            "        [[[-0.0293]],\n",
            "\n",
            "         [[-0.0414]],\n",
            "\n",
            "         [[-0.0015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.0024]],\n",
            "\n",
            "         [[-0.0062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0828]],\n",
            "\n",
            "         [[ 0.0651]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0030]],\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         [[ 0.0023]]]])), ('module.encoder_q.layer4.2.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_q.layer4.2.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_q.layer4.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_q.fc.weight', tensor([[-0.0081,  0.0063,  0.0161,  ..., -0.0020, -0.0093,  0.0168],\n",
            "        [ 0.0048,  0.0026,  0.0047,  ...,  0.0117, -0.0106, -0.0206],\n",
            "        [ 0.0209,  0.0199,  0.0157,  ..., -0.0144,  0.0018,  0.0043],\n",
            "        ...,\n",
            "        [ 0.0198, -0.0134,  0.0195,  ...,  0.0024,  0.0092, -0.0167],\n",
            "        [ 0.0014,  0.0007, -0.0198,  ..., -0.0160, -0.0062,  0.0201],\n",
            "        [ 0.0105, -0.0088, -0.0184,  ..., -0.0037, -0.0045, -0.0127]])), ('module.encoder_q.fc.bias', tensor([-1.8850e-02, -1.2881e-02, -1.8548e-02,  5.2929e-03, -4.2578e-04,\n",
            "         6.2410e-03, -6.0432e-03, -1.7987e-02,  5.2036e-03,  1.7101e-02,\n",
            "        -1.0713e-03,  1.5382e-02,  1.4721e-02,  1.9232e-02,  7.8328e-03,\n",
            "        -1.1483e-02,  1.4599e-02, -7.4539e-03, -9.3652e-03,  3.1690e-03,\n",
            "        -1.5743e-02,  8.5620e-03, -4.1524e-03, -1.3842e-02,  8.7397e-03,\n",
            "        -1.2668e-02,  4.7690e-03,  1.5000e-02,  1.2169e-03, -1.2670e-02,\n",
            "        -1.7457e-02,  2.0774e-02,  1.1249e-02, -6.5765e-03,  1.0404e-02,\n",
            "        -8.0480e-03, -1.0871e-02,  1.4320e-02,  5.5180e-03, -1.0175e-02,\n",
            "        -9.4095e-04, -2.1050e-02, -1.6231e-02, -3.2174e-03,  1.0916e-02,\n",
            "         7.4000e-04,  1.9413e-02,  4.0848e-03,  8.1386e-03, -1.3290e-02,\n",
            "         3.4723e-03, -1.8777e-02,  1.1552e-02,  1.3159e-03, -3.9887e-03,\n",
            "         2.1802e-02, -1.7572e-02, -1.8880e-02, -2.1247e-02, -1.3334e-02,\n",
            "        -1.1884e-02, -2.1541e-02, -1.2873e-02,  1.0784e-02, -8.6019e-03,\n",
            "         5.2551e-03, -4.3500e-03, -1.6887e-02, -3.3832e-03, -1.2741e-02,\n",
            "        -2.0780e-02,  7.0939e-03,  4.8625e-03, -1.0340e-03,  5.5888e-03,\n",
            "         1.2200e-02, -1.6891e-02, -1.8968e-02, -2.0300e-04,  1.7168e-02,\n",
            "         7.3278e-03, -1.4220e-02, -2.0420e-03,  3.5878e-03,  1.9396e-02,\n",
            "         5.9262e-03,  1.6508e-02, -1.3431e-02,  7.8597e-03,  1.6805e-02,\n",
            "         1.4482e-02, -1.7457e-02,  7.1747e-05,  5.4276e-03, -1.9222e-02,\n",
            "         5.6133e-03,  1.0148e-02,  8.6298e-03, -4.6073e-03, -6.3356e-03,\n",
            "        -1.7702e-02,  6.8228e-03,  1.9177e-02, -1.5759e-03, -2.0157e-02,\n",
            "        -2.1031e-02, -1.0851e-02,  1.1812e-02, -2.1555e-02, -2.0973e-02,\n",
            "        -1.3836e-03, -1.5844e-02,  2.8856e-03, -1.3456e-02,  1.5726e-04,\n",
            "        -8.9887e-03,  4.9299e-03,  5.4562e-03,  3.7262e-03,  3.0027e-03,\n",
            "        -1.0395e-02, -7.2112e-03, -5.5407e-03,  1.7928e-02, -6.7132e-03,\n",
            "        -3.4835e-04,  1.9563e-02,  1.5847e-02])), ('module.encoder_k.conv1.weight', tensor([[[[ 7.0230e-02, -4.1660e-02,  4.2025e-02,  ...,  7.0984e-03,\n",
            "            1.7880e-02,  6.1800e-03],\n",
            "          [-3.7125e-02,  2.1589e-02, -6.1565e-02,  ...,  2.3484e-02,\n",
            "           -1.0346e-02,  9.8234e-03],\n",
            "          [-6.0116e-03, -3.5639e-02,  6.6227e-02,  ...,  2.8408e-03,\n",
            "           -1.8451e-02,  1.1533e-02],\n",
            "          ...,\n",
            "          [ 2.8007e-02, -2.9953e-02, -1.4943e-04,  ...,  7.7149e-03,\n",
            "            1.0768e-02, -3.9815e-03],\n",
            "          [ 3.5528e-02,  1.2809e-02,  1.1890e-02,  ..., -1.5099e-02,\n",
            "           -3.3117e-02,  2.6577e-03],\n",
            "          [ 1.0346e-02,  2.0440e-02,  1.7211e-02,  ..., -1.4749e-02,\n",
            "           -3.1250e-02,  1.9889e-02]],\n",
            "\n",
            "         [[ 1.6978e-02, -2.0200e-02, -1.5252e-02,  ..., -9.0668e-03,\n",
            "            2.0540e-02,  5.4303e-02],\n",
            "          [ 5.8020e-03,  4.0708e-03, -4.3752e-02,  ..., -3.2700e-02,\n",
            "            1.2490e-02,  3.5838e-02],\n",
            "          [-4.4854e-03,  5.2392e-02,  6.5438e-02,  ..., -2.9543e-02,\n",
            "           -2.2481e-03,  2.8845e-02],\n",
            "          ...,\n",
            "          [-6.2591e-02,  1.4685e-02,  2.0848e-04,  ..., -1.1576e-02,\n",
            "           -2.1890e-02, -3.1101e-03],\n",
            "          [ 3.5477e-02,  6.7638e-03,  3.6611e-03,  ...,  2.1740e-02,\n",
            "           -2.5287e-02, -1.5249e-02],\n",
            "          [-9.2705e-03,  2.7793e-02,  4.0567e-03,  ...,  5.7866e-03,\n",
            "           -2.4483e-02,  5.1187e-02]],\n",
            "\n",
            "         [[-2.7297e-02,  3.8953e-02, -1.3653e-02,  ...,  1.3295e-03,\n",
            "            2.4538e-02,  2.1381e-02],\n",
            "          [ 7.1911e-03, -2.2159e-03, -2.1939e-04,  ...,  7.2159e-03,\n",
            "           -4.1779e-02,  3.4479e-02],\n",
            "          [-6.8842e-03,  4.6468e-03,  4.4188e-03,  ..., -3.7277e-04,\n",
            "           -2.0970e-02,  1.0558e-02],\n",
            "          ...,\n",
            "          [ 4.2007e-02,  3.8454e-02,  1.8357e-03,  ...,  2.9692e-02,\n",
            "           -1.7751e-03, -4.3309e-02],\n",
            "          [-6.9537e-03,  3.9794e-02, -4.0673e-02,  ...,  2.8152e-02,\n",
            "            8.8234e-03, -4.8268e-03],\n",
            "          [-3.5405e-03, -1.0165e-03,  1.2776e-02,  ...,  9.8090e-03,\n",
            "           -9.8217e-03, -5.3463e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4752e-02, -8.4444e-03, -2.9275e-02,  ..., -7.1644e-02,\n",
            "            3.8834e-02,  1.1322e-03],\n",
            "          [ 2.2865e-03,  2.8854e-03, -2.2197e-02,  ..., -4.7384e-02,\n",
            "           -1.6463e-02,  1.3788e-02],\n",
            "          [-2.9182e-02, -5.0805e-02,  1.3142e-02,  ...,  1.7480e-02,\n",
            "           -2.7692e-02,  2.5823e-02],\n",
            "          ...,\n",
            "          [ 3.3552e-02,  3.1358e-02,  2.7909e-02,  ..., -4.8022e-02,\n",
            "            3.4819e-02, -4.6961e-02],\n",
            "          [-1.5143e-02,  4.9633e-03, -2.4345e-03,  ..., -9.2266e-03,\n",
            "           -1.1866e-02,  4.0504e-02],\n",
            "          [-7.0114e-04, -1.0913e-02,  5.0891e-03,  ..., -3.0052e-02,\n",
            "           -8.0363e-03, -2.8494e-02]],\n",
            "\n",
            "         [[ 3.6098e-02, -3.8480e-03, -2.0068e-02,  ...,  1.9626e-02,\n",
            "            3.3643e-04,  2.2916e-02],\n",
            "          [ 3.1339e-02, -1.6150e-02, -1.1722e-02,  ...,  1.8728e-02,\n",
            "           -2.0508e-02,  4.5048e-02],\n",
            "          [-2.8513e-02, -1.1217e-02,  4.4236e-02,  ...,  4.2896e-02,\n",
            "            5.4312e-03,  5.4972e-02],\n",
            "          ...,\n",
            "          [ 7.5011e-03,  2.9551e-02,  5.5053e-02,  ...,  2.0889e-02,\n",
            "            1.6487e-02,  4.0055e-02],\n",
            "          [ 1.7780e-02,  2.6815e-03,  5.7258e-03,  ..., -3.5343e-02,\n",
            "            2.4972e-02,  5.0713e-04],\n",
            "          [ 7.8590e-03,  6.4522e-03, -1.0198e-02,  ...,  8.6444e-03,\n",
            "            1.8308e-02,  2.9113e-03]],\n",
            "\n",
            "         [[-4.5121e-02,  6.9182e-03, -5.1733e-03,  ..., -3.8342e-02,\n",
            "           -2.5513e-02, -2.0584e-02],\n",
            "          [-3.2628e-03, -1.7867e-02, -1.6492e-02,  ..., -6.9671e-04,\n",
            "            3.4794e-02, -1.8322e-02],\n",
            "          [ 2.7563e-02, -7.7159e-05,  2.1879e-02,  ...,  4.0160e-02,\n",
            "           -1.1417e-02,  1.9615e-02],\n",
            "          ...,\n",
            "          [ 1.0656e-02,  1.6287e-02, -1.4590e-02,  ...,  1.4935e-02,\n",
            "            1.3162e-02, -8.6805e-03],\n",
            "          [ 1.6429e-02,  1.6164e-02,  2.2839e-02,  ...,  9.4537e-03,\n",
            "            3.4451e-02, -8.0257e-03],\n",
            "          [-3.1262e-02,  4.3514e-02, -3.8360e-02,  ...,  5.0107e-03,\n",
            "           -8.1864e-03,  2.0612e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.9908e-02,  8.1612e-03, -1.1382e-03,  ..., -6.3385e-02,\n",
            "           -1.1457e-02,  1.9245e-02],\n",
            "          [-2.6531e-02, -7.4353e-04,  1.3543e-02,  ...,  2.9808e-02,\n",
            "           -1.5420e-02, -1.1478e-03],\n",
            "          [ 8.9283e-03, -2.0357e-02, -8.1833e-03,  ..., -1.5308e-02,\n",
            "            1.9048e-02, -2.5538e-02],\n",
            "          ...,\n",
            "          [ 8.5311e-03,  1.6157e-02,  3.9713e-02,  ..., -3.0088e-02,\n",
            "            2.5326e-02, -2.4186e-02],\n",
            "          [-2.0506e-02,  2.2312e-02, -5.8071e-03,  ...,  8.7675e-05,\n",
            "           -8.1253e-03, -1.9233e-02],\n",
            "          [ 1.9164e-02, -3.8491e-02, -2.1227e-02,  ...,  2.8487e-02,\n",
            "           -2.4936e-02,  2.8053e-02]],\n",
            "\n",
            "         [[-3.1551e-02,  3.0845e-02, -4.6333e-02,  ..., -2.0439e-02,\n",
            "           -1.3002e-04,  2.3501e-03],\n",
            "          [-5.4811e-02,  2.4578e-02,  3.4488e-02,  ..., -1.0159e-02,\n",
            "            8.3985e-03, -1.3669e-02],\n",
            "          [ 2.6749e-02,  3.3788e-02, -7.4282e-02,  ..., -2.8719e-02,\n",
            "            1.0436e-02, -3.4942e-02],\n",
            "          ...,\n",
            "          [-3.9291e-02,  8.9732e-03,  1.1399e-02,  ...,  3.3853e-02,\n",
            "           -3.7613e-03,  1.7712e-02],\n",
            "          [ 2.6835e-02,  3.6792e-02,  2.8290e-02,  ..., -3.8296e-03,\n",
            "            1.5680e-02, -2.1990e-02],\n",
            "          [ 1.5139e-02,  1.3929e-03, -1.9972e-02,  ..., -3.4302e-02,\n",
            "           -1.8412e-03, -5.6194e-02]],\n",
            "\n",
            "         [[-3.4498e-02, -1.9150e-02, -1.7266e-03,  ..., -2.6108e-02,\n",
            "            4.9628e-02, -3.5181e-02],\n",
            "          [-2.5755e-02,  9.3788e-03, -2.6652e-02,  ..., -4.2523e-02,\n",
            "           -2.0693e-02, -1.1058e-02],\n",
            "          [-9.0799e-03,  3.2399e-03,  8.1756e-03,  ..., -1.7115e-03,\n",
            "            1.7861e-02, -4.4432e-03],\n",
            "          ...,\n",
            "          [ 2.0659e-02,  5.6964e-02,  1.0905e-02,  ...,  1.1691e-02,\n",
            "           -5.7176e-02,  1.1352e-02],\n",
            "          [-2.3308e-02,  3.2889e-02,  4.9990e-03,  ...,  3.7745e-02,\n",
            "            4.1016e-02,  3.4258e-02],\n",
            "          [-2.5163e-03, -1.5997e-02, -8.1919e-03,  ...,  7.8564e-03,\n",
            "           -1.2524e-02,  1.1577e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-6.1407e-02,  1.3469e-02,  4.2060e-03,  ...,  5.6182e-03,\n",
            "           -2.2445e-02, -1.5390e-02],\n",
            "          [ 3.3404e-03, -4.0883e-02, -7.7294e-03,  ..., -1.2372e-02,\n",
            "           -2.1456e-02,  1.1274e-03],\n",
            "          [-6.6711e-04,  1.7167e-03,  5.2219e-03,  ...,  2.5639e-02,\n",
            "            2.6200e-02, -2.6497e-02],\n",
            "          ...,\n",
            "          [ 1.6529e-02,  2.6490e-02, -1.7791e-02,  ...,  3.3424e-03,\n",
            "            1.1694e-02, -1.6976e-03],\n",
            "          [-1.6655e-02, -6.1082e-03, -2.2970e-02,  ..., -3.9323e-02,\n",
            "            6.1883e-04, -2.3682e-03],\n",
            "          [ 4.4987e-02, -8.7138e-03, -7.6173e-03,  ...,  3.3059e-02,\n",
            "           -1.3781e-02, -3.5161e-02]],\n",
            "\n",
            "         [[ 1.9720e-03,  4.7350e-03,  5.8949e-03,  ..., -4.0766e-02,\n",
            "           -2.0361e-02,  1.3355e-02],\n",
            "          [ 3.6404e-02, -8.5382e-03,  2.0897e-02,  ...,  1.7898e-02,\n",
            "           -6.1549e-03, -2.1664e-02],\n",
            "          [ 9.8432e-03, -1.3589e-02, -1.3936e-02,  ...,  1.3763e-02,\n",
            "           -2.6872e-02,  3.3035e-02],\n",
            "          ...,\n",
            "          [-3.6468e-03, -3.1737e-02, -1.7515e-02,  ...,  4.0983e-02,\n",
            "           -6.5273e-03, -3.9143e-02],\n",
            "          [ 8.3578e-03,  3.1648e-04, -2.8919e-02,  ..., -2.7139e-03,\n",
            "            1.4206e-02, -1.4428e-02],\n",
            "          [ 1.8483e-02,  3.5556e-02, -7.5411e-02,  ..., -1.8482e-02,\n",
            "            4.6642e-02, -1.1625e-02]],\n",
            "\n",
            "         [[ 5.4270e-02,  4.2750e-02,  9.4106e-03,  ...,  6.2735e-04,\n",
            "            1.4387e-02,  5.2428e-02],\n",
            "          [ 1.1644e-03, -1.2585e-02,  3.3322e-03,  ..., -2.3003e-02,\n",
            "            1.5390e-02,  8.0922e-03],\n",
            "          [ 5.3882e-03, -1.7276e-02,  1.7107e-02,  ...,  4.4807e-03,\n",
            "            6.5512e-03, -1.6624e-02],\n",
            "          ...,\n",
            "          [-2.5646e-02,  5.3798e-03, -1.7412e-03,  ...,  1.3048e-02,\n",
            "           -2.4354e-03, -8.9014e-04],\n",
            "          [-1.0876e-02,  3.7389e-02, -2.5460e-02,  ..., -3.4094e-02,\n",
            "            9.7123e-03, -2.9183e-02],\n",
            "          [-2.4222e-02, -2.3116e-02, -5.5438e-02,  ..., -2.6687e-04,\n",
            "            2.3819e-02, -1.8324e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0084e-02,  2.8457e-02, -5.8527e-03,  ..., -9.9049e-03,\n",
            "           -8.7022e-04,  4.8238e-02],\n",
            "          [-5.0136e-02, -4.4192e-02,  3.7280e-03,  ..., -3.7206e-03,\n",
            "            2.9080e-02, -5.5944e-02],\n",
            "          [-2.7226e-02,  3.7091e-02, -3.7416e-03,  ..., -7.4820e-03,\n",
            "            2.8279e-02, -3.3986e-02],\n",
            "          ...,\n",
            "          [-4.1813e-03,  4.1199e-02, -1.0520e-02,  ...,  5.5861e-02,\n",
            "            1.9605e-02,  1.8645e-02],\n",
            "          [-1.6161e-02, -1.2307e-02, -1.2783e-02,  ..., -6.7683e-02,\n",
            "           -1.0589e-02, -1.0007e-02],\n",
            "          [ 1.9776e-02,  2.1824e-02,  7.5859e-03,  ..., -1.1652e-02,\n",
            "           -3.6287e-02, -2.7321e-02]],\n",
            "\n",
            "         [[ 2.3408e-02,  1.0959e-02, -2.1279e-02,  ..., -1.2795e-02,\n",
            "            7.1886e-03,  3.9015e-02],\n",
            "          [-7.0718e-04, -1.1121e-02, -4.0811e-02,  ..., -2.3752e-03,\n",
            "           -1.4919e-02, -1.1367e-02],\n",
            "          [ 1.6177e-02,  2.0736e-02,  1.1559e-02,  ..., -2.1132e-02,\n",
            "           -2.4160e-02, -1.8381e-02],\n",
            "          ...,\n",
            "          [-1.9383e-02, -3.1119e-02, -1.4758e-02,  ...,  9.5608e-03,\n",
            "            8.8614e-03, -1.3779e-02],\n",
            "          [ 5.4465e-03, -1.9311e-02,  3.4193e-02,  ..., -2.4402e-02,\n",
            "           -4.3357e-03,  2.7986e-02],\n",
            "          [ 4.5155e-02,  8.9034e-03, -5.0754e-03,  ..., -4.0866e-02,\n",
            "            3.1324e-02, -2.1887e-02]],\n",
            "\n",
            "         [[ 1.8403e-02, -3.3352e-02, -1.5684e-02,  ..., -2.6239e-02,\n",
            "            2.4014e-02,  3.5036e-02],\n",
            "          [-5.6479e-03, -4.5572e-02,  1.0105e-02,  ...,  1.7639e-02,\n",
            "            1.2393e-02, -3.8210e-03],\n",
            "          [-4.5983e-03, -4.6958e-02,  1.4627e-02,  ...,  2.6429e-02,\n",
            "           -1.1667e-02,  7.4409e-03],\n",
            "          ...,\n",
            "          [ 2.6675e-02, -5.2743e-02,  4.2398e-03,  ..., -2.5748e-02,\n",
            "            2.7027e-02, -1.8848e-02],\n",
            "          [ 8.2440e-03,  1.1575e-02, -2.3767e-02,  ...,  9.9610e-03,\n",
            "            5.6627e-03,  2.1254e-02],\n",
            "          [ 4.3452e-03,  4.3235e-02, -2.5197e-02,  ...,  8.4720e-03,\n",
            "           -3.5400e-03,  1.5177e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4204e-02,  5.1498e-03,  6.4632e-04,  ..., -4.1986e-02,\n",
            "           -1.0445e-02, -3.4503e-02],\n",
            "          [ 3.8031e-03,  5.5788e-02, -2.3032e-03,  ..., -6.8555e-04,\n",
            "           -2.2692e-02,  5.6992e-03],\n",
            "          [-5.7408e-03, -1.6614e-02, -2.6557e-02,  ...,  7.0247e-02,\n",
            "            6.0583e-03,  3.5718e-02],\n",
            "          ...,\n",
            "          [ 4.4964e-03,  2.5738e-03,  1.5803e-02,  ...,  1.3609e-02,\n",
            "            1.2865e-02, -7.7757e-03],\n",
            "          [ 5.0254e-03, -5.7688e-02,  1.7978e-02,  ..., -2.8550e-02,\n",
            "            1.3342e-02,  4.7349e-02],\n",
            "          [ 8.0002e-03, -7.3216e-03, -2.1323e-02,  ..., -3.7589e-02,\n",
            "           -4.0416e-02,  2.6647e-02]],\n",
            "\n",
            "         [[ 1.0272e-02,  3.4455e-02, -7.7892e-04,  ..., -1.7804e-02,\n",
            "            1.7395e-02,  4.1567e-03],\n",
            "          [-1.1379e-02,  2.8746e-02,  1.2102e-02,  ..., -3.7311e-02,\n",
            "           -3.6472e-03,  1.7210e-02],\n",
            "          [-2.8158e-03,  2.6575e-02,  1.0746e-02,  ..., -4.6048e-03,\n",
            "           -7.5171e-03,  1.8699e-02],\n",
            "          ...,\n",
            "          [-1.4394e-02, -1.0298e-02,  1.0477e-02,  ...,  2.8987e-02,\n",
            "            3.3398e-03,  3.4187e-02],\n",
            "          [-2.1582e-02,  2.8460e-02,  2.2240e-02,  ..., -3.6928e-02,\n",
            "           -4.4400e-02, -3.8616e-02],\n",
            "          [ 1.5327e-03,  2.0117e-03, -3.6534e-02,  ..., -3.3467e-03,\n",
            "            1.5529e-02,  1.4318e-02]],\n",
            "\n",
            "         [[ 1.7505e-02, -3.9768e-02, -2.1495e-02,  ...,  4.4170e-02,\n",
            "            1.4225e-02, -1.0634e-02],\n",
            "          [ 4.0998e-02,  1.9948e-02, -3.0305e-02,  ...,  1.4370e-02,\n",
            "            3.2112e-03, -3.5947e-04],\n",
            "          [ 1.8017e-02, -4.4208e-02,  3.3003e-02,  ...,  4.0463e-02,\n",
            "           -4.3131e-02, -7.4157e-02],\n",
            "          ...,\n",
            "          [ 2.9672e-02,  1.3462e-02,  2.6593e-02,  ..., -1.0309e-03,\n",
            "            3.1557e-02, -1.7248e-02],\n",
            "          [-2.6385e-02,  1.0508e-02,  6.3523e-03,  ...,  1.5473e-02,\n",
            "           -2.7822e-02,  1.1228e-03],\n",
            "          [ 1.6536e-03,  5.4364e-02,  1.5907e-02,  ...,  1.4138e-02,\n",
            "           -4.5217e-02, -2.6619e-02]]]])), ('module.encoder_k.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.0.conv1.weight', tensor([[[[ 0.0953]],\n",
            "\n",
            "         [[ 0.1736]],\n",
            "\n",
            "         [[-0.1402]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1086]],\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         [[-0.1563]]],\n",
            "\n",
            "\n",
            "        [[[-0.1641]],\n",
            "\n",
            "         [[-0.0071]],\n",
            "\n",
            "         [[ 0.2727]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0580]],\n",
            "\n",
            "         [[ 0.2194]],\n",
            "\n",
            "         [[-0.1120]]],\n",
            "\n",
            "\n",
            "        [[[-0.0537]],\n",
            "\n",
            "         [[-0.0324]],\n",
            "\n",
            "         [[ 0.2052]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1070]],\n",
            "\n",
            "         [[-0.0249]],\n",
            "\n",
            "         [[ 0.0808]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0952]],\n",
            "\n",
            "         [[-0.2897]],\n",
            "\n",
            "         [[-0.0294]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0598]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         [[-0.1976]]],\n",
            "\n",
            "\n",
            "        [[[-0.1860]],\n",
            "\n",
            "         [[-0.0718]],\n",
            "\n",
            "         [[ 0.2525]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0538]],\n",
            "\n",
            "         [[ 0.2263]],\n",
            "\n",
            "         [[ 0.1914]]],\n",
            "\n",
            "\n",
            "        [[[-0.4515]],\n",
            "\n",
            "         [[ 0.2588]],\n",
            "\n",
            "         [[ 0.0228]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0364]],\n",
            "\n",
            "         [[ 0.0959]],\n",
            "\n",
            "         [[-0.0864]]]])), ('module.encoder_k.layer1.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.0.conv2.weight', tensor([[[[-0.0503,  0.0082,  0.0151],\n",
            "          [-0.0864,  0.0201, -0.0398],\n",
            "          [-0.0194,  0.0198,  0.0288]],\n",
            "\n",
            "         [[ 0.0515,  0.0416, -0.0776],\n",
            "          [ 0.0598, -0.0157,  0.0211],\n",
            "          [-0.0337, -0.0146, -0.0351]],\n",
            "\n",
            "         [[-0.0137, -0.0381,  0.0651],\n",
            "          [ 0.0350, -0.0639,  0.0508],\n",
            "          [-0.0206,  0.0213, -0.0806]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0087,  0.0487, -0.0541],\n",
            "          [ 0.0186,  0.0020, -0.0955],\n",
            "          [-0.0774,  0.0930, -0.0208]],\n",
            "\n",
            "         [[-0.0222, -0.0623,  0.0315],\n",
            "          [ 0.0644, -0.0668, -0.0968],\n",
            "          [-0.0893, -0.0195, -0.0200]],\n",
            "\n",
            "         [[-0.0394, -0.0638,  0.0178],\n",
            "          [-0.0823, -0.0321,  0.0420],\n",
            "          [-0.0490,  0.0152,  0.0242]]],\n",
            "\n",
            "\n",
            "        [[[-0.0579,  0.0290,  0.0165],\n",
            "          [ 0.0490,  0.0363,  0.1265],\n",
            "          [ 0.0931,  0.0347,  0.0121]],\n",
            "\n",
            "         [[ 0.0273,  0.0466, -0.0225],\n",
            "          [-0.0083, -0.0497,  0.0003],\n",
            "          [-0.1060,  0.0444, -0.0250]],\n",
            "\n",
            "         [[ 0.0043, -0.0553,  0.0670],\n",
            "          [ 0.0851,  0.0343, -0.0508],\n",
            "          [-0.0814, -0.0263, -0.1125]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0116, -0.0296, -0.0278],\n",
            "          [ 0.0895, -0.0178,  0.0262],\n",
            "          [-0.0558, -0.0599,  0.0509]],\n",
            "\n",
            "         [[-0.0023, -0.0432, -0.0626],\n",
            "          [-0.0371,  0.0572,  0.0531],\n",
            "          [-0.0518, -0.0283, -0.0850]],\n",
            "\n",
            "         [[ 0.0099,  0.0266,  0.0954],\n",
            "          [ 0.0287,  0.0324, -0.0365],\n",
            "          [ 0.0725,  0.0800, -0.0616]]],\n",
            "\n",
            "\n",
            "        [[[-0.1050,  0.0031,  0.0057],\n",
            "          [ 0.0368,  0.0322, -0.0948],\n",
            "          [-0.0974, -0.0177,  0.0062]],\n",
            "\n",
            "         [[ 0.0012,  0.0179,  0.0028],\n",
            "          [-0.0045,  0.0955,  0.0806],\n",
            "          [-0.0363,  0.0656,  0.1129]],\n",
            "\n",
            "         [[ 0.0220,  0.0024, -0.1031],\n",
            "          [-0.0946,  0.0183,  0.0122],\n",
            "          [ 0.0750, -0.0300,  0.0271]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0645, -0.1163,  0.0157],\n",
            "          [ 0.1172,  0.0285, -0.0353],\n",
            "          [ 0.0278, -0.0606,  0.0098]],\n",
            "\n",
            "         [[-0.0210,  0.0239, -0.0548],\n",
            "          [-0.0453,  0.0913, -0.0608],\n",
            "          [-0.0110,  0.1067,  0.0035]],\n",
            "\n",
            "         [[-0.0636,  0.0035, -0.0306],\n",
            "          [ 0.0949,  0.0762,  0.0221],\n",
            "          [ 0.0006, -0.0208, -0.0439]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1025, -0.1338, -0.0422],\n",
            "          [-0.0293, -0.0308, -0.0128],\n",
            "          [-0.0152,  0.0761,  0.0145]],\n",
            "\n",
            "         [[ 0.0104, -0.0274,  0.0339],\n",
            "          [-0.1868, -0.0419, -0.0578],\n",
            "          [ 0.1339,  0.0050,  0.0860]],\n",
            "\n",
            "         [[ 0.0179,  0.0811, -0.1119],\n",
            "          [ 0.0541,  0.1185, -0.0222],\n",
            "          [-0.0892,  0.0222,  0.0395]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1419,  0.0914,  0.0201],\n",
            "          [-0.0113, -0.0709,  0.0150],\n",
            "          [-0.0608, -0.0171, -0.0725]],\n",
            "\n",
            "         [[-0.0247, -0.0260,  0.0348],\n",
            "          [ 0.0721, -0.0374, -0.0026],\n",
            "          [ 0.0679,  0.0066,  0.0163]],\n",
            "\n",
            "         [[ 0.0056, -0.0475, -0.0386],\n",
            "          [-0.0294, -0.0072,  0.0433],\n",
            "          [ 0.1199, -0.0136,  0.0428]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0608, -0.0322, -0.0085],\n",
            "          [-0.0598, -0.0667, -0.0329],\n",
            "          [ 0.0607, -0.0763, -0.0750]],\n",
            "\n",
            "         [[-0.0419, -0.1956,  0.0004],\n",
            "          [-0.0137,  0.1166,  0.0582],\n",
            "          [-0.0116,  0.0063, -0.0289]],\n",
            "\n",
            "         [[-0.0224,  0.0332, -0.1120],\n",
            "          [-0.1162, -0.0252,  0.0242],\n",
            "          [ 0.1963, -0.0145,  0.0184]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0264,  0.0890,  0.0523],\n",
            "          [ 0.0194, -0.0512, -0.0061],\n",
            "          [-0.0152,  0.0824, -0.0444]],\n",
            "\n",
            "         [[ 0.0468, -0.0456,  0.0277],\n",
            "          [-0.0202, -0.0626,  0.0102],\n",
            "          [-0.0094,  0.0107,  0.0494]],\n",
            "\n",
            "         [[-0.0484, -0.0689, -0.0976],\n",
            "          [ 0.0118, -0.0284,  0.0255],\n",
            "          [-0.1383, -0.0997, -0.0219]]],\n",
            "\n",
            "\n",
            "        [[[-0.0527,  0.1238,  0.0615],\n",
            "          [ 0.0659, -0.0324,  0.0751],\n",
            "          [ 0.0907, -0.1133,  0.0249]],\n",
            "\n",
            "         [[-0.0110, -0.0023, -0.0174],\n",
            "          [ 0.0196,  0.0117, -0.0020],\n",
            "          [-0.0474, -0.0106, -0.0483]],\n",
            "\n",
            "         [[ 0.0768,  0.0051,  0.0955],\n",
            "          [-0.0243,  0.0323, -0.0065],\n",
            "          [-0.0158, -0.0086, -0.0324]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0818, -0.1410, -0.0508],\n",
            "          [ 0.0659, -0.0870, -0.0003],\n",
            "          [-0.0525,  0.0063, -0.0181]],\n",
            "\n",
            "         [[-0.0286, -0.0691,  0.0024],\n",
            "          [-0.0282,  0.0489, -0.0776],\n",
            "          [ 0.0347,  0.0379, -0.0288]],\n",
            "\n",
            "         [[-0.1418, -0.0059,  0.0695],\n",
            "          [-0.0191,  0.0104, -0.1015],\n",
            "          [-0.0149, -0.0225, -0.0067]]]])), ('module.encoder_k.layer1.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.0.conv3.weight', tensor([[[[ 0.0086]],\n",
            "\n",
            "         [[ 0.1217]],\n",
            "\n",
            "         [[-0.0309]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0394]],\n",
            "\n",
            "         [[-0.0780]],\n",
            "\n",
            "         [[ 0.1036]]],\n",
            "\n",
            "\n",
            "        [[[-0.0775]],\n",
            "\n",
            "         [[-0.0274]],\n",
            "\n",
            "         [[-0.0844]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1288]],\n",
            "\n",
            "         [[-0.0166]],\n",
            "\n",
            "         [[-0.0381]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0108]],\n",
            "\n",
            "         [[-0.0093]],\n",
            "\n",
            "         [[-0.1621]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0759]],\n",
            "\n",
            "         [[ 0.0121]],\n",
            "\n",
            "         [[ 0.0193]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0542]],\n",
            "\n",
            "         [[-0.1269]],\n",
            "\n",
            "         [[ 0.0742]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         [[ 0.0302]],\n",
            "\n",
            "         [[-0.0487]]],\n",
            "\n",
            "\n",
            "        [[[-0.0417]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         [[ 0.0897]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1649]],\n",
            "\n",
            "         [[-0.1305]],\n",
            "\n",
            "         [[ 0.0708]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0028]],\n",
            "\n",
            "         [[-0.0789]],\n",
            "\n",
            "         [[ 0.0831]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0823]],\n",
            "\n",
            "         [[-0.0459]],\n",
            "\n",
            "         [[ 0.0028]]]])), ('module.encoder_k.layer1.0.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.0.downsample.0.weight', tensor([[[[ 0.0380]],\n",
            "\n",
            "         [[ 0.0571]],\n",
            "\n",
            "         [[ 0.0408]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0871]],\n",
            "\n",
            "         [[ 0.0048]],\n",
            "\n",
            "         [[ 0.1026]]],\n",
            "\n",
            "\n",
            "        [[[-0.0139]],\n",
            "\n",
            "         [[ 0.0301]],\n",
            "\n",
            "         [[ 0.0937]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0712]],\n",
            "\n",
            "         [[-0.0161]],\n",
            "\n",
            "         [[-0.0416]]],\n",
            "\n",
            "\n",
            "        [[[-0.2329]],\n",
            "\n",
            "         [[-0.1154]],\n",
            "\n",
            "         [[ 0.2080]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0241]],\n",
            "\n",
            "         [[-0.1014]],\n",
            "\n",
            "         [[-0.2189]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0531]],\n",
            "\n",
            "         [[ 0.0785]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0398]],\n",
            "\n",
            "         [[ 0.0452]],\n",
            "\n",
            "         [[ 0.0389]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1086]],\n",
            "\n",
            "         [[-0.0810]],\n",
            "\n",
            "         [[ 0.1441]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0723]],\n",
            "\n",
            "         [[ 0.0156]],\n",
            "\n",
            "         [[ 0.1300]]],\n",
            "\n",
            "\n",
            "        [[[-0.0777]],\n",
            "\n",
            "         [[-0.0059]],\n",
            "\n",
            "         [[-0.0633]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1431]],\n",
            "\n",
            "         [[ 0.1648]],\n",
            "\n",
            "         [[ 0.0437]]]])), ('module.encoder_k.layer1.0.downsample.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.0.downsample.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.downsample.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.0.downsample.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.1.conv1.weight', tensor([[[[-0.2225]],\n",
            "\n",
            "         [[-0.2296]],\n",
            "\n",
            "         [[-0.1735]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2486]],\n",
            "\n",
            "         [[-0.0756]],\n",
            "\n",
            "         [[-0.0332]]],\n",
            "\n",
            "\n",
            "        [[[-0.1860]],\n",
            "\n",
            "         [[ 0.0561]],\n",
            "\n",
            "         [[-0.0155]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         [[-0.3197]],\n",
            "\n",
            "         [[ 0.2779]]],\n",
            "\n",
            "\n",
            "        [[[-0.0550]],\n",
            "\n",
            "         [[-0.0024]],\n",
            "\n",
            "         [[ 0.2024]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0075]],\n",
            "\n",
            "         [[ 0.0226]],\n",
            "\n",
            "         [[ 0.1982]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0716]],\n",
            "\n",
            "         [[-0.2513]],\n",
            "\n",
            "         [[-0.1058]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.4073]],\n",
            "\n",
            "         [[-0.2568]],\n",
            "\n",
            "         [[-0.1591]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2728]],\n",
            "\n",
            "         [[ 0.1823]],\n",
            "\n",
            "         [[-0.1355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2628]],\n",
            "\n",
            "         [[ 0.1837]],\n",
            "\n",
            "         [[ 0.1337]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1592]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[ 0.0342]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2679]],\n",
            "\n",
            "         [[-0.0896]],\n",
            "\n",
            "         [[ 0.1781]]]])), ('module.encoder_k.layer1.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.1.conv2.weight', tensor([[[[-6.5673e-02,  6.5597e-02,  5.1537e-03],\n",
            "          [-6.0078e-03,  8.3128e-02, -4.9375e-02],\n",
            "          [ 9.3630e-02,  4.0858e-02, -6.1507e-02]],\n",
            "\n",
            "         [[-8.2784e-02,  4.0099e-02, -9.3083e-02],\n",
            "          [ 7.1944e-02, -3.3836e-02,  6.5259e-03],\n",
            "          [ 2.4779e-02, -5.3078e-02, -5.4378e-02]],\n",
            "\n",
            "         [[-8.3928e-03,  1.0463e-01, -8.7174e-02],\n",
            "          [ 8.0704e-02, -2.4267e-02, -6.5795e-02],\n",
            "          [ 2.9890e-02,  9.1220e-04,  1.4737e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.9785e-03, -9.4143e-02,  1.8813e-02],\n",
            "          [-2.9107e-02,  5.7558e-02, -4.6638e-02],\n",
            "          [ 3.5302e-03,  6.7818e-02, -3.9947e-02]],\n",
            "\n",
            "         [[ 5.5756e-02,  2.5369e-02,  2.5120e-02],\n",
            "          [ 2.0748e-02, -4.2986e-02, -4.8831e-02],\n",
            "          [ 3.0477e-03, -1.0818e-01, -6.0839e-02]],\n",
            "\n",
            "         [[-4.5327e-02, -2.1476e-02,  4.9856e-02],\n",
            "          [ 8.0569e-03, -4.7794e-02, -2.0113e-03],\n",
            "          [-1.7258e-01, -6.5406e-02,  7.6279e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.6070e-03, -6.2043e-02,  4.3469e-02],\n",
            "          [ 1.4060e-02,  2.3879e-02, -8.9212e-02],\n",
            "          [ 1.0773e-02,  2.0363e-02,  1.3298e-02]],\n",
            "\n",
            "         [[ 5.5590e-02, -6.2404e-02,  3.1229e-02],\n",
            "          [ 1.3064e-01,  7.4132e-02,  2.8472e-02],\n",
            "          [-9.7442e-02,  6.6070e-02,  1.2241e-02]],\n",
            "\n",
            "         [[ 2.3923e-02, -1.2311e-01, -6.8299e-02],\n",
            "          [ 6.6578e-02, -6.9903e-02, -5.5504e-02],\n",
            "          [-3.4481e-04, -1.4249e-01,  1.1030e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.7050e-02, -2.7398e-03, -2.0177e-03],\n",
            "          [-4.9660e-03,  1.0688e-02,  8.2533e-02],\n",
            "          [ 1.7431e-02, -3.9503e-02,  5.7283e-02]],\n",
            "\n",
            "         [[-2.3632e-02, -1.8841e-02,  3.4771e-02],\n",
            "          [ 1.3370e-01,  3.9075e-02,  1.1259e-01],\n",
            "          [ 8.2257e-02, -5.4913e-02,  4.2678e-02]],\n",
            "\n",
            "         [[-2.8088e-02,  7.3369e-02,  3.4175e-02],\n",
            "          [ 5.2580e-02, -3.2959e-02, -7.2868e-02],\n",
            "          [ 6.9150e-02,  4.1473e-02,  2.6726e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4513e-02,  5.8604e-02, -3.7320e-02],\n",
            "          [ 6.4221e-02, -3.0385e-03, -1.7816e-01],\n",
            "          [-5.5555e-02, -3.2168e-02, -1.3486e-01]],\n",
            "\n",
            "         [[-5.4363e-02, -5.9631e-02,  6.7412e-02],\n",
            "          [-8.2694e-02,  1.1926e-01,  1.6039e-02],\n",
            "          [ 3.7751e-02, -2.3702e-02,  2.9976e-02]],\n",
            "\n",
            "         [[-5.0905e-02,  3.0562e-02,  7.1059e-02],\n",
            "          [ 6.7741e-03,  5.7531e-02, -4.1475e-02],\n",
            "          [-7.5536e-02,  2.0857e-02,  1.0407e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.0639e-02, -2.6243e-02, -1.4337e-02],\n",
            "          [-5.3915e-03,  1.7152e-02,  7.5500e-02],\n",
            "          [ 3.3060e-02,  3.7353e-02,  2.1464e-02]],\n",
            "\n",
            "         [[-4.3894e-02,  8.8875e-02,  3.8173e-02],\n",
            "          [-7.3647e-02, -4.3829e-03,  1.0784e-02],\n",
            "          [-6.9969e-02, -2.2678e-03,  7.8271e-02]],\n",
            "\n",
            "         [[ 3.5074e-02, -3.1899e-02, -7.5564e-02],\n",
            "          [ 7.1015e-02, -1.1879e-01,  7.6878e-02],\n",
            "          [ 6.5666e-02, -9.8525e-03, -6.4458e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.5469e-02,  5.5147e-02,  3.1574e-03],\n",
            "          [ 2.6864e-02,  4.9064e-02,  4.5578e-02],\n",
            "          [ 5.8666e-02,  4.7466e-02,  1.2792e-01]],\n",
            "\n",
            "         [[-6.9840e-03, -1.1045e-01,  7.2633e-02],\n",
            "          [-1.1106e-02,  5.8288e-02,  1.0451e-01],\n",
            "          [-6.7101e-02, -3.8129e-02,  4.4633e-02]],\n",
            "\n",
            "         [[-2.9951e-03, -3.4150e-02, -2.1943e-02],\n",
            "          [-5.4951e-02, -2.6643e-02,  4.2370e-02],\n",
            "          [-2.2774e-02,  2.4258e-02,  1.1675e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1285e-02,  1.5558e-02,  7.6102e-02],\n",
            "          [-2.6794e-02,  8.6562e-02, -1.9055e-03],\n",
            "          [-9.7718e-02,  8.7692e-02, -4.8950e-02]],\n",
            "\n",
            "         [[-8.7578e-02,  2.4455e-02,  7.8888e-02],\n",
            "          [ 2.9745e-02, -2.2924e-02, -3.9564e-03],\n",
            "          [ 5.0226e-02, -7.6325e-02, -7.0053e-02]],\n",
            "\n",
            "         [[ 4.7228e-03, -7.1214e-02, -4.4870e-02],\n",
            "          [-2.0086e-01, -8.6639e-02,  8.7553e-03],\n",
            "          [-2.8885e-02, -3.5340e-02,  2.9298e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6981e-02,  8.8044e-02, -2.7243e-02],\n",
            "          [ 3.8394e-02,  1.9731e-04, -1.7240e-02],\n",
            "          [-6.5699e-02,  4.7398e-02, -1.0411e-01]],\n",
            "\n",
            "         [[-3.0350e-02, -6.3512e-02,  2.0827e-02],\n",
            "          [-5.2706e-02,  4.0507e-04, -4.7975e-02],\n",
            "          [ 1.4005e-02, -1.8404e-02, -1.4714e-02]],\n",
            "\n",
            "         [[ 3.4095e-02, -9.7688e-03,  8.5852e-02],\n",
            "          [-1.0031e-01, -1.4331e-01, -9.0626e-03],\n",
            "          [ 1.2238e-01,  2.3100e-02, -6.8060e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.3225e-03,  1.3182e-02, -3.2347e-02],\n",
            "          [ 8.9527e-02,  3.2962e-02,  1.8867e-02],\n",
            "          [ 7.2466e-02, -7.3928e-02, -2.7953e-02]],\n",
            "\n",
            "         [[ 6.3800e-02,  1.4418e-01,  3.4040e-02],\n",
            "          [ 7.4271e-02,  8.5860e-03, -2.5841e-02],\n",
            "          [-2.3854e-02, -1.1485e-01,  2.6870e-02]],\n",
            "\n",
            "         [[ 5.9830e-02, -3.6188e-02, -3.8140e-02],\n",
            "          [ 2.8009e-02,  3.1075e-02, -3.7484e-02],\n",
            "          [ 8.4571e-03, -1.7862e-02,  3.9864e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 7.9828e-02, -5.4043e-02, -2.9599e-02],\n",
            "          [ 1.6376e-02,  2.0085e-03,  3.5066e-02],\n",
            "          [ 2.3815e-02, -1.0063e-01, -5.8876e-02]],\n",
            "\n",
            "         [[-6.4904e-02,  5.8849e-02,  5.6255e-02],\n",
            "          [-5.0280e-03,  6.4268e-03,  2.3374e-02],\n",
            "          [-6.1599e-02,  1.1111e-01, -1.0597e-01]],\n",
            "\n",
            "         [[-4.8450e-02, -5.7946e-02,  7.5990e-02],\n",
            "          [-1.0928e-01, -5.8135e-02,  2.8330e-02],\n",
            "          [-5.9680e-03, -8.4228e-02,  4.4362e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.2177e-02,  1.1847e-03, -3.8432e-02],\n",
            "          [-2.2157e-02, -6.9662e-03, -1.6152e-01],\n",
            "          [ 1.2358e-02,  1.0428e-02,  1.6503e-02]],\n",
            "\n",
            "         [[-6.8377e-02, -1.0550e-01, -4.7228e-02],\n",
            "          [ 2.9491e-02, -2.9811e-02,  1.3245e-02],\n",
            "          [ 9.6639e-02,  3.0286e-02,  8.3568e-02]],\n",
            "\n",
            "         [[-1.8480e-01, -2.0892e-02,  1.9227e-02],\n",
            "          [ 3.7227e-02,  4.6209e-02, -1.2227e-01],\n",
            "          [-1.2171e-01, -7.8799e-02,  5.2849e-02]]]])), ('module.encoder_k.layer1.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.1.conv3.weight', tensor([[[[ 0.0277]],\n",
            "\n",
            "         [[ 0.0183]],\n",
            "\n",
            "         [[-0.0957]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1118]],\n",
            "\n",
            "         [[ 0.0809]],\n",
            "\n",
            "         [[-0.0681]]],\n",
            "\n",
            "\n",
            "        [[[-0.1046]],\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[-0.0474]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0763]],\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[ 0.0323]]],\n",
            "\n",
            "\n",
            "        [[[-0.0742]],\n",
            "\n",
            "         [[ 0.0631]],\n",
            "\n",
            "         [[-0.0554]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0305]],\n",
            "\n",
            "         [[-0.0777]],\n",
            "\n",
            "         [[-0.0941]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0636]],\n",
            "\n",
            "         [[-0.0241]],\n",
            "\n",
            "         [[-0.2409]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0855]],\n",
            "\n",
            "         [[ 0.0521]],\n",
            "\n",
            "         [[ 0.0948]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1568]],\n",
            "\n",
            "         [[ 0.0065]],\n",
            "\n",
            "         [[ 0.0316]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1434]],\n",
            "\n",
            "         [[-0.0642]],\n",
            "\n",
            "         [[ 0.0926]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0520]],\n",
            "\n",
            "         [[-0.1135]],\n",
            "\n",
            "         [[-0.0087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0121]],\n",
            "\n",
            "         [[-0.0872]],\n",
            "\n",
            "         [[ 0.0980]]]])), ('module.encoder_k.layer1.1.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.1.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.2.conv1.weight', tensor([[[[-0.1526]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         [[ 0.1592]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0120]],\n",
            "\n",
            "         [[ 0.3159]],\n",
            "\n",
            "         [[-0.0656]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1162]],\n",
            "\n",
            "         [[-0.1572]],\n",
            "\n",
            "         [[-0.1217]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2382]],\n",
            "\n",
            "         [[ 0.1467]],\n",
            "\n",
            "         [[-0.1869]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0670]],\n",
            "\n",
            "         [[ 0.2555]],\n",
            "\n",
            "         [[ 0.1076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0891]],\n",
            "\n",
            "         [[-0.0641]],\n",
            "\n",
            "         [[-0.0242]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0284]],\n",
            "\n",
            "         [[ 0.0487]],\n",
            "\n",
            "         [[-0.3654]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1371]],\n",
            "\n",
            "         [[ 0.2403]],\n",
            "\n",
            "         [[-0.0616]]],\n",
            "\n",
            "\n",
            "        [[[-0.0829]],\n",
            "\n",
            "         [[ 0.1793]],\n",
            "\n",
            "         [[-0.0796]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0634]],\n",
            "\n",
            "         [[ 0.0374]],\n",
            "\n",
            "         [[-0.1871]]],\n",
            "\n",
            "\n",
            "        [[[-0.3399]],\n",
            "\n",
            "         [[-0.0732]],\n",
            "\n",
            "         [[ 0.1289]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2831]],\n",
            "\n",
            "         [[ 0.1750]],\n",
            "\n",
            "         [[ 0.0203]]]])), ('module.encoder_k.layer1.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.2.conv2.weight', tensor([[[[-6.0778e-03,  2.1031e-02,  2.5290e-02],\n",
            "          [-5.1883e-02,  9.1967e-03,  2.5988e-02],\n",
            "          [ 3.9177e-03,  3.2230e-02,  7.0825e-02]],\n",
            "\n",
            "         [[ 3.9418e-02,  6.9763e-02,  1.1778e-01],\n",
            "          [ 1.4276e-02,  7.8560e-02,  2.9490e-02],\n",
            "          [-6.5573e-02,  9.8496e-03, -2.1543e-02]],\n",
            "\n",
            "         [[-2.8932e-02, -9.0720e-02,  2.9278e-02],\n",
            "          [ 2.3240e-02, -1.1038e-02, -1.0610e-02],\n",
            "          [-3.4702e-02,  6.9394e-02,  9.1250e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.0101e-02, -4.4052e-03,  1.9697e-02],\n",
            "          [-1.5685e-02, -4.5189e-02,  3.0481e-02],\n",
            "          [ 3.6819e-03, -6.3322e-02,  3.5783e-05]],\n",
            "\n",
            "         [[-1.6072e-02,  9.6707e-02, -3.9388e-02],\n",
            "          [-7.8277e-02,  3.8245e-02, -4.2239e-02],\n",
            "          [-2.4985e-02,  1.0249e-01, -5.5338e-02]],\n",
            "\n",
            "         [[-1.9227e-02, -5.4404e-02, -8.4714e-02],\n",
            "          [-5.9622e-02,  4.2524e-02,  1.0980e-01],\n",
            "          [ 3.3176e-02,  1.4340e-02,  7.2818e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4554e-02,  1.9929e-02, -7.8697e-02],\n",
            "          [ 9.6134e-03, -8.3944e-02,  7.2779e-02],\n",
            "          [ 5.7358e-02, -9.0376e-02, -5.0937e-03]],\n",
            "\n",
            "         [[-1.2439e-02, -8.4718e-02, -6.4281e-05],\n",
            "          [-1.1148e-01, -5.6460e-02, -2.6405e-02],\n",
            "          [-1.5739e-02, -2.4567e-04, -8.8720e-02]],\n",
            "\n",
            "         [[-1.7407e-02, -1.1308e-02,  4.6703e-02],\n",
            "          [-7.2237e-02, -5.2607e-02,  6.3663e-02],\n",
            "          [ 6.4852e-02, -7.3712e-02,  5.3530e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.1049e-02,  7.3583e-03, -8.8328e-02],\n",
            "          [-5.1333e-02, -4.4481e-02,  4.9971e-02],\n",
            "          [-1.7573e-02, -2.5875e-02,  1.6520e-02]],\n",
            "\n",
            "         [[-6.9118e-02, -2.9721e-02, -3.7937e-02],\n",
            "          [-6.0912e-02, -2.5121e-02,  2.4538e-02],\n",
            "          [-5.7496e-02,  7.1583e-02, -3.6002e-02]],\n",
            "\n",
            "         [[-3.5448e-03,  8.4357e-02,  1.7223e-02],\n",
            "          [-8.0595e-02, -8.6246e-03,  3.2503e-02],\n",
            "          [-8.5198e-02,  4.1421e-02, -5.5877e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.6130e-02,  2.0584e-02, -3.2139e-02],\n",
            "          [-1.0153e-01,  2.5168e-02,  4.0848e-02],\n",
            "          [-1.0837e-01,  1.0187e-01,  9.4544e-03]],\n",
            "\n",
            "         [[-2.2456e-02,  5.9296e-02,  1.8459e-02],\n",
            "          [ 1.0181e-02, -8.8629e-02,  6.7996e-02],\n",
            "          [ 1.0445e-01,  5.9389e-02,  7.8330e-04]],\n",
            "\n",
            "         [[-5.3213e-02, -9.7417e-02,  1.8210e-02],\n",
            "          [ 1.0116e-01,  6.0832e-02,  8.5433e-02],\n",
            "          [ 4.8347e-02, -6.5057e-03,  6.1583e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7600e-02,  4.8636e-02,  1.3369e-02],\n",
            "          [-5.2037e-03, -6.1425e-03, -1.7332e-01],\n",
            "          [ 4.6918e-02,  7.0206e-02,  6.1246e-02]],\n",
            "\n",
            "         [[-4.7921e-02,  2.8547e-02, -2.2433e-02],\n",
            "          [ 1.1644e-01, -1.1179e-01,  4.2170e-02],\n",
            "          [ 4.6279e-02, -5.5693e-03,  4.0620e-02]],\n",
            "\n",
            "         [[-4.3897e-03, -1.9469e-03, -2.9500e-03],\n",
            "          [-3.9732e-02,  6.5351e-02,  2.3392e-02],\n",
            "          [-6.3447e-02, -9.5497e-03,  9.9367e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.3290e-02,  4.3588e-02, -6.4836e-02],\n",
            "          [ 2.7611e-02,  1.4736e-02, -4.6644e-02],\n",
            "          [ 1.2004e-03,  7.7106e-02, -6.9098e-03]],\n",
            "\n",
            "         [[-4.6347e-02, -3.4102e-02, -5.4033e-02],\n",
            "          [-1.8556e-02,  1.9300e-01, -1.0496e-01],\n",
            "          [-3.4021e-02, -2.7948e-02,  2.0478e-02]],\n",
            "\n",
            "         [[ 7.8592e-02,  3.8000e-03, -5.4964e-02],\n",
            "          [-7.5379e-02, -7.1115e-03, -8.3431e-02],\n",
            "          [-8.7539e-03,  7.9315e-02, -1.0940e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.7544e-02, -6.7479e-02, -2.9374e-02],\n",
            "          [-3.9698e-02, -1.2420e-02, -1.6550e-01],\n",
            "          [ 3.3778e-03, -5.8733e-02, -7.9985e-02]],\n",
            "\n",
            "         [[-2.9937e-02, -2.4995e-02,  2.9781e-02],\n",
            "          [ 2.1947e-02,  6.3806e-02, -5.7573e-02],\n",
            "          [-5.3851e-02,  5.7907e-02, -6.4272e-02]],\n",
            "\n",
            "         [[ 8.5677e-02,  5.1765e-02, -8.0795e-02],\n",
            "          [-1.6212e-02,  4.7519e-02,  4.3720e-02],\n",
            "          [ 2.7326e-03, -1.3319e-02,  4.2344e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.9530e-02,  3.7925e-02, -9.9350e-03],\n",
            "          [ 6.4543e-02,  4.9591e-02,  6.1224e-02],\n",
            "          [ 4.4094e-02, -6.5532e-03, -7.1924e-02]],\n",
            "\n",
            "         [[ 5.3679e-02, -5.8549e-02, -4.0666e-02],\n",
            "          [-7.7944e-02,  2.2262e-02,  1.1973e-02],\n",
            "          [ 1.0957e-02,  3.6152e-02,  2.0136e-02]],\n",
            "\n",
            "         [[ 7.0934e-02,  8.0707e-02, -1.0715e-01],\n",
            "          [ 1.2147e-01, -3.7879e-02,  7.5630e-03],\n",
            "          [ 7.4727e-02, -1.1200e-01,  4.2435e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2437e-02,  4.4417e-02, -1.8937e-01],\n",
            "          [ 2.1761e-02,  8.8527e-03,  5.9626e-03],\n",
            "          [ 4.8839e-02, -2.0821e-02, -6.5295e-02]],\n",
            "\n",
            "         [[ 1.0098e-01,  2.3350e-02,  3.1670e-02],\n",
            "          [ 1.1844e-01, -5.7054e-02,  4.0257e-02],\n",
            "          [ 7.8167e-03,  9.1751e-02,  3.0461e-02]],\n",
            "\n",
            "         [[ 2.7224e-02,  6.5090e-02, -3.0683e-02],\n",
            "          [-6.4743e-02,  1.8940e-02,  4.5373e-02],\n",
            "          [-8.8446e-03, -1.8280e-02,  9.8689e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.4499e-02,  6.3660e-02,  2.3537e-02],\n",
            "          [ 4.3741e-03, -6.5495e-02, -2.3966e-02],\n",
            "          [-1.2779e-02,  2.9163e-02, -6.8777e-02]],\n",
            "\n",
            "         [[-2.7703e-02,  8.8968e-02, -9.8178e-02],\n",
            "          [-6.2503e-03,  4.5962e-02, -5.9999e-02],\n",
            "          [ 3.1836e-02,  7.9025e-02,  5.9087e-03]],\n",
            "\n",
            "         [[ 3.0821e-03,  4.4218e-02, -1.7628e-02],\n",
            "          [-3.0777e-03, -5.7251e-02, -1.1024e-02],\n",
            "          [-9.4324e-03, -1.5370e-03,  1.9066e-01]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.8486e-02, -4.7505e-02, -1.2007e-01],\n",
            "          [ 2.8841e-02, -2.6374e-02,  5.5415e-02],\n",
            "          [-6.8415e-02, -8.7069e-02,  2.9346e-03]],\n",
            "\n",
            "         [[ 7.2117e-04,  4.3525e-02,  1.8491e-02],\n",
            "          [ 1.0621e-01,  1.4593e-02,  1.4970e-02],\n",
            "          [ 8.6689e-03, -1.0337e-01,  5.6997e-02]],\n",
            "\n",
            "         [[-5.6581e-02, -2.2049e-02, -7.6268e-02],\n",
            "          [ 5.3347e-03,  2.3434e-02,  3.2561e-03],\n",
            "          [ 1.7297e-02,  4.4042e-02, -3.6694e-02]]]])), ('module.encoder_k.layer1.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer1.2.conv3.weight', tensor([[[[-0.0433]],\n",
            "\n",
            "         [[ 0.0604]],\n",
            "\n",
            "         [[ 0.0423]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168]],\n",
            "\n",
            "         [[ 0.1426]],\n",
            "\n",
            "         [[ 0.1472]]],\n",
            "\n",
            "\n",
            "        [[[-0.0353]],\n",
            "\n",
            "         [[ 0.0615]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0833]],\n",
            "\n",
            "         [[ 0.0340]],\n",
            "\n",
            "         [[-0.0431]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0315]],\n",
            "\n",
            "         [[-0.1730]],\n",
            "\n",
            "         [[ 0.0494]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1409]],\n",
            "\n",
            "         [[ 0.0236]],\n",
            "\n",
            "         [[-0.1658]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0690]],\n",
            "\n",
            "         [[-0.0737]],\n",
            "\n",
            "         [[-0.0288]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0120]],\n",
            "\n",
            "         [[ 0.0804]],\n",
            "\n",
            "         [[ 0.0157]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0792]],\n",
            "\n",
            "         [[-0.1062]],\n",
            "\n",
            "         [[-0.1223]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0941]],\n",
            "\n",
            "         [[-0.0180]],\n",
            "\n",
            "         [[ 0.0022]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0565]],\n",
            "\n",
            "         [[ 0.1556]],\n",
            "\n",
            "         [[ 0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0662]],\n",
            "\n",
            "         [[-0.0322]],\n",
            "\n",
            "         [[-0.0803]]]])), ('module.encoder_k.layer1.2.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer1.2.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer1.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.0.conv1.weight', tensor([[[[ 0.0335]],\n",
            "\n",
            "         [[ 0.0788]],\n",
            "\n",
            "         [[ 0.0653]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1057]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[-0.0691]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2211]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         [[ 0.1696]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0826]],\n",
            "\n",
            "         [[ 0.0656]],\n",
            "\n",
            "         [[-0.1677]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2016]],\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.1313]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0590]],\n",
            "\n",
            "         [[ 0.2383]],\n",
            "\n",
            "         [[-0.1460]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0083]],\n",
            "\n",
            "         [[-0.0768]],\n",
            "\n",
            "         [[-0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0340]],\n",
            "\n",
            "         [[-0.0193]],\n",
            "\n",
            "         [[ 0.0039]]],\n",
            "\n",
            "\n",
            "        [[[-0.0493]],\n",
            "\n",
            "         [[ 0.0630]],\n",
            "\n",
            "         [[ 0.1726]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0117]],\n",
            "\n",
            "         [[-0.2906]],\n",
            "\n",
            "         [[ 0.0218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2447]],\n",
            "\n",
            "         [[ 0.1345]],\n",
            "\n",
            "         [[ 0.3536]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1933]],\n",
            "\n",
            "         [[-0.0029]],\n",
            "\n",
            "         [[-0.1509]]]])), ('module.encoder_k.layer2.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.0.conv2.weight', tensor([[[[ 9.5564e-02,  7.4802e-03,  6.7313e-02],\n",
            "          [-3.0044e-02, -1.5301e-02,  1.1513e-02],\n",
            "          [-1.0669e-02,  7.7900e-03, -1.1240e-02]],\n",
            "\n",
            "         [[ 3.5639e-02,  2.9068e-02,  2.7528e-02],\n",
            "          [ 5.7293e-02, -9.8795e-03,  2.0632e-02],\n",
            "          [-1.6313e-02, -8.3863e-02, -4.4737e-02]],\n",
            "\n",
            "         [[ 4.4271e-02,  1.8065e-02,  2.0374e-02],\n",
            "          [ 1.5781e-02,  4.0068e-03,  5.6635e-03],\n",
            "          [-1.8553e-02, -1.7232e-03, -2.7541e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1890e-02, -1.3627e-02, -5.1101e-02],\n",
            "          [ 2.0286e-03,  2.2264e-02,  1.8767e-05],\n",
            "          [ 8.1193e-03,  2.7130e-02, -4.5714e-02]],\n",
            "\n",
            "         [[ 3.7817e-02,  2.7810e-02, -4.9336e-02],\n",
            "          [-7.6076e-03,  6.6028e-03, -1.4366e-02],\n",
            "          [ 7.7824e-03, -4.4112e-02,  5.2326e-02]],\n",
            "\n",
            "         [[ 4.4187e-02, -9.5055e-03, -5.1266e-03],\n",
            "          [-9.1394e-03, -7.4296e-02, -7.4889e-02],\n",
            "          [ 1.6104e-02,  2.1934e-02, -6.0913e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2608e-02,  4.1064e-02, -3.2276e-02],\n",
            "          [ 4.2542e-02,  1.2734e-02,  5.3378e-02],\n",
            "          [ 7.7442e-03, -4.9562e-02,  3.4951e-02]],\n",
            "\n",
            "         [[-1.7049e-04, -9.5120e-04,  3.8512e-02],\n",
            "          [-1.2933e-02, -2.6473e-02,  5.1219e-02],\n",
            "          [-2.3943e-02,  1.0201e-01, -1.5647e-03]],\n",
            "\n",
            "         [[-1.0711e-01, -1.0715e-02, -2.5244e-02],\n",
            "          [ 1.2424e-02, -7.6289e-02,  6.4690e-03],\n",
            "          [-5.2877e-02,  5.6392e-03,  4.1979e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.2500e-02,  1.2385e-02, -2.8566e-02],\n",
            "          [ 5.1617e-04,  3.4973e-02,  2.9874e-02],\n",
            "          [ 5.0883e-03, -2.7488e-02, -1.8361e-02]],\n",
            "\n",
            "         [[ 1.0285e-02,  1.9435e-02,  2.6590e-02],\n",
            "          [-3.2130e-02, -7.1974e-03, -9.5913e-03],\n",
            "          [ 3.7731e-03,  1.4688e-03,  3.9087e-04]],\n",
            "\n",
            "         [[ 3.4970e-02,  1.7187e-02,  5.6129e-02],\n",
            "          [ 1.5058e-02, -2.8139e-03,  2.1764e-02],\n",
            "          [ 1.5986e-02,  2.7617e-02, -6.4071e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.2208e-03, -1.1835e-02, -9.4561e-02],\n",
            "          [-7.2751e-03,  7.4011e-02,  6.3089e-02],\n",
            "          [ 1.7558e-02,  8.8767e-02, -3.3039e-02]],\n",
            "\n",
            "         [[-1.0553e-02, -3.5139e-03,  4.1840e-03],\n",
            "          [ 6.4999e-02,  9.1774e-02,  1.5115e-02],\n",
            "          [-2.3631e-02, -3.5679e-02,  2.5063e-02]],\n",
            "\n",
            "         [[ 3.8487e-02,  4.2044e-02,  2.5408e-02],\n",
            "          [ 9.7594e-03,  4.6497e-02, -3.3497e-02],\n",
            "          [-5.2825e-02,  1.7522e-02, -1.8611e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.6521e-02, -3.4359e-02, -1.3447e-02],\n",
            "          [ 1.0213e-01, -1.6399e-03,  1.6602e-02],\n",
            "          [ 2.6341e-02, -1.1826e-02, -6.2982e-04]],\n",
            "\n",
            "         [[-6.4889e-03, -5.0561e-02, -1.0876e-01],\n",
            "          [ 7.4923e-02, -2.6142e-02,  1.0679e-01],\n",
            "          [ 3.4326e-02,  8.0179e-02,  4.8701e-02]],\n",
            "\n",
            "         [[ 3.2389e-02,  3.1953e-02, -5.8567e-02],\n",
            "          [ 5.5803e-02,  8.4076e-03,  1.8383e-02],\n",
            "          [ 3.3115e-02,  2.6133e-03, -1.4742e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.9049e-02, -1.9286e-04,  7.1004e-03],\n",
            "          [ 4.3563e-02, -5.9369e-02, -2.6085e-02],\n",
            "          [ 4.7260e-02, -2.8975e-02, -6.3615e-02]],\n",
            "\n",
            "         [[ 8.8889e-03,  1.2512e-03,  2.1641e-02],\n",
            "          [ 1.9218e-02,  4.8266e-02,  3.0982e-02],\n",
            "          [ 2.3080e-02,  8.0840e-03, -3.3561e-02]],\n",
            "\n",
            "         [[-5.8409e-02, -3.1792e-03,  2.0712e-02],\n",
            "          [-1.2524e-02, -1.5699e-02, -6.1308e-03],\n",
            "          [ 6.1127e-02,  2.8549e-02,  9.1019e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7961e-03,  2.0993e-02,  8.4987e-02],\n",
            "          [-2.7398e-02, -8.0587e-02, -1.8647e-02],\n",
            "          [ 5.0908e-02,  1.6297e-02, -4.1915e-03]],\n",
            "\n",
            "         [[-1.7441e-02,  5.2442e-02, -4.4641e-02],\n",
            "          [-2.3515e-02,  2.8372e-02, -7.5687e-02],\n",
            "          [ 4.0277e-02,  5.4168e-02, -3.7372e-02]],\n",
            "\n",
            "         [[ 1.9991e-02,  6.0403e-03,  2.6457e-02],\n",
            "          [ 2.8366e-02,  7.2770e-02,  7.4291e-02],\n",
            "          [-6.9783e-02,  3.4633e-02, -4.6988e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9415e-02, -6.0324e-03, -6.8092e-02],\n",
            "          [-1.3770e-02,  7.1382e-02,  2.4164e-02],\n",
            "          [ 1.4306e-02,  3.7954e-03, -2.7367e-02]],\n",
            "\n",
            "         [[-4.1882e-02,  6.7325e-02,  7.6916e-02],\n",
            "          [ 1.1186e-01,  4.1740e-02, -2.7499e-02],\n",
            "          [-4.8076e-02, -1.9526e-02, -1.8575e-02]],\n",
            "\n",
            "         [[-1.1417e-02, -1.6355e-02,  3.0151e-02],\n",
            "          [ 6.0729e-02,  2.0041e-02, -1.2763e-02],\n",
            "          [ 2.1167e-02, -1.7334e-02,  1.9317e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.0206e-02, -1.0961e-01, -5.2340e-02],\n",
            "          [-1.8403e-02,  8.3577e-02,  2.0537e-02],\n",
            "          [ 9.0196e-02,  1.1627e-02,  1.4996e-02]],\n",
            "\n",
            "         [[ 3.4345e-02, -7.8837e-02,  1.7752e-02],\n",
            "          [-4.4236e-02,  3.0105e-02,  6.1128e-02],\n",
            "          [ 9.6327e-02,  5.0425e-02,  4.9496e-03]],\n",
            "\n",
            "         [[ 3.4890e-02,  4.9269e-02,  1.3378e-02],\n",
            "          [-5.0193e-02,  1.7138e-03,  1.8194e-02],\n",
            "          [ 2.0615e-03,  5.7121e-02, -4.5547e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.0124e-01,  3.5744e-02,  3.5384e-02],\n",
            "          [-1.7518e-02, -2.2879e-02,  7.3905e-02],\n",
            "          [-5.2962e-02, -1.2880e-02, -3.7926e-02]],\n",
            "\n",
            "         [[ 3.8139e-02,  1.6738e-02,  3.1361e-02],\n",
            "          [-5.8242e-03, -3.7098e-02, -6.8245e-03],\n",
            "          [ 3.0275e-02, -5.3301e-02, -5.8391e-03]],\n",
            "\n",
            "         [[ 4.0760e-02, -3.9798e-02,  6.0473e-02],\n",
            "          [ 6.9290e-02, -5.0383e-02,  2.5765e-02],\n",
            "          [ 3.5284e-02, -1.3286e-02,  3.2636e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3105e-03, -2.3914e-02,  6.7505e-02],\n",
            "          [ 1.2013e-02, -2.1723e-02,  3.6502e-02],\n",
            "          [-1.2688e-02,  7.5403e-03, -6.0569e-02]],\n",
            "\n",
            "         [[-1.9598e-04,  1.5440e-02, -5.5732e-02],\n",
            "          [-1.9595e-02, -2.8402e-02,  3.6859e-02],\n",
            "          [ 2.7925e-02, -3.8986e-02, -6.6399e-02]],\n",
            "\n",
            "         [[ 4.7966e-02, -5.1521e-05,  3.1309e-02],\n",
            "          [ 4.6506e-02, -3.3850e-02,  4.2715e-02],\n",
            "          [ 6.1498e-02,  5.5042e-02, -5.9903e-02]]]])), ('module.encoder_k.layer2.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.0.conv3.weight', tensor([[[[ 0.0392]],\n",
            "\n",
            "         [[ 0.0557]],\n",
            "\n",
            "         [[ 0.0739]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2723]],\n",
            "\n",
            "         [[-0.0327]],\n",
            "\n",
            "         [[-0.0063]]],\n",
            "\n",
            "\n",
            "        [[[-0.0261]],\n",
            "\n",
            "         [[-0.0548]],\n",
            "\n",
            "         [[-0.0799]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0633]],\n",
            "\n",
            "         [[-0.0845]],\n",
            "\n",
            "         [[-0.0055]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0203]],\n",
            "\n",
            "         [[ 0.0198]],\n",
            "\n",
            "         [[-0.0436]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1107]],\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.1057]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0040]],\n",
            "\n",
            "         [[ 0.0428]],\n",
            "\n",
            "         [[-0.0767]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0691]],\n",
            "\n",
            "         [[-0.0083]],\n",
            "\n",
            "         [[-0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0685]],\n",
            "\n",
            "         [[-0.1017]],\n",
            "\n",
            "         [[ 0.0291]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0607]],\n",
            "\n",
            "         [[-0.0116]],\n",
            "\n",
            "         [[ 0.0878]]],\n",
            "\n",
            "\n",
            "        [[[-0.0722]],\n",
            "\n",
            "         [[ 0.0875]],\n",
            "\n",
            "         [[ 0.0860]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0552]],\n",
            "\n",
            "         [[ 0.0235]],\n",
            "\n",
            "         [[-0.0231]]]])), ('module.encoder_k.layer2.0.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.0.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.0.downsample.0.weight', tensor([[[[-0.0634]],\n",
            "\n",
            "         [[-0.0314]],\n",
            "\n",
            "         [[ 0.1495]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0341]],\n",
            "\n",
            "         [[ 0.0252]],\n",
            "\n",
            "         [[-0.0214]]],\n",
            "\n",
            "\n",
            "        [[[-0.0924]],\n",
            "\n",
            "         [[ 0.0035]],\n",
            "\n",
            "         [[-0.0706]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0218]],\n",
            "\n",
            "         [[ 0.0111]],\n",
            "\n",
            "         [[-0.0233]]],\n",
            "\n",
            "\n",
            "        [[[-0.0484]],\n",
            "\n",
            "         [[ 0.0520]],\n",
            "\n",
            "         [[ 0.0971]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0257]],\n",
            "\n",
            "         [[ 0.0249]],\n",
            "\n",
            "         [[-0.1163]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0049]],\n",
            "\n",
            "         [[ 0.0545]],\n",
            "\n",
            "         [[-0.0500]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0796]],\n",
            "\n",
            "         [[ 0.0463]],\n",
            "\n",
            "         [[-0.0497]]],\n",
            "\n",
            "\n",
            "        [[[-0.0442]],\n",
            "\n",
            "         [[ 0.0846]],\n",
            "\n",
            "         [[ 0.1007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[-0.0272]],\n",
            "\n",
            "         [[ 0.0153]]],\n",
            "\n",
            "\n",
            "        [[[-0.1229]],\n",
            "\n",
            "         [[-0.0187]],\n",
            "\n",
            "         [[ 0.0064]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0772]],\n",
            "\n",
            "         [[-0.1290]],\n",
            "\n",
            "         [[ 0.0257]]]])), ('module.encoder_k.layer2.0.downsample.1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.0.downsample.1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.downsample.1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.0.downsample.1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.1.conv1.weight', tensor([[[[ 0.0926]],\n",
            "\n",
            "         [[-0.0228]],\n",
            "\n",
            "         [[-0.2365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1820]],\n",
            "\n",
            "         [[ 0.1204]],\n",
            "\n",
            "         [[-0.0330]]],\n",
            "\n",
            "\n",
            "        [[[-0.0729]],\n",
            "\n",
            "         [[ 0.1143]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0717]],\n",
            "\n",
            "         [[ 0.1223]],\n",
            "\n",
            "         [[ 0.0861]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0740]],\n",
            "\n",
            "         [[-0.0293]],\n",
            "\n",
            "         [[ 0.0721]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0764]],\n",
            "\n",
            "         [[-0.0872]],\n",
            "\n",
            "         [[-0.0515]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0044]],\n",
            "\n",
            "         [[-0.1122]],\n",
            "\n",
            "         [[ 0.1625]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[-0.0420]],\n",
            "\n",
            "         [[-0.1038]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[-0.0912]],\n",
            "\n",
            "         [[ 0.1461]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[ 0.0585]],\n",
            "\n",
            "         [[-0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0135]],\n",
            "\n",
            "         [[ 0.0570]],\n",
            "\n",
            "         [[ 0.0341]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0164]],\n",
            "\n",
            "         [[ 0.0017]],\n",
            "\n",
            "         [[ 0.0894]]]])), ('module.encoder_k.layer2.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.1.conv2.weight', tensor([[[[ 0.0605, -0.0221,  0.0493],\n",
            "          [ 0.0430,  0.0210, -0.0888],\n",
            "          [ 0.0691,  0.1352, -0.0750]],\n",
            "\n",
            "         [[-0.0194,  0.0388,  0.0074],\n",
            "          [ 0.0081, -0.0321,  0.0505],\n",
            "          [ 0.0345, -0.0367,  0.0024]],\n",
            "\n",
            "         [[-0.0347,  0.0069,  0.0237],\n",
            "          [ 0.0146, -0.0034,  0.0035],\n",
            "          [ 0.0026,  0.0506, -0.0235]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0208,  0.0627,  0.0128],\n",
            "          [-0.0596, -0.0180,  0.0352],\n",
            "          [ 0.0771,  0.0187,  0.0314]],\n",
            "\n",
            "         [[-0.0243,  0.0847, -0.0102],\n",
            "          [ 0.0136,  0.0416,  0.0080],\n",
            "          [-0.0395,  0.0238,  0.0154]],\n",
            "\n",
            "         [[ 0.0877,  0.0118,  0.0320],\n",
            "          [ 0.0359, -0.0305,  0.0360],\n",
            "          [-0.0262,  0.0336,  0.0391]]],\n",
            "\n",
            "\n",
            "        [[[-0.0273,  0.0717, -0.0551],\n",
            "          [-0.0415, -0.0250, -0.0744],\n",
            "          [-0.0089, -0.0122, -0.0054]],\n",
            "\n",
            "         [[-0.0137, -0.0302,  0.0637],\n",
            "          [ 0.0687,  0.0456, -0.0472],\n",
            "          [-0.0964, -0.0372,  0.0214]],\n",
            "\n",
            "         [[ 0.0042,  0.0280, -0.0206],\n",
            "          [ 0.0138,  0.0227, -0.0590],\n",
            "          [ 0.0506, -0.0112, -0.0128]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0236,  0.0151, -0.0401],\n",
            "          [-0.0677, -0.0117, -0.0193],\n",
            "          [ 0.0034, -0.0228, -0.0306]],\n",
            "\n",
            "         [[-0.0173,  0.0231,  0.0418],\n",
            "          [ 0.0226, -0.0199, -0.0228],\n",
            "          [ 0.0773, -0.1227, -0.0147]],\n",
            "\n",
            "         [[-0.0737, -0.0305, -0.0120],\n",
            "          [ 0.0064, -0.0600, -0.0155],\n",
            "          [-0.0060,  0.0035,  0.0031]]],\n",
            "\n",
            "\n",
            "        [[[-0.0206, -0.0342, -0.0228],\n",
            "          [-0.0318, -0.0736,  0.0076],\n",
            "          [-0.0182, -0.0178,  0.0931]],\n",
            "\n",
            "         [[-0.0305, -0.0263,  0.0389],\n",
            "          [ 0.0376, -0.0330, -0.0054],\n",
            "          [ 0.0701, -0.0252, -0.0254]],\n",
            "\n",
            "         [[ 0.0363, -0.0257,  0.0052],\n",
            "          [-0.0229,  0.0177, -0.0502],\n",
            "          [-0.0205, -0.0332,  0.0573]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0168, -0.0095,  0.0150],\n",
            "          [-0.0227,  0.0057,  0.0603],\n",
            "          [-0.0458,  0.0450, -0.0382]],\n",
            "\n",
            "         [[-0.0137,  0.0209, -0.0698],\n",
            "          [ 0.0308,  0.0515, -0.0535],\n",
            "          [-0.0064,  0.0711,  0.0512]],\n",
            "\n",
            "         [[-0.0007,  0.0081, -0.0236],\n",
            "          [ 0.0362, -0.0455, -0.0123],\n",
            "          [ 0.1983, -0.0110,  0.0077]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0373,  0.0840,  0.0479],\n",
            "          [ 0.0394,  0.0844, -0.0636],\n",
            "          [-0.0830,  0.0423,  0.0227]],\n",
            "\n",
            "         [[-0.0226, -0.0209, -0.0335],\n",
            "          [-0.0501, -0.0605, -0.0595],\n",
            "          [ 0.0196,  0.0336, -0.0248]],\n",
            "\n",
            "         [[ 0.0394, -0.0675, -0.0319],\n",
            "          [-0.0551, -0.0101,  0.0052],\n",
            "          [-0.0075, -0.0035, -0.0240]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0017, -0.0399, -0.0223],\n",
            "          [-0.0839,  0.0908,  0.0245],\n",
            "          [ 0.0590, -0.0581,  0.0532]],\n",
            "\n",
            "         [[ 0.0266, -0.0241, -0.0070],\n",
            "          [-0.0298,  0.0043, -0.0791],\n",
            "          [-0.0161, -0.0036,  0.0418]],\n",
            "\n",
            "         [[-0.0231,  0.0510,  0.0889],\n",
            "          [-0.0795, -0.0165, -0.0217],\n",
            "          [ 0.0311,  0.0143, -0.0167]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0523,  0.0327, -0.0152],\n",
            "          [ 0.0339,  0.0518,  0.0175],\n",
            "          [-0.0447,  0.0073, -0.0508]],\n",
            "\n",
            "         [[-0.0112, -0.0210,  0.0064],\n",
            "          [-0.0236,  0.0236,  0.0024],\n",
            "          [-0.0025, -0.0117,  0.0310]],\n",
            "\n",
            "         [[ 0.0025, -0.0809, -0.0177],\n",
            "          [-0.0382,  0.0278, -0.0614],\n",
            "          [ 0.0110,  0.0540, -0.0103]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0041, -0.0212, -0.0609],\n",
            "          [-0.0502,  0.0309, -0.0925],\n",
            "          [ 0.0149, -0.1268,  0.0253]],\n",
            "\n",
            "         [[ 0.0020, -0.0173,  0.0035],\n",
            "          [-0.0459, -0.0693, -0.0476],\n",
            "          [-0.0444,  0.0187,  0.0373]],\n",
            "\n",
            "         [[-0.0434, -0.0307,  0.0406],\n",
            "          [-0.0169, -0.0245,  0.0410],\n",
            "          [-0.0281,  0.0011, -0.0632]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0013, -0.0097,  0.0696],\n",
            "          [ 0.0381, -0.0180,  0.0155],\n",
            "          [ 0.0637, -0.0496,  0.0377]],\n",
            "\n",
            "         [[ 0.0663, -0.0438,  0.0324],\n",
            "          [ 0.0165, -0.0185, -0.0194],\n",
            "          [-0.0364,  0.0202,  0.0805]],\n",
            "\n",
            "         [[ 0.0216,  0.0192, -0.0202],\n",
            "          [ 0.1161,  0.0192, -0.0294],\n",
            "          [ 0.0287, -0.0170, -0.0026]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0194, -0.0406,  0.0145],\n",
            "          [ 0.0105, -0.0202, -0.0229],\n",
            "          [ 0.0237, -0.0048, -0.0188]],\n",
            "\n",
            "         [[-0.0350,  0.0564,  0.0321],\n",
            "          [ 0.0348, -0.0583,  0.0178],\n",
            "          [-0.0045,  0.0256, -0.0667]],\n",
            "\n",
            "         [[ 0.0178,  0.0496, -0.0991],\n",
            "          [-0.0374,  0.0535,  0.1022],\n",
            "          [-0.0446, -0.0028,  0.0672]]]])), ('module.encoder_k.layer2.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.1.conv3.weight', tensor([[[[-0.0307]],\n",
            "\n",
            "         [[ 0.0356]],\n",
            "\n",
            "         [[ 0.0464]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0450]],\n",
            "\n",
            "         [[-0.0658]],\n",
            "\n",
            "         [[ 0.1105]]],\n",
            "\n",
            "\n",
            "        [[[-0.0297]],\n",
            "\n",
            "         [[ 0.0140]],\n",
            "\n",
            "         [[-0.0420]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0199]],\n",
            "\n",
            "         [[ 0.1145]],\n",
            "\n",
            "         [[ 0.0236]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0164]],\n",
            "\n",
            "         [[-0.0030]],\n",
            "\n",
            "         [[ 0.0698]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1073]],\n",
            "\n",
            "         [[-0.0822]],\n",
            "\n",
            "         [[-0.0799]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1021]],\n",
            "\n",
            "         [[ 0.0298]],\n",
            "\n",
            "         [[ 0.0249]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.0085]],\n",
            "\n",
            "         [[-0.0738]]],\n",
            "\n",
            "\n",
            "        [[[-0.0259]],\n",
            "\n",
            "         [[-0.1195]],\n",
            "\n",
            "         [[-0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0510]],\n",
            "\n",
            "         [[ 0.0883]],\n",
            "\n",
            "         [[-0.0678]]],\n",
            "\n",
            "\n",
            "        [[[-0.0384]],\n",
            "\n",
            "         [[-0.1033]],\n",
            "\n",
            "         [[ 0.0134]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0214]],\n",
            "\n",
            "         [[ 0.0112]],\n",
            "\n",
            "         [[-0.0111]]]])), ('module.encoder_k.layer2.1.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.1.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.1.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.2.conv1.weight', tensor([[[[-0.0462]],\n",
            "\n",
            "         [[-0.0860]],\n",
            "\n",
            "         [[ 0.2435]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.3129]],\n",
            "\n",
            "         [[ 0.0518]],\n",
            "\n",
            "         [[ 0.0729]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0233]],\n",
            "\n",
            "         [[-0.1573]],\n",
            "\n",
            "         [[ 0.0401]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1704]],\n",
            "\n",
            "         [[ 0.1288]],\n",
            "\n",
            "         [[-0.0288]]],\n",
            "\n",
            "\n",
            "        [[[-0.0690]],\n",
            "\n",
            "         [[-0.0855]],\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1292]],\n",
            "\n",
            "         [[-0.0148]],\n",
            "\n",
            "         [[-0.0995]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0591]],\n",
            "\n",
            "         [[ 0.2056]],\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1038]],\n",
            "\n",
            "         [[ 0.2020]],\n",
            "\n",
            "         [[-0.2573]]],\n",
            "\n",
            "\n",
            "        [[[-0.2237]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[ 0.2163]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0736]],\n",
            "\n",
            "         [[-0.0507]],\n",
            "\n",
            "         [[ 0.3319]]],\n",
            "\n",
            "\n",
            "        [[[-0.1276]],\n",
            "\n",
            "         [[-0.0740]],\n",
            "\n",
            "         [[-0.2575]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.2182]],\n",
            "\n",
            "         [[ 0.0925]],\n",
            "\n",
            "         [[ 0.1306]]]])), ('module.encoder_k.layer2.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.2.conv2.weight', tensor([[[[ 0.0156, -0.0523, -0.0431],\n",
            "          [ 0.0094, -0.0275,  0.0040],\n",
            "          [-0.0086,  0.0213, -0.0466]],\n",
            "\n",
            "         [[-0.0323,  0.0137, -0.0159],\n",
            "          [-0.0079,  0.0211, -0.0577],\n",
            "          [ 0.0061, -0.0110,  0.0037]],\n",
            "\n",
            "         [[-0.0221,  0.0452, -0.0110],\n",
            "          [-0.0069, -0.0090,  0.0394],\n",
            "          [-0.0128,  0.0437,  0.0475]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0002, -0.0187, -0.0038],\n",
            "          [-0.0023,  0.0272,  0.0494],\n",
            "          [ 0.0324, -0.0002,  0.0056]],\n",
            "\n",
            "         [[-0.0024, -0.0769, -0.0661],\n",
            "          [ 0.0170,  0.0370, -0.0587],\n",
            "          [ 0.0465, -0.0149,  0.0545]],\n",
            "\n",
            "         [[ 0.0080,  0.0128, -0.0002],\n",
            "          [ 0.0168, -0.0569,  0.0042],\n",
            "          [ 0.0293,  0.0134, -0.0533]]],\n",
            "\n",
            "\n",
            "        [[[-0.0319,  0.0042, -0.0065],\n",
            "          [-0.0259, -0.0445,  0.0489],\n",
            "          [-0.0051,  0.0231,  0.0149]],\n",
            "\n",
            "         [[ 0.0405,  0.0749,  0.0042],\n",
            "          [-0.0036, -0.0351,  0.0708],\n",
            "          [-0.0349,  0.0490,  0.0033]],\n",
            "\n",
            "         [[ 0.0372,  0.0191,  0.0284],\n",
            "          [ 0.0045,  0.0048,  0.0284],\n",
            "          [-0.0244, -0.0733, -0.0292]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0019,  0.0564,  0.0096],\n",
            "          [-0.0330,  0.0924, -0.0306],\n",
            "          [-0.1008,  0.0624, -0.0037]],\n",
            "\n",
            "         [[-0.0325, -0.0426,  0.0185],\n",
            "          [-0.0231, -0.0849, -0.0240],\n",
            "          [-0.0200, -0.0055,  0.0203]],\n",
            "\n",
            "         [[ 0.0360,  0.0226, -0.0500],\n",
            "          [ 0.0521, -0.0231,  0.0311],\n",
            "          [ 0.0043,  0.0227,  0.0063]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0134,  0.0300,  0.0283],\n",
            "          [ 0.0089,  0.0305,  0.0248],\n",
            "          [ 0.0380, -0.0514,  0.0168]],\n",
            "\n",
            "         [[ 0.0572, -0.0589,  0.0530],\n",
            "          [ 0.0251,  0.0233, -0.0319],\n",
            "          [ 0.0101,  0.0021, -0.0621]],\n",
            "\n",
            "         [[-0.0523,  0.0199, -0.1482],\n",
            "          [ 0.0550,  0.0036, -0.0362],\n",
            "          [ 0.0010,  0.0554,  0.0521]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0133, -0.0239,  0.0029],\n",
            "          [ 0.0212,  0.0130, -0.0425],\n",
            "          [ 0.0104, -0.0491, -0.0216]],\n",
            "\n",
            "         [[-0.0175, -0.0524,  0.0127],\n",
            "          [-0.0010,  0.0363,  0.0634],\n",
            "          [-0.0104,  0.0031, -0.0983]],\n",
            "\n",
            "         [[ 0.0006, -0.0316,  0.0387],\n",
            "          [ 0.0465, -0.0353,  0.0334],\n",
            "          [ 0.0518, -0.0092, -0.0312]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0012,  0.0051, -0.0505],\n",
            "          [ 0.0195, -0.0126,  0.0038],\n",
            "          [-0.0099, -0.0123, -0.0881]],\n",
            "\n",
            "         [[-0.0666, -0.0317, -0.0035],\n",
            "          [-0.0081, -0.0313,  0.0622],\n",
            "          [-0.0186, -0.0818, -0.0326]],\n",
            "\n",
            "         [[-0.0119,  0.0031, -0.0378],\n",
            "          [ 0.0335,  0.0566,  0.0344],\n",
            "          [ 0.0376, -0.0257, -0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0035,  0.0588, -0.0296],\n",
            "          [ 0.0371,  0.0096, -0.0034],\n",
            "          [-0.0469, -0.0070, -0.0211]],\n",
            "\n",
            "         [[ 0.0301,  0.0367,  0.0473],\n",
            "          [-0.0174,  0.0542, -0.0306],\n",
            "          [-0.0458,  0.0167, -0.0362]],\n",
            "\n",
            "         [[-0.0148, -0.0122,  0.0332],\n",
            "          [-0.0126, -0.0476,  0.0123],\n",
            "          [-0.0582,  0.0326,  0.0765]]],\n",
            "\n",
            "\n",
            "        [[[-0.0315, -0.0141, -0.0791],\n",
            "          [ 0.0666,  0.1131, -0.0225],\n",
            "          [ 0.0528,  0.0480, -0.0180]],\n",
            "\n",
            "         [[ 0.0527,  0.0678,  0.0131],\n",
            "          [-0.0050, -0.0128,  0.0170],\n",
            "          [-0.1508,  0.0283, -0.0398]],\n",
            "\n",
            "         [[ 0.0272, -0.0006, -0.0738],\n",
            "          [-0.0428,  0.0259,  0.0080],\n",
            "          [-0.0037,  0.0254, -0.0113]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0430, -0.0658, -0.0068],\n",
            "          [ 0.0223, -0.0101, -0.0929],\n",
            "          [-0.0381,  0.0391,  0.0074]],\n",
            "\n",
            "         [[-0.0194, -0.1032, -0.0640],\n",
            "          [ 0.0284, -0.0526, -0.0340],\n",
            "          [ 0.0734, -0.0605,  0.0427]],\n",
            "\n",
            "         [[ 0.0558,  0.0489, -0.0586],\n",
            "          [ 0.0505,  0.0066,  0.0449],\n",
            "          [-0.0349, -0.0071,  0.0624]]],\n",
            "\n",
            "\n",
            "        [[[-0.0207,  0.0273,  0.0014],\n",
            "          [-0.1042, -0.0158,  0.0229],\n",
            "          [ 0.0422, -0.0650,  0.0165]],\n",
            "\n",
            "         [[ 0.0073,  0.0427, -0.0058],\n",
            "          [-0.0366, -0.0107, -0.0447],\n",
            "          [ 0.0086, -0.0177, -0.0010]],\n",
            "\n",
            "         [[ 0.0402,  0.0321,  0.0216],\n",
            "          [-0.0080, -0.0428,  0.0240],\n",
            "          [ 0.0438,  0.0190,  0.0041]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0186, -0.0121, -0.0897],\n",
            "          [-0.0147,  0.0569, -0.0360],\n",
            "          [ 0.0399, -0.0361,  0.0084]],\n",
            "\n",
            "         [[ 0.0687, -0.0346, -0.0108],\n",
            "          [-0.0281, -0.0493,  0.0418],\n",
            "          [ 0.0051, -0.0045,  0.0392]],\n",
            "\n",
            "         [[-0.0019,  0.0615, -0.0528],\n",
            "          [-0.0098, -0.0565, -0.0086],\n",
            "          [ 0.0702, -0.0490,  0.0441]]]])), ('module.encoder_k.layer2.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.2.conv3.weight', tensor([[[[ 0.0162]],\n",
            "\n",
            "         [[ 0.0204]],\n",
            "\n",
            "         [[-0.0581]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0006]],\n",
            "\n",
            "         [[-0.0278]],\n",
            "\n",
            "         [[-0.0658]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0367]],\n",
            "\n",
            "         [[-0.0580]],\n",
            "\n",
            "         [[-0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0252]],\n",
            "\n",
            "         [[ 0.0281]],\n",
            "\n",
            "         [[-0.1131]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0028]],\n",
            "\n",
            "         [[ 0.0339]],\n",
            "\n",
            "         [[ 0.0179]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1477]],\n",
            "\n",
            "         [[-0.0822]],\n",
            "\n",
            "         [[-0.0192]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0572]],\n",
            "\n",
            "         [[-0.0946]],\n",
            "\n",
            "         [[-0.0280]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0124]],\n",
            "\n",
            "         [[ 0.1155]],\n",
            "\n",
            "         [[-0.0201]]],\n",
            "\n",
            "\n",
            "        [[[-0.0326]],\n",
            "\n",
            "         [[-0.0597]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0582]],\n",
            "\n",
            "         [[-0.1249]],\n",
            "\n",
            "         [[-0.0081]]],\n",
            "\n",
            "\n",
            "        [[[-0.0914]],\n",
            "\n",
            "         [[-0.0796]],\n",
            "\n",
            "         [[-0.0320]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0934]],\n",
            "\n",
            "         [[-0.0957]],\n",
            "\n",
            "         [[-0.0545]]]])), ('module.encoder_k.layer2.2.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.2.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.2.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.3.conv1.weight', tensor([[[[ 0.1634]],\n",
            "\n",
            "         [[ 0.1546]],\n",
            "\n",
            "         [[-0.1973]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0063]],\n",
            "\n",
            "         [[-0.0004]],\n",
            "\n",
            "         [[-0.2340]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1462]],\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[-0.0380]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1263]],\n",
            "\n",
            "         [[-0.1100]],\n",
            "\n",
            "         [[ 0.1089]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0204]],\n",
            "\n",
            "         [[ 0.1834]],\n",
            "\n",
            "         [[-0.0685]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0970]],\n",
            "\n",
            "         [[ 0.0020]],\n",
            "\n",
            "         [[-0.1100]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0636]],\n",
            "\n",
            "         [[-0.0080]],\n",
            "\n",
            "         [[ 0.0098]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1787]],\n",
            "\n",
            "         [[-0.0566]],\n",
            "\n",
            "         [[ 0.1044]]],\n",
            "\n",
            "\n",
            "        [[[-0.1067]],\n",
            "\n",
            "         [[ 0.1645]],\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0935]],\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         [[ 0.2193]]],\n",
            "\n",
            "\n",
            "        [[[-0.0080]],\n",
            "\n",
            "         [[ 0.2346]],\n",
            "\n",
            "         [[ 0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         [[ 0.0264]],\n",
            "\n",
            "         [[-0.0833]]]])), ('module.encoder_k.layer2.3.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.3.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.3.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.3.conv2.weight', tensor([[[[ 7.3497e-02,  2.1962e-02, -4.2201e-03],\n",
            "          [ 9.5974e-03, -8.6623e-04, -1.3851e-02],\n",
            "          [-4.1984e-03, -6.3631e-02, -3.2177e-02]],\n",
            "\n",
            "         [[ 3.8268e-02,  4.4671e-03,  6.2141e-03],\n",
            "          [-1.7520e-02,  4.2654e-02,  5.0988e-02],\n",
            "          [-9.7652e-03,  1.3578e-01, -4.3674e-02]],\n",
            "\n",
            "         [[ 1.7944e-02,  3.4590e-02,  1.4852e-02],\n",
            "          [-5.2700e-02, -3.3267e-02, -2.7509e-02],\n",
            "          [ 1.3541e-03,  8.5641e-03,  2.8167e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.7612e-02, -2.9776e-02,  5.7160e-03],\n",
            "          [-1.1761e-02, -4.3762e-03,  5.4077e-02],\n",
            "          [ 6.0091e-02,  2.1712e-02,  7.7632e-02]],\n",
            "\n",
            "         [[-1.9806e-02,  2.7688e-02,  7.4892e-02],\n",
            "          [-1.4858e-02, -2.8394e-02, -1.9524e-02],\n",
            "          [-7.8309e-02, -2.6777e-02,  1.0059e-01]],\n",
            "\n",
            "         [[ 5.7815e-02, -1.4227e-02, -7.2202e-02],\n",
            "          [ 6.8782e-02,  1.6994e-02,  2.5283e-03],\n",
            "          [-3.2463e-02,  2.5852e-02, -3.2543e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.6790e-02,  9.2434e-03, -5.7604e-02],\n",
            "          [ 5.6901e-02, -6.6339e-03,  6.2517e-02],\n",
            "          [ 6.0121e-02,  1.1022e-02,  5.8181e-02]],\n",
            "\n",
            "         [[-3.6046e-03, -1.7133e-02,  2.5426e-02],\n",
            "          [ 4.6385e-02,  2.8519e-02, -5.0508e-02],\n",
            "          [ 1.1826e-02, -1.3038e-01, -1.1524e-02]],\n",
            "\n",
            "         [[-8.1995e-02,  5.7327e-02,  4.5260e-02],\n",
            "          [ 8.9381e-02,  1.1208e-01,  1.4266e-03],\n",
            "          [-4.4925e-02, -7.4783e-02, -1.1810e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4496e-03, -2.6290e-02, -3.5686e-02],\n",
            "          [-8.6725e-02, -6.6405e-02, -2.5709e-02],\n",
            "          [ 2.3962e-02,  2.9266e-02, -1.3232e-02]],\n",
            "\n",
            "         [[ 4.7316e-03, -3.2027e-03, -6.1636e-02],\n",
            "          [ 2.9870e-02, -5.1156e-02, -1.9421e-02],\n",
            "          [ 2.5220e-02, -7.3778e-04,  4.0020e-02]],\n",
            "\n",
            "         [[ 5.4043e-02, -9.1860e-03,  7.7965e-02],\n",
            "          [ 4.5336e-02, -1.9628e-02,  7.1211e-02],\n",
            "          [ 2.3061e-02, -4.5180e-02, -2.3573e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.0291e-01, -7.8657e-02, -1.9550e-02],\n",
            "          [-1.0191e-02,  4.3485e-03, -5.6207e-02],\n",
            "          [ 6.6759e-03, -4.6502e-02,  3.6970e-02]],\n",
            "\n",
            "         [[ 3.8708e-02,  2.9876e-02,  3.3753e-02],\n",
            "          [ 8.7522e-02, -4.2145e-02, -7.5818e-02],\n",
            "          [-3.1546e-02,  3.6052e-02,  1.4430e-02]],\n",
            "\n",
            "         [[ 4.5737e-02, -9.3283e-02, -6.2237e-02],\n",
            "          [-2.4330e-04,  1.9173e-02,  9.2847e-03],\n",
            "          [ 1.0665e-03,  3.0539e-02, -2.9983e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.8350e-02, -2.0814e-02, -2.2883e-02],\n",
            "          [-3.6517e-02, -2.6142e-02, -2.8073e-02],\n",
            "          [-2.9324e-02,  1.1660e-02, -2.8289e-03]],\n",
            "\n",
            "         [[-8.4914e-02, -5.4831e-03, -4.1188e-02],\n",
            "          [-1.5806e-02, -3.9671e-02,  3.7419e-02],\n",
            "          [-4.9370e-02, -2.4254e-02,  6.7274e-02]],\n",
            "\n",
            "         [[-8.8635e-02,  4.3669e-02,  5.9139e-02],\n",
            "          [-6.3563e-03,  9.1158e-03,  6.5693e-02],\n",
            "          [ 2.6917e-02, -3.1036e-02, -2.2993e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.8321e-04,  1.2337e-02,  6.0565e-02],\n",
            "          [-2.1838e-02,  1.4173e-02, -2.1628e-02],\n",
            "          [-5.2156e-02, -3.1882e-02, -3.1025e-02]],\n",
            "\n",
            "         [[-7.5517e-03, -7.9413e-02,  4.0100e-02],\n",
            "          [ 1.9147e-02, -3.7430e-02, -8.7601e-02],\n",
            "          [-1.2509e-02, -1.0716e-02,  2.8296e-02]],\n",
            "\n",
            "         [[-2.3965e-02, -3.0195e-02, -3.8776e-02],\n",
            "          [ 3.2006e-02,  7.6516e-03, -2.1318e-02],\n",
            "          [ 8.9448e-03, -6.7615e-02,  2.9057e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2462e-04,  6.6771e-02, -5.1844e-03],\n",
            "          [ 2.5719e-02, -5.1697e-02,  3.3111e-02],\n",
            "          [ 2.5794e-02, -1.5443e-02,  5.4360e-02]],\n",
            "\n",
            "         [[-9.5505e-02,  4.6302e-02,  1.1384e-02],\n",
            "          [-1.0154e-02,  2.9378e-02,  5.1836e-02],\n",
            "          [ 8.7175e-03, -3.3500e-02,  2.5306e-02]],\n",
            "\n",
            "         [[ 1.4768e-02,  3.7158e-02, -2.0268e-02],\n",
            "          [-2.2832e-02,  4.7761e-03, -2.6948e-03],\n",
            "          [ 5.8582e-04,  1.1468e-02,  3.6419e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.1331e-03, -5.8595e-03,  3.6922e-02],\n",
            "          [ 1.7414e-02,  1.1410e-01, -4.0412e-04],\n",
            "          [-1.1058e-02, -1.6056e-02, -6.6449e-02]],\n",
            "\n",
            "         [[ 3.0792e-02, -2.9954e-02, -3.5840e-02],\n",
            "          [-4.8895e-02, -1.2940e-02, -2.4149e-02],\n",
            "          [ 1.2103e-01, -5.6121e-03,  5.1470e-03]],\n",
            "\n",
            "         [[-1.1212e-02,  5.5661e-02, -2.0974e-02],\n",
            "          [-1.3182e-02,  6.5907e-02,  5.7097e-02],\n",
            "          [ 4.7265e-02,  9.5786e-02, -1.7952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.0440e-02, -3.0773e-02,  1.7443e-02],\n",
            "          [ 1.0650e-02, -7.2580e-02, -7.6375e-02],\n",
            "          [ 4.6634e-02,  4.6443e-02,  1.5834e-02]],\n",
            "\n",
            "         [[ 6.1971e-04,  2.0822e-02,  2.6039e-02],\n",
            "          [ 5.9719e-02, -2.4735e-02, -3.5424e-02],\n",
            "          [-4.4247e-02,  2.7197e-04,  1.9516e-02]],\n",
            "\n",
            "         [[ 5.2017e-03, -6.0717e-02,  3.9297e-02],\n",
            "          [-1.3585e-02, -4.4474e-02,  3.6900e-02],\n",
            "          [-1.0438e-02, -2.1893e-02,  4.5572e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.0926e-02,  2.5006e-02,  1.9450e-02],\n",
            "          [ 4.2647e-02,  1.3402e-02, -6.2047e-03],\n",
            "          [ 6.8751e-03, -1.7562e-02, -3.6012e-02]],\n",
            "\n",
            "         [[-6.4880e-03, -2.9046e-04,  3.6202e-02],\n",
            "          [-2.4446e-02,  3.0826e-02,  9.7593e-02],\n",
            "          [-1.7705e-02, -1.1504e-02,  1.0390e-01]],\n",
            "\n",
            "         [[ 1.5943e-02,  1.0239e-02, -6.3483e-02],\n",
            "          [-9.6723e-02,  1.0609e-02,  5.3427e-02],\n",
            "          [ 6.3694e-03,  5.1223e-02, -9.3401e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.4862e-03, -1.1650e-02, -1.7556e-02],\n",
            "          [ 3.3485e-02, -1.6501e-02,  2.8443e-03],\n",
            "          [ 3.3304e-02,  8.6860e-02,  3.3843e-02]],\n",
            "\n",
            "         [[-3.6320e-02, -1.8913e-02, -1.1707e-02],\n",
            "          [ 8.2705e-03, -5.0673e-02, -6.2071e-02],\n",
            "          [-2.4736e-02,  6.1819e-02,  2.7819e-02]],\n",
            "\n",
            "         [[-3.9525e-02, -3.9709e-02, -2.6275e-02],\n",
            "          [ 4.6188e-02,  4.7785e-02, -3.5540e-02],\n",
            "          [-6.5820e-02,  9.9100e-03, -3.9453e-02]]]])), ('module.encoder_k.layer2.3.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.3.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1.])), ('module.encoder_k.layer2.3.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer2.3.conv3.weight', tensor([[[[-0.0496]],\n",
            "\n",
            "         [[ 0.0308]],\n",
            "\n",
            "         [[-0.0671]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0225]],\n",
            "\n",
            "         [[-0.0443]],\n",
            "\n",
            "         [[-0.0912]]],\n",
            "\n",
            "\n",
            "        [[[-0.0430]],\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[ 0.1286]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0950]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         [[-0.0738]]],\n",
            "\n",
            "\n",
            "        [[[-0.0059]],\n",
            "\n",
            "         [[ 0.0812]],\n",
            "\n",
            "         [[-0.0936]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1761]],\n",
            "\n",
            "         [[ 0.0358]],\n",
            "\n",
            "         [[ 0.0380]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0665]],\n",
            "\n",
            "         [[ 0.0652]],\n",
            "\n",
            "         [[ 0.0116]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0563]],\n",
            "\n",
            "         [[-0.0551]],\n",
            "\n",
            "         [[-0.0765]]],\n",
            "\n",
            "\n",
            "        [[[-0.0174]],\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         [[ 0.0449]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0276]],\n",
            "\n",
            "         [[-0.1217]],\n",
            "\n",
            "         [[ 0.0428]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0202]],\n",
            "\n",
            "         [[-0.1253]],\n",
            "\n",
            "         [[-0.0650]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0617]],\n",
            "\n",
            "         [[-0.0924]],\n",
            "\n",
            "         [[-0.0165]]]])), ('module.encoder_k.layer2.3.bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.3.bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer2.3.bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer2.3.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.0.conv1.weight', tensor([[[[-0.0199]],\n",
            "\n",
            "         [[-0.0956]],\n",
            "\n",
            "         [[ 0.0166]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0142]],\n",
            "\n",
            "         [[ 0.0951]],\n",
            "\n",
            "         [[-0.0889]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0015]],\n",
            "\n",
            "         [[-0.1013]],\n",
            "\n",
            "         [[-0.1308]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0605]],\n",
            "\n",
            "         [[-0.1027]],\n",
            "\n",
            "         [[ 0.0254]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0518]],\n",
            "\n",
            "         [[ 0.1133]],\n",
            "\n",
            "         [[ 0.0779]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1883]],\n",
            "\n",
            "         [[-0.0159]],\n",
            "\n",
            "         [[-0.0929]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0577]],\n",
            "\n",
            "         [[ 0.0295]],\n",
            "\n",
            "         [[ 0.0622]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0487]],\n",
            "\n",
            "         [[ 0.1069]],\n",
            "\n",
            "         [[-0.0538]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0331]],\n",
            "\n",
            "         [[ 0.0904]],\n",
            "\n",
            "         [[-0.1863]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0472]],\n",
            "\n",
            "         [[-0.0035]],\n",
            "\n",
            "         [[-0.0246]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0551]],\n",
            "\n",
            "         [[-0.2448]],\n",
            "\n",
            "         [[-0.0770]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0390]],\n",
            "\n",
            "         [[-0.0319]],\n",
            "\n",
            "         [[ 0.0552]]]])), ('module.encoder_k.layer3.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.0.conv2.weight', tensor([[[[-4.9663e-02,  2.3397e-02,  2.8464e-03],\n",
            "          [ 2.2094e-03, -2.4448e-02, -2.2365e-02],\n",
            "          [ 3.7250e-03, -2.2872e-02, -7.1784e-03]],\n",
            "\n",
            "         [[-5.3836e-03,  5.0482e-02, -4.6048e-02],\n",
            "          [-2.2515e-02,  1.5977e-02, -1.6546e-02],\n",
            "          [ 3.6730e-03,  2.8759e-03,  1.3568e-02]],\n",
            "\n",
            "         [[-3.9657e-02,  1.3886e-03, -1.4713e-02],\n",
            "          [-7.8913e-02,  2.3137e-02, -3.6984e-03],\n",
            "          [ 4.4267e-02,  3.6957e-02, -1.4662e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.6209e-03,  2.7667e-02, -9.4998e-03],\n",
            "          [ 1.9873e-02, -4.2416e-02,  3.9956e-03],\n",
            "          [ 8.1255e-03, -2.8597e-02,  5.3577e-03]],\n",
            "\n",
            "         [[-1.0911e-02, -9.2327e-03,  5.4599e-02],\n",
            "          [-2.9180e-02,  1.6269e-02,  5.1846e-03],\n",
            "          [-1.3205e-02,  8.4887e-03,  4.6257e-02]],\n",
            "\n",
            "         [[ 1.1215e-02, -3.5248e-02, -4.9783e-02],\n",
            "          [-5.0163e-03, -1.1215e-03,  2.2925e-02],\n",
            "          [ 3.6902e-02, -1.4246e-02,  4.8238e-03]]],\n",
            "\n",
            "\n",
            "        [[[-3.3506e-03, -3.2564e-02, -2.5500e-02],\n",
            "          [-2.0019e-03, -4.2125e-04,  2.5693e-03],\n",
            "          [-5.2061e-02,  2.6567e-02, -3.3902e-02]],\n",
            "\n",
            "         [[-3.3594e-02, -2.3197e-02,  1.1350e-02],\n",
            "          [-4.6662e-02, -4.1333e-02,  5.3211e-02],\n",
            "          [ 1.4485e-02, -1.1782e-02, -1.5482e-02]],\n",
            "\n",
            "         [[ 4.1609e-02, -2.8274e-03, -3.6219e-02],\n",
            "          [ 3.0869e-02, -2.0871e-02, -2.5953e-02],\n",
            "          [ 1.2111e-03,  3.8068e-03, -1.3093e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.6906e-02,  4.1184e-02, -6.7997e-03],\n",
            "          [ 4.6377e-02,  3.4289e-02, -2.0415e-02],\n",
            "          [ 4.4391e-05, -2.9314e-02,  1.6006e-02]],\n",
            "\n",
            "         [[ 1.6508e-02,  4.4465e-02, -4.7056e-03],\n",
            "          [-3.2881e-02,  6.7810e-03, -1.1304e-02],\n",
            "          [ 9.3818e-03,  6.8706e-03, -2.6984e-02]],\n",
            "\n",
            "         [[-4.8381e-02,  1.0455e-02, -6.8211e-03],\n",
            "          [ 2.8087e-02,  3.0887e-02,  3.3556e-03],\n",
            "          [-3.1545e-03,  4.8943e-02, -7.6599e-03]]],\n",
            "\n",
            "\n",
            "        [[[-1.2367e-02, -3.1496e-02,  6.0545e-03],\n",
            "          [ 4.3655e-02,  2.5236e-03, -2.4202e-02],\n",
            "          [-1.3633e-03, -7.6109e-03,  4.8260e-02]],\n",
            "\n",
            "         [[ 2.6626e-02,  4.0929e-02,  9.6613e-03],\n",
            "          [-2.7113e-02,  3.9245e-02,  2.4958e-03],\n",
            "          [-8.7761e-03,  2.9972e-02, -8.8409e-03]],\n",
            "\n",
            "         [[-1.6143e-02,  3.1484e-02, -5.0397e-03],\n",
            "          [-9.5713e-03, -3.8084e-02, -2.8171e-02],\n",
            "          [-1.9697e-02, -4.7335e-03, -2.3531e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.8628e-02, -4.3312e-02,  1.9249e-02],\n",
            "          [ 4.5846e-03, -1.8125e-02, -3.0215e-03],\n",
            "          [-2.6459e-02,  2.9310e-02, -1.7524e-03]],\n",
            "\n",
            "         [[ 3.4652e-02,  1.3164e-02, -2.7427e-03],\n",
            "          [-9.8975e-02,  4.9779e-03, -1.7790e-02],\n",
            "          [ 3.3417e-02, -3.0878e-02,  3.3808e-02]],\n",
            "\n",
            "         [[-3.9711e-02,  7.3333e-02, -3.0276e-02],\n",
            "          [-2.8341e-02, -1.5603e-03,  7.1847e-04],\n",
            "          [ 2.4754e-03,  4.1580e-02, -2.1754e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-4.1305e-02, -3.0037e-02, -3.0353e-02],\n",
            "          [ 6.7595e-03,  1.3360e-02,  1.0195e-02],\n",
            "          [-3.0045e-02, -1.6443e-02,  1.6502e-02]],\n",
            "\n",
            "         [[ 1.3505e-02, -1.1012e-02,  1.7798e-02],\n",
            "          [ 3.4832e-02, -4.8080e-02, -2.5357e-02],\n",
            "          [ 2.9775e-03,  3.1159e-03, -6.5683e-02]],\n",
            "\n",
            "         [[-2.6140e-02, -3.5974e-03, -5.7961e-02],\n",
            "          [ 3.7935e-02,  1.7469e-02, -3.7175e-02],\n",
            "          [-1.9885e-02, -1.0218e-02,  7.3468e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.3351e-02,  2.0622e-03, -3.2270e-02],\n",
            "          [-1.8721e-02,  5.7329e-03,  6.9424e-03],\n",
            "          [-3.0536e-02,  2.5859e-02,  1.7404e-02]],\n",
            "\n",
            "         [[-2.4225e-02,  3.1108e-02, -3.4956e-02],\n",
            "          [ 1.2613e-02, -1.6718e-02, -5.7247e-02],\n",
            "          [ 3.3959e-02, -3.9786e-02,  2.5693e-02]],\n",
            "\n",
            "         [[-2.2300e-02,  1.8675e-02, -1.8242e-02],\n",
            "          [ 1.9164e-02, -2.0378e-02, -3.4195e-02],\n",
            "          [ 1.1678e-02,  4.6326e-02, -5.3498e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6348e-02, -2.9376e-03,  3.0171e-02],\n",
            "          [ 3.0700e-02, -8.8262e-03, -2.7142e-02],\n",
            "          [-5.1273e-02,  4.5427e-02, -1.2912e-02]],\n",
            "\n",
            "         [[-2.8729e-02, -1.1387e-02,  5.3612e-03],\n",
            "          [-2.4562e-02,  1.8516e-02, -5.5989e-02],\n",
            "          [ 3.2987e-02,  1.5897e-02, -3.7957e-02]],\n",
            "\n",
            "         [[-5.0488e-02, -7.0461e-02,  1.9902e-02],\n",
            "          [ 1.6605e-02,  7.2966e-03, -3.2870e-02],\n",
            "          [-4.7814e-03,  1.5486e-02, -2.4417e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.9508e-02, -3.5648e-02, -2.5301e-02],\n",
            "          [-4.6586e-03, -1.7064e-02,  2.5175e-02],\n",
            "          [ 5.2074e-02, -3.9429e-02, -7.1824e-02]],\n",
            "\n",
            "         [[-8.0111e-03, -1.8161e-02,  1.7190e-02],\n",
            "          [ 1.8336e-02,  1.0150e-02,  1.3615e-02],\n",
            "          [-2.3567e-02, -5.4529e-02, -2.7474e-02]],\n",
            "\n",
            "         [[ 4.9409e-02,  9.0935e-03,  3.9998e-02],\n",
            "          [ 3.7406e-03, -6.4088e-02,  3.3114e-02],\n",
            "          [-1.7218e-02,  2.1583e-02, -1.5669e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.2692e-02, -1.9992e-02,  6.2626e-02],\n",
            "          [-5.2451e-02, -2.2966e-02, -2.9006e-02],\n",
            "          [-1.2961e-02,  1.7061e-02, -1.2150e-02]],\n",
            "\n",
            "         [[-4.3864e-02,  2.8314e-03, -6.4951e-03],\n",
            "          [-9.5238e-03,  1.7325e-02, -1.4232e-02],\n",
            "          [-2.3668e-02, -6.7524e-02, -4.6335e-02]],\n",
            "\n",
            "         [[-1.9403e-02, -2.3183e-02, -1.2787e-02],\n",
            "          [-4.4870e-03, -1.2735e-02,  3.5427e-02],\n",
            "          [ 4.7133e-04, -7.3741e-02, -2.7211e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7108e-02,  1.8472e-02, -2.4584e-03],\n",
            "          [-1.9707e-02,  1.0193e-02,  5.6982e-02],\n",
            "          [ 2.0483e-02,  4.0088e-02,  9.4193e-03]],\n",
            "\n",
            "         [[-1.6692e-02,  6.4275e-02, -2.5562e-02],\n",
            "          [-9.6341e-03,  1.1054e-02, -4.5480e-03],\n",
            "          [ 2.0154e-03, -5.0286e-02,  6.6681e-02]],\n",
            "\n",
            "         [[ 1.0447e-03,  1.3399e-02, -2.0519e-03],\n",
            "          [ 1.4928e-02, -6.2575e-03,  3.9796e-02],\n",
            "          [ 1.3097e-02,  1.3690e-02,  4.8567e-02]]]])), ('module.encoder_k.layer3.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.0.conv3.weight', tensor([[[[ 0.0193]],\n",
            "\n",
            "         [[-0.0338]],\n",
            "\n",
            "         [[ 0.0822]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0016]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         [[ 0.0770]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0033]],\n",
            "\n",
            "         [[ 0.0469]],\n",
            "\n",
            "         [[ 0.0356]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0240]],\n",
            "\n",
            "         [[-0.0358]],\n",
            "\n",
            "         [[ 0.0104]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0578]],\n",
            "\n",
            "         [[ 0.0277]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0446]],\n",
            "\n",
            "         [[-0.0372]],\n",
            "\n",
            "         [[ 0.0213]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0054]],\n",
            "\n",
            "         [[-0.0139]],\n",
            "\n",
            "         [[-0.0508]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         [[-0.0679]],\n",
            "\n",
            "         [[ 0.0852]]],\n",
            "\n",
            "\n",
            "        [[[-0.0079]],\n",
            "\n",
            "         [[ 0.0787]],\n",
            "\n",
            "         [[-0.0173]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0285]],\n",
            "\n",
            "         [[ 0.0218]],\n",
            "\n",
            "         [[ 0.0574]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0525]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         [[-0.0303]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0213]],\n",
            "\n",
            "         [[-0.0300]],\n",
            "\n",
            "         [[ 0.0243]]]])), ('module.encoder_k.layer3.0.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.0.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.0.downsample.0.weight', tensor([[[[ 0.0392]],\n",
            "\n",
            "         [[ 0.0246]],\n",
            "\n",
            "         [[-0.0177]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0758]],\n",
            "\n",
            "         [[-0.0460]],\n",
            "\n",
            "         [[-0.0219]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0417]],\n",
            "\n",
            "         [[-0.0274]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0185]],\n",
            "\n",
            "         [[ 0.1011]],\n",
            "\n",
            "         [[-0.0318]]],\n",
            "\n",
            "\n",
            "        [[[-0.0215]],\n",
            "\n",
            "         [[ 0.0232]],\n",
            "\n",
            "         [[ 0.0761]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0296]],\n",
            "\n",
            "         [[-0.0149]],\n",
            "\n",
            "         [[-0.0079]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.1125]],\n",
            "\n",
            "         [[-0.0478]],\n",
            "\n",
            "         [[-0.0519]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0230]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0618]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0179]],\n",
            "\n",
            "         [[-0.0252]],\n",
            "\n",
            "         [[-0.0375]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0022]],\n",
            "\n",
            "         [[ 0.0551]],\n",
            "\n",
            "         [[ 0.0322]]],\n",
            "\n",
            "\n",
            "        [[[-0.0244]],\n",
            "\n",
            "         [[-0.0082]],\n",
            "\n",
            "         [[ 0.0995]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0575]],\n",
            "\n",
            "         [[-0.0205]],\n",
            "\n",
            "         [[ 0.0132]]]])), ('module.encoder_k.layer3.0.downsample.1.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.0.downsample.1.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.0.downsample.1.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.0.downsample.1.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.1.conv1.weight', tensor([[[[ 0.0807]],\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0097]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         [[ 0.0112]]],\n",
            "\n",
            "\n",
            "        [[[-0.0172]],\n",
            "\n",
            "         [[-0.0354]],\n",
            "\n",
            "         [[ 0.0108]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1473]],\n",
            "\n",
            "         [[-0.0188]],\n",
            "\n",
            "         [[ 0.1102]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1178]],\n",
            "\n",
            "         [[ 0.0543]],\n",
            "\n",
            "         [[ 0.0593]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1215]],\n",
            "\n",
            "         [[ 0.0952]],\n",
            "\n",
            "         [[-0.0217]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0756]],\n",
            "\n",
            "         [[-0.0607]],\n",
            "\n",
            "         [[ 0.0654]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[-0.0525]],\n",
            "\n",
            "         [[-0.0188]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0455]],\n",
            "\n",
            "         [[-0.0460]],\n",
            "\n",
            "         [[-0.1572]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[-0.0425]],\n",
            "\n",
            "         [[-0.0976]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1218]],\n",
            "\n",
            "         [[ 0.0242]],\n",
            "\n",
            "         [[-0.1139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0453]],\n",
            "\n",
            "         [[-0.0877]],\n",
            "\n",
            "         [[ 0.0651]]]])), ('module.encoder_k.layer3.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.1.conv2.weight', tensor([[[[ 0.0032, -0.0051,  0.0349],\n",
            "          [ 0.0125, -0.0590,  0.0119],\n",
            "          [ 0.0204, -0.0140, -0.0222]],\n",
            "\n",
            "         [[ 0.0156,  0.0457, -0.0649],\n",
            "          [-0.0375,  0.0392, -0.0283],\n",
            "          [ 0.0025, -0.0237, -0.0171]],\n",
            "\n",
            "         [[-0.0547, -0.0167,  0.0195],\n",
            "          [-0.0066,  0.0331,  0.0187],\n",
            "          [ 0.0283, -0.0397,  0.0076]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0435,  0.0277,  0.0117],\n",
            "          [-0.0409,  0.0077,  0.0216],\n",
            "          [-0.0702,  0.0298, -0.0381]],\n",
            "\n",
            "         [[-0.0260, -0.0069, -0.0239],\n",
            "          [ 0.0437, -0.0274,  0.0626],\n",
            "          [ 0.0156,  0.0352,  0.0203]],\n",
            "\n",
            "         [[ 0.0471,  0.0069, -0.0261],\n",
            "          [ 0.0295,  0.0107,  0.0434],\n",
            "          [-0.0010, -0.0103, -0.0194]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0051, -0.0396, -0.0489],\n",
            "          [-0.0104,  0.0123, -0.0211],\n",
            "          [-0.0206, -0.0182, -0.0463]],\n",
            "\n",
            "         [[ 0.0713, -0.0569, -0.0073],\n",
            "          [-0.0098,  0.0084, -0.0003],\n",
            "          [-0.0051,  0.0743,  0.0210]],\n",
            "\n",
            "         [[ 0.0140, -0.0011, -0.0072],\n",
            "          [-0.0444,  0.0273, -0.0052],\n",
            "          [-0.0724, -0.0344,  0.0515]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0294, -0.0039, -0.0071],\n",
            "          [ 0.0933, -0.0392,  0.0472],\n",
            "          [ 0.0230, -0.0042,  0.0516]],\n",
            "\n",
            "         [[ 0.0017,  0.0021, -0.0161],\n",
            "          [ 0.0210,  0.0025,  0.0162],\n",
            "          [ 0.0208,  0.0050,  0.0532]],\n",
            "\n",
            "         [[ 0.0240, -0.0368,  0.0369],\n",
            "          [-0.0222,  0.0151, -0.0234],\n",
            "          [ 0.0392,  0.0008, -0.0069]]],\n",
            "\n",
            "\n",
            "        [[[-0.0287, -0.0374,  0.0039],\n",
            "          [ 0.0444, -0.0070,  0.0044],\n",
            "          [ 0.0025, -0.0442,  0.0050]],\n",
            "\n",
            "         [[ 0.0071,  0.0097, -0.0076],\n",
            "          [ 0.0093,  0.0133, -0.0313],\n",
            "          [-0.0097,  0.0343, -0.0166]],\n",
            "\n",
            "         [[-0.0079,  0.0239, -0.0434],\n",
            "          [-0.0326,  0.0129, -0.0250],\n",
            "          [-0.0011, -0.0389, -0.0252]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0232,  0.0356,  0.0025],\n",
            "          [ 0.0119, -0.0193, -0.0030],\n",
            "          [-0.0019,  0.0208, -0.0085]],\n",
            "\n",
            "         [[ 0.0052, -0.0287,  0.0148],\n",
            "          [ 0.0010,  0.0112, -0.0117],\n",
            "          [ 0.0253,  0.0097,  0.0309]],\n",
            "\n",
            "         [[ 0.0142,  0.0101,  0.0317],\n",
            "          [-0.0081,  0.0380, -0.0338],\n",
            "          [ 0.0202, -0.0305,  0.0354]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0224, -0.0193,  0.0210],\n",
            "          [-0.0169, -0.0204, -0.0081],\n",
            "          [-0.0280,  0.0347,  0.0095]],\n",
            "\n",
            "         [[-0.0111, -0.0086,  0.0285],\n",
            "          [-0.0436,  0.0025, -0.0190],\n",
            "          [-0.0227,  0.0127,  0.0139]],\n",
            "\n",
            "         [[ 0.0398, -0.0096, -0.0086],\n",
            "          [-0.0162, -0.0160, -0.0023],\n",
            "          [ 0.0154, -0.0226,  0.0320]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0841,  0.0549,  0.0102],\n",
            "          [ 0.0017, -0.0586,  0.0183],\n",
            "          [ 0.0321, -0.0490,  0.0501]],\n",
            "\n",
            "         [[ 0.0502, -0.0068, -0.0228],\n",
            "          [-0.0474,  0.0025,  0.0394],\n",
            "          [ 0.0092, -0.0043, -0.0518]],\n",
            "\n",
            "         [[ 0.0134,  0.0361,  0.0151],\n",
            "          [ 0.0316, -0.0263,  0.0125],\n",
            "          [ 0.0194,  0.0359, -0.0384]]],\n",
            "\n",
            "\n",
            "        [[[-0.0415,  0.0374, -0.0066],\n",
            "          [ 0.0118,  0.0407,  0.0016],\n",
            "          [-0.0187, -0.0168,  0.0363]],\n",
            "\n",
            "         [[ 0.0699, -0.0003, -0.0231],\n",
            "          [-0.0317,  0.0075, -0.0151],\n",
            "          [-0.0105,  0.0221, -0.0091]],\n",
            "\n",
            "         [[-0.0168, -0.0044, -0.0073],\n",
            "          [ 0.0234,  0.0258, -0.0571],\n",
            "          [ 0.0324,  0.0292, -0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0440, -0.0024,  0.0367],\n",
            "          [ 0.0137,  0.0202, -0.0371],\n",
            "          [-0.0304,  0.0308, -0.0212]],\n",
            "\n",
            "         [[-0.0270, -0.0288, -0.0269],\n",
            "          [ 0.0740,  0.0410,  0.0238],\n",
            "          [ 0.0031,  0.0354,  0.0316]],\n",
            "\n",
            "         [[ 0.0287, -0.0049, -0.0097],\n",
            "          [-0.0260,  0.0295, -0.0172],\n",
            "          [ 0.0288,  0.0437, -0.0021]]],\n",
            "\n",
            "\n",
            "        [[[-0.0572,  0.0229, -0.0047],\n",
            "          [ 0.0278,  0.0123,  0.0061],\n",
            "          [ 0.0248,  0.0215, -0.0076]],\n",
            "\n",
            "         [[-0.0206,  0.0160,  0.0061],\n",
            "          [-0.0286, -0.0193,  0.0251],\n",
            "          [-0.0140,  0.0350,  0.0214]],\n",
            "\n",
            "         [[ 0.0138, -0.0378,  0.0720],\n",
            "          [ 0.0035, -0.0041,  0.0079],\n",
            "          [ 0.0269, -0.0355,  0.0153]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0055, -0.0400, -0.0421],\n",
            "          [-0.0009, -0.0363, -0.0327],\n",
            "          [ 0.0452, -0.0046,  0.0044]],\n",
            "\n",
            "         [[ 0.0357, -0.0156,  0.0356],\n",
            "          [ 0.0051,  0.0086, -0.0025],\n",
            "          [-0.0248,  0.0487,  0.0141]],\n",
            "\n",
            "         [[ 0.0330,  0.0084,  0.0097],\n",
            "          [-0.0096, -0.0114, -0.0373],\n",
            "          [-0.0487, -0.0550,  0.0282]]]])), ('module.encoder_k.layer3.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.1.conv3.weight', tensor([[[[-0.0442]],\n",
            "\n",
            "         [[-0.0007]],\n",
            "\n",
            "         [[ 0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1020]],\n",
            "\n",
            "         [[-0.0623]],\n",
            "\n",
            "         [[ 0.0324]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0431]],\n",
            "\n",
            "         [[ 0.0072]],\n",
            "\n",
            "         [[-0.0353]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[-0.0932]],\n",
            "\n",
            "         [[-0.0387]]],\n",
            "\n",
            "\n",
            "        [[[-0.0175]],\n",
            "\n",
            "         [[-0.0396]],\n",
            "\n",
            "         [[-0.0007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0453]],\n",
            "\n",
            "         [[ 0.1117]],\n",
            "\n",
            "         [[ 0.0139]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0107]],\n",
            "\n",
            "         [[ 0.0327]],\n",
            "\n",
            "         [[ 0.0460]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0875]],\n",
            "\n",
            "         [[ 0.0180]],\n",
            "\n",
            "         [[ 0.0078]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0091]],\n",
            "\n",
            "         [[-0.0017]],\n",
            "\n",
            "         [[ 0.0335]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0858]],\n",
            "\n",
            "         [[ 0.0190]],\n",
            "\n",
            "         [[-0.0294]]],\n",
            "\n",
            "\n",
            "        [[[-0.0109]],\n",
            "\n",
            "         [[ 0.0166]],\n",
            "\n",
            "         [[ 0.0310]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0086]],\n",
            "\n",
            "         [[ 0.0105]],\n",
            "\n",
            "         [[ 0.0325]]]])), ('module.encoder_k.layer3.1.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.1.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.2.conv1.weight', tensor([[[[-0.0274]],\n",
            "\n",
            "         [[-0.0174]],\n",
            "\n",
            "         [[ 0.0243]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0985]],\n",
            "\n",
            "         [[ 0.0036]],\n",
            "\n",
            "         [[-0.0047]]],\n",
            "\n",
            "\n",
            "        [[[-0.0339]],\n",
            "\n",
            "         [[-0.0891]],\n",
            "\n",
            "         [[-0.0051]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0517]],\n",
            "\n",
            "         [[-0.1746]],\n",
            "\n",
            "         [[-0.1943]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0243]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0423]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0425]],\n",
            "\n",
            "         [[-0.0675]],\n",
            "\n",
            "         [[-0.0299]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0167]],\n",
            "\n",
            "         [[-0.0739]],\n",
            "\n",
            "         [[-0.0005]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0609]],\n",
            "\n",
            "         [[-0.0851]],\n",
            "\n",
            "         [[ 0.0511]]],\n",
            "\n",
            "\n",
            "        [[[-0.2224]],\n",
            "\n",
            "         [[ 0.0176]],\n",
            "\n",
            "         [[ 0.0696]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[ 0.0170]],\n",
            "\n",
            "         [[-0.0864]]],\n",
            "\n",
            "\n",
            "        [[[-0.0312]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         [[ 0.0597]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0719]],\n",
            "\n",
            "         [[ 0.0622]],\n",
            "\n",
            "         [[ 0.0539]]]])), ('module.encoder_k.layer3.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.2.conv2.weight', tensor([[[[-0.0643,  0.0223,  0.0073],\n",
            "          [ 0.0162, -0.0381,  0.0261],\n",
            "          [-0.0165,  0.0149,  0.0564]],\n",
            "\n",
            "         [[-0.0097,  0.0235, -0.0080],\n",
            "          [-0.0150, -0.0014, -0.0292],\n",
            "          [ 0.0432, -0.0088,  0.0094]],\n",
            "\n",
            "         [[-0.0078, -0.0232,  0.0319],\n",
            "          [ 0.0023,  0.0009,  0.0180],\n",
            "          [ 0.0438,  0.0202, -0.0544]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0281,  0.0036, -0.0266],\n",
            "          [ 0.0365,  0.0640, -0.0349],\n",
            "          [-0.0848, -0.0114, -0.0288]],\n",
            "\n",
            "         [[ 0.0426, -0.0100,  0.0073],\n",
            "          [-0.0480, -0.0071, -0.0553],\n",
            "          [-0.0200,  0.0513,  0.0159]],\n",
            "\n",
            "         [[ 0.0402, -0.0476,  0.0255],\n",
            "          [-0.0136,  0.0160, -0.0121],\n",
            "          [ 0.0555,  0.0129,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[-0.0239,  0.0209,  0.0062],\n",
            "          [-0.0331,  0.0579, -0.0338],\n",
            "          [-0.0065,  0.0223,  0.0047]],\n",
            "\n",
            "         [[ 0.0165, -0.0215,  0.0520],\n",
            "          [-0.0438, -0.0154, -0.0185],\n",
            "          [-0.0012,  0.0539, -0.0542]],\n",
            "\n",
            "         [[ 0.0294,  0.0187, -0.0234],\n",
            "          [ 0.0244,  0.0481,  0.0672],\n",
            "          [-0.0100, -0.0477,  0.0354]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0134, -0.0125, -0.0260],\n",
            "          [-0.0299,  0.0121,  0.0122],\n",
            "          [-0.0525, -0.0131, -0.0469]],\n",
            "\n",
            "         [[ 0.0039,  0.0256, -0.0228],\n",
            "          [ 0.0170, -0.0026, -0.0413],\n",
            "          [ 0.0329,  0.0189, -0.0141]],\n",
            "\n",
            "         [[-0.0151, -0.0145, -0.0449],\n",
            "          [ 0.0039,  0.0094, -0.0355],\n",
            "          [ 0.0268,  0.0145, -0.0196]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0052,  0.0215,  0.0100],\n",
            "          [-0.0039,  0.0448,  0.0085],\n",
            "          [ 0.0734,  0.0120,  0.0126]],\n",
            "\n",
            "         [[ 0.0521, -0.0005,  0.0276],\n",
            "          [-0.0158,  0.0335,  0.0498],\n",
            "          [-0.0126,  0.0727, -0.0156]],\n",
            "\n",
            "         [[-0.0998, -0.0048,  0.0272],\n",
            "          [-0.0034,  0.0141,  0.0077],\n",
            "          [ 0.0203, -0.0094,  0.0261]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0272,  0.0455, -0.0812],\n",
            "          [ 0.0325,  0.0141,  0.0399],\n",
            "          [ 0.0117,  0.0029,  0.0020]],\n",
            "\n",
            "         [[-0.0203, -0.0459,  0.0109],\n",
            "          [ 0.0452, -0.0026,  0.0010],\n",
            "          [ 0.0003, -0.0345, -0.0043]],\n",
            "\n",
            "         [[-0.0413, -0.0033, -0.0667],\n",
            "          [-0.0121, -0.0124, -0.0042],\n",
            "          [-0.0197, -0.0158,  0.0031]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0072,  0.0461,  0.0095],\n",
            "          [-0.0013,  0.0059, -0.0221],\n",
            "          [-0.0396,  0.0050, -0.0216]],\n",
            "\n",
            "         [[ 0.0043, -0.0269, -0.0075],\n",
            "          [ 0.0044, -0.0500, -0.0524],\n",
            "          [-0.0131,  0.0083,  0.0448]],\n",
            "\n",
            "         [[ 0.0147, -0.0036,  0.0378],\n",
            "          [-0.0350, -0.0124, -0.0100],\n",
            "          [-0.0219, -0.0230, -0.0448]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0114, -0.0230,  0.0363],\n",
            "          [ 0.0042, -0.0237,  0.0023],\n",
            "          [-0.0379,  0.0189,  0.0090]],\n",
            "\n",
            "         [[ 0.0151,  0.0036, -0.0057],\n",
            "          [-0.0053,  0.0030,  0.0486],\n",
            "          [ 0.0136,  0.0249,  0.0402]],\n",
            "\n",
            "         [[ 0.0108, -0.0105,  0.0003],\n",
            "          [-0.0175,  0.0449, -0.0467],\n",
            "          [ 0.0103,  0.0106,  0.0008]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0437, -0.0165, -0.0123],\n",
            "          [ 0.0187, -0.0420, -0.0154],\n",
            "          [ 0.0508, -0.0394, -0.0162]],\n",
            "\n",
            "         [[ 0.0202, -0.0033,  0.0333],\n",
            "          [-0.0191, -0.0061,  0.0133],\n",
            "          [-0.0239, -0.0229,  0.0214]],\n",
            "\n",
            "         [[ 0.0463,  0.0008,  0.0137],\n",
            "          [-0.0088,  0.0123, -0.0059],\n",
            "          [-0.0055, -0.0631, -0.0345]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0030, -0.0097,  0.0106],\n",
            "          [ 0.0060, -0.0005, -0.0054],\n",
            "          [-0.0397,  0.0170,  0.0177]],\n",
            "\n",
            "         [[-0.0287, -0.0639, -0.0053],\n",
            "          [ 0.0037, -0.0585, -0.0272],\n",
            "          [ 0.0076, -0.0113,  0.0544]],\n",
            "\n",
            "         [[-0.0519,  0.0067,  0.0457],\n",
            "          [ 0.0775, -0.0114,  0.0120],\n",
            "          [-0.0241, -0.0231,  0.0114]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0041, -0.0243,  0.0234],\n",
            "          [ 0.0091,  0.0364, -0.0146],\n",
            "          [-0.0123, -0.0127,  0.0271]],\n",
            "\n",
            "         [[-0.0203, -0.0301,  0.0107],\n",
            "          [-0.0191,  0.0026,  0.0096],\n",
            "          [-0.0156, -0.0539,  0.0371]],\n",
            "\n",
            "         [[ 0.0344,  0.0038, -0.0109],\n",
            "          [-0.0147,  0.0592, -0.0123],\n",
            "          [-0.0229, -0.0084, -0.0109]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0335,  0.0209,  0.0526],\n",
            "          [-0.0490, -0.0254,  0.0236],\n",
            "          [ 0.0111, -0.0114,  0.0162]],\n",
            "\n",
            "         [[-0.0454,  0.0177, -0.0170],\n",
            "          [ 0.0010, -0.0315, -0.0019],\n",
            "          [-0.0272, -0.0231,  0.0362]],\n",
            "\n",
            "         [[ 0.0032, -0.0265, -0.0161],\n",
            "          [-0.0130, -0.0284,  0.0087],\n",
            "          [ 0.0304, -0.0663, -0.0237]]]])), ('module.encoder_k.layer3.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.2.conv3.weight', tensor([[[[ 8.7330e-02]],\n",
            "\n",
            "         [[ 1.8150e-02]],\n",
            "\n",
            "         [[-3.7326e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.9561e-02]],\n",
            "\n",
            "         [[-3.0356e-02]],\n",
            "\n",
            "         [[-1.5931e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.2362e-02]],\n",
            "\n",
            "         [[-4.6797e-02]],\n",
            "\n",
            "         [[ 4.0196e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.9174e-02]],\n",
            "\n",
            "         [[-3.8268e-02]],\n",
            "\n",
            "         [[-1.2184e-02]]],\n",
            "\n",
            "\n",
            "        [[[-9.0946e-02]],\n",
            "\n",
            "         [[ 3.2996e-02]],\n",
            "\n",
            "         [[ 4.6675e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8309e-02]],\n",
            "\n",
            "         [[ 1.0863e-02]],\n",
            "\n",
            "         [[-9.7164e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.7940e-02]],\n",
            "\n",
            "         [[-5.3418e-02]],\n",
            "\n",
            "         [[ 4.0627e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8222e-02]],\n",
            "\n",
            "         [[-6.7527e-02]],\n",
            "\n",
            "         [[-3.9943e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.5668e-03]],\n",
            "\n",
            "         [[ 3.1713e-03]],\n",
            "\n",
            "         [[-1.7004e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.2723e-03]],\n",
            "\n",
            "         [[ 9.0465e-02]],\n",
            "\n",
            "         [[ 2.6719e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.9085e-02]],\n",
            "\n",
            "         [[-4.1878e-05]],\n",
            "\n",
            "         [[ 1.9438e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1368e-02]],\n",
            "\n",
            "         [[ 6.1185e-02]],\n",
            "\n",
            "         [[-4.8456e-02]]]])), ('module.encoder_k.layer3.2.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.2.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.3.conv1.weight', tensor([[[[ 0.0106]],\n",
            "\n",
            "         [[-0.0747]],\n",
            "\n",
            "         [[ 0.1107]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0489]],\n",
            "\n",
            "         [[ 0.0715]],\n",
            "\n",
            "         [[-0.0667]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0502]],\n",
            "\n",
            "         [[ 0.0354]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1239]],\n",
            "\n",
            "         [[ 0.1164]],\n",
            "\n",
            "         [[-0.0048]]],\n",
            "\n",
            "\n",
            "        [[[-0.0058]],\n",
            "\n",
            "         [[ 0.0650]],\n",
            "\n",
            "         [[-0.1496]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1950]],\n",
            "\n",
            "         [[ 0.0182]],\n",
            "\n",
            "         [[-0.0900]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1352]],\n",
            "\n",
            "         [[-0.2122]],\n",
            "\n",
            "         [[-0.0060]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1065]],\n",
            "\n",
            "         [[-0.0028]],\n",
            "\n",
            "         [[-0.0944]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0566]],\n",
            "\n",
            "         [[ 0.0987]],\n",
            "\n",
            "         [[ 0.1623]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0158]],\n",
            "\n",
            "         [[-0.1581]],\n",
            "\n",
            "         [[-0.0340]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0085]],\n",
            "\n",
            "         [[-0.0855]],\n",
            "\n",
            "         [[-0.0304]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0025]],\n",
            "\n",
            "         [[ 0.0801]],\n",
            "\n",
            "         [[-0.0548]]]])), ('module.encoder_k.layer3.3.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.3.conv2.weight', tensor([[[[ 2.3732e-02, -1.5593e-02,  1.1678e-02],\n",
            "          [-5.4454e-03, -7.3257e-02,  4.1764e-02],\n",
            "          [-4.7421e-02,  5.0688e-02,  2.8520e-04]],\n",
            "\n",
            "         [[-3.2251e-02,  1.4166e-02,  1.9641e-02],\n",
            "          [-3.1768e-03,  2.6278e-02,  3.7000e-02],\n",
            "          [-6.4823e-02,  4.0941e-02,  1.6621e-02]],\n",
            "\n",
            "         [[ 5.8608e-02, -5.1863e-03, -4.0947e-03],\n",
            "          [-1.4858e-02, -3.2162e-02,  3.3937e-02],\n",
            "          [-5.2022e-03,  2.4755e-02,  2.1484e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7701e-02, -7.8604e-03, -3.1996e-02],\n",
            "          [-4.6200e-02, -3.9020e-02,  8.4957e-05],\n",
            "          [-1.1204e-02, -1.2654e-02, -5.2672e-03]],\n",
            "\n",
            "         [[-3.5223e-02, -5.3915e-02,  2.3004e-02],\n",
            "          [-1.0993e-02,  2.0502e-02, -8.6021e-03],\n",
            "          [ 7.0887e-03,  2.8324e-03, -6.1497e-02]],\n",
            "\n",
            "         [[-5.4516e-03, -1.0753e-02,  1.9851e-02],\n",
            "          [ 3.3721e-03,  2.9858e-02, -1.7922e-03],\n",
            "          [-1.2642e-02, -3.6905e-04,  6.3297e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9347e-02,  1.9499e-02,  2.1435e-02],\n",
            "          [ 1.5802e-02,  9.2978e-04, -1.9972e-02],\n",
            "          [-6.1844e-02, -1.5045e-02,  6.0212e-02]],\n",
            "\n",
            "         [[ 6.2442e-03,  7.2824e-02, -8.0176e-03],\n",
            "          [ 1.8436e-02,  2.5399e-02, -1.4074e-02],\n",
            "          [-2.0551e-02, -2.8144e-02, -8.5662e-03]],\n",
            "\n",
            "         [[-7.5520e-03,  1.3732e-02,  2.5948e-02],\n",
            "          [-5.3264e-03, -2.5864e-02, -1.2898e-02],\n",
            "          [-7.7851e-03,  5.7545e-03,  1.1646e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9417e-02, -7.6236e-03,  9.8140e-03],\n",
            "          [-2.7307e-02,  8.3805e-03, -2.4744e-02],\n",
            "          [-2.2565e-03, -2.4605e-02, -9.5554e-03]],\n",
            "\n",
            "         [[-1.4980e-02,  2.3043e-02, -1.0219e-02],\n",
            "          [ 5.2415e-02,  1.8503e-02, -1.7898e-02],\n",
            "          [-4.1631e-02,  8.4491e-03,  6.4376e-04]],\n",
            "\n",
            "         [[-3.7732e-03, -1.8132e-02, -3.2454e-02],\n",
            "          [-3.3283e-02,  5.9590e-03, -1.0538e-02],\n",
            "          [-1.0680e-02, -3.2789e-02,  1.7172e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.7386e-02,  1.2469e-02, -6.8572e-04],\n",
            "          [ 3.2313e-02,  8.9345e-03,  6.6208e-02],\n",
            "          [-2.8205e-02,  1.6004e-02, -2.2782e-02]],\n",
            "\n",
            "         [[-3.5977e-02, -5.5905e-02,  2.1250e-02],\n",
            "          [-3.7974e-02, -5.5258e-02, -1.9676e-02],\n",
            "          [ 1.3267e-02, -4.1506e-02, -6.7810e-02]],\n",
            "\n",
            "         [[ 1.1042e-03,  2.6430e-02,  6.8759e-02],\n",
            "          [ 3.2589e-03, -1.5611e-02,  6.7705e-02],\n",
            "          [ 3.4563e-02, -8.5563e-03,  3.4557e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2739e-02, -2.3634e-02, -5.2943e-02],\n",
            "          [ 2.3409e-02, -5.7300e-02,  4.8073e-02],\n",
            "          [-9.7026e-03,  2.4309e-03,  4.3754e-03]],\n",
            "\n",
            "         [[ 3.4525e-02, -7.9031e-03,  3.2685e-03],\n",
            "          [-3.0254e-02, -4.2163e-02,  3.3051e-02],\n",
            "          [ 5.2238e-03, -5.5978e-03,  3.1332e-02]],\n",
            "\n",
            "         [[-1.8831e-02, -3.1148e-03, -1.7265e-02],\n",
            "          [ 3.1696e-02,  2.7305e-02, -2.8414e-02],\n",
            "          [-3.3642e-02, -2.8114e-03, -7.8746e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-5.7127e-02, -1.3488e-02, -4.0076e-02],\n",
            "          [ 2.9296e-02, -5.2778e-02, -7.7201e-03],\n",
            "          [ 4.3360e-02, -1.5603e-02, -2.5685e-02]],\n",
            "\n",
            "         [[ 5.2682e-02,  2.9663e-02, -1.5212e-02],\n",
            "          [ 2.3712e-02,  9.6656e-03, -2.3161e-02],\n",
            "          [ 3.2293e-02, -4.1549e-02,  5.6114e-02]],\n",
            "\n",
            "         [[ 3.9051e-02, -4.3433e-02,  1.3252e-02],\n",
            "          [ 3.5322e-02,  2.5708e-02,  1.8754e-02],\n",
            "          [-1.0086e-02,  2.3038e-02, -3.9194e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.9949e-02, -2.0227e-02, -1.7385e-03],\n",
            "          [ 5.3137e-03, -9.6847e-02, -6.8197e-02],\n",
            "          [ 6.7398e-03,  1.3202e-02,  4.9642e-02]],\n",
            "\n",
            "         [[ 1.7395e-03,  4.3736e-03, -4.8616e-02],\n",
            "          [ 3.2420e-02,  6.2609e-02,  7.4321e-02],\n",
            "          [-1.2509e-02,  1.2482e-02,  4.2508e-02]],\n",
            "\n",
            "         [[-2.2197e-02, -3.9564e-02,  5.0979e-03],\n",
            "          [ 2.1141e-02,  3.1019e-02,  4.0500e-05],\n",
            "          [ 1.1919e-02,  1.9278e-02,  3.7940e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.5047e-02,  7.2339e-04, -1.4314e-02],\n",
            "          [ 3.1569e-02,  1.8815e-02, -1.3703e-02],\n",
            "          [ 1.8622e-02, -6.1251e-02,  3.2271e-03]],\n",
            "\n",
            "         [[-4.3960e-02,  1.1834e-02, -7.2148e-03],\n",
            "          [-2.8679e-02, -7.3731e-03, -9.6342e-03],\n",
            "          [ 4.7729e-02, -3.2625e-02, -9.0215e-03]],\n",
            "\n",
            "         [[-5.0980e-02,  6.6582e-03,  1.0131e-02],\n",
            "          [ 1.3340e-02,  1.7635e-02,  1.0425e-03],\n",
            "          [-6.0471e-02,  1.6080e-02, -4.1475e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.7050e-03,  4.7610e-02,  3.4454e-02],\n",
            "          [-1.9878e-02,  6.3343e-02, -4.0136e-02],\n",
            "          [-2.0662e-03,  6.2416e-05, -2.7687e-02]],\n",
            "\n",
            "         [[ 9.0488e-03,  1.2649e-02, -8.6824e-03],\n",
            "          [-9.5001e-03, -2.0791e-02,  3.5548e-02],\n",
            "          [ 3.1303e-02, -2.0169e-03, -2.5569e-02]],\n",
            "\n",
            "         [[-2.7612e-03,  7.8085e-03,  1.4336e-02],\n",
            "          [-3.8492e-03,  4.5317e-03, -1.1357e-02],\n",
            "          [ 3.9413e-03,  3.0328e-02, -3.1430e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2665e-02,  2.2151e-02, -3.8377e-02],\n",
            "          [-5.1898e-02,  2.1006e-02, -4.3976e-02],\n",
            "          [ 1.6070e-02, -1.7512e-02,  8.7686e-03]],\n",
            "\n",
            "         [[ 1.2831e-02, -2.3482e-02, -7.7172e-02],\n",
            "          [ 5.6686e-02, -1.3040e-02,  1.1819e-02],\n",
            "          [-2.9326e-02,  3.2904e-02,  3.0136e-02]],\n",
            "\n",
            "         [[ 8.9100e-03,  2.7034e-02,  3.1578e-02],\n",
            "          [-1.5928e-02, -1.8973e-02, -3.4173e-03],\n",
            "          [ 1.9817e-02,  6.5007e-02,  5.0847e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.8451e-02, -8.4973e-04, -2.4299e-02],\n",
            "          [-1.5435e-02,  2.4706e-02, -2.8424e-02],\n",
            "          [-2.8462e-02, -2.1828e-02,  4.1044e-02]],\n",
            "\n",
            "         [[-9.3262e-03, -1.2199e-02, -2.8219e-02],\n",
            "          [-9.3040e-03,  1.5445e-02,  8.1939e-03],\n",
            "          [ 2.0456e-02,  1.8526e-02,  6.8105e-03]],\n",
            "\n",
            "         [[-3.2708e-02,  3.1330e-02,  1.4906e-02],\n",
            "          [ 2.7782e-03, -6.4040e-02,  1.6050e-02],\n",
            "          [-6.7987e-02,  7.6307e-03,  2.2476e-02]]]])), ('module.encoder_k.layer3.3.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.3.conv3.weight', tensor([[[[ 0.0196]],\n",
            "\n",
            "         [[-0.0302]],\n",
            "\n",
            "         [[-0.0862]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0102]],\n",
            "\n",
            "         [[-0.0092]],\n",
            "\n",
            "         [[-0.0122]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0399]],\n",
            "\n",
            "         [[-0.0524]],\n",
            "\n",
            "         [[-0.0882]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0732]],\n",
            "\n",
            "         [[-0.0345]],\n",
            "\n",
            "         [[-0.0184]]],\n",
            "\n",
            "\n",
            "        [[[-0.1086]],\n",
            "\n",
            "         [[-0.0271]],\n",
            "\n",
            "         [[-0.0176]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0346]],\n",
            "\n",
            "         [[ 0.0667]],\n",
            "\n",
            "         [[ 0.0071]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0578]],\n",
            "\n",
            "         [[ 0.0352]],\n",
            "\n",
            "         [[-0.0026]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0163]],\n",
            "\n",
            "         [[ 0.0215]],\n",
            "\n",
            "         [[-0.0598]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0192]],\n",
            "\n",
            "         [[-0.0185]],\n",
            "\n",
            "         [[-0.0079]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0390]],\n",
            "\n",
            "         [[ 0.0543]],\n",
            "\n",
            "         [[-0.0640]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0416]],\n",
            "\n",
            "         [[-0.0424]],\n",
            "\n",
            "         [[-0.0597]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0072]],\n",
            "\n",
            "         [[ 0.0494]],\n",
            "\n",
            "         [[ 0.0014]]]])), ('module.encoder_k.layer3.3.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.3.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.3.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.4.conv1.weight', tensor([[[[ 0.0799]],\n",
            "\n",
            "         [[-0.0296]],\n",
            "\n",
            "         [[-0.0306]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1074]],\n",
            "\n",
            "         [[-0.0672]],\n",
            "\n",
            "         [[ 0.1173]]],\n",
            "\n",
            "\n",
            "        [[[-0.0271]],\n",
            "\n",
            "         [[-0.0502]],\n",
            "\n",
            "         [[ 0.0263]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0407]],\n",
            "\n",
            "         [[-0.1001]],\n",
            "\n",
            "         [[-0.0853]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1534]],\n",
            "\n",
            "         [[ 0.1222]],\n",
            "\n",
            "         [[ 0.2072]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0918]],\n",
            "\n",
            "         [[ 0.0631]],\n",
            "\n",
            "         [[-0.0900]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0545]],\n",
            "\n",
            "         [[ 0.0312]],\n",
            "\n",
            "         [[ 0.1165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.3064]],\n",
            "\n",
            "         [[-0.0094]],\n",
            "\n",
            "         [[-0.1112]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1367]],\n",
            "\n",
            "         [[ 0.1480]],\n",
            "\n",
            "         [[ 0.1162]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0068]],\n",
            "\n",
            "         [[-0.0569]],\n",
            "\n",
            "         [[ 0.0480]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0080]],\n",
            "\n",
            "         [[ 0.0227]],\n",
            "\n",
            "         [[ 0.0858]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0177]],\n",
            "\n",
            "         [[ 0.0481]],\n",
            "\n",
            "         [[-0.0725]]]])), ('module.encoder_k.layer3.4.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.4.conv2.weight', tensor([[[[ 7.3338e-03,  1.9373e-02,  1.9707e-02],\n",
            "          [-2.1532e-02,  3.3052e-02,  3.8693e-03],\n",
            "          [ 4.9842e-02,  1.1481e-02, -1.8720e-02]],\n",
            "\n",
            "         [[-4.4669e-03, -1.9365e-02,  2.7681e-02],\n",
            "          [-3.4476e-02,  3.0804e-02,  2.4409e-02],\n",
            "          [ 6.7232e-02,  4.8196e-02, -2.9887e-02]],\n",
            "\n",
            "         [[-2.9078e-02,  2.1809e-03, -3.0370e-02],\n",
            "          [ 1.8337e-02,  6.7131e-02, -2.2435e-02],\n",
            "          [ 6.6499e-03, -2.2528e-02,  1.3491e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5089e-02, -2.4167e-02, -2.0454e-03],\n",
            "          [-1.8794e-02, -5.5745e-03,  2.6232e-02],\n",
            "          [-4.9493e-02, -5.8282e-03, -2.5210e-02]],\n",
            "\n",
            "         [[ 2.2521e-02,  9.8507e-03, -2.4652e-02],\n",
            "          [-2.0316e-02,  3.1309e-02,  4.9494e-02],\n",
            "          [ 1.4034e-02, -3.7115e-02,  2.3547e-02]],\n",
            "\n",
            "         [[-1.1358e-03,  3.5542e-04, -1.2628e-03],\n",
            "          [-1.6295e-02, -1.1953e-02, -1.4556e-02],\n",
            "          [ 1.0524e-02, -5.7744e-02, -4.0654e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.2436e-02,  3.2009e-02,  6.1339e-02],\n",
            "          [ 8.0088e-03,  5.2708e-02,  2.2592e-02],\n",
            "          [ 2.7179e-02,  5.4765e-02, -1.7246e-02]],\n",
            "\n",
            "         [[-5.5990e-03,  4.9686e-03,  2.7578e-02],\n",
            "          [ 4.8319e-03, -1.5796e-03, -2.1701e-02],\n",
            "          [-1.9010e-04, -1.3032e-02, -1.1791e-02]],\n",
            "\n",
            "         [[ 2.0560e-02, -3.8087e-03,  7.5032e-03],\n",
            "          [-2.0210e-02,  2.4846e-02, -2.5836e-02],\n",
            "          [ 3.7694e-02, -4.5862e-02, -6.7203e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2206e-02, -3.1616e-02,  1.6677e-02],\n",
            "          [ 7.6647e-03, -5.9905e-03,  1.3925e-02],\n",
            "          [ 1.1554e-02,  1.2417e-02, -5.2968e-02]],\n",
            "\n",
            "         [[ 1.6572e-02, -2.4887e-03,  3.1444e-02],\n",
            "          [-4.7708e-03,  1.3446e-02,  7.4763e-02],\n",
            "          [ 5.2145e-02, -2.1992e-02,  2.6994e-02]],\n",
            "\n",
            "         [[-1.3365e-02, -4.1066e-02,  3.8403e-03],\n",
            "          [ 3.1768e-02,  2.6510e-02,  4.0382e-03],\n",
            "          [-4.7060e-03, -4.0799e-02,  6.2538e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1928e-02,  4.6622e-03,  1.2519e-02],\n",
            "          [ 9.7049e-03,  2.6652e-02, -1.2445e-02],\n",
            "          [ 2.8512e-02,  7.0706e-03,  8.5247e-03]],\n",
            "\n",
            "         [[ 5.4512e-03,  2.0676e-02,  2.9383e-02],\n",
            "          [-2.1671e-02,  1.8166e-03,  3.6396e-02],\n",
            "          [ 2.3776e-03,  3.2034e-02, -3.0996e-02]],\n",
            "\n",
            "         [[ 1.6800e-02, -1.1749e-02, -1.1074e-02],\n",
            "          [-4.0777e-02,  3.5455e-02,  1.4780e-02],\n",
            "          [ 2.1859e-02, -3.9251e-03,  3.2919e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7828e-02,  1.0827e-05,  1.9743e-06],\n",
            "          [-1.9438e-02,  3.9270e-02,  9.7671e-03],\n",
            "          [ 3.0816e-02, -7.8504e-03,  3.0842e-03]],\n",
            "\n",
            "         [[-2.8241e-02, -4.5488e-02,  5.5693e-02],\n",
            "          [ 1.2261e-02, -2.2980e-02,  2.0408e-02],\n",
            "          [ 2.0188e-02,  7.4564e-02,  3.4933e-02]],\n",
            "\n",
            "         [[-2.7857e-02,  5.7332e-02, -7.4515e-03],\n",
            "          [-3.1164e-02, -5.1421e-02,  2.6589e-02],\n",
            "          [ 4.6449e-03, -3.9002e-02, -1.3897e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.5883e-02, -2.0598e-02, -1.4898e-02],\n",
            "          [-2.8440e-02,  4.8448e-03, -5.1242e-02],\n",
            "          [-5.1865e-02,  3.6375e-02, -1.8724e-02]],\n",
            "\n",
            "         [[-5.4636e-03,  5.8682e-02, -3.4376e-03],\n",
            "          [-1.2862e-02,  5.4607e-02, -1.1043e-02],\n",
            "          [ 3.0432e-03, -1.9293e-02, -5.6977e-04]],\n",
            "\n",
            "         [[-3.0361e-02, -5.6498e-02, -3.7615e-02],\n",
            "          [-2.0395e-02,  5.2192e-03, -4.0035e-03],\n",
            "          [-4.6382e-02, -2.7645e-02, -3.2080e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6264e-02,  4.3974e-03,  5.9875e-02],\n",
            "          [-1.9964e-02,  2.3373e-02,  1.3863e-02],\n",
            "          [ 5.4157e-02, -6.6494e-04,  3.0034e-02]],\n",
            "\n",
            "         [[ 1.9180e-02,  2.3389e-02, -3.8610e-03],\n",
            "          [-8.3238e-02,  4.8742e-02,  5.2547e-02],\n",
            "          [-1.2360e-02,  1.8731e-02,  3.9457e-02]],\n",
            "\n",
            "         [[ 4.5196e-02,  2.6556e-02, -1.0691e-02],\n",
            "          [-4.0563e-02, -1.7030e-02,  4.0822e-03],\n",
            "          [ 3.1594e-02, -2.4108e-02,  5.5873e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4277e-02, -3.7920e-03, -4.5502e-02],\n",
            "          [ 2.4866e-02,  4.6103e-02, -1.8280e-02],\n",
            "          [-2.1839e-02, -1.2583e-02,  3.2019e-03]],\n",
            "\n",
            "         [[-1.9080e-02, -1.4795e-03, -6.8670e-02],\n",
            "          [ 2.6803e-02,  3.2726e-02, -2.3882e-02],\n",
            "          [-8.9142e-03,  1.1211e-02, -2.6944e-02]],\n",
            "\n",
            "         [[-2.7137e-02, -8.7176e-04,  6.0583e-02],\n",
            "          [-1.8364e-02, -3.9713e-02,  3.0423e-02],\n",
            "          [ 1.0112e-02,  1.7569e-02, -3.2467e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7712e-02,  3.1637e-02, -4.1139e-02],\n",
            "          [ 2.4305e-02, -3.3765e-02, -4.2754e-02],\n",
            "          [-3.1040e-02, -2.4065e-02, -2.4195e-02]],\n",
            "\n",
            "         [[-1.1691e-02, -1.6935e-02, -3.4363e-02],\n",
            "          [-7.1964e-02,  1.9702e-02,  5.0091e-02],\n",
            "          [-4.8034e-02,  1.9559e-02,  1.8886e-02]],\n",
            "\n",
            "         [[-3.0133e-02, -4.1614e-02,  2.3148e-02],\n",
            "          [-1.0256e-03,  2.5346e-02,  2.7380e-02],\n",
            "          [-2.7163e-02, -5.9948e-02,  3.5772e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2613e-02, -8.2736e-03, -1.3233e-02],\n",
            "          [ 1.3102e-02,  9.8061e-03, -1.5685e-02],\n",
            "          [-1.8228e-02, -3.6573e-03, -3.1424e-02]],\n",
            "\n",
            "         [[-1.9826e-02,  1.5436e-02,  2.0194e-02],\n",
            "          [ 3.3407e-02, -2.4175e-02,  3.7801e-02],\n",
            "          [-1.5570e-02, -1.7875e-02, -3.9777e-02]],\n",
            "\n",
            "         [[-2.8840e-03, -8.4796e-03, -4.2131e-02],\n",
            "          [-4.1780e-02,  1.7280e-02,  2.9073e-02],\n",
            "          [-1.2562e-02,  1.5958e-02, -6.5201e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5029e-03, -2.3417e-02, -8.4006e-03],\n",
            "          [-5.1869e-02, -1.0626e-02, -6.8510e-03],\n",
            "          [ 1.2352e-02, -3.8892e-02,  1.0894e-02]],\n",
            "\n",
            "         [[ 2.6845e-03,  2.3776e-02,  2.6875e-02],\n",
            "          [ 3.8813e-03,  2.6486e-03,  2.1920e-02],\n",
            "          [ 2.8081e-02, -6.7758e-02,  2.8913e-02]],\n",
            "\n",
            "         [[-1.5596e-02, -1.3100e-02, -6.2818e-03],\n",
            "          [-8.4096e-03, -2.2520e-02,  1.0863e-02],\n",
            "          [ 1.2086e-02,  1.9446e-02, -1.4481e-02]]]])), ('module.encoder_k.layer3.4.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.4.conv3.weight', tensor([[[[ 0.0591]],\n",
            "\n",
            "         [[-0.0245]],\n",
            "\n",
            "         [[ 0.0028]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0344]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         [[ 0.0369]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0241]],\n",
            "\n",
            "         [[ 0.0255]],\n",
            "\n",
            "         [[-0.0615]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0379]],\n",
            "\n",
            "         [[ 0.0380]],\n",
            "\n",
            "         [[-0.0156]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0351]],\n",
            "\n",
            "         [[-0.0084]],\n",
            "\n",
            "         [[-0.0114]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0226]],\n",
            "\n",
            "         [[ 0.0018]],\n",
            "\n",
            "         [[-0.0682]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0098]],\n",
            "\n",
            "         [[-0.0784]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0286]],\n",
            "\n",
            "         [[-0.0435]],\n",
            "\n",
            "         [[-0.0261]]],\n",
            "\n",
            "\n",
            "        [[[-0.0007]],\n",
            "\n",
            "         [[-0.0155]],\n",
            "\n",
            "         [[-0.0395]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0143]],\n",
            "\n",
            "         [[-0.0031]],\n",
            "\n",
            "         [[-0.0070]]],\n",
            "\n",
            "\n",
            "        [[[-0.0179]],\n",
            "\n",
            "         [[-0.0476]],\n",
            "\n",
            "         [[ 0.0652]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0006]],\n",
            "\n",
            "         [[ 0.0597]],\n",
            "\n",
            "         [[-0.0157]]]])), ('module.encoder_k.layer3.4.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.4.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.4.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.5.conv1.weight', tensor([[[[ 0.0311]],\n",
            "\n",
            "         [[-0.1026]],\n",
            "\n",
            "         [[-0.0805]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0174]],\n",
            "\n",
            "         [[ 0.0507]],\n",
            "\n",
            "         [[ 0.0129]]],\n",
            "\n",
            "\n",
            "        [[[-0.0657]],\n",
            "\n",
            "         [[ 0.1879]],\n",
            "\n",
            "         [[ 0.0184]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0172]],\n",
            "\n",
            "         [[-0.1596]],\n",
            "\n",
            "         [[ 0.0704]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0384]],\n",
            "\n",
            "         [[-0.1039]],\n",
            "\n",
            "         [[ 0.0004]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0151]],\n",
            "\n",
            "         [[ 0.1015]],\n",
            "\n",
            "         [[ 0.0039]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0008]],\n",
            "\n",
            "         [[-0.1391]],\n",
            "\n",
            "         [[ 0.0889]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0930]],\n",
            "\n",
            "         [[ 0.1101]],\n",
            "\n",
            "         [[-0.1277]]],\n",
            "\n",
            "\n",
            "        [[[-0.0543]],\n",
            "\n",
            "         [[-0.0452]],\n",
            "\n",
            "         [[-0.1099]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.2051]],\n",
            "\n",
            "         [[ 0.1050]],\n",
            "\n",
            "         [[-0.0097]]],\n",
            "\n",
            "\n",
            "        [[[-0.0711]],\n",
            "\n",
            "         [[-0.1662]],\n",
            "\n",
            "         [[-0.0603]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.1026]],\n",
            "\n",
            "         [[-0.0911]],\n",
            "\n",
            "         [[-0.0779]]]])), ('module.encoder_k.layer3.5.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.5.conv2.weight', tensor([[[[ 9.0440e-02,  2.0534e-02, -7.7406e-03],\n",
            "          [ 2.8284e-03,  4.9834e-02, -2.4910e-02],\n",
            "          [ 4.5202e-02, -6.1041e-03, -1.2747e-02]],\n",
            "\n",
            "         [[-2.1289e-02, -2.5111e-02, -1.7840e-02],\n",
            "          [-6.7436e-02,  3.6001e-02,  3.3544e-02],\n",
            "          [ 1.0144e-03, -2.8867e-02,  9.5248e-02]],\n",
            "\n",
            "         [[-2.1593e-02, -2.9160e-02, -7.8151e-03],\n",
            "          [-4.5436e-03,  1.7428e-02, -1.1323e-02],\n",
            "          [-2.9771e-02,  2.1989e-02,  2.3313e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8566e-03, -4.8792e-03, -1.4691e-03],\n",
            "          [ 5.8666e-03, -1.8188e-02,  9.4425e-03],\n",
            "          [-3.2236e-04,  3.7093e-02, -5.2100e-03]],\n",
            "\n",
            "         [[ 5.4807e-03,  3.6524e-02, -2.6637e-02],\n",
            "          [-9.7260e-03, -2.5284e-03,  2.2978e-02],\n",
            "          [-1.2457e-02,  2.0358e-02,  9.4651e-03]],\n",
            "\n",
            "         [[-1.3539e-02,  2.7713e-02, -2.6751e-02],\n",
            "          [ 7.9041e-02, -6.8605e-04,  8.7066e-03],\n",
            "          [ 3.2171e-02,  1.1949e-02, -2.6947e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7576e-02,  6.2860e-03, -1.6077e-02],\n",
            "          [-2.1336e-03, -3.3161e-02, -2.5050e-02],\n",
            "          [ 2.9323e-03,  2.7131e-02, -4.6799e-02]],\n",
            "\n",
            "         [[ 2.5350e-02, -6.8396e-02,  4.2902e-02],\n",
            "          [ 2.6301e-02,  1.4769e-02,  1.3784e-02],\n",
            "          [ 1.4025e-02,  3.7343e-02, -1.1796e-02]],\n",
            "\n",
            "         [[-4.9172e-02,  2.6133e-03, -3.6964e-02],\n",
            "          [ 3.0517e-02,  3.0161e-02,  5.6012e-03],\n",
            "          [ 4.1809e-03,  2.2845e-02, -9.0767e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9861e-02,  3.4645e-03, -2.5882e-05],\n",
            "          [ 3.2645e-02, -1.5918e-02,  4.2310e-03],\n",
            "          [ 7.5870e-03,  5.6676e-02, -1.2210e-02]],\n",
            "\n",
            "         [[ 3.5530e-03,  2.3748e-02,  3.7409e-02],\n",
            "          [ 3.2672e-03,  2.1271e-02, -1.0553e-02],\n",
            "          [ 1.3351e-02,  4.8374e-02,  6.1318e-02]],\n",
            "\n",
            "         [[-1.3426e-02, -2.4830e-02,  3.1365e-02],\n",
            "          [-1.3926e-02, -5.5849e-03,  1.7786e-02],\n",
            "          [-3.2056e-03,  6.4852e-02, -5.9317e-03]]],\n",
            "\n",
            "\n",
            "        [[[-4.1134e-03,  8.0173e-03,  4.2754e-04],\n",
            "          [ 6.9294e-03,  3.0562e-02, -2.0753e-02],\n",
            "          [-2.2630e-02,  3.1358e-02, -1.6587e-02]],\n",
            "\n",
            "         [[-1.0962e-02, -1.6781e-02, -7.3434e-05],\n",
            "          [-8.0097e-04,  4.2661e-03,  2.4255e-02],\n",
            "          [-1.0004e-02,  4.0777e-03,  1.5919e-02]],\n",
            "\n",
            "         [[-1.2314e-02,  5.5724e-02, -6.2577e-03],\n",
            "          [-1.5044e-02,  2.6860e-02, -1.1038e-02],\n",
            "          [ 3.3670e-02, -1.1752e-02, -1.9094e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.1297e-02,  1.3522e-02, -3.2208e-02],\n",
            "          [-8.9566e-03, -1.9581e-02, -1.9526e-02],\n",
            "          [ 4.5077e-02,  1.1327e-02, -2.8326e-02]],\n",
            "\n",
            "         [[-1.1127e-02, -1.4566e-02, -2.0468e-02],\n",
            "          [ 1.6162e-02, -1.4077e-02, -1.3731e-02],\n",
            "          [-5.8856e-03,  6.9850e-02, -2.3763e-02]],\n",
            "\n",
            "         [[ 6.3726e-03,  3.0382e-03,  1.8988e-02],\n",
            "          [-3.2335e-03, -4.2224e-02, -2.7614e-02],\n",
            "          [-2.1357e-02,  8.9532e-03,  1.1307e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.9779e-02,  4.7866e-02, -1.4124e-03],\n",
            "          [ 1.9138e-02,  2.0259e-03, -2.4408e-04],\n",
            "          [-3.4522e-02,  5.6187e-03,  1.4601e-03]],\n",
            "\n",
            "         [[-4.5323e-03, -3.1312e-02, -1.5576e-02],\n",
            "          [-5.0370e-03, -2.0592e-02, -4.8158e-02],\n",
            "          [-3.3287e-02,  6.8144e-04,  1.8129e-02]],\n",
            "\n",
            "         [[ 2.8428e-02, -6.4925e-02,  2.6934e-02],\n",
            "          [ 4.8027e-02,  3.3632e-02,  4.3520e-02],\n",
            "          [-3.5167e-02, -6.8467e-02,  4.9150e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8043e-03, -7.1903e-02, -2.2077e-02],\n",
            "          [-2.9521e-02, -9.1072e-03,  2.9936e-02],\n",
            "          [-3.7952e-02, -1.4079e-02, -6.6847e-02]],\n",
            "\n",
            "         [[-1.0489e-02,  3.8752e-03, -8.1818e-02],\n",
            "          [ 1.0940e-02, -4.9740e-03, -6.2629e-03],\n",
            "          [ 2.2878e-02,  2.9969e-03, -5.6671e-03]],\n",
            "\n",
            "         [[-2.2620e-02, -2.6445e-02,  1.9574e-02],\n",
            "          [-2.8337e-04,  9.4012e-03, -1.1164e-02],\n",
            "          [-2.7370e-02,  4.5752e-04,  1.6665e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7664e-02, -2.3467e-02,  1.6995e-02],\n",
            "          [ 2.4366e-02, -4.9385e-03,  2.4229e-02],\n",
            "          [-1.8158e-02, -8.3595e-03, -6.2210e-02]],\n",
            "\n",
            "         [[-6.5096e-03, -2.6362e-02, -1.4052e-02],\n",
            "          [ 6.0626e-02, -1.0534e-02, -2.6178e-02],\n",
            "          [-1.1044e-03, -1.1587e-02, -5.7076e-04]],\n",
            "\n",
            "         [[ 2.7055e-02,  2.6492e-02,  6.9794e-02],\n",
            "          [-2.1124e-02,  1.6630e-03, -2.0191e-02],\n",
            "          [ 3.0975e-02, -2.7955e-02,  1.5355e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7466e-02,  5.0268e-02,  2.4323e-02],\n",
            "          [ 4.4811e-02,  3.7672e-03,  5.0753e-02],\n",
            "          [ 3.0597e-02, -2.6485e-02,  1.3060e-04]],\n",
            "\n",
            "         [[ 9.0979e-03, -3.6375e-02,  4.8779e-02],\n",
            "          [ 3.6125e-03,  5.0255e-03, -1.2534e-02],\n",
            "          [-3.3372e-02, -2.4967e-02,  2.5237e-03]],\n",
            "\n",
            "         [[ 2.9611e-02,  2.5255e-02,  2.0107e-02],\n",
            "          [ 2.9365e-03,  2.6167e-02, -2.4041e-02],\n",
            "          [ 2.0335e-02, -3.6483e-02,  7.8198e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.3002e-02, -1.7374e-02,  9.7171e-03],\n",
            "          [-2.9202e-02, -1.3995e-03, -1.9644e-02],\n",
            "          [ 3.4119e-02,  1.2469e-02,  1.5316e-02]],\n",
            "\n",
            "         [[-1.3471e-02, -4.1007e-02, -9.1064e-03],\n",
            "          [-3.7565e-02,  1.9079e-02, -4.2723e-02],\n",
            "          [-4.0482e-02, -1.6124e-02,  2.3614e-02]],\n",
            "\n",
            "         [[-1.4701e-02, -1.8024e-02,  6.4676e-02],\n",
            "          [-4.4285e-02, -5.6837e-02, -2.2810e-02],\n",
            "          [-1.6795e-02, -1.4620e-03, -3.0532e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3792e-02,  1.3065e-02,  3.5286e-02],\n",
            "          [-4.8995e-02, -7.7605e-03, -1.6198e-02],\n",
            "          [-4.0200e-02, -2.0337e-03,  5.1502e-04]],\n",
            "\n",
            "         [[ 2.7279e-03,  4.0213e-02, -2.7145e-02],\n",
            "          [-1.7334e-02,  3.6952e-04,  7.1956e-03],\n",
            "          [-2.6340e-02,  1.3979e-02,  3.9511e-02]],\n",
            "\n",
            "         [[ 1.0842e-02, -1.5908e-02, -4.6484e-02],\n",
            "          [ 4.5240e-04,  3.8241e-04, -3.6206e-02],\n",
            "          [-3.5801e-02,  1.5203e-02, -1.7612e-02]]]])), ('module.encoder_k.layer3.5.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer3.5.conv3.weight', tensor([[[[-0.0345]],\n",
            "\n",
            "         [[ 0.0133]],\n",
            "\n",
            "         [[-0.0003]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0130]],\n",
            "\n",
            "         [[-0.0922]],\n",
            "\n",
            "         [[-0.0202]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0217]],\n",
            "\n",
            "         [[ 0.0492]],\n",
            "\n",
            "         [[ 0.0692]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0034]],\n",
            "\n",
            "         [[-0.0288]],\n",
            "\n",
            "         [[-0.0011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0283]],\n",
            "\n",
            "         [[-0.0106]],\n",
            "\n",
            "         [[-0.0659]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0403]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.0135]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0396]],\n",
            "\n",
            "         [[ 0.0737]],\n",
            "\n",
            "         [[ 0.0505]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[ 0.0138]],\n",
            "\n",
            "         [[-0.0799]]],\n",
            "\n",
            "\n",
            "        [[[-0.0458]],\n",
            "\n",
            "         [[-0.0399]],\n",
            "\n",
            "         [[ 0.0443]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0192]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[ 0.0061]]],\n",
            "\n",
            "\n",
            "        [[[-0.0401]],\n",
            "\n",
            "         [[ 0.0034]],\n",
            "\n",
            "         [[ 0.0205]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0270]],\n",
            "\n",
            "         [[ 0.0619]],\n",
            "\n",
            "         [[ 0.0519]]]])), ('module.encoder_k.layer3.5.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer3.5.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer3.5.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.0.conv1.weight', tensor([[[[ 0.0840]],\n",
            "\n",
            "         [[-0.0026]],\n",
            "\n",
            "         [[ 0.0714]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1042]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         [[ 0.0499]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1154]],\n",
            "\n",
            "         [[ 0.0465]],\n",
            "\n",
            "         [[-0.0511]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         [[ 0.0704]],\n",
            "\n",
            "         [[-0.0620]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1430]],\n",
            "\n",
            "         [[-0.0147]],\n",
            "\n",
            "         [[ 0.0401]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0937]],\n",
            "\n",
            "         [[-0.0057]],\n",
            "\n",
            "         [[ 0.0867]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0336]],\n",
            "\n",
            "         [[ 0.1140]],\n",
            "\n",
            "         [[-0.0714]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0301]],\n",
            "\n",
            "         [[ 0.1395]],\n",
            "\n",
            "         [[ 0.0135]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0646]],\n",
            "\n",
            "         [[-0.1104]],\n",
            "\n",
            "         [[ 0.0441]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.1529]],\n",
            "\n",
            "         [[ 0.0207]],\n",
            "\n",
            "         [[-0.0339]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0903]],\n",
            "\n",
            "         [[-0.0557]],\n",
            "\n",
            "         [[-0.0779]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0726]],\n",
            "\n",
            "         [[ 0.0023]],\n",
            "\n",
            "         [[ 0.0010]]]])), ('module.encoder_k.layer4.0.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.0.conv2.weight', tensor([[[[ 6.5585e-03, -3.2748e-02,  1.4668e-02],\n",
            "          [ 2.2598e-02, -9.6221e-03, -1.6693e-02],\n",
            "          [ 3.8255e-02, -1.7218e-02,  4.2272e-03]],\n",
            "\n",
            "         [[ 1.4050e-02, -2.0900e-03, -2.1188e-03],\n",
            "          [ 6.9391e-03, -1.4407e-02, -6.0526e-03],\n",
            "          [-2.6982e-02,  8.1345e-03, -3.1335e-02]],\n",
            "\n",
            "         [[-8.4789e-03,  9.3633e-03, -3.0524e-02],\n",
            "          [ 8.5017e-03, -3.8445e-02,  5.5057e-03],\n",
            "          [ 2.6320e-02, -5.3213e-02, -1.8361e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.2976e-04,  1.1157e-03, -1.9025e-02],\n",
            "          [ 3.6225e-03,  1.9838e-02,  1.0335e-04],\n",
            "          [-1.9048e-02, -3.8563e-02,  1.9773e-02]],\n",
            "\n",
            "         [[ 9.7245e-03,  8.0973e-03,  2.8868e-02],\n",
            "          [ 8.7752e-04, -3.4818e-02, -1.2328e-02],\n",
            "          [ 1.3617e-02,  1.6038e-02, -3.6396e-02]],\n",
            "\n",
            "         [[-9.6424e-03, -1.6470e-03,  3.7932e-03],\n",
            "          [-9.1329e-04,  3.1398e-02, -2.9201e-02],\n",
            "          [ 2.1374e-02, -2.9768e-02, -9.4264e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2604e-02, -2.9150e-02,  4.5612e-02],\n",
            "          [ 5.2425e-03, -2.1961e-02, -2.1806e-03],\n",
            "          [ 2.8476e-02, -2.0675e-02,  1.5138e-02]],\n",
            "\n",
            "         [[ 1.5065e-02, -2.2665e-03,  2.0867e-02],\n",
            "          [ 4.6234e-03,  2.4643e-03, -8.6775e-04],\n",
            "          [-1.1015e-02, -2.7199e-02,  1.9833e-02]],\n",
            "\n",
            "         [[ 1.6576e-02, -8.4360e-03,  2.3408e-02],\n",
            "          [ 3.6334e-03, -2.4203e-02, -1.6086e-02],\n",
            "          [ 1.2978e-02,  6.4331e-03, -1.8426e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.4435e-02, -3.3955e-02,  5.9870e-03],\n",
            "          [-3.2614e-02,  4.3992e-03, -1.5491e-02],\n",
            "          [ 9.7659e-03, -3.1873e-03, -4.1006e-02]],\n",
            "\n",
            "         [[-5.1243e-03,  1.1752e-02,  1.5294e-02],\n",
            "          [-1.2933e-02, -2.0291e-02,  4.8796e-03],\n",
            "          [-2.8228e-02,  3.1144e-03,  4.8573e-02]],\n",
            "\n",
            "         [[-3.9237e-02, -1.8004e-02,  1.8811e-02],\n",
            "          [-1.2395e-02,  5.9403e-03, -3.6181e-03],\n",
            "          [ 3.6783e-02,  1.7589e-03, -3.2825e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.8778e-03, -7.3901e-03,  6.1089e-03],\n",
            "          [ 3.7169e-02,  6.9986e-03,  2.0635e-02],\n",
            "          [-2.6032e-02, -7.9848e-03, -3.8109e-02]],\n",
            "\n",
            "         [[ 2.1097e-02, -2.7189e-02, -1.8741e-03],\n",
            "          [ 1.9571e-02,  1.9764e-02,  2.7685e-03],\n",
            "          [-2.3287e-02, -1.5894e-02,  4.9156e-03]],\n",
            "\n",
            "         [[ 1.0963e-03,  2.8113e-02,  7.4703e-03],\n",
            "          [-1.4931e-02, -1.3069e-02,  3.8060e-02],\n",
            "          [-4.5288e-02,  2.6818e-03,  1.1763e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.2792e-03,  6.4174e-03, -2.1990e-02],\n",
            "          [-6.9425e-03, -1.6088e-02,  8.9639e-03],\n",
            "          [-5.3009e-03, -5.2146e-03,  1.8017e-02]],\n",
            "\n",
            "         [[-3.7953e-02,  2.2104e-03,  9.5364e-03],\n",
            "          [ 8.5368e-04, -1.2426e-03, -8.1243e-03],\n",
            "          [ 4.1929e-02,  4.7146e-03,  2.0462e-02]],\n",
            "\n",
            "         [[ 2.0886e-02, -8.3334e-03, -8.3462e-03],\n",
            "          [-1.1562e-02, -8.2201e-03,  4.7284e-03],\n",
            "          [ 4.9911e-03,  5.5469e-03,  7.3941e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.3924e-02, -1.3986e-02, -1.1217e-02],\n",
            "          [ 3.1803e-02,  4.5202e-02,  2.6818e-02],\n",
            "          [-4.4075e-02,  2.4556e-02,  1.3719e-02]],\n",
            "\n",
            "         [[-6.9594e-03, -1.0092e-03, -5.3897e-02],\n",
            "          [ 8.2898e-03, -3.5543e-02,  4.9238e-03],\n",
            "          [ 1.3407e-03, -3.7284e-03, -6.5214e-03]],\n",
            "\n",
            "         [[-1.3087e-02,  1.2744e-03,  7.0806e-03],\n",
            "          [ 7.1695e-03,  1.7984e-02,  5.7473e-06],\n",
            "          [-9.0714e-03, -2.1370e-03, -1.3192e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8769e-02, -1.3857e-02,  3.1347e-03],\n",
            "          [ 2.5172e-03, -5.9059e-05,  1.7332e-02],\n",
            "          [ 2.4516e-02,  1.2461e-02,  1.0119e-02]],\n",
            "\n",
            "         [[-1.7007e-02, -7.7989e-04,  3.1556e-02],\n",
            "          [-7.7296e-03,  2.2028e-02, -2.9343e-02],\n",
            "          [-6.1727e-04, -2.2441e-02,  1.9114e-02]],\n",
            "\n",
            "         [[-2.0412e-04, -3.8693e-02, -5.2298e-03],\n",
            "          [-1.0716e-02,  1.3632e-02,  2.1280e-02],\n",
            "          [-2.5349e-03, -3.3848e-03,  1.6969e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.6080e-02,  1.8601e-02, -4.5164e-02],\n",
            "          [-1.3685e-02, -5.2854e-04, -1.3513e-02],\n",
            "          [ 1.2640e-02,  1.5251e-02, -2.5658e-02]],\n",
            "\n",
            "         [[-9.8698e-03,  2.8484e-02,  7.6270e-03],\n",
            "          [ 6.5307e-03,  1.8197e-02, -1.1473e-02],\n",
            "          [ 2.1544e-02, -1.0207e-02,  1.6369e-02]],\n",
            "\n",
            "         [[-2.0815e-02, -2.9778e-02,  5.2350e-03],\n",
            "          [-1.4085e-02,  2.0180e-02, -2.0708e-02],\n",
            "          [-7.8979e-03,  5.5252e-03, -2.2205e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2889e-02, -5.2528e-03, -1.1750e-02],\n",
            "          [-1.3108e-03,  8.1215e-03, -1.9652e-02],\n",
            "          [-7.2737e-03,  1.7644e-02, -1.7358e-02]],\n",
            "\n",
            "         [[-3.1226e-02, -2.3212e-04,  1.6040e-02],\n",
            "          [-4.0378e-02,  4.3791e-03, -9.0051e-03],\n",
            "          [-9.3602e-03, -3.6968e-02, -1.3541e-02]],\n",
            "\n",
            "         [[-1.5561e-02, -2.0917e-02,  8.8536e-03],\n",
            "          [-3.3578e-02,  1.1117e-02, -1.0509e-02],\n",
            "          [-5.2379e-03, -6.5119e-03, -1.2110e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.2155e-02, -1.4971e-02,  8.9321e-03],\n",
            "          [-4.2680e-02,  5.3592e-03,  7.9697e-03],\n",
            "          [-1.0014e-02, -1.8525e-02,  8.7852e-04]],\n",
            "\n",
            "         [[ 4.1528e-02, -6.1444e-04,  4.6572e-02],\n",
            "          [-1.8386e-02, -2.4102e-02, -6.7021e-03],\n",
            "          [ 1.2595e-02, -1.9719e-02, -2.6093e-02]],\n",
            "\n",
            "         [[ 1.2358e-02, -7.2542e-02, -4.5360e-03],\n",
            "          [ 2.1530e-02,  1.7947e-02, -2.6980e-02],\n",
            "          [-7.2753e-05,  2.8378e-03, -1.0552e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.7559e-03,  1.4703e-02,  2.1935e-02],\n",
            "          [-1.1185e-02, -3.1418e-02, -2.4522e-03],\n",
            "          [ 1.8595e-02,  2.2634e-03, -6.7254e-03]],\n",
            "\n",
            "         [[-3.7949e-02,  3.5406e-02,  4.2613e-03],\n",
            "          [ 3.7572e-03, -2.4697e-03,  1.1840e-03],\n",
            "          [-2.8383e-02, -8.3262e-03, -4.7166e-03]],\n",
            "\n",
            "         [[ 3.1577e-03,  4.5717e-02,  2.8721e-02],\n",
            "          [ 3.8448e-04,  3.3520e-02,  2.2737e-02],\n",
            "          [-1.3515e-02, -3.2723e-02,  1.1897e-02]]]])), ('module.encoder_k.layer4.0.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.0.conv3.weight', tensor([[[[ 0.0418]],\n",
            "\n",
            "         [[-0.0500]],\n",
            "\n",
            "         [[ 0.0070]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0754]],\n",
            "\n",
            "         [[ 0.0114]],\n",
            "\n",
            "         [[-0.0376]]],\n",
            "\n",
            "\n",
            "        [[[-0.0601]],\n",
            "\n",
            "         [[-0.0061]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0101]],\n",
            "\n",
            "         [[-0.0408]],\n",
            "\n",
            "         [[-0.0297]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0108]],\n",
            "\n",
            "         [[-0.0137]],\n",
            "\n",
            "         [[-0.0062]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299]],\n",
            "\n",
            "         [[ 0.0403]],\n",
            "\n",
            "         [[ 0.0407]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0107]],\n",
            "\n",
            "         [[-0.0451]],\n",
            "\n",
            "         [[-0.0189]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0032]],\n",
            "\n",
            "         [[-0.0014]],\n",
            "\n",
            "         [[ 0.0116]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0093]],\n",
            "\n",
            "         [[ 0.0097]],\n",
            "\n",
            "         [[ 0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0715]],\n",
            "\n",
            "         [[-0.0019]],\n",
            "\n",
            "         [[ 0.0420]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295]],\n",
            "\n",
            "         [[-0.0347]],\n",
            "\n",
            "         [[ 0.0564]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0428]],\n",
            "\n",
            "         [[-0.0206]],\n",
            "\n",
            "         [[-0.0400]]]])), ('module.encoder_k.layer4.0.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.0.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.0.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.0.downsample.0.weight', tensor([[[[ 0.0240]],\n",
            "\n",
            "         [[-0.0141]],\n",
            "\n",
            "         [[-0.0311]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0036]],\n",
            "\n",
            "         [[-0.0349]],\n",
            "\n",
            "         [[ 0.0338]]],\n",
            "\n",
            "\n",
            "        [[[-0.0387]],\n",
            "\n",
            "         [[ 0.0074]],\n",
            "\n",
            "         [[-0.0292]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0191]],\n",
            "\n",
            "         [[-0.0171]],\n",
            "\n",
            "         [[ 0.0069]]],\n",
            "\n",
            "\n",
            "        [[[-0.0112]],\n",
            "\n",
            "         [[-0.0184]],\n",
            "\n",
            "         [[-0.0273]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0364]],\n",
            "\n",
            "         [[-0.0100]],\n",
            "\n",
            "         [[ 0.0402]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0193]],\n",
            "\n",
            "         [[ 0.0047]],\n",
            "\n",
            "         [[-0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0366]],\n",
            "\n",
            "         [[ 0.0290]],\n",
            "\n",
            "         [[-0.0057]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[ 0.0476]],\n",
            "\n",
            "         [[-0.0223]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0083]],\n",
            "\n",
            "         [[-0.0258]],\n",
            "\n",
            "         [[ 0.0263]]],\n",
            "\n",
            "\n",
            "        [[[-0.0365]],\n",
            "\n",
            "         [[-0.0131]],\n",
            "\n",
            "         [[ 0.0445]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0026]],\n",
            "\n",
            "         [[-0.0248]],\n",
            "\n",
            "         [[ 0.0026]]]])), ('module.encoder_k.layer4.0.downsample.1.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.0.downsample.1.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.0.downsample.1.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.0.downsample.1.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.0.downsample.1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.1.conv1.weight', tensor([[[[ 0.0951]],\n",
            "\n",
            "         [[ 0.1021]],\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0090]],\n",
            "\n",
            "         [[-0.0827]],\n",
            "\n",
            "         [[-0.1062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0229]],\n",
            "\n",
            "         [[-0.0817]],\n",
            "\n",
            "         [[-0.0741]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0466]],\n",
            "\n",
            "         [[ 0.0008]],\n",
            "\n",
            "         [[-0.0212]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0010]],\n",
            "\n",
            "         [[ 0.0578]],\n",
            "\n",
            "         [[ 0.0438]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         [[-0.0104]],\n",
            "\n",
            "         [[-0.0219]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0129]],\n",
            "\n",
            "         [[-0.0391]],\n",
            "\n",
            "         [[ 0.0391]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0363]],\n",
            "\n",
            "         [[-0.0317]],\n",
            "\n",
            "         [[-0.0484]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0240]],\n",
            "\n",
            "         [[ 0.0067]],\n",
            "\n",
            "         [[-0.0232]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0216]],\n",
            "\n",
            "         [[-0.0421]],\n",
            "\n",
            "         [[-0.0655]]],\n",
            "\n",
            "\n",
            "        [[[-0.0347]],\n",
            "\n",
            "         [[ 0.0098]],\n",
            "\n",
            "         [[ 0.0200]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0417]],\n",
            "\n",
            "         [[ 0.0411]],\n",
            "\n",
            "         [[-0.0480]]]])), ('module.encoder_k.layer4.1.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.1.conv2.weight', tensor([[[[-7.3814e-03, -1.6185e-03,  4.1269e-02],\n",
            "          [-3.4813e-04, -6.5095e-03, -8.9302e-03],\n",
            "          [-2.0391e-02,  6.4274e-03, -4.2294e-03]],\n",
            "\n",
            "         [[-1.7317e-02, -2.8197e-02, -3.4322e-02],\n",
            "          [-2.8817e-02, -3.6634e-03,  1.6631e-02],\n",
            "          [-6.0894e-02,  2.3477e-02,  9.4727e-03]],\n",
            "\n",
            "         [[ 1.5811e-02, -5.5481e-03,  8.6242e-03],\n",
            "          [-2.8544e-03,  1.7761e-02, -1.2966e-02],\n",
            "          [-1.5290e-02, -1.6547e-02, -1.0916e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4917e-02, -3.5584e-02,  7.1230e-03],\n",
            "          [ 1.4633e-02,  1.2499e-03,  9.4763e-03],\n",
            "          [-1.5858e-02, -1.4865e-02, -5.3695e-03]],\n",
            "\n",
            "         [[-2.1831e-02,  2.2923e-02,  2.3531e-02],\n",
            "          [-2.7302e-03,  1.0418e-02, -1.3314e-02],\n",
            "          [ 2.9128e-03, -1.1342e-02, -4.1396e-03]],\n",
            "\n",
            "         [[-1.9575e-02, -1.3802e-02, -3.6632e-02],\n",
            "          [-1.5000e-02, -1.3952e-02,  3.3575e-02],\n",
            "          [ 3.6460e-02, -3.3979e-02,  1.3541e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.1492e-02, -3.7352e-04,  3.1189e-02],\n",
            "          [-3.9138e-02, -1.3486e-02,  2.5266e-02],\n",
            "          [-2.4664e-02,  2.6599e-02, -1.6492e-02]],\n",
            "\n",
            "         [[ 2.7748e-02,  1.4629e-02,  1.2743e-02],\n",
            "          [ 9.3989e-03, -5.6655e-03, -6.9773e-03],\n",
            "          [-4.7968e-03, -1.7719e-02, -2.5712e-02]],\n",
            "\n",
            "         [[ 3.0530e-02, -7.2237e-03,  2.6349e-02],\n",
            "          [ 1.2789e-02,  1.2519e-02,  3.7331e-02],\n",
            "          [ 3.5956e-02, -2.0166e-03,  4.1376e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.1789e-02,  1.4381e-02, -1.8169e-02],\n",
            "          [-1.8865e-02,  8.9827e-03,  8.8650e-03],\n",
            "          [ 1.5344e-02, -4.2490e-02, -2.6014e-03]],\n",
            "\n",
            "         [[-1.5715e-02,  7.7178e-03, -2.4319e-02],\n",
            "          [-1.0312e-02,  1.1892e-03,  6.0195e-03],\n",
            "          [ 6.2908e-03,  1.7201e-02,  9.1106e-03]],\n",
            "\n",
            "         [[-1.6010e-03,  3.1782e-02, -2.2814e-02],\n",
            "          [-1.2059e-02,  8.3228e-04, -1.9418e-02],\n",
            "          [-4.0015e-02,  1.9597e-02, -2.1821e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.7584e-02,  2.6464e-02, -2.3271e-03],\n",
            "          [-3.9331e-03,  2.9278e-02,  1.4493e-02],\n",
            "          [ 1.8865e-02,  3.2255e-02,  1.8295e-02]],\n",
            "\n",
            "         [[ 8.7632e-04,  2.9559e-02, -1.0432e-02],\n",
            "          [-1.9121e-02,  2.7266e-02, -3.4690e-02],\n",
            "          [-4.1126e-02, -1.2117e-02,  3.9537e-02]],\n",
            "\n",
            "         [[-1.8303e-02,  3.3266e-03,  2.6360e-03],\n",
            "          [-7.3329e-03,  1.2197e-02,  1.9004e-02],\n",
            "          [-5.2972e-03,  3.2684e-02, -1.8616e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1077e-03,  3.3310e-03, -4.1052e-02],\n",
            "          [-2.6801e-02, -5.9275e-03,  2.6260e-02],\n",
            "          [-3.3463e-02, -2.8397e-02,  1.0909e-02]],\n",
            "\n",
            "         [[ 4.9467e-02,  9.3187e-03, -1.3890e-02],\n",
            "          [ 1.2055e-02, -2.3214e-02,  5.7277e-03],\n",
            "          [ 3.1605e-02, -5.0976e-05, -3.9619e-02]],\n",
            "\n",
            "         [[ 3.2946e-02,  2.1702e-02,  2.4688e-03],\n",
            "          [ 2.9190e-03, -3.6701e-04,  2.5533e-04],\n",
            "          [ 2.3168e-02,  1.4762e-02, -6.1189e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.8243e-02, -8.6041e-03, -2.8301e-02],\n",
            "          [ 5.3847e-04,  3.2997e-02, -1.9101e-03],\n",
            "          [-4.0163e-02,  3.0870e-02, -6.9938e-03]],\n",
            "\n",
            "         [[-5.6154e-03, -1.8680e-02,  2.4065e-02],\n",
            "          [ 2.2318e-02, -1.4281e-03,  4.5899e-02],\n",
            "          [-2.5011e-03, -6.5530e-03,  2.3204e-02]],\n",
            "\n",
            "         [[-1.5518e-02,  1.7247e-03,  2.7762e-02],\n",
            "          [-1.4071e-02, -3.1900e-02,  2.0102e-03],\n",
            "          [ 6.6558e-03,  1.2910e-02,  1.1491e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.0742e-02,  1.0239e-02,  1.6182e-03],\n",
            "          [ 5.8820e-03,  1.4353e-02, -5.8836e-03],\n",
            "          [ 1.3609e-02,  2.0870e-02, -5.4176e-03]],\n",
            "\n",
            "         [[ 1.8857e-03, -3.8026e-03,  1.0044e-02],\n",
            "          [ 1.7379e-03,  3.5733e-03, -1.9635e-02],\n",
            "          [ 3.9499e-03, -1.2560e-02,  7.0899e-03]],\n",
            "\n",
            "         [[ 1.4400e-02, -1.6410e-02,  1.1526e-03],\n",
            "          [ 3.7114e-03, -2.4402e-02, -2.0224e-02],\n",
            "          [ 1.0286e-02,  1.3683e-02, -3.6651e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9415e-03,  9.3087e-03,  1.2978e-02],\n",
            "          [ 1.1848e-02, -1.6089e-03,  9.8278e-03],\n",
            "          [ 1.0717e-02, -2.1980e-02,  3.2408e-02]],\n",
            "\n",
            "         [[ 2.4709e-02, -7.7980e-03,  3.6737e-02],\n",
            "          [-1.2486e-03,  1.3969e-02, -1.2195e-02],\n",
            "          [ 8.6391e-03,  2.7633e-02,  1.1783e-02]],\n",
            "\n",
            "         [[ 9.3668e-03, -1.5184e-02, -1.3857e-02],\n",
            "          [ 1.5560e-02,  3.9109e-02, -1.0901e-02],\n",
            "          [-4.3304e-04,  2.0903e-02, -1.3750e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.9821e-02, -9.4683e-03, -5.5842e-03],\n",
            "          [ 1.2902e-02, -1.8058e-02,  1.0444e-02],\n",
            "          [ 6.8827e-03, -2.0821e-02, -1.1689e-02]],\n",
            "\n",
            "         [[ 9.3320e-03, -1.5785e-02, -3.4661e-02],\n",
            "          [-5.5720e-02, -1.5326e-02, -2.7506e-02],\n",
            "          [ 6.0891e-03, -3.2175e-02,  2.8354e-02]],\n",
            "\n",
            "         [[ 3.4392e-03, -1.2277e-02, -3.2340e-02],\n",
            "          [-6.5083e-04,  4.0298e-02,  6.7452e-03],\n",
            "          [ 1.0148e-02,  1.0345e-02, -6.6034e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 3.0150e-02,  2.2810e-02, -2.0671e-03],\n",
            "          [-3.9005e-02,  1.3107e-02,  3.3569e-03],\n",
            "          [ 1.6399e-02, -7.4265e-03, -6.2866e-03]],\n",
            "\n",
            "         [[ 1.4259e-02,  4.2510e-02,  6.4062e-03],\n",
            "          [-1.6002e-02, -2.5729e-02, -4.1847e-02],\n",
            "          [-1.5609e-03,  6.8361e-03, -2.9198e-02]],\n",
            "\n",
            "         [[ 2.5413e-02, -2.7298e-02,  1.9589e-02],\n",
            "          [-8.4087e-03, -8.7112e-03, -9.8301e-03],\n",
            "          [-2.5651e-02,  2.4844e-03, -8.6954e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8682e-02,  1.9608e-02, -2.1790e-02],\n",
            "          [-4.5122e-02, -3.1113e-02, -4.1028e-02],\n",
            "          [ 6.6815e-03, -1.4416e-02, -5.6779e-02]],\n",
            "\n",
            "         [[ 1.3445e-02,  1.5687e-02,  3.0581e-03],\n",
            "          [-7.7190e-03, -3.9109e-02,  4.0275e-02],\n",
            "          [-3.0644e-03, -3.8116e-02,  1.3374e-02]],\n",
            "\n",
            "         [[-3.9553e-02, -6.8817e-03,  4.8256e-02],\n",
            "          [-2.0112e-02, -1.3887e-02, -2.6608e-02],\n",
            "          [ 2.8581e-02,  1.5040e-02,  1.3006e-02]]]])), ('module.encoder_k.layer4.1.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.1.conv3.weight', tensor([[[[-0.0004]],\n",
            "\n",
            "         [[-0.0085]],\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152]],\n",
            "\n",
            "         [[-0.0393]],\n",
            "\n",
            "         [[ 0.0093]]],\n",
            "\n",
            "\n",
            "        [[[-0.0329]],\n",
            "\n",
            "         [[ 0.0480]],\n",
            "\n",
            "         [[-0.0115]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0094]],\n",
            "\n",
            "         [[-0.0045]],\n",
            "\n",
            "         [[-0.0413]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0245]],\n",
            "\n",
            "         [[-0.0070]],\n",
            "\n",
            "         [[ 0.0283]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0239]],\n",
            "\n",
            "         [[ 0.0085]],\n",
            "\n",
            "         [[ 0.0109]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0085]],\n",
            "\n",
            "         [[ 0.0196]],\n",
            "\n",
            "         [[-0.0204]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0417]],\n",
            "\n",
            "         [[-0.0248]],\n",
            "\n",
            "         [[-0.0273]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0067]],\n",
            "\n",
            "         [[ 0.0250]],\n",
            "\n",
            "         [[ 0.0365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221]],\n",
            "\n",
            "         [[ 0.0444]],\n",
            "\n",
            "         [[ 0.0047]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0098]],\n",
            "\n",
            "         [[-0.0702]],\n",
            "\n",
            "         [[ 0.0077]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0256]],\n",
            "\n",
            "         [[-0.0266]],\n",
            "\n",
            "         [[-0.0424]]]])), ('module.encoder_k.layer4.1.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.1.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.1.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.2.conv1.weight', tensor([[[[ 0.1153]],\n",
            "\n",
            "         [[ 0.0825]],\n",
            "\n",
            "         [[-0.0131]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0117]],\n",
            "\n",
            "         [[-0.0547]],\n",
            "\n",
            "         [[ 0.0557]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0194]],\n",
            "\n",
            "         [[ 0.0795]],\n",
            "\n",
            "         [[-0.0266]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0044]],\n",
            "\n",
            "         [[ 0.0511]],\n",
            "\n",
            "         [[-0.0564]]],\n",
            "\n",
            "\n",
            "        [[[-0.0736]],\n",
            "\n",
            "         [[-0.0221]],\n",
            "\n",
            "         [[ 0.0939]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0190]],\n",
            "\n",
            "         [[ 0.0300]],\n",
            "\n",
            "         [[-0.1061]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0377]],\n",
            "\n",
            "         [[ 0.0640]],\n",
            "\n",
            "         [[-0.0344]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0970]],\n",
            "\n",
            "         [[ 0.0518]],\n",
            "\n",
            "         [[ 0.0572]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0218]],\n",
            "\n",
            "         [[ 0.0071]],\n",
            "\n",
            "         [[-0.0213]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0385]],\n",
            "\n",
            "         [[ 0.0416]],\n",
            "\n",
            "         [[ 0.0302]]],\n",
            "\n",
            "\n",
            "        [[[-0.0708]],\n",
            "\n",
            "         [[ 0.0136]],\n",
            "\n",
            "         [[-0.0095]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0462]],\n",
            "\n",
            "         [[ 0.0313]],\n",
            "\n",
            "         [[-0.0069]]]])), ('module.encoder_k.layer4.2.bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn1.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.2.conv2.weight', tensor([[[[ 0.0198, -0.0144, -0.0280],\n",
            "          [-0.0083,  0.0060,  0.0126],\n",
            "          [ 0.0387,  0.0154,  0.0037]],\n",
            "\n",
            "         [[-0.0123, -0.0223, -0.0089],\n",
            "          [-0.0496, -0.0540, -0.0110],\n",
            "          [-0.0109,  0.0283, -0.0093]],\n",
            "\n",
            "         [[ 0.0273, -0.0269,  0.0045],\n",
            "          [-0.0064, -0.0310,  0.0015],\n",
            "          [ 0.0408, -0.0158, -0.0171]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0319, -0.0090,  0.0173],\n",
            "          [ 0.0236, -0.0102, -0.0111],\n",
            "          [ 0.0154,  0.0089, -0.0134]],\n",
            "\n",
            "         [[ 0.0055,  0.0201, -0.0339],\n",
            "          [ 0.0214,  0.0113, -0.0058],\n",
            "          [-0.0055,  0.0187,  0.0171]],\n",
            "\n",
            "         [[-0.0101, -0.0113,  0.0033],\n",
            "          [ 0.0262,  0.0064,  0.0201],\n",
            "          [ 0.0099, -0.0223,  0.0605]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0004, -0.0221, -0.0226],\n",
            "          [ 0.0304, -0.0093, -0.0220],\n",
            "          [-0.0012, -0.0492,  0.0036]],\n",
            "\n",
            "         [[-0.0018, -0.0071, -0.0181],\n",
            "          [ 0.0116, -0.0282, -0.0052],\n",
            "          [-0.0198, -0.0203, -0.0014]],\n",
            "\n",
            "         [[-0.0066, -0.0061,  0.0030],\n",
            "          [-0.0434, -0.0013, -0.0249],\n",
            "          [ 0.0138, -0.0082, -0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0004,  0.0087,  0.0178],\n",
            "          [ 0.0046, -0.0325,  0.0149],\n",
            "          [ 0.0308, -0.0171,  0.0033]],\n",
            "\n",
            "         [[-0.0233, -0.0115, -0.0232],\n",
            "          [-0.0117, -0.0149, -0.0089],\n",
            "          [ 0.0117,  0.0358, -0.0034]],\n",
            "\n",
            "         [[-0.0501, -0.0036, -0.0037],\n",
            "          [ 0.0398,  0.0110,  0.0049],\n",
            "          [ 0.0089,  0.0308, -0.0197]]],\n",
            "\n",
            "\n",
            "        [[[-0.0228,  0.0103, -0.0156],\n",
            "          [ 0.0145,  0.0077, -0.0412],\n",
            "          [-0.0144,  0.0323,  0.0099]],\n",
            "\n",
            "         [[-0.0014, -0.0085, -0.0130],\n",
            "          [-0.0094,  0.0098, -0.0002],\n",
            "          [ 0.0255, -0.0489, -0.0073]],\n",
            "\n",
            "         [[ 0.0168,  0.0053,  0.0306],\n",
            "          [ 0.0147, -0.0221, -0.0315],\n",
            "          [-0.0107, -0.0093,  0.0215]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0024, -0.0573, -0.0021],\n",
            "          [ 0.0184,  0.0126,  0.0228],\n",
            "          [-0.0049,  0.0235, -0.0148]],\n",
            "\n",
            "         [[-0.0297, -0.0136, -0.0271],\n",
            "          [-0.0154,  0.0025,  0.0271],\n",
            "          [-0.0014,  0.0277, -0.0272]],\n",
            "\n",
            "         [[ 0.0256, -0.0128,  0.0199],\n",
            "          [-0.0202,  0.0083,  0.0363],\n",
            "          [-0.0100, -0.0069, -0.0107]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0027, -0.0139,  0.0074],\n",
            "          [-0.0159, -0.0197, -0.0303],\n",
            "          [ 0.0058,  0.0348,  0.0143]],\n",
            "\n",
            "         [[-0.0127, -0.0087,  0.0287],\n",
            "          [-0.0010, -0.0099,  0.0137],\n",
            "          [ 0.0016,  0.0311, -0.0080]],\n",
            "\n",
            "         [[-0.0220,  0.0131, -0.0088],\n",
            "          [-0.0260,  0.0568,  0.0581],\n",
            "          [-0.0286, -0.0034,  0.0127]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0213, -0.0386,  0.0412],\n",
            "          [ 0.0181,  0.0101, -0.0074],\n",
            "          [-0.0118, -0.0215,  0.0303]],\n",
            "\n",
            "         [[-0.0170, -0.0038,  0.0018],\n",
            "          [ 0.0003, -0.0133,  0.0429],\n",
            "          [ 0.0085,  0.0146, -0.0261]],\n",
            "\n",
            "         [[ 0.0006, -0.0192, -0.0245],\n",
            "          [ 0.0234,  0.0092,  0.0546],\n",
            "          [-0.0278,  0.0069,  0.0308]]],\n",
            "\n",
            "\n",
            "        [[[-0.0231, -0.0050,  0.0123],\n",
            "          [-0.0045, -0.0221,  0.0097],\n",
            "          [-0.0267, -0.0306,  0.0314]],\n",
            "\n",
            "         [[-0.0439, -0.0237,  0.0148],\n",
            "          [-0.0164, -0.0367, -0.0075],\n",
            "          [ 0.0219,  0.0066,  0.0170]],\n",
            "\n",
            "         [[-0.0211,  0.0015,  0.0091],\n",
            "          [-0.0029,  0.0032, -0.0607],\n",
            "          [-0.0018, -0.0084,  0.0017]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0112, -0.0396, -0.0138],\n",
            "          [-0.0106,  0.0051,  0.0133],\n",
            "          [-0.0034, -0.0034,  0.0126]],\n",
            "\n",
            "         [[-0.0026,  0.0196,  0.0100],\n",
            "          [ 0.0327, -0.0248, -0.0230],\n",
            "          [-0.0145, -0.0203,  0.0136]],\n",
            "\n",
            "         [[ 0.0225, -0.0001, -0.0105],\n",
            "          [ 0.0244,  0.0028,  0.0009],\n",
            "          [ 0.0104,  0.0341, -0.0064]]],\n",
            "\n",
            "\n",
            "        [[[-0.0085,  0.0118,  0.0018],\n",
            "          [-0.0175, -0.0206,  0.0113],\n",
            "          [ 0.0007,  0.0072,  0.0180]],\n",
            "\n",
            "         [[-0.0081, -0.0136, -0.0261],\n",
            "          [-0.0063, -0.0119, -0.0099],\n",
            "          [ 0.0010,  0.0366, -0.0021]],\n",
            "\n",
            "         [[ 0.0268,  0.0007,  0.0016],\n",
            "          [ 0.0138, -0.0101, -0.0098],\n",
            "          [ 0.0419, -0.0491,  0.0006]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0308,  0.0002,  0.0265],\n",
            "          [-0.0022,  0.0268,  0.0387],\n",
            "          [ 0.0033,  0.0021,  0.0031]],\n",
            "\n",
            "         [[-0.0165, -0.0078, -0.0187],\n",
            "          [ 0.0084, -0.0122,  0.0170],\n",
            "          [ 0.0002,  0.0452, -0.0151]],\n",
            "\n",
            "         [[ 0.0156,  0.0026,  0.0126],\n",
            "          [ 0.0165, -0.0126, -0.0112],\n",
            "          [ 0.0076,  0.0259,  0.0252]]]])), ('module.encoder_k.layer4.2.bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 1., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn2.num_batches_tracked', tensor(0)), ('module.encoder_k.layer4.2.conv3.weight', tensor([[[[ 0.0252]],\n",
            "\n",
            "         [[-0.0268]],\n",
            "\n",
            "         [[-0.0158]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0273]],\n",
            "\n",
            "         [[-0.0331]],\n",
            "\n",
            "         [[ 0.0271]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243]],\n",
            "\n",
            "         [[ 0.0089]],\n",
            "\n",
            "         [[-0.0130]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0416]],\n",
            "\n",
            "         [[-0.0473]],\n",
            "\n",
            "         [[ 0.0464]]],\n",
            "\n",
            "\n",
            "        [[[-0.0072]],\n",
            "\n",
            "         [[ 0.0607]],\n",
            "\n",
            "         [[ 0.0355]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0253]],\n",
            "\n",
            "         [[-0.0096]],\n",
            "\n",
            "         [[ 0.0302]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0282]],\n",
            "\n",
            "         [[ 0.0019]],\n",
            "\n",
            "         [[ 0.0621]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0351]],\n",
            "\n",
            "         [[ 0.0210]],\n",
            "\n",
            "         [[-0.0142]]],\n",
            "\n",
            "\n",
            "        [[[-0.0293]],\n",
            "\n",
            "         [[-0.0414]],\n",
            "\n",
            "         [[-0.0015]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0347]],\n",
            "\n",
            "         [[ 0.0024]],\n",
            "\n",
            "         [[-0.0062]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0828]],\n",
            "\n",
            "         [[ 0.0651]],\n",
            "\n",
            "         [[-0.0219]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0030]],\n",
            "\n",
            "         [[ 0.0163]],\n",
            "\n",
            "         [[ 0.0023]]]])), ('module.encoder_k.layer4.2.bn3.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn3.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn3.running_mean', tensor([0., 0., 0.,  ..., 0., 0., 0.])), ('module.encoder_k.layer4.2.bn3.running_var', tensor([1., 1., 1.,  ..., 1., 1., 1.])), ('module.encoder_k.layer4.2.bn3.num_batches_tracked', tensor(0)), ('module.encoder_k.fc.weight', tensor([[-0.0081,  0.0063,  0.0161,  ..., -0.0020, -0.0093,  0.0168],\n",
            "        [ 0.0048,  0.0026,  0.0047,  ...,  0.0117, -0.0106, -0.0206],\n",
            "        [ 0.0209,  0.0199,  0.0157,  ..., -0.0144,  0.0018,  0.0043],\n",
            "        ...,\n",
            "        [ 0.0198, -0.0134,  0.0195,  ...,  0.0024,  0.0092, -0.0167],\n",
            "        [ 0.0014,  0.0007, -0.0198,  ..., -0.0160, -0.0062,  0.0201],\n",
            "        [ 0.0105, -0.0088, -0.0184,  ..., -0.0037, -0.0045, -0.0127]])), ('module.encoder_k.fc.bias', tensor([-1.8850e-02, -1.2881e-02, -1.8548e-02,  5.2929e-03, -4.2578e-04,\n",
            "         6.2410e-03, -6.0432e-03, -1.7987e-02,  5.2036e-03,  1.7101e-02,\n",
            "        -1.0713e-03,  1.5382e-02,  1.4721e-02,  1.9232e-02,  7.8328e-03,\n",
            "        -1.1483e-02,  1.4599e-02, -7.4539e-03, -9.3652e-03,  3.1690e-03,\n",
            "        -1.5743e-02,  8.5620e-03, -4.1524e-03, -1.3842e-02,  8.7397e-03,\n",
            "        -1.2668e-02,  4.7690e-03,  1.5000e-02,  1.2169e-03, -1.2670e-02,\n",
            "        -1.7457e-02,  2.0774e-02,  1.1249e-02, -6.5765e-03,  1.0404e-02,\n",
            "        -8.0480e-03, -1.0871e-02,  1.4320e-02,  5.5180e-03, -1.0175e-02,\n",
            "        -9.4095e-04, -2.1050e-02, -1.6231e-02, -3.2174e-03,  1.0916e-02,\n",
            "         7.4000e-04,  1.9413e-02,  4.0848e-03,  8.1386e-03, -1.3290e-02,\n",
            "         3.4723e-03, -1.8777e-02,  1.1552e-02,  1.3159e-03, -3.9887e-03,\n",
            "         2.1802e-02, -1.7572e-02, -1.8880e-02, -2.1247e-02, -1.3334e-02,\n",
            "        -1.1884e-02, -2.1541e-02, -1.2873e-02,  1.0784e-02, -8.6019e-03,\n",
            "         5.2551e-03, -4.3500e-03, -1.6887e-02, -3.3832e-03, -1.2741e-02,\n",
            "        -2.0780e-02,  7.0939e-03,  4.8625e-03, -1.0340e-03,  5.5888e-03,\n",
            "         1.2200e-02, -1.6891e-02, -1.8968e-02, -2.0300e-04,  1.7168e-02,\n",
            "         7.3278e-03, -1.4220e-02, -2.0420e-03,  3.5878e-03,  1.9396e-02,\n",
            "         5.9262e-03,  1.6508e-02, -1.3431e-02,  7.8597e-03,  1.6805e-02,\n",
            "         1.4482e-02, -1.7457e-02,  7.1747e-05,  5.4276e-03, -1.9222e-02,\n",
            "         5.6133e-03,  1.0148e-02,  8.6298e-03, -4.6073e-03, -6.3356e-03,\n",
            "        -1.7702e-02,  6.8228e-03,  1.9177e-02, -1.5759e-03, -2.0157e-02,\n",
            "        -2.1031e-02, -1.0851e-02,  1.1812e-02, -2.1555e-02, -2.0973e-02,\n",
            "        -1.3836e-03, -1.5844e-02,  2.8856e-03, -1.3456e-02,  1.5726e-04,\n",
            "        -8.9887e-03,  4.9299e-03,  5.4562e-03,  3.7262e-03,  3.0027e-03,\n",
            "        -1.0395e-02, -7.2112e-03, -5.5407e-03,  1.7928e-02, -6.7132e-03,\n",
            "        -3.4835e-04,  1.9563e-02,  1.5847e-02]))]), 'optimizer': {'state': {}, 'param_groups': [{'lr': 0.00030000000000000003, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0.0001, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321]}]}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py"
      ],
      "metadata": {
        "id": "E43uFO13n3Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  --lr 0.03 \\\n",
        "  --batch-size 256 \\\n",
        "  --mlp --moco-t 0.2 --aug-plus --cos \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\\n"
      ],
      "metadata": {
        "id": "jrPC1CMTm2BL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7e403b0-b82f-4391-b1f7-cd13f1aa152b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 12:03:36.011575: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 12:03:36.167261: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-07 12:03:36.945763: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 12:03:36.945863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 12:03:36.945881: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 12:03:41.510804: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 12:03:41.510922: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 12:03:41.510941: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet50'\n",
            "MoCo(\n",
            "  (encoder_q): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (encoder_k): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "5734\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 446, in <module>\n",
            "    main()\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 143, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 160, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 301, in main_worker\n",
            "    print(train_loader.shape)\n",
            "AttributeError: 'DataLoader' object has no attribute 'shape'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Master_Thesis/main_moco.py \\\n",
        "  -a resnet50 \\\n",
        "  --lr 0.10 \\\n",
        "  --batch-size 128 \\\n",
        "  --mlp --moco-t 0.2 --aug-plus --cos \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdN-L14q0r6B",
        "outputId": "5211b78d-a16a-4bb9-9bfe-0a7b3292b18d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 14:45:50.088603: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 14:45:50.254826: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-07 14:45:51.059732: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:45:51.059836: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:45:51.059854: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:45:55.669879: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:45:55.670004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:45:55.670025: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet50'\n",
            "MoCo(\n",
            "  (encoder_q): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (encoder_k): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (3): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (4): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (5): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): Bottleneck(\n",
            "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "      (2): Bottleneck(\n",
            "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Sequential(\n",
            "      (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=2048, out_features=128, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2023-03-07 14:46:03.524024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:03.524137: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:03.524156: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:07.857874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:07.857988: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:07.858008: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:12.134212: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:12.134317: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:12.134336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:16.257624: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:16.257727: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:16.257745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:20.331093: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:20.331186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:20.331203: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:24.378451: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:24.378555: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:24.378573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:28.455813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:28.455924: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:28.455943: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:32.531747: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:32.531845: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:32.531866: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:36.621917: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:36.622015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:36.622032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:40.661522: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:40.661656: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:40.661680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:44.734892: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:44.735006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:44.735023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:46:48.827055: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:48.827158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:46:48.827176: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [0][  0/537]\tTime 61.424 (61.424)\tData 53.818 (53.818)\tLoss 6.5256e+00 (6.5256e+00)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [0][ 10/537]\tTime  0.216 ( 5.776)\tData  0.000 ( 4.893)\tLoss 7.4947e+00 (7.0846e+00)\tAcc@1   0.00 (  9.45)\tAcc@5   1.56 ( 10.72)\n",
            "Epoch: [0][ 20/537]\tTime  0.216 ( 3.132)\tData  0.000 ( 2.566)\tLoss 7.9681e+00 (7.4148e+00)\tAcc@1   3.91 (  5.36)\tAcc@5   3.91 (  6.88)\n",
            "Epoch: [0][ 30/537]\tTime  0.250 ( 2.195)\tData  0.001 ( 1.741)\tLoss 8.3042e+00 (7.6561e+00)\tAcc@1   0.78 (  3.76)\tAcc@5   4.69 (  5.44)\n",
            "Epoch: [0][ 40/537]\tTime  0.226 ( 1.717)\tData  0.000 ( 1.318)\tLoss 8.5517e+00 (7.8487e+00)\tAcc@1   1.56 (  3.01)\tAcc@5   3.12 (  4.76)\n",
            "Epoch: [0][ 50/537]\tTime  0.222 ( 1.425)\tData  0.009 ( 1.061)\tLoss 8.7449e+00 (8.0082e+00)\tAcc@1   0.00 (  2.50)\tAcc@5   2.34 (  4.32)\n",
            "Epoch: [0][ 60/537]\tTime  0.248 ( 1.245)\tData  0.009 ( 0.905)\tLoss 8.8907e+00 (8.1427e+00)\tAcc@1   0.78 (  2.42)\tAcc@5   3.12 (  4.65)\n",
            "Epoch: [0][ 70/537]\tTime  0.226 ( 1.116)\tData  0.023 ( 0.794)\tLoss 8.9974e+00 (8.2568e+00)\tAcc@1   3.12 (  2.46)\tAcc@5   7.81 (  5.16)\n",
            "Epoch: [0][ 80/537]\tTime  0.217 ( 1.017)\tData  0.008 ( 0.709)\tLoss 9.0756e+00 (8.3538e+00)\tAcc@1   2.34 (  2.48)\tAcc@5   7.03 (  5.94)\n",
            "Epoch: [0][ 90/537]\tTime  0.245 ( 0.940)\tData  0.010 ( 0.642)\tLoss 9.1333e+00 (8.4367e+00)\tAcc@1   0.00 (  2.58)\tAcc@5  24.22 (  6.92)\n",
            "Epoch: [0][100/537]\tTime  0.266 ( 0.870)\tData  0.012 ( 0.579)\tLoss 9.1784e+00 (8.5082e+00)\tAcc@1  16.41 (  2.85)\tAcc@5  21.09 (  7.84)\n",
            "Epoch: [0][110/537]\tTime  0.216 ( 0.821)\tData  0.002 ( 0.536)\tLoss 9.2172e+00 (8.5706e+00)\tAcc@1  13.28 (  3.39)\tAcc@5  23.44 (  9.29)\n",
            "Epoch: [0][120/537]\tTime  0.224 ( 0.782)\tData  0.010 ( 0.503)\tLoss 9.2495e+00 (8.6255e+00)\tAcc@1  21.88 (  3.81)\tAcc@5  34.38 ( 10.29)\n",
            "Epoch: [0][130/537]\tTime  0.208 ( 0.744)\tData  0.009 ( 0.472)\tLoss 9.2774e+00 (8.6744e+00)\tAcc@1  18.75 (  4.06)\tAcc@5  21.88 ( 11.00)\n",
            "Epoch: [0][140/537]\tTime  0.247 ( 0.712)\tData  0.000 ( 0.444)\tLoss 9.3034e+00 (8.7182e+00)\tAcc@1  10.16 (  4.40)\tAcc@5  20.31 ( 11.86)\n",
            "Epoch: [0][150/537]\tTime  0.757 ( 0.686)\tData  0.581 ( 0.422)\tLoss 9.3245e+00 (8.7577e+00)\tAcc@1  10.94 (  4.48)\tAcc@5  26.56 ( 12.59)\n",
            "Epoch: [0][160/537]\tTime  0.222 ( 0.659)\tData  0.000 ( 0.398)\tLoss 9.3457e+00 (8.7937e+00)\tAcc@1   5.47 (  4.61)\tAcc@5  19.53 ( 13.20)\n",
            "Epoch: [0][170/537]\tTime  0.201 ( 0.640)\tData  0.000 ( 0.382)\tLoss 9.3640e+00 (8.8266e+00)\tAcc@1   3.91 (  4.82)\tAcc@5  21.09 ( 13.88)\n",
            "Epoch: [0][180/537]\tTime  0.217 ( 0.623)\tData  0.000 ( 0.368)\tLoss 9.3809e+00 (8.8568e+00)\tAcc@1   7.81 (  5.01)\tAcc@5  29.69 ( 14.28)\n",
            "Epoch: [0][190/537]\tTime  0.196 ( 0.608)\tData  0.009 ( 0.355)\tLoss 9.3957e+00 (8.8847e+00)\tAcc@1   8.59 (  5.08)\tAcc@5  34.38 ( 14.81)\n",
            "Epoch: [0][200/537]\tTime  0.223 ( 0.591)\tData  0.009 ( 0.341)\tLoss 9.4106e+00 (8.9106e+00)\tAcc@1   3.12 (  5.17)\tAcc@5  25.78 ( 15.21)\n",
            "Epoch: [0][210/537]\tTime  0.334 ( 0.578)\tData  0.146 ( 0.330)\tLoss 9.4244e+00 (8.9346e+00)\tAcc@1   7.03 (  5.47)\tAcc@5  17.19 ( 15.49)\n",
            "Epoch: [0][220/537]\tTime  0.257 ( 0.566)\tData  0.000 ( 0.319)\tLoss 9.4364e+00 (8.9571e+00)\tAcc@1   5.47 (  5.49)\tAcc@5  17.97 ( 15.70)\n",
            "Epoch: [0][230/537]\tTime  0.267 ( 0.556)\tData  0.014 ( 0.311)\tLoss 9.4469e+00 (8.9780e+00)\tAcc@1   4.69 (  5.68)\tAcc@5  20.31 ( 16.17)\n",
            "Epoch: [0][240/537]\tTime  0.262 ( 0.546)\tData  0.074 ( 0.302)\tLoss 9.4566e+00 (8.9977e+00)\tAcc@1   5.47 (  5.87)\tAcc@5  17.19 ( 16.54)\n",
            "Epoch: [0][250/537]\tTime  0.385 ( 0.537)\tData  0.178 ( 0.294)\tLoss 9.4654e+00 (9.0162e+00)\tAcc@1   7.03 (  6.13)\tAcc@5  27.34 ( 16.95)\n",
            "Epoch: [0][260/537]\tTime  0.227 ( 0.527)\tData  0.010 ( 0.286)\tLoss 9.4747e+00 (9.0336e+00)\tAcc@1   2.34 (  6.18)\tAcc@5  10.16 ( 17.05)\n",
            "Epoch: [0][270/537]\tTime  0.396 ( 0.520)\tData  0.206 ( 0.280)\tLoss 9.4813e+00 (9.0499e+00)\tAcc@1  10.16 (  6.34)\tAcc@5  17.97 ( 17.35)\n",
            "Epoch: [0][280/537]\tTime  0.221 ( 0.512)\tData  0.000 ( 0.273)\tLoss 9.4876e+00 (9.0654e+00)\tAcc@1  11.72 (  6.43)\tAcc@5  32.81 ( 17.58)\n",
            "Epoch: [0][290/537]\tTime  0.219 ( 0.506)\tData  0.010 ( 0.268)\tLoss 9.4934e+00 (9.0800e+00)\tAcc@1   5.47 (  6.39)\tAcc@5  25.00 ( 17.72)\n",
            "Epoch: [0][300/537]\tTime  0.219 ( 0.500)\tData  0.007 ( 0.263)\tLoss 9.4982e+00 (9.0938e+00)\tAcc@1   7.03 (  6.44)\tAcc@5  29.69 ( 17.92)\n",
            "Epoch: [0][310/537]\tTime  0.800 ( 0.493)\tData  0.581 ( 0.257)\tLoss 9.5020e+00 (9.1069e+00)\tAcc@1   6.25 (  6.52)\tAcc@5  13.28 ( 18.07)\n",
            "Epoch: [0][320/537]\tTime  0.220 ( 0.486)\tData  0.005 ( 0.251)\tLoss 9.5049e+00 (9.1193e+00)\tAcc@1   4.69 (  6.66)\tAcc@5  25.00 ( 18.25)\n",
            "Epoch: [0][330/537]\tTime  0.618 ( 0.482)\tData  0.413 ( 0.247)\tLoss 9.5090e+00 (9.1310e+00)\tAcc@1  18.75 (  6.74)\tAcc@5  24.22 ( 18.32)\n",
            "Epoch: [0][340/537]\tTime  0.227 ( 0.475)\tData  0.008 ( 0.241)\tLoss 9.5090e+00 (9.1421e+00)\tAcc@1   0.78 (  6.78)\tAcc@5  34.38 ( 18.45)\n",
            "Epoch: [0][350/537]\tTime  0.222 ( 0.471)\tData  0.000 ( 0.238)\tLoss 9.5125e+00 (9.1526e+00)\tAcc@1   8.59 (  6.87)\tAcc@5  21.88 ( 18.57)\n",
            "Epoch: [0][360/537]\tTime  0.211 ( 0.467)\tData  0.000 ( 0.235)\tLoss 9.5107e+00 (9.1625e+00)\tAcc@1  10.94 (  6.98)\tAcc@5  27.34 ( 18.73)\n",
            "Epoch: [0][370/537]\tTime  0.834 ( 0.465)\tData  0.616 ( 0.233)\tLoss 9.5122e+00 (9.1720e+00)\tAcc@1   6.25 (  7.02)\tAcc@5  25.00 ( 18.89)\n",
            "Epoch: [0][380/537]\tTime  0.201 ( 0.459)\tData  0.009 ( 0.228)\tLoss 9.5122e+00 (9.1809e+00)\tAcc@1   6.25 (  7.01)\tAcc@5  19.53 ( 18.89)\n",
            "Epoch: [0][390/537]\tTime  0.270 ( 0.455)\tData  0.086 ( 0.224)\tLoss 9.5094e+00 (9.1893e+00)\tAcc@1   8.59 (  7.05)\tAcc@5  24.22 ( 18.98)\n",
            "Epoch: [0][400/537]\tTime  0.209 ( 0.451)\tData  0.009 ( 0.221)\tLoss 9.5062e+00 (9.1973e+00)\tAcc@1   7.03 (  7.15)\tAcc@5  19.53 ( 19.06)\n",
            "Epoch: [0][410/537]\tTime  0.208 ( 0.448)\tData  0.000 ( 0.218)\tLoss 9.5039e+00 (9.2047e+00)\tAcc@1   1.56 (  7.13)\tAcc@5  24.22 ( 19.16)\n",
            "Epoch: [0][420/537]\tTime  0.274 ( 0.446)\tData  0.000 ( 0.216)\tLoss 9.4990e+00 (9.2118e+00)\tAcc@1   7.03 (  7.16)\tAcc@5  28.12 ( 19.33)\n",
            "Epoch: [0][430/537]\tTime  1.179 ( 0.444)\tData  1.000 ( 0.214)\tLoss 9.4927e+00 (9.2184e+00)\tAcc@1   7.03 (  7.18)\tAcc@5  24.22 ( 19.42)\n",
            "Epoch: [0][440/537]\tTime  0.240 ( 0.439)\tData  0.000 ( 0.210)\tLoss 9.4864e+00 (9.2245e+00)\tAcc@1  15.62 (  7.24)\tAcc@5  22.66 ( 19.48)\n",
            "Epoch: [0][450/537]\tTime  0.220 ( 0.436)\tData  0.009 ( 0.207)\tLoss 9.4777e+00 (9.2302e+00)\tAcc@1  14.06 (  7.33)\tAcc@5  21.88 ( 19.54)\n",
            "Epoch: [0][460/537]\tTime  0.243 ( 0.433)\tData  0.000 ( 0.205)\tLoss 9.4683e+00 (9.2355e+00)\tAcc@1   3.12 (  7.29)\tAcc@5  17.97 ( 19.56)\n",
            "Epoch: [0][470/537]\tTime  0.234 ( 0.431)\tData  0.000 ( 0.203)\tLoss 9.4556e+00 (9.2403e+00)\tAcc@1  10.16 (  7.30)\tAcc@5  19.53 ( 19.64)\n",
            "Epoch: [0][480/537]\tTime  0.216 ( 0.429)\tData  0.000 ( 0.201)\tLoss 9.4403e+00 (9.2446e+00)\tAcc@1  16.41 (  7.37)\tAcc@5  31.25 ( 19.72)\n",
            "Epoch: [0][490/537]\tTime  0.428 ( 0.426)\tData  0.223 ( 0.199)\tLoss 9.4224e+00 (9.2484e+00)\tAcc@1  10.16 (  7.35)\tAcc@5  20.31 ( 19.76)\n",
            "Epoch: [0][500/537]\tTime  0.237 ( 0.422)\tData  0.000 ( 0.196)\tLoss 9.3995e+00 (9.2516e+00)\tAcc@1   5.47 (  7.36)\tAcc@5  25.00 ( 19.85)\n",
            "Epoch: [0][510/537]\tTime  0.254 ( 0.421)\tData  0.001 ( 0.194)\tLoss 9.3675e+00 (9.2542e+00)\tAcc@1   3.12 (  7.36)\tAcc@5  21.09 ( 19.93)\n",
            "Epoch: [0][520/537]\tTime  0.216 ( 0.419)\tData  0.000 ( 0.192)\tLoss 9.3467e+00 (9.2561e+00)\tAcc@1  11.72 (  7.38)\tAcc@5  29.69 ( 19.99)\n",
            "Epoch: [0][530/537]\tTime  0.214 ( 0.416)\tData  0.000 ( 0.190)\tLoss 9.3369e+00 (9.2577e+00)\tAcc@1   0.00 (  7.38)\tAcc@5  15.62 ( 20.04)\n",
            "epoch: 0\n",
            "2023-03-07 14:49:47.904930: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:47.905029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:47.905047: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:49:52.078461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:52.078559: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:52.078578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:49:56.209084: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:56.209193: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:49:56.209218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:00.352433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:00.352535: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:00.352556: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:04.626994: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:04.627099: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:04.627117: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:08.969476: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:08.969571: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:08.969589: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:13.251853: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:13.251969: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:13.251987: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:17.435374: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:17.435469: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:17.435488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:21.719217: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:21.719322: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:21.719340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:25.918049: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:25.918142: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:25.918160: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:30.023990: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:30.024086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:30.024106: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:50:34.173036: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:34.173126: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:50:34.173142: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [1][  0/537]\tTime 54.331 (54.331)\tData 54.106 (54.106)\tLoss 9.3288e+00 (9.3288e+00)\tAcc@1   8.59 (  8.59)\tAcc@5  25.00 ( 25.00)\n",
            "Epoch: [1][ 10/537]\tTime  0.230 ( 5.150)\tData  0.000 ( 4.926)\tLoss 9.3183e+00 (9.3242e+00)\tAcc@1   8.59 (  7.39)\tAcc@5  23.44 ( 21.24)\n",
            "Epoch: [1][ 20/537]\tTime  0.238 ( 2.853)\tData  0.000 ( 2.634)\tLoss 9.3109e+00 (9.3201e+00)\tAcc@1  11.72 (  9.04)\tAcc@5  33.59 ( 20.98)\n",
            "Epoch: [1][ 30/537]\tTime  0.215 ( 2.028)\tData  0.000 ( 1.811)\tLoss 9.3060e+00 (9.3160e+00)\tAcc@1   7.03 (  9.05)\tAcc@5  14.06 ( 21.14)\n",
            "Epoch: [1][ 40/537]\tTime  0.216 ( 1.619)\tData  0.000 ( 1.404)\tLoss 9.2961e+00 (9.3120e+00)\tAcc@1   1.56 (  8.61)\tAcc@5  14.06 ( 20.54)\n",
            "Epoch: [1][ 50/537]\tTime  0.386 ( 1.362)\tData  0.179 ( 1.148)\tLoss 9.2892e+00 (9.3081e+00)\tAcc@1   9.38 (  8.26)\tAcc@5  21.09 ( 20.91)\n",
            "Epoch: [1][ 60/537]\tTime  0.889 ( 1.187)\tData  0.693 ( 0.973)\tLoss 9.2828e+00 (9.3045e+00)\tAcc@1  11.72 (  7.93)\tAcc@5  15.62 ( 20.90)\n",
            "Epoch: [1][ 70/537]\tTime  0.238 ( 1.055)\tData  0.000 ( 0.841)\tLoss 9.2765e+00 (9.3011e+00)\tAcc@1  12.50 (  8.04)\tAcc@5  20.31 ( 21.17)\n",
            "Epoch: [1][ 80/537]\tTime  0.227 ( 0.963)\tData  0.000 ( 0.749)\tLoss 9.2736e+00 (9.2977e+00)\tAcc@1   6.25 (  7.79)\tAcc@5  17.19 ( 21.05)\n",
            "Epoch: [1][ 90/537]\tTime  0.224 ( 0.897)\tData  0.000 ( 0.682)\tLoss 9.2654e+00 (9.2945e+00)\tAcc@1   7.03 (  7.71)\tAcc@5  11.72 ( 20.42)\n",
            "Epoch: [1][100/537]\tTime  0.224 ( 0.838)\tData  0.000 ( 0.624)\tLoss 9.2597e+00 (9.2914e+00)\tAcc@1  13.28 (  7.74)\tAcc@5  19.53 ( 20.17)\n",
            "Epoch: [1][110/537]\tTime  0.228 ( 0.791)\tData  0.001 ( 0.577)\tLoss 9.2597e+00 (9.2886e+00)\tAcc@1   5.47 (  7.70)\tAcc@5  20.31 ( 20.01)\n",
            "Epoch: [1][120/537]\tTime  1.284 ( 0.755)\tData  1.057 ( 0.540)\tLoss 9.2533e+00 (9.2858e+00)\tAcc@1  11.72 (  7.57)\tAcc@5  14.84 ( 19.93)\n",
            "Epoch: [1][130/537]\tTime  0.206 ( 0.715)\tData  0.000 ( 0.500)\tLoss 9.2468e+00 (9.2831e+00)\tAcc@1  11.72 (  7.33)\tAcc@5  28.91 ( 19.90)\n",
            "Epoch: [1][140/537]\tTime  0.222 ( 0.690)\tData  0.000 ( 0.475)\tLoss 9.2457e+00 (9.2805e+00)\tAcc@1   7.03 (  7.25)\tAcc@5  12.50 ( 19.63)\n",
            "Epoch: [1][150/537]\tTime  0.226 ( 0.665)\tData  0.000 ( 0.451)\tLoss 9.2428e+00 (9.2780e+00)\tAcc@1  10.16 (  7.21)\tAcc@5  15.62 ( 19.50)\n",
            "Epoch: [1][160/537]\tTime  0.212 ( 0.643)\tData  0.009 ( 0.430)\tLoss 9.2380e+00 (9.2756e+00)\tAcc@1   5.47 (  7.15)\tAcc@5  20.31 ( 19.35)\n",
            "Epoch: [1][170/537]\tTime  0.213 ( 0.625)\tData  0.000 ( 0.412)\tLoss 9.2323e+00 (9.2733e+00)\tAcc@1  14.84 (  7.36)\tAcc@5  27.34 ( 19.34)\n",
            "Epoch: [1][180/537]\tTime  1.202 ( 0.609)\tData  1.012 ( 0.395)\tLoss 9.2305e+00 (9.2710e+00)\tAcc@1  10.94 (  7.34)\tAcc@5  19.53 ( 19.22)\n",
            "Epoch: [1][190/537]\tTime  0.216 ( 0.589)\tData  0.000 ( 0.375)\tLoss 9.2289e+00 (9.2689e+00)\tAcc@1   6.25 (  7.28)\tAcc@5   7.03 ( 18.99)\n",
            "Epoch: [1][200/537]\tTime  0.227 ( 0.575)\tData  0.000 ( 0.362)\tLoss 9.2268e+00 (9.2667e+00)\tAcc@1   3.91 (  7.25)\tAcc@5   7.03 ( 18.89)\n",
            "Epoch: [1][210/537]\tTime  0.216 ( 0.563)\tData  0.000 ( 0.350)\tLoss 9.2183e+00 (9.2647e+00)\tAcc@1   2.34 (  7.17)\tAcc@5  14.06 ( 18.73)\n",
            "Epoch: [1][220/537]\tTime  0.192 ( 0.552)\tData  0.000 ( 0.339)\tLoss 9.2200e+00 (9.2627e+00)\tAcc@1   4.69 (  7.06)\tAcc@5  15.62 ( 18.52)\n",
            "Epoch: [1][230/537]\tTime  0.237 ( 0.543)\tData  0.000 ( 0.330)\tLoss 9.2162e+00 (9.2607e+00)\tAcc@1   0.78 (  7.00)\tAcc@5  11.72 ( 18.37)\n",
            "Epoch: [1][240/537]\tTime  1.340 ( 0.535)\tData  1.133 ( 0.321)\tLoss 9.2131e+00 (9.2588e+00)\tAcc@1   4.69 (  6.97)\tAcc@5  12.50 ( 18.23)\n",
            "Epoch: [1][250/537]\tTime  0.188 ( 0.522)\tData  0.010 ( 0.309)\tLoss 9.2134e+00 (9.2570e+00)\tAcc@1   4.69 (  6.91)\tAcc@5  15.62 ( 18.13)\n",
            "Epoch: [1][260/537]\tTime  0.201 ( 0.514)\tData  0.009 ( 0.300)\tLoss 9.2108e+00 (9.2552e+00)\tAcc@1   0.00 (  6.83)\tAcc@5  16.41 ( 18.04)\n",
            "Epoch: [1][270/537]\tTime  0.220 ( 0.506)\tData  0.009 ( 0.292)\tLoss 9.2105e+00 (9.2535e+00)\tAcc@1   0.78 (  6.82)\tAcc@5   7.81 ( 17.93)\n",
            "Epoch: [1][280/537]\tTime  0.249 ( 0.500)\tData  0.013 ( 0.287)\tLoss 9.2041e+00 (9.2518e+00)\tAcc@1  17.19 (  6.85)\tAcc@5  21.09 ( 17.89)\n",
            "Epoch: [1][290/537]\tTime  0.243 ( 0.495)\tData  0.007 ( 0.282)\tLoss 9.2040e+00 (9.2502e+00)\tAcc@1   0.78 (  6.84)\tAcc@5  24.22 ( 17.79)\n",
            "Epoch: [1][300/537]\tTime  0.584 ( 0.487)\tData  0.384 ( 0.274)\tLoss 9.2050e+00 (9.2486e+00)\tAcc@1   0.00 (  6.81)\tAcc@5  13.28 ( 17.69)\n",
            "Epoch: [1][310/537]\tTime  0.237 ( 0.481)\tData  0.000 ( 0.268)\tLoss 9.2010e+00 (9.2472e+00)\tAcc@1   7.81 (  6.76)\tAcc@5  17.97 ( 17.54)\n",
            "Epoch: [1][320/537]\tTime  0.215 ( 0.476)\tData  0.000 ( 0.262)\tLoss 9.1987e+00 (9.2457e+00)\tAcc@1  10.16 (  6.83)\tAcc@5  22.66 ( 17.49)\n",
            "Epoch: [1][330/537]\tTime  0.238 ( 0.471)\tData  0.000 ( 0.258)\tLoss 9.1971e+00 (9.2442e+00)\tAcc@1   4.69 (  6.79)\tAcc@5  20.31 ( 17.44)\n",
            "Epoch: [1][340/537]\tTime  0.219 ( 0.467)\tData  0.000 ( 0.254)\tLoss 9.1963e+00 (9.2428e+00)\tAcc@1   0.00 (  6.71)\tAcc@5  10.94 ( 17.39)\n",
            "Epoch: [1][350/537]\tTime  0.219 ( 0.462)\tData  0.009 ( 0.248)\tLoss 9.1964e+00 (9.2414e+00)\tAcc@1   9.38 (  6.68)\tAcc@5  14.84 ( 17.39)\n",
            "Epoch: [1][360/537]\tTime  0.346 ( 0.456)\tData  0.153 ( 0.243)\tLoss 9.1916e+00 (9.2401e+00)\tAcc@1   4.69 (  6.61)\tAcc@5  10.94 ( 17.27)\n",
            "Epoch: [1][370/537]\tTime  0.239 ( 0.453)\tData  0.000 ( 0.239)\tLoss 9.1896e+00 (9.2388e+00)\tAcc@1   1.56 (  6.56)\tAcc@5  12.50 ( 17.18)\n",
            "Epoch: [1][380/537]\tTime  0.209 ( 0.449)\tData  0.010 ( 0.236)\tLoss 9.1910e+00 (9.2376e+00)\tAcc@1   7.81 (  6.51)\tAcc@5  14.06 ( 17.05)\n",
            "Epoch: [1][390/537]\tTime  0.236 ( 0.447)\tData  0.000 ( 0.234)\tLoss 9.1927e+00 (9.2364e+00)\tAcc@1   4.69 (  6.49)\tAcc@5  14.06 ( 16.99)\n",
            "Epoch: [1][400/537]\tTime  0.225 ( 0.444)\tData  0.000 ( 0.231)\tLoss 9.1859e+00 (9.2352e+00)\tAcc@1  10.94 (  6.49)\tAcc@5  18.75 ( 16.98)\n",
            "Epoch: [1][410/537]\tTime  0.222 ( 0.440)\tData  0.003 ( 0.227)\tLoss 9.1883e+00 (9.2341e+00)\tAcc@1   6.25 (  6.48)\tAcc@5  17.19 ( 16.94)\n",
            "Epoch: [1][420/537]\tTime  0.222 ( 0.436)\tData  0.009 ( 0.222)\tLoss 9.1858e+00 (9.2330e+00)\tAcc@1   4.69 (  6.50)\tAcc@5  10.94 ( 16.92)\n",
            "Epoch: [1][430/537]\tTime  0.225 ( 0.433)\tData  0.000 ( 0.219)\tLoss 9.1855e+00 (9.2319e+00)\tAcc@1   3.91 (  6.49)\tAcc@5   8.59 ( 16.88)\n",
            "Epoch: [1][440/537]\tTime  0.241 ( 0.430)\tData  0.014 ( 0.217)\tLoss 9.1868e+00 (9.2308e+00)\tAcc@1   3.12 (  6.46)\tAcc@5  13.28 ( 16.79)\n",
            "Epoch: [1][450/537]\tTime  0.236 ( 0.428)\tData  0.001 ( 0.215)\tLoss 9.1845e+00 (9.2298e+00)\tAcc@1   1.56 (  6.46)\tAcc@5  18.75 ( 16.76)\n",
            "Epoch: [1][460/537]\tTime  0.226 ( 0.426)\tData  0.000 ( 0.213)\tLoss 9.1810e+00 (9.2288e+00)\tAcc@1   6.25 (  6.44)\tAcc@5  21.88 ( 16.73)\n",
            "Epoch: [1][470/537]\tTime  0.908 ( 0.423)\tData  0.713 ( 0.210)\tLoss 9.1828e+00 (9.2279e+00)\tAcc@1   4.69 (  6.43)\tAcc@5  14.06 ( 16.71)\n",
            "Epoch: [1][480/537]\tTime  0.246 ( 0.419)\tData  0.001 ( 0.206)\tLoss 9.1814e+00 (9.2269e+00)\tAcc@1   6.25 (  6.44)\tAcc@5  14.06 ( 16.72)\n",
            "Epoch: [1][490/537]\tTime  0.284 ( 0.418)\tData  0.001 ( 0.204)\tLoss 9.1864e+00 (9.2260e+00)\tAcc@1   5.47 (  6.47)\tAcc@5  13.28 ( 16.69)\n",
            "Epoch: [1][500/537]\tTime  0.223 ( 0.416)\tData  0.009 ( 0.202)\tLoss 9.1853e+00 (9.2252e+00)\tAcc@1   6.25 (  6.44)\tAcc@5  10.94 ( 16.62)\n",
            "Epoch: [1][510/537]\tTime  0.228 ( 0.414)\tData  0.003 ( 0.201)\tLoss 9.1810e+00 (9.2244e+00)\tAcc@1   4.69 (  6.41)\tAcc@5  18.75 ( 16.60)\n",
            "Epoch: [1][520/537]\tTime  0.216 ( 0.412)\tData  0.000 ( 0.198)\tLoss 9.1822e+00 (9.2236e+00)\tAcc@1   6.25 (  6.42)\tAcc@5  17.97 ( 16.60)\n",
            "Epoch: [1][530/537]\tTime  0.214 ( 0.408)\tData  0.000 ( 0.195)\tLoss 9.1826e+00 (9.2228e+00)\tAcc@1   9.38 (  6.41)\tAcc@5  17.97 ( 16.61)\n",
            "epoch: 1\n",
            "2023-03-07 14:53:28.222874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:28.222981: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:28.222999: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:32.406690: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:32.406797: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:32.406816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:36.519607: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:36.519704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:36.519722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:40.670131: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:40.670242: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:40.670262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:44.784404: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:44.784503: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:44.784522: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:48.944600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:48.944700: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:48.944718: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:53.056173: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:53.056281: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:53.056300: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:53:57.184344: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:57.184452: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:53:57.184470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:54:01.335698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:01.335800: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:01.335818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:54:05.676493: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:05.676595: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:05.676613: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:54:10.029004: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:10.029111: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:10.029130: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:54:14.212918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:14.213027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:54:14.213046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [2][  0/537]\tTime 54.287 (54.287)\tData 54.031 (54.031)\tLoss 9.1804e+00 (9.1804e+00)\tAcc@1   5.47 (  5.47)\tAcc@5  21.09 ( 21.09)\n",
            "Epoch: [2][ 10/537]\tTime  0.223 ( 5.179)\tData  0.008 ( 4.961)\tLoss 9.1817e+00 (9.1817e+00)\tAcc@1   8.59 (  6.46)\tAcc@5  12.50 ( 18.47)\n",
            "Epoch: [2][ 20/537]\tTime  0.226 ( 2.859)\tData  0.010 ( 2.649)\tLoss 9.1825e+00 (9.1817e+00)\tAcc@1   0.78 (  5.80)\tAcc@5  11.72 ( 17.26)\n",
            "Epoch: [2][ 30/537]\tTime  0.217 ( 2.029)\tData  0.000 ( 1.819)\tLoss 9.1824e+00 (9.1817e+00)\tAcc@1   3.91 (  6.63)\tAcc@5  14.84 ( 17.34)\n",
            "Epoch: [2][ 40/537]\tTime  0.216 ( 1.609)\tData  0.000 ( 1.400)\tLoss 9.1819e+00 (9.1820e+00)\tAcc@1   7.03 (  6.80)\tAcc@5  17.19 ( 17.02)\n",
            "Epoch: [2][ 50/537]\tTime  0.229 ( 1.359)\tData  0.000 ( 1.150)\tLoss 9.1818e+00 (9.1822e+00)\tAcc@1   9.38 (  7.03)\tAcc@5  17.97 ( 17.03)\n",
            "Epoch: [2][ 60/537]\tTime  1.333 ( 1.191)\tData  1.114 ( 0.981)\tLoss 9.1815e+00 (9.1823e+00)\tAcc@1  10.16 (  7.21)\tAcc@5  17.97 ( 17.26)\n",
            "Epoch: [2][ 70/537]\tTime  0.216 ( 1.054)\tData  0.011 ( 0.844)\tLoss 9.1854e+00 (9.1824e+00)\tAcc@1   7.81 (  7.34)\tAcc@5  17.97 ( 17.29)\n",
            "Epoch: [2][ 80/537]\tTime  0.231 ( 0.965)\tData  0.000 ( 0.755)\tLoss 9.1834e+00 (9.1825e+00)\tAcc@1  13.28 (  7.48)\tAcc@5  23.44 ( 17.69)\n",
            "Epoch: [2][ 90/537]\tTime  0.196 ( 0.894)\tData  0.010 ( 0.685)\tLoss 9.1823e+00 (9.1826e+00)\tAcc@1  18.75 (  7.54)\tAcc@5  25.00 ( 17.89)\n",
            "Epoch: [2][100/537]\tTime  0.200 ( 0.839)\tData  0.000 ( 0.629)\tLoss 9.1857e+00 (9.1826e+00)\tAcc@1   4.69 (  7.67)\tAcc@5   6.25 ( 17.74)\n",
            "Epoch: [2][110/537]\tTime  0.213 ( 0.792)\tData  0.009 ( 0.583)\tLoss 9.1844e+00 (9.1827e+00)\tAcc@1   3.91 (  7.98)\tAcc@5  10.94 ( 18.11)\n",
            "Epoch: [2][120/537]\tTime  0.449 ( 0.747)\tData  0.283 ( 0.538)\tLoss 9.1852e+00 (9.1829e+00)\tAcc@1   3.12 (  8.04)\tAcc@5  15.62 ( 18.38)\n",
            "Epoch: [2][130/537]\tTime  0.221 ( 0.714)\tData  0.009 ( 0.505)\tLoss 9.1833e+00 (9.1831e+00)\tAcc@1   3.12 (  7.95)\tAcc@5  21.09 ( 18.50)\n",
            "Epoch: [2][140/537]\tTime  0.223 ( 0.686)\tData  0.000 ( 0.476)\tLoss 9.1882e+00 (9.1833e+00)\tAcc@1  10.16 (  7.94)\tAcc@5  14.84 ( 18.67)\n",
            "Epoch: [2][150/537]\tTime  0.224 ( 0.664)\tData  0.001 ( 0.453)\tLoss 9.1856e+00 (9.1835e+00)\tAcc@1  15.62 (  7.99)\tAcc@5  26.56 ( 18.99)\n",
            "Epoch: [2][160/537]\tTime  0.225 ( 0.644)\tData  0.010 ( 0.433)\tLoss 9.1862e+00 (9.1837e+00)\tAcc@1  17.97 (  7.99)\tAcc@5  27.34 ( 19.08)\n",
            "Epoch: [2][170/537]\tTime  0.236 ( 0.626)\tData  0.009 ( 0.415)\tLoss 9.1867e+00 (9.1839e+00)\tAcc@1  10.94 (  8.00)\tAcc@5  31.25 ( 19.39)\n",
            "Epoch: [2][180/537]\tTime  0.214 ( 0.604)\tData  0.000 ( 0.392)\tLoss 9.1872e+00 (9.1841e+00)\tAcc@1  10.16 (  7.91)\tAcc@5  19.53 ( 19.57)\n",
            "Epoch: [2][190/537]\tTime  0.217 ( 0.589)\tData  0.000 ( 0.377)\tLoss 9.1882e+00 (9.1843e+00)\tAcc@1   8.59 (  8.03)\tAcc@5  21.88 ( 19.80)\n",
            "Epoch: [2][200/537]\tTime  0.212 ( 0.575)\tData  0.010 ( 0.363)\tLoss 9.1874e+00 (9.1844e+00)\tAcc@1  14.06 (  8.24)\tAcc@5  28.12 ( 20.09)\n",
            "Epoch: [2][210/537]\tTime  0.211 ( 0.563)\tData  0.001 ( 0.352)\tLoss 9.1891e+00 (9.1847e+00)\tAcc@1  14.06 (  8.36)\tAcc@5  28.12 ( 20.57)\n",
            "Epoch: [2][220/537]\tTime  0.216 ( 0.551)\tData  0.000 ( 0.339)\tLoss 9.1911e+00 (9.1848e+00)\tAcc@1   5.47 (  8.52)\tAcc@5  18.75 ( 20.85)\n",
            "Epoch: [2][230/537]\tTime  0.214 ( 0.541)\tData  0.008 ( 0.329)\tLoss 9.1894e+00 (9.1850e+00)\tAcc@1  10.16 (  8.73)\tAcc@5  37.50 ( 21.32)\n",
            "Epoch: [2][240/537]\tTime  0.234 ( 0.529)\tData  0.010 ( 0.317)\tLoss 9.1908e+00 (9.1853e+00)\tAcc@1  13.28 (  8.77)\tAcc@5  25.00 ( 21.67)\n",
            "Epoch: [2][250/537]\tTime  0.236 ( 0.522)\tData  0.000 ( 0.310)\tLoss 9.1908e+00 (9.1855e+00)\tAcc@1  12.50 (  8.96)\tAcc@5  35.16 ( 22.12)\n",
            "Epoch: [2][260/537]\tTime  0.213 ( 0.515)\tData  0.000 ( 0.303)\tLoss 9.1926e+00 (9.1857e+00)\tAcc@1   8.59 (  9.04)\tAcc@5  33.59 ( 22.55)\n",
            "Epoch: [2][270/537]\tTime  0.211 ( 0.508)\tData  0.010 ( 0.296)\tLoss 9.1921e+00 (9.1859e+00)\tAcc@1   8.59 (  9.20)\tAcc@5  27.34 ( 22.86)\n",
            "Epoch: [2][280/537]\tTime  0.215 ( 0.498)\tData  0.010 ( 0.286)\tLoss 9.1930e+00 (9.1861e+00)\tAcc@1  22.66 (  9.44)\tAcc@5  38.28 ( 23.42)\n",
            "Epoch: [2][290/537]\tTime  0.217 ( 0.493)\tData  0.013 ( 0.281)\tLoss 9.1938e+00 (9.1864e+00)\tAcc@1  13.28 (  9.63)\tAcc@5  41.41 ( 23.97)\n",
            "Epoch: [2][300/537]\tTime  0.544 ( 0.486)\tData  0.367 ( 0.274)\tLoss 9.1938e+00 (9.1866e+00)\tAcc@1  16.41 (  9.98)\tAcc@5  45.31 ( 24.50)\n",
            "Epoch: [2][310/537]\tTime  0.233 ( 0.481)\tData  0.009 ( 0.269)\tLoss 9.1930e+00 (9.1868e+00)\tAcc@1   0.78 ( 10.00)\tAcc@5  50.78 ( 25.07)\n",
            "Epoch: [2][320/537]\tTime  0.221 ( 0.476)\tData  0.000 ( 0.265)\tLoss 9.1941e+00 (9.1870e+00)\tAcc@1   9.38 ( 10.34)\tAcc@5  46.09 ( 25.79)\n",
            "Epoch: [2][330/537]\tTime  0.235 ( 0.471)\tData  0.009 ( 0.259)\tLoss 9.1948e+00 (9.1873e+00)\tAcc@1  10.94 ( 10.60)\tAcc@5  43.75 ( 26.49)\n",
            "Epoch: [2][340/537]\tTime  0.529 ( 0.465)\tData  0.308 ( 0.253)\tLoss 9.1954e+00 (9.1875e+00)\tAcc@1  29.69 ( 10.86)\tAcc@5  43.75 ( 27.15)\n",
            "Epoch: [2][350/537]\tTime  0.242 ( 0.461)\tData  0.000 ( 0.249)\tLoss 9.1954e+00 (9.1877e+00)\tAcc@1  28.91 ( 11.08)\tAcc@5  55.47 ( 27.74)\n",
            "Epoch: [2][360/537]\tTime  0.638 ( 0.457)\tData  0.448 ( 0.245)\tLoss 9.1958e+00 (9.1879e+00)\tAcc@1  10.16 ( 11.26)\tAcc@5  42.19 ( 28.26)\n",
            "Epoch: [2][370/537]\tTime  0.227 ( 0.453)\tData  0.009 ( 0.241)\tLoss 9.1953e+00 (9.1881e+00)\tAcc@1  10.94 ( 11.20)\tAcc@5  33.59 ( 28.31)\n",
            "Epoch: [2][380/537]\tTime  0.247 ( 0.450)\tData  0.013 ( 0.238)\tLoss 9.1974e+00 (9.1884e+00)\tAcc@1   5.47 ( 11.09)\tAcc@5  14.06 ( 28.11)\n",
            "Epoch: [2][390/537]\tTime  0.234 ( 0.446)\tData  0.009 ( 0.234)\tLoss 9.1969e+00 (9.1886e+00)\tAcc@1   3.12 ( 10.91)\tAcc@5  10.94 ( 27.82)\n",
            "Epoch: [2][400/537]\tTime  0.219 ( 0.441)\tData  0.010 ( 0.228)\tLoss 9.1983e+00 (9.1888e+00)\tAcc@1   0.78 ( 10.71)\tAcc@5  10.94 ( 27.42)\n",
            "Epoch: [2][410/537]\tTime  0.230 ( 0.438)\tData  0.034 ( 0.225)\tLoss 9.1970e+00 (9.1891e+00)\tAcc@1   0.78 ( 10.53)\tAcc@5  14.84 ( 27.01)\n",
            "Epoch: [2][420/537]\tTime  0.250 ( 0.435)\tData  0.010 ( 0.223)\tLoss 9.1978e+00 (9.1893e+00)\tAcc@1   2.34 ( 10.34)\tAcc@5   7.81 ( 26.54)\n",
            "Epoch: [2][430/537]\tTime  0.245 ( 0.433)\tData  0.010 ( 0.221)\tLoss 9.1979e+00 (9.1895e+00)\tAcc@1   3.12 ( 10.15)\tAcc@5   3.91 ( 26.09)\n",
            "Epoch: [2][440/537]\tTime  0.200 ( 0.430)\tData  0.010 ( 0.218)\tLoss 9.1994e+00 (9.1897e+00)\tAcc@1   0.78 (  9.97)\tAcc@5   5.47 ( 25.61)\n",
            "Epoch: [2][450/537]\tTime  0.245 ( 0.428)\tData  0.000 ( 0.215)\tLoss 9.2015e+00 (9.1899e+00)\tAcc@1   1.56 (  9.78)\tAcc@5   3.12 ( 25.14)\n",
            "Epoch: [2][460/537]\tTime  0.224 ( 0.423)\tData  0.000 ( 0.211)\tLoss 9.2007e+00 (9.1901e+00)\tAcc@1   1.56 (  9.59)\tAcc@5   3.12 ( 24.69)\n",
            "Epoch: [2][470/537]\tTime  0.218 ( 0.421)\tData  0.000 ( 0.209)\tLoss 9.1998e+00 (9.1903e+00)\tAcc@1   0.00 (  9.42)\tAcc@5   5.47 ( 24.26)\n",
            "Epoch: [2][480/537]\tTime  0.240 ( 0.420)\tData  0.000 ( 0.207)\tLoss 9.2014e+00 (9.1905e+00)\tAcc@1   1.56 (  9.25)\tAcc@5   2.34 ( 23.83)\n",
            "Epoch: [2][490/537]\tTime  0.215 ( 0.418)\tData  0.009 ( 0.205)\tLoss 9.1997e+00 (9.1907e+00)\tAcc@1   1.56 (  9.09)\tAcc@5   3.91 ( 23.43)\n",
            "Epoch: [2][500/537]\tTime  0.211 ( 0.416)\tData  0.011 ( 0.203)\tLoss 9.2011e+00 (9.1909e+00)\tAcc@1   0.78 (  8.93)\tAcc@5   2.34 ( 23.02)\n",
            "Epoch: [2][510/537]\tTime  0.217 ( 0.414)\tData  0.000 ( 0.201)\tLoss 9.1991e+00 (9.1911e+00)\tAcc@1   0.00 (  8.77)\tAcc@5   5.47 ( 22.64)\n",
            "Epoch: [2][520/537]\tTime  0.217 ( 0.411)\tData  0.000 ( 0.198)\tLoss 9.1997e+00 (9.1913e+00)\tAcc@1   0.78 (  8.62)\tAcc@5   3.91 ( 22.27)\n",
            "Epoch: [2][530/537]\tTime  0.214 ( 0.408)\tData  0.000 ( 0.195)\tLoss 9.2005e+00 (9.1915e+00)\tAcc@1   0.78 (  8.48)\tAcc@5   3.91 ( 21.90)\n",
            "epoch: 2\n",
            "2023-03-07 14:57:08.489935: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:08.490065: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:08.490087: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:12.752334: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:12.752439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:12.752458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:16.864104: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:16.864238: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:16.864260: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:20.973813: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:20.973944: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:20.973966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:25.112565: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:25.112699: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:25.112722: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:29.222339: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:29.222433: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:29.222451: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:33.300985: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:33.301081: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:33.301100: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:37.378160: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:37.378261: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:37.378281: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:41.531132: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:41.531240: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:41.531259: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:45.589083: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:45.589186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:45.589213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:49.714534: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:49.714627: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:49.714645: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 14:57:53.831245: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:53.831346: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 14:57:53.831364: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [3][  0/537]\tTime 54.189 (54.189)\tData 53.950 (53.950)\tLoss 9.2024e+00 (9.2024e+00)\tAcc@1   0.00 (  0.00)\tAcc@5   2.34 (  2.34)\n",
            "Epoch: [3][ 10/537]\tTime  0.229 ( 5.131)\tData  0.010 ( 4.913)\tLoss 9.1972e+00 (9.2000e+00)\tAcc@1   0.78 (  1.21)\tAcc@5   4.69 (  2.91)\n",
            "Epoch: [3][ 20/537]\tTime  0.235 ( 2.827)\tData  0.009 ( 2.613)\tLoss 9.2019e+00 (9.2004e+00)\tAcc@1   1.56 (  1.04)\tAcc@5   1.56 (  2.79)\n",
            "Epoch: [3][ 30/537]\tTime  0.226 ( 2.040)\tData  0.010 ( 1.824)\tLoss 9.2020e+00 (9.2006e+00)\tAcc@1   0.00 (  1.06)\tAcc@5   3.12 (  2.70)\n",
            "Epoch: [3][ 40/537]\tTime  0.222 ( 1.619)\tData  0.009 ( 1.403)\tLoss 9.2025e+00 (9.2006e+00)\tAcc@1   0.78 (  1.09)\tAcc@5   2.34 (  2.69)\n",
            "Epoch: [3][ 50/537]\tTime  0.228 ( 1.365)\tData  0.009 ( 1.151)\tLoss 9.1994e+00 (9.2003e+00)\tAcc@1   0.78 (  1.09)\tAcc@5   1.56 (  2.62)\n",
            "Epoch: [3][ 60/537]\tTime  0.975 ( 1.190)\tData  0.781 ( 0.977)\tLoss 9.1991e+00 (9.2002e+00)\tAcc@1   0.78 (  1.01)\tAcc@5   3.12 (  2.56)\n",
            "Epoch: [3][ 70/537]\tTime  0.217 ( 1.054)\tData  0.000 ( 0.840)\tLoss 9.1995e+00 (9.2001e+00)\tAcc@1   0.78 (  0.96)\tAcc@5   1.56 (  2.52)\n",
            "Epoch: [3][ 80/537]\tTime  0.217 ( 0.961)\tData  0.000 ( 0.748)\tLoss 9.2010e+00 (9.2001e+00)\tAcc@1   0.78 (  0.94)\tAcc@5   0.78 (  2.46)\n",
            "Epoch: [3][ 90/537]\tTime  0.218 ( 0.902)\tData  0.000 ( 0.688)\tLoss 9.1969e+00 (9.2000e+00)\tAcc@1   0.00 (  0.88)\tAcc@5   1.56 (  2.43)\n",
            "Epoch: [3][100/537]\tTime  0.201 ( 0.843)\tData  0.000 ( 0.630)\tLoss 9.1983e+00 (9.1998e+00)\tAcc@1   0.00 (  0.85)\tAcc@5   1.56 (  2.40)\n",
            "Epoch: [3][110/537]\tTime  0.214 ( 0.794)\tData  0.009 ( 0.581)\tLoss 9.1968e+00 (9.1996e+00)\tAcc@1   1.56 (  0.83)\tAcc@5   3.12 (  2.41)\n",
            "Epoch: [3][120/537]\tTime  1.108 ( 0.754)\tData  0.898 ( 0.541)\tLoss 9.1981e+00 (9.1995e+00)\tAcc@1   0.00 (  0.80)\tAcc@5   1.56 (  2.38)\n",
            "Epoch: [3][130/537]\tTime  0.237 ( 0.714)\tData  0.000 ( 0.500)\tLoss 9.1976e+00 (9.1992e+00)\tAcc@1   0.00 (  0.78)\tAcc@5   2.34 (  2.38)\n",
            "Epoch: [3][140/537]\tTime  0.216 ( 0.688)\tData  0.000 ( 0.475)\tLoss 9.1930e+00 (9.1990e+00)\tAcc@1   2.34 (  0.78)\tAcc@5   3.12 (  2.35)\n",
            "Epoch: [3][150/537]\tTime  0.217 ( 0.663)\tData  0.000 ( 0.450)\tLoss 9.1963e+00 (9.1987e+00)\tAcc@1   2.34 (  0.79)\tAcc@5   2.34 (  2.33)\n",
            "Epoch: [3][160/537]\tTime  0.216 ( 0.640)\tData  0.000 ( 0.427)\tLoss 9.1925e+00 (9.1983e+00)\tAcc@1   1.56 (  0.80)\tAcc@5   1.56 (  2.30)\n",
            "Epoch: [3][170/537]\tTime  0.246 ( 0.624)\tData  0.000 ( 0.411)\tLoss 9.1934e+00 (9.1980e+00)\tAcc@1   0.78 (  0.79)\tAcc@5   1.56 (  2.24)\n",
            "Epoch: [3][180/537]\tTime  1.592 ( 0.610)\tData  1.386 ( 0.396)\tLoss 9.1866e+00 (9.1976e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   1.56 (  2.22)\n",
            "Epoch: [3][190/537]\tTime  0.217 ( 0.589)\tData  0.011 ( 0.376)\tLoss 9.1917e+00 (9.1973e+00)\tAcc@1   0.00 (  0.76)\tAcc@5   2.34 (  2.17)\n",
            "Epoch: [3][200/537]\tTime  0.238 ( 0.575)\tData  0.008 ( 0.362)\tLoss 9.1869e+00 (9.1969e+00)\tAcc@1   0.78 (  0.75)\tAcc@5   0.78 (  2.16)\n",
            "Epoch: [3][210/537]\tTime  0.242 ( 0.564)\tData  0.010 ( 0.350)\tLoss 9.1853e+00 (9.1964e+00)\tAcc@1   0.78 (  0.73)\tAcc@5   1.56 (  2.15)\n",
            "Epoch: [3][220/537]\tTime  0.216 ( 0.551)\tData  0.001 ( 0.338)\tLoss 9.1866e+00 (9.1960e+00)\tAcc@1   1.56 (  0.73)\tAcc@5   1.56 (  2.14)\n",
            "Epoch: [3][230/537]\tTime  0.205 ( 0.542)\tData  0.010 ( 0.329)\tLoss 9.1852e+00 (9.1955e+00)\tAcc@1   0.78 (  0.72)\tAcc@5   1.56 (  2.11)\n",
            "Epoch: [3][240/537]\tTime  1.370 ( 0.534)\tData  1.184 ( 0.320)\tLoss 9.1814e+00 (9.1950e+00)\tAcc@1   0.78 (  0.72)\tAcc@5   1.56 (  2.09)\n",
            "Epoch: [3][250/537]\tTime  0.232 ( 0.522)\tData  0.000 ( 0.308)\tLoss 9.1812e+00 (9.1945e+00)\tAcc@1   0.00 (  0.71)\tAcc@5   2.34 (  2.07)\n",
            "Epoch: [3][260/537]\tTime  0.216 ( 0.514)\tData  0.002 ( 0.300)\tLoss 9.1809e+00 (9.1940e+00)\tAcc@1   1.56 (  0.70)\tAcc@5   1.56 (  2.06)\n",
            "Epoch: [3][270/537]\tTime  0.235 ( 0.506)\tData  0.009 ( 0.292)\tLoss 9.1746e+00 (9.1934e+00)\tAcc@1   0.00 (  0.69)\tAcc@5   2.34 (  2.06)\n",
            "Epoch: [3][280/537]\tTime  0.220 ( 0.500)\tData  0.000 ( 0.286)\tLoss 9.1749e+00 (9.1928e+00)\tAcc@1   0.78 (  0.68)\tAcc@5   2.34 (  2.05)\n",
            "Epoch: [3][290/537]\tTime  0.223 ( 0.495)\tData  0.009 ( 0.282)\tLoss 9.1767e+00 (9.1922e+00)\tAcc@1   0.00 (  0.67)\tAcc@5   0.78 (  2.05)\n",
            "Epoch: [3][300/537]\tTime  1.096 ( 0.489)\tData  0.898 ( 0.275)\tLoss 9.1762e+00 (9.1916e+00)\tAcc@1   0.00 (  0.66)\tAcc@5   1.56 (  2.04)\n",
            "Epoch: [3][310/537]\tTime  0.241 ( 0.481)\tData  0.011 ( 0.267)\tLoss 9.1717e+00 (9.1910e+00)\tAcc@1   0.78 (  0.67)\tAcc@5   0.78 (  2.01)\n",
            "Epoch: [3][320/537]\tTime  0.243 ( 0.475)\tData  0.010 ( 0.261)\tLoss 9.1662e+00 (9.1903e+00)\tAcc@1   0.00 (  0.66)\tAcc@5   2.34 (  2.01)\n",
            "Epoch: [3][330/537]\tTime  0.235 ( 0.470)\tData  0.009 ( 0.256)\tLoss 9.1666e+00 (9.1896e+00)\tAcc@1   0.78 (  0.66)\tAcc@5   2.34 (  2.00)\n",
            "Epoch: [3][340/537]\tTime  0.215 ( 0.466)\tData  0.009 ( 0.252)\tLoss 9.1693e+00 (9.1888e+00)\tAcc@1   0.00 (  0.66)\tAcc@5   1.56 (  1.99)\n",
            "Epoch: [3][350/537]\tTime  0.224 ( 0.462)\tData  0.010 ( 0.248)\tLoss 9.1634e+00 (9.1881e+00)\tAcc@1   0.00 (  0.65)\tAcc@5   1.56 (  1.98)\n",
            "Epoch: [3][360/537]\tTime  1.291 ( 0.458)\tData  1.110 ( 0.244)\tLoss 9.1546e+00 (9.1873e+00)\tAcc@1   0.00 (  0.64)\tAcc@5   1.56 (  1.97)\n",
            "Epoch: [3][370/537]\tTime  0.216 ( 0.452)\tData  0.011 ( 0.238)\tLoss 9.1603e+00 (9.1865e+00)\tAcc@1   0.78 (  0.63)\tAcc@5   2.34 (  1.96)\n",
            "Epoch: [3][380/537]\tTime  0.224 ( 0.448)\tData  0.001 ( 0.234)\tLoss 9.1570e+00 (9.1858e+00)\tAcc@1   0.00 (  0.64)\tAcc@5   0.78 (  1.95)\n",
            "Epoch: [3][390/537]\tTime  0.196 ( 0.446)\tData  0.000 ( 0.232)\tLoss 9.1563e+00 (9.1850e+00)\tAcc@1   0.00 (  0.63)\tAcc@5   0.78 (  1.95)\n",
            "Epoch: [3][400/537]\tTime  0.217 ( 0.444)\tData  0.005 ( 0.230)\tLoss 9.1582e+00 (9.1842e+00)\tAcc@1   0.78 (  0.63)\tAcc@5   1.56 (  1.95)\n",
            "Epoch: [3][410/537]\tTime  0.184 ( 0.441)\tData  0.000 ( 0.227)\tLoss 9.1458e+00 (9.1833e+00)\tAcc@1   0.00 (  0.63)\tAcc@5   0.78 (  1.95)\n",
            "Epoch: [3][420/537]\tTime  1.193 ( 0.438)\tData  0.983 ( 0.224)\tLoss 9.1470e+00 (9.1825e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   1.56 (  1.95)\n",
            "Epoch: [3][430/537]\tTime  0.249 ( 0.434)\tData  0.000 ( 0.219)\tLoss 9.1460e+00 (9.1816e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   2.34 (  1.95)\n",
            "Epoch: [3][440/537]\tTime  0.225 ( 0.432)\tData  0.004 ( 0.217)\tLoss 9.1448e+00 (9.1807e+00)\tAcc@1   2.34 (  0.62)\tAcc@5   2.34 (  1.95)\n",
            "Epoch: [3][450/537]\tTime  0.227 ( 0.430)\tData  0.000 ( 0.215)\tLoss 9.1425e+00 (9.1798e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   2.34 (  1.94)\n",
            "Epoch: [3][460/537]\tTime  0.244 ( 0.427)\tData  0.000 ( 0.213)\tLoss 9.1432e+00 (9.1789e+00)\tAcc@1   0.78 (  0.63)\tAcc@5   0.78 (  1.95)\n",
            "Epoch: [3][470/537]\tTime  0.208 ( 0.425)\tData  0.010 ( 0.210)\tLoss 9.1324e+00 (9.1780e+00)\tAcc@1   0.78 (  0.63)\tAcc@5   1.56 (  1.94)\n",
            "Epoch: [3][480/537]\tTime  0.902 ( 0.422)\tData  0.707 ( 0.208)\tLoss 9.1363e+00 (9.1772e+00)\tAcc@1   0.78 (  0.63)\tAcc@5   0.78 (  1.94)\n",
            "Epoch: [3][490/537]\tTime  0.232 ( 0.418)\tData  0.009 ( 0.203)\tLoss 9.1295e+00 (9.1763e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   1.56 (  1.93)\n",
            "Epoch: [3][500/537]\tTime  0.238 ( 0.417)\tData  0.013 ( 0.203)\tLoss 9.1272e+00 (9.1754e+00)\tAcc@1   0.78 (  0.62)\tAcc@5   3.12 (  1.93)\n",
            "Epoch: [3][510/537]\tTime  0.216 ( 0.415)\tData  0.000 ( 0.200)\tLoss 9.1318e+00 (9.1745e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   0.78 (  1.93)\n",
            "Epoch: [3][520/537]\tTime  0.215 ( 0.413)\tData  0.000 ( 0.199)\tLoss 9.1275e+00 (9.1736e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   0.78 (  1.93)\n",
            "Epoch: [3][530/537]\tTime  0.214 ( 0.409)\tData  0.000 ( 0.195)\tLoss 9.1222e+00 (9.1728e+00)\tAcc@1   0.00 (  0.62)\tAcc@5   3.12 (  1.93)\n",
            "epoch: 3\n",
            "2023-03-07 15:00:48.989514: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:48.989614: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:48.989631: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:00:53.077997: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:53.078091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:53.078108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:00:57.181753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:57.181852: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:00:57.181872: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:01.317400: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:01.317505: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:01.317525: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:05.633311: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:05.633415: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:05.633435: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:10.014032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:10.014144: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:10.014163: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:14.227650: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:14.227764: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:14.227783: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:18.297781: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:18.297881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:18.297899: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:22.495143: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:22.495246: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:22.495264: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:26.627106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:26.627211: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:26.627230: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:30.738520: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:30.738619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:30.738637: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:01:34.849108: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:34.849205: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:01:34.849229: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [4][  0/537]\tTime 53.928 (53.928)\tData 53.745 (53.745)\tLoss 9.1201e+00 (9.1201e+00)\tAcc@1   1.56 (  1.56)\tAcc@5   1.56 (  1.56)\n",
            "Epoch: [4][ 10/537]\tTime  0.213 ( 5.157)\tData  0.009 ( 4.944)\tLoss 9.1266e+00 (9.1226e+00)\tAcc@1   1.56 (  0.85)\tAcc@5   1.56 (  2.56)\n",
            "Epoch: [4][ 20/537]\tTime  0.223 ( 2.836)\tData  0.000 ( 2.623)\tLoss 9.1195e+00 (9.1221e+00)\tAcc@1   1.56 (  0.86)\tAcc@5   2.34 (  2.53)\n",
            "Epoch: [4][ 30/537]\tTime  0.218 ( 2.032)\tData  0.009 ( 1.820)\tLoss 9.1153e+00 (9.1215e+00)\tAcc@1   0.00 (  0.73)\tAcc@5   6.25 (  2.70)\n",
            "Epoch: [4][ 40/537]\tTime  0.216 ( 1.616)\tData  0.000 ( 1.404)\tLoss 9.1173e+00 (9.1206e+00)\tAcc@1   1.56 (  0.72)\tAcc@5   5.47 (  3.05)\n",
            "Epoch: [4][ 50/537]\tTime  0.243 ( 1.367)\tData  0.000 ( 1.155)\tLoss 9.1222e+00 (9.1201e+00)\tAcc@1   0.78 (  0.74)\tAcc@5   2.34 (  3.31)\n",
            "Epoch: [4][ 60/537]\tTime  0.531 ( 1.185)\tData  0.329 ( 0.973)\tLoss 9.1168e+00 (9.1191e+00)\tAcc@1   1.56 (  0.81)\tAcc@5   3.91 (  3.45)\n",
            "Epoch: [4][ 70/537]\tTime  0.212 ( 1.060)\tData  0.009 ( 0.848)\tLoss 9.1120e+00 (9.1187e+00)\tAcc@1   0.78 (  0.84)\tAcc@5   7.81 (  3.49)\n",
            "Epoch: [4][ 80/537]\tTime  0.228 ( 0.970)\tData  0.007 ( 0.757)\tLoss 9.1192e+00 (9.1181e+00)\tAcc@1   0.78 (  0.84)\tAcc@5   3.91 (  3.61)\n",
            "Epoch: [4][ 90/537]\tTime  0.222 ( 0.898)\tData  0.005 ( 0.686)\tLoss 9.1146e+00 (9.1176e+00)\tAcc@1   5.47 (  0.88)\tAcc@5   6.25 (  4.22)\n",
            "Epoch: [4][100/537]\tTime  0.207 ( 0.848)\tData  0.000 ( 0.636)\tLoss 9.1134e+00 (9.1170e+00)\tAcc@1   1.56 (  0.89)\tAcc@5   6.25 (  4.71)\n",
            "Epoch: [4][110/537]\tTime  0.232 ( 0.802)\tData  0.009 ( 0.590)\tLoss 9.1086e+00 (9.1166e+00)\tAcc@1   0.78 (  0.94)\tAcc@5   6.25 (  4.86)\n",
            "Epoch: [4][120/537]\tTime  0.210 ( 0.755)\tData  0.000 ( 0.542)\tLoss 9.1092e+00 (9.1161e+00)\tAcc@1   0.00 (  0.98)\tAcc@5   7.81 (  5.14)\n",
            "Epoch: [4][130/537]\tTime  0.222 ( 0.721)\tData  0.000 ( 0.507)\tLoss 9.1067e+00 (9.1156e+00)\tAcc@1   5.47 (  1.02)\tAcc@5  17.19 (  5.52)\n",
            "Epoch: [4][140/537]\tTime  0.222 ( 0.690)\tData  0.000 ( 0.476)\tLoss 9.1155e+00 (9.1153e+00)\tAcc@1   0.00 (  1.10)\tAcc@5   8.59 (  5.93)\n",
            "Epoch: [4][150/537]\tTime  0.227 ( 0.666)\tData  0.009 ( 0.453)\tLoss 9.1116e+00 (9.1150e+00)\tAcc@1   0.00 (  1.30)\tAcc@5   7.81 (  6.36)\n",
            "Epoch: [4][160/537]\tTime  0.220 ( 0.645)\tData  0.000 ( 0.431)\tLoss 9.1101e+00 (9.1148e+00)\tAcc@1   0.78 (  1.32)\tAcc@5  16.41 (  6.74)\n",
            "Epoch: [4][170/537]\tTime  0.222 ( 0.626)\tData  0.009 ( 0.412)\tLoss 9.1129e+00 (9.1146e+00)\tAcc@1   1.56 (  1.32)\tAcc@5   9.38 (  6.96)\n",
            "Epoch: [4][180/537]\tTime  0.226 ( 0.604)\tData  0.009 ( 0.390)\tLoss 9.1140e+00 (9.1145e+00)\tAcc@1   1.56 (  1.38)\tAcc@5  12.50 (  7.23)\n",
            "Epoch: [4][190/537]\tTime  0.216 ( 0.587)\tData  0.000 ( 0.373)\tLoss 9.1109e+00 (9.1143e+00)\tAcc@1   1.56 (  1.39)\tAcc@5  21.09 (  7.53)\n",
            "Epoch: [4][200/537]\tTime  0.216 ( 0.574)\tData  0.000 ( 0.360)\tLoss 9.1103e+00 (9.1142e+00)\tAcc@1   3.91 (  1.46)\tAcc@5  18.75 (  7.93)\n",
            "Epoch: [4][210/537]\tTime  0.237 ( 0.565)\tData  0.010 ( 0.351)\tLoss 9.1139e+00 (9.1141e+00)\tAcc@1   3.12 (  1.49)\tAcc@5  11.72 (  8.14)\n",
            "Epoch: [4][220/537]\tTime  0.230 ( 0.555)\tData  0.009 ( 0.341)\tLoss 9.1117e+00 (9.1141e+00)\tAcc@1   6.25 (  1.56)\tAcc@5  23.44 (  8.46)\n",
            "Epoch: [4][230/537]\tTime  0.234 ( 0.544)\tData  0.000 ( 0.330)\tLoss 9.1144e+00 (9.1142e+00)\tAcc@1   1.56 (  1.69)\tAcc@5  17.97 (  8.89)\n",
            "Epoch: [4][240/537]\tTime  0.223 ( 0.531)\tData  0.009 ( 0.316)\tLoss 9.1168e+00 (9.1143e+00)\tAcc@1   1.56 (  1.74)\tAcc@5  20.31 (  9.11)\n",
            "Epoch: [4][250/537]\tTime  0.259 ( 0.522)\tData  0.000 ( 0.308)\tLoss 9.1169e+00 (9.1144e+00)\tAcc@1   0.78 (  1.78)\tAcc@5  14.84 (  9.32)\n",
            "Epoch: [4][260/537]\tTime  0.237 ( 0.515)\tData  0.000 ( 0.300)\tLoss 9.1186e+00 (9.1146e+00)\tAcc@1   8.59 (  1.85)\tAcc@5  20.31 (  9.66)\n",
            "Epoch: [4][270/537]\tTime  0.222 ( 0.508)\tData  0.011 ( 0.293)\tLoss 9.1199e+00 (9.1148e+00)\tAcc@1   3.12 (  1.93)\tAcc@5  19.53 (  9.88)\n",
            "Epoch: [4][280/537]\tTime  0.230 ( 0.502)\tData  0.000 ( 0.287)\tLoss 9.1243e+00 (9.1150e+00)\tAcc@1   0.00 (  2.04)\tAcc@5   7.03 ( 10.05)\n",
            "Epoch: [4][290/537]\tTime  0.239 ( 0.496)\tData  0.000 ( 0.282)\tLoss 9.1230e+00 (9.1153e+00)\tAcc@1   1.56 (  2.16)\tAcc@5  25.00 ( 10.34)\n",
            "Epoch: [4][300/537]\tTime  0.238 ( 0.487)\tData  0.000 ( 0.273)\tLoss 9.1292e+00 (9.1156e+00)\tAcc@1   0.00 (  2.22)\tAcc@5   4.69 ( 10.62)\n",
            "Epoch: [4][310/537]\tTime  0.215 ( 0.483)\tData  0.000 ( 0.268)\tLoss 9.1280e+00 (9.1160e+00)\tAcc@1   0.00 (  2.25)\tAcc@5  11.72 ( 10.83)\n",
            "Epoch: [4][320/537]\tTime  0.227 ( 0.477)\tData  0.010 ( 0.262)\tLoss 9.1301e+00 (9.1165e+00)\tAcc@1  19.53 (  2.32)\tAcc@5  32.81 ( 11.21)\n",
            "Epoch: [4][330/537]\tTime  0.221 ( 0.472)\tData  0.000 ( 0.257)\tLoss 9.1317e+00 (9.1169e+00)\tAcc@1   0.00 (  2.36)\tAcc@5  17.19 ( 11.47)\n",
            "Epoch: [4][340/537]\tTime  0.220 ( 0.467)\tData  0.000 ( 0.252)\tLoss 9.1354e+00 (9.1174e+00)\tAcc@1   7.81 (  2.47)\tAcc@5  25.00 ( 11.76)\n",
            "Epoch: [4][350/537]\tTime  0.233 ( 0.462)\tData  0.009 ( 0.248)\tLoss 9.1387e+00 (9.1180e+00)\tAcc@1   1.56 (  2.48)\tAcc@5  14.84 ( 11.97)\n",
            "Epoch: [4][360/537]\tTime  0.220 ( 0.456)\tData  0.000 ( 0.241)\tLoss 9.1419e+00 (9.1186e+00)\tAcc@1  16.41 (  2.58)\tAcc@5  30.47 ( 12.22)\n",
            "Epoch: [4][370/537]\tTime  0.246 ( 0.454)\tData  0.000 ( 0.239)\tLoss 9.1408e+00 (9.1193e+00)\tAcc@1   3.12 (  2.71)\tAcc@5  19.53 ( 12.42)\n",
            "Epoch: [4][380/537]\tTime  0.216 ( 0.450)\tData  0.000 ( 0.235)\tLoss 9.1458e+00 (9.1199e+00)\tAcc@1   5.47 (  2.85)\tAcc@5  14.84 ( 12.69)\n",
            "Epoch: [4][390/537]\tTime  0.232 ( 0.447)\tData  0.010 ( 0.231)\tLoss 9.1455e+00 (9.1206e+00)\tAcc@1  25.00 (  2.99)\tAcc@5  50.00 ( 13.03)\n",
            "Epoch: [4][400/537]\tTime  0.236 ( 0.443)\tData  0.000 ( 0.228)\tLoss 9.1496e+00 (9.1214e+00)\tAcc@1   3.12 (  3.07)\tAcc@5  24.22 ( 13.31)\n",
            "Epoch: [4][410/537]\tTime  0.244 ( 0.441)\tData  0.000 ( 0.226)\tLoss 9.1548e+00 (9.1222e+00)\tAcc@1  12.50 (  3.18)\tAcc@5  23.44 ( 13.58)\n",
            "Epoch: [4][420/537]\tTime  0.213 ( 0.436)\tData  0.000 ( 0.221)\tLoss 9.1562e+00 (9.1230e+00)\tAcc@1   0.00 (  3.31)\tAcc@5  29.69 ( 13.93)\n",
            "Epoch: [4][430/537]\tTime  0.222 ( 0.434)\tData  0.000 ( 0.219)\tLoss 9.1608e+00 (9.1238e+00)\tAcc@1   0.78 (  3.42)\tAcc@5  14.84 ( 14.25)\n",
            "Epoch: [4][440/537]\tTime  0.231 ( 0.431)\tData  0.009 ( 0.216)\tLoss 9.1642e+00 (9.1247e+00)\tAcc@1   1.56 (  3.55)\tAcc@5  18.75 ( 14.54)\n",
            "Epoch: [4][450/537]\tTime  0.232 ( 0.429)\tData  0.010 ( 0.213)\tLoss 9.1659e+00 (9.1256e+00)\tAcc@1  21.88 (  3.70)\tAcc@5  38.28 ( 14.91)\n",
            "Epoch: [4][460/537]\tTime  0.253 ( 0.426)\tData  0.013 ( 0.211)\tLoss 9.1703e+00 (9.1265e+00)\tAcc@1  23.44 (  3.82)\tAcc@5  35.94 ( 15.30)\n",
            "Epoch: [4][470/537]\tTime  0.208 ( 0.425)\tData  0.000 ( 0.209)\tLoss 9.1747e+00 (9.1275e+00)\tAcc@1   5.47 (  4.01)\tAcc@5  32.03 ( 15.62)\n",
            "Epoch: [4][480/537]\tTime  0.259 ( 0.421)\tData  0.010 ( 0.205)\tLoss 9.1771e+00 (9.1285e+00)\tAcc@1  10.16 (  4.10)\tAcc@5  41.41 ( 15.93)\n",
            "Epoch: [4][490/537]\tTime  0.226 ( 0.419)\tData  0.000 ( 0.203)\tLoss 9.1821e+00 (9.1296e+00)\tAcc@1  12.50 (  4.21)\tAcc@5  21.88 ( 16.17)\n",
            "Epoch: [4][500/537]\tTime  0.216 ( 0.416)\tData  0.000 ( 0.201)\tLoss 9.1850e+00 (9.1307e+00)\tAcc@1  28.91 (  4.42)\tAcc@5  39.06 ( 16.48)\n",
            "Epoch: [4][510/537]\tTime  0.216 ( 0.415)\tData  0.011 ( 0.199)\tLoss 9.1900e+00 (9.1318e+00)\tAcc@1  16.41 (  4.63)\tAcc@5  25.78 ( 16.79)\n",
            "Epoch: [4][520/537]\tTime  0.216 ( 0.413)\tData  0.000 ( 0.197)\tLoss 9.1926e+00 (9.1329e+00)\tAcc@1   2.34 (  4.80)\tAcc@5  21.09 ( 17.10)\n",
            "Epoch: [4][530/537]\tTime  0.214 ( 0.409)\tData  0.000 ( 0.194)\tLoss 9.1962e+00 (9.1341e+00)\tAcc@1   8.59 (  4.97)\tAcc@5  17.97 ( 17.41)\n",
            "epoch: 4\n",
            "2023-03-07 15:04:29.348441: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:29.348537: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:29.348557: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:33.463894: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:33.464001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:33.464018: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:37.560867: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:37.560984: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:37.561002: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:41.674798: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:41.674897: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:41.674925: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:45.794324: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:45.794409: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:45.794425: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:49.902139: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:49.902252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:49.902271: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:53.978685: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:53.978785: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:53.978803: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:04:58.128468: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:58.128568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:04:58.128587: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:05:02.289793: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:02.289900: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:02.289929: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:05:06.626413: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:06.626512: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:06.626531: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:05:10.982164: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:10.982264: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:10.982287: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:05:15.097568: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:15.097666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:05:15.097684: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [5][  0/537]\tTime 53.722 (53.722)\tData 53.510 (53.510)\tLoss 9.1980e+00 (9.1980e+00)\tAcc@1  17.97 ( 17.97)\tAcc@5  46.09 ( 46.09)\n",
            "Epoch: [5][ 10/537]\tTime  0.216 ( 5.118)\tData  0.000 ( 4.906)\tLoss 9.2018e+00 (9.2006e+00)\tAcc@1  13.28 ( 12.07)\tAcc@5  28.91 ( 35.16)\n",
            "Epoch: [5][ 20/537]\tTime  0.211 ( 2.846)\tData  0.010 ( 2.633)\tLoss 9.2059e+00 (9.2027e+00)\tAcc@1  10.16 ( 12.61)\tAcc@5  40.62 ( 35.08)\n",
            "Epoch: [5][ 30/537]\tTime  0.201 ( 2.028)\tData  0.000 ( 1.817)\tLoss 9.2100e+00 (9.2044e+00)\tAcc@1  19.53 ( 13.16)\tAcc@5  28.12 ( 34.98)\n",
            "Epoch: [5][ 40/537]\tTime  0.223 ( 1.608)\tData  0.010 ( 1.398)\tLoss 9.2127e+00 (9.2062e+00)\tAcc@1  39.84 ( 14.42)\tAcc@5  50.00 ( 35.48)\n",
            "Epoch: [5][ 50/537]\tTime  1.306 ( 1.358)\tData  1.095 ( 1.148)\tLoss 9.2178e+00 (9.2082e+00)\tAcc@1  25.00 ( 14.78)\tAcc@5  41.41 ( 35.39)\n",
            "Epoch: [5][ 60/537]\tTime  0.234 ( 1.172)\tData  0.030 ( 0.961)\tLoss 9.2217e+00 (9.2101e+00)\tAcc@1  17.19 ( 14.49)\tAcc@5  32.03 ( 34.80)\n",
            "Epoch: [5][ 70/537]\tTime  0.212 ( 1.054)\tData  0.000 ( 0.844)\tLoss 9.2243e+00 (9.2119e+00)\tAcc@1  13.28 ( 15.38)\tAcc@5  27.34 ( 35.54)\n",
            "Epoch: [5][ 80/537]\tTime  0.204 ( 0.965)\tData  0.015 ( 0.755)\tLoss 9.2296e+00 (9.2139e+00)\tAcc@1  21.88 ( 15.45)\tAcc@5  34.38 ( 35.54)\n",
            "Epoch: [5][ 90/537]\tTime  0.231 ( 0.894)\tData  0.010 ( 0.684)\tLoss 9.2335e+00 (9.2158e+00)\tAcc@1   7.03 ( 15.63)\tAcc@5  32.81 ( 36.03)\n",
            "Epoch: [5][100/537]\tTime  0.219 ( 0.836)\tData  0.011 ( 0.626)\tLoss 9.2377e+00 (9.2178e+00)\tAcc@1   4.69 ( 15.95)\tAcc@5  34.38 ( 36.49)\n",
            "Epoch: [5][110/537]\tTime  1.319 ( 0.791)\tData  1.093 ( 0.580)\tLoss 9.2419e+00 (9.2198e+00)\tAcc@1  13.28 ( 16.03)\tAcc@5  34.38 ( 36.87)\n",
            "Epoch: [5][120/537]\tTime  0.223 ( 0.744)\tData  0.010 ( 0.532)\tLoss 9.2455e+00 (9.2217e+00)\tAcc@1  13.28 ( 16.48)\tAcc@5  32.81 ( 37.10)\n",
            "Epoch: [5][130/537]\tTime  0.225 ( 0.711)\tData  0.000 ( 0.499)\tLoss 9.2499e+00 (9.2237e+00)\tAcc@1  28.12 ( 16.56)\tAcc@5  32.03 ( 37.12)\n",
            "Epoch: [5][140/537]\tTime  0.225 ( 0.684)\tData  0.001 ( 0.472)\tLoss 9.2516e+00 (9.2256e+00)\tAcc@1  27.34 ( 16.54)\tAcc@5  49.22 ( 37.03)\n",
            "Epoch: [5][150/537]\tTime  0.255 ( 0.660)\tData  0.000 ( 0.447)\tLoss 9.2586e+00 (9.2276e+00)\tAcc@1  10.94 ( 16.47)\tAcc@5  47.66 ( 37.16)\n",
            "Epoch: [5][160/537]\tTime  0.223 ( 0.638)\tData  0.010 ( 0.426)\tLoss 9.2612e+00 (9.2296e+00)\tAcc@1  25.00 ( 16.65)\tAcc@5  50.78 ( 37.37)\n",
            "Epoch: [5][170/537]\tTime  1.392 ( 0.624)\tData  1.156 ( 0.410)\tLoss 9.2657e+00 (9.2316e+00)\tAcc@1  28.91 ( 16.91)\tAcc@5  35.94 ( 37.33)\n",
            "Epoch: [5][180/537]\tTime  0.265 ( 0.602)\tData  0.000 ( 0.388)\tLoss 9.2697e+00 (9.2336e+00)\tAcc@1  32.03 ( 16.97)\tAcc@5  42.97 ( 37.32)\n",
            "Epoch: [5][190/537]\tTime  0.220 ( 0.589)\tData  0.009 ( 0.375)\tLoss 9.2738e+00 (9.2356e+00)\tAcc@1   3.12 ( 16.69)\tAcc@5  31.25 ( 37.25)\n",
            "Epoch: [5][200/537]\tTime  0.226 ( 0.575)\tData  0.005 ( 0.361)\tLoss 9.2779e+00 (9.2376e+00)\tAcc@1  21.88 ( 16.76)\tAcc@5  39.06 ( 37.32)\n",
            "Epoch: [5][210/537]\tTime  0.232 ( 0.563)\tData  0.013 ( 0.349)\tLoss 9.2816e+00 (9.2396e+00)\tAcc@1  13.28 ( 17.03)\tAcc@5  42.19 ( 37.38)\n",
            "Epoch: [5][220/537]\tTime  0.260 ( 0.552)\tData  0.000 ( 0.338)\tLoss 9.2858e+00 (9.2416e+00)\tAcc@1  14.84 ( 17.03)\tAcc@5  39.06 ( 37.37)\n",
            "Epoch: [5][230/537]\tTime  1.310 ( 0.542)\tData  1.130 ( 0.329)\tLoss 9.2895e+00 (9.2436e+00)\tAcc@1  20.31 ( 17.21)\tAcc@5  42.97 ( 37.47)\n",
            "Epoch: [5][240/537]\tTime  0.238 ( 0.530)\tData  0.000 ( 0.316)\tLoss 9.2935e+00 (9.2456e+00)\tAcc@1  42.19 ( 17.42)\tAcc@5  47.66 ( 37.60)\n",
            "Epoch: [5][250/537]\tTime  0.222 ( 0.521)\tData  0.006 ( 0.307)\tLoss 9.2968e+00 (9.2476e+00)\tAcc@1  24.22 ( 17.54)\tAcc@5  35.16 ( 37.56)\n",
            "Epoch: [5][260/537]\tTime  0.215 ( 0.512)\tData  0.010 ( 0.298)\tLoss 9.3011e+00 (9.2497e+00)\tAcc@1  24.22 ( 17.71)\tAcc@5  35.94 ( 37.55)\n",
            "Epoch: [5][270/537]\tTime  0.209 ( 0.505)\tData  0.010 ( 0.291)\tLoss 9.3051e+00 (9.2517e+00)\tAcc@1  20.31 ( 17.76)\tAcc@5  45.31 ( 37.51)\n",
            "Epoch: [5][280/537]\tTime  0.215 ( 0.499)\tData  0.012 ( 0.286)\tLoss 9.3081e+00 (9.2537e+00)\tAcc@1  13.28 ( 17.80)\tAcc@5  29.69 ( 37.35)\n",
            "Epoch: [5][290/537]\tTime  1.342 ( 0.494)\tData  1.145 ( 0.280)\tLoss 9.3140e+00 (9.2557e+00)\tAcc@1  16.41 ( 17.73)\tAcc@5  47.66 ( 37.44)\n",
            "Epoch: [5][300/537]\tTime  0.222 ( 0.485)\tData  0.009 ( 0.272)\tLoss 9.3183e+00 (9.2577e+00)\tAcc@1  15.62 ( 17.91)\tAcc@5  28.91 ( 37.43)\n",
            "Epoch: [5][310/537]\tTime  0.236 ( 0.479)\tData  0.000 ( 0.266)\tLoss 9.3219e+00 (9.2597e+00)\tAcc@1  27.34 ( 17.85)\tAcc@5  39.84 ( 37.30)\n",
            "Epoch: [5][320/537]\tTime  0.204 ( 0.474)\tData  0.004 ( 0.261)\tLoss 9.3258e+00 (9.2617e+00)\tAcc@1  13.28 ( 17.89)\tAcc@5  39.84 ( 37.35)\n",
            "Epoch: [5][330/537]\tTime  0.270 ( 0.471)\tData  0.010 ( 0.257)\tLoss 9.3292e+00 (9.2637e+00)\tAcc@1  20.31 ( 17.81)\tAcc@5  35.94 ( 37.34)\n",
            "Epoch: [5][340/537]\tTime  0.223 ( 0.467)\tData  0.010 ( 0.253)\tLoss 9.3332e+00 (9.2656e+00)\tAcc@1  19.53 ( 17.79)\tAcc@5  28.12 ( 37.31)\n",
            "Epoch: [5][350/537]\tTime  1.066 ( 0.463)\tData  0.883 ( 0.249)\tLoss 9.3363e+00 (9.2676e+00)\tAcc@1  26.56 ( 17.94)\tAcc@5  35.94 ( 37.38)\n",
            "Epoch: [5][360/537]\tTime  0.248 ( 0.457)\tData  0.007 ( 0.242)\tLoss 9.3411e+00 (9.2696e+00)\tAcc@1  17.19 ( 17.97)\tAcc@5  46.88 ( 37.43)\n",
            "Epoch: [5][370/537]\tTime  0.217 ( 0.453)\tData  0.004 ( 0.238)\tLoss 9.3452e+00 (9.2716e+00)\tAcc@1   7.03 ( 18.06)\tAcc@5  43.75 ( 37.52)\n",
            "Epoch: [5][380/537]\tTime  0.219 ( 0.450)\tData  0.009 ( 0.236)\tLoss 9.3488e+00 (9.2736e+00)\tAcc@1   6.25 ( 18.06)\tAcc@5  47.66 ( 37.57)\n",
            "Epoch: [5][390/537]\tTime  0.217 ( 0.446)\tData  0.013 ( 0.232)\tLoss 9.3515e+00 (9.2755e+00)\tAcc@1  23.44 ( 18.16)\tAcc@5  38.28 ( 37.59)\n",
            "Epoch: [5][400/537]\tTime  0.216 ( 0.443)\tData  0.012 ( 0.229)\tLoss 9.3559e+00 (9.2775e+00)\tAcc@1  10.94 ( 18.13)\tAcc@5  32.81 ( 37.58)\n",
            "Epoch: [5][410/537]\tTime  1.164 ( 0.439)\tData  0.946 ( 0.226)\tLoss 9.3600e+00 (9.2795e+00)\tAcc@1  12.50 ( 18.22)\tAcc@5  21.09 ( 37.49)\n",
            "Epoch: [5][420/537]\tTime  0.222 ( 0.434)\tData  0.000 ( 0.220)\tLoss 9.3645e+00 (9.2814e+00)\tAcc@1  17.97 ( 18.26)\tAcc@5  25.00 ( 37.41)\n",
            "Epoch: [5][430/537]\tTime  0.212 ( 0.432)\tData  0.000 ( 0.218)\tLoss 9.3676e+00 (9.2834e+00)\tAcc@1  35.16 ( 18.21)\tAcc@5  41.41 ( 37.33)\n",
            "Epoch: [5][440/537]\tTime  0.240 ( 0.430)\tData  0.009 ( 0.216)\tLoss 9.3711e+00 (9.2853e+00)\tAcc@1  18.75 ( 18.24)\tAcc@5  26.56 ( 37.31)\n",
            "Epoch: [5][450/537]\tTime  0.214 ( 0.428)\tData  0.000 ( 0.214)\tLoss 9.3737e+00 (9.2872e+00)\tAcc@1  15.62 ( 18.19)\tAcc@5  31.25 ( 37.31)\n",
            "Epoch: [5][460/537]\tTime  0.215 ( 0.425)\tData  0.000 ( 0.211)\tLoss 9.3776e+00 (9.2892e+00)\tAcc@1  21.09 ( 18.25)\tAcc@5  34.38 ( 37.28)\n",
            "Epoch: [5][470/537]\tTime  0.767 ( 0.422)\tData  0.572 ( 0.208)\tLoss 9.3820e+00 (9.2911e+00)\tAcc@1   0.78 ( 18.19)\tAcc@5  35.16 ( 37.21)\n",
            "Epoch: [5][480/537]\tTime  0.203 ( 0.418)\tData  0.000 ( 0.204)\tLoss 9.3837e+00 (9.2930e+00)\tAcc@1  16.41 ( 18.19)\tAcc@5  35.94 ( 37.18)\n",
            "Epoch: [5][490/537]\tTime  0.215 ( 0.416)\tData  0.013 ( 0.202)\tLoss 9.3883e+00 (9.2949e+00)\tAcc@1  23.44 ( 18.10)\tAcc@5  42.19 ( 37.13)\n",
            "Epoch: [5][500/537]\tTime  0.210 ( 0.415)\tData  0.000 ( 0.201)\tLoss 9.3916e+00 (9.2968e+00)\tAcc@1   7.03 ( 18.01)\tAcc@5  33.59 ( 37.09)\n",
            "Epoch: [5][510/537]\tTime  0.202 ( 0.413)\tData  0.000 ( 0.199)\tLoss 9.3937e+00 (9.2987e+00)\tAcc@1   6.25 ( 17.99)\tAcc@5  31.25 ( 36.98)\n",
            "Epoch: [5][520/537]\tTime  0.216 ( 0.410)\tData  0.000 ( 0.197)\tLoss 9.3979e+00 (9.3006e+00)\tAcc@1   4.69 ( 17.93)\tAcc@5  46.88 ( 36.96)\n",
            "Epoch: [5][530/537]\tTime  0.230 ( 0.407)\tData  0.065 ( 0.193)\tLoss 9.4015e+00 (9.3024e+00)\tAcc@1  10.94 ( 17.88)\tAcc@5  38.28 ( 36.95)\n",
            "epoch: 5\n",
            "2023-03-07 15:08:08.596643: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:08.596752: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:08.596772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:12.833992: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:12.834091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:12.834110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:16.960902: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:16.961015: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:16.961034: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:21.100158: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:21.100263: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:21.100286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:25.165982: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:25.166076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:25.166093: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:29.270369: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:29.270478: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:29.270503: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:33.384630: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:33.384728: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:33.384745: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:37.501779: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:37.501882: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:37.501901: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:41.593775: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:41.593874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:41.593892: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:45.755959: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:45.756063: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:45.756081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:49.845370: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:49.845470: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:49.845488: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:08:53.921141: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:53.921236: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:08:53.921254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [6][  0/537]\tTime 53.917 (53.917)\tData 53.669 (53.669)\tLoss 9.4043e+00 (9.4043e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  32.81 ( 32.81)\n",
            "Epoch: [6][ 10/537]\tTime  0.230 ( 5.112)\tData  0.010 ( 4.890)\tLoss 9.4088e+00 (9.4062e+00)\tAcc@1  29.69 ( 16.12)\tAcc@5  43.75 ( 36.36)\n",
            "Epoch: [6][ 20/537]\tTime  0.229 ( 2.844)\tData  0.000 ( 2.625)\tLoss 9.4109e+00 (9.4077e+00)\tAcc@1  29.69 ( 18.34)\tAcc@5  39.84 ( 36.64)\n",
            "Epoch: [6][ 30/537]\tTime  0.214 ( 2.025)\tData  0.010 ( 1.806)\tLoss 9.4142e+00 (9.4092e+00)\tAcc@1  22.66 ( 18.83)\tAcc@5  32.81 ( 36.42)\n",
            "Epoch: [6][ 40/537]\tTime  0.213 ( 1.618)\tData  0.000 ( 1.401)\tLoss 9.4176e+00 (9.4109e+00)\tAcc@1   5.47 ( 17.74)\tAcc@5  35.16 ( 36.17)\n",
            "Epoch: [6][ 50/537]\tTime  0.237 ( 1.368)\tData  0.005 ( 1.150)\tLoss 9.4205e+00 (9.4124e+00)\tAcc@1  12.50 ( 17.72)\tAcc@5  32.81 ( 35.74)\n",
            "Epoch: [6][ 60/537]\tTime  0.226 ( 1.181)\tData  0.000 ( 0.963)\tLoss 9.4240e+00 (9.4140e+00)\tAcc@1  28.12 ( 17.74)\tAcc@5  42.19 ( 35.07)\n",
            "Epoch: [6][ 70/537]\tTime  0.264 ( 1.059)\tData  0.013 ( 0.841)\tLoss 9.4266e+00 (9.4155e+00)\tAcc@1   5.47 ( 16.95)\tAcc@5  30.47 ( 34.60)\n",
            "Epoch: [6][ 80/537]\tTime  0.223 ( 0.967)\tData  0.010 ( 0.750)\tLoss 9.4300e+00 (9.4170e+00)\tAcc@1   3.91 ( 16.94)\tAcc@5  21.88 ( 34.75)\n",
            "Epoch: [6][ 90/537]\tTime  0.245 ( 0.896)\tData  0.013 ( 0.680)\tLoss 9.4337e+00 (9.4185e+00)\tAcc@1  28.12 ( 16.77)\tAcc@5  35.94 ( 34.58)\n",
            "Epoch: [6][100/537]\tTime  0.223 ( 0.838)\tData  0.001 ( 0.622)\tLoss 9.4358e+00 (9.4201e+00)\tAcc@1   7.81 ( 16.54)\tAcc@5  29.69 ( 34.58)\n",
            "Epoch: [6][110/537]\tTime  0.615 ( 0.795)\tData  0.400 ( 0.580)\tLoss 9.4376e+00 (9.4215e+00)\tAcc@1  10.94 ( 16.74)\tAcc@5  26.56 ( 34.52)\n",
            "Epoch: [6][120/537]\tTime  0.256 ( 0.748)\tData  0.000 ( 0.532)\tLoss 9.4410e+00 (9.4230e+00)\tAcc@1  17.19 ( 16.71)\tAcc@5  32.03 ( 34.46)\n",
            "Epoch: [6][130/537]\tTime  0.229 ( 0.715)\tData  0.000 ( 0.500)\tLoss 9.4438e+00 (9.4246e+00)\tAcc@1   9.38 ( 16.47)\tAcc@5  40.62 ( 34.42)\n",
            "Epoch: [6][140/537]\tTime  0.226 ( 0.687)\tData  0.000 ( 0.472)\tLoss 9.4465e+00 (9.4261e+00)\tAcc@1  14.84 ( 16.46)\tAcc@5  33.59 ( 34.35)\n",
            "Epoch: [6][150/537]\tTime  0.218 ( 0.665)\tData  0.000 ( 0.450)\tLoss 9.4496e+00 (9.4275e+00)\tAcc@1  10.94 ( 16.40)\tAcc@5  22.66 ( 34.19)\n",
            "Epoch: [6][160/537]\tTime  0.240 ( 0.647)\tData  0.005 ( 0.432)\tLoss 9.4516e+00 (9.4290e+00)\tAcc@1  20.31 ( 16.33)\tAcc@5  36.72 ( 34.18)\n",
            "Epoch: [6][170/537]\tTime  1.243 ( 0.628)\tData  1.046 ( 0.413)\tLoss 9.4556e+00 (9.4305e+00)\tAcc@1  12.50 ( 16.25)\tAcc@5  28.91 ( 33.96)\n",
            "Epoch: [6][180/537]\tTime  0.233 ( 0.606)\tData  0.009 ( 0.391)\tLoss 9.4570e+00 (9.4319e+00)\tAcc@1   7.81 ( 16.24)\tAcc@5  34.38 ( 33.86)\n",
            "Epoch: [6][190/537]\tTime  0.246 ( 0.591)\tData  0.013 ( 0.376)\tLoss 9.4610e+00 (9.4333e+00)\tAcc@1   0.00 ( 16.22)\tAcc@5  32.03 ( 33.86)\n",
            "Epoch: [6][200/537]\tTime  0.235 ( 0.577)\tData  0.001 ( 0.362)\tLoss 9.4638e+00 (9.4348e+00)\tAcc@1   1.56 ( 16.36)\tAcc@5  30.47 ( 33.96)\n",
            "Epoch: [6][210/537]\tTime  0.252 ( 0.567)\tData  0.009 ( 0.352)\tLoss 9.4654e+00 (9.4362e+00)\tAcc@1   9.38 ( 16.41)\tAcc@5  27.34 ( 34.04)\n",
            "Epoch: [6][220/537]\tTime  0.196 ( 0.556)\tData  0.000 ( 0.341)\tLoss 9.4690e+00 (9.4377e+00)\tAcc@1  25.78 ( 16.57)\tAcc@5  34.38 ( 33.95)\n",
            "Epoch: [6][230/537]\tTime  1.081 ( 0.546)\tData  0.870 ( 0.331)\tLoss 9.4724e+00 (9.4391e+00)\tAcc@1   4.69 ( 16.31)\tAcc@5  14.06 ( 33.68)\n",
            "Epoch: [6][240/537]\tTime  0.235 ( 0.532)\tData  0.005 ( 0.317)\tLoss 9.4735e+00 (9.4405e+00)\tAcc@1  14.06 ( 16.25)\tAcc@5  25.78 ( 33.66)\n",
            "Epoch: [6][250/537]\tTime  0.229 ( 0.523)\tData  0.000 ( 0.308)\tLoss 9.4762e+00 (9.4418e+00)\tAcc@1  16.41 ( 16.29)\tAcc@5  39.06 ( 33.63)\n",
            "Epoch: [6][260/537]\tTime  0.222 ( 0.516)\tData  0.010 ( 0.301)\tLoss 9.4802e+00 (9.4432e+00)\tAcc@1  23.44 ( 16.37)\tAcc@5  36.72 ( 33.51)\n",
            "Epoch: [6][270/537]\tTime  0.221 ( 0.508)\tData  0.009 ( 0.293)\tLoss 9.4807e+00 (9.4446e+00)\tAcc@1  11.72 ( 16.18)\tAcc@5  28.12 ( 33.30)\n",
            "Epoch: [6][280/537]\tTime  0.222 ( 0.501)\tData  0.000 ( 0.286)\tLoss 9.4838e+00 (9.4460e+00)\tAcc@1   7.03 ( 16.10)\tAcc@5  38.28 ( 33.21)\n",
            "Epoch: [6][290/537]\tTime  1.112 ( 0.495)\tData  0.912 ( 0.279)\tLoss 9.4874e+00 (9.4473e+00)\tAcc@1  15.62 ( 15.94)\tAcc@5  29.69 ( 33.07)\n",
            "Epoch: [6][300/537]\tTime  0.220 ( 0.486)\tData  0.001 ( 0.270)\tLoss 9.4896e+00 (9.4487e+00)\tAcc@1  12.50 ( 15.94)\tAcc@5  28.91 ( 32.97)\n",
            "Epoch: [6][310/537]\tTime  0.271 ( 0.481)\tData  0.000 ( 0.266)\tLoss 9.4924e+00 (9.4500e+00)\tAcc@1  21.09 ( 15.96)\tAcc@5  31.25 ( 33.03)\n",
            "Epoch: [6][320/537]\tTime  0.223 ( 0.476)\tData  0.010 ( 0.260)\tLoss 9.4946e+00 (9.4514e+00)\tAcc@1  14.84 ( 16.02)\tAcc@5  32.81 ( 33.00)\n",
            "Epoch: [6][330/537]\tTime  0.222 ( 0.470)\tData  0.009 ( 0.255)\tLoss 9.4962e+00 (9.4527e+00)\tAcc@1  18.75 ( 16.03)\tAcc@5  35.94 ( 33.01)\n",
            "Epoch: [6][340/537]\tTime  0.230 ( 0.466)\tData  0.009 ( 0.250)\tLoss 9.5025e+00 (9.4541e+00)\tAcc@1  15.62 ( 15.98)\tAcc@5  33.59 ( 32.90)\n",
            "Epoch: [6][350/537]\tTime  0.965 ( 0.461)\tData  0.786 ( 0.246)\tLoss 9.5021e+00 (9.4555e+00)\tAcc@1  17.19 ( 16.03)\tAcc@5  27.34 ( 32.87)\n",
            "Epoch: [6][360/537]\tTime  0.216 ( 0.454)\tData  0.000 ( 0.239)\tLoss 9.5072e+00 (9.4568e+00)\tAcc@1  19.53 ( 15.92)\tAcc@5  38.28 ( 32.78)\n",
            "Epoch: [6][370/537]\tTime  0.210 ( 0.451)\tData  0.009 ( 0.236)\tLoss 9.5080e+00 (9.4582e+00)\tAcc@1   7.03 ( 15.93)\tAcc@5  23.44 ( 32.79)\n",
            "Epoch: [6][380/537]\tTime  0.231 ( 0.449)\tData  0.000 ( 0.233)\tLoss 9.5104e+00 (9.4595e+00)\tAcc@1  18.75 ( 15.95)\tAcc@5  33.59 ( 32.72)\n",
            "Epoch: [6][390/537]\tTime  0.224 ( 0.444)\tData  0.010 ( 0.229)\tLoss 9.5140e+00 (9.4609e+00)\tAcc@1   2.34 ( 15.80)\tAcc@5  29.69 ( 32.65)\n",
            "Epoch: [6][400/537]\tTime  0.231 ( 0.441)\tData  0.000 ( 0.225)\tLoss 9.5172e+00 (9.4622e+00)\tAcc@1   6.25 ( 15.73)\tAcc@5  17.97 ( 32.59)\n",
            "Epoch: [6][410/537]\tTime  1.505 ( 0.439)\tData  1.316 ( 0.224)\tLoss 9.5183e+00 (9.4636e+00)\tAcc@1  16.41 ( 15.70)\tAcc@5  34.38 ( 32.60)\n",
            "Epoch: [6][420/537]\tTime  0.243 ( 0.434)\tData  0.000 ( 0.219)\tLoss 9.5198e+00 (9.4650e+00)\tAcc@1  14.06 ( 15.64)\tAcc@5  36.72 ( 32.60)\n",
            "Epoch: [6][430/537]\tTime  0.199 ( 0.432)\tData  0.009 ( 0.217)\tLoss 9.5266e+00 (9.4664e+00)\tAcc@1  13.28 ( 15.57)\tAcc@5  26.56 ( 32.51)\n",
            "Epoch: [6][440/537]\tTime  0.226 ( 0.429)\tData  0.013 ( 0.214)\tLoss 9.5299e+00 (9.4677e+00)\tAcc@1  12.50 ( 15.57)\tAcc@5  27.34 ( 32.47)\n",
            "Epoch: [6][450/537]\tTime  0.231 ( 0.426)\tData  0.009 ( 0.211)\tLoss 9.5304e+00 (9.4691e+00)\tAcc@1  17.97 ( 15.45)\tAcc@5  29.69 ( 32.42)\n",
            "Epoch: [6][460/537]\tTime  0.218 ( 0.424)\tData  0.006 ( 0.209)\tLoss 9.5350e+00 (9.4705e+00)\tAcc@1  17.97 ( 15.39)\tAcc@5  28.12 ( 32.34)\n",
            "Epoch: [6][470/537]\tTime  1.515 ( 0.422)\tData  1.310 ( 0.207)\tLoss 9.5382e+00 (9.4719e+00)\tAcc@1  10.16 ( 15.33)\tAcc@5  32.03 ( 32.26)\n",
            "Epoch: [6][480/537]\tTime  0.232 ( 0.418)\tData  0.008 ( 0.203)\tLoss 9.5409e+00 (9.4733e+00)\tAcc@1  10.16 ( 15.21)\tAcc@5  23.44 ( 32.17)\n",
            "Epoch: [6][490/537]\tTime  0.237 ( 0.416)\tData  0.000 ( 0.201)\tLoss 9.5458e+00 (9.4748e+00)\tAcc@1   6.25 ( 15.18)\tAcc@5  25.78 ( 32.13)\n",
            "Epoch: [6][500/537]\tTime  0.236 ( 0.414)\tData  0.000 ( 0.199)\tLoss 9.5440e+00 (9.4762e+00)\tAcc@1  23.44 ( 15.12)\tAcc@5  33.59 ( 32.05)\n",
            "Epoch: [6][510/537]\tTime  0.217 ( 0.412)\tData  0.000 ( 0.197)\tLoss 9.5503e+00 (9.4776e+00)\tAcc@1  19.53 ( 15.07)\tAcc@5  28.91 ( 31.97)\n",
            "Epoch: [6][520/537]\tTime  0.217 ( 0.410)\tData  0.000 ( 0.195)\tLoss 9.5535e+00 (9.4791e+00)\tAcc@1  14.06 ( 14.97)\tAcc@5  28.91 ( 31.83)\n",
            "Epoch: [6][530/537]\tTime  0.214 ( 0.406)\tData  0.039 ( 0.191)\tLoss 9.5587e+00 (9.4806e+00)\tAcc@1  14.84 ( 14.94)\tAcc@5  29.69 ( 31.71)\n",
            "epoch: 6\n",
            "2023-03-07 15:11:47.275713: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:47.275811: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:47.275831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:11:51.445000: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:51.445091: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:51.445110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:11:55.603106: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:55.603213: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:55.603232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:11:59.689333: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:59.689439: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:11:59.689458: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:03.942736: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:03.942840: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:03.942860: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:08.299133: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:08.299252: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:08.299273: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:12.544463: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:12.544556: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:12.544573: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:16.649708: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:16.649806: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:16.649824: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:20.787518: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:20.787615: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:20.787633: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:24.909932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:24.910039: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:24.910056: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:28.991497: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:28.991600: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:28.991618: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 15:12:33.146806: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:33.146932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 15:12:33.146953: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Epoch: [7][  0/537]\tTime 54.040 (54.040)\tData 53.820 (53.820)\tLoss 9.5637e+00 (9.5637e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  28.91 ( 28.91)\n",
            "Epoch: [7][ 10/537]\tTime  0.216 ( 5.124)\tData  0.000 ( 4.913)\tLoss 9.5664e+00 (9.5644e+00)\tAcc@1  11.72 ( 12.57)\tAcc@5  24.22 ( 26.49)\n",
            "Epoch: [7][ 20/537]\tTime  0.223 ( 2.848)\tData  0.012 ( 2.639)\tLoss 9.5646e+00 (9.5653e+00)\tAcc@1  10.16 ( 11.24)\tAcc@5  17.97 ( 25.82)\n",
            "Epoch: [7][ 30/537]\tTime  0.242 ( 2.032)\tData  0.005 ( 1.822)\tLoss 9.5638e+00 (9.5670e+00)\tAcc@1  22.66 ( 12.55)\tAcc@5  40.62 ( 26.39)\n",
            "Epoch: [7][ 40/537]\tTime  0.231 ( 1.623)\tData  0.010 ( 1.413)\tLoss 9.5797e+00 (9.5684e+00)\tAcc@1   5.47 ( 12.29)\tAcc@5  17.97 ( 26.11)\n",
            "Epoch: [7][ 50/537]\tTime  0.222 ( 1.364)\tData  0.010 ( 1.154)\tLoss 9.5765e+00 (9.5704e+00)\tAcc@1  14.06 ( 11.86)\tAcc@5  30.47 ( 25.58)\n",
            "Epoch: [7][ 60/537]\tTime  1.053 ( 1.191)\tData  0.866 ( 0.980)\tLoss 9.5851e+00 (9.5723e+00)\tAcc@1   5.47 ( 11.64)\tAcc@5  18.75 ( 24.85)\n",
            "Epoch: [7][ 70/537]\tTime  0.200 ( 1.054)\tData  0.010 ( 0.844)\tLoss 9.5919e+00 (9.5743e+00)\tAcc@1  11.72 ( 11.28)\tAcc@5  19.53 ( 24.42)\n",
            "Epoch: [7][ 80/537]\tTime  0.212 ( 0.964)\tData  0.004 ( 0.753)\tLoss 9.5900e+00 (9.5762e+00)\tAcc@1   6.25 ( 11.10)\tAcc@5  21.88 ( 24.11)\n",
            "Epoch: [7][ 90/537]\tTime  0.216 ( 0.901)\tData  0.010 ( 0.690)\tLoss 9.5970e+00 (9.5783e+00)\tAcc@1   9.38 ( 10.68)\tAcc@5  19.53 ( 23.49)\n",
            "Epoch: [7][100/537]\tTime  0.229 ( 0.843)\tData  0.009 ( 0.632)\tLoss 9.6032e+00 (9.5803e+00)\tAcc@1   6.25 ( 10.39)\tAcc@5  19.53 ( 23.09)\n",
            "Epoch: [7][110/537]\tTime  0.235 ( 0.795)\tData  0.010 ( 0.584)\tLoss 9.5915e+00 (9.5821e+00)\tAcc@1  12.50 ( 10.05)\tAcc@5  25.00 ( 22.75)\n",
            "Epoch: [7][120/537]\tTime  1.503 ( 0.758)\tData  1.315 ( 0.547)\tLoss 9.6081e+00 (9.5841e+00)\tAcc@1  11.72 (  9.93)\tAcc@5  25.00 ( 22.51)\n",
            "Epoch: [7][130/537]\tTime  0.221 ( 0.717)\tData  0.000 ( 0.506)\tLoss 9.6092e+00 (9.5859e+00)\tAcc@1   0.78 (  9.61)\tAcc@5  17.97 ( 22.08)\n",
            "Epoch: [7][140/537]\tTime  0.206 ( 0.690)\tData  0.000 ( 0.479)\tLoss 9.6218e+00 (9.5879e+00)\tAcc@1   1.56 (  9.30)\tAcc@5  12.50 ( 21.58)\n",
            "Epoch: [7][150/537]\tTime  0.234 ( 0.667)\tData  0.009 ( 0.456)\tLoss 9.6206e+00 (9.5897e+00)\tAcc@1   7.03 (  9.07)\tAcc@5  16.41 ( 21.27)\n",
            "Epoch: [7][160/537]\tTime  0.217 ( 0.644)\tData  0.000 ( 0.433)\tLoss 9.6277e+00 (9.5919e+00)\tAcc@1   7.03 (  8.86)\tAcc@5  14.84 ( 20.96)\n",
            "Epoch: [7][170/537]\tTime  0.219 ( 0.624)\tData  0.005 ( 0.412)\tLoss 9.6194e+00 (9.5934e+00)\tAcc@1   5.47 (  8.66)\tAcc@5  10.16 ( 20.70)\n",
            "Epoch: [7][180/537]\tTime  1.324 ( 0.608)\tData  1.134 ( 0.396)\tLoss 9.6433e+00 (9.5955e+00)\tAcc@1   6.25 (  8.51)\tAcc@5  14.06 ( 20.29)\n",
            "Epoch: [7][190/537]\tTime  0.213 ( 0.588)\tData  0.000 ( 0.376)\tLoss 9.6268e+00 (9.5975e+00)\tAcc@1   7.03 (  8.35)\tAcc@5  20.31 ( 19.93)\n",
            "Epoch: [7][200/537]\tTime  0.230 ( 0.574)\tData  0.009 ( 0.363)\tLoss 9.6358e+00 (9.5992e+00)\tAcc@1   6.25 (  8.17)\tAcc@5   8.59 ( 19.54)\n",
            "Epoch: [7][210/537]\tTime  0.238 ( 0.562)\tData  0.008 ( 0.350)\tLoss 9.6232e+00 (9.6009e+00)\tAcc@1   4.69 (  7.97)\tAcc@5  11.72 ( 19.14)\n",
            "Epoch: [7][220/537]\tTime  0.201 ( 0.552)\tData  0.010 ( 0.341)\tLoss 9.6411e+00 (9.6025e+00)\tAcc@1   3.91 (  7.82)\tAcc@5  10.94 ( 18.80)\n",
            "Epoch: [7][230/537]\tTime  0.217 ( 0.544)\tData  0.000 ( 0.332)\tLoss 9.6549e+00 (9.6043e+00)\tAcc@1   3.12 (  7.66)\tAcc@5  10.16 ( 18.49)\n",
            "Epoch: [7][240/537]\tTime  1.580 ( 0.536)\tData  1.370 ( 0.325)\tLoss 9.6414e+00 (9.6057e+00)\tAcc@1   2.34 (  7.48)\tAcc@5   9.38 ( 18.22)\n",
            "Epoch: [7][250/537]\tTime  0.230 ( 0.524)\tData  0.000 ( 0.312)\tLoss 9.6344e+00 (9.6073e+00)\tAcc@1   7.81 (  7.35)\tAcc@5  14.06 ( 17.88)\n",
            "Epoch: [7][260/537]\tTime  0.232 ( 0.516)\tData  0.009 ( 0.304)\tLoss 9.6398e+00 (9.6089e+00)\tAcc@1   0.78 (  7.20)\tAcc@5   7.03 ( 17.53)\n",
            "Epoch: [7][270/537]\tTime  0.241 ( 0.509)\tData  0.000 ( 0.297)\tLoss 9.6400e+00 (9.6104e+00)\tAcc@1   7.03 (  7.07)\tAcc@5  10.16 ( 17.20)\n",
            "Epoch: [7][280/537]\tTime  0.217 ( 0.502)\tData  0.000 ( 0.290)\tLoss 9.6263e+00 (9.6119e+00)\tAcc@1   6.25 (  6.93)\tAcc@5  14.06 ( 16.92)\n",
            "Epoch: [7][290/537]\tTime  0.237 ( 0.496)\tData  0.000 ( 0.284)\tLoss 9.6874e+00 (9.6133e+00)\tAcc@1   0.78 (  6.79)\tAcc@5   2.34 ( 16.64)\n",
            "Epoch: [7][300/537]\tTime  1.121 ( 0.490)\tData  0.936 ( 0.278)\tLoss 9.6479e+00 (9.6145e+00)\tAcc@1   1.56 (  6.62)\tAcc@5  10.16 ( 16.32)\n",
            "Epoch: [7][310/537]\tTime  0.227 ( 0.482)\tData  0.000 ( 0.269)\tLoss 9.6799e+00 (9.6159e+00)\tAcc@1   1.56 (  6.49)\tAcc@5   3.91 ( 16.00)\n",
            "Epoch: [7][320/537]\tTime  0.219 ( 0.477)\tData  0.010 ( 0.264)\tLoss 9.6577e+00 (9.6172e+00)\tAcc@1   3.91 (  6.35)\tAcc@5   6.25 ( 15.72)\n",
            "Epoch: [7][330/537]\tTime  0.236 ( 0.472)\tData  0.000 ( 0.259)\tLoss 9.6292e+00 (9.6184e+00)\tAcc@1   3.91 (  6.26)\tAcc@5  12.50 ( 15.54)\n",
            "Epoch: [7][340/537]\tTime  0.220 ( 0.468)\tData  0.000 ( 0.255)\tLoss 9.6870e+00 (9.6197e+00)\tAcc@1   2.34 (  6.15)\tAcc@5   3.91 ( 15.29)\n",
            "Epoch: [7][350/537]\tTime  0.218 ( 0.464)\tData  0.000 ( 0.251)\tLoss 9.6765e+00 (9.6210e+00)\tAcc@1   0.78 (  6.03)\tAcc@5   3.12 ( 15.04)\n",
            "Epoch: [7][360/537]\tTime  1.119 ( 0.460)\tData  0.873 ( 0.247)\tLoss 9.6927e+00 (9.6220e+00)\tAcc@1   0.78 (  5.91)\tAcc@5   3.91 ( 14.82)\n",
            "Epoch: [7][370/537]\tTime  0.210 ( 0.453)\tData  0.009 ( 0.240)\tLoss 9.6594e+00 (9.6234e+00)\tAcc@1   2.34 (  5.80)\tAcc@5   7.81 ( 14.56)\n",
            "Epoch: [7][380/537]\tTime  0.243 ( 0.450)\tData  0.004 ( 0.237)\tLoss 9.6505e+00 (9.6245e+00)\tAcc@1   0.78 (  5.69)\tAcc@5   3.91 ( 14.33)\n",
            "Epoch: [7][390/537]\tTime  0.259 ( 0.446)\tData  0.013 ( 0.233)\tLoss 9.6548e+00 (9.6259e+00)\tAcc@1   3.12 (  5.59)\tAcc@5   5.47 ( 14.11)\n",
            "Epoch: [7][400/537]\tTime  0.216 ( 0.443)\tData  0.009 ( 0.230)\tLoss 9.6561e+00 (9.6268e+00)\tAcc@1   0.00 (  5.48)\tAcc@5   3.12 ( 13.89)\n",
            "Epoch: [7][410/537]\tTime  0.223 ( 0.441)\tData  0.009 ( 0.227)\tLoss 9.6508e+00 (9.6277e+00)\tAcc@1   3.12 (  5.38)\tAcc@5   6.25 ( 13.68)\n",
            "Epoch: [7][420/537]\tTime  1.124 ( 0.437)\tData  0.944 ( 0.224)\tLoss 9.6864e+00 (9.6287e+00)\tAcc@1   0.78 (  5.28)\tAcc@5   2.34 ( 13.45)\n",
            "Epoch: [7][430/537]\tTime  0.223 ( 0.433)\tData  0.000 ( 0.219)\tLoss 9.6894e+00 (9.6297e+00)\tAcc@1   0.00 (  5.19)\tAcc@5   5.47 ( 13.25)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 441, in <module>\n",
            "    main()\n",
            "  File \"/content/Master_Thesis/main_moco.py\", line 143, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 109, in join\n",
            "    ready = multiprocessing.connection.wait(\n",
            "  File \"/usr/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.8/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt\n",
            "Error in atexit._run_exitfuncs:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/matplotlib/_pylab_helpers.py\", line 92, in destroy_all\n",
            "    gc.collect(1)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Master_Thesis/main_lincls.py \\\n",
        "  --lr 30.0 \\\n",
        "  --batch-size 256 \\\n",
        "  --pretrained /content/drive/MyDrive/checkpoint_0019.pth.tar \\\n",
        "  --dist-url 'tcp://localhost:10001' --multiprocessing-distributed --world-size 1 --rank 0 \\"
      ],
      "metadata": {
        "id": "W2zR7dEjZnlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6c2451d-a9dc-41de-84ef-6efb52abf2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-03-07 10:31:19.340027: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-07 10:31:19.498040: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-03-07 10:31:20.281473: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:31:20.281596: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:31:20.281616: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:31:24.908593: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:31:24.908698: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:31:24.908717: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "Use GPU: 0 for training\n",
            "=> creating model 'resnet50'\n",
            "=> loading checkpoint '/content/drive/MyDrive/checkpoint_0019.pth.tar'\n",
            "=> loaded pre-trained model '/content/drive/MyDrive/checkpoint_0019.pth.tar'\n",
            "2023-03-07 10:40:08.554909: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:08.555001: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:08.555019: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:12.634704: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:12.634812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:12.634831: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:16.707165: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:16.707271: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:16.707290: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:20.723337: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:20.723444: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:20.723462: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:24.776663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:24.776759: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:24.776777: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:28.830616: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:28.830709: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:28.830727: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:32.872033: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:32.872136: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:32.872154: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:36.914162: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:36.914258: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:36.914277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:40.961395: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:40.961524: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:40.961544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:44.991848: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:44.991942: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:44.991961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:49.029047: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:49.029145: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:49.029164: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "2023-03-07 10:40:53.095027: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:53.095138: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2023-03-07 10:40:53.095158: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "torch.Size([256, 1000])\n",
            "torch.Size([256])\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "../aten/src/ATen/native/cuda/Loss.cu:242: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Master_Thesis/main_lincls.py\", line 670, in <module>\n",
            "    main()\n",
            "  File \"/content/Master_Thesis/main_lincls.py\", line 200, in main\n",
            "    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 240, in spawn\n",
            "    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 198, in start_processes\n",
            "    while not context.join():\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 160, in join\n",
            "    raise ProcessRaisedException(msg, error_index, failed_process.pid)\n",
            "torch.multiprocessing.spawn.ProcessRaisedException: \n",
            "\n",
            "-- Process 0 terminated with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/multiprocessing/spawn.py\", line 69, in _wrap\n",
            "    fn(i, *args)\n",
            "  File \"/content/Master_Thesis/main_lincls.py\", line 442, in main_worker\n",
            "    train(train_loader, model, criterion, optimizer, epoch, args)\n",
            "  File \"/content/Master_Thesis/main_lincls.py\", line 512, in train\n",
            "    loss.backward()\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\", line 488, in backward\n",
            "    torch.autograd.backward(\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\", line 197, in backward\n",
            "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
            "RuntimeError: CUDA error: device-side assert triggered\n",
            "CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\n",
            "For debugging consider passing CUDA_LAUNCH_BLOCKING=1.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchvision\n",
        "!pip install --upgrade -U torchvision -f https://data.pyg.org/whl/torch-0.14.2+cu117.html\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uu2JYzjWm-5A",
        "outputId": "ebe00283-914f-4117-c8f3-7f91beed4443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torchvision 0.14.1+cu116\n",
            "Uninstalling torchvision-0.14.1+cu116:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision-0.14.1+cu116.dist-info/*\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libcudart.a44f4c9b.so.11.0\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libjpeg.ceea7512.so.62\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libnvjpeg.5afee195.so.11\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libpng16.7f72a3c5.so.16\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision.libs/libz.1328edc3.so.1\n",
            "    /usr/local/lib/python3.8/dist-packages/torchvision/*\n",
            "Proceed (Y/n)? Y\n",
            "  Successfully uninstalled torchvision-0.14.1+cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-0.14.2+cu117.html\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.14.1-cp38-cp38-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (8.4.0)\n",
            "Requirement already satisfied: torch==1.13.1 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.22.4)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.1->torchvision) (11.7.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1->torchvision) (57.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.26.14)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.14.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "cv34I957tbJw",
        "outputId": "834a24e8-6180-4904-abd7-500be44fa7a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-3882461a2f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'torchvision' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9yRYFma1cJ8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pylab as plt\n",
        "import numpy as np\n",
        "import h5py\n",
        "from PIL import Image\n",
        "\n",
        "f = h5py.File('/content/drive/MyDrive/train_test_2016-2019_input-length_12_img-ahead_6_rain-threshhold_50.h5', \"r\")\n",
        "traindir = f['/train/images']\n",
        "print(traindir.shape)\n",
        "test = np.reshape(traindir[0][17:], (288,288))\n",
        "test = test*10000\n",
        "\n",
        "image = Image.fromarray(np.uint8(test))\n",
        "image.save(\"test.jpeg\")\n",
        "image.open(\"test.jpeg\")\n",
        "plt.imshow(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "BNKWPapwnmnY",
        "outputId": "5045f5d6-6605-4719-90df-b58019f1c6c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5734, 18, 288, 288)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f420d2f0310>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push https://github.com/tamarasessink/Master_Thesis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86UtcR9SxL7G",
        "outputId": "4a009a2d-b88b-4421-e18c-e719b9529313"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "# after agmentation\n",
        "image = Image.fromarray(np.uint8(test))\n",
        "\n",
        "transform = transforms.RandomHorizontalFlip(p=0.8)\n",
        "img = transform(image)\n",
        "plt.imshow(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "X5fjm0-OnNiF",
        "outputId": "f5c99b3f-b051-4c97-bedd-0058952dd845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6c97127850>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# we only have 1 not 3 dimensions per image thus only 1 mean and std\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "# get tensor image\n",
        "img_tr = transform(image)\n",
        "# calculate mean and std\n",
        "mean, std = img_tr.mean([1,2]), img_tr.std([1,2])\n",
        "# print mean and std\n",
        "print(\"mean and std before normalize:\")\n",
        "print(\"Mean of the image:\", mean)\n",
        "print(\"Std of the image:\", std)\n",
        "\n",
        "\n",
        "normalize = transforms.Normalize(mean=[0.0188],\n",
        "                                     std=[0.0278])\n",
        "augmentation = [transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
        "            transforms.RandomGrayscale(p=0.2),\n",
        "            transforms.ColorJitter(0.4, 0.4, 0.4, 0.4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(), normalize]\n",
        "aug = transforms.Compose(augmentation)\n",
        "img = aug(image)\n",
        "test2 =  torch.squeeze(img,0)\n",
        "plt.imshow(test2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "P1FzRzFAtAIt",
        "outputId": "2bcc8453-8875-46c8-cdd4-3a32f1330f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean and std before normalize:\n",
            "Mean of the image: tensor([0.0188])\n",
            "Std of the image: tensor([0.0278])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6c945a4c40>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}